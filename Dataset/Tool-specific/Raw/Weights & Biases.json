[
	{
		"Question_title": "About the W&B Help category",
		"Question_link": "https://community.wandb.ai/t/about-the-w-b-help-category/539",
		"Question_created_time": "2021-09-13T16:24:10.999Z",
		"Question_answer_count": 1,
		"Question_score_count": 1,
		"Question_view_count": 1074,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Ask your W&amp;B questions here. Let us know if you have an issue and one of our engineers or community experts will get back to you ASAP. If you have an urgent W&amp;B issue, please contact our support team at <a href=\"mailto:support@wandb.com\">support@wandb.com</a></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-24T10:22:12.884Z",
				"Answer_body": "",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Cross entropy ranges from 0 to 1?",
		"Question_link": "https://community.wandb.ai/t/cross-entropy-ranges-from-0-to-1/4201",
		"Question_created_time": "2023-04-09T20:10:34.109Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 126,
		"Question_has_accepted_answer": false,
		"Question_body": "<p><a href=\"https://wandb.ai/sauravmaheshkar/cross-entropy/reports/What-Is-Cross-Entropy-Loss-A-Tutorial-With-Code--VmlldzoxMDA5NTMx\">This post states that</a> \u2018Cross entropy loss is a metric used to measure how well a classification model in machine learning performs. The loss (or error) is measured as a number between 0 and 1, with 0 being a perfect model. The goal is generally to get your model as close to 0 as possible.\u2019 But as far as I understand, there is no upper bound for cross-entropy loss, as it is nothing but KL divergence differed by some constant.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-12T14:20:04.180Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/zyzhang\">@zyzhang</a>, thanks for pointing this out! I\u2019d say the upper bound of 1 only applies for binary clasification but not for multilabel clasification so this should be probably modifed. I\u2019ll ask internally about this!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-15T02:35:39.177Z",
				"Answer_body": "<p>Hi is there any update in this issue?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-19T15:07:49.591Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/zyzhang\">@zyzhang</a>, apologies for the delay here. This is been reviewed internally and will be updated. Thanks!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Error in W&B_Prompts_Quickstart notebook",
		"Question_link": "https://community.wandb.ai/t/error-in-w-b-prompts-quickstart-notebook/4411",
		"Question_created_time": "2023-05-16T07:36:59.108Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 20,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I have the following error while running <a href=\"http://wandb.me/prompts-quickstart\" rel=\"noopener nofollow ugc\">W&amp;B_Prompts_Quickstart notebook</a> <div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/8/88da9eb34b5ef62baf4fcd367d69c08d5579c825.png\" data-download-href=\"/uploads/short-url/jwFkh0P5adLx7fGnRM3YtxxLn4p.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/8/88da9eb34b5ef62baf4fcd367d69c08d5579c825.png\" alt=\"image\" data-base62-sha1=\"jwFkh0P5adLx7fGnRM3YtxxLn4p\" width=\"690\" height=\"289\" data-dominant-color=\"F4F4F4\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">774\u00d7325 8.32 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-16T10:13:37.937Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tinsae\">@tinsae</a> thanks for reporting this issue. There\u2019s a breaking change with newer LangChain version, and the Growth team is working on a fix.</p>\n<p>You could run the Prompts Quickstart notebook for now by pinning a previous LangChain version which I just tested and seems to be working fine. Could you please change the installation section as follows:</p>\n<pre><code class=\"lang-auto\">!pip install \"wandb&gt;=0.15.2\" -qqq\n!pip install \"langchain==v0.0.158\" openai\n</code></pre>\n<p>Would this work for you?</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-05-16T12:30:45.932Z",
				"Answer_body": "<p>That worked. Thank you!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-19T12:33:39.980Z",
				"Answer_body": "<p>Thank you <a class=\"mention\" href=\"/u/tinsae\">@tinsae</a> for the confirmation! We\u2019re planning on moving the integration to LangChain repo over the next days, so that this would be compatible with any newer versions. I will close this one for now, but please feel free to reopen this if you had more issues/questions.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Unable to login",
		"Question_link": "https://community.wandb.ai/t/unable-to-login/4335",
		"Question_created_time": "2023-05-03T20:51:16.135Z",
		"Question_answer_count": 8,
		"Question_score_count": 2,
		"Question_view_count": 341,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am unable to login to wandb init. This is the error code:</p>\n<pre><code class=\"lang-auto\">wandb.init()\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/__main__.py\", line 1, in &lt;module&gt;\n    from wandb.cli import cli\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/cli/cli.py\", line 932, in &lt;module&gt;\n    @display_error\n  File \"/opt/conda/lib/python3.7/site-packages/click/core.py\", line 1234, in decorator\n    cmd = command(*args, **kwargs)(f)\n  File \"/opt/conda/lib/python3.7/site-packages/click/decorators.py\", line 115, in decorator\n    cmd = _make_command(f, name, attrs, cls)\n  File \"/opt/conda/lib/python3.7/site-packages/click/decorators.py\", line 89, in _make_command\n    callback=f, params=params, **attrs)\nTypeError: __init__() got an unexpected keyword argument 'no_args_is_help'\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 1169, in init\n    raise e\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 1146, in init\n    wi.setup(kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 172, in setup\n    self._wl = wandb_setup.setup(settings=setup_settings)\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_setup.py\", line 327, in setup\n    ret = _setup(settings=settings)\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_setup.py\", line 320, in _setup\n    wl = _WandbSetup(settings=settings)\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_setup.py\", line 303, in __init__\n    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_setup.py\", line 114, in __init__\n    self._setup()\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_setup.py\", line 250, in _setup\n    self._setup_manager()\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_setup.py\", line 277, in _setup_manager\n    self._manager = wandb_manager._Manager(settings=self._settings)\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_manager.py\", line 145, in __init__\n    self._service.start()\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/service/service.py\", line 199, in start\n    self._launch_server()\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/service/service.py\", line 193, in _launch_server\n    _sentry.reraise(e)\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/analytics/sentry.py\", line 146, in reraise\n    raise exc.with_traceback(sys.exc_info()[2])\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/service/service.py\", line 191, in _launch_server\n    self._wait_for_ports(fname, proc=internal_proc)\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/service/service.py\", line 121, in _wait_for_ports\n    context=context,\nwandb.sdk.service.service.ServiceStartProcessError: The wandb service process exited with 1. Ensure that `sys.executable` is a valid python interpreter. You can override it with the `_executable` setting or with the `WANDB__EXECUTABLE` environmentvariable.\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-05T13:15:31.359Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/asking28\">@asking28</a> thanks for reporting this issue. From the stack trace error it appears it won\u2019t find a python interpreter in your environment. What\u2019s the output of these:</p>\n<pre><code class=\"lang-auto\">import sys\nprint(sys.executable)\n</code></pre>\n<p>Could you please also provide some more information, what\u2019s your current wandb client/SDK version? and where are you running this script? What happens if you call <code>wandb.login()</code>?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-05T21:18:31.202Z",
				"Answer_body": "<p>I am having a similar issue with the latest 0.15.1 version of wandb.<br>\nInstalling 0.15.0 works fine.</p>\n<p><code>sys.executable</code> for me is <code>/usr/bin/python3</code></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-05T22:17:46.104Z",
				"Answer_body": "<p>Its same as <a class=\"mention\" href=\"/u/anisha-mazumder\">@anisha-mazumder</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-05T22:19:37.881Z",
				"Answer_body": "<p>Thanks <a class=\"mention\" href=\"/u/anisha-mazumder\">@anisha-mazumder</a>  this solutions works for me as well.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-10T13:07:04.438Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/asking28\">@asking28</a> <a class=\"mention\" href=\"/u/anisha-mazumder\">@anisha-mazumder</a> could you please provide us with more information to help us find the root cause. What\u2019s your current training infrastructure and would you still receive this error after exporting the environment variable  <code>WANDB__EXECUTABLE</code> to your Python\u2019s binary path?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-15T17:18:16.588Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/asking28\">@asking28</a> just checking in here to see if you could provide us further information about your compute infra, and if you could create a new conda virtual environment to install there our latest wandb version and test if you\u2019re still getting this error? Thank you!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-16T02:15:20.956Z",
				"Answer_body": "<p>The same config does not work with 0.15.1 or 0.15.2<br>\nOS</p>\n<p>Linux-5.4.0-148-generic-x86_64-with-debian-buster-sid</p>\n<p>Python version</p>\n<p>3.7.3</p>\n<p>Python executable</p>\n<p>/opt/conda/bin/python</p>\n<p>System Hardware</p>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th>CPU count</th>\n<th>24</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>GPU count</td>\n<td>1</td>\n</tr>\n<tr>\n<td>GPU type</td>\n<td>NVIDIA RTX A6000</td>\n</tr>\n</tbody>\n</table>\n</div><p>W&amp;B CLI Version</p>\n<p>0.15.0</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-19T11:29:10.242Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/asking28\">@asking28</a> thanks for the additional information, I have installed the same Linux version in a VM and wasn\u2019t able to reproduce this issue. It might be related with a conflict with your other packages installed in your conda virtual environment. Could you please send us this file with all your dependencies:<br>\n<code>conda list --explicit &gt; requirements.txt</code></p>\n<p>Also, can you please try to create a new virtual environment and <code>pip install wandb</code> only, would you run into the same issue there as well?</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to create a copy of wandb plots online as well as offline",
		"Question_link": "https://community.wandb.ai/t/how-to-create-a-copy-of-wandb-plots-online-as-well-as-offline/4172",
		"Question_created_time": "2023-04-03T10:42:42.128Z",
		"Question_answer_count": 11,
		"Question_score_count": 0,
		"Question_view_count": 129,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi Everyone,</p>\n<p>How I can create a copy of a wandb logs? For example, I trained a model for 100 epochs and now I like to try several different configurations on top of it. The wandb should show me the previous logs and new logs on the same figure.<br>\nSuppose I have \u201cbase_experiment\u201d and on top of it, i want to run 4 different experiments. So I will have the following 5 experiments;</p>\n<ol start=\"0\">\n<li>base_experiment</li>\n<li>base_experiment_followed_by_configuration_1</li>\n<li>base_experiment_followed_by_configuration_2</li>\n<li>base_experiment_followed_by_configuration_3</li>\n<li>base_experiment_followed_by_configuration_4</li>\n</ol>\n<p>How i can create a copy of base experiment and use it for other 4 experiments?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-10T14:23:43.010Z",
				"Answer_body": "<p>Hi Vishal, and when you are talking about wandb logs, are you talking about the output logs in this case?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-10T16:41:31.006Z",
				"Answer_body": "<p>I am talking about the wandb logs which get pushed to the online wandb-api. Suppose I ran an \u201cexperiment_A\u201d, now I need to run the \u201cexperiment_B\u201d, the \u201cexperiment_B\u201d start from where \u201cexperiment_A\u201d left. One way to do it is to resume that training, but I want to have two separate experiments, one is original A and 2nd A+B.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-20T20:03:55.123Z",
				"Answer_body": "<p>Hi Vishal, apologies it took so long to get back to you had to check a few things internally. For a follow-up question, I am assuming when you are talking about different experiments, the main differences between them are going to be the datasets you are testing/training the models on?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-25T22:33:40.165Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-27T11:24:33.744Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/artsiom\">@artsiom</a>,</p>\n<p>Thanks for following up with me. Just wanted to let you know that I\u2019ll be using the same dataset for my project. Basically, I\u2019m working on a problem of continual learning. The idea is to train the model on a set of \u201cbase classes\u201d and then, at a later stage, train it on a set of \u201cother classes\u201d using different training configurations. This could be as simple as adjusting the learning rate or using knowledge distillation methods.</p>\n<p>The training process for the base classes takes around 3 days, so I\u2019m planning to save the logs for that run and then use them to try out different hyperparameters for the other classes. That way, I can start the wandb_logs directly from the base class logs for multiple runs.</p>\n<p>I hope this is clear. I have added a sample plot as well please see below.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/0/030b4265951d27780de074916aa061f173016fd0.jpeg\" data-download-href=\"/uploads/short-url/qVyrhsImdyPRhbQUXyhGHrHpHa.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/0/030b4265951d27780de074916aa061f173016fd0_2_526x500.jpeg\" alt=\"image\" data-base62-sha1=\"qVyrhsImdyPRhbQUXyhGHrHpHa\" width=\"526\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/0/030b4265951d27780de074916aa061f173016fd0_2_526x500.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/0/030b4265951d27780de074916aa061f173016fd0_2_789x750.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/0/030b4265951d27780de074916aa061f173016fd0_2_1052x1000.jpeg 2x\" data-dominant-color=\"FBFBFA\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1640\u00d71557 69.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-01T15:23:21.071Z",
				"Answer_body": "<p>Gotcha!</p>\n<p>Thank you so much for the graph and the explanation. Is there a specific python library you are using for your training?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-04T17:16:29.624Z",
				"Answer_body": "<p>Hi Vishal,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Is there a specific Python library you are using for your training?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-07T17:49:23.769Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/artsiom\">@artsiom</a>, Thank you for your reply. I am using PyTorchLightning for my experiments.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-11T19:31:55.980Z",
				"Answer_body": "<p>Perfect! Although it\u2019s not a perfect workaround, and is pretty hacky, I think what you could do is run the first part of your run in offline mode. Then sync it to wandb 4 different times using  <code>Wandb sync \u2014Id 12345678 path/to/dir</code> but with 4 different id\u2019s which should make it into 4 different runs in the UI. Then you can <a href=\"https://docs.wandb.ai/guides/runs/resuming\">resume those runs</a> with the configs  you would like.</p>\n<p>We do have a know bug that is being worked on, although logging all of the metrics works with the method,  where the console logs do get overwritten when you are resuming a run in that way.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-16T21:20:41.228Z",
				"Answer_body": "<p>Hey Vishal,</p>\n<p>Following up on this thread to see if the suggestion has helped you out at all?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-18T18:18:29.388Z",
				"Answer_body": "<p>Hi Vishal, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>\n<p>If you would like to reopen the conversation, please go ahead and open a new thread and link this one in there.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Log stats with different global steps",
		"Question_link": "https://community.wandb.ai/t/log-stats-with-different-global-steps/4375",
		"Question_created_time": "2023-05-11T05:56:21.634Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 43,
		"Question_has_accepted_answer": true,
		"Question_body": "<pre><code class=\"lang-auto\">wandb.log(train_stats, step=train_step)\nwandb.log(test_stats, step=test_step)\n</code></pre>\n<p>In my code, training and testing happen in parallel. I get training stats at every step, but testing stats are available only once in a while (I don\u2019t pause training to wait for testing results). For instance, I may get testing stats at steps [10, 12, 20, 33].<br>\nThe problem with this is that above commands doesn\u2019t work if <code>test_step</code> and <code>train_step</code> are not the same. Only the first <code>log</code> succeeds, and the second is not logged at all (no error, the program keeps running). If I pass the same step, e.g., <code>wandb.log(test_stats, step=train_step)</code> then it works.</p>\n<p>Is it possible to log stats with different steps?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-13T03:06:15.356Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/parisi\">@parisi</a> , happy to help. An important note about wandb step is it must always <a href=\"https://docs.wandb.ai/guides/track/log/logging-faqs#why-am-i-seeing-fewer-data-points-than-i-logged:~:text=monotonically%20increasing\">monotonically increase</a> and it increases with each wandb.log call. There are several way to specify which step to log at, including <a href=\"https://docs.wandb.ai/guides/track/log/customize-logging-axes\">custom logging axes</a>, or you could through conditional logic</p>\n<pre><code class=\"lang-auto\">wandb.log({\"train_acc\": acc}) #Logs every training step\nif epoch%5 ==0:\n          wandb.log({\"test_acc\": acc}) #Logs  every 5 training steps\n</code></pre>\n<p>See this <a href=\"https://wandb.ai/mohammadbakir/mb-custom-axis?workspace=user-mohammadbakir\">workspace</a> for a few toy examples of difference approach, code is included for each run.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-13T04:01:50.980Z",
				"Answer_body": "<p>Thanks, I am using <code>define_metric</code> and it works!<br>\nJust one more question. What I am doing is</p>\n<pre><code class=\"lang-auto\">wandb.define_metric('Steps')\nwandb.define_metric(\"*\", step_metric=\"Steps\")\nwandb.log({**train_stats, 'Steps': train_step})\nwandb.log({**test_stats, 'Steps': test_step})\n</code></pre>\n<p>However, wandb creates one plot for \u2018Steps\u2019 as well. Can I avoid that? I tried with <code>define_metric('Steps', hidden=True, step_sync=False)</code> but the plot is still there. It is just an useless plot and I would like to get rid of it.</p>\n<p>Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-18T17:47:57.050Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/parisi\">@parisi</a> ,</p>\n<p>You\u2019re welcome! I\u2019m glad to hear that <code>define_metric</code> is working well for your use case. Unfortunately, there isn\u2019t a direct method to hide the <code>steps charts</code> in the SDK. However, you can drag the steps chart to the hidden panel section of your main/run workspace. By doing so, any subsequent runs logged will automatically have the steps chart hidden from view. Marking initial inquiry resolved on our end, but please do reach out again anytime we could be of help.</p>",
				"Answer_has_accepted": true
			}
		]
	},
	{
		"Question_title": "How to log a table of media to artifacts",
		"Question_link": "https://community.wandb.ai/t/how-to-log-a-table-of-media-to-artifacts/4377",
		"Question_created_time": "2023-05-11T08:53:28.624Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 36,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am busy with an audio generation diffusion  project and would like to save and image and an audio file every epoch and track their evolving as artifacts, here is my current code:</p>\n<h1>\n<a name=\"log-media-table-1\" class=\"anchor\" href=\"#log-media-table-1\"></a>Log media table</h1>\n<pre><code>            wandb_table_media = wandb.Table(\n                    columns=['Epoch', 'Step', 'Clean-Images', \n                             'Generated-Mel-Images', 'Generated-Audio'])\n            img_shape = np.reshape(images[0], (1, 256, 256))\n            wandb_table_media.add_data(\n                epoch, \n                global_step, wandb.Image(clean_images[0]),\n                wandb.Image(img_shape),\n                wandb.Audio(normalize(audios[0]), sample_rate=sample_rate))\n            wandb.log({'wandb_table_media': wandb_table_media})\n            \n        # Log media artifact\n        \n            media_artifact = wandb.Artifact(\n                f'media-table-{args.project_name}',\n                type='table',\n                description='media-table'\n                )\n            media_artifact.add(wandb_table_media, \"media-table-sonic-diffusion\")\n            wandb.log_artifact(media_artifact,\n                               aliases=[f'step_{global_step}', f'epoch_{epoch}'])\n</code></pre>\n<p>It logs the table artifact fine in WANDB\u2026how do i create a table in WANDB to view these images and audio files?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-13T02:42:09.200Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/markstent\">@markstent</a> , happy to help. If you logged a table as an artifact you can view this table in the workspace using a <a href=\"https://docs.wandb.ai/guides/app/features/panels/weave#creating-weave-panels\">weave panel</a>.  After creating the panel, use the following weave query to view your artifact table.</p>\n<p><code>project.artifact(\"artifact-name\").versions.file(\"artifact-file-name\")</code>,</p>\n<p>example of this for <a href=\"https://wandb.ai/mohammadbakir/nature_photos/artifacts/run_table/run-1z5qqesz-test_results/v0/files\">this artifact</a></p>\n<p><code>project.artifact(\"run-1z5qqesz-test_results\").versions.file(\"test_results.table.json\")</code></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-18T17:34:43.447Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/markstent\">@markstent</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Run number of hyperparameter sweep?",
		"Question_link": "https://community.wandb.ai/t/run-number-of-hyperparameter-sweep/4419",
		"Question_created_time": "2023-05-17T20:15:39.476Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 21,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi there,</p>\n<p>When running a hyperparameter sweep, is there any option to access the run number of a particularl run, within the train() function?</p>\n<p>I have:</p>\n<pre><code class=\"lang-auto\">sweep_id = wandb.sweep(sweep=sweep_configuration, project='hyperparam_sweeps_dev')\n\nwandb.agent(sweep_id, function=train, count=8)\n</code></pre>\n<p>and would like to have a variable inside the train function that corresponds to the run number, which In this case would be from 1-8.</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-18T16:24:15.225Z",
				"Answer_body": "<p>Hi Chris,</p>\n<p>Happy to help. There isn\u2019t currently a way for you to access the run number directly, but here are a few workarounds:</p>\n<ul>\n<li>You can use <code>wandb.log</code> and manually log run numbers if you\u2019d like them to be numbered 1-8 (or if you\u2019d like to save them as artifacts, that is an option too)</li>\n<li>Alternatively, you can access the run ID for a particular run using <code>wandb.run.id</code> if you\u2019d like to access the unique run ID\u2019s for a particular run.</li>\n</ul>\n<p>All the best,</p>\n<p>Uma</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Expressions don't work for bar plots",
		"Question_link": "https://community.wandb.ai/t/expressions-dont-work-for-bar-plots/4302",
		"Question_created_time": "2023-04-30T21:55:17.692Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 40,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am plotting evaluation accuracies in a bar plot on my dashboard. I would like to subtract the baseline accuracy from these values, so I type the expression</p>\n<p>${summary:final_val/acc} - 0.726</p>\n<p>(where 0.726 is the baseline accuracy) into the expressions box, but nothing changes.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-01T22:21:57.386Z",
				"Answer_body": "<p>Hi! Could you send me a link to the workspace where you are experiencing this?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-05T15:25:55.854Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-10T17:31:19.140Z",
				"Answer_body": "<p>Hi Jeremiah, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know! Looks like our tickets aren\u2019t reopening after you write back in, so if you would like to reopen the conversation please create a new thread with a link referring to this one.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-18T13:45:32.591Z",
				"Answer_body": "<p>Hi,</p>\n<p>I would like to reopen this. For some reason, I did not get any email notifications about your reply so I never checked it, my apologies.</p>\n<p>Here is the workspace: <a href=\"https://wandb.ai/jcoholich/barc?workspace=user-jcoholich\" class=\"inline-onebox\">Weights &amp; Biases</a></p>\n<ul>\n<li>Jeremiah</li>\n</ul>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Adding media to a finished run",
		"Question_link": "https://community.wandb.ai/t/adding-media-to-a-finished-run/4420",
		"Question_created_time": "2023-05-18T01:40:58.929Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 9,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Some metrics I want to add to evaluate the performance of each trained ML model are very expensive to calculate, and need to be calculated after execution of the training script. But for the purposes of keeping all my plots together, it\u2019d be great to have these metrics added to the finished run, post hoc. Is it possible to do something like re-initialise a run in a seperate script, to add some additional media to the dashboard?</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-18T12:50:34.470Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/chris-pedersen\">@chris-pedersen</a>, thanks for your question! This is absolutely possible by resuming your run. <a href=\"https://docs.wandb.ai/guides/runs/resuming\">Here</a> you can have a look at our docs about resuming with a detailed explanation on how to do that. Please let me know if this is helpful!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb: Network error (SSLError), entering retry loop",
		"Question_link": "https://community.wandb.ai/t/wandb-network-error-sslerror-entering-retry-loop/4408",
		"Question_created_time": "2023-05-15T17:05:10.172Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 16,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Its my first time to use wandb and I\u2019m having issue with the initialisation. I did enter my API key.</p>\n<p>This issue get triggered when I call wandb.init():<br>\nwandb: Network error (SSLError), entering retry loop.<br>\nwandb: W&amp;B API key is configured. Use <code>wandb login --relogin</code> to force relogin</p>\n<p>I tried relogin many times but same issue keeps recurring. Could you please advise?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-17T22:46:34.152Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ahmadamer\">@ahmadamer</a> , happy to help. Could you try the following.</p>\n<ul>\n<li>Delete your netrc file storing your credentials, <code>rm ~/.netrc</code>\n</li>\n<li>Refresh your login <code>wandb login --relogin --cloud</code>\n</li>\n<li>Try the following, does it succeed</li>\n</ul>\n<pre><code class=\"lang-auto\">import wandb\nwandb.init(entity=\"&lt;your-entity&gt;\", project=\"test-project\") \nwandb.finish()\n</code></pre>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Box plot - sweep",
		"Question_link": "https://community.wandb.ai/t/box-plot-sweep/4406",
		"Question_created_time": "2023-05-15T15:56:27.460Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 16,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi.<br>\nI\u2019m running a sweep on some hyper-parameter (let\u2019s say learning_rate).<br>\nIn each run, I  obtain a list of length N: rewards = [1, 2, 3, 4, 5, \u2026].<br>\nDuring the sweep, I want to obtain a box plot for each individual run (where the x-axis is the hyper-parameter (learning_rate)), and ultimatly I want to view all of the box plots in the same figure so i can compare the hyper-parameter values.<br>\nThanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-17T21:29:54.087Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/eladsharony\">@eladsharony</a> thanks for writing in! This could be feasible with a Custom Chart using a customised Vega spec. Just wanted to confirm would something like <a href=\"https://vega.github.io/editor/#/examples/vega-lite/boxplot_2D_vertical\" rel=\"noopener nofollow ugc\">this plot</a> work for you, where in X-Axis you have the different runs labelled by their learning rate? also, how are you logging the rewards, are these in <code>wandb.Table</code> or as a metric\u2019s history?</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Artifacts version",
		"Question_link": "https://community.wandb.ai/t/artifacts-version/4379",
		"Question_created_time": "2023-05-11T14:29:47.945Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 40,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Is there a way to either 1) set a max to the number of versions an artifact can have (if more are uploaded then oldest get deleted), or 2) keep only the latest version?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-11T23:15:19.157Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/parisi\">@parisi</a> !</p>\n<p>You can do this by deleting all artifacts that do not have the alias <code>latest</code> (which is outlined <a href=\"https://docs.wandb.ai/guides/artifacts/delete-artifacts#delete-all-versions-of-an-artifact-that-do-not-have-an-alias\">here</a> in our docs. You could write a script to assign tags to the last newest 5 artifacts by obtaining the versions of all artifacts and deleting anything that is not the five newest versions. However, deleting all artifacts but the <code>latest</code> will be easier.</p>\n<p>Warning: I would recommend waiting to delete artifacts once that have already been uploaded to <code>wandb</code>. If you delete an artifact that is still in the middle of uploading, it may cause issues. For example, if you make deleting all but the latest artifact as part of your code, it may break the process since some artifacts will be delete before they are uploaded. Therefore, it would be safe to include a buffer i.e. delete all but the last 5 artifacts.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-12T18:10:39.802Z",
				"Answer_body": "<p>Thanks!</p>\n<p>It would be nice to have a command to define a policy that takes care of that. Like <code>wand.config_artifacts</code> where you define how many versions of each artifact (or what artifact, passing its name) you want to keep.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-17T18:10:27.946Z",
				"Answer_body": "<p>That is a fair recommendation and I can pass this to our SDK team via a feature request. The team is scoping on what methods to implement for artifact deletion so this will be helpful. Thanks!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Filter just one plot",
		"Question_link": "https://community.wandb.ai/t/filter-just-one-plot/4390",
		"Question_created_time": "2023-05-12T22:06:02.225Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 31,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am doing a big sweep over my hyperparameters. I can plot the same statistic (accuracy) in multiple plots, grouping each plot by a different hyperparameter. Then, by looking at the plots I can see which hyperparameters perform best.<br>\nAt this point, I need to plot the accuracy in one plot filtering according to the best hyperparameters. I can use the filter button above the runs, but that filters ALL plots. I want to filter only one plot.<br>\nHow can I do that?</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-17T17:56:53.245Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/parisi\">@parisi</a> !</p>\n<p>As you mentioned, the grouping and filtering will apply to all plots within the workspace. Since you would like to have different filters for different plots, I would recommend <a href=\"https://docs.wandb.ai/guides/reports/create-a-report\">making a Report</a> and visualizing the plots there. In a Report, you will be able to add <a href=\"https://docs.wandb.ai/guides/reports/edit-a-report#add-run-sets\">Run Sets</a> in which you can apply different filters and groupings of the data. Each plot will be based on the associated Run Sets. If you have graphs you already have, you can <a href=\"https://docs.wandb.ai/guides/reports/cross-project-reports#send-a-graph-to-a-report\">send the graph to a Report</a> and it will appear on the Report.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb.finish() takes too long to finish",
		"Question_link": "https://community.wandb.ai/t/wandb-finish-takes-too-long-to-finish/4415",
		"Question_created_time": "2023-05-17T01:44:44.091Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 26,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I was working with wandb to track my experiment.<br>\nThe experiment run on the GKE cluster by using MLFlow Projects.<br>\nBut, from several weeks ago (I suggest it\u2019s around the release of wandb 0.15.0), I found that my training job doesn\u2019t exit just after it finished the traininig job. It finished almost after 24 hours.<br>\nI didn\u2019t mkae breaking change in my code. So I\u2019m suspecting whether there is discrepency on this situation.<br>\nBecause of that reason, I started to fix version of wandb to be 0.14.2 rather than 0.15.0.<br>\nCan I get the help?<br>\nHere is the last log from the running process.</p>\n<hr>\n<p>wandb: Waiting for W&amp;B process to finish\u2026 (success).<br>\nwandb: Network error (ReadTimeout), entering retry loop.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-17T17:30:14.485Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/axb-data\">@axb-data</a> !</p>\n<p>If there has not been any changes and you are now just experiencing this error, could you send me the debug logs for this run?</p>\n<p>They should be located in the <code>wandb</code> folder in the same directory as where the script was run. The <code>wandb</code> folder has folders formatted as <code>run-DATETIME-ID</code> associated with a single run. Could you retrieve the <code>debug.log</code> and <code>debug-internal.log</code> files from one of these folders specifically from the run that is having issues?</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Error installing @wandb/sdk",
		"Question_link": "https://community.wandb.ai/t/error-installing-wandb-sdk/4374",
		"Question_created_time": "2023-05-11T04:13:49.798Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 33,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi - tried to install JS lib with most recent langchain version, but failed.<br>\nWhen i forced install, there was a runtime error as well. Maybe SDK hasn\u2019t caught up to most recent langchain version?</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/e/eeed937064538e9dbb56f6e12befa07cdc59d26d.png\" data-download-href=\"/uploads/short-url/y5EDO4fdEWd8RakxKMamNcED4q9.png?dl=1\" title=\"Screenshot 2023-05-10 at 9.08.44 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/eeed937064538e9dbb56f6e12befa07cdc59d26d_2_690x382.png\" alt=\"Screenshot 2023-05-10 at 9.08.44 PM\" data-base62-sha1=\"y5EDO4fdEWd8RakxKMamNcED4q9\" width=\"690\" height=\"382\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/eeed937064538e9dbb56f6e12befa07cdc59d26d_2_690x382.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/eeed937064538e9dbb56f6e12befa07cdc59d26d_2_1035x573.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/e/eeed937064538e9dbb56f6e12befa07cdc59d26d.png 2x\" data-dominant-color=\"2D2C2C\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2023-05-10 at 9.08.44 PM</span><span class=\"informations\">1136\u00d7630 92.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-11T17:54:47.859Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/benjaminrigby\">@benjaminrigby</a> thanks so much for reporting this issue. We\u2019ve just released 0.4.0 to address this, could you please install the newest <code> wandb-js</code> version and check if that would work for you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-17T16:47:23.617Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/benjaminrigby\">@benjaminrigby</a> we\u2019ve released v0.5.0 to additionally tackle an issue with LangChain. Could you please try to install this version and try your code again? Thank you!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Problem loading code when using code saving",
		"Question_link": "https://community.wandb.ai/t/problem-loading-code-when-using-code-saving/4303",
		"Question_created_time": "2023-05-01T07:23:11.773Z",
		"Question_answer_count": 14,
		"Question_score_count": 0,
		"Question_view_count": 86,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\nI am trying to use code saving function but get errors when attempt to compare codes:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/e/e99ef3d13a44e6db4754295d293a1ebbfb7c6595.png\" data-download-href=\"/uploads/short-url/xkHNSPbTfeOJK7EM8gc2TJecNG5.png?dl=1\" title=\"Screenshot from 2023-05-01 09-12-11\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/e99ef3d13a44e6db4754295d293a1ebbfb7c6595_2_690x334.png\" alt=\"Screenshot from 2023-05-01 09-12-11\" data-base62-sha1=\"xkHNSPbTfeOJK7EM8gc2TJecNG5\" width=\"690\" height=\"334\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/e99ef3d13a44e6db4754295d293a1ebbfb7c6595_2_690x334.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/e99ef3d13a44e6db4754295d293a1ebbfb7c6595_2_1035x501.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/e99ef3d13a44e6db4754295d293a1ebbfb7c6595_2_1380x668.png 2x\" data-dominant-color=\"F4F4F4\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot from 2023-05-01 09-12-11</span><span class=\"informations\">2394\u00d71161 105 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nI follow the instruction here: <a href=\"https://docs.wandb.ai/guides/app/features/panels/code\">https://docs.wandb.ai/guides/app/features/panels/code</a> and this is how I call this function in my coding:</p>\n<pre><code class=\"lang-auto\">    run = wandb.init(name=args.log_id, config=args, project=args.project, entity=args.entity, settings=wandb.Settings(code_dir=\".\"))\n</code></pre>\n<p>I am not sure where I did wrong. Thanks for your help!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-03T12:40:55.223Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/1060111768\">@1060111768</a>, thanks for reporting this! Could you please send me a link to that project so I can have a look at the issue? Also, if you access every single run, are you able to see the code under the code tab?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-05T09:02:39.052Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-05T20:25:40.240Z",
				"Answer_body": "<p>Hi,<br>\nsorry to reply late. I made a new trial, and this problem updates:</p>\n<ol>\n<li>\n<p>Codes can be saved in personal entity, but not in company/insititue entity<br>\nHere is a personal link, it has records:<br>\n<a href=\"https://wandb.ai/kiglis_trial/saving_codes_trial?workspace=user-1060111768\" class=\"inline-onebox\">Weights &amp; Biases</a><br>\nHere is a institute-coorperative link, it doesn\u2019t record:<br>\n<a href=\"https://wandb.ai/graph-diffusion-model-link-prediction/saving_codes_trial?workspace=user-1060111768\" class=\"inline-onebox\">Weights &amp; Biases</a></p>\n</li>\n<li>\n<p>I can only save the script which contains the line for coding saving: <code>wandb.run.log_code(\".\")</code> or  <code>wandb.init(settings=wandb.Settings(code_dir=\".\"))</code>. I cannot save other files, even though I have set other paths:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/a15be07274a63eca57acc4e25efd963ff937996a.png\" data-download-href=\"/uploads/short-url/n1rIv5c9tacPG7IY5VtUJizkz9w.png?dl=1\" title=\"Screenshot from 2023-05-05 22-22-39\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/a15be07274a63eca57acc4e25efd963ff937996a_2_690x176.png\" alt=\"Screenshot from 2023-05-05 22-22-39\" data-base62-sha1=\"n1rIv5c9tacPG7IY5VtUJizkz9w\" width=\"690\" height=\"176\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/a15be07274a63eca57acc4e25efd963ff937996a_2_690x176.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/a15be07274a63eca57acc4e25efd963ff937996a.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/a15be07274a63eca57acc4e25efd963ff937996a.png 2x\" data-dominant-color=\"352719\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot from 2023-05-05 22-22-39</span><span class=\"informations\">866\u00d7221 37.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n</li>\n</ol>\n<p>Thanks for your help!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-09T15:47:36.833Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/1060111768\">@1060111768</a>, thanks for providing this context! This is probably because you have the code saving option disabled under your team settings. Could you please enable it and try again?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/220e825809aefe49ba7ead7be134080767c9332e.jpeg\" data-download-href=\"/uploads/short-url/4RhjOZPcyM5MKh3sSKdRWWm7wZ0.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/220e825809aefe49ba7ead7be134080767c9332e_2_690x285.jpeg\" alt=\"image\" data-base62-sha1=\"4RhjOZPcyM5MKh3sSKdRWWm7wZ0\" width=\"690\" height=\"285\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/220e825809aefe49ba7ead7be134080767c9332e_2_690x285.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/220e825809aefe49ba7ead7be134080767c9332e_2_1035x427.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/220e825809aefe49ba7ead7be134080767c9332e_2_1380x570.jpeg 2x\" data-dominant-color=\"F8F8F8\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1920\u00d7794 62 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-09T16:12:12.806Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/luis_bergua1\">@luis_bergua1</a> ,</p>\n<p>thanks for your advice. I found that in my personal project, I have already <strong>enabled code saving by default</strong>, so it can save codes. But I am not sure if it also the same in another coorperated project, because I am not the Administrator of that project. I will turn to the Administrator about this.</p>\n<p>By the way, about another question, is there a clue why cannot I save other files with this?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/a15be07274a63eca57acc4e25efd963ff937996a.png\" data-download-href=\"/uploads/short-url/n1rIv5c9tacPG7IY5VtUJizkz9w.png?dl=1\" title=\"Screenshot from 2023-05-05 22-22-39\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/a15be07274a63eca57acc4e25efd963ff937996a_2_690x176.png\" alt=\"Screenshot from 2023-05-05 22-22-39\" data-base62-sha1=\"n1rIv5c9tacPG7IY5VtUJizkz9w\" width=\"690\" height=\"176\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/a15be07274a63eca57acc4e25efd963ff937996a_2_690x176.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/a15be07274a63eca57acc4e25efd963ff937996a.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/a15be07274a63eca57acc4e25efd963ff937996a.png 2x\" data-dominant-color=\"352719\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot from 2023-05-05 22-22-39</span><span class=\"informations\">866\u00d7221 37.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nthank you very much!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-09T16:24:20.660Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/1060111768\">@1060111768</a>, sounds good! The reason is probably the same, the code saving flag not enabled as that\u2019s the behavior I\u2019m getting on my end. Could you please inform me if this is not the case once you get that enabled?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-09T16:55:35.561Z",
				"Answer_body": "<p>OK. I will wait for the administrator of another coorperated project to response <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-11T10:52:56.143Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/1060111768\">@1060111768</a>, sounds good! Let me know if this fixes the issue!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-12T09:29:59.624Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/luis_bergua1\">@luis_bergua1</a> ,<br>\nthe administrator of my coorperated project has checked enable code saving by default, and the code can be saved now. Thanks!<br>\nBut there is still a problem. I can still only record the code file containing line <code>run.log_code()</code>, I cannot record any other files. And what is strange is, after I even comment <code>run.log_code()</code>, it still record the file and only the file.<br>\nI tried the solution here, it still doesn\u2019t solve this problem:</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/ref/python/run#log_code\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/a8a891bd0c452878b336bf4d3feef488fb0dff8c.png\" class=\"site-icon\" data-dominant-color=\"FCB119\" width=\"27\" height=\"27\">\n\n      <a href=\"https://docs.wandb.ai/ref/python/run#log_code\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    \n\n<h3><a href=\"https://docs.wandb.ai/ref/python/run#log_code\" target=\"_blank\" rel=\"noopener\">Run | Weights &amp; Biases Documentation</a></h3>\n\n  <p>View source on GitHub</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<pre><code class=\"lang-auto\">run.log_code(\n \"../\", include_fn=lambda path: path.endswith(\".py\") or path.endswith(\".ipynb\")\n)\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-17T09:46:12.055Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/1060111768\">@1060111768</a>, thanks for your reply and sorry that this is still causing issues! Would it be possible to share the structure of your folder so I can try to reproduce this on my end? Also, could you please share your <code>wandb</code> version with <code>pip show wandb</code>?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-17T12:13:46.388Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/luis_bergua1\">@luis_bergua1</a> ,<br>\nI am not sure how to share my folder structure. Is it ok to share a screenshot like this?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/c/cae76fe80b67f62d00325f12c4f59b2db922cda9.png\" data-download-href=\"/uploads/short-url/sWYiEi7PWd9enBreB85rISnGZMR.png?dl=1\" title=\"Screenshot from 2023-05-17 14-12-24\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/cae76fe80b67f62d00325f12c4f59b2db922cda9_2_259x500.png\" alt=\"Screenshot from 2023-05-17 14-12-24\" data-base62-sha1=\"sWYiEi7PWd9enBreB85rISnGZMR\" width=\"259\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/cae76fe80b67f62d00325f12c4f59b2db922cda9_2_259x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/cae76fe80b67f62d00325f12c4f59b2db922cda9_2_388x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/c/cae76fe80b67f62d00325f12c4f59b2db922cda9.png 2x\" data-dominant-color=\"392C18\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot from 2023-05-17 14-12-24</span><span class=\"informations\">440\u00d7847 41.2 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>And here is the verson I installed:</p>\n<pre><code class=\"lang-auto\">Name: wandb\nVersion: 0.13.9\nSummary: A CLI and library for interacting with the Weights and Biases API.\nHome-page: https://github.com/wandb/wandb\nAuthor: Weights &amp; Biases\nAuthor-email: support@wandb.com\nLicense: MIT license\nLocation: /home/hardli/anaconda3/envs/kiglis/lib/python3.10/site-packages\nRequires: appdirs, Click, docker-pycreds, GitPython, pathtools, protobuf, psutil, PyYAML, requests, sentry-sdk, setproctitle, setuptools\nRequired-by:\n</code></pre>\n<p>Thanks a lot!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-17T12:45:37.444Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/1060111768\">@1060111768</a>, thanks a lot for sharing this! Could you try upgrading to the latest <code>wandb</code> package (<code>0.15.2</code>) with <code>pip install wandb --upgrade</code> and see if the behavior is still the same? Regarding your folder structure, that\u2019s helpful! Would you mind explaining to me which file are you executing and which ones are you trying to log?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-17T14:13:27.298Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/luis_bergua1\">@luis_bergua1</a> ,<br>\nI tried the updated version. The problem remains. I can still only record the file executing <code>wandb.init()</code>.<br>\nI execute the file <code>run_sciimproved.py</code>, which contains <code>wandb.init()</code> and is located in most outside of this folder <code>SCINET-KIGLIS</code>, and tried to record <code>utils/util.py</code>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-17T14:17:18.282Z",
				"Answer_body": "<p>May I ask how it should be like to record other files, if it is successfully recorded? I am not sure now whether I operated something wrong. I check the recorded files with<code> Add panel - Code</code> here:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/c/cdcb64126d7f5a585717de2fb0125221c8a88985.png\" data-download-href=\"/uploads/short-url/tmxDXgcAce26DW12Zcltp2Cpl4x.png?dl=1\" title=\"Screenshot from 2023-05-17 16-14-59\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/cdcb64126d7f5a585717de2fb0125221c8a88985_2_566x500.png\" alt=\"Screenshot from 2023-05-17 16-14-59\" data-base62-sha1=\"tmxDXgcAce26DW12Zcltp2Cpl4x\" width=\"566\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/cdcb64126d7f5a585717de2fb0125221c8a88985_2_566x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/cdcb64126d7f5a585717de2fb0125221c8a88985_2_849x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/c/cdcb64126d7f5a585717de2fb0125221c8a88985.png 2x\" data-dominant-color=\"FBFBFB\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot from 2023-05-17 16-14-59</span><span class=\"informations\">960\u00d7847 53.4 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nAnd in the panel, I can see this comparison:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/9/97bcc76c919fadc6f726e0e886a4384d403ab276.png\" data-download-href=\"/uploads/short-url/lEkyq77MPBCa7ErLHrZ7NpkZkKa.png?dl=1\" title=\"Screenshot from 2023-05-17 16-15-44\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/9/97bcc76c919fadc6f726e0e886a4384d403ab276_2_689x340.png\" alt=\"Screenshot from 2023-05-17 16-15-44\" data-base62-sha1=\"lEkyq77MPBCa7ErLHrZ7NpkZkKa\" width=\"689\" height=\"340\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/9/97bcc76c919fadc6f726e0e886a4384d403ab276_2_689x340.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/9/97bcc76c919fadc6f726e0e886a4384d403ab276_2_1033x510.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/9/97bcc76c919fadc6f726e0e886a4384d403ab276_2_1378x680.png 2x\" data-dominant-color=\"EEF2EF\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot from 2023-05-17 16-15-44</span><span class=\"informations\">2390\u00d71178 338 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nBut there is only this file inside. This is the one executing <code>wandb.init()</code> but not the one I set to be recorded.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "BUG: Line-Plot, X-Axis Settings not working in report",
		"Question_link": "https://community.wandb.ai/t/bug-line-plot-x-axis-settings-not-working-in-report/4417",
		"Question_created_time": "2023-05-17T07:18:42.591Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 11,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>If one combines two Line-Plots in one report, data points vanish if one sets the X-Axis Max to something in the range of existing data points. For example, WandB crops away a big portion of the blue line if setting the X-Max to 6M but it clearly has more than 6M (see screenshots).  What\u2019s happening here?</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/9/98dc8098b54028cebc832276757f22756b6f8c89.jpeg\" data-download-href=\"/uploads/short-url/lOgZYlWwsqAJjHyMl3XUEBGawm5.jpeg?dl=1\" title=\"Screenshot 2023-05-17 at 09.26.32\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/9/98dc8098b54028cebc832276757f22756b6f8c89_2_604x499.jpeg\" alt=\"Screenshot 2023-05-17 at 09.26.32\" data-base62-sha1=\"lOgZYlWwsqAJjHyMl3XUEBGawm5\" width=\"604\" height=\"499\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/9/98dc8098b54028cebc832276757f22756b6f8c89_2_604x499.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/9/98dc8098b54028cebc832276757f22756b6f8c89_2_906x748.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/9/98dc8098b54028cebc832276757f22756b6f8c89_2_1208x998.jpeg 2x\" data-dominant-color=\"F5F5F7\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2023-05-17 at 09.26.32</span><span class=\"informations\">1920\u00d71588 112 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-17T07:46:47.757Z",
				"Answer_body": "<p>It also happens if you only select one plot. How come this is in production?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-18T17:19:54.465Z",
				"Answer_body": "<p>Hey Maitreya,</p>\n<p>Thank you so much for reporting this. Could you send a screenshot of what you\u2019re seeing on your side as well as a link to your workspace?</p>\n<p>Best,</p>\n<p>Uma</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Is it possible to log to multiple runs simultaneously",
		"Question_link": "https://community.wandb.ai/t/is-it-possible-to-log-to-multiple-runs-simultaneously/4387",
		"Question_created_time": "2023-05-12T14:01:35.935Z",
		"Question_answer_count": 2,
		"Question_score_count": 1,
		"Question_view_count": 47,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019d like to log to multiple separate runs (experiments) from a single script, but I\u2019m not sure if it\u2019s possible to do this so I\u2019m asking for help here.</p>\n<p>The issue I\u2019m facing is that my code uses a relatively small model, but is bottlenecked by data loading so GPU utilization is quite low. Thus, the goal is to update multiple individual models per batch, which would help \u2018hide\u2019 the data loading time by spending more time with GPU compute.<br>\nThen for each model, I\u2019d have a corresponding \u2018run\u2019 object in WandB:</p>\n<pre><code class=\"lang-python\">for x, labels in dataloader:\n    loss1 = model1(x, labels)\n    loss2 = model2(x, labels)\n    ...\n    lossN = modelN(x, labels)\n    run1.log({'loss': loss1.item()})\n    run2.log({'loss': loss2.item()})\n    ....\n    runN.log({'loss': lossN.item()})\n</code></pre>\n<p>The issue is that the traditional <code>wandb.log()</code> seems like a call to some global run instance and can\u2019t be split into multiple individual instances.</p>\n<p>Is it possible to achieve this with WandB? Perhaps using <code>wandb.Api()</code> is a starting point, but I\u2019m not sure if it\u2019s feasible.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-15T22:53:37.715Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/numpee\">@numpee</a>!</p>\n<p>Happy to help!</p>\n<p>Running multiple <code>run = wandb.init()</code> at the same time will cause errors or take a long time as the client would have to change runs often so I suggest to log at the end of your script with something like the following:</p>\n<pre><code class=\"lang-auto\">import wandb\n\nloss1 = []\nloss2 = []\n\n\n### Your training here resulting in\n### loss1 = [&lt;loss from run1&gt;]\n### loss2 = [&lt;loss from run2&gt;]\n\n\nrun1 = wandb.init(project = &lt;project&gt;)\nrun1.log({'loss':loss1})\nrun1.finish()\nrun2 = wandb.init(project = &lt;project&gt;)\nrun2.log({'loss':loss2})\nrun2.finish()\n\n# or log it like\n\nlosses = [loss1, loss2]\n\nfor loss in losses:\n     step = 1\n     run = wandb.init(&lt;project-name&gt;)\n     for val in loss:\n          run.log({\"loss\": val},  step = step)\n          step  +=1 \n     run.finish()\n</code></pre>\n<p>This may not be an ideal setup for you but this would work as a workaround to log multiple runs in the same script. Would this work for you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-17T04:01:28.657Z",
				"Answer_body": "<p>Hi, thanks for the response.<br>\nI was hoping there\u2019d be a clever way to be able to track values real time in the web client, but I guess not. I think one workaround would be to keep logging one experiment real-time, while others are logged afterwards (like in the second example you provided).<br>\nThat should work - Thanks for the idea!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb error by usage of mlflow",
		"Question_link": "https://community.wandb.ai/t/wandb-error-by-usage-of-mlflow/4401",
		"Question_created_time": "2023-05-14T19:24:32.896Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 34,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I 'm getting the exact same error with this <a href=\"https://community.wandb.ai/t/wandb-error-by-usage-of-mlflow-and-hydra-regarding-protobuf-lib/3866/1\">one</a> .  I tried to  create a new venv either with conda, venv but, downgrade protobuf but it persists.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-15T19:25:46.000Z",
				"Answer_body": "<p>Hi all,</p>\n<p>Sorry for not having answered adding the issue to the community, I was too busy \u2026<br>\nNevertheless, my virutal env for the project is created and activated from conda.</p>\n<p>Regards,<br>\nIlona</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-16T23:40:00.130Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/imanousar\">@imanousar</a>, happy to help. Could you expand on your specific problem. What is it that you are running into? Version incompatibilities?</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to speed up batch delete of files & artifacts?",
		"Question_link": "https://community.wandb.ai/t/how-to-speed-up-batch-delete-of-files-artifacts/4251",
		"Question_created_time": "2023-04-21T03:41:22.710Z",
		"Question_answer_count": 6,
		"Question_score_count": 1,
		"Question_view_count": 139,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have been concerned with trying to stay within the 100GB limit on files and artifact storage imposed by Wandb, so I have the idea to delete files &amp; artifacts on old runs.</p>\n<p>However, I do not want to delete all files on those runs! It is definitely useful to be able to see the progression of generated files over time. I don\u2019t need to see all 50,000 or so logged steps on each run, but I\u2019ll just keep 100 of them evenly spaced in time. so I programmed a script to do that by indexing all my files on Wandb using the Python API, grouping them, sorting them, and selecting files to delete.</p>\n<p>My issue comes with how slow the current API seems to be to delete files &amp; artifacts: Using <a href=\"https://docs.wandb.ai/ref/python/public-api/file#delete\">File.delete</a>, it takes around 2s per file. With hundreds of runs and tens of thousands of files per run, I am then looking at weeks of time needed to delete the files I need to delete.</p>\n<p>I then tried to refactor my code into parallel workers, thinking I could increase that speed several fold, but I quickly ran into the 200 call/minute <a href=\"https://docs.wandb.ai/guides/track/limits#rate-limits\">rate limit</a>. It even started to affect my ongoing runs.</p>\n<p>Is there any better way I could prune the files &amp; artifacts so that I could have the process complete faster?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-21T18:45:05.693Z",
				"Answer_body": "<p>While I do not have the answer, I would like to bump this post and hope W&amp;B could chime in with a solution.</p>\n<p>I was also looking at deleting specific files from a run to keep within the quota, but also to avoid saving files that would never be used, e.g., models within a sweep that performed poorly.</p>\n<p>The files are <strong>not</strong> logged as artifacts in my case.</p>\n<p>Hope someone can help?<br>\nI note that there are other people requesting support with similar issues as seen in<br>\n<a href=\"https://community.wandb.ai/t/how-to-delete-files-like-images-and-tables-logged-in-the-files-section/2552\">[1]</a> and <a href=\"https://community.wandb.ai/t/delete-files-from-a-run/1031\">[2]</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-24T03:46:19.028Z",
				"Answer_body": "<p>Even after adding a mechanism to limit my deletions/s to 1, I was still getting regular errors from the wandb API. It is now running stably at 0.5 delete/s\u2026 ETA &gt; 1 year <img src=\"https://emoji.discourse-cdn.com/twitter/sweat_smile.png?v=12\" title=\":sweat_smile:\" class=\"emoji\" alt=\":sweat_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<p>To me, this seems much slower than what <code>wandb sync [...]</code> is capable of doing\u2026 I wonder if the rate limiting counts that as just 1 API call, even if it uploads tens of thousands of files. I wonder if that could be my solution? Would <code>wandb sync</code> be able to delete online files if I delete them from a downloaded run locally, then sync the folder?</p>\n<p>My testing cannot really proceed, since I am now blocked from even the wandb web console by \u201crate limit exceeded\u201d error messages. I might wait a few hours (<a href=\"https://community.wandb.ai/t/rate-limit-exceeded-wandb-website/3001\">or days</a>) and see if it disappears.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-25T18:22:01.203Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/snobso\">@snobso</a> and <a class=\"mention\" href=\"/u/aabywan\">@aabywan</a> , thank you both for writing in and providing your valuable feedback. This specific request hasn\u2019t surfaced in a while, so the status of batch deletion or improvements in how API handles many file deletions isn\u2019t changed. At this time the user:</p>\n<ul>\n<li>Could delete an entire run and it\u2019s files</li>\n<li>Rate limit their calls for individual file deletions.</li>\n</ul>\n<p>I filed a feature request with eng and will keep you updated once they\u2019ve reviewed your request.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-28T10:38:30.685Z",
				"Answer_body": "<p>Thanks. Is that feature request anywhere public, so that I could vote for it?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-05T03:50:15.310Z",
				"Answer_body": "<p>I\u2019m not sure if this would apply to all use cases, but in my case, a RegEx-based or glob-like deletion API would be extremely helpful</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-16T21:46:54.999Z",
				"Answer_body": "<p>Appreciate the feature request.</p>\n<p>In my preferences, I would like to see the \u201cfiles\u201d option be more like a files explore where you can do the expected file management including move, delete, rename, copy, and so on similar to a file explore on operating systems.</p>\n<p>Best,<br>\nPeter.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Exporting api stopped working",
		"Question_link": "https://community.wandb.ai/t/exporting-api-stopped-working/4404",
		"Question_created_time": "2023-05-15T14:19:52.491Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 17,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>The following code until recently was working. right now it only send back \u201cNone\u201d for every logged value.</p>\n<pre><code class=\"lang-auto\">import wandb\napi = wandb.Api(timeout=109)\nentity, project = \"barthelemymp\", \"Generalization_below20out\"  # set to your entity and project \ngen = api.run(\"barthelemymp/Generalization_below20out/6hz5riae\")\nresults300 = {}\n\nfor row in gen.scan_history():\n    if \"epochT\" in row.keys():\n        if row[\"epochT\"] == 300:\n            for k in row.keys():\n                if \"_e\" in k:\n                    print(k)\n                    results300[k] = 1- row[k]\n                    \n\n</code></pre>\n<p>Mainly here I save every logged value which name end in \u201c_e\u201d at epoch 300.<br>\nEventhough the code is probably not the most efficient until recently it was loading the correct values (for the same run). Something changed apparently</p>\n<p>I really need to be able to have access to this data. What happened ?</p>\n<p>Best</p>\n<p>Barthelemy</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-15T15:54:16.881Z",
				"Answer_body": "<p>Hi Baethelemy,</p>\n<p>Could you send me a link to a run you are trying to access using the API?</p>\n<p>Warmly,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-16T15:04:29.997Z",
				"Answer_body": "<p>Thanks <a class=\"mention\" href=\"/u/artsiom\">@artsiom</a></p>\n<p>Here is the link: <a href=\"https://wandb.ai/barthelemymp/Generalization_below20out/runs/6hz5riae?workspace=user-barthelemymp\" class=\"inline-onebox\">Weights &amp; Biases</a></p>\n<p>Best regards</p>\n<p>Barth</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Default grouping range",
		"Question_link": "https://community.wandb.ai/t/default-grouping-range/4381",
		"Question_created_time": "2023-05-11T20:46:14.151Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 37,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>When I group runs using the \u201cgroup\u201d field, all my plots are grouped nicely. However, the default range for all is min/max. I need to use std dev, and the only way to do that is to manually change it for every plot. This is very annoying. Isn\u2019t there a way to select std dev as default grouping range?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-15T20:53:09.732Z",
				"Answer_body": "<p>Hey Simone,</p>\n<p>Thank you very much for this feature  request. I\u2019ve logged it in our system and I\u2019ll update you once I get feedback from our app team.</p>\n<p>Best,</p>\n<p>Uma</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Average multiple runs over one parameter",
		"Question_link": "https://community.wandb.ai/t/average-multiple-runs-over-one-parameter/4371",
		"Question_created_time": "2023-05-10T19:29:05.478Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 34,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am doing a sweep over multiple parameters. For every configuration, I also have a seed to control randomness.<br>\nFor instance, let\u2019s say I am sweeping over learning rate in [0.1, 0.01] and batch size in [16, 32]. This will give me 4 runs, and for each I will have two runs with seed 1 and 2, treated as hyperparameter, for a total of 8 runs.<br>\nI\u2019d like to average ALL plots over the 2 seeds. So, instead of having 8 curves per plot I\u2019ll have only 4.<br>\nI can do this manually by grouping over learning rate and batch size. However, in practice, I have way more hyperparameters than 2, and I don\u2019t want to manually add all of them one by one to the group.</p>\n<p>Is there a way to, basically, \u201cgroup over all but one\u201d hyperparameter?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-11T17:05:02.512Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/parisi\">@parisi</a> !</p>\n<p>Thank you for bringing this up! We do not support this currently but I can make a feature request for you for our internal team to look at.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-11T17:17:19.986Z",
				"Answer_body": "<p>That would be great, thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-15T17:24:32.979Z",
				"Answer_body": "<p>Yes, I do this as well and more tooling would help.</p>\n<p>More broadly, when doing a HPO it would be great to be able to tell it to run a set number of seeds at each hyperparameter value and then use the median (or whatever) as the HPO objective value.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to plot config value on x-axis versus metric on y-axis in a report?",
		"Question_link": "https://community.wandb.ai/t/how-to-plot-config-value-on-x-axis-versus-metric-on-y-axis-in-a-report/4317",
		"Question_created_time": "2023-05-02T07:32:22.733Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 57,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have a multiple runs with a varying hyperparameter (for simplicities sake: number of training samples).</p>\n<p>I would like to plot the mean and standard deviation of the accuracy after finished training in relationship to the number of training samples used.</p>\n<p>y=accuracy<br>\n^<br>\n| ----------   x<br>\n|  ------  x<br>\n| --x<br>\n_____________  x-axis = training samples from config</p>\n<p>Currently I only see wandb reports being able to plot metrics against their time/step stamp.</p>\n<p>Weave is a possibility but even afters years of matplotlib use I haven\u2019t figured out how to use weave as I can\u2019t find a understandable documentation.</p>\n<p>Exporting the data to a Jupyter notebook is also a possibility which I have done, but it sort of undermines the purpose of wandb for quick run comparison and visualization as it includes laborious fiddling with matplotlib.</p>\n<p>Any help on how to use config values on the x-axis of plots is greatly appreciated. <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-04T20:47:04.702Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ludwigwinkler\">@ludwigwinkler</a> thanks for writing in! Since you have multiple runs, you will have to add the panel in the Project level. You could add a Scatter plot and plot the config variable against accuracy. Have you logged the mean and std of the accuracy? If you edit the Panel, in the Annotations tab, there are some running aggregate metrics. Would these work for your use case?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-10T12:49:30.248Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ludwigwinkler\">@ludwigwinkler</a> I wanted to follow up with you on this request, and see if the above option would work for you, or if you were looking into a different solution such as Weave? Thank you!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-15T15:06:11.793Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ludwigwinkler\">@ludwigwinkler</a> since we haven\u2019t heard back from you, I will go ahead and close this ticket for now. Please feel free to message us back if you\u2019re still experiencing any issue, and we will be glad to keep investigating!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sweep UI icon bug",
		"Question_link": "https://community.wandb.ai/t/sweep-ui-icon-bug/4403",
		"Question_created_time": "2023-05-15T13:06:59.614Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 29,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi the size of icons in the sweep pannel has a bug.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/29950955f81eb70062033f11614523153afcb8ab.png\" data-download-href=\"/uploads/short-url/5VQSTFb976mRm4eJNcWLwiYv1nd.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/29950955f81eb70062033f11614523153afcb8ab_2_329x500.png\" alt=\"image\" data-base62-sha1=\"5VQSTFb976mRm4eJNcWLwiYv1nd\" width=\"329\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/29950955f81eb70062033f11614523153afcb8ab_2_329x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/29950955f81eb70062033f11614523153afcb8ab_2_493x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/29950955f81eb70062033f11614523153afcb8ab_2_658x1000.png 2x\" data-dominant-color=\"F6F7F7\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1106\u00d71680 133 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-15T13:51:03.103Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/geoffrey-chen\">@geoffrey-chen</a> thanks so much for reporting this bug in our App. I was able to reproduce this on our end in multi-line Sweep names. I have reported it to our engineers, and we will reach out to you here once it\u2019s fixed. Thank you!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to store a raw data artifact on s3 which requires MFA",
		"Question_link": "https://community.wandb.ai/t/how-to-store-a-raw-data-artifact-on-s3-which-requires-mfa/4397",
		"Question_created_time": "2023-05-14T04:15:21.342Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 26,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>i would like to store my artifacts on s3.  I was looking at:</p>\n<p><a href=\"https://docs.wandb.ai/guides/artifacts/track-external-files\">https://docs.wandb.ai/guides/artifacts/track-external-files</a></p>\n<p>but do not see anything in regards to s3 iam which requires MFA.   Is it possible to store remote artifacts on s3 if the s3 requires MFA? Any help is appreciated.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-16T22:25:35.101Z",
				"Answer_body": "<p>Hi Mathew,</p>\n<p>Happy to help. Could you please expand on your question as it pertains to MFA. MFA would not prevent you from referencing artifacts as you would be using your AWS credentials to log the reference. Are you running into any specific problem?</p>\n<p>Regards,<br>\nMohammad</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Resuming training",
		"Question_link": "https://community.wandb.ai/t/resuming-training/4360",
		"Question_created_time": "2023-05-08T15:54:11.086Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 44,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey everyone, Im new to WandB and would love some advice.</p>\n<p>This is my current setup:</p>\n<ol>\n<li>Run the model first time and save the model every epoch (based on a variable) using the following:</li>\n</ol>\n<h1>\n<a name=\"log-wandb-artifact-1\" class=\"anchor\" href=\"#log-wandb-artifact-1\"></a>log wandb artifact</h1>\n<pre><code>            model_artifact = wandb.Artifact(\n                f'{args.project_name}',\n                type='model',\n                description='sonic-diffusion-model-256'\n                )\n        \n            model_artifact.add_dir(args.output_dir)\n            wandb.log_artifact(\n                model_artifact,\n                aliases=[f'step_{global_step}', f'epoch_{epoch}']\n</code></pre>\n<ol start=\"2\">\n<li>i have resume as \u2018True\u2019 in the configs</li>\n<li>I then load the last saved model (i am using diffusion from hugging face):</li>\n</ol>\n<p>if wandb.run.resumed:<br>\nprint(\u201cResuming run\u2026\u201d)<br>\nartifact_name = args.model_resume_name<br>\nartifact = wandb.use_artifact(artifact_name)</p>\n<pre><code>    # Download the model file(s) and return the path to the downloaded artifact\n    artifact_dir = artifact.download()\n\n    pipeline = AudioDiffusionPipeline.from_pretrained(artifact_dir)\n\n    mel = pipeline.mel\n    model = pipeline.unet\n</code></pre>\n<p>How do i continue training from the last epoch i left off from? Is 3) above even necessary? does the resume load the optimizer settings, learning rate at specific epoch?</p>\n<p>The docs are not very clear.</p>\n<p>I hope i am articulating myself properly.</p>\n<p>Mark</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-10T21:42:27.138Z",
				"Answer_body": "<p>Hi Mark,</p>\n<p>I responded to your issue via email shortly ago, but will respond here as well for visibility.</p>\n<p>It looks like you\u2019re storing your epochs as aliases, and in order to properly resume training from a given epoch, you need to access that explicitly under your if wandb.run.resumed line. One way you could go about doing that is by including the following line underneath to properly access the correct epoch:</p>\n<p>start_epoch = int(filter(lambda alias: alias.startswith(\u2018epoch\u2019), artifact.aliases)[0].split(\u2018_\u2019)[1])</p>\n<p>which would give you the correct epoch to start at going forward.</p>\n<p>Let me know if you need anything else!</p>\n<p>Uma</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-11T07:16:10.015Z",
				"Answer_body": "<p>Where would i use the start_epoch once i have it in the training loop\u2026where would i apply this to make it work?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-11T07:20:59.792Z",
				"Answer_body": "<p>I assume it would be in the training loop and changing it to:</p>\n<p>for epoch in range(start_epoch, args.num_epochs):</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-11T18:56:16.018Z",
				"Answer_body": "<p>Hi Mark,</p>\n<p>You are definitely correct to assume it would be in the training loop and that you need to change that particular line of code. Since you save the most recent epoch # when you save the artifact, you should be referencing start_epoch+1 to get the following epoch.</p>\n<p>Also, since you are calling scheduler.step() and optimizer.step(), be sure to save those (either as an artifact or anything else of your choosing) to ensure you\u2019re using the correct values when resuming from a specific epoch.</p>\n<p>Best,</p>\n<p>Uma</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Missing image panels in UI, even though media appears under files",
		"Question_link": "https://community.wandb.ai/t/missing-image-panels-in-ui-even-though-media-appears-under-files/4351",
		"Question_created_time": "2023-05-06T23:10:17.784Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 42,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Dear wandb community,</p>\n<p>I am facing some issues seeing logged images in the UI. I log my images under <code>pairs/train</code>, <code>pairs/Y18-jj-long</code>, <code>pairs/Y18-jj-long-augmented</code>, and <code>pairs/Y18-jj-short</code>. However, not all panels (if any) would sometimes appear. I can find the media logged locally as well as in the project under <code>Files &gt;  root / media / images / pairs</code>.  The code I use for logging these images goes as <code>wandb_image = wandb.Image(image); wandb.log({f'pairs/{prefix}': wandb_image}, step=it)</code>, where <code>image</code> is an <code>np.uint8</code> numpy array of shape <code>(H, W, 3)</code> with values in [0, 255]. I use wandb 0.15.2. The height and width of images vary across steps, one image was for example (3360, 4265, 3). These are example runs demonstrating the issue (part of a private project):</p>\n<ul>\n<li>\n<a href=\"https://wandb.ai/user72/train-vos/runs/2igdf0cg?workspace=user-user72\" class=\"inline-onebox\">Weights &amp; Biases</a> - no image panels</li>\n<li>\n<a href=\"https://wandb.ai/user72/train-vos/runs/m4j5ely0?workspace=user-user72\" class=\"inline-onebox\">Weights &amp; Biases</a> - only the image panel <code>pairs/Y18-jj-long</code> appears, others are missing</li>\n</ul>\n<p>I tried clearing the workspace, logging to a different project, and logging to a different team/entity. I am facing this issue of images not appearing in a panel since yesterday. Until then I only had one \u201cpairs/train\u201d images logged and there were no major problems. Now I want to have 4 image panels under \u201cpairs/\u2026\u201d. If relevant, wandb crashed a few times yesterday, asking me to fill a crash report for feedback, not sure if this is related. For more code context, the relevant part of the codebase is logged under \u201cartifacts &gt; code\u201d.</p>\n<p>Any ideas on why the images do not appear in a panel in the UI?<br>\nShould I be aware of certain limits of the UI or the amount of data logged or image resolution?</p>\n<p>Best regards,<br>\nFrano</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-10T18:39:54.612Z",
				"Answer_body": "<p>Hello!</p>\n<p>How are you running your program? Is it with something like <code>python3 train.py</code>  or is it something like <code>python3 -m folder_name</code>? There has been an issue before with code saving when running a module as a script so there may be an issue with modules and uploading images.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-15T21:57:47.104Z",
				"Answer_body": "<p>Hi user72, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "\"rate limit exceeded\" blocking access to wandb dashboard",
		"Question_link": "https://community.wandb.ai/t/rate-limit-exceeded-blocking-access-to-wandb-dashboard/4292",
		"Question_created_time": "2023-04-28T03:20:58.589Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 56,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>Similar to other posts, I have accidentally exceeded the <a href=\"https://docs.wandb.ai/guides/track/limits#rate-limits\">wandb rate limitations</a>.</p>\n<p>I am completely unable to view my wandb console, even after stopping the processes that caused the rate limit to trigger, and waiting several days:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/b/be66cc18a480fc50288337f35a815cb86e9de8d2.png\" data-download-href=\"/uploads/short-url/ramXBVzI8tCgfMITlbAXRrwYf4u.png?dl=1\" title=\"wandb rate limit exceeded\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/be66cc18a480fc50288337f35a815cb86e9de8d2_2_690x270.png\" alt=\"wandb rate limit exceeded\" data-base62-sha1=\"ramXBVzI8tCgfMITlbAXRrwYf4u\" width=\"690\" height=\"270\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/be66cc18a480fc50288337f35a815cb86e9de8d2_2_690x270.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/be66cc18a480fc50288337f35a815cb86e9de8d2_2_1035x405.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/be66cc18a480fc50288337f35a815cb86e9de8d2_2_1380x540.png 2x\" data-dominant-color=\"FEFCFD\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">wandb rate limit exceeded</span><span class=\"informations\">1613\u00d7633 9.66 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>It seems entirely appropriate to me for wandb to enforce a rate limit, but I don\u2019t think that rate limit should apply to the web interface, for an extended time, especially after stopping the excessive requests.</p>\n<p>What can I do to resolve this, and how should I avoid triggering it in the future?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-28T10:49:38.626Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/atinybrewery\">@atinybrewery</a> thank you for reporting this, we have just now reset your rate limits. Apologies for  any inconvenience caused but our engineers had to temporarily limit these to safeguard the wider performance of our service. Please let us know if you\u2019re still experiencing any issues.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-05T03:52:31.212Z",
				"Answer_body": "<p>Thanks! Everything is working better now</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-10T13:14:35.677Z",
				"Answer_body": "<p>Great, thank you <a class=\"mention\" href=\"/u/atinybrewery\">@atinybrewery</a> for the confirmation! And apologies again for the inconvenience. I will close this ticket now, and please feel free to reach out to us if you had any more questions.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb sync confusing personal project for team project",
		"Question_link": "https://community.wandb.ai/t/wandb-sync-confusing-personal-project-for-team-project/4315",
		"Question_created_time": "2023-05-01T16:04:18.371Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 71,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I have a project \u201cfoo\u201d on my personal wandb account (entity \u201cuser\u201d). However, I am also a member of a team (\u201cteam\u201d). When I try to sync an offline run using <code>wandb sync path/to/foo/run</code>, I want it to be saved in project \u201cfoo\u201d on my personal account. However, wandb creates a new project \u201cfoo\u201d that is owned by \u201cteam\u201d.</p>\n<p>Is there any way I can fix this? Do I need to change the way I\u2019m logged in to my wandb account? wandb says that I am logged in as <code>user (team)</code>, but I\u2019m not sure how to change that.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-02T13:35:36.819Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/adamoyoung\">@adamoyoung</a> thanks for reporting this issue. Could you please provide the <code>--entity</code> and <code>--project</code> arguments as follows:<br>\n<code>wandb sync -e personal -p foo path/to/foo/run</code></p>\n<p>Would this work for you? There\u2019s a <code>Project Defaults</code> section in your <a href=\"https://wandb.ai/settings\">personal settings page</a> where this in your case seems to be configured for your team entity. You may change that if you wanted the default to be your personal account.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-05-05T15:08:19.478Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/adamoyoung\">@adamoyoung</a> just checking in here to see if you were able to sync your run after providing the entity/project arguments? Thank you!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-05T20:59:26.546Z",
				"Answer_body": "<p>Thank you for the tip! Yes, using <code>wandb sync -e user -p foo path/to/foo/run</code> seems to work for me ( in my case, user is <code>adamoyoung</code>).</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-10T13:08:10.839Z",
				"Answer_body": "<p>Thank you <a class=\"mention\" href=\"/u/adamoyoung\">@adamoyoung</a> for the confirmation, glad to hear this! I will close this ticket now, but please feel free to reach out to us if you had any other questions.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How do I share a private project with another user?",
		"Question_link": "https://community.wandb.ai/t/how-do-i-share-a-private-project-with-another-user/4263",
		"Question_created_time": "2023-04-23T14:36:46.285Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 157,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have a private project that is under my account. How do I share it with another person so that the other person can read everything in the project, upload results/experiments to that project, and basically have the same function as myself? Is it possible to do this while making the project still private among the two of us?</p>\n<p>For example this link has something similar but the person asked to make it public. I am hoping to keep it private among the two of us.</p><aside class=\"quote\" data-post=\"1\" data-topic=\"1873\">\n  <div class=\"title\">\n    <div class=\"quote-controls\"></div>\n    <img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/s/ecc23a/40.png\" class=\"avatar\">\n    <a href=\"https://community.wandb.ai/t/get-a-link-to-share-project/1873\">Get a link to share project</a> <a class=\"badge-wrapper  bullet\" href=\"/c/w-b-support/36\"><span class=\"badge-category-bg\" style=\"background-color: #0088CC;\"></span><span style=\"\" data-drop-close=\"true\" class=\"badge-category clear-badge\" title=\"Ask your W&amp;B questions here. Let us know if you have an issue and one of our engineers or community experts will get back to you ASAP. If you have an urgent W&amp;B issue, please contact our support team at support@wandb.com\">W&amp;B Help</span></a>\n  </div>\n  <blockquote>\n    I have an existing project. I want to be able to make it public and share it to someone so that they can take a look at the graphs\n  </blockquote>\n</aside>\n\n<p>If this is not possible, it seems like a wandb \u201cteam\u201d might be doable. Is there a way to transfer my private project to the team so that we don\u2019t lose information from my earlier runs?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-24T11:16:31.543Z",
				"Answer_body": "<p>Hi takeshidanny,</p>\n<p>Thanks for writing in! This is not possible as projects under your personal account are only accessible to you. The only exception is sharing a report with a concrete user. Working under a team would be the solution for this. We can move projects across entities, I would only need the name of the project and the destination team and owner username.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-26T11:18:40.967Z",
				"Answer_body": "<p>Hi takeshidanny,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-29T20:51:28.032Z",
				"Answer_body": "<p>Hi luis_bergua1, thank you for the reply and for your efforts in doing this. Apologies, I wasn\u2019t getting notifications for this post.</p>\n<p>I have a private project under my account (<a href=\"https://wandb.ai/danieltakeshi\" class=\"inline-onebox\">Weights &amp; Biases</a>) named <code>isaac-gym</code>.  For the owner username, I think that is <a href=\"https://wandb.ai/danieltakeshi\" class=\"inline-onebox\">Weights &amp; Biases</a>? For the destination team, since this is an academic team, I would only be allowed to have one team? I just made one here <a href=\"https://wandb.ai/daniel-seita-teams\" class=\"inline-onebox\">Weights &amp; Biases</a></p>\n<p>To clarify: if you move that private project to my team, I can share that project with my desired colleagues. AND would I also be able to make other private projects within that team, which I could then share with a set of different colleagues?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-05T16:53:43.493Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/danieltakeshi\">@danieltakeshi</a>, thanks for getting back! So the project you shared is under your personal account. This means that unless you set it to public, other users won\u2019t be able to visualize it. I can see you are also part of <a href=\"https://wandb.ai/daniel-seita-teams/members\">this</a> team (and the only user). If you invite colleagues to that team, they will be able to view every project under that team so if you want do share projects with different sets of users, you\u2019d need different teams. Please let me know if that makes sense!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-05T17:24:55.675Z",
				"Answer_body": "<p>Thanks! To clarify, it seems like my academic account only allows for one team. I had to ask an administrator for another team that I was part of, to remove me from the team, in order to make that new team you mentioned in your last post.</p>\n<p>Can I have multiple projects under that team, but which have different visibility levels? Let\u2019s say Project A and Project B under my team. Can I set potentially different groups to view those two respective projects?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-09T15:36:28.033Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/danieltakeshi\">@danieltakeshi</a>, thanks for the explanation! So you can have multiple projects under a team but they\u2019ll be accesible for every member under the team. If you\u2019d like to have different groups of people viewing each project, you need to work under separate teams. Please let me know if this helps!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Hyperparameter sweep within some subdomain of possible values",
		"Question_link": "https://community.wandb.ai/t/hyperparameter-sweep-within-some-subdomain-of-possible-values/4008",
		"Question_created_time": "2023-03-06T17:43:15.063Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 72,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi there! I\u2019m looking to run a hyerparameter sweep across a wide range of resnet configurations. I would like to explore two relevant paramters - the number of resnet blocks, and the number of filters in each resnet block. I would like the option for both of these hyperparameters to be large, but not at the same time! As this model will just take too long to train, and so my sweep time will be dominated by just one or two modules. So in the 2D domain of n_resnet_blocks and n_conv_filters, I want to explore some subdomain of this. Is there some way this could be done within the sweep configuration? An obvious approach would be just to run consecutive sweeps, capping each dimension to some sensible value while exploring the other one, but it\u2019d just be neater if the space could be explored within a single sweep. So interested to hear any ideas!</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-09T19:08:36.538Z",
				"Answer_body": "<p>Hi Chris,</p>\n<p>Thank you for contacting support! To be clear are you trying to have different types of search configurations in the same sweep?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-14T20:30:04.007Z",
				"Answer_body": "<p>Hello Chris could you please clarify for me?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-23T20:54:58.329Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/bill-morrisson\">@bill-morrisson</a>  - apologies for the late reply, thanks for getting back to me. I guess I\u2019m describing some additional criterion. Imagine we have two hyperparameters, a and b, which we both want to vary between [0, 1]. I am looking to search this space, but exclude runs where <em>both</em> a&gt;0.5 and b&gt;0.5. I guess I could add a break clause within the train() function to skip such values, but wondering if this could be done within the sweep configuration itself.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-08T19:41:35.850Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/chris-pedersen\">@chris-pedersen</a> , apologies for the delay here. What you are describing above seems to be conditional sweeps or having conditional sweep parameters. Would that be correct? For instance, condition paramA on paramB and in this case, conditions: a &lt; 0.5 with b &lt; 0.5, a &lt; 0.5 with b &gt; 0.5, a &gt; 0.5 with b &lt; 0.5.</p>\n<p>Also, note that this should become possible with the support for external sweeps controllers, you\u2019ll be able to use Optuna / Hyperopt to do conditional searching to start. We are going to release this feature soon this quarter and i\u2019ll surely keep you posted regarding the same.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "A small UI design issue, which is uncomfortable to my eyes",
		"Question_link": "https://community.wandb.ai/t/a-small-ui-design-issue-which-is-uncomfortable-to-my-eyes/4348",
		"Question_created_time": "2023-05-06T20:50:33.483Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 27,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Let me first say that I really like the <a href=\"http://wandb.ai\">wandb.ai</a> and have &gt;900 runs logged into its platform. my small issue is that  I use wandb in Night mode. However, when I want to delete a run (screenshot attached), the entire screen turns white. This sudden transition is painful to my eyes. It would be great if this could as well be in black.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/ac461cf4c2ffcf0921999390ec87b7a73867bb9d.jpeg\" data-download-href=\"/uploads/short-url/oA0laXOG86Pc97aBsxsFFySDV4p.jpeg?dl=1\" title=\"Screenshot 2023-05-06 at 22.48.15\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/ac461cf4c2ffcf0921999390ec87b7a73867bb9d_2_690x393.jpeg\" alt=\"Screenshot 2023-05-06 at 22.48.15\" data-base62-sha1=\"oA0laXOG86Pc97aBsxsFFySDV4p\" width=\"690\" height=\"393\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/ac461cf4c2ffcf0921999390ec87b7a73867bb9d_2_690x393.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/ac461cf4c2ffcf0921999390ec87b7a73867bb9d_2_1035x589.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/ac461cf4c2ffcf0921999390ec87b7a73867bb9d_2_1380x786.jpeg 2x\" data-dominant-color=\"D6D6D6\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2023-05-06 at 22.48.15</span><span class=\"informations\">2652\u00d71514 169 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-08T10:29:39.982Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ashesh276\">@ashesh276</a>, thanks for sharing this feedback! I\u2019ll create a new feature request for this!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "100% offline sweep",
		"Question_link": "https://community.wandb.ai/t/100-offline-sweep/3482",
		"Question_created_time": "2022-12-01T10:27:07.034Z",
		"Question_answer_count": 14,
		"Question_score_count": 8,
		"Question_view_count": 890,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I\u2019m using wandb sweeps for bayesian optimisation . However I recently got access to new powerfull gpus which are not connected to internet. So i\u2019m trying to use the offline mode of wandb that seems to works fine with regular runs but doesn\u2019t with sweeps. Indeed even in offline mode a connexion seems to still be required in order to create the sweep and to synchronise the data after a run (for the optimisation process).</p>\n<p>Is there any way  to run a 100% offline sweep and to synchronise it manually at the end off  each run or of the whole sweep ?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-01T15:14:31.918Z",
				"Answer_body": "<p>Hi Felix,</p>\n<p>Unfortunately, there is no way for us to run sweeps in offline mode, this feature is not available as of right now.</p>\n<p>If you would like I could create a feature request for it, bump up the priority, and submit it to our engineers.</p>\n<p>Warmly,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-06T17:09:55.106Z",
				"Answer_body": "<p>Hi F\u00e9lix,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-09T19:25:01.471Z",
				"Answer_body": "<p>Hi F\u00e9lix,<br>\nSince we have not heard back from you, we will close this request. If you would like to re-open the conversation, please let us know!</p>\n<p>Cheers!</p>\n<p>Weights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-12T17:00:56.662Z",
				"Answer_body": "<p>Hi,</p>\n<p>I also run wandb on an Slurm cluster in which computational nodes do not have internet connection. I am really interested in this feature. Has the feature request been created?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-19T22:09:53.425Z",
				"Answer_body": "<p>Same here! I really need that feature</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-19T23:06:44.185Z",
				"Answer_body": "<p>I really need this feature too! <a class=\"mention\" href=\"/u/artsiom\">@artsiom</a> , are there any workarounds?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-19T23:17:04.385Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/artsiom\">@artsiom</a> , to clarify my use case, I can create a sweep just fine (i.e. <code>wandb sweep &lt;path to YAML config&gt;</code> works). Previous, I would launch SLURM jobs, each with 1 W&amp;B agent, but due to my SLURM cluster\u2019s new policies, each SLURM job has no internet access and thus no agent can acquire a run.</p>\n<p>Is there a workaround?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-20T08:51:38.054Z",
				"Answer_body": "<p>I would love this feature too! To be honest I wouldn\u2019t know how one could manage the run configuration exchange with the agent without connection, but running sweeps offline would be great!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-26T12:02:46.703Z",
				"Answer_body": "<p>Same here. Unfortunately most slurm cluster do not support network connection.<br>\nHope update soon.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-12T19:20:22.394Z",
				"Answer_body": "<p>I now have this problem with 2 other clusters. Can someone from W&amp;B please suggest a solution, or discuss a workaround? I\u2019m wondering if we can somehow persuade our clusters to run a W&amp;B server internally that then gets occasionally synced to W&amp;B\u2019s machines?</p>\n<p><a class=\"mention\" href=\"/u/artsiom\">@artsiom</a> , could you perhaps advise?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-24T18:54:23.857Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/artsiom\">@artsiom</a> I share this interest just like the other users, but I have not seen a reply in a long time. Do we need to make a new post?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-25T17:47:15.666Z",
				"Answer_body": "<p>Hi all,<br>\nI am woundering if this feature has been implemented yet ?<br>\nI also need to use it since  most of the clusters I have access to has no internet access.<br>\nBest regards</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-07T22:15:33.472Z",
				"Answer_body": "<p>Hi Guys, for some reason haven\u2019t been getting notifications for this thread at all! Apologies to everyone. I have followed up with the our eng department and still waiting for a reply. I\u2019ll make another feature request for you. But I would also advise making a new ticket, for visibility to show how many people want this feature request.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-07T22:21:07.716Z",
				"Answer_body": "<p>As a workaround,</p>\n<p>You can now potentially use the <a href=\"https://docs.wandb.ai/guides/sweeps/local-controller\">Local Controller</a>, then when ready, you can <a href=\"https://docs.wandb.ai/ref/cli/wandb-sync\">sync</a> your runs to your profile.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Saving error stopping sweep",
		"Question_link": "https://community.wandb.ai/t/saving-error-stopping-sweep/4328",
		"Question_created_time": "2023-05-03T08:36:06.247Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 63,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I am trying to run the sweep for tensorflow but it keeps stopping with a broken pipe error. When I checked the logs, I get this traceback error message.</p>\n<p>Traceback (most recent call last):<br>\nFile \u201c/nobackup/eeerog/./general_training_model_5classes.py\u201d, line 713, in <br>\nwandb.agent(sweep_id = sweep_id, function=train(class_weightsh, class_weightsv, class_weightsc, train_datagen, valid_datagen, nom_classes1 = 5, nom_classes2 = 5))<br>\nFile \u201c/nobackup/eeerog/./general_training_model_5classes.py\u201d, line 708, in train<br>\nmodel.fit(train_datagen,epochs=3,steps_per_epoch=860, callbacks = [early_stopping,reduce_lr, model_checkpoint_callback, WandbCallback()], validation_data=valid_datagen, validation_steps = 10)<br>\nFile \u201c/home/home02/eeerog/.conda/envs/deep_learning/lib/python3.9/site-packages/wandb/integration/keras/keras.py\u201d, line 174, in new_v2<br>\nreturn old_v2(*args, **kwargs)<br>\nFile \u201c/home/home02/eeerog/.conda/envs/deep_learning/lib/python3.9/site-packages/wandb/integration/keras/keras.py\u201d, line 174, in new_v2<br>\nreturn old_v2(*args, **kwargs)<br>\nFile \u201c/home/home02/eeerog/.conda/envs/deep_learning/lib/python3.9/site-packages/wandb/integration/keras/keras.py\u201d, line 174, in new_v2<br>\nreturn old_v2(*args, **kwargs)<br>\nFile \u201c/home/home02/eeerog/.conda/envs/deep_learning/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u201d, line 1145, in fit<br>\ncallbacks.on_epoch_end(epoch, epoch_logs)<br>\nFile \u201c/home/home02/eeerog/.conda/envs/deep_learning/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py\u201d, line 428, in on_epoch_end<br>\ncallback.on_epoch_end(epoch, logs)<br>\nFile \u201c/home/home02/eeerog/.conda/envs/deep_learning/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py\u201d, line 1344, in on_epoch_end<br>\nself._save_model(epoch=epoch, logs=logs)<br>\nFile \u201c/home/home02/eeerog/.conda/envs/deep_learning/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py\u201d, line 1393, in _save_model<br>\nself.model.save_weights(<br>\nFile \u201c/home/home02/eeerog/.conda/envs/deep_learning/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u201d, line 2124, in save_weights<br>\nself._trackable_saver.save(filepath, session=session, options=options)<br>\nFile \u201c/home/home02/eeerog/.conda/envs/deep_learning/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\u201d, line 1215, in save<br>\nfile_io.recursive_create_dir(os.path.dirname(file_prefix))<br>\nFile \u201c/home/home02/eeerog/.conda/envs/deep_learning/lib/python3.9/site-packages/tensorflow/python/lib/io/file_io.py\u201d, line 468, in recursive_create_dir<br>\nrecursive_create_dir_v2(dirname)<br>\nFile \u201c/home/home02/eeerog/.conda/envs/deep_learning/lib/python3.9/site-packages/tensorflow/python/lib/io/file_io.py\u201d, line 483, in recursive_create_dir_v2<br>\n_pywrap_file_io.RecursivelyCreateDir(compat.path_to_bytes(path))<br>\ntensorflow.python.framework.errors_impl.PermissionDeniedError: /home/eeerog; Permission denied</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-05T23:03:35.966Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"eeerog\" data-post=\"1\" data-topic=\"4328\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/e/a587f6/40.png\" class=\"avatar\"> eeerog:</div>\n<blockquote>\n<p>tensorflow.python.framework.errors_impl.PermissionDeniedError: /home/eeerog; Permission denied</p>\n</blockquote>\n</aside>\n<p>Hello! It looks like this may be an issue with Tensorflow having Permission issues but I can look at your debug logs as they can help with debugging the issue. They should be located in the <code>wandb</code> folder in the same directory as where the script was run. The <code>wandb</code> folder has folders formatted as <code>run-DATETIME-ID</code> associated with a single run. Could you retrieve the <code>debug.log</code> and <code>debug-internal.log</code> files from one of these folders specifically from the run that is having issues?</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Log scale axis for bar plots?",
		"Question_link": "https://community.wandb.ai/t/log-scale-axis-for-bar-plots/4331",
		"Question_created_time": "2023-05-03T14:41:44.371Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 29,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Can I set my bar plot axis to log scale? I looked over the <a href=\"https://docs.wandb.ai/guides/app/features/panels/bar-plot\">documentation</a> but didn\u2019t see this mentioned.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-05T16:13:24.088Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ivnle\">@ivnle</a>! could you send me a link to your workspace where you are trying to do this?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-10T18:11:45.136Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-15T16:55:35.509Z",
				"Answer_body": "<p>Hi Ivan, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!<br>\nSeems like our tickets aren\u2019t reopening right now, so please if you\u2019d like to continue the conversation create a new thread and link this one in the new one.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Logging list of wandb.Plotly not working",
		"Question_link": "https://community.wandb.ai/t/logging-list-of-wandb-plotly-not-working/4044",
		"Question_created_time": "2023-03-10T16:48:15.888Z",
		"Question_answer_count": 16,
		"Question_score_count": 1,
		"Question_view_count": 343,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I am trying to log multiple connected plots similar to using images, as <a href=\"https://docs.wandb.ai/ref/python/log#image-from-numpy\">shown in the documentation</a>:</p>\n<pre><code class=\"lang-auto\">examples = []\nfor i in range(3):\n pixels = np.random.randint(low=0, high=256, size=(100, 100, 3))\n image = wandb.Image(pixels, caption=f\"random field {i}\")\n examples.append(image)\nwandb.log({\"examples\": examples})\n</code></pre>\n<p>Trying this with <code>wandb.Plotly</code> instead of <code>wandb.Image</code>:</p>\n<pre><code class=\"lang-auto\">plots = []\nfor i in range(3):\n fig = create_plotly_plot(index=i)\n plot = wandb.Plotly(fig)\n plots.append(plot)\nwandb.log({\"examples\": plots})\n</code></pre>\n<p>results in an error in the UI:</p>\n<blockquote>\n<p>Selected runs are not logging media for the key <strong>examples</strong>, but instead are logging values of type <strong>list</strong>.</p>\n<p>If <strong>examples</strong> is never supposed to be a media type, please delete this panel and create the proper panel type manually.</p>\n</blockquote>\n<p>How can I log a list of plots similar to a list of images?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-13T16:56:46.876Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mbp\">@mbp</a> thanks for writing in! Would it work for you to add a slider instead for your Plotly figures as follows:</p>\n<pre><code class=\"lang-auto\">import plotly.graph_objects as go\nimport numpy as np\n\nfor i in range(3):\n    x = np.linspace(0, 10, 100)\n    y = np.sin(x) + np.random.normal(0, 0.1, 100)\n    fig = go.Figure(data=go.Scatter(x=x, y=y))\n    plot = wandb.Plotly(fig)\n    wandb.log({\"examples_2\": plot}, step = i)\n</code></pre>\n<p>Another alternative would be to convert the <code>Plotly</code> to <code>html</code> and add them in a <code>wandb.Table</code>, for example:</p>\n<pre><code class=\"lang-auto\"># Create a table\ntable = wandb.Table(columns = [\"plotly_figure\"])\nfor i in range(3):\n    x = np.linspace(0, 10, 100)\n    y = np.sin(x) + np.random.normal(0, 0.1, 100)\n    fig = go.Figure(data=go.Scatter(x=x, y=y))\n\n    # Create path for Plotly figure\n    path_to_plotly_html = \"./plotly_figure.html\"\n    # Write Plotly figure to HTML\n    fig.write_html(path_to_plotly_html, auto_play = False) \n    # Add Plotly figure as HTML file into Table\n    table.add_data(wandb.Html(path_to_plotly_html))\n\nwandb.log({\"examples_3\": table})\n</code></pre>\n<p>Would any of these options work for your use case?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-14T08:55:07.019Z",
				"Answer_body": "<p>Thank you for your reply. When doing it this way the plots do not show up in the UI at all, unfortunately. I can see them in the files section unter <code>root/media/plotly</code> but they cannot be added to the charts section.</p>\n<p>By chance, I  tried to log the plots one by one without the <code>step=i</code> part and then they showed up in the charts section with a slider. Could you clarify if that is the intended way to do it maybe?</p>\n<p>Thank you!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-17T11:28:40.416Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mbp\">@mbp</a> thanks for the update, could you please try to <code>Add Panel</code> &gt; <code>Plotly</code> and then add in <code>media keys</code> the key you had used to log the plots (for instance in the code snippet above that would be <code>examples_2</code>). Would this work for you?</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/263a38638b22a9ea3dea09667a3b1ab5994d3661.png\" data-download-href=\"/uploads/short-url/5saSzAXGOYxgnGC65JdHfW2uPCN.png?dl=1\" title=\"Screenshot 2023-03-17 at 11.03.16\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/263a38638b22a9ea3dea09667a3b1ab5994d3661_2_690x314.png\" alt=\"Screenshot 2023-03-17 at 11.03.16\" data-base62-sha1=\"5saSzAXGOYxgnGC65JdHfW2uPCN\" width=\"690\" height=\"314\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/263a38638b22a9ea3dea09667a3b1ab5994d3661_2_690x314.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/263a38638b22a9ea3dea09667a3b1ab5994d3661_2_1035x471.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/263a38638b22a9ea3dea09667a3b1ab5994d3661_2_1380x628.png 2x\" data-dominant-color=\"F9FAFB\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2023-03-17 at 11.03.16</span><span class=\"informations\">2210\u00d71008 158 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-17T12:43:40.317Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a>, thanks for your reply. I\u2019m sorry that I did not mention it explicitly but I have tried to add it manually before and the problem is, that the key does not exist in the backend. Here is an excerpt from my code:</p>\n<pre><code class=\"lang-auto\">_fs = self.log_pred_probs(\n     y_train_pred_prob, y_test_pred_prob, threshold=0.5, n_plots=20\n)\nfor i, _f in enumerate(_fs):\n     _pf = wandb.Plotly(_f)\n     run.log({\"prediction_probabilities\": _pf}, step=i)\n</code></pre>\n<p>And the files in the <code>files</code> section:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/9/906253e40bf61ed18a59bc7a68969f6391566d9a.png\" data-download-href=\"/uploads/short-url/kBhq9EJeCiUUxMIazIwSW7IKTnY.png?dl=1\" title=\"grafik\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/9/906253e40bf61ed18a59bc7a68969f6391566d9a.png\" alt=\"grafik\" data-base62-sha1=\"kBhq9EJeCiUUxMIazIwSW7IKTnY\" width=\"690\" height=\"290\" data-dominant-color=\"272727\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">grafik</span><span class=\"informations\">880\u00d7370 23.6 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>But when adding a plot, the media key does not exist:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/22e8f2175ee3874a7306065b30135c3d45354cb4.png\" data-download-href=\"/uploads/short-url/4YPjHA9DAXy5Qd1HbMn7Up0jB9G.png?dl=1\" title=\"grafik\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/22e8f2175ee3874a7306065b30135c3d45354cb4_2_512x500.png\" alt=\"grafik\" data-base62-sha1=\"4YPjHA9DAXy5Qd1HbMn7Up0jB9G\" width=\"512\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/22e8f2175ee3874a7306065b30135c3d45354cb4_2_512x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/22e8f2175ee3874a7306065b30135c3d45354cb4.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/22e8f2175ee3874a7306065b30135c3d45354cb4.png 2x\" data-dominant-color=\"262728\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">grafik</span><span class=\"informations\">727\u00d7709 18.2 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Manually specifying the key does not work at all.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-17T13:28:02.244Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mbp\">@mbp</a> thanks for the additional details, this shouldn\u2019t be the expected behaviour. Are you logging in our SaaS (<a href=\"http://wandb.ai\">wandb.ai</a>) or in a local W&amp;B instance? If the former could you please send us a link to your Workspace (or email it to <a href=\"mailto:support@wandb.com\">support@wandb.com</a> in case you don\u2019t want to publicly share), or in the latter case please provide us with your Local/Server version (found from <code>&lt;host-url&gt;/settings</code> page).</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-20T09:18:52.545Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a>, it is a local setup (Docker) and the version from <code>/settings</code> is</p>\n<blockquote>\n<p>W&amp;B Local 0.30.0</p>\n</blockquote>\n<p>However, this was tested with 0.29.0 as I have since upgraded the version.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-23T20:03:55.402Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mbp\">@mbp</a> thanks for the additional details, that\u2019s important to know you\u2019re on a self-hosted instance. I have tested it as well though in a 0.30.0 deployment and it worked for me. Could you please try the following code again (in a completely new project)?</p>\n<pre><code class=\"lang-auto\">import wandb\n\nimport plotly.graph_objects as go\nimport numpy as np\n\nwandb.init(project='plotly')\n\nfor i in range(3):\n    x = np.linspace(0, 10, 100)\n    y = np.sin(x) + np.random.normal(0, 0.1, 100)\n    fig = go.Figure(data=go.Scatter(x=x, y=y))\n    plot = wandb.Plotly(fig)\n    wandb.log({\"examples_2\": plot}, step = i)\n\nwandb.finish()\n</code></pre>\n<p>Please let me know if this still won\u2019t work for you. I will then try to reproduce if the issue occurs because you logged the data in <code>0.29.0</code> and then you upgraded to <code>0.30.0</code>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-29T16:04:13.096Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a>, thank you for your reply. I can confirm that your example yields  the expected result and the slider is shown with the <code>step</code> values.</p>\n<p>I am thinking out loud here but what if:</p>\n<ul>\n<li>running multiple agents messes up the <code>step</code> value since in my experiments with multiple agents, the <code>step</code> value shown in the dashboard is usually not contiguous, i.e. instead of <code>{1, 2, 3, ..., n}</code> the  steps are e.g. <code>{54, 78, 90, ..., m}</code>.</li>\n</ul>\n<p>What do you think?</p>\n<ul>\n<li>setting the <code>step</code> manually, overwrites the automatic value and allows multiple agents to set the same <code>step</code> value</li>\n</ul>\n<p>You can see this in my screenshot above, where three files with the name <code>prediction_probabilities_154_xxxx.plotly.json</code> exist;  note the same <code>step=154</code> value.</p>\n<p>What do you think?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-11T17:25:32.783Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mbp\">@mbp</a> sorry for the late response here, but glad to hear that the previous code snippet worked for you. Regarding the <code>steps</code> issue, I can see that you have indeed created three plots at 154th iteration. Could you please try to enforce commiting the global step by adding the argument as follows:</p>\n<pre><code class=\"lang-auto\">wandb.log({\"examples_2\": plot}, step = i, commit=True)\n</code></pre>\n<p>You could also try to omit the <code>step</code> argument in that case.</p>\n<p>Regarding the multiple parallel agents, I don\u2019t see how you could create a conflict since each one would log the plotly files in a different run. Could you please provide us with a code snippet to try and reproduce that behavior?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-13T13:27:18.226Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a> , thanks for the follow-up. I created the followin MWE that showcases the behavior I was referring to:</p>\n<pre><code class=\"lang-python\">import wandb\nimport numpy as np\nimport plotly.graph_objects as go\n\n\ndef func():\n    wandb.init()\n\n    plots = []\n    for i in range(3):\n        x = np.linspace(0, 10, 100)\n        o = np.random.randint(0, 2 * np.pi)\n        y = np.sin(x + o) + np.random.normal(0, 0.1, 100)\n        fig = go.Figure(data=go.Scatter(x=x, y=y))\n        plot = wandb.Plotly(fig)\n        plots.append(plot)\n\n    wandb.log({\"error\": o})\n    wandb.log({\"examples\": plots})\n\n    wandb.finish()\n\n\nwandb.login(\n    key=\"\",\n    host=\"\",\n    relogin=True,\n)\n\nSWEEP_CONFIG = {\n    \"method\": \"random\",\n    \"name\": \"my_config\",\n    \"metric\": {\"goal\": \"minimize\", \"name\": \"error\"},\n    \"parameters\": {\n        \"param1\": {\"values\": [8, 16, 32]},\n    },\n}\n\nsweep_id = wandb.sweep(sweep=SWEEP_CONFIG, project=\"plotly\")\nagent = wandb.agent(\n    sweep_id=sweep_id,\n    function=func,\n    project=\"plotly\",\n    count=5,\n)\n</code></pre>\n<p>It plots three Plotly figures during each run. They are added to a local list and then logged all at once. Unfortunately, instead of showing in the web interface, the error message mentioned in the first post appears. You can see the files available in the \u201cFiles\u201d section and all have the same step value, as discussed.</p>\n<p>It doesn\u2019t seem to be caused by multiple agents, since this also happens when running the above snippet only once (i.e., not in parallel).</p>\n<p>Adding <code>commit=True</code> in this MWE does not have any effect, though I didn\u2019t test it with logging each step separately inside the loop (will do this later).</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-17T20:40:16.110Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mbp\">@mbp</a> thanks a lot for the update, and the provided code. Could you please try also logging them inside the loop with the <code>step</code> and <code>commit</code> arguments, would this work for you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-21T10:42:49.506Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mbp\">@mbp</a> just checking in here to see if this worked for you when executing this within a loop? thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-25T07:11:41.162Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a>, thank you for your reply. It works for the MWE I provided. But if I add a second plot it will only show the first one (key <code>examples</code>) and skip/ignore the second one (<code>examples2</code>). It is also not possible to add the plot manually, the key <code>examples2</code> does not exist in the list.</p>\n<pre><code class=\"lang-python\">def func():\n    wandb.init()\n\n    for i in range(3):\n        x = np.linspace(0, 10, 100)\n        o = np.random.randint(0, 2 * np.pi)\n\n        y = np.sin(x + o) + np.random.normal(0, 0.1, 100)\n        fig = go.Figure(data=go.Scatter(x=x, y=y))\n        plot = wandb.Plotly(fig)\n        wandb.log({\"examples\": plot}, step=i, commit=True)\n\n        y2 = np.sin(x + o) + np.random.normal(0, 0.1, 100)\n        fig2 = go.Figure(data=go.Scatter(x=x, y=y2))\n        plot2 = wandb.Plotly(fig2)\n        wandb.log({\"examples2\": plot2}, step=i, commit=True)\n\n    wandb.log({\"error\": o})\n\n    wandb.finish()\n</code></pre>\n<p>I can see the files being present though:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/e/ef99f38bd471bbe81bea3899b01858dd7ae4d9da.png\" data-download-href=\"/uploads/short-url/ybBXbP1BbvrezxDmmhZHpspbdOi.png?dl=1\" title=\"grafik\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ef99f38bd471bbe81bea3899b01858dd7ae4d9da_2_517x299.png\" alt=\"grafik\" data-base62-sha1=\"ybBXbP1BbvrezxDmmhZHpspbdOi\" width=\"517\" height=\"299\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ef99f38bd471bbe81bea3899b01858dd7ae4d9da_2_517x299.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ef99f38bd471bbe81bea3899b01858dd7ae4d9da_2_775x448.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/e/ef99f38bd471bbe81bea3899b01858dd7ae4d9da.png 2x\" data-dominant-color=\"252526\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">grafik</span><span class=\"informations\">883\u00d7511 21.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-26T13:45:32.035Z",
				"Answer_body": "<p>Thanks so much <a class=\"mention\" href=\"/u/mbp\">@mbp</a> for the reproducible example, I could see the issue indeed. In this case, it\u2019s resolved if you omit the <code>commit=True</code> argument. The previously shared example would work with this argument because it had only one <code>wandb.log()</code> call.  Could you please try again without the <code>commit</code>?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-01T14:08:26.012Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mbp\">@mbp</a> just checking in here to see if it eventually worked for you without the <code>commit</code> argument? Thank you!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-04T16:13:32.521Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mbp\">@mbp</a> since we haven\u2019t heard back from you, I will go ahead and close this ticket for now. However, please feel free to reopen it if the issue persists for you and we would be glad to keep investigating.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sync offline Run in a other machine",
		"Question_link": "https://community.wandb.ai/t/sync-offline-run-in-a-other-machine/4218",
		"Question_created_time": "2023-04-14T07:46:55.797Z",
		"Question_answer_count": 8,
		"Question_score_count": 1,
		"Question_view_count": 136,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hello, I ran a Unet on an other machine whithout internet and retrieved the offline Run. I am trying to sync it with wandb but, there are en issu that say:</p>\n<p>wandb: ERROR Uploading artifact file failed. Artifact won\u2019t be committed.<br>\nwandb: ERROR Error uploading [Path of the artefact on the other machine] : FileNotFoundError, [Errno 2] No such file or directory: [Path of the artefact on the other machine]</p>\n<p>When I searched for a solution, I couldn\u2019t find anything that realy helped and all the last topics had been finished whithout solution or answer from person who questions.</p>\n<p>I tryed this:</p>\n<ul>\n<li>\n<p>!wandb sync --project [the name] --entity [the name] [the path]</p>\n</li>\n<li>\n<p>!wandb sync  [the path]</p>\n</li>\n<li>\n<p>wandbId=wandb.util.generate_id()<br>\n!wandb sync [the path] --id wandbId</p>\n</li>\n</ul>\n<p>Thank you for your time, I hope you can help me</p>\n<p>Have a good day</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-18T12:57:46.632Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/seirihiri\">@seirihiri</a>, thanks for writing in! In order to sync your run, you need to have it under the folder <code>wandb/offline-run-&lt;date_time&gt;-&lt;run-id&gt;</code> which is created by default when you execute your offline run. Could you please make sure that this folder exists and then run <code>wandb sync &lt;path to run folder&gt;</code> if you want to sync an specific run or <code>wandb sync --sync-all</code> if you want to sync all runs (docs <a href=\"https://docs.wandb.ai/ref/cli/wandb-sync\">here</a>)?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-18T13:29:28.519Z",
				"Answer_body": "<p>Hello, this document is create, there is no problem with this part.</p>\n<p>The problem is with the file in the directory <code>wandb/offline-run-&lt;date_time&gt;-&lt;run-id&gt;</code> which is name, <code>run-2pch16mp.wandb</code> for me. In this file, they are a part where he call artifact at a specific adress on the original computer. Exemple:<br>\n<code>storageLayout\"V2\"\"\u017d ?media/classes/99a736c11d116504b33cd665c82578ca_cls.classes.jsond4Xyvg8rzyrpfp12eRJNHg== Z2O/home/.cache/wandb/artifacts/obj/md5/77/85f2be0f2bcf2ae97e9d7679124d1e\"\u0096 %media/images/019575fbc7635ac842d2.pngAZV1+8djWshC0s0BMUfS+w== \u010c\u00872O/home/.cache/wandb/artifacts/obj/md5/01/9575fbc7635ac842d2cd013147d2fb\"\u0096 %media/images/03f0392f2ffbda0f67d6.pngA/A5Ly/72g9n1rEtoo1k/g== \u009c\u02dd2O/home/.cache/wandb/artifacts/obj/md5/03/f0392f2ffbda0f67d6b12da28d64fe\"\u0096 %media/images/04a1b3c0e7ead0fa5726.pngBKGzwOfq0PpXJvGHqQDSIA== \u0083\u02dd2O/home/.cache/wandb/artifacts/obj/md5/04/a1b3c0e7ead0fa5726f187a900d220\"\u0096</code></p>\n<p>But, in the computer where I can sync, I dont have the artifacts in the same directory. I try to change the path in the document <code>run-2pch16mp.wandb</code> but it made a error like <code>invalid header</code> maybe because this file was not UTF-8 encoded.</p>\n<p>If I ignore the error: <code>wandb: ERROR Uploading artifact file failed. Artifact won\u2019t be committed. wandb: ERROR Error uploading [Path of the artefact on the other machine] : FileNotFoundError, [Errno 2] No such file or directory: [Path of the artefact on the other machine]</code>  and let run the sync with it, nothing appears in wandb.</p>\n<p>(sorry for my english, it\u2019s not my native language)</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-18T13:50:37.118Z",
				"Answer_body": "<p>So, I want to know if it\u2019s possible to :</p>\n<ul>\n<li>say to wandb: \" my artefact are in an other directory that mension in the file <code>run-2pch16mp.wandb</code>\"</li>\n<li>run offline without creating artifact</li>\n<li>change the path by hand in the file without making an error<br>\nor another solution that overrides the error</li>\n</ul>\n<p>thank you</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-24T11:57:29.098Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/seirihiri\">@seirihiri</a>, thanks for the explanation! You can set the artifacts folder with the <a href=\"https://docs.wandb.ai/guides/track/environment-variables#optional-environment-variables\">env variable</a> <code>WANDB_CACHE_DIR </code> and point that to the folder you want. Regarding the artifacts created when running offline, it depends if you\u2019re creating them or not (they can be created not only when logging an <a href=\"https://docs.wandb.ai/guides/artifacts#how-it-works\">artifact</a> but also when logging tables for example). Let me know if this helps!</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-04-25T06:09:53.766Z",
				"Answer_body": "<p>Thanks, I will try this as soon as I can. I will let you know if it is the solution.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-25T09:22:55.301Z",
				"Answer_body": "<p>Sounds good! Keep me updated.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-27T10:02:13.099Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-04T10:54:09.553Z",
				"Answer_body": "<p>Hello,<br>\nsorry for the time, I didn\u2019t have time before today to test the solution so it works.</p>\n<p>Thanks you</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Run.finish() hangs",
		"Question_link": "https://community.wandb.ai/t/run-finish-hangs/4069",
		"Question_created_time": "2023-03-16T15:15:12.586Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 137,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I\u2019m using wandb version 0.14.0 in an ipynb file using vscode as part of assignment 1 of the \u2018Effective MLOps\u2019 course (logging dataset as artifact and visualising data with a table)</p>\n<p>When I execute <code>run.finish()</code> at the end of my file the cell hangs indefinitely with the message</p>\n<pre><code class=\"lang-console\">Waiting for W&amp;B process to finish... (success).\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-16T16:10:24.296Z",
				"Answer_body": "<p>How much data are you logging? It might still be uploading in the background. You can check one of the <code>debug.log</code> or <code>debug-internal.log</code> files in the <code>wandb</code> folder to see if there is any upload activity happening</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-03-17T10:21:58.746Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/arthur-howard\">@arthur-howard</a>, thanks for reporting this! In addition to Morgan\u2019s suggestion, could you please share those files for a specific run affected? They are under your local folder <code>wandb/run-&lt;date-time&gt;-&lt;run-id&gt;/logs</code> in the same directory where you\u2019re running your code. Also, if you restart runtime on your notebook is the issue still raising or it only appears sometimes?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-17T10:29:33.291Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/luis_bergua1\">@luis_bergua1</a> as Morgan suggested there is a rather large artifact uploading the debug log is 70,000 lines long and growing so  I think everything is working as expected thank you!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-04T03:34:33.801Z",
				"Answer_body": "<p>Hi there, I have the same issue. From time to time wand.finish() hangs and will not finish unless terminated. wandb==0.13.10</p>\n<p>app.log</p>\n<p>2023-05-04 03:20:08,768 - INFO - utils.process_results - Logging wandb results<br>\n2023-05-04 03:20:11,232 - INFO - utils.process_results - Finishing wandb run (after the logging there is wandb.finish() line)</p>\n<p>debug.log</p>\n<pre><code class=\"lang-auto\">2023-05-04 03:14:40,270 INFO    MainThread:1501 [wandb_init.py:init():775] starting run threads in backend\n2023-05-04 03:14:40,328 INFO    MainThread:1501 [wandb_run.py:_console_start():2114] atexit reg\n2023-05-04 03:14:40,328 INFO    MainThread:1501 [wandb_run.py:_redirect():1969] redirect: SettingsConsole.WRAP_RAW\n2023-05-04 03:14:40,328 INFO    MainThread:1501 [wandb_run.py:_redirect():2034] Wrapping output streams.\n2023-05-04 03:14:40,328 INFO    MainThread:1501 [wandb_run.py:_redirect():2059] Redirects installed.\n2023-05-04 03:14:40,329 INFO    MainThread:1501 [wandb_init.py:init():817] run started, returning control to user process\n2023-05-04 03:20:11,232 INFO    MainThread:1501 [wandb_run.py:_finish():1854] finishing run silver-way/FR BT 3/jz5k5gh9\n2023-05-04 03:20:11,233 INFO    MainThread:1501 [wandb_run.py:_atexit_cleanup():2083] got exitcode: 0\n2023-05-04 03:20:11,233 INFO    MainThread:1501 [wandb_run.py:_restore():2066] restore\n2023-05-04 03:20:11,233 INFO    MainThread:1501 [wandb_run.py:_restore():2072] restore done\n</code></pre>\n<p>debug-internal.log</p>\n<pre><code class=\"lang-auto\">2023-05-04 03:20:13,343 INFO    SenderThread:1680 [sender.py:transition_state():587] send defer: 10\n2023-05-04 03:20:13,343 DEBUG   SenderThread:1680 [sender.py:send_request():363] send_request: poll_exit\n2023-05-04 03:20:13,344 DEBUG   HandlerThread:1680 [handler.py:handle_request():144] handle_request: defer\n2023-05-04 03:20:13,344 INFO    HandlerThread:1680 [handler.py:handle_request_defer():170] handle defer: 10\n2023-05-04 03:20:13,345 DEBUG   SenderThread:1680 [sender.py:send_request():363] send_request: defer\n2023-05-04 03:20:13,345 INFO    SenderThread:1680 [sender.py:send_request_defer():583] handle sender defer: 10\n2023-05-04 03:20:13,345 INFO    SenderThread:1680 [file_pusher.py:finish():162] shutting down file pusher\n2023-05-04 03:20:13,784 INFO    wandb-upload_37:1680 [upload_job.py:push():138] Uploaded file /optimalasset/wandb/run-20230504_031439-jz5k5gh9/files/output.log\n2023-05-04 03:20:13,798 INFO    wandb-upload_29:1680 [upload_job.py:push():138] Uploaded file /optimalasset/wandb/run-20230504_031439-jz5k5gh9/files/config.yaml\n2023-05-04 03:20:13,810 INFO    wandb-upload_33:1680 [upload_job.py:push():138] Uploaded file /optimalasset/wandb/run-20230504_031439-jz5k5gh9/files/wandb-summary.json\n2023-05-04 03:20:13,810 INFO    wandb-upload_0:1680 [upload_job.py:push():138] Uploaded file /optimalasset/wandb/run-20230504_031439-jz5k5gh9/files/requirements.txt\n2023-05-04 03:20:14,235 DEBUG   HandlerThread:1680 [handler.py:handle_request():144] handle_request: poll_exit\n2023-05-04 03:20:14,235 DEBUG   SenderThread:1680 [sender.py:send_request():363] send_request: poll_exit\n2023-05-04 03:20:15,235 DEBUG   HandlerThread:1680 [handler.py:handle_request():144] handle_request: poll_exit\n2023-05-04 03:20:15,235 DEBUG   SenderThread:1680 [sender.py:send_request():363] send_request: poll_exit\n2023-05-04 03:20:16,236 DEBUG   HandlerThread:1680 [handler.py:handle_request():144] handle_request: poll_exit\n2023-05-04 03:20:16,236 DEBUG   SenderThread:1680 [sender.py:send_request():363] send_request: poll_exit\n2023-05-04 03:20:17,236 DEBUG   HandlerThread:1680 [handler.py:handle_request():144] handle_request: poll_exit\n2023-05-04 03:20:17,236 DEBUG   SenderThread:1680 [sender.py:send_request():363] send_request: poll_exit\n</code></pre>\n<p>The poll_exit loop is keep logging forever until stopped.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Broken pipe error while wandb.init() files are not sync",
		"Question_link": "https://community.wandb.ai/t/broken-pipe-error-while-wandb-init-files-are-not-sync/4334",
		"Question_created_time": "2023-05-03T17:35:35.271Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 79,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Traceback (most recent call last):<br>\nFile \u201c/home/aakash/anaconda3/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u201d, line 1150, in init<br>\nrun = wi.init()<br>\nFile \u201c/home/aakash/anaconda3/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u201d, line 601, in init<br>\nmanager._inform_init(settings=self.settings, run_id=self.settings.run_id)<br>\nFile \u201c/home/aakash/anaconda3/lib/python3.9/site-packages/wandb/sdk/wandb_manager.py\u201d, line 208, in _inform_init<br>\nsvc_iface._svc_inform_init(settings=settings, run_id=run_id)<br>\nFile \u201c/home/aakash/anaconda3/lib/python3.9/site-packages/wandb/sdk/service/service_sock.py\u201d, line 38, in _svc_inform_init<br>\nself._sock_client.send(inform_init=inform_init)<br>\nFile \u201c/home/aakash/anaconda3/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\u201d, line 211, in send<br>\nself.send_server_request(server_req)<br>\nFile \u201c/home/aakash/anaconda3/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\u201d, line 155, in send_server_request<br>\nself._send_message(msg)<br>\nFile \u201c/home/aakash/anaconda3/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\u201d, line 152, in _send_message<br>\nself._sendall_with_error_handle(header + data)<br>\nFile \u201c/home/aakash/anaconda3/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\u201d, line 130, in _sendall_with_error_handle<br>\nsent = self._sock.send(data)<br>\nI am using Jupiter notebook on  Ubuntu 20.04 Linux system.<br>\nwandb 23.0.1<br>\nprotobuf-3.20.3 tensorboardx-2.6</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-03T22:11:29.857Z",
				"Answer_body": "<p>Hello!<br>\nIt appears that there may be a problem with the connection between your computer and the <code>wandb</code> server. Are you using a load balancer, VPN, or proxy that could be preventing the connection? The <code>sent = self._sock.send(data)</code> error message in the stack trace indicates that the client is having difficulty sending data to the server. This suggests that the issue might be related to network connectivity during this run.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-09T17:07:38.425Z",
				"Answer_body": "<p>Hi Aakash, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Runs never terminating in Dashboard even when requested to stop in UI with wandb-service killed",
		"Question_link": "https://community.wandb.ai/t/runs-never-terminating-in-dashboard-even-when-requested-to-stop-in-ui-with-wandb-service-killed/4271",
		"Question_created_time": "2023-04-24T14:14:07.254Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 43,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019ve been trying to stop my runs for a few days now with no luck. Every new experiment I track using wandb shows a state <em>running</em> , and when the experiment is completed, it stays in that state even when requested to stop within the runs overview or the project runs sidebar.</p>\n<p>The ones that I have requested to stop manually keep showing the <em>green dot</em> to indicate that the run is still active but shows state <em>stopping</em> (some of these have been in state <em>stopping</em> for more than three days). This occurs in all my projects and all runs. I\u2019ve tested with a new project, same issue.</p>\n<p>Any help would be greatly appreciated!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-26T16:21:18.863Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/corentinartaud\">@corentinartaud</a>, could you send me a link to a project where you see this and I can take a look?</p>\n<p>Also, are you stopping the runs with the stop button in the UI?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-03T22:01:56.058Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/corentinartaud\">@corentinartaud</a>, I just wanted to follow up on this and see if you were still running into this?</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to handle resuming and changing config file",
		"Question_link": "https://community.wandb.ai/t/how-to-handle-resuming-and-changing-config-file/4301",
		"Question_created_time": "2023-04-30T11:55:18.818Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 42,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have the following scenario:</p>\n<p>Let\u2019s say I have started a run with a specific config, e.g. at the beginning of my run I would do something like this</p>\n<pre><code class=\"lang-auto\">config = {\"lr\" : 0.01, \"a\": \"b\", ..., \"sample_interval\": 2000}\nwandb.init(config = config, ...)\n</code></pre>\n<p>Now after some time, I realize I want to change something about my model. For example, here I want to sample more often. I would then stop the run and rerun my script with the correct resume ID</p>\n<pre><code class=\"lang-auto\">config = {\"lr\" : 0.01, \"a\": \"b\", ..., \"sample_interval\": 1000}\nwandb.init(config = config, id = OLD_ID, resume = \"allow\",  ...)\n</code></pre>\n<p>I think the behaviour wandb has, is to then have the config be changed to the second config online. Is the first config just overwritten or can it still be seen somewhere?</p>\n<p>In my more concrete usecase, I might want to change more big things. For example: I have trained with one dataloader for some time, then wrote a more efficient dataloader and would like to switch.<br>\nIdeally I would want both of the information, the old and the new config to be seen. Is there a way to do this?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-03T12:34:45.179Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/carla_s\">@carla_s</a>, thanks for your question! So you\u2019re right that in the example you provided the config will be overwritten. You can add every config to a different key, this is:</p>\n<pre><code class=\"lang-auto\">config = {\"config_1\": {\"lr\" : 0.01, \"a\": \"b\", ..., \"sample_interval\": 2000}}\nrun = wandb.init(config = config, ...)\n...\nrun = wandb.init(config = config, id = OLD_ID, resume = \"allow\",  ...)\nrun.config[\"config_2\"] = {\"lr\" : 0.01, \"a\": \"b\", ..., \"sample_interval\": 1000}\n</code></pre>\n<p>However, if you\u2019re changing big things, I would recommend you to use <a href=\"https://docs.wandb.ai/guides/runs/grouping\">groups</a> so that you create one separate run and you can access those runs individually but also visualize those runs grouped. Please let me know if this helps!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-05T09:02:26.000Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-09T12:31:50.758Z",
				"Answer_body": "<p>Hi Carla, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How can I develop my writing skills during IT training?",
		"Question_link": "https://community.wandb.ai/t/how-can-i-develop-my-writing-skills-during-it-training/4326",
		"Question_created_time": "2023-05-03T07:25:22.099Z",
		"Question_answer_count": 0,
		"Question_score_count": 0,
		"Question_view_count": 47,
		"Question_has_accepted_answer": false,
		"Question_body": "<h5>\n<a name=\"encouraging-your-forming-skills-during-it-planning-can-be-trying-but-there-are-a-couple-of-frameworks-that-you-can-use-to-additionally-foster-your-capacities-to-make-1\" class=\"anchor\" href=\"#encouraging-your-forming-skills-during-it-planning-can-be-trying-but-there-are-a-couple-of-frameworks-that-you-can-use-to-additionally-foster-your-capacities-to-make-1\"></a>Encouraging your forming skills during IT planning can be trying, but there are a couple of frameworks that you can use to additionally foster your capacities to make.</h5>\n<p>Encouraging your forming skills during IT planning can be trying, but there are a couple of frameworks that you can use to additionally foster your capacities to make. Coming up next are two or three hints that may be valuable: <a href=\"https://www.sevenmentor.com/\" rel=\"noopener nofollow ugc\">Best Training Institute in Pune</a></p>\n<p>Scrutinize comprehensively: Examining generally can open you to different forming styles and help you with understanding how to structure and smooth your considerations. Endeavor to scrutinize different classes, including particular structure, academic papers, online diaries, and reports.</p>\n<p><strong>Practice regularly:</strong></p>\n<p>Creating reliably can help you with chipping away at your capacities, so endeavor to cut out a valuable open door to reliably make. You can start by keeping a journal or forming short pieces on different focuses.</p>\n<p><strong>Search for input:</strong></p>\n<p>Input is central for additional fostering your creating skills, so contemplate conferring your work to others and mentioning helpful investigation. You can moreover use online gadgets like Grammarly or Hemingway to get input on your creation.</p>\n<p><strong>Acquire from trained professionals:</strong></p>\n<p>Look for creating guides and informative activities that are appropriate to your field. You can moreover go to studios or courses on specific arrangement or business forming.</p>\n<p><strong>Use an unquestionable and brief creating style:</strong></p>\n<p>In specific creation, it is crucial to use a sensible and reduced making style. Make an effort not to use language or unnecessarily obfuscated language that can bewilder your perusers. Use list things and subheadings to isolate your substance and simplify it to examine.</p>\n<p><strong>Change and update:</strong></p>\n<p>Changing and rethinking your work is a basic piece of the innovative cycle. Whenever you have created your most vital draft, carve out a time to rethink it and guarantee that it is proficient, coherent, and bungle free.</p>\n<p>By following these techniques, you can additionally foster your abilities to create during IT getting ready and produce content that is clear, compact, and securing. Remember, cautious discipline achieves promising outcomes, so the more you make, the better you will transform into. Good luck!</p>\n<p>Address- <a href=\"https://goo.gl/maps/QBF6MJVEAtejg9Pk6\" rel=\"noopener nofollow ugc\">A Wing, 5th Floor, Office No 119, Shreenath Plaza, Dnyaneshwar Paduka Chowk, Pune, Maharashtra 411005</a></p>",
		"Answer_list": []
	},
	{
		"Question_title": "Elapsed time per epoch much slower for sweep than for individual runs",
		"Question_link": "https://community.wandb.ai/t/elapsed-time-per-epoch-much-slower-for-sweep-than-for-individual-runs/4061",
		"Question_created_time": "2023-03-15T21:45:58.983Z",
		"Question_answer_count": 8,
		"Question_score_count": 0,
		"Question_view_count": 99,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>When I run the same model individually as I would in a sweep, the performance is much better in terms of time elapsed per epoch. In one recent test I saw a 3x improvement (10min vs 30min). I am running the bayes sweep, minimizing the val/loss,  and using hyperband with min_iter = 1. Both jobs run on a single A100 40Gb GPU. I have also included the following line as I am running on SLURM:<br>\nwandb agent --count 1 SWEEP_ID</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-20T19:30:32.163Z",
				"Answer_body": "<p>Hi Noah,</p>\n<p>Do you notice this huge difference in performance when you are running Sweep vs a Regular run?</p>\n<p>Cheers,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-21T17:46:05.450Z",
				"Answer_body": "<p>Hello Artsiom,</p>\n<p>Yes, that is exactly my issue.</p>\n<p>Best,<br>\nNoah</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-02T20:26:30.700Z",
				"Answer_body": "<p>Could you potentially share a code snippet and we could see if we can reproduce this on our side?</p>\n<p>Warmly,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-10T14:19:47.350Z",
				"Answer_body": "<p>Hi Noah,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-13T16:04:25.985Z",
				"Answer_body": "<p>Hi Noah, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-02T20:45:04.724Z",
				"Answer_body": "<p>Hi artsiom,</p>\n<p>Sorry for my slow response. I put together an example to see if I could reproduce the issue, but it doesn\u2019t seem to do so.</p>\n<p>I will include it here below in case there is something obvious I can do to stress the system more.</p>\n<p>Thanks,<br>\nNoah</p>\n<blockquote>\n<p>import os<br>\nimport wandb</p>\n<p>from argparse import ArgumentParser</p>\n<p>import torch<br>\nfrom torch import nn<br>\nfrom torch.nn import functional as F<br>\nfrom torch.utils.data import DataLoader<br>\nfrom torch.utils.data import random_split<br>\nfrom torchvision.datasets import MNIST<br>\nfrom torchvision import transforms<br>\nimport pytorch_lightning as pl</p>\n<p>class LitAutoEncoder(pl.LightningModule):<br>\ndef <strong>init</strong>(self):<br>\nsuper().<strong>init</strong>()<br>\nself.encoder = nn.Sequential(<br>\nnn.Linear(28 * 28, 64),<br>\nnn.ReLU(),<br>\nnn.Linear(64, 3))<br>\nself.decoder = nn.Sequential(<br>\nnn.Linear(3, 64),<br>\nnn.ReLU(),<br>\nnn.Linear(64, 28 * 28))</p>\n<pre><code>def forward(self, x):\n    embedding = self.encoder(x)\n    return embedding\n\ndef configure_optimizers(self):\n    optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n    return optimizer\n\ndef training_step(self, train_batch, batch_idx):\n    x, y = train_batch\n    x = x.view(x.size(0), -1)\n    z = self.encoder(x)\n    x_hat = self.decoder(z)\n    loss = F.mse_loss(x_hat, x)\n    self.log('train_loss', loss)\n    wandb.log({\"train_loss\": loss})\n    wandb.log({\"epoch\": self.current_epoch})\n    return loss\n\n\ndef validation_step(self, val_batch, batch_idx):\n    x, y = val_batch\n    x = x.view(x.size(0), -1)\n    z = self.encoder(x)\n    x_hat = self.decoder(z)\n    loss = F.mse_loss(x_hat, x)\n    self.log('val_loss', loss)\n    wandb.log({\"val_loss\": loss})\n</code></pre>\n<p>def main(args):</p>\n<pre><code>project = os.getenv(\"TEST_WANDB_PROJ\")\nentity = os.getenv(\"TEST_WANDB_ACCT\")\nprint(f'project: {project}, entity: {entity}')\n\n\nlog_dir = os.getenv(\"TEST_LOG_DIR\")\nif log_dir is None:\n    log_dir = \"./data/TEST_LOG_DIR\"\n    print(\n        \"Using default wandb log dir path of ./data/TEST_LOG_DIR. This can be adjusted with the environment variable `TEST_LOG_DIR`\"\n    )\nif not os.path.exists(log_dir):\n    os.makedirs(log_dir)\nassert (\n    project is not None and entity is not None\n), \"Please set environment variables `TEST_WANDB_ACCT` and `TEST_WANDB_PROJ` with \\n\\\n    your wandb user/organization name and project title, respectively.\"\nexperiment = wandb.init(\n    project=project,\n    entity=entity,\n    config=args,\n    dir=log_dir,\n    reinit=True,\n)\nconfig = wandb.config\nwandb.run.name = args.run_name\nwandb.run.save()\n\n# data\ndataset = MNIST('', train=True, download=True, transform=transforms.ToTensor())\nmnist_train, mnist_val = random_split(dataset, [55000, 5000])\n\ntrain_loader = DataLoader(mnist_train, batch_size=args.batch_size)\nval_loader = DataLoader(mnist_val, batch_size=args.batch_size)\n\n# model\nmodel = LitAutoEncoder()\n\nlogger = pl.loggers.WandbLogger(\n    experiment=experiment, save_dir=\"./data/TEST_LOG_DIR\")\nlogger.log_hyperparams(config)\n\n# training\ntrainer = pl.Trainer(gpus=1, num_nodes=1, precision=32, limit_train_batches=0.5, max_epochs=50)\ntrainer.fit(model, train_loader, val_loader)\n\nexperiment.finish()\n</code></pre>\n<p>if <strong>name</strong> == \u2018<strong>main</strong>\u2019:</p>\n<pre><code>parser = ArgumentParser()\nparser.add_argument(\"--run_name\", type=str, required=True)\nparser.add_argument(\"--batch_size\", type=int, default=32)\n\nargs = parser.parse_args()\nmain(args)\n</code></pre>\n</blockquote>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-15T15:28:42.999Z",
				"Answer_body": "<p>Hi Noah,</p>\n<p>Trying to reproduce this and still no luck on my side, could you send me a link to the workspace of a sweep and a regular run for comparison where one runs slower than the other?</p>\n<p>Warmly,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-18T17:17:18.200Z",
				"Answer_body": "<p>Hi Noah,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "SageMaker Processing jobs have a less informative config than Training jobs",
		"Question_link": "https://community.wandb.ai/t/sagemaker-processing-jobs-have-a-less-informative-config-than-training-jobs/4307",
		"Question_created_time": "2023-05-01T13:43:27.614Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 14,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi all,</p>\n<p>SageMaker integrates fairly well with wandb through <a href=\"https://docs.wandb.ai/guides/integrations/sagemaker\" class=\"inline-onebox\">SageMaker | Weights &amp; Biases Documentation</a>. However, whereas training jobs automatically add all arguments (i.e. \u201chyperparameters\u201d in an Estimator <a href=\"https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Estimators \u2014 sagemaker 2.151.0 documentation</a>) and some extra information (such as the sagemaker_training_job_name, sagemaker_region) to the wandb config, processing jobs do not. I could of course manually add these to my processing job wandb runs, but would rather have it handled through wandb seamless API.</p>\n<p>Is there an intention to close this gap?</p>\n<p>PS this post was flagged as \u2018spam\u2019 because it is considered an \u2018advertisement\u2019. Please let me know why. How can I advertise something when it is not even working? Furthermore, I am only providing relevant facts, I am running into a (minor) limitation, and there is no customer service.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-02T18:04:43.875Z",
				"Answer_body": "<p>Thanks a lot <a class=\"mention\" href=\"/u/laut\">@laut</a> I have proceeded with a feature request on this, as it would be very helpful indeed. We will reach out here once there are any updates.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Unable to link artifacts programatically to the model registry (a \"collection\")",
		"Question_link": "https://community.wandb.ai/t/unable-to-link-artifacts-programatically-to-the-model-registry-a-collection/4306",
		"Question_created_time": "2023-05-01T13:29:38.571Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 22,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi all,</p>\n<p>I am training a model in a SageMaker pipeline. The pipeline consists of a training step (a training job) and an evaluation step (a processing job). I have integrated both these jobs into run groups for each run of the pipeline. The flow is as follows:</p>\n<ol>\n<li>In the training step, the model artefacts with the best performance on the validation set are optionally logged as an Artifact to wandb. This works as expected. There are two Artifacts.</li>\n<li>In the evaluation step, the model artefact are loaded via s3 (not via wandb). In case the test performance is sufficient according to some criteria, the model artefacts are to be logged as Artifacts again to wandb for the evaluation run and afterwards these Artifacts are linked to the model registry.</li>\n</ol>\n<p>Step 2 fails. I have attempted the following:</p>\n<ol>\n<li>Use the initiliased wandb run to call link_artifact (<a href=\"https://docs.wandb.ai/ref/python/run#link_artifact\" class=\"inline-onebox\">Run | Weights &amp; Biases Documentation</a>). This worked twice once for one of the models (except for the fact that created a new Model with the same name in the model registry). For the other model nothing is registered.</li>\n<li>Use the artifact directly to call link (<a href=\"https://docs.wandb.ai/ref/python/public-api/artifact#link\" class=\"inline-onebox\">Artifact | Weights &amp; Biases Documentation</a>). This has not been implemented\u2026</li>\n</ol>\n<p>Any support is appreciated. This seems to me to be basic and core functionality.</p>\n<p>PS this post was flagged as \u2018spam\u2019 because it is considered an \u2018advertisement\u2019. Please let me know why. How can I advertise something when it is not even working? Furthermore, I am only providing relevant facts, I am running into a serious limitation, there is no clear customer service and only very few (basic and superficial) examples exist.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-02T13:48:33.515Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/laut\">@laut</a> thanks for reporting this issue. Let\u2019s continue the troubleshooting on Slack for this one as it requires debug logs and other information, and I can update the thread here afterwards for any future reference.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Tensorboard tab not displaying",
		"Question_link": "https://community.wandb.ai/t/tensorboard-tab-not-displaying/4313",
		"Question_created_time": "2023-05-01T14:12:23.137Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 52,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi all,</p>\n<p>I would like to display my TensorBoard (TB) tab for a run through the integration outlined in the wandb docs for TensorBoard.</p>\n<p>I am using PyTorch (Geometric) and all is going well, except for the fact that no TB tab appears as in the example from the guide. What I have tried:</p>\n<ol>\n<li>Use sync_tensorboard=True in wandb.init. Later on create some SummaryWriter. Indeed my tfevents appear nicely in the files section as in your example run. However, no TB tab appears.</li>\n<li>Explicitly specify wandb.tensorboard.patch(tensorboard_x=False, pytorch=True) with some rootdir. Do not specify sync_tensorboard=True in wandb.init. Later on create a SummaryWrtier. Again, tfevents appear in Files but no TB tab.</li>\n</ol>\n<p>Does anyone have advice for how to force the TB tab to appear?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-02T13:05:04.623Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/laut\">@laut</a> thanks for reporting this issue. Following our discussion on Slack, I wanted to also mention here that TensorBoard tab is only on our public cloud instance <a href=\"http://wandb.ai\">wandb.ai</a>, and isn\u2019t currently supported in W&amp;B Local/Server. This is actively worked on and I will follow up here once it\u2019s released soon.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Integrating Wandb and AWS Lambda - Multiprocessing",
		"Question_link": "https://community.wandb.ai/t/integrating-wandb-and-aws-lambda-multiprocessing/4160",
		"Question_created_time": "2023-03-31T10:20:40.689Z",
		"Question_answer_count": 8,
		"Question_score_count": 0,
		"Question_view_count": 165,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello!</p>\n<p>When I try to download an artifact in an AWS Lambda, I get the following error:</p>\n<pre><code class=\"lang-auto\">[ERROR] OSError: [Errno 38] Function not implemented\nTraceback (most recent call last):\n  File \"/var/task/on_lambda.py\", line 149, in lambda_entrypoint\n    generate_predictions(\n  File \"/var/task/on_lambda.py\", line 75, in generate_predictions\n    models_data = get_models_data()\n  File \"/var/task/on_lambda.py\", line 156, in &lt;lambda&gt;\n    get_models_data=lambda: get_customer_models_data(\n  File \"/var/task/models.py\", line 38, in get_customer_models_data\n    artifact_dir = artifact.download(root=CUSTOMER_DATA_DIR)\n  File \"/var/task/wandb/apis/public.py\", line 3763, in download\n    pool = multiprocessing.dummy.Pool(32)\n  File \"/var/lang/lib/python3.9/multiprocessing/dummy/__init__.py\", line 124, in Pool\n    return ThreadPool(processes, initializer, initargs)\n  File \"/var/lang/lib/python3.9/multiprocessing/pool.py\", line 927, in __init__\n    Pool.__init__(self, processes, initializer, initargs)\n  File \"/var/lang/lib/python3.9/multiprocessing/pool.py\", line 196, in __init__\n    self._change_notifier = self._ctx.SimpleQueue()\n  File \"/var/lang/lib/python3.9/multiprocessing/context.py\", line 113, in SimpleQueue\n    return SimpleQueue(ctx=self.get_context())\n  File \"/var/lang/lib/python3.9/multiprocessing/queues.py\", line 341, in __init__\n    self._rlock = ctx.Lock()\n  File \"/var/lang/lib/python3.9/multiprocessing/context.py\", line 68, in Lock\n    return Lock(ctx=self.get_context())\n  File \"/var/lang/lib/python3.9/multiprocessing/synchronize.py\", line 162, in __init__\n    SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx)\n  File \"/var/lang/lib/python3.9/multiprocessing/synchronize.py\", line 57, in __init__\n    sl = self._semlock = _multiprocessing.SemLock(\n</code></pre>\n<p>Is there a way around this? It seems to be an issue with multiprocessing. I tried setting <code>WANDB_START_METHOD = thread</code> which I saw mentioned in a few places, but the error doesn\u2019t change.</p>\n<p>This is how I\u2019m downloading the artifact:</p>\n<pre><code class=\"lang-auto\">    api = wandb.Api()\n    artifact = api.artifact(artifact_name)\n    artifact_dir = artifact.download(root=data_dir)\n</code></pre>\n<p>I saw two other threads on this topic but they didn\u2019t have a solution</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-05T17:01:25.664Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/chiara_mc\">@chiara_mc</a>,</p>\n<p>AWS Lambda does not support the use of Semaphores at the moment : <a href=\"https://stackoverflow.com/questions/34005930/multiprocessing-semlock-is-not-implemented-when-running-on-aws-lambda\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">python multiprocessing - _multiprocessing.SemLock is not implemented when running on AWS Lambda - Stack Overflow</a></p>\n<p>Is there a specific use case you have in mind? We can see if there is any way to work around this issue since the direct usage of artifacts does not seem possible.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-08T01:39:35.101Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/chiara_mc\">@chiara_mc</a>, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-10T16:49:28.008Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/chiara_mc\">@chiara_mc</a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-11T14:14:59.436Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a>, thanks for your reply!</p>\n<p>We need the lambda to be able to load models and run them, and we liked the idea of being able to retrieve them directly from our wandb\u2019s model registry using aliases, such that we can easily change what models are being used in prod from the wandb website.</p>\n<p>The workaround we are using is to store all model version in our own s3 bucket, using artifact references so that we can still manage the model versions through wandb. The lambda is then able to call wandb to know which versions to use (using the ETag), and can load them from S3.</p>\n<p>Actually, we realised that while <code>artifact.download()</code> causes issues, we can download individual files using <code>artifact.get_path(model_path).download()</code> without issues (at least when they are stored on S3, not sure if it would also work if they were stored on wandb).</p>\n<p>If you have any thoughts on this I\u2019d be keen to hear them!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-18T17:54:03.315Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/chiara_mc\">@chiara_mc</a>,</p>\n<p>I see. Since Semaphores are not available on AWS Lambda, Artifacts are not directly going to be available through Lambda. If you are using Artifact references linked to an S3 bucket, you should be able to use the W&amp;B API to get the reference\u2019s path and use that alongside boto3 to download them.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-24T16:02:34.931Z",
				"Answer_body": "<p>Hi Chiara,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-26T19:19:04.391Z",
				"Answer_body": "<p>Hi Chiara, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-02T10:28:20.357Z",
				"Answer_body": "<p>great post. thanks for sharing. AWS Training in Pune enables you to attain the skills needed to clear the AWS Certified Solutions Architect exam. Join now for the best AWS Certification Course in Pune.</p>\n<p><a href=\"https://www.sevenmentor.com/amazon-web-services-training-institute-in-pune.php\" rel=\"noopener nofollow ugc\">AWS course in Pune</a></p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "wandb.errors.CommError: Run initialization has timed out after 60.0 sec",
		"Question_link": "https://community.wandb.ai/t/wandb-errors-commerror-run-initialization-has-timed-out-after-60-0-sec/4284",
		"Question_created_time": "2023-04-26T08:42:51.327Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 319,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,<br>\nI want to achieve the following behavior:</p>\n<p>I have a yaml file containing all hyper-parameters for my experiment. One of the parameters is a list of values. I want to run a separate wandb run for each value in the list while all other hyper-parameters are the same.<br>\nFor that I split up the config file (containing the hyper-parameters) into multiple config files, each with a different value from the aforementioned list.<br>\nThen I loop over the config files and  initialize a wandb run. Once the run is over or I abort it, the next wandb run is started with another config file.</p>\n<p>Here the loop over the config files:</p>\n<pre><code class=\"lang-auto\">for run_config in run_configs:\n   self.create_dirs()  # this created new directories for the run to save the logs and models to\n   self.run_config = copy.deepcopy(run_config)  # populate the run configuration\n   self.run_experiment(self.run_config[\"tag\"])  # run the experiment with the current run configuration\n</code></pre>\n<p>here the code inside self.run_experiment(tag)</p>\n<pre><code class=\"lang-auto\">run = wandb.init(project=\"MyProjectName\", name=\"unique name\", sync_tensorboard=True,  save_code=True,\n                             dir=unique_directory,  config=self.run_config,  notes=\"some notes\",  tags=tag,  reinit=True, id=wandb.util.generate_id(),\n                             entity=\"MyUserName\",  settings=wandb.Settings(start_method=\"fork\"))\n# the settings=wandb.Settings(start_method=\"fork\")) I found in the wandb documentation but it did not solve my issue\n\ntry:\n    # here I train my agent and log stuff to wandb\nexcept KeyboardInterrupt:\n    # this allows to save the model when interrupting training\n    pass\n\nfinally:\n    # Release resources\n    try:\n        self.save_everything(agent)\n         run.finish()\n         env.close()\n         eval_env.close()\n         del agent\n         del env\n         del eval_env\n    except EOFError:\n         pass\nreturn\n</code></pre>\n<p>So once I manually interrupt the execution my model is saved, the wandb run is finished, everything is deleted and the next iteration of the for-loop begins.</p>\n<p>The issue:</p>\n<p>However, instead of starting the next wandb run after the first one is over/was interrupted I get the following error instead:<br>\nError communicating with wandb process, exiting<br>\nwandb Exception: problem</p>\n<p>after I updated to wandb version 0.15. I get the following error instead:</p>\n<p>wandb: ERROR Run initialization has timed out after 60.0 sec.</p>\n<p>EDIT:<br>\nI have solved the issue. The problem seems to be connected to the fact that I am using PyCharm.<br>\nThe problem at hand is that when I interrupt my script in PyCharm using the red Stop-Button in the top right corner, wandb triggers a KeyBoardInterrupt internally and finishes the run. Afterwards, however, I cannot initialize a new run with wandb.init()<br>\nWhen I go to Run/Edit Configurations inside PyCharm and toggle \u201cEmulate terminal in output console\u201d, I can send the KeyBoardInterrupt usind Control+C inside the output console of PyCharm, In that case wandb allows me to reinitialize a new run after the KeyboardInterrupt was caught.<br>\nSo somehow wandb functions differently in the case where the script receives the KeyBoardInterrupt signal from PyCharm\u2019s red stop button as compared to receiving the KeyBoardInterrupt from the output console with Ctrl+C</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-26T09:37:56.387Z",
				"Answer_body": "<p>Also after trying to restructure the code I am running into the same issue. I cannot run one wandb run after the oher with different configurations. Every time I interrupt one run to start the next one (with a new config), wandb fails with the error message</p>\n<blockquote>\n<p>wandb.errors.CommError: Run initialization has timed out after 60.0 sec.</p>\n</blockquote>\n<p>This time I tried the following init call:</p>\n<pre><code class=\"lang-auto\">\nwandb.init(project=\"SemesterThesis_restructured\", name=self.wandb_name, sync_tensorboard=True, save_code=True,\n                             dir=self.wandb_dir, config=self.run_config, notes=\"\", tags=tag)\n</code></pre>\n<p>and to stop the run I do</p>\n<pre><code class=\"lang-auto\">       except KeyboardInterrupt:\n            # this allows to save the model when interrupting training\n            pass\n\n        finally:\n            # Release resources\n            try:\n                self.save_everything(agent)\n                print(\"everything saved\")\n                wandb.finish()\n                print(\"wandb finished\")\n                # time.sleep(2)\n                env.close()\n                eval_env.close()\n                del agent\n                del env\n                del eval_env\n                print(\"everything closed and deleted\")\n            except EOFError:\n                pass\n        return\n</code></pre>\n<p>Inside my main I now have the following loop:</p>\n<pre><code class=\"lang-auto\">def main() -&gt; int:\n\n    parser = ExperimentParser()\n    for i in [0, 1]: # loop over different yaml files. One file per experiment\n        configs = parser.parse_experiment_config(exp_num=i)\n        for config_dict in configs:\n            experiment = Experiment(config=config_dict, use_wandb=True, record_eval=False)\n            experiment.run_experiment()  # in here I call wandb.init and wand.finish\n            del experiment \n\n    return 0\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-26T10:07:13.837Z",
				"Answer_body": "<p>After debugging some more I found out that the problem only occurs when I interrupt the process manually. If the learning process (inside the try statement) ends naturally (meaning the agent is done learning) everything works as intended. Only when I manually interrupt the learning, wandb fails to restart the next run with the new config.</p>\n<p>How can I solve that issue? I want to be able to interrupt the learning manually and start and new run with a new config automatically afterwards.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-01T18:19:32.149Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/erikk\">@erikk</a> , thank you for confirming you were able to successfully resolve your issue.</p>\n<p>When wandb catches a KeyboardInterrupt exception, it tries to properly finish and close the current run before exiting. However, in the case where the KeyboardInterrupt is caused by a SIGINT signal from PyCharm, it seems that wandb was not able to properly finish the current run, which prevented you from initializing a new run.</p>\n<p>This is difficult to trace, but my best assumption here is in PyCharm, when the stop button is pressed, PyCharm intercepts the signal and handles it internally, <strong>before forwarding</strong> it to the python interpreter process.</p>\n<p>By toggling \u201cEmulate terminal in output console\u201d, you were able to send a Ctrl+C keystroke to the Python interpreter process <strong>immediately</strong> when you pressed the stop button.</p>\n<p>This slight difference in delivery is most likely contributing.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Getting AttributeError: 'NoneType' object has no attribute '_log' while generating model predictions",
		"Question_link": "https://community.wandb.ai/t/getting-attributeerror-nonetype-object-has-no-attribute-log-while-generating-model-predictions/4281",
		"Question_created_time": "2023-04-26T06:19:42.866Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 113,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have a function to generate predictions from my pytorch model like so,</p>\n<pre><code class=\"lang-py\">@torch.inference_mode()\ndef generate_submission(model, test_loader, name='submission.csv'):\n    test_files = listdir(test_dir)\n    len(test_files)\n\n    predictions = []\n    model.eval()\n    for batch_idx, data in enumerate(test_loader):\n        for key, value in data.items():\n            data[key] = value.to(device)\n        model_output = model(data['Image'])\n        _, preds = torch.max(model_output['Probabilities'], dim=1)\n        #preds.cpu()\n        predictions.append(preds)\n\n    final_predictions = torch.cat(predictions, dim=0).to('cpu')\n    df = pd.DataFrame({'id':test_files, 'category':final_predictions})\n    df.to_csv(name, index = False)\n    \n    return df\n</code></pre>\n<p>This function works fine without wandb addition in my code, but after adding wandb logging even though that is nowhere in this specific function I get an error.</p>\n<pre><code class=\"lang-py\">---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n/tmp/ipykernel_23/3664024534.py in &lt;module&gt;\n----&gt; 1 generate_submission(model, test_loader, name='submission-simple.csv')\n\n/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py in decorate_context(*args, **kwargs)\n     25         def decorate_context(*args, **kwargs):\n     26             with self.clone():\n---&gt; 27                 return func(*args, **kwargs)\n     28         return cast(F, decorate_context)\n     29 \n\n/tmp/ipykernel_23/459273187.py in generate_submission(model, test_loader, name)\n      9         for key, value in data.items():\n     10             data[key] = value.to(device)\n---&gt; 11         model_output = model(data['Image'])\n     12         _, preds = torch.max(model_output['Probabilities'], dim=1)\n     13         #preds.cpu()\n\n/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)\n   1209         if _global_forward_hooks or self._forward_hooks:\n   1210             for hook in (*_global_forward_hooks.values(), *self._forward_hooks.values()):\n-&gt; 1211                 hook_result = hook(self, input, result)\n   1212                 if hook_result is not None:\n   1213                     result = hook_result\n\n/opt/conda/lib/python3.7/site-packages/wandb/wandb_torch.py in &lt;lambda&gt;(mod, inp, outp)\n    109             hook = module.register_forward_hook(\n    110                 lambda mod, inp, outp: parameter_log_hook(\n--&gt; 111                     mod, inp, outp, log_track_params\n    112                 )\n    113             )\n\n/opt/conda/lib/python3.7/site-packages/wandb/wandb_torch.py in parameter_log_hook(module, input_, output, log_track)\n    103                 else:\n    104                     data = parameter\n--&gt; 105                 self.log_tensor_stats(data.cpu(), \"parameters/\" + prefix + name)\n    106 \n    107         log_track_params = log_track_init(log_freq)\n\n/opt/conda/lib/python3.7/site-packages/wandb/wandb_torch.py in log_tensor_stats(self, tensor, name)\n    254             bins = torch.Tensor(bins_np)\n    255 \n--&gt; 256         wandb.run._log(\n    257             {name: wandb.Histogram(np_histogram=(tensor.tolist(), bins.tolist()))},\n    258             commit=False,\n\nAttributeError: 'NoneType' object has no attribute '_log'\n</code></pre>\n<p>I don\u2019t understand why is wandb.run._log() even being called here? Only in my training loop did I have a wandb.watch() parameter and wandb.log(metrics) and then used wandb.finish() to close it. Why is this being called here?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-28T21:20:04.903Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/aurko21166\">@aurko21166</a> , this error indicates that a wandb run was not correctly initialized resulting in a None object. Could you provide an example of how you integrated your logic with <a href=\"https://docs.wandb.ai/guides/integrations/lightning#using-pytorch-lightnings-wandblogger\">wandbs ptl logger</a>?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-29T07:00:05.007Z",
				"Answer_body": "<p>I think is error is because wandb adds callbacks to the model upon using wandb.watch(). So after I use wandb.finish() I get this error because the callbacks are still there. I used wandb.unwatch() before finish() to fix it.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb resumed offline runs aren't updating when synced",
		"Question_link": "https://community.wandb.ai/t/wandb-resumed-offline-runs-arent-updating-when-synced/4188",
		"Question_created_time": "2023-04-05T15:12:38.154Z",
		"Question_answer_count": 9,
		"Question_score_count": 1,
		"Question_view_count": 178,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi all! Before my question, let me describe my setup. I am running a training, offline, and then I use a checkpoint from that training to resume training later, also offline. I use the same run ID for both the initial training and the resumed trainings, so wandb generates log folders with the same names but different timestamps.</p>\n<p>When I run wandb sync --sync-all, it appears to sync all of the directories. However only some of the plots get updated with the new data from the resumed runs while others don\u2019t. Is there any reason why this might happen?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-07T17:26:14.698Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/chulabhaya\">@chulabhaya</a>!</p>\n<p>Could you do the following:</p>\n<ol>\n<li>Try running <code>wandb sync ~/my_run_path/wandb/run-timestamp-runid</code> for that particular run and see if that syncs the run to <code>wandb</code> correctly</li>\n<li>Send a link to the project that has runs not updating</li>\n<li>Send the debug logs for a run that isn\u2019t updating.</li>\n</ol>\n<p>The <code>debug.log</code> and <code>debug-internal.log</code> files related to the run can be obtained from the <code>wandb</code> folder located in the same directory as the script execution. The <code>wandb</code> folder contains subfolders with names formatted as <code>run-DATETIME-ID</code>, each representing a single run. Can you retrieve the mentioned log files from the folder corresponding to the specific run that is encountering problems?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-08T15:35:30.788Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/raphael-sanandres\">@raphael-sanandres</a> , thank you for the response!</p>\n<p>So I\u2019ve been able to replicate the issue again.  Regarding the steps you mentioned:</p>\n<ol>\n<li>So I tried the individual resuming and it didn\u2019t work.</li>\n<li>Here is a run from a project that isn\u2019t updating: <a href=\"https://wandb.ai/chulabhaya/sac_heavenhell_3/runs/hh_3_sac_baseline_seed_102_time_1680707984_ob6o2cba?workspace=user-chulabhaya\" class=\"inline-onebox\">Weights &amp; Biases</a>\n</li>\n</ol>\n<p>The weird thing about this is though is that this run <em>was</em> able to update several times successfully, but at some point it just stops being able to update and I don\u2019t know why. You can see this in the Steps Per Second plot where there are spikes at around 200k and 420k which is when the run resumed from a checkpoint.</p>\n<ol start=\"3\">\n<li>Here\u2019s a set of debug logs. The first pair of debug logs is from the 420k offline resuming, which DID update the plots correctly (these are the logs with _correct). The second set of debug logs is from when I resumed training at the 700k mark, but with these offline folders the results don\u2019t sync.</li>\n</ol>\n<p><a href=\"https://drive.google.com/drive/folders/1oOlyuiPYtQwku0AcrCSsyfGAEkT-9bEd?usp=sharing\" class=\"onebox\" target=\"_blank\" rel=\"noopener nofollow ugc\">https://drive.google.com/drive/folders/1oOlyuiPYtQwku0AcrCSsyfGAEkT-9bEd?usp=sharing</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-14T17:27:57.411Z",
				"Answer_body": "<p>Looking into this, could I ask what packages are you using for your training?</p>\n<p>It does look like the run has been synced to <code>wandb</code> so could you try <code>wandb sync --include-offline --include-synced</code> and see if <code>wandb</code> can re-upload it. Also, updating your <code>wandb</code> to <code>0.14.0</code> may help. There has been a similar bug in the past but it was fixed so I am curious to see what may be causing a single run to not be synced. Lastly, I looked into your debug logs and nothing stands out but I will keep looking.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-18T14:08:08.452Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/raphael-sanandres\">@raphael-sanandres</a> ! Could you clarify what you mean by what packages I\u2019m using for training? I\u2019m not using any packages, just standard PyTorch.</p>\n<p>I tried the sync command you provided but sadly that didn\u2019t work either. This is becoming a rather frustrating issue because it means that I can\u2019t do split long training jobs on clusters with reliability since I don\u2019t know if Wandb will be able to actually log the data. I appreciate you still looking, but I might also start looking for a wandb alternative in the meantime that does handle offline jobs correctly.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-21T16:34:45.901Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/chulabhaya\">@chulabhaya</a>!</p>\n<p>I have been asking around internally for this issue and we want to take a closer look at your local machine\u2019s <code>wandb</code> setup to see if there is an issue with other parts of the <code>wandb</code>. In the same directory as where you ran your Python file for training, there should be a <code>wandb</code> folder. This should be the same folder where you navigated to grab the debug bundle.</p>\n<p>Would you be able to send the full folder to us?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-26T07:45:51.849Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"raphael-sanandres\" data-post=\"6\" data-topic=\"4188\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/r/7cd45c/40.png\" class=\"avatar\"> raphael-sanandres:</div>\n<blockquote>\n<p>e a <code>wandb</code> folder. This should be the same folder where you navigated to grab the debug bundle.</p>\n</blockquote>\n</aside>\n<p>Hello <a class=\"mention\" href=\"/u/raphael-sanandres\">@raphael-sanandres</a><br>\nRecently, I encountered a similar problem. By setting \u201cresume=true\u201d and \u201cmode=offline\u201d in the \u201cwandb.init()\u201d function, I was able to obtain multiple offline folders with the same run id but different timestamps as names, such as \u201cwandb/offline-run-20230426_140332-1pe01d2q\u201d and \u201cwandb/offline-run-20230426_140604-1pe01d2q\u201d. When I attempted to upload them separately using the \u201cwandb sync\u201d command, the training process of the second uploaded file did not show up in the charts or system page as expected. It is worth noting that: 1) on the overview page of the run, the start time, config, and summary were updated correctly, and only the information on the chart page did not update. 2) Regarding the difference between these two offline files, they started recording the training process from different steps due to loading different checkpoints. When I did not load the ckpt in the second experiment, the aforementioned problem did not occur, but this is clearly not what I hoped for.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-26T18:39:49.781Z",
				"Answer_body": "<p>Just this morning, I noticed the exact same thing Kevin just commented about, and have posted a detailed working example on a related github issue.  See <a href=\"https://github.com/wandb/wandb/issues/2423#issuecomment-1523812656\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">[Feature] Resume offline runs \u00b7 Issue #2423 \u00b7 wandb/wandb \u00b7 GitHub</a> .  I\u2019m really hoping that a fix can be provided soon, since both offline runs and resuming from checkpoint are strict requirements in my usecase, and they were certainly working at some point.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-27T17:26:38.488Z",
				"Answer_body": "<p>Thanks for everyone\u2019s feedback! Since there are many of you reporting this, I work on reproducing this and writing an internal report on it. Thank you for also posting a reproducible example!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-29T04:10:46.526Z",
				"Answer_body": "<p>Hi again;  just wanted to mention here as well, that I got in contact with the support team by email too, and got the solution to the issue that I mentioned in my latest reply.  See the mentioned feature for a resolution that has been working for me.  Thank you!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to correctly use wandb hyperparameter tuning with Huggingface?",
		"Question_link": "https://community.wandb.ai/t/how-to-correctly-use-wandb-hyperparameter-tuning-with-huggingface/4058",
		"Question_created_time": "2023-03-15T04:27:03.796Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 221,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi everyone <img src=\"https://emoji.discourse-cdn.com/twitter/wave.png?v=12\" title=\":wave:\" class=\"emoji\" alt=\":wave:\" loading=\"lazy\" width=\"20\" height=\"20\">, I am using wandb with Huggingface in a AWS Sagemaker notebook and I am refering to the tutorial here: <a href=\"https://docs.wandb.ai/guides/sweeps/define-sweep-configuration\" class=\"inline-onebox\">Define sweep configuration for hyperparameter tuning.</a> and <a href=\"https://huggingface.co/docs/transformers/hpo_train\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Hyperparameter Search using Trainer API</a>.</p>\n<p>My codes works well without hyperparameter search, but all runs failed after I enable hyperparameter search.</p>\n<p>This is the error message from one of the failed runs:</p>\n<pre><code class=\"lang-auto\">Run 0ilv70r3 errored: ValueError(\"boxes1 must be in [x0, y0, x1, y1] (corner) format, but got tensor([[nan, nan, nan, nan],\\n [nan, nan, nan, nan],\\n [nan, nan, nan, nan],\\n ...,\\n [nan, nan, nan, nan],\\n [nan, nan, nan, nan],\\n [nan, nan, nan, nan]], device='cuda:0', dtype=torch.float16)\") wandb: ERROR Run 0ilv70r3 errored: ValueError(\"boxes1 must be in [x0, y0, x1, y1] (corner) format, but got tensor([[nan, nan, nan, nan],\\n [nan, nan, nan, nan],\\n [nan, nan, nan, nan],\\n ...,\\n [nan, nan, nan, nan],\\n [nan, nan, nan, nan],\\n [nan, nan, nan, nan]], device='cuda:0', dtype=torch.float16)\")\n</code></pre>\n<p>My model is an object detection model. It seems that the outputs do not fit. I wonder how can I solve this issue.</p>\n<p>Here are some useful snippets of my code:</p>\n<pre><code class=\"lang-auto\">def wandb_hp_space(trial):\n    return {\n        \"method\": \"bayes\",\n        \"metric\": {\"name\": \"loss\", \"goal\": \"minimize\"},\n        \"parameters\": {\n            \"learning_rate\": {\"distribution\": \"log_uniform\", \"min\": 1e-6, \"max\": 1e-4},\n            \"per_device_train_batch_size\": {\"values\": [8, 16]},\n        },\n    }\n\n    training_args = TrainingArguments(\n        output_dir=args.output_dir,\n        overwrite_output_dir=True,\n        per_device_train_batch_size=args.per_device_train_batch_size,\n        weight_decay=args.weight_decay,\n        warmup_steps=args.warmup_steps,\n        save_total_limit=args.save_total_limit,\n        learning_rate=args.learning_rate,\n        fp16=True,\n        save_strategy=\"epoch\",\n        logging_strategy='epoch',\n        remove_unused_columns=False,\n        push_to_hub=True,\n        hub_model_id=args.hub_model_id,\n        hub_token=args.hub_token,\n        hub_strategy=\"every_save\",\n        report_to=\"wandb\",\n    )\n\n    def model_init(trial):\n        return AutoModelForObjectDetection.from_pretrained(\n            args.pretrained_model,\n            id2label=CLASS_ID_TO_NAME,\n            label2id=CLASS_NAME_TO_ID,\n            ignore_mismatched_sizes=True,\n        )\n\n    trainer = Trainer(\n        model=None,\n        model_init=model_init,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=test_dataset,\n        data_collator=collate_fn,\n        tokenizer=image_processor,\n    )\n\n    trainer.hyperparameter_search(\n        hp_space=wandb_hp_space,\n        n_trials=5,\n        direction=\"minimize\",\n        backend=\"wandb\",\n    )\n</code></pre>\n<p>I would greatly appreciate any guidance or advice on how to resolve this issue. Thank you very much in advance for your help! <img src=\"https://emoji.discourse-cdn.com/twitter/pray.png?v=12\" title=\":pray:\" class=\"emoji\" alt=\":pray:\" loading=\"lazy\" width=\"20\" height=\"20\"> <img src=\"https://emoji.discourse-cdn.com/twitter/pray.png?v=12\" title=\":pray:\" class=\"emoji\" alt=\":pray:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-20T17:32:15.841Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/oschan77\">@oschan77</a>, could you print all of the args that your script is receiving in your <code>model_init</code>?  From what I can tell, the search space config looks good but I wanted to check that all the arg values are valid since this should be the only difference between a hyperparam search and a standard run.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-20T17:57:17.958Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nathank\">@nathank</a> ! Thank you for your help! This is all the args that the script receive:</p>\n<pre><code class=\"lang-auto\">  parser.add_argument(\"--per_device_train_batch_size\", type=int, default=4)\n  parser.add_argument(\"--warmup_steps\", type=int, default=100)\n  parser.add_argument(\"--save_total_limit\", type=int, default=2)\n  parser.add_argument(\"--pretrained_model\", type=str, default=\"facebook/detr-resnet-50\")\n  parser.add_argument(\"--learning_rate\", type=float, default=1e-5)\n  parser.add_argument(\"--weight_decay\", type=float, default=1e-4)\n  parser.add_argument(\"--image_resize_ratio\", type=float, default=0.25)\n  parser.add_argument(\"--hub_model_id\", type=str, default=None)\n  parser.add_argument(\"--hub_token\", type=str, default=None)\n  parser.add_argument(\"--wandb_token\", type=str, default=None)\n  parser.add_argument(\"--wandb_project_name\", type=str, default=\"detr-algae-v0\")\n  parser.add_argument(\"--wandb_run_name\", type=str, default=None)\n  parser.add_argument(\"--output_dir\", type=str, default=os.environ[\"SM_MODEL_DIR\"])\n  parser.add_argument(\"--n_gpus\", type=str, default=os.environ[\"SM_NUM_GPUS\"])\n  parser.add_argument(\"--training_dir\", type=str, default=os.environ[\"SM_CHANNEL_TRAIN\"])\n  parser.add_argument(\"--test_dir\", type=str, default=os.environ[\"SM_CHANNEL_TEST\"])\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-27T07:43:13.723Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nathank\">@nathank</a> , any ideas? I am still facing the same issue. Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-19T18:18:15.524Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/oschan77\">@oschan77</a>, can you print out the shape and values of your boxes1 during your training to confirm these are Nan\u2019s?</p>\n<p>Also, it\u2019s possible that some of the parameters being suggested by the sweep are not within bounds that work for your model. Could you share your sweep config?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-28T15:05:43.837Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/oschan77\">@oschan77</a>, I wanted to follow up and see if this is still an issue?</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Encountering network error when running sweep",
		"Question_link": "https://community.wandb.ai/t/encountering-network-error-when-running-sweep/4290",
		"Question_created_time": "2023-04-27T16:25:41.303Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 56,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019ve been running sweeps without issue for the past few weeks. This morning, however, I ran into the issue below.</p>\n<pre><code class=\"lang-auto\">(my_env) \u279c  scripts git:(main) \u2717 wandb agent usr/dir/xxxx\nwandb: Starting wandb agent \ud83d\udd75\ufe0f\nwandb: Network error (ReadTimeout), entering retry loop.\n</code></pre>\n<p>I don\u2019t see any issues on <a href=\"https://status.wandb.com/\" rel=\"noopener nofollow ugc\">https://status.wandb.com/</a>. There also doesn\u2019t seem to be any issues on my side connecting to any other external resource (e.g., github, <code>wget</code>ing files.)</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-27T17:59:13.558Z",
				"Answer_body": "<p>Hi Ivan,</p>\n<p>Could you send me the debug logs that were generated after you tried tunning this sweep?</p>\n<p>Cheers,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-28T05:49:09.678Z",
				"Answer_body": "<p>Is there a specific place I should be looking for the related log? I have the <code>wandb</code> directory that contains the logs for each of my prior runs, but in this case, I can\u2019t even get the run to start. It just hangs after displaying <code>wandb: Network error (ReadTimeout), entering retry loop.</code>.</p>\n<p>Edit, more info:</p>\n<ol>\n<li>\n<p>The sweep I\u2019m having issues with finished at a previous time. A few runs in this sweep crashed so I want to rerun them. I deleted the crashed runs, resumed  the sweep in Sweep Controls, and launched my agents as usual before encountering this network error.</p>\n</li>\n<li>\n<p>I upgraded to wandb-0.15.0, but the issue persists.</p>\n</li>\n<li>\n<p>I\u2019m able to run new sweeps from scratch.</p>\n</li>\n</ol>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-01T22:07:44.654Z",
				"Answer_body": "<p>Dang, since there are no logs, do you happen to have some reproducible code, as well as all of the logs for the error when you are running into it?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-05T17:49:02.092Z",
				"Answer_body": "<p>Hi Ivan,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-09T15:46:16.017Z",
				"Answer_body": "<p>Hi Ivan,</p>\n<p>Since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know! Seems like the tickets don\u2019t reopen right now when you write back in for some reason, so please make a new thread and link this thread in there.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Summary value can not be displayed in the scalar chart / dashboard?",
		"Question_link": "https://community.wandb.ai/t/summary-value-can-not-be-displayed-in-the-scalar-chart-dashboard/4294",
		"Question_created_time": "2023-04-28T03:23:07.345Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 37,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I define the max metric value in the code. and the summary file looks like this</p>\n<pre><code class=\"lang-auto\">  \"loss_total\": {\n    \"min\": -0.7097547054290771\n  },\n</code></pre>\n<p>but when i add a scalar chart panel on this metric,  the value can not be displayed, which said \u201cSelect runs that logged summary:loss_total.min to visualize data in this chart.\u201d<br>\nIs there something set wrong ?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-05-02T21:09:46.590Z",
				"Answer_body": "<p>Hi Xinming,</p>\n<p>Could you send me a link to your workspace where you are experiencing this?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-08T15:07:49.765Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-11T17:13:49.943Z",
				"Answer_body": "<p>Hi Xinming, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb assertion errror",
		"Question_link": "https://community.wandb.ai/t/wandb-assertion-errror/4260",
		"Question_created_time": "2023-04-23T06:45:09.854Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 48,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi,<br>\nsometimes I meet with this kind of error, when I run on a remote device:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/3/3210bee6d41f470899393ebd804a54d0b8eacb85.png\" data-download-href=\"/uploads/short-url/78TKyZQzgGPLZDlHXk14ZJlglYV.png?dl=1\" title=\"Screenshot from 2023-04-23 08-40-26\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/3210bee6d41f470899393ebd804a54d0b8eacb85_2_690x93.png\" alt=\"Screenshot from 2023-04-23 08-40-26\" data-base62-sha1=\"78TKyZQzgGPLZDlHXk14ZJlglYV\" width=\"690\" height=\"93\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/3210bee6d41f470899393ebd804a54d0b8eacb85_2_690x93.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/3210bee6d41f470899393ebd804a54d0b8eacb85_2_1035x139.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/3210bee6d41f470899393ebd804a54d0b8eacb85_2_1380x186.png 2x\" data-dominant-color=\"2A2319\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot from 2023-04-23 08-40-26</span><span class=\"informations\">1482\u00d7200 40.2 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\n<code>Error: Run xxx errored: AssertionError()</code><br>\nDubugging tool in vscode cannot locate it. It just pops up and tells you the run is failed. I can find which line is the reason of this error, but have no idea what happens.<br>\nAfter checking for much time, I can do nothing but disconnect with remote device and connect again. And the problem is gone\u2026 Is there a more specific reason?<br>\nThanks a lot!<br>\nJialei Li</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-23T08:18:31.711Z",
				"Answer_body": "<p>Now I find that re-connection cannot completely solve this problem as well. And it raises ramdomly\u2026</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-25T23:10:32.533Z",
				"Answer_body": "<p>Hello! Could you send the debug logs for your runs? The <code>wandb</code> folder has folders formatted as <code>run-DATETIME-ID</code> associated with a single run. Could you retrieve the <code>debug.log</code> and <code>debug-internal.log</code> files from one of these folders specifically from the run that is having issues?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-27T07:56:57.924Z",
				"Answer_body": "<p>Hi,<br>\nsorry for late reply. I found one of those run files, but I don\u2019t know how to upload log files, because they are not legel files to upload in forum. Would you please advise an alternative way for me to give the logs?<br>\nThanks a lot <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-27T17:56:47.071Z",
				"Answer_body": "<p>Hi,<br>\nI found the reason now. It is relative with other part of my project\u2019s program. It has nothing to do with wandb actually\u2026 Still thanks a lot for your willingness to check error for me <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": true
			}
		]
	},
	{
		"Question_title": "Changing path or removing cache of artifacts",
		"Question_link": "https://community.wandb.ai/t/changing-path-or-removing-cache-of-artifacts/4275",
		"Question_created_time": "2023-04-25T07:11:20.716Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 109,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am having an issue of running wandb on a slurm cluster and the artifacts populate in my user dir <code>~/.local/share/wandb/artifacts/staging</code>. This dir is populated with <code>tmp*</code> files. I want to change the environment variable to reroute this path, but none of the paths listed on the <a href=\"https://docs.wandb.ai/guides/artifacts/storage#docusaurus_skipToContent_fallback\">storage docs</a> do it.</p>\n<p>Those same docs say that you can run<code>$ wandb artifact cache cleanup 1GB</code> from the cmd line but it is unclear of this is for the cache <code>~/.cache</code>. Since this command only caps the cache it is hard to tell if it is working without hitting the <code>1GB</code> limit. Can you help clarify if this command is for <code>~/.local/share/wandb/artifacts/staging</code> or if it is for <code>~/.cache</code>? Thanks for any help.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-27T15:57:37.320Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mjvolk3\">@mjvolk3</a>, thanks for your question! Do you know if <code>.local/share</code> is the system cache directory? The default path should be <code>~/cache/wandb/artifacts/</code> unless you set <code>WANDB_CACHE_DIR</code>. Said this, <code>wandb artifact cache cleanup</code> should be for <code>~/cache/wandb/artifacts/</code> since this is the default cache dir. Also, could you check with <code>env | grep -i wandb*</code> if <code>WANDB_CACHE_DIR</code> is set?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-03T08:31:22.838Z",
				"Answer_body": "<p>Hi Michael,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Why do I have an army of wandb files everywhere? It's overwhelming my disk quota",
		"Question_link": "https://community.wandb.ai/t/why-do-i-have-an-army-of-wandb-files-everywhere-its-overwhelming-my-disk-quota/4221",
		"Question_created_time": "2023-04-14T19:03:35.691Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 96,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I think this was caused by wandb</p>\n<pre><code class=\"lang-auto\">(mds_env_gpu) brando9~ $ ls\ndata\t\t\t\t\t\t   pymp-5u3y_5ds  pymp-bkacd1x6  pymp-hvosikw7\tpymp-o4ubsmvp  pymp-u2hxw56_\ndebug-cli.brando9.log\t\t\t\t   pymp-5ufiwnum  pymp-bkeosgoh  pymp-hwp6mlgl\tpymp-o5709m1c  pymp-u3pu2_8j\ndiversity-for-predictive-success-of-meta-learning  pymp-5v6yw2ny  pymp-bli8hdga  pymp-hxkt2k6m\tpymp-o5pz2fw4  pymp-u4atcmq1\niit-term-synthesis\t\t\t\t   pymp-5vfjyiy8  pymp-blu04xre  pymp-hy_6a7yv\tpymp-o5qihl07  pymp-u4hs1l_h\nminiconda\t\t\t\t\t   pymp-5vkol09u  pymp-bm04j6u_  pymp-hybr3wao\tpymp-o5v4yyjh  pymp-u5hwvurq\nminiconda.sh\t\t\t\t\t   pymp-5w0ycex5  pymp-bm1af1s4  pymp-hyd9kp9k\tpymp-o78e5rv_  pymp-_u6saect\nproverbot9001\t\t\t\t\t   pymp-5wk26dbe  pymp-bm_hml09  pymp-hyg2wzja\tpymp-o7u0brbq  pymp-u7341z_u\npycoq\t\t\t\t\t\t   pymp-5wv1264k  pymp-bmwsk0ui  pymp-hyujmqqx\tpymp-o8dzl_uf  pymp-u75jwgya\npymp-00y0lbly\t\t\t\t\t   pymp-5x3lfjus  pymp-bnduqemj  pymp-hyvxx7e3\tpymp-o8rez_1_  pymp-u7ca8y7o\n...\n\t\t\t\t   pymp-be9ogs4j  pymp-hptd30xx  pymp-ny7y25f5\tpymp-tudnkgfd  tmpft4wdrhxwandb\npymp-5no2jlmt\t\t\t\t\t   pymp-bedy_tkt  pymp-hpybolff  pymp-nyra71s5\tpymp-t_uf7u5j  tmpfvg5and3wandb\npymp-5ntrk5up\t\t\t\t\t   pymp-beha_4zu  pymp-hq7fmd8n  pymp-nzpgew4t\tpymp-tvqwp5ey  tmpj6j0zfbj\npymp-5omzfs4r\t\t\t\t\t   pymp-bei9ikn0  pymp-hqydweky  pymp-o08sw9t7\tpymp-tvwdr69z  tmpj8tzqwx4\npymp-5_pfdtfd\t\t\t\t\t   pymp-berkyhno  pymp-hr4yovs8  pymp-o0c0lcxr\tpymp-twvu_nlb  tmplgskh1xrwandb-artifacts\npymp-5p_xds_i\t\t\t\t\t   pymp-bgxwfpek  pymp-hr5p_4ss  pymp-o0hmcwva\tpymp-tx00ffcm  tmpmfxif8o4wandb-media\npymp-5q_5m8lf\t\t\t\t\t   pymp-_bgy7q56  pymp-hra_cgtz  pymp-o0jepdlw\tpymp-txu77bbs  tmpol_hgq43wandb-artifacts\npymp-5qxdpjjs\t\t\t\t\t   pymp-bhelzwte  pymp-hrc22cf7  pymp-_o0s21so\tpymp-ty8mdfqa  tmppybf10yp\npymp-5rlt16x0\t\t\t\t\t   pymp-bhfw5927  pymp-hrtr23se  pymp-o1hh7338\tpymp-tykpaaaa  tmpq3i3awq2wandb-media\npymp-5rlwn6_h\t\t\t\t\t   pymp-bhfz8nzu  pymp-hs_0tj_l  pymp-o1mmetf7\tpymp-tz38gxnk  tmpvbj3c1glwandb-artifacts\npymp-5sf007t_\t\t\t\t\t   pymp-bhzzq3ji  pymp-hs60ap_i  pymp-o2pg14r2\tpymp-tz5zx4w5  tmpx795b348wandb-media\npymp-5smqiuo8\t\t\t\t\t   pymp-_bi71ltm  pymp-ht16ywuf  pymp-o3sgbsuh\tpymp-u03tywik  tmpz6nn0yezwandb-media\npymp-5svxeand\t\t\t\t\t   pymp-bia6j600  pymp-htb33wdv  pymp-o41jeuwi\tpymp-u19gfzmg  tmpzkt1j4lt\npymp-5tpni86a\t\t\t\t\t   pymp-bip9y835  pymp-htj63od5  pymp-o48ihbt6\tpymp-u1a3qbtw  tmpzov5_ez7wandb-artifacts\npymp-5turfdfv\t\t\t\t\t   pymp-b_j5cszm  pymp-hu621te7  pymp-o4hse0ac\tpymp-u215nj9s  ultimate-utils\npymp-5_u0d4ov\t\t\t\t\t   pymp-bk6h_1kx  pymp-huvexmsv  pymp-o4tpqmbs\tpymp-u21uakvb  wandb\n</code></pre>\n<p>I have this:</p>\n<pre><code class=\"lang-auto\"># - use local machine as home, can't start with cd because like in .bashrc.user since we need to figure out local path in lfs\n#export LOCAL_MACHINE_PWD=$(python3 -c \"import socket;hostname=socket.gethostname().split('.')[0];print(f'/lfs/{hostname}/0/brando9');\")\nexport LOCAL_MACHINE_PWD=$(python3 -c \"import socket;hostname=socket.gethostname().split('.')[0];print('/lfs/'+str(hostname)+'/0/brando9');\")\nmkdir -p $LOCAL_MACHINE_PWD\nexport WANDB_DIR=$LOCAL_MACHINE_PWD\nexport HOME=$LOCAL_MACHINE_PWD\n</code></pre>\n<p>is it wrong?</p>\n<p>Also, why would it take 11T of info?</p>\n<pre><code class=\"lang-auto\">(mds_env_gpu) brando9~ $ df -h /lfs/hyperturing2/0/brando9/\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/md127       11T   11T   48M 100% /lfs/hyperturing2/0\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-19T11:57:06.144Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/brando\">@brando</a> thanks for reporting this issue. Could you please clarify in which files/directories are you referring to?</p>\n<p>The <code>pymp-*</code> folders seem to be coming from the multiprocessing python package, and it\u2019s an issue that <a href=\"https://bugs.python.org/issue21664\" rel=\"noopener nofollow ugc\">has been addressed</a> in certain Python versions, what\u2019s your current one? However, the  <code>tmp&lt;run-id&gt;wandb</code> are definitely created by wandb, could you please output disk usage per directory to see what\u2019s actually related with wandb ones?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-24T13:05:35.684Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/brando\">@brando</a> I wanted to follow up with you and see if you could provide us any further information requested in the previous message, so that we could understand what caused this issue for you. Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-27T15:15:44.475Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/brando\">@brando</a> since we haven\u2019t heard back from you, I will go ahead and close this ticket for now. Please let us now though if the issue persists for you,  and we will be happy to keep investigating!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How can I move a whole project to a team?",
		"Question_link": "https://community.wandb.ai/t/how-can-i-move-a-whole-project-to-a-team/4270",
		"Question_created_time": "2023-04-24T13:55:53.640Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 45,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have a personal project with some sweeps on it that I\u2019d like to move to our newly-created team. I see a way to move a run between projects, but not a way to move a whole project. Is this possible?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-25T20:21:54.712Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thomasj02\">@thomasj02</a> , happy to help. Users can\u2019t move entire projects but could move all runs within a project to another project/entity, see <a href=\"https://docs.wandb.ai/guides/app/features/runs-table#select-all-runs-in-table\">here</a>. We could move the projects for you. Please email <a href=\"mailto:support@wandb.ai\">support@wandb.ai</a> with the project name, and from/to entities.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Summary metric from runs not visible in sweep (bug?)",
		"Question_link": "https://community.wandb.ai/t/summary-metric-from-runs-not-visible-in-sweep-bug/4276",
		"Question_created_time": "2023-04-25T11:58:31.865Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 40,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Greetings WandB, many thanks for your fantastic service!</p>\n<p>I have been running several sweeps in a project and only realised that the summary metrics for the sweeping overview got several missing values despite the runs containing and having successfully logged these. Did I log my metrics wrong and need to redo all my experiments, or is it a bug, as described below? <img src=\"https://emoji.discourse-cdn.com/twitter/innocent.png?v=12\" title=\":innocent:\" class=\"emoji\" alt=\":innocent:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<p>Please see this first image, containing the run summary of <em>toasty-sweep-31</em>, which logged <em><strong>Test_AUC_std</strong></em> and <em>Test_EER_std</em>. Let\u2019s focus on the \u2018Test_AUC_std\u2019 since that column is also visible in the following screenshot showing the sweep summary metrics; however, the same issue appears for several other columns also logged within each run.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/daaa3450969a597cb1f40eef9649cc508f8b01dc.png\" data-download-href=\"/uploads/short-url/vcoKtRVH2OFQYEi2J7FzZW4jySo.png?dl=1\" title=\"summary_metric_in_run\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/daaa3450969a597cb1f40eef9649cc508f8b01dc.png\" alt=\"summary_metric_in_run\" data-base62-sha1=\"vcoKtRVH2OFQYEi2J7FzZW4jySo\" width=\"690\" height=\"363\" data-dominant-color=\"242324\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">summary_metric_in_run</span><span class=\"informations\">904\u00d7476 11.8 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>In the sweep summary metrics, I am showing all columns available, including <em><strong>Test_auc_std</strong></em>, but now the AUC is lowercase, and the values are missing. Same for the \u201cTest_EER_std\u201d etc.</p>\n<p>Since the columns are automatically inferred from runs, how could I \u2018refresh\u2019 the columns to synchronise with the runs? I do not recall logging \u2018Test_auc\u2019, but that may be a spillover from early runs. Is there are way to \u2018recompile\u2019 the project and these summary metrics?</p>\n<p>The sweep is available <a href=\"https://wandb.ai/aabywan/SigDraw2/sweeps/tnc1g4c7/table?workspace=user-aabywan\">here</a></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-27T17:28:56.222Z",
				"Answer_body": "<p>Hi Peter,</p>\n<p>It is a bug and I am very sorry you are running into this. Unfortunately as of yet, wandb isn\u2019t case-sensitive, and if in one of the older runs you have switched it to lowercase and then back to uppercase, that might have messed it up, and now it\u2019s showing only the lowercase one although both of them are saved successfully as shown in the summary.</p>\n<p>For now, the workaround would be rerunning your sweep and making sure you don\u2019t have the same-named variables with different capitalizations that might mess it up.</p>\n<p>I\u2019ll report this bug instance to our eng team.</p>\n<p>Apologies you are running into this again,</p>\n<p>Warmly,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Choppy table movement (web)",
		"Question_link": "https://community.wandb.ai/t/choppy-table-movement-web/4211",
		"Question_created_time": "2023-04-13T06:08:22.619Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 74,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have a small (I think) table of around 20 runs and 20 columns. When dragging the slide bar horizontally, visible lag (~500ms) exists when a block of numbers is getting loaded. The latency is acceptable, but the movement seems to be waiting on this lag and the movement becomes choppy. This prevents me from efficiently locate a column I want to look at.<br>\nIs there a way to accomodate this lag? It is okay that the numbers don\u2019t show immediately but at least it should not interfere with the slide bar movement.<br>\nI do not have any complicated contents (images, for example) in the table. Only short strings and numbers.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-17T16:17:53.980Z",
				"Answer_body": "<p>HI <a class=\"mention\" href=\"/u/eliphat\">@eliphat</a>, could you possibly post a link to the workspace where you are seeing this so I can pass this onto our engineering team?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-18T01:26:55.804Z",
				"Answer_body": "<p>Basically every workspace I am in, except for very small projects where there are less than 10 rows and 10 columns. For example, <a href=\"https://wandb.ai/rom1504/eval_openclip/table?workspace=user-eliphat\">eval_openclip Table \u2013 Weights &amp; Biases (wandb.ai)</a><br>\nSimply drag the horizontal slidebar back and forth for a good distance, and you will see that it once and again gets stuck for a while.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-18T01:27:36.411Z",
				"Answer_body": "<p>P.S. I am using the latest version of the Edge browser.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-24T15:50:31.083Z",
				"Answer_body": "<p>I see, thank you for reporting this. I was able to reproduce this in Safari as well. I\u2019ll report the bug to the engineering team and follow up once they are able to get a fix on this.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sync error",
		"Question_link": "https://community.wandb.ai/t/sync-error/4267",
		"Question_created_time": "2023-04-24T12:28:33.448Z",
		"Question_answer_count": 7,
		"Question_score_count": 3,
		"Question_view_count": 89,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>When I finished the training with the offline mode, I use  the following command to upload the trained results to the cloud service.</p>\n<pre><code class=\"lang-auto\">wandb  sync   MY_RUN_DIRECTORY\n</code></pre>\n<p>But I got the KeyError: \u2018run_url\u2019<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/ae1f879a48417b9728aa910bc9e8bb757627f044.jpeg\" data-download-href=\"/uploads/short-url/oQmDb7gGEFmjb7DrMnTKtSiKweM.jpeg?dl=1\" title=\"Screenshot 2023-04-24 202643\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/ae1f879a48417b9728aa910bc9e8bb757627f044_2_690x240.jpeg\" alt=\"Screenshot 2023-04-24 202643\" data-base62-sha1=\"oQmDb7gGEFmjb7DrMnTKtSiKweM\" width=\"690\" height=\"240\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/ae1f879a48417b9728aa910bc9e8bb757627f044_2_690x240.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/ae1f879a48417b9728aa910bc9e8bb757627f044_2_1035x360.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/ae1f879a48417b9728aa910bc9e8bb757627f044_2_1380x480.jpeg 2x\" data-dominant-color=\"181818\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2023-04-24 202643</span><span class=\"informations\">1396\u00d7487 192 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>How to solve this question?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-24T12:59:05.609Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lee086824\">@lee086824</a> thanks for reporting this issue. There was a regression in wandb <code>v0.14.1</code> that would throw this <code>KeyError: 'run_url'</code>. Is this your current version, and if so could you please upgrade to our most recent client/SDK version and try to sync your runs again? Would it work for you?</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-04-24T13:24:56.757Z",
				"Answer_body": "<p>Yes!!! You are right!  It works for me.  Thank you so much!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-24T13:30:34.490Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lee086824\">@lee086824</a> perfect, glad to hear this worked, thanks a lot for the confirmation! I will now close this ticket, and feel free to reach out to us again if you have any other questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-24T13:46:12.919Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a>  there is another question<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/0/02b45195d906aa5918502412ca3495d2b10ad345.png\" data-download-href=\"/uploads/short-url/nVhJdSTarJhXBW81apH0R3nESV.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/0/02b45195d906aa5918502412ca3495d2b10ad345_2_690x79.png\" alt=\"image\" data-base62-sha1=\"nVhJdSTarJhXBW81apH0R3nESV\" width=\"690\" height=\"79\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/0/02b45195d906aa5918502412ca3495d2b10ad345_2_690x79.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/0/02b45195d906aa5918502412ca3495d2b10ad345_2_1035x118.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/0/02b45195d906aa5918502412ca3495d2b10ad345_2_1380x158.png 2x\" data-dominant-color=\"201F20\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1893\u00d7218 51.7 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nI uploaded it once before, but there was only one run record in the cloud service, and there was no training data in it, so I deleted that, and this question happened when I uploaded it again.<br>\nSo how to solve this question?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-24T14:13:12.794Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lee086824\">@lee086824</a> thanks for following up on this. You could undelete this run from your Project\u2019s Overview page: <code>https://wandb.ai/ENTITY/PROJECT/overview</code> (please replace ENTITY and PROJECT with your details) and click on three vertical dots in top right corner of Overview and <code>Undelete runs</code>. You could then try to sync again this run that fails.</p>\n<p>Another alternative would be to specify a new unique id (<code>new-run-id</code>) when syncing this run, using the <code>wandb sync --id=new-run-id wandb/offline-run-date_time-old_runid</code> command. You could get a new unique id as follows:<br>\n<code>python -c \"import wandb; print(wandb.util.generate_id())\"</code></p>\n<p>Would any of these work for you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-24T15:15:29.460Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a><br>\nYes! These did work for me .  Thank you once again!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-24T15:24:31.964Z",
				"Answer_body": "<p>Great! Thanks for confirming these worked for you <a class=\"mention\" href=\"/u/lee086824\">@lee086824</a> ! I will close this ticket again, but please let us know if you had any other questions and we will be happy to keep investigating.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Bayes method for searching in sweep",
		"Question_link": "https://community.wandb.ai/t/bayes-method-for-searching-in-sweep/4261",
		"Question_created_time": "2023-04-23T11:30:20.766Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 29,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\nI am using Bayes searching method to sweep through a group of hyper-parameters. Number of all permutations of these 2 hyper-parameters is 15. I set sweep count as 60, in order to get more cases. However when I check the sweep plots, I see this:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/b/b5d24ccd8cabd322b72c5d1f40a604d4adbdfe21.png\" data-download-href=\"/uploads/short-url/pWsZfhMVsFezceHwQ3Aibtbmbsd.png?dl=1\" title=\"Screenshot from 2023-04-23 13-17-49\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b5d24ccd8cabd322b72c5d1f40a604d4adbdfe21_2_690x328.png\" alt=\"Screenshot from 2023-04-23 13-17-49\" data-base62-sha1=\"pWsZfhMVsFezceHwQ3Aibtbmbsd\" width=\"690\" height=\"328\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b5d24ccd8cabd322b72c5d1f40a604d4adbdfe21_2_690x328.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b5d24ccd8cabd322b72c5d1f40a604d4adbdfe21_2_1035x492.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b5d24ccd8cabd322b72c5d1f40a604d4adbdfe21_2_1380x656.png 2x\" data-dominant-color=\"F8F8F9\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot from 2023-04-23 13-17-49</span><span class=\"informations\">2460\u00d71170 312 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>There are already 44 sweeps, but it seems many of cases are exactly identical. As a result, I actually only get 6 or 7 cases, even less than grid search. As you can see above, many cases are really superpositioned\u2026</p>\n<p>So it confuses me now that how should I understand Bayes searching method.<br>\nAnd there is corresponding code about sweep:</p>\n<pre><code class=\"lang-auto\">sweep_configuration = {\n'method': 'bayes',\n'name': f'{args.dataset_name} 3rd class: levels, hidden_size',\n'metric': {'goal': 'minimize', 'name': 'valid/ber'},\n'parameters':\n{\n    'levels': {'values': [1,2,3,4,5]},\n    'hidden_size': {'values': [1.0,2.0,3.0]}\n}\n}\nargs.tune_count = 60\nwandb.agent(sweep_id, function=Hyper_param_Tune, count=args.tune_count)\n</code></pre>\n<p>Thanks for any help!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-23T11:30:57.254Z",
				"Answer_body": "<p>Here is also another prove that many cases are identical:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/dc775db0aa61e7d11d2051bb303d1a65077a1dd0.jpeg\" data-download-href=\"/uploads/short-url/vskMBpgsB7zo8DLoXFH7T1un3uU.jpeg?dl=1\" title=\"Screenshot from 2023-04-23 13-18-00\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/dc775db0aa61e7d11d2051bb303d1a65077a1dd0_2_690x328.jpeg\" alt=\"Screenshot from 2023-04-23 13-18-00\" data-base62-sha1=\"vskMBpgsB7zo8DLoXFH7T1un3uU\" width=\"690\" height=\"328\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/dc775db0aa61e7d11d2051bb303d1a65077a1dd0_2_690x328.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/dc775db0aa61e7d11d2051bb303d1a65077a1dd0_2_1035x492.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/dc775db0aa61e7d11d2051bb303d1a65077a1dd0_2_1380x656.jpeg 2x\" data-dominant-color=\"F5F5F4\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot from 2023-04-23 13-18-00</span><span class=\"informations\">1920\u00d7913 188 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-26T21:17:52.472Z",
				"Answer_body": "<p>Hi Jialei, apologies you are running into this, could you send a link to your workspace, as well a the minimal reproduction steps?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-02T15:13:35.369Z",
				"Answer_body": "<p>Hi Jialei,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-05T17:32:03.633Z",
				"Answer_body": "<p>Hi Jialei, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Collect results from sweep",
		"Question_link": "https://community.wandb.ai/t/collect-results-from-sweep/4238",
		"Question_created_time": "2023-04-19T20:48:57.687Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 33,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi,<br>\nI am tuning hyper-params with <code>wandb.sweep</code>. For now, in order to get the best group of hyper-params, I have to look for the best group on my own and record those params manually. I wonder whether there is a way to extract or collect reuslts of hyper-params automatically by <code>wandb</code>?<br>\nThanks a lot!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-20T16:55:19.809Z",
				"Answer_body": "<p>Hello!</p>\n<p>We have <a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W%26B.ipynb#scrollTo=G01IM4yVkc6u\" rel=\"noopener nofollow ugc\">Parallel Coordinate plots and Hyper Parameter Importance Plots</a> in the UI that can help with looking for the best group! In terms of collecting results of sweeps, the hyperparameters are automatically logged to the <code>config.yaml</code> file in your run\u2019s file tab.  However, if you want to collect the hyperparameters  yourself, you can also access individual hyperparameter values using <code>wandb.config['hyperparameter-name']</code> within the <code>main()</code> function you are running your sweep on. <a href=\"https://docs.wandb.ai/guides/track/config\">Here</a> is our documentation on ways to use access and update the config file.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-04-20T17:53:51.120Z",
				"Answer_body": "<p>Thank you very much for your advices! <img src=\"https://emoji.discourse-cdn.com/twitter/laughing.png?v=12\" title=\":laughing:\" class=\"emoji\" alt=\":laughing:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to add prior runs to Sweep via Python API?",
		"Question_link": "https://community.wandb.ai/t/how-to-add-prior-runs-to-sweep-via-python-api/4207",
		"Question_created_time": "2023-04-12T18:01:06.655Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 74,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Sweeps <a href=\"https://docs.wandb.ai/guides/sweeps/faq#is-there-a-way-to-add-extra-values-to-a-sweep-or-do-i-need-to-start-a-new-one\">FAQ</a> describes a way of adding prior runs to a new sweep via Web/GUI:</p>\n<blockquote>\n<p><strong>Is there a way to add extra values to a sweep, or do I need to start a new one?</strong></p>\n<p>You cannot change the Sweep configuration once a W&amp;B Sweep has started. But you can go to any table view, and use the checkboxes to select runs, then use the <strong>Create sweep</strong> menu option to create a new Sweep configuration using prior runs.</p>\n</blockquote>\n<p>How do I do the same using WandB Python API?</p>\n<p>Thanks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-17T13:58:09.057Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/avm21\">@avm21</a>, thanks for writing in! This isn\u2019t possible at this moment as this feature is only available through the UI. I can for sure create a feature request if you would like to have this feature available in the future, would you mind explaining to me your use case? Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-17T14:52:33.794Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/luis_bergua1\">@luis_bergua1</a>, thanks for your response!</p>\n<p>My use case is the same as in what the UI feature is for. I first did several manual Runs, then a grid search Sweep or two, and later decided that I want to continue my hyperparameter search using Bayesian optimisation, and I don\u2019t want the previous runs be wasted.</p>\n<p>The only difference is that I would like to select relevant Runs for inclusion into the new sweep programmatically, just because I find this more convenient.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-20T17:14:11.724Z",
				"Answer_body": "<p>Thanks for confirming this <a class=\"mention\" href=\"/u/avm21\">@avm21</a>! I\u2019ll share this feedback internally with our product team.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Debug error with wandb",
		"Question_link": "https://community.wandb.ai/t/debug-error-with-wandb/4155",
		"Question_created_time": "2023-03-30T16:23:41.703Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 166,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\nI met with a debug error when tuning hyperparams with sweep.</p>\n<p><code>wandb: ERROR Run c3yfj87h errored: RuntimeError('cuDNN error: CUDNN_STATUS_INTERNAL_ERROR')</code></p>\n<p><code>wandb: ERROR Run 542e421i errored: RuntimeError('false INTERNAL ASSERT FAILED at \"../c10/cuda/CUDAGraphsC10Utils.h\":73, please report a bug to PyTorch. Unknown CUDA graph CaptureStatus32522')</code></p>\n<p>When I directly run it with a terminal, there is no such error. It only occurs when I debug. Could someone give some clues about the reason why?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-06T20:49:37.824Z",
				"Answer_body": "<p>According to a <a href=\"https://stackoverflow.com/questions/62067849/pytorch-model-training-runtimeerror-cudnn-error-cudnn-status-internal-error\" rel=\"noopener nofollow ugc\">Stack Overflow post</a>,  the error <code>RuntimeError('cuDNN error: CUDNN_STATUS_INTERNAL_ERROR')</code> normally indicates that this is an out of memory problem.</p>\n<p>This is likely this is an issue with PyTorch but there may be information in the debug logs of the run. They should be located in the <code>wandb</code> folder in the same directory as where the script was run. The <code>wandb</code> folder has folders formatted as <code>run-DATETIME-ID</code> associated with a single run. Could you retrieve the <code>debug.log</code> and <code>debug-internal.log</code> files from one of these folders specifically from the run that is having issues?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-11T23:31:10.331Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-19T20:44:52.842Z",
				"Answer_body": "<p>Hi,<br>\nsorry for delay of my reply. Unfortunately I cannot remember which run is related with this issue. For now I have not seen this error for several days. If the same problem occurrs again, I will turn to here then. Thanks for your help <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How can I extract params from sweep and add them into name of wandb.init()",
		"Question_link": "https://community.wandb.ai/t/how-can-i-extract-params-from-sweep-and-add-them-into-name-of-wandb-init/4146",
		"Question_created_time": "2023-03-29T12:03:52.727Z",
		"Question_answer_count": 2,
		"Question_score_count": 1,
		"Question_view_count": 87,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi,<br>\nI am tuning hyper-params with wandb.sweep(). As I know the params are defined in sweep_id and insert into wandb.sweep() like this:</p>\n<pre><code class=\"lang-auto\">    sweep_configuration = {\n    'method': 'bayes',\n    'name': 'I dont believe that I can not just give you a name!',\n    'metric': {'goal': 'minimize', 'name': 'Valid/final_ber'},\n    'parameters':\n    {\n        'batch_size': {'distribution': 'int_uniform','min': 10,'max': 12},\n        'lr': {'distribution': 'int_uniform','max': -3,'min': -4}\n    }\n    }\n    sweep_id = wandb.sweep(sweep=sweep_configuration, project=args.project, entity=args.entity)\n</code></pre>\n<p>Now I what I want to do is to extract the params <strong>batch_size</strong> and <strong>lr</strong> from each sweep into the name of <code>wand.init()</code>, because I need these information in name of each run to identify them.<br>\nBut in wandb frame, I cannot get access to the params in <code>wandb.config</code> before <code>wandb.init()</code>. As a result I cannot define argument <strong>name</strong>  in <code>wandb.init()</code> with params which are given during each sweep.</p>\n<pre><code class=\"lang-auto\">......\nwandb.init(name=f'{wandb.config.lr}_{wandb.config.batch_size}')\n......\n\nRun wnb56ush errored: Error('You must call wandb.init() before wandb.config.lr')\nwandb: ERROR Run wnb56ush errored: Error('You must call wandb.init() before wandb.config.lr')\n</code></pre>\n<p>Is there a way to get the params given by <code>wandb.sweep()</code> before wandb.init()?<br>\nThanks at advance</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-06T21:18:11.261Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/1060111768\">@1060111768</a> , it\u2019s not possible to get the sweep parameters before calling <code>wandb.init()</code>.</p>\n<p>When you run <code>wandb.sweep()</code> to define a hyperparameter sweep, it generates a unique sweep ID that is used to link the sweep to the subsequent runs that are generated by the sweep. This sweep ID is used to retrieve the sweep parameters when you initialize WandB by calling <code>wandb.init()</code>. The <code>wandb.init()</code> function retrieves the sweep parameters from the WandB servers using the sweep ID, and uses them to configure the run. Once you have called <code>wandb.init()</code>, you can access the sweep parameters using the <code>config</code> object.</p>\n<p>Instead of specifying a name in wandb init, rename the run immediately after initializing the run.<br>\nExample:</p>\n<pre><code class=\"lang-auto\">run =  wandb.init(config=config)\nrun.name=f\"{wandb.config.lr}_{wandb.config.batch_size}\"\n</code></pre>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-04-19T20:41:06.576Z",
				"Answer_body": "<p>Hi, <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a><br>\nthanks very much for your advice! It works in my case <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Multivariate Time Series Data",
		"Question_link": "https://community.wandb.ai/t/multivariate-time-series-data/4086",
		"Question_created_time": "2023-03-21T10:50:41.798Z",
		"Question_answer_count": 5,
		"Question_score_count": 1,
		"Question_view_count": 135,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\nI am trying to use W&amp;B in order to run experiments with satellite time series data. As we are working on a relatively large scale, we do not work with entire images, but rather one representative pixel for each ROI. This way we end up with a dataset consisting of <code>num_samples</code> amount of data points for <code>t</code> timesteps and each with <code>num_bands</code> channels.<br>\n<strong>One sample</strong> might look like that:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/6/6fe94f2cac394129b6bc000fc8bf10d1eed512de.png\" data-download-href=\"/uploads/short-url/fY0RrFz6ZlHyaa6uxnty06uvzWu.png?dl=1\" title=\"MTS\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/6/6fe94f2cac394129b6bc000fc8bf10d1eed512de_2_690x369.png\" alt=\"MTS\" data-base62-sha1=\"fY0RrFz6ZlHyaa6uxnty06uvzWu\" width=\"690\" height=\"369\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/6/6fe94f2cac394129b6bc000fc8bf10d1eed512de_2_690x369.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/6/6fe94f2cac394129b6bc000fc8bf10d1eed512de.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/6/6fe94f2cac394129b6bc000fc8bf10d1eed512de.png 2x\" data-dominant-color=\"E9EAE4\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">MTS</span><span class=\"informations\">897\u00d7480 184 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nThe 13 individual lines are the reflectance values for each spectral band over the course of a year for a single sample.</p>\n<p>My question is the following:<br>\nIs there a wandb type that produces such representation as an entry in a table? I personally think that handling it as a plot is a bit of an overkill but on the other hand it seems like time series data can only be stored when it is univariate.</p>\n<p>Thank you in advance!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-21T12:35:35.663Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/maja601\">@maja601</a> thanks for writing in! It seems you\u2019re looking for the <code>wandb.Table</code> data type, and you could directly log a Pandas dataframe directly as in <a href=\"https://docs.wandb.ai/ref/python/data-types/table\">this example</a>. Then you will be able to use <code>Weave</code> to plot your multivariate time series. Please also check <a href=\"https://wandb.ai/stacey/sidereal/reports/Time-Series-Forecasting-in-W-B--VmlldzoyNzczMzcy\">this Report</a> from Stacey to explore available options with time series data. Would this work for you? Feel free to ask us any further questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-21T13:05:15.332Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a> thank you so much for your quick reply!</p>\n<p>Just to clarify, each data point has in total 13 \u2018sub\u2019-time series which makes my data 3D. As far as I understood, <code>wandb.Table</code> allows you to store a 2D array (e.g. rows are <code>sample_id</code> and cols are <code>timesteps</code>), but then the third dimension becomes an awkward array of numbers. Same when treating it like a dataframe; each cell would have to hold an entire array with 13 values, e.g. like that:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/f/f664cd107caf840bd9ff5c03ac175dfe2dc47f37.png\" data-download-href=\"/uploads/short-url/z9HqdOaWE2zkAyDuZQwwRtlkJSv.png?dl=1\" title=\"Screenshot 2023-03-21 at 13.56.08\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/f/f664cd107caf840bd9ff5c03ac175dfe2dc47f37_2_690x36.png\" alt=\"Screenshot 2023-03-21 at 13.56.08\" data-base62-sha1=\"z9HqdOaWE2zkAyDuZQwwRtlkJSv\" width=\"690\" height=\"36\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/f/f664cd107caf840bd9ff5c03ac175dfe2dc47f37_2_690x36.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/f/f664cd107caf840bd9ff5c03ac175dfe2dc47f37_2_1035x54.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/f/f664cd107caf840bd9ff5c03ac175dfe2dc47f37_2_1380x72.png 2x\" data-dominant-color=\"323A4A\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2023-03-21 at 13.56.08</span><span class=\"informations\">2294\u00d7122 14.5 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>What I would like to have instead is a 2D data type that can go inside a table cell (a bit like a nested table), in such a way that the entire dataset looks like that<br>\n<a href=\"https://i.imgur.com/TrvS9VE.png\" rel=\"noopener nofollow ugc\">https://i.imgur.com/TrvS9VE.png</a><br>\nbut instead of the image, the multidimensional time series as seen in my original question is visualised or a 2D table holding <code>timesteps</code> as cols and <code>bands</code> as rows is shown.</p>\n<p>If this is possible with the examples you\u2019ve shown me, please let me know. I am relatively new to W&amp;B and I am not sure if I understood that all correctly.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-11T19:00:04.397Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/maja601\">@maja601</a> thanks a lot for the clarification, I see what you\u2019re trying to achieve. You could combine the <code>wandb.Table</code> where each row is a Plotly chart, would this work for you? or you could have the <code>num_samples</code> as a slider, let me know if you would prefer that. Please see below for an example:</p>\n<pre><code class=\"lang-auto\">import wandb\nimport random\nimport pandas as pd\nimport plotly.express as px\n\nnum_samples = 5  # number of dataframes to create\nt = 1000  # number of rows in each dataframe\nnum_bands = 12  # number of columns in each dataframe\n\n# Initialize a new run\nrun = wandb.init(project=\"log-table-3d\")\n\n# Create a table\ntable = wandb.Table(columns = [\"plotly_figure\"])\n\nfor i in range(num_samples):\n    # create dummy dataframe\n  df = pd.DataFrame(\n      data=[[random.random() for _ in range(num_bands)] for _ in range(t)],\n      columns=[f\"Band {j}\" for j in range(1, num_bands+1)]\n  )\n  #print(f\"Sample {i+1}:\\n{df}\\n\")  # print the dataframe for this sample\n\n  # Create path for Plotly figure\n  path_to_plotly_html = \"./plotly_figure.html\"\n\n  # Example Plotly figure\n  fig = px.line(data_frame = df)\n\n  # Write Plotly figure to HTML\n  fig.write_html(path_to_plotly_html, auto_play = False) # Setting auto_play to False prevents animated Plotly charts from playing in the table automatically\n\n  # Add Plotly figure as HTML file into Table\n  table.add_data(wandb.Html(path_to_plotly_html))\n\n# Log Table\nrun.log({\"table\": table}, step=i)\n\nrun.finish()\n</code></pre>\n<p>Is this something you would be interested at, or would you like us to proceed with a feature request to support nested tables?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-13T11:22:46.616Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a> thank you for the proposed workaround! I am just wondering, whether that solution does create a bit too much overhead? In the domain of Earth Observation (EO), the type of data I showed you is fairly common and the amount of samples (rows) goes into the millions. Of course, we would not have to visualise all of them, but creating a Plotly chart for each sample seems a bit much.<br>\nIn case W&amp;B aims to support EO datasets, I would suggest the feature request route as a lot of scientists might benefit from it.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-19T12:38:26.652Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/maja601\">@maja601</a> thanks so much for the detailed explanation of your use case. I agree for that order of data, it would make the Workspace very slow to render all these plots. Therefore, I have proceeded with a feature request and linked it to that thread here, so that we can share with you any updates. Thank you for this very useful suggestion.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Why the weights for my model are not logged while I can see the gradients?",
		"Question_link": "https://community.wandb.ai/t/why-the-weights-for-my-model-are-not-logged-while-i-can-see-the-gradients/4174",
		"Question_created_time": "2023-04-03T14:39:46.143Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 119,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I would like to track the weights and gradients for my model while it trains. I have three networks that are being trained jointly. I am calling \u2018wandb.watch\u2019 for each one of them individually. This allowed me to see the gradients, but for some reason, I can\u2019t see the weights for one of these networks in the \u2018parameters\u2019 tab.</p>\n<p>I would appreciate if anyone could help me to figure out what is the issue and how I can fix it.</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-06T22:43:09.052Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ahof1704\">@ahof1704</a>,</p>\n<p>Have you set the <code>log='all'</code> parameter for <code>wandb.watch</code>?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-07T12:28:28.464Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a> ,</p>\n<p>Maybe I should provide more details about my model. It consists of 3 neural networks (NN):</p>\n<pre><code class=\"lang-auto\">Encoder = NN1()\nDecoder = NN2()\nmodel = NN3()\n</code></pre>\n<p>For training, I make a list of all the parameters and pass that to the optimizer as follows</p>\n<pre><code class=\"lang-auto\">All_parameters = list(model.parameters())+list(Encoder.parameters())+list(Decoder.parameters())\noptimizer = torch.optim.Adam(All_parameters, lr=args.lr, weight_decay=args.weight_decay)\n</code></pre>\n<p>Since <code>wand.watch</code> takes just one network at a time, I call that command three times in my code:</p>\n<pre><code class=\"lang-auto\">wandb.watch(Encoder, log=\"all\",log_freq=1)\nwandb.watch(Decoder, log=\"all\",log_freq=1)\nwandb.watch(model, log=\"all\",log_freq=1)\n</code></pre>\n<p>This allows me to see the gradients for all three networks, but not the weights. Only the weights for Encoder and Decoder are listed on the Parameters tab.</p>\n<p>I hope this clarifies the problem I am having.</p>\n<p>Thank you for helping!<br>\nAntonio</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-10T21:23:10.173Z",
				"Answer_body": "<p>I see. Could you share a link to a project workspace where you see this? I\u2019ll look into this for you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-11T12:37:57.000Z",
				"Answer_body": "<p>Yes, here it is: <a href=\"https://wandb.ai/ahof1704/ANIE/runs/n3qqff5n?workspace=user-ahof1704\">https://wandb.ai/ahof1704/ANIE/runs/n3qqff5n?workspace=user-ahof1704</a><br>\nPlease let me know if you need any further information.</p>\n<p>Thanks!!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-18T23:15:21.308Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/ahof1704\">@ahof1704</a></p>\n<p>Let me know if my understanding of your pipeline incorrect, but is there a reason you are not setting your model up as <code>full_model = nn.Sequential([Encoder, model, Decoder])</code>? You should be able to watch over your whole model as <code>wandb.watch(full_model)</code>.</p>\n<p><code>wandb.watch</code> usually hooks into a PyTorch model - my suspiscion here is that watch is only keeping track of the last model that is being \u201cwatched\u201d - since I do see a set of parameters being tracked.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-24T16:02:44.267Z",
				"Answer_body": "<p>Hi Antonio,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-26T19:18:52.733Z",
				"Answer_body": "<p>Hi Antonio, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to create wandb.Table with image previews for a big dataset with most efficiency?",
		"Question_link": "https://community.wandb.ai/t/how-to-create-wandb-table-with-image-previews-for-a-big-dataset-with-most-efficiency/3855",
		"Question_created_time": "2023-02-09T10:26:56.479Z",
		"Question_answer_count": 6,
		"Question_score_count": 2,
		"Question_view_count": 207,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have a dataset that has ~40k images. I want to upload them all using arifacts, i used run.add_dir(\u201cpath_to_dir_with_images\u201d).<br>\nI also have a csv that contains the labels of these images as well as the name of the image. Is there a way to create a wandb.Table so that i can explore this csv but also to have a column called images that has a reference to the images from the artifact via the file name. So that when i do EDA i can look at the images that are in the artifact instead of adding a column \u201cimages\u201d to the csv and populating it with wandb.Image objects and then uploading it as a wandb.Table?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-13T21:56:08.990Z",
				"Answer_body": "<p>Hey Milos,</p>\n<p>Thank you for bringing that up! I will be looking into it internally and let you know as soon as possible.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-17T20:09:33.097Z",
				"Answer_body": "<p>Hey Milos,</p>\n<p>Thank you very much for your patience!<br>\nYes, there is a way you can create a <strong>wandb.Table</strong> that references images in your artifact via their file names.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-23T21:26:36.067Z",
				"Answer_body": "<p>Hello Milos,</p>\n<p>Is everything alright with your query? Have you tried it?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-07T11:19:29.542Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/bill-morrisson\">@bill-morrisson</a> . I am interested as well. Could you provide a reference about how to do so?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-13T14:15:38.227Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/bill-morrisson\">@bill-morrisson</a> . Same here, I\u2019m very interested in how to do this, as, in my case, the full table including wandb.Image objects does not fit in memory.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-18T20:29:57.038Z",
				"Answer_body": "<p>Still no updates? Am also interested in this</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "NotFoundError() in Sweep after 1 epoch",
		"Question_link": "https://community.wandb.ai/t/notfounderror-in-sweep-after-1-epoch/4205",
		"Question_created_time": "2023-04-11T12:11:45.373Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 71,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey there,<br>\nI am currently trying to run a sweep for my model. Every time, after the first epoch has finished training, I get the following output:</p>\n<pre><code class=\"lang-auto\">wandb: Waiting for W&amp;B process to finish... (failed 1). Press Control-C to abort syncing.\nwandb: Synced rich-sweep-1: https://wandb.ai/prosit-compms/intensity_normalization_optimization/runs/axdt1t4l\nwandb: Synced 6 W&amp;B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)\nwandb: Find logs at: ./wandb/run-20230411_132216-axdt1t4l/logs\nRun axdt1t4l errored: NotFoundError()\nwandb: ERROR Run axdt1t4l errored: NotFoundError()\n</code></pre>\n<p>Soon after this, a new Agent starts and the same error appears after 1 epoch.<br>\nDoes anyone have an idea what might be causing this error.</p>\n<p>The Sweep and the run is visible in the wandb UI.</p>\n<p>It would be a great help to me if anyone has a suggestion on how to resolve this issue.</p>\n<p>Using wandb version: 0.14.2<br>\npython version: 3.9.15</p>\n<p>The Debug file: <a href=\"https://drive.google.com/file/d/1_7ZYlrGKnMBrIgcoO6eO68r4O6PE_gMu/view?usp=sharing\" rel=\"noopener nofollow ugc\">debug.log</a><br>\nThe internal debug file: <a href=\"https://drive.google.com/file/d/1gSzLi-ytrlh7if9Ov86FcGczhlzEtIWI/view?usp=sharing\" rel=\"noopener nofollow ugc\">debug-internal.log</a><br>\nThank you!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-12T11:56:48.688Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/finnkap\">@finnkap</a> sorry to hear you\u2019re experiencing this issue. The run seems to have been deleted since you reported the issue, may I please ask if you had interrupted the process by pressing Ctr+C? Could you run the agent again from the CLI as follows: <code>wandb agent entity/project/sweep-id</code> or from the Python SDK with<code> wandb.agent()</code> call and let us know if the problem persists for you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-13T09:50:21.015Z",
				"Answer_body": "<p>Hey, thanks for the reply. I restarted the agent from the Python SDK and the problem unfortunately perists. Each time I start an agent, wandb starts the number of specified runs. and each run is only one epoch before it throws the error. I did not interrupt the process by ctr+C.</p>\n<p>Here are the debug files for one run of the sweep: prosit-compms/intensity_normalization_optimization/bljppe0j</p>\n<p><a href=\"https://drive.google.com/file/d/1Xmxh0OKCAoDaik_s4zGinojm-yJCxDB4/view?usp=sharing\" rel=\"noopener nofollow ugc\">debug.log</a><br>\n<a href=\"https://drive.google.com/file/d/1fKD24iuAAPISPoVRCtL2eA2y-_4L46_f/view?usp=sharing\" rel=\"noopener nofollow ugc\">debug-internal.log</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-13T13:14:59.482Z",
				"Answer_body": "<p>Hello there,</p>\n<p>the issue has been resolved, it was not an error of wandb but because a folder in the directory was missing.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-18T19:25:00.550Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/finnkap\">@finnkap</a> that\u2019s great to hear you got this resolved, thanks for letting us know. I will close this ticket for now, and please feel free to reach out to us again if you have any other questions or issues.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "WARNING .wandb file is incomplete (invalid padding)",
		"Question_link": "https://community.wandb.ai/t/warning-wandb-file-is-incomplete-invalid-padding/4153",
		"Question_created_time": "2023-03-30T12:37:06.946Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 80,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hello all!</p>\n<p>I am running a lot of runs per day (~2K sometimes) and have been encountering some strange errors in a handful of my runs. I am doing this on a large computation cluster, so to avoid putting too much strain on the network for every run I</p>\n<ol>\n<li>set wandb to run offline (<code>export WANDB_MODE=\"offline\"</code>)</li>\n<li>set the <code>WANDB_DIR</code> to be a tmp directory (<code>WANDB_DIR=$(mktemp -d)</code>)</li>\n<li>Run my run as normal (runs are relatively short often taking ~2-20 minutes)</li>\n<li>Sync my wandb runs (<code>wandb sync $WANDB_DIR/wandb/offline*</code>)</li>\n<li>Clean up my tmpdir (<code>rm -rf $WANDB_DIR </code>)</li>\n</ol>\n<p>The full script is below:</p>\n<pre><code class=\"lang-auto\">my_config= # some config unique to this run\nexport WANDB_MODE=\"offline\"\nexport WANDB_DIR=$(mktemp -d)\npython train.py --config $my_config \nwandb sync $WANDB_DIR/wandb/offline*\nrm -rf $WANDB_DIR \n\n</code></pre>\n<p>In 99% of runs this works totally fine, however in a handful I get messages like:</p>\n<pre><code class=\"lang-auto\">Syncing: https://wandb.ai/some_run ... wandb: WARNING .wandb file is incomplete (invalid padding), be sure to sync this run again once it's finished\ndone.\n</code></pre>\n<p>If I actually <em>look</em> at <code>some_run</code>, it seems totally normal and I don\u2019t see any missing data. Furthermore the <code>wandb sync</code> command returns 0 exit code so I would assume all is well despite the error message. But the existence of the error is concerning and I am not sure the best way to deal with it or if it needs to be delt with at all. I am grateful for any advice people have!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-06T20:31:11.550Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/evanv\">@evanv</a> , that warning is safe to ignore, the run will eventually sync. For the runs that throw this warning, are you seeing there are discrepancies in the data logged to the workspace?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-07T22:31:49.320Z",
				"Answer_body": "<p>Hi there <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> ! Nothing appears to be wrong wtih the runs. Out of curiosity, why is the wanring thrown?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-17T20:01:28.163Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/evanv\">@evanv</a> , apologies for the delay.</p>\n<p>The <code>invalid padding</code> error occurs when  wandb tries to read data from your run file, but the file may not be  in an expected format. This could happen for a variety of reasons including file corruption, or issues when the file is read. When wandb scans your file and finds a discrepency with the format, it raises a warning informing you to  <code>sync this run again once it's finished</code> as precautionary measure. If it successfully synced the first time around, then great, if not try again.</p>",
				"Answer_has_accepted": true
			}
		]
	},
	{
		"Question_title": "Create both sweep and start an agent for it in shell script",
		"Question_link": "https://community.wandb.ai/t/create-both-sweep-and-start-an-agent-for-it-in-shell-script/4091",
		"Question_created_time": "2023-03-21T19:52:16.936Z",
		"Question_answer_count": 5,
		"Question_score_count": 2,
		"Question_view_count": 137,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I want to build a replication package for a paper, where we are using W&amp;B to generate and store our results.</p>\n<p>Ideally I would just give people a bash or powershell script which creates the sweeps and creates an agent to run a sweep.  In all cases it is sufficient to run a single agent on a single computer.</p>\n<p>My ideal script would look something like</p>\n<pre><code class=\"lang-bash\">wandb sweep --name MyExperiment1 sweep_1.yaml\nwandb agent  XXXXXXXX\nwandb sweep --name MyExperiment2 sweep_2.yaml\nwandb agent  YYYYYYYYY\n</code></pre>\n<p>etc.   In all cases the <code>yaml</code> would be a grid with a finite number of iterations before finishing.  I guess I could also do things like <code>wandb agent XXXXXXX &amp;</code> to have a child process.</p>\n<p>But I am not sure how I get the sweepid returned from the wandb sweep to call <code>wandb agent</code>?  Are there any tricks?  I guess I can also use the python calls to create a sweep and an agent directly, but in that case I am not sure how to tell it to use a <code>yaml</code> file?</p>\n<p>Alternatively, is this the sort of thing that a job queue is best used for?  If so, any templates on how to handle that?  I guess my shell script would just create all of the jobs for a queue and then a single agent would run it?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-22T12:55:27.622Z",
				"Answer_body": "<p>In the python script you can load your yml file into a dictionary and use that as the sweep config.<br>\nI think you would only have to ignore the \u201cprogram\u201d key.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-05T17:01:54.595Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/jlperla\">@jlperla</a> does the solution of using Python work for you? Here is our <a href=\"https://docs.wandb.ai/guides/sweeps/define-sweep-configuration\">documentation</a> on how to define a sweep in Python.  If you were to try to programmatically start a sweep via CLI you would probably have to parse <code>stdout</code> from the <code>wandb sweep</code> command to get the sweep id.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-05T18:43:01.079Z",
				"Answer_body": "<p>Thanks <a class=\"mention\" href=\"/u/nathank\">@nathank</a>    I decided to hack on the commandline. ChatGPT and a response from W&amp;B led me to the following code, which works on windows git bash and refers to a subfolder called <code>replication_scripts</code> where I keep my sweeps.</p>\n<pre><code class=\"lang-bash\">PROJECT_NAME=\"my_project\" # swap out globally\n\nrun_sweep_and_agent () {\n  # Set the SWEEP_NAME variable\n  SWEEP_NAME=\"$1\"\n  \n  # Run the wandb sweep command and store the output in a temporary file\n  wandb sweep --project \"$PROJECT_NAME\" --name \"$SWEEP_NAME\" \"replication_scripts/$SWEEP_NAME.yaml\" &gt;temp_output.txt 2&gt;&amp;1\n  \n  # Extract the sweep ID using awk\n  SWEEP_ID=$(awk '/wandb agent/{ match($0, /wandb agent (.+)/, arr); print arr[1]; }' temp_output.txt)\n  \n  # Remove the temporary output file\n  rm temp_output.txt\n  \n  # Run the wandb agent command\n  wandb agent $SWEEP_ID\n}\n\n# list of sweeps to call\nrun_sweep_and_agent \"my_sweep_1\"\nrun_sweep_and_agent \"my_sweep_2\"\n</code></pre>\n<p>I think that simpler regex based setups might replace awk on non-windows platforms, but I would guess this works with minor modifications in other places.</p>\n<p>All of this is to say that a new feature to create a sweep and immediately run it would be nice in the <code>wandb sweep</code> command itself.  I added a github issue proposing that.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-14T15:01:27.328Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/jlperla\">@jlperla</a>, glad you were able to make this work! Yes, I can make a feature request for this. Something like a <code>--start-agent</code> flag you can pass to <code>wandb sweep</code> seems like a good solution. I\u2019ll pass this onto the engineering team and follow up once they have a chance to look into this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-14T15:11:07.106Z",
				"Answer_body": "<p>Ah, I see the feature request you made and it looks like Raphael has already captured it. We will follow up on the Github thread once the team has had a chance to work on this.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Logging Datasets other than files (for example: tensorflow_dataset object)",
		"Question_link": "https://community.wandb.ai/t/logging-datasets-other-than-files-for-example-tensorflow-dataset-object/4148",
		"Question_created_time": "2023-03-29T15:49:56.196Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 72,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>I see many examples in the documentation for logging actual files as datasets/artifacts, but how do I log datasets that aren\u2019t files? For example, I am using tensorflow_datasets to download my dataset directly into train and validation splits and would like to log these directly. Is there an easy way to do this or can they only live in a table object?</p>\n<p>Thank you</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-06T21:45:11.186Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/stevencocke\">@stevencocke</a> <code>wandb.log()</code> function, accepts a variety of data types including NumPy arrays, Python dictionaries, and other data structures. Are you looking to do something <a href=\"https://wandb.ai/mohammadbakir/tf-data-test/runs/dom9k6t3?workspace=user-mohammadbakir\">similar to this</a>?</p>\n<pre><code class=\"lang-auto\">import tensorflow_datasets as tfds\nimport wandb\n\n# Initialize WandB\nwandb.init(project=\"tf-data-test\")\n\n# Load MNIST dataset\nds_train, ds_test = tfds.load('mnist', split=['train[:20]', 'test[:20]'], shuffle_files=True)\n\n# Create a WandB Table\ntable = wandb.Table(columns=[\"image\", \"label\"])\n\n# Log examples to WandB &amp; add data to table\nfor example in ds_train:\n    image = example['image'].numpy()\n    label = example['label'].numpy()\n    wandb.log({\"image\": wandb.Image(image, caption=f\"Label: {label}\")})\n    table.add_data(wandb.Image(image), label)\n\n# Log the table to WandB\nwandb.log({\"mnist\": table})\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-13T18:10:16.973Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/stevencocke\">@stevencocke</a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Use the same parameter but produce different results in Bayesian Sweep",
		"Question_link": "https://community.wandb.ai/t/use-the-same-parameter-but-produce-different-results-in-bayesian-sweep/4186",
		"Question_created_time": "2023-04-05T03:48:10.649Z",
		"Question_answer_count": 8,
		"Question_score_count": 0,
		"Question_view_count": 156,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I was trying to use Sweep for hyperparameter tuning.   And I want to do grid sweep in tuning. Coincidently I happend to use the Bayes Sweep (since last time I use the bayes for tuning). Then something weird happened.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/e/eab8bc4fae8510d8bd8187cc1a1434ecb341a135.png\" data-download-href=\"/uploads/short-url/xurwnzUO5SdxA25PtlOLTx1c0L3.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/eab8bc4fae8510d8bd8187cc1a1434ecb341a135_2_690x132.png\" alt=\"image\" data-base62-sha1=\"xurwnzUO5SdxA25PtlOLTx1c0L3\" width=\"690\" height=\"132\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/eab8bc4fae8510d8bd8187cc1a1434ecb341a135_2_690x132.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/eab8bc4fae8510d8bd8187cc1a1434ecb341a135_2_1035x198.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/eab8bc4fae8510d8bd8187cc1a1434ecb341a135_2_1380x264.png 2x\" data-dominant-color=\"F9F9F9\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1868\u00d7358 27.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nI can understand the Bayes search may choose same combination of hyperparameters, But why the same hyperparameters come into different results? And I check my code, I definitely have set the seed. Is there anything I missed?<br>\nAnd this is the yaml config I use:</p>\n<blockquote></blockquote>\n<p>method: bayes<br>\nproject: classify<br>\nname: roberta-large<br>\nmetric:<br>\ngoal: maximize<br>\nname: best_valid_metric<br>\nparameters:<br>\ntask:<br>\nvalues: [\u201cemotion\u201d]<br>\nbatch_size:<br>\nvalues: [8, 16, 32]<br>\nplm_learning_rate:<br>\nvalues: [1e-5, 2e-5, 3e-5, 4e-5, 5e-5]<br>\nother_learning_rate:<br>\nvalues: [1e-4, 2e-4, 3e-4, 4e-4, 5e-4]<br>\ndropout:<br>\nvalues: [0, 0.3, 0.5]<br>\nmodel_name:<br>\nvalue: 1<br>\nnum_labels:<br>\nvalue: 8<br>\ncommand:</p>\n<ul>\n<li>${env}</li>\n<li>${interpreter}</li>\n<li>${program}</li>\n<li>\u201c\u2013use_wandb\u201d</li>\n<li>${args}</li>\n</ul>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-05T08:29:32.199Z",
				"Answer_body": "<p>Dear Zhuojun,</p>\n<p>would you be able to confirm if you are using wandb server locally or our public cloud offering?</p>\n<p>This is a known bug that has now been fixed in our latest version of wandb serve 0.31.0 which was released yesterday.</p>\n<p>Upgrading to this version should fix the issue that you are experiencing with sweep combinations (repetition) of what should be permutations of parameters.</p>\n<p>Warm regards,</p>\n<p>Frida</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-04-05T13:57:19.427Z",
				"Answer_body": "<p>OK, Thank you. I use the public cloud offering for hyperparameter tuning yesterday. Maybe it was not updated then. But I\u2019m still curious that why the same parameter choices come into different result in bayes sweep <img src=\"https://emoji.discourse-cdn.com/twitter/joy.png?v=12\" title=\":joy:\" class=\"emoji\" alt=\":joy:\" loading=\"lazy\" width=\"20\" height=\"20\"><br>\nWhat\u2019s important is that I can\u2019t reproduce the best result  in the pic I have shown:smiling_face_with_tear: Althrough the several training results keep consistent on my machine when I try to find out whether there were faults in my code.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-08T07:34:36.710Z",
				"Answer_body": "<p>Well, finally find the problem. I used the LSTM in my code. And there are some \u201cnon-determinism issues for RNN functions on some versions of cuDNN and CUDA.\u201d<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/f/ff22c764ecbd91a33021b0283d279feb1ed596a0.png\" data-download-href=\"/uploads/short-url/Ap2gDEiftw0A3xyRCDtslnF4pCU.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/f/ff22c764ecbd91a33021b0283d279feb1ed596a0_2_690x242.png\" alt=\"image\" data-base62-sha1=\"Ap2gDEiftw0A3xyRCDtslnF4pCU\" width=\"690\" height=\"242\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/f/ff22c764ecbd91a33021b0283d279feb1ed596a0_2_690x242.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/f/ff22c764ecbd91a33021b0283d279feb1ed596a0_2_1035x363.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/f/ff22c764ecbd91a33021b0283d279feb1ed596a0_2_1380x484.png 2x\" data-dominant-color=\"EBDEDF\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1562\u00d7548 47.7 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-12T19:02:19.264Z",
				"Answer_body": "<p>Dear Zhuojun,</p>\n<p>Thanks for sharing your insights on Cuda\u2019s non-deterministic behavior, I was not aware of this myself. I also wanted to follow up on your question about Bayesian sweeps and advice that we currently don\u2019t offer a method to select using a random state and as such there will be variability in for example maximizing a particular metric.</p>\n<p>I will add ensure that your use case is added to a feature request for this.</p>\n<p>Please let us know if there is anything else that you would like assistance with at this time.</p>\n<p>Best,</p>\n<p>Frida</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-13T11:58:21.500Z",
				"Answer_body": "<p>Hi Frida, is there any work around to prevent this in the public cloud version? I\u2019m having agents repeat parameter combinations 5 + times after only 3-5 completed runs. This is in a search space of only 120 combinations so using bayes is currently seeming to be more pain than it\u2019s worth.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-18T14:47:34.374Z",
				"Answer_body": "<p>Hi Hubert,</p>\n<p>Thank you for messaging and sorry that you\u2019re not getting the behavior that you are anticipating.  I wonder if you would be able to share the config that you are using so I can spin it up on my side?</p>\n<p>I think it is technically possible for Bayesian sweep to arrive at repeat parameters if the best set of parameters is quickly reached, and would be super curious/grateful if you\u2019d be able to advise if the parameters that you are seeing do reflect the most accurate models.</p>\n<p>Best,</p>\n<p>Frida</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-20T09:50:05.650Z",
				"Answer_body": "<p>Hi Hubert,</p>\n<p>Wanted to check in \u2013 I see that on the original thread, this was marked as solved \u2013 I can look into this further if this is helpful but would be great if you\u2019d be able to share the config that you are using either .yaml or python dictionary format.</p>\n<p>Look forward to hearing back from you.</p>\n<p>Frida</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-21T09:33:22.733Z",
				"Answer_body": "<p>Hi Hubert,</p>\n<p>Going to go ahead and close this off for you as we\u2019ve not heard back. Let me know if you need any further help now or in the future.</p>\n<p>Best,</p>\n<p>Frida</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Stable Baslines3: step vs global_step vs tensorboard step",
		"Question_link": "https://community.wandb.ai/t/stable-baslines3-step-vs-global-step-vs-tensorboard-step/4178",
		"Question_created_time": "2023-04-04T07:00:08.048Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 136,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello Community,</p>\n<p>I have a very basic question regarding the stable baseline3 integration.<br>\nI want to plot basic stuff like the average episode reward. However, I am confused by the terms step and global_step. What is the difference between them?<br>\nWhen plotting global_step over step I was expecting a straight line, but it turns out there is no linear relationship between those two values.<br>\nCould someone explain to me the increment-rules of step and global_step?</p>\n<p>Also, when looking at the tensor board plots from within the WandB dashboard, I can see that the number of steps tensor board uses as x-axis differs to both global_step and step used in the wandb plots. Something is very weird.</p>\n<p>Thanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-06T19:25:39.436Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/erikk\">@erikk</a> , happy to help. At a high level the RL trainers maintain track of how many steps have been taken during the training when <strong>batches</strong> are processed during training. During training, the <code>global_step</code> is updated every time a batch is processed. When logging training metrics to wandb, the <code>global_step</code> is used as the x-axis to indicate this. The wandb sdk also has an internal step counter which follows a different rule for increments. Hence, both the trainer global step and wandb step variables are updated at different times due to the update conditions being different.</p>\n<p>In regards to the Tensor Board behavior you are seeing, could you provide me a link to your workspace for review, or screenshots of what you are seeing. This will help me better understand what you are seeing.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-11T22:26:51.366Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/erikk\">@erikk</a> since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Duplicate runs after 500 runs when using local controller",
		"Question_link": "https://community.wandb.ai/t/duplicate-runs-after-500-runs-when-using-local-controller/4105",
		"Question_created_time": "2023-03-23T09:12:45.969Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 95,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I deploy a wandb server in my local server, and use grid search to sweep hyperparameters with 4 parallel agents.</p>\n<p>In my case, the size of the search space exceeds 500, and each run takes about 2 minutes to finish.</p>\n<p>I always find that after 500 runs finish, the generated hyperparameter configurations of the newly started runs from the beginning again. That is, the configuration of the 501st run (or possibly the 502nd run) is the same as that of the first run, the configuration of the 502nd run (or possibly the 503rd run) is the same as that of the second run, and so on.</p>\n<p>I also check the log of the local controller, and the number of runs keeps to be 500 as follows:<br>\n\u2026<br>\nSweep: t3muh8oq (grid) | Runs: 470 (Running: 2, Finished: 468)<br>\nSweep: t3muh8oq (grid) | Runs: 471 (Running: 3, Finished: 468)<br>\nSweep: t3muh8oq (grid) | Runs: 472 (Running: 4, Finished: 468)<br>\nSweep: t3muh8oq (grid) | Runs: 472 (Running: 3, Finished: 469)<br>\nSweep: t3muh8oq (grid) | Runs: 473 (Running: 4, Finished: 469)<br>\nSweep: t3muh8oq (grid) | Runs: 473 (Running: 3, Finished: 470)<br>\nSweep: t3muh8oq (grid) | Runs: 474 (Running: 4, Finished: 470)<br>\nSweep: t3muh8oq (grid) | Runs: 474 (Running: 3, Finished: 471)<br>\nSweep: t3muh8oq (grid) | Runs: 475 (Running: 3, Finished: 472)<br>\nSweep: t3muh8oq (grid) | Runs: 476 (Running: 4, Finished: 472)<br>\nSweep: t3muh8oq (grid) | Runs: 476 (Running: 2, Finished: 474)<br>\nSweep: t3muh8oq (grid) | Runs: 477 (Running: 3, Finished: 474)<br>\nSweep: t3muh8oq (grid) | Runs: 478 (Running: 4, Finished: 474)<br>\nSweep: t3muh8oq (grid) | Runs: 478 (Running: 3, Finished: 475)<br>\nSweep: t3muh8oq (grid) | Runs: 478 (Running: 2, Finished: 476)<br>\nSweep: t3muh8oq (grid) | Runs: 479 (Running: 3, Finished: 476)<br>\nSweep: t3muh8oq (grid) | Runs: 480 (Running: 4, Finished: 476)<br>\nSweep: t3muh8oq (grid) | Runs: 480 (Running: 3, Finished: 477)<br>\nSweep: t3muh8oq (grid) | Runs: 481 (Running: 3, Finished: 478)<br>\nSweep: t3muh8oq (grid) | Runs: 482 (Running: 4, Finished: 478)<br>\nSweep: t3muh8oq (grid) | Runs: 482 (Running: 3, Finished: 479)<br>\nSweep: t3muh8oq (grid) | Runs: 483 (Running: 4, Finished: 479)<br>\nSweep: t3muh8oq (grid) | Runs: 483 (Running: 3, Finished: 480)<br>\nSweep: t3muh8oq (grid) | Runs: 484 (Running: 4, Finished: 480)<br>\nSweep: t3muh8oq (grid) | Runs: 484 (Running: 2, Finished: 482)<br>\nSweep: t3muh8oq (grid) | Runs: 485 (Running: 3, Finished: 482)<br>\nSweep: t3muh8oq (grid) | Runs: 486 (Running: 3, Finished: 483)<br>\nSweep: t3muh8oq (grid) | Runs: 487 (Running: 3, Finished: 484)<br>\nSweep: t3muh8oq (grid) | Runs: 488 (Running: 4, Finished: 484)<br>\nSweep: t3muh8oq (grid) | Runs: 488 (Running: 3, Finished: 485)<br>\nSweep: t3muh8oq (grid) | Runs: 489 (Running: 3, Finished: 486)<br>\nSweep: t3muh8oq (grid) | Runs: 490 (Running: 4, Finished: 486)<br>\nSweep: t3muh8oq (grid) | Runs: 490 (Running: 3, Finished: 487)<br>\nSweep: t3muh8oq (grid) | Runs: 491 (Running: 3, Finished: 488)<br>\nSweep: t3muh8oq (grid) | Runs: 492 (Running: 4, Finished: 488)<br>\nSweep: t3muh8oq (grid) | Runs: 492 (Running: 3, Finished: 489)<br>\nSweep: t3muh8oq (grid) | Runs: 493 (Running: 3, Finished: 490)<br>\nSweep: t3muh8oq (grid) | Runs: 494 (Running: 2, Finished: 492)<br>\nSweep: t3muh8oq (grid) | Runs: 495 (Running: 3, Finished: 492)<br>\nSweep: t3muh8oq (grid) | Runs: 496 (Running: 4, Finished: 492)<br>\nSweep: t3muh8oq (grid) | Runs: 496 (Running: 3, Finished: 493)<br>\nSweep: t3muh8oq (grid) | Runs: 497 (Running: 3, Finished: 494)<br>\nSweep: t3muh8oq (grid) | Runs: 498 (Running: 3, Finished: 495)<br>\nSweep: t3muh8oq (grid) | Runs: 499 (Running: 3, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 2, Finished: 498)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 4, Finished: 496)<br>\nSweep: t3muh8oq (grid) | Runs: 500 (Running: 3, Finished: 497)</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-04T13:55:38.772Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lanlin\">@lanlin</a> , apologies for the delay here. We were able to reproduce the issue on our end and confirmed that the upgrade to <a href=\"https://github.com/wandb/server/releases\" rel=\"noopener nofollow ugc\">0.30.0</a> introduced a regression. Would rolling back the upgrade to 0.29.0 be an option for you here? However, this regression was introduced for runs numbered <span class=\"hashtag\">#1</span>, <span class=\"hashtag\">#2</span> and not &gt; 500th.</p>\n<p>Also, you can definitely see it converge to a single value in some cases where the parameter space is small. Could you please share your sweep config so that we can confirm the same?</p>\n<p>Some more context: It tries to balance exploring the parameter space with returning values that maximize expected improvement. It is always trying to attain balance there. In cases where the parameter space is small, it finishes exploring reasonably fast. So, when it finds an extremum it can indeed converge there. Therefore, when we reach optimal, and it is possible that we\u2019ll continue to suggest the same params. This is actually the expected functionality for <code>bayes</code> (only) with categorical parameters. Therefore, it would be really helpful in troubleshooting/reproducing this behavior on our end if you could share your sweep config and the code snippet you\u2019re executing.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-11T13:53:21.210Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lanlin\">@lanlin</a> , I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-11T14:13:04.000Z",
				"Answer_body": "<p>Hi,</p>\n<p>I read the code of wandb local controller, and found that the controller requests the existing runs from the remote server when it needs to generate a new run.</p>\n<p>After debugging, I found that the maximum number of runs that the remote server can return is truncated to 500. Thus, I modified the wandb local controller to maintain a list of the existing runs locally, and now it works normally.</p>\n<p>\u53d1\u81ea\u6211\u7684\u624b\u673a</p>\n<p>\u53d1\u4ef6\u4eba\uff1a Anmol Mann via W&amp;B Community <a href=\"mailto:notifications@wandb.discoursemail.com\">notifications@wandb.discoursemail.com</a><br>\n\u65e5\u671f\uff1a 2023\u5e744\u670811\u65e5\u5468\u4e8c 22:03<br>\n\u6536\u4ef6\u4eba\uff1a <a href=\"mailto:llan.xjtu@foxmail.com\">llan.xjtu@foxmail.com</a><br>\n\u4e3b \u9898\uff1a [W&amp;B Community] [W&amp;B Help] Duplicate runs after 500 runs when using<br>\nlocal controller</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-11T15:07:17.143Z",
				"Answer_body": "<p>Thanks for the update, <a class=\"mention\" href=\"/u/lanlin\">@lanlin</a>! I\u2019m glad that you were able to find the root-cause of this issue.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How do I store a sweep_id in a cli environment variable so that it runs in a wandb agent later?",
		"Question_link": "https://community.wandb.ai/t/how-do-i-store-a-sweep-id-in-a-cli-environment-variable-so-that-it-runs-in-a-wandb-agent-later/4157",
		"Question_created_time": "2023-03-31T05:52:28.958Z",
		"Question_answer_count": 7,
		"Question_score_count": 1,
		"Question_view_count": 173,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>how do I run a wandb sweep in a cli/terminal/bash and store the sweep id in a env variable to use it later in the wandb agent cli command?</p>\n<p>Is this really correct/recommended way?</p>\n<pre><code class=\"lang-auto\">export SWEEP_ID=$(wandb sweep sweep.yaml --project &lt;your-project-name&gt; | awk '/ID:/{print $2}')\nwandb agent --count $N $SWEEP_ID\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-03T19:40:46.246Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/corey-strausman\">@corey-strausman</a> do you know the answer? (sorry for the direct ping)</p>\n<p>It\u2019s really annoying to copy paste the sweep_id directly when using the cli terminal.</p>\n<aside class=\"onebox stackexchange\" data-onebox-src=\"https://stackoverflow.com/questions/75923213/how-do-i-store-a-sweep-id-in-a-cli-environment-variable-so-that-it-runs-in-a-wan\">\n  <header class=\"source\">\n\n      <a href=\"https://stackoverflow.com/questions/75923213/how-do-i-store-a-sweep-id-in-a-cli-environment-variable-so-that-it-runs-in-a-wan\" target=\"_blank\" rel=\"noopener nofollow ugc\">stackoverflow.com</a>\n  </header>\n\n  <article class=\"onebox-body\">\n      <a href=\"https://stackoverflow.com/users/1601580/charlie-parker\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n    <img alt=\"Charlie Parker\" src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/b/bb2f9cef778caf270587e88c958db69ee60fb45e.png\" class=\"thumbnail onebox-avatar\" width=\"256\" height=\"256\">\n  </a>\n\n<h4>\n  <a href=\"https://stackoverflow.com/questions/75923213/how-do-i-store-a-sweep-id-in-a-cli-environment-variable-so-that-it-runs-in-a-wan\" target=\"_blank\" rel=\"noopener nofollow ugc\">How do I store a sweep_id in a cli environment variable so that it runs in a wandb agent later?</a>\n</h4>\n\n<div class=\"tags\">\n  <strong>wandb</strong>\n</div>\n\n<div class=\"date\">\n  asked by\n  \n  <a href=\"https://stackoverflow.com/users/1601580/charlie-parker\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n    Charlie Parker\n  </a>\n  on <a href=\"https://stackoverflow.com/questions/75923213/how-do-i-store-a-sweep-id-in-a-cli-environment-variable-so-that-it-runs-in-a-wan\" target=\"_blank\" rel=\"noopener nofollow ugc\">07:41PM - 03 Apr 23 UTC</a>\n</div>\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-03T20:36:00.862Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/brando\">@brando</a></p>\n<p>To store a sweep_id in a CLI environment variable and run it with wandb agent later, follow these steps:</p>\n<ol>\n<li>Initialize the sweep using the wandb sweep command and provide the name of the YAML file. Optionally, provide the name of the project for the project flag (\u2013project):</li>\n</ol>\n<pre><code class=\"lang-auto\">bash\nwandb sweep --project your_project_name config.yaml\n</code></pre>\n<p>This command will return a sweep ID.</p>\n<ol start=\"2\">\n<li>Store the sweep ID in an environment variable:</li>\n</ol>\n<pre><code class=\"lang-auto\">bash\nexport SWEEP_ID=your_sweep_id\n</code></pre>\n<p>Replace <code>your_sweep_id</code> with the actual sweep ID you got from the previous step.</p>\n<p>3.Start the sweep agent using the stored environment variable:</p>\n<pre><code class=\"lang-auto\">bash\nwandb agent --count $NUM your-entity/your_project_name/$SWEEP_ID\n</code></pre>\n<p>Replace <code>your-entity</code> and <code>your_project_name</code> with the appropriate values, and <code>$NUM</code> with the maximum number of runs the sweep agent should try.</p>\n<p>Here are some docs to reference:</p>\n<ul>\n<li><a href=\"https://docs.wandb.ai/guides/sweeps/add-w-and-b-to-your-code\">Add W&amp;B to your code</a></li>\n<li><a href=\"https://docs.wandb.ai/guides/track/environment-variables\">Environment Variables</a></li>\n<li><a href=\"https://docs.wandb.ai/guides/sweeps/faq\">Sweeps FAQ</a></li>\n<li><a href=\"https://docs.wandb.ai/guides/sweeps/quickstart\">Sweeps Quickstart</a></li>\n</ul>\n<p>I hope this helps!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-04T09:05:45.018Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"brando\" data-post=\"1\" data-topic=\"4157\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://sea2.discourse-cdn.com/business7/user_avatar/community.wandb.ai/brando/40/199_2.png\" class=\"avatar\"> brando:</div>\n<blockquote>\n<pre><code class=\"lang-auto\">export SWEEP_ID=$(wandb sweep sweep.yaml --project &lt;your-project-name&gt; | awk '/ID:/{print $2}')\n</code></pre>\n</blockquote>\n</aside>\n<p>I see what you\u2019re trying to do. You want to run a sweep after creating it within a bash script. There\u2019s no way currently to have <em>just</em> the ID as the output and use it for this purpose so your <code>awk</code> solution should suffice for now, but I agree it\u2019s not very elegant and I\u2019ll forward this feedback to the relevant team.</p>\n<p>You can use the Python <code>sweeps</code> API to do this better programmatically, as the Sweep ID is returned as a variable in python when you call <code>wandb.sweep</code>. But this may not suit you for your workflow.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-06T19:37:00.543Z",
				"Answer_body": "<p>Thanks <a class=\"mention\" href=\"/u/corey-strausman\">@corey-strausman</a> and <a class=\"mention\" href=\"/u/_scott\">@_scott</a> for the answers!</p>\n<p><a class=\"mention\" href=\"/u/brando\">@brando</a> Was your question answered or is there something else that you are having issues with?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-06T23:05:06.656Z",
				"Answer_body": "<p>sorry I\u2019m puzzled, can it not be done?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-11T10:11:59.272Z",
				"Answer_body": "<p>Sorry for the confusion. It can be done programmatically in Python, but not in bash. Your way of getting the ID from the logs is an admittedly inelegant workaround in bash. I\u2019ve passed this feedback to the team, and requested some way to get the ID of the sweep so you can assign it to a variable in bash.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-17T18:05:01.303Z",
				"Answer_body": "<p>Hello Brando! Did that answer your question or do you have any other concerns?</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "I'm facing assert isinstance( AssertionError: Insufficient permissions to fetch Artifact)",
		"Question_link": "https://community.wandb.ai/t/im-facing-assert-isinstance-assertionerror-insufficient-permissions-to-fetch-artifact/3998",
		"Question_created_time": "2023-03-04T01:38:50.066Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 81,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I dont have much interest on the artifacts and I\u2019m just trying to run  my training and log my results on the webapi and it throws me an error :     assert isinstance(<br>\nAssertionError: Insufficient permissions to fetch Artifact with id QXXX.XXXX4 . This works perfectly fine on my other machine. Please let me know if any one knows what exactly is happening here.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-08T19:15:25.528Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/qutub\">@qutub</a> , for the machine that your call isn\u2019t working from, could you <code>wandb login --relogin</code>to update the netrc file with credentials and try again.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-15T02:41:02.569Z",
				"Answer_body": "<p>hI <a class=\"mention\" href=\"/u/qutub\">@qutub</a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-10T22:03:52.089Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a>  Thank you for your reply. Unfortunately, I missed the notifications from this page. I would request you reopen this request if possible. So even after logging the issue still persists. Plus, I don\u2019t see any issue with the netrc file because I tried the same netrc file on another machine and it works.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How do I have two different run files to log to the same sweep?",
		"Question_link": "https://community.wandb.ai/t/how-do-i-have-two-different-run-files-to-log-to-the-same-sweep/4150",
		"Question_created_time": "2023-03-29T17:18:55.191Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 88,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I noticed that the config file can have the program to run. I want all my runs for two different methods (and therefore use two different files and want to avoid refactoring). Can\u2019t the agent take the file path? (I know it can\u2019t) Or some alternative?</p>\n<pre><code class=\"lang-auto\">export SWEEPID=$(wandb sweep config.yaml)\nNUM=10\nwandb agent train_sl.py --count $NUM $SWEEPID\nwandb agent train_maml.py --count $NUM $SWEEPID\n</code></pre>\n<p>cross: <a href=\"https://stackoverflow.com/questions/75880299/0-vote-how-do-i-have-two-different-run-files-to-log-to-the-same-sweep\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">wandb - 0 Vote How do I have two different run files to log to the same sweep? - Stack Overflow</a></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-10T17:56:56.699Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/brando\">@brando</a>, thank you for writing in with your question. When generating a sweep via config file, the sweep controller only considers a single method and program. There isn\u2019t currently a method around this but we are working on expanding more controls over sweeps and flexibility of initializing and calling them. I\u2019ve added you to list of users requsting this and will keep you updated once it\u2019s been implemented. Cheers!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "I faced an error while following the Fine-tune GPT-3 with Weights & Biases",
		"Question_link": "https://community.wandb.ai/t/i-faced-an-error-while-following-the-fine-tune-gpt-3-with-weights-biases/4183",
		"Question_created_time": "2023-04-04T18:25:52.203Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 59,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>While following <a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/openai/Fine_tune_GPT_3_with_Weights_%26_Biases.ipynb#scrollTo=93tQxYhLgkUE\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Google Colab</a>,  the \u201cCreate a fine-tuned model\u201d section created the following error.</p>\n<p>CommError: Project {entity}/GPT-3 does not contain artifact: \u201cwiki-dataset-train:latest\u201d</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-10T16:55:19.746Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nathannam\">@nathannam</a>,</p>\n<p>There is a cell above with the following code:</p>\n<pre><code class=\"lang-auto\"># Create artifacts\nartifact_train = wandb.Artifact('train-wiki_train.jsonl', type='training_files', metadata={'samples': n_train})\nartifact_train.add_file('wiki_train.jsonl')\nartifact_train.add(table_train, 'wiki_train')\n\nartifact_valid = wandb.Artifact('valid-wiki_valid.jsonl', type='validation_files', metadata={'samples': n_valid})\nartifact_valid.add_file('wiki_valid.jsonl')\nartifact_valid.add(table_valid, 'wiki_valid')\n\n# Log files\nrun.log_artifact(artifact_train)\nrun.log_artifact(artifact_valid)\n</code></pre>\n<p>Did you let this cell and the subsequent <code>wandb.finish()</code> call run to completion? It looks like your artifact hadn\u2019t uploaded before being it is attempted to be used.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-13T16:34:59.210Z",
				"Answer_body": "<p>Hi Nathan,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-17T17:51:21.616Z",
				"Answer_body": "<p>Hi Nathan, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Hyperparameter tuning combined with k-fold cross validation",
		"Question_link": "https://community.wandb.ai/t/hyperparameter-tuning-combined-with-k-fold-cross-validation/3881",
		"Question_created_time": "2023-02-14T15:16:52.496Z",
		"Question_answer_count": 13,
		"Question_score_count": 2,
		"Question_view_count": 459,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I found <a href=\"https://github.com/wandb/examples/blob/master/examples/wandb-sweeps/sweeps-cross-validation/train-cross-validation.py\" rel=\"noopener nofollow ugc\">this official example</a> showcasing an implementation of k-fold cross validation using Sweeps. However, I am doing hyperparameter tuning with sweeps so I am coming from a different angle: I want to do k-fold CV for one given set of parametersr for each sweep run. I would imagine that there should be sub-groups for each CV-group in the sweep view of the web interface.</p>\n<p>Is this possible to do with Wandb or should I look elsewhere?</p>\n<p>Thank you!</p>\n<p>EDIT: the rationale behind it is to prevent optimizing hyper parameters to overfit the test set. If you have another means to reach this goal, I am open for it.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-16T20:17:45.648Z",
				"Answer_body": "<p>Hey,</p>\n<p>Thank you for contacting us! Yes, it is possible to perform k-fold cross-validation for a given set of hyperparameters with Wandb Sweeps. In fact, the example you found is a good starting point for implementing k-fold cross-validation in your own Sweep runs.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-20T16:52:27.006Z",
				"Answer_body": "<p>Thank you for your reply. Maybe I misunderstood, but as I understand it, the example that I found does not perform hyperparameter tuning at all and instead just performs k-fold CV using Sweep runs. I.e., the example uses one sweep run for each fold resulting in a total of k runs. Can you confirm that?</p>\n<p>Additionally, the example uses multiprocessing for some reason while at the same time <code>join</code>ing each of the created processes immediately (see <a href=\"https://github.com/wandb/examples/blob/5727f44e4aa1acc995a8b8c63f44c3266203c165/examples/wandb-sweeps/sweeps-cross-validation/train-cross-validation.py#L84\" rel=\"noopener nofollow ugc\">here</a>). In my understanding, that means that each process runs after the previous one (no parallelism) and the usage of threading seems to be due to other non-obvious reasons.</p>\n<p>The problem for me seems to be that with a given set of hyperparameters, each call to <code>wandb.init()</code> refers to the very same run internally. So if I want to loop over the folds using the same hyperparameters, Wandb ends up overwriting the previous runs/folds every time.</p>\n<p>Here is a minimal working example:</p>\n<pre><code class=\"lang-auto\">import wandb\nimport wandb.sdk\nimport randomname\nimport numpy as np\nfrom sklearn.model_selection import KFold\n\nSWEEP_CONFIG = {\n    \"method\": \"random\",\n    \"name\": \"my_config\",\n    \"metric\": {\"goal\": \"minimize\", \"name\": \"val_root_mean_squared_error\"},\n    \"parameters\": {\n        \"param1\": {\"values\": [8, 16, 32]},\n        \"param2\": {\"values\": [1, 2, 4]},\n    },\n}\n\n\nclass Experiment:\n    def __init__(self) -&gt; None:\n        self.x_train = np.random.random((2048, 3, 1))\n        self.y_train = np.random.random((2048, 1))\n\n    def train(self) -&gt; None:\n        kf = KFold(n_splits=4, shuffle=True)\n        cv_name = randomname.get_name()\n        for fold, (ix_train, ix_val) in enumerate(kf.split(self.x_train)):\n            x_fold_train, y_fold_train = self.x_train[ix_train], self.y_train[ix_train]\n            x_fold_val, y_fold_val = self.x_train[ix_val], self.y_train[ix_val]\n\n            run_name = f\"{cv_name}-{fold:02}\"\n            run = wandb.init(group=f\"cv_{cv_name}\", name=run_name, reinit=True)\n            assert run is not None\n            assert type(run) is wandb.sdk.wandb_run.Run\n            wandb.summary[\"cv_fold\"] = fold\n            wandb.summary[\"num_cv_folds\"] = kf.n_splits\n            wandb.summary[\"cv_random_state\"] = kf.random_state\n\n            param1 = wandb.config.param1\n            param2 = wandb.config.param2\n            # random result for MWE\n            rmse = param1 * np.mean(y_fold_train) + param2 * np.mean(y_fold_val)\n            score = rmse\n            wandb.log({\"val_root_mean_squared_error\": score})\n            wandb.finish()\n\n\nif __name__ == \"__main__\":\n    exp = Experiment()\n\n    sweep_id = wandb.sweep(sweep=SWEEP_CONFIG, project=\"my_proj\")\n    wandb.agent(\n        sweep_id=sweep_id,\n        function=exp.train,\n        project=\"my_proj\",\n        # count=40,\n    )\n</code></pre>\n<p>Could you point out what needs to change in this example for it to work?</p>\n<p>EDIT: Obviously I could just NOT log the training to Wandb and instead only return the average result score for all folds - however, this is not what I want. I want to be able to compare the loss graphs of different folds etc.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-28T14:47:44.540Z",
				"Answer_body": "<p>I just want to make sure I understand correctly: Even though you said that this should be possible to do, I have shown in my MVP that it does not work. In my understanding this means that you did misunderstand what I meant (or didn\u2019t know) and it is indeed not possible to perform hyperparameter tuning in addition to k-fold CV with W&amp;B and I will have to look somewhere else. Could you confirm this? Please let me know.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-28T15:51:38.404Z",
				"Answer_body": "<p>Hi,</p>\n<p>Thank you for your patience! Please give me a couple of minutes let me get back to you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-03T14:21:58.980Z",
				"Answer_body": "<p>I\u2019m also looking for ways to do this. As <a class=\"mention\" href=\"/u/mbp\">@mbp</a> wrote, it would be nice to have metric curves per run and then be able to group these per fold. Now, if you just create a new run per every fold, it gets overwritten next configuration sweep.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-03T14:48:40.595Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/mbp\">@MBP</a>,<br>\nThank you very much for your patience!<br>\nI mentioned that the example you found was a good starting point for implementing k-fold cross validation in your sweep runs. Meaning it was a good starting point to add the sweep configurations to launch the agents.<br>\nThe example you provided do run one sweep for each fold.<br>\nIt seems like I didn\u2019t get to understand what you wanted. Are you trying to parallelize sweep agents in such a way that each sweep agent performs k-fold CV?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-04T20:57:29.896Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/bill-morrisson\">@bill-morrisson</a>, I am not sure what more I can do to explain this. I have even added source code above so that you can run it yourself and see the issue. I will try to rephrase it:</p>\n<p>I want to run a hyperparameter study with W&amp;B and I want to use Sweeps for it. This is well-documented and works on its own. For each <code>run</code> I will receive a set of parameters from <code>run.config</code>. So far so good!</p>\n<p>Now I want to use one <code>run</code> and the parameters from this particular <code>run</code> and I want to perform k-fold cross validation with these parameters. That would be easy - I just need to run the training in a loop,  and train one model for each fold, right?</p>\n<p>But now, I want to log all those runs to W&amp;B as well! How to do that? It seems it\u2019s not possible because when I use the <code>wandb.log</code> and other functions in the loop, the previous value will just be overwritten. This is the problem I want to solve - how to do this without overwriting the previous values?</p>\n<p>Additionally, one could think that if I run <code>wandb.init</code> once for each fold, then maybe the <code>wandb.log</code> will not be overwritten and instead the folds will be logged. Alas the values will still be overwritten. A new <code>run</code> will be created in W&amp;B but the previous run will just disappear. For example the first run/fold is called <code>mysterious-sweep-1</code> and then the second fold will start, a new <code>run</code> with the name <code>epic-sweep-2</code>. And now, the run <code>mysterious-sweep-1</code> is disappeared completely and all previous logged values are overwritten.</p>\n<p>I hope this helps to clarify.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-08T19:57:25.081Z",
				"Answer_body": "<p>I understand your question.<br>\nI jsut want to point oout, I\u2019m having the same issue. Previous runs getting overwritten. Im ending up with only 3 run per job, not 1 per kFold.<br>\nWhen I run it with kfold not within a sweep agent, it works as inteden (grouped in the UI, all there)<br>\nAnyone any idea?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-11T16:20:45.190Z",
				"Answer_body": "<p>I have the same problem where multiple runs for the same group, each run for a different fold, are all overwritten into 1 run for the entire k-folds.<br>\nIt means that <strong>all the information</strong> of the runs not including the last fold run <strong>is lost</strong>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-14T09:05:25.351Z",
				"Answer_body": "<p>I think we don\u2019t get any official replies because either this is</p>\n<ul>\n<li>not possible and therefore we wait in vain, or</li>\n<li>it is so simple and obvious that we are being ignored.</li>\n</ul>\n<p>I hope it\u2019s the latter and we can find out how to do it ourselves. <img src=\"https://emoji.discourse-cdn.com/twitter/sweat_smile.png?v=12\" title=\":sweat_smile:\" class=\"emoji\" alt=\":sweat_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-14T13:15:15.042Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mbp\">@MBP</a>,</p>\n<p>Sorry for the time taken to get back to you. We haven\u2019t yet dug into it specifically.<br>\nWe\u2019ll be looking into it with our engineering team and let you know.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-15T11:17:16.772Z",
				"Answer_body": "<p>I have posted an github issue. I think they are referring to that.</p><aside class=\"onebox githubissue\" data-onebox-src=\"https://github.com/wandb/wandb/issues/5119\">\n  <header class=\"source\">\n\n      <a href=\"https://github.com/wandb/wandb/issues/5119\" target=\"_blank\" rel=\"noopener nofollow ugc\">github.com/wandb/wandb</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"github-row\">\n  <div class=\"github-icon-container\" title=\"Issue\">\n\t  <svg width=\"60\" height=\"60\" class=\"github-icon\" viewbox=\"0 0 14 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z\"></path></svg>\n  </div>\n\n  <div class=\"github-info-container\">\n    <h4>\n      <a href=\"https://github.com/wandb/wandb/issues/5119\" target=\"_blank\" rel=\"noopener nofollow ugc\">[CLI]: Using sweeps,  successive wandb.init() calls overwrite older runs</a>\n    </h4>\n\n    <div class=\"github-info\">\n      <div class=\"date\">\n        opened <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2023-03-09\" data-time=\"11:41:42\" data-timezone=\"UTC\">11:41AM - 09 Mar 23 UTC</span>\n      </div>\n\n\n      <div class=\"user\">\n        <a href=\"https://github.com/MarSond\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n          <img alt=\"MarSond\" src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/4/49d66b621f345d9a6f2032508b65e6bfa62568a7.png\" class=\"onebox-avatar-inline\" width=\"20\" height=\"20\">\n          MarSond\n        </a>\n      </div>\n    </div>\n\n    <div class=\"labels\">\n        <span style=\"display:inline-block;margin-top:2px;background-color: #B8B8B8;padding: 2px;border-radius: 4px;color: #fff;margin-left: 3px;\">\n          c:sweeps\n        </span>\n        <span style=\"display:inline-block;margin-top:2px;background-color: #B8B8B8;padding: 2px;border-radius: 4px;color: #fff;margin-left: 3px;\">\n          cli\n        </span>\n    </div>\n  </div>\n</div>\n\n  <div class=\"github-row\">\n    <p class=\"github-body-container\">### Describe the bug\n\n\nUsing KFold nested runs, within a sweep loop. Runs are g<span class=\"show-more-container\"><a href=\"\" rel=\"noopener\" class=\"show-more\">\u2026</a></span><span class=\"excerpt hidden\">rouped with a random id. But after the sweep / all folds are finished, only the most recent KFold run is persistent and old data is overwritten. Every KFold, there is a new run created, but ID and Path are always the same. Only in the next sweep run the group cand run id changes.\n\nYou can see, the printed run id in the attached log and also the \"view run at\" URL stays identical.\nI experimented with reinit=True/False, adding extra wandb.finish(), but no change. \nWhen calling the run_loop() manually, it gives the expected results. The issue is only when called from sweep agent.\nUsing notebook or .py file for sweeps changes nothing. I tried aswell, not to use \"with wand.init() as run\", but start and save the run object and use it then with run.finish()\n\n\n```python\nclass Training():\n\tdef __init__(self, base_config, device):\n\t\tself.base_config = base_config\n\t\tself.device = device\n\t\tself.datalist = None\n        \n\tdef set_data(self, inputs, outputs):\n\t\tself.datalist = [(inputs[i], outputs[i]) for i in range(len(inputs))]\n\n\tdef train_loop(self, kFoldSplits=2):\n\t\tmyKfold = KFold(n_splits=kFoldSplits, shuffle=True)\n\t\tkSplit = 0\n\t\tfor train_index, val_index in myKfold.split(self.datalist):\n\t\t\tkSplit += 1\n\t\t\twith wandb.init(config=self.base_config, group=self.base_config['group_name']) as temp_run: # New run for every fold\n\t\t\t\tself.run_config = temp_run.config \t# Updated config to reflect sweep changes\n\t\t\t\tprint(\"run id: \", temp_run.id)\t\t# ISSUE here: for every kFOld iteration, the new init produces same ID and name, overwriting older folds\n\t\t\t\tprint(\"run name: \", temp_run.name)\n\t\t\t\tprint(\"run path: \", temp_run.dir)\n\t\t\t\tprint(f\"Start KFold {kSplit}\")\n\t\t\t\t#trainloader, validationloader = self.get_dataloader(train_index, val_index)\n\t\t\t\tfor epoch in range(self.run_config['epochs']):\n\t\t\t\t\tprint(\"-\"*25)\n\t\t\t\t\tprint(f\"Start Training Epoch {epoch}\")\n\t\t\t\t\t#self.train_epoch(trainloader, temp_run) # Real training would be here\n\t\t\t\t\ttemp_run.log({\"target\": epoch}) # obviously bogus, just to test\n\t\t\t\tprint(f\"Finish KFold {kSplit}\")\n\t\tprint(\"$\"*80)\n\n##########\n\ndef run_job(): # Main method, called once per sweep\n\tdevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\tgroup_name=f\"experiment_{random.randrange(111111, 999999, 6)}\" # Random group name, unique for each sweep job\n\tprint(\"Group name: \", group_name)\n\tbase_config = {\n\t\t\"lr\": 0.001,\n\t\t\"epochs\": 10,\n\t\t\"batch_size\": 32,\n\t\t\"kfold\": 3, # ...\n\t\t\"group_name\": group_name,\n\t} # My config which contains lr, epochs, batch_size, etc.\n\n\ttraining = Training(base_config = base_config, device = device) # Training wrapper - Stripped version\n\ttraining.set_data(torch.randn(100, 10),torch.randn(100, 1))\t\t\n\ttraining.train_loop(kFoldSplits=3) # start the training with folds\n\n########### Sweep creation and start\n\nsweep_configuration = {\n\t'method': 'random',\n\t'name': 'sweep_test',\n\t'metric': {'goal': 'maximize', 'name': 'target'},\n\t'parameters': \n\t{\n\t\t'epochs': {'values': [2, 4]},\n\t\t'kfold': {'values': [2, 4]},\n\t}\n}\nSTART_NEW_SWEEP = True\n\nif START_NEW_SWEEP:\n\tsweep_id = wandb.sweep(sweep=sweep_configuration, project=\"test-sweep_project_name\")\n\tprint(sweep_id)\n\n#sweep_id = sweep_id\nsweep_id = \"pp7qjzz9\"\nwandb.agent(sweep_id, function=run_job, project=\"test-sweep_project_name\")\n\n## Running the run_job with sweep agent, it produices the opverwriting issue\n## Calling run_job individually, produces expected resutls, one group, with num_fold individually tracked runs\n```\n\n\n```shell\n\nwandb: Agent Starting Run: a0jp1107 with config:\nwandb: \tepochs: 4\nwandb: \tkfold: 4\nGroup name:  experiment_165261\nwandb: Currently logged in as: magenbrot. Use `wandb login --relogin` to force relogin\nTracking run with wandb version 0.13.11\nSyncing run lilac-sweep-3 to Weights &amp; Biases (docs)\nSweep page: https://wandb.ai/magenbrot/test-sweep_project_name/sweeps/pp7qjzz9\nView project at https://wandb.ai/magenbrot/test-sweep_project_name\nView sweep at https://wandb.ai/magenbrot/test-sweep_project_name/sweeps/pp7qjzz9\nView run at https://wandb.ai/magenbrot/test-sweep_project_name/runs/a0jp1107\nrun id:  **_a0jp1107_**\nrun name:  lilac-sweep-3\nStart KFold 1\n-------------------------\nStart Training Epoch 0\nStart Validation Epoch 0\n-------------------------\nStart Training Epoch 1\nStart Validation Epoch 1\n-------------------------\nStart Training Epoch 2\nStart Validation Epoch 2\n-------------------------\nStart Training Epoch 3\nStart Validation Epoch 3\nFinish KFold 1\nWaiting for W&amp;B process to finish... (success).\n0.067 MB of 0.089 MB uploaded (0.000 MB deduped)\nRun history:\n\ntarget\t\u2581\u2583\u2586\u2588\nval_target\t\u2581\u2583\u2586\u2588\n\nRun summary:\n\ntarget\t3\nval_target\t4\n\nView run lilac-sweep-3 at: https://wandb.ai/magenbrot/test-sweep_project_name/runs/a0jp1107\nSynced 7 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\nFind logs at: .\\wandb\\run-20230309_121936-a0jp1107\\logs\nWaiting for wandb.init()...\nTracking run with wandb version 0.13.11\nSyncing run lilac-sweep-3 to Weights &amp; Biases (docs)\nSweep page: https://wandb.ai/magenbrot/test-sweep_project_name/sweeps/pp7qjzz9\nView project at https://wandb.ai/magenbrot/test-sweep_project_name\nView sweep at https://wandb.ai/magenbrot/test-sweep_project_name/sweeps/pp7qjzz9\nView run at https://wandb.ai/magenbrot/test-sweep_project_name/runs/a0jp1107\nrun id:  **_a0jp1107_**\nrun name:  lilac-sweep-3\nStart KFold 2\n-------------------------\nStart Training Epoch 0\nStart Validation Epoch 0\n-------------------------\nStart Training Epoch 1\nStart Validation Epoch 1\n-------------------------\nStart Training Epoch 2\nStart Validation Epoch 2\n-------------------------\nStart Training Epoch 3\nStart Validation Epoch 3\nFinish KFold 2\nWaiting for W&amp;B process to finish... (success).\nRun history:\n\ntarget\t\u2581\u2583\u2586\u2588\nval_target\t\u2581\u2583\u2586\u2588\n\nRun summary:\n\ntarget\t3\nval_target\t4\n\nView run lilac-sweep-3 at: https://wandb.ai/magenbrot/test-sweep_project_name/runs/a0jp1107\nSynced 7 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\nFind logs at: .\\wandb\\run-20230309_121951-a0jp1107\\logs\nWaiting for wandb.init()...\nTracking run with wandb version 0.13.11\nSyncing run lilac-sweep-3 to Weights &amp; Biases (docs)\nSweep page: https://wandb.ai/magenbrot/test-sweep_project_name/sweeps/pp7qjzz9\nView project at https://wandb.ai/magenbrot/test-sweep_project_name\nView sweep at https://wandb.ai/magenbrot/test-sweep_project_name/sweeps/pp7qjzz9\nView run at https://wandb.ai/magenbrot/test-sweep_project_name/runs/a0jp1107\nrun id:  **_a0jp1107_**\nrun name:  lilac-sweep-3\nStart KFold 3\n-------------------------\nStart Training Epoch 0\nStart Validation Epoch 0\n-------------------------\nStart Training Epoch 1\nStart Validation Epoch 1\n-------------------------\nStart Training Epoch 2\nStart Validation Epoch 2\n-------------------------\nStart Training Epoch 3\nStart Validation Epoch 3\nFinish KFold 3\nWaiting for W&amp;B process to finish... (success).\n0.080 MB of 0.090 MB uploaded (0.000 MB deduped)\nRun history:\n\ntarget\t\u2581\u2583\u2586\u2588\nval_target\t\u2581\u2583\u2586\u2588\n\nRun summary:\n\ntarget\t3\nval_target\t4\n\nView run lilac-sweep-3 at: https://wandb.ai/magenbrot/test-sweep_project_name/runs/a0jp1107\nSynced 7 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\nFind logs at: .\\wandb\\run-20230309_122006-a0jp1107\\logs\n\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n**_New Sweep starting here using new group_** \n\nwandb: Agent Starting Run: hjtswhd8 with config:\nwandb: \tepochs: 2\nwandb: \tkfold: 2\n.....\n```\n\n\n### Additional Files\n\n_No response_\n\n### Environment\n\nWandB version: 0.13.11 (but tested at 0.13.6 with same issue)\n\nOS: Windows 11\n\nPython version: 3.9.16 using mamba\n\nVersions of relevant libraries: \"up to date installed for this python version\"\n\n\n\n### Additional Context\n\n_No response_</span></p>\n  </div>\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n<p>\nShould help additionally to reproduce and find error</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-10T15:04:55.143Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/magenbrot\">@magenbrot</a> , <a class=\"mention\" href=\"/u/mbp\">@mbp</a> : I\u2019ve left a reply <a href=\"https://github.com/wandb/wandb/issues/5119#issuecomment-1501879656\" rel=\"noopener nofollow ugc\">here</a>. Hoping to revive the conversation in the GitHub thread.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Handling a variable defined for a project",
		"Question_link": "https://community.wandb.ai/t/handling-a-variable-defined-for-a-project/4099",
		"Question_created_time": "2023-03-22T15:18:40.900Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 53,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am new to wandb so this might be a basic question,</p>\n<p>I want to assign, modify and keep track of a variable assigned to a project. The use case would be let\u2019s say I have a variable \u201ccount\u201d assigned to a project staging with several workers collaborating on this project. Then lets say user A performs some runs offline and now wants to sync them to the project, then A would want to first retrieve the value of the \u201ccount\u201d variable, assign it or tag it to all his runs and then sync them and finally increment \u201ccount\u201d for the project. Now if user B wants to start his experiments he  should be able to retrieve the current \u201ccount\u201d value assign it to his set runs before syncing  them, I would really appreciate any help on what would be the best way to achieve this.<br>\nThanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-24T11:23:17.039Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/prishruit\">@prishruit</a> thanks for writing in! This is an interesting use case, we have a feature request on having <code>Tags</code> or <code>metadata</code> at the project level which would help but it\u2019s not currently available.</p>\n<p>A workaround to mock this functionality would be to log this variable <code>count</code> as an <code>Artifact</code>. This could be either a <code>wandb.Table</code> if you were interested to have some version control enabled, or a simpler option would be to include that information as <code>key:value</code> in a dummy artifact\u2019s <code>metadata</code>. Please see below an example of this:</p>\n<p>The first run (online) will log the dummy artifact as follows:</p>\n<pre><code class=\"lang-auto\">wandb.init(project='artifact-project')\nart = wandb.Artifact(name='project-tags', type='metadata', metadata={'count': 1})\nwandb.log_artifact(art)\nwandb.finish()\n</code></pre>\n<p>Before running the next offline runs, you can get the <code>count</code> value from API as:</p>\n<pre><code class=\"lang-auto\">api = wandb.Api()\nart = api.artifact('ENTITY/artifact-project/project-tags:latest', type='metadata')\ncount = art.metadata['count']\n</code></pre>\n<p>Then you could <a href=\"https://docs.wandb.ai/guides/artifacts/update-an-artifact\">update the artifact metadata</a> any time you would need either from a run as below or from API (with <code>artifact.save()</code> method):</p>\n<pre><code class=\"lang-auto\">wandb.init(project='artifact-project')\nart = wandb.use_artifact('ENTITY/artifact-project/project-tags:latest', type='metadata')\nart.metadata\nart.metadata['count'] = 2\nart.save()\nwandb.finish()\n</code></pre>\n<p>Would this work for your use case? Please note in this simpler version it won\u2019t create any new artifact versions, and if you wanted to also track its lineage you might want  to write the value to a <code>wandb.Table</code>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-03T13:19:26.815Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/prishruit\">@prishruit</a> I wanted to follow up with you on this request. I was wondering if you\u2019ve tried the above, would this work for you and are there any more questions we could help with? thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-10T11:54:39.745Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/prishruit\">@prishruit</a> since we haven\u2019t heard back from you, I will go ahead and close this ticket for now. However, please let us know if you\u2019re still having any issues or further questions, and we will be happy to assist you further.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Integrating W&B with Lightning CLI",
		"Question_link": "https://community.wandb.ai/t/integrating-w-b-with-lightning-cli/4190",
		"Question_created_time": "2023-04-05T19:26:24.789Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 126,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m using the PyTorch Lightning CLI, with code that looks like this</p>\n<pre><code class=\"lang-auto\">def main():\n    cli = CLI(model class, data module)\n\nif __name__ == \"__main__\":\n    main()\n\n</code></pre>\n<p>To launch, I do something like this:</p>\n<pre><code class=\"lang-auto\">python -u main.py fit \n</code></pre>\n<p>I saw you can integrate it with the PT Lightning <a href=\"https://wandb.ai/manan-goel/MNIST/reports/How-to-Integrate-PyTorch-Lightning-with-Weights-Biases--VmlldzoxNjg1ODQ1\">trainer</a>, but I\u2019m not sure how to integrate it with the CLI. How can one do this?</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-10T10:47:16.290Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/minimario\">@minimario</a>, thanks for writing in! I can see this was requested <a href=\"https://github.com/Lightning-AI/lightning/issues/10574#issuecomment-1015864152\" rel=\"noopener nofollow ugc\">here</a> and it\u2019s possible with a command like <code>python trainer. py fit --trainer.logger=WandbLogger</code>. Please let me know if this is helpful!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-13T12:11:03.368Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-17T08:45:53.846Z",
				"Answer_body": "<p>Hi there, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "What is the correct way to resume a paused or crashed run?",
		"Question_link": "https://community.wandb.ai/t/what-is-the-correct-way-to-resume-a-paused-or-crashed-run/4196",
		"Question_created_time": "2023-04-07T21:59:40.888Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 151,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi I am new to using WandB. I have my project setup with Tensorflow and am logging to WandB by syncing my Tensorboard <code>wandb.init(project='my-project', sync_tensorboard=True)</code>.</p>\n<p>Sometimes this run may crash or I have to pause the run to retrieve certain artifacts. Then when the run reinitiates how do I ensure that this is not logged as a new run in WandB? but instead just a continuation of the previous one. The step counters also seem to be reset when this happens, even though the step counters are accurate in tensorboard</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-10T10:39:06.605Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/amnikhil\">@amnikhil</a>, thanks for writing in! <a href=\"https://docs.wandb.ai/guides/runs/resuming#resuming-guidance\">Here</a> you can have a look at out docs about resuming runs but basically you need to set arguments <code>resume</code> and <code>run_id</code> when calling the init function as <code>wandb.init(id=run_id, resume=\"must\")</code>. Please let me know if this is useful for you!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-13T12:10:49.548Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-17T08:46:31.818Z",
				"Answer_body": "<p>Hi there, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "BrokenPipeError on Ubuntu machine",
		"Question_link": "https://community.wandb.ai/t/brokenpipeerror-on-ubuntu-machine/4117",
		"Question_created_time": "2023-03-24T09:28:14.773Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 260,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>A VAE built using PyTorch runs smoothly when I train it directly. However, with wandb sweeps, I encounter the following BrokerPipeError. According to some forum threads, the main cause seems to be the more than one <code>num_workers</code> in the DataLoader module when running on Windows OS. However, I have a DGX-station running Ubuntu, and I still get the error.</p>\n<pre><code class=\"lang-auto\">wandb: Waiting for W&amp;B process to finish... (failed 1). Press Control-C to abort syncing.\nException in thread ChkStopThr:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.8/threading.py\", line 870, in run\n    Exception in thread self._target(*self._args, **self._kwargs)NetStatThr\n:\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 276, in check_stop_status\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n    self._loop_check_status(\n      File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 214, in _loop_check_status\nself.run()\n  File \"/opt/conda/lib/python3.8/threading.py\", line 870, in run\n    local_handle = request()\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 787, in deliver_stop_status\n    self._target(*self._args, **self._kwargs)\nreturn self._deliver_stop_status(status)\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 258, in check_network_status\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 585, in _deliver_stop_status\n    self._loop_check_status(\nreturn self._deliver_record(record)  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 214, in _loop_check_status\n\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 560, in _deliver_record\n    handle = mailbox._deliver_record(record, interface=self)\n    local_handle = request()  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 795, in deliver_network_status\n    interface._publish(record)\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n    return self._deliver_network_status(status)\n      File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 601, in _deliver_network_status\nself.send_server_request(server_req)\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n    return self._deliver_record(record)\n      File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 560, in _deliver_record\nself._sendall_with_error_handle(header + data)\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n    handle = mailbox._deliver_record(record, interface=self)\nsent = self._sock.send(data)  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n\nBrokenPipeError: [Errno 32] Broken pipe\n    interface._publish(record)\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n    self.send_server_request(server_req)\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nBrokenPipeError: [Errno 32] Broken pipe\n</code></pre>\n<p>Any help would be greatly appreciated. Thank you in advance!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-04T21:46:05.720Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/janandd\">@janandd</a> !</p>\n<p>Would you be able to send the debug bundle for the run that is running into the <code>BrokenPipeError</code>?</p>\n<p>They should be located in the <code>wandb</code> folder in the same directory as where the script was run. The <code>wandb</code> folder has folders formatted as <code>run-DATETIME-ID</code> associated with a single run. Could you retrieve the <code>debug.log</code> and <code>debug-internal.log</code> files from one of these folders specifically from the run that is having issues?</p>\n<p>Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-05T02:10:19.343Z",
				"Answer_body": "<p>I tried running the sweep again today, and am getting the same error. The two requested log files are pasted below.</p>\n<ol>\n<li>debug.log</li>\n</ol>\n<pre><code class=\"lang-auto\">2023-04-05 01:59:48,222 INFO    MainThread:8836 [wandb_setup.py:_flush():76] Configure stats pid to 8836\n2023-04-05 01:59:48,222 INFO    MainThread:8836 [wandb_setup.py:_flush():76] Loading settings from /root/.config/wandb/settings\n2023-04-05 01:59:48,222 INFO    MainThread:8836 [wandb_setup.py:_flush():76] Loading settings from /root/src/my_data_dir/wandb/settings\n2023-04-05 01:59:48,222 INFO    MainThread:8836 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}\n2023-04-05 01:59:48,222 INFO    MainThread:8836 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}\n2023-04-05 01:59:48,223 INFO    MainThread:8836 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'vae_sweep.py', 'program': 'vae_sweep.py'}\n2023-04-05 01:59:48,223 INFO    MainThread:8836 [wandb_init.py:_log_setup():506] Logging user logs to /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/logs/debug.log\n2023-04-05 01:59:48,223 INFO    MainThread:8836 [wandb_init.py:_log_setup():507] Logging internal logs to /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/logs/debug-internal.log\n2023-04-05 01:59:48,223 INFO    MainThread:8836 [wandb_init.py:init():546] calling init triggers\n2023-04-05 01:59:48,223 INFO    MainThread:8836 [wandb_init.py:init():552] wandb.init called with sweep_config: {}\nconfig: {}\n2023-04-05 01:59:48,223 INFO    MainThread:8836 [wandb_init.py:init():602] starting backend\n2023-04-05 01:59:48,223 INFO    MainThread:8836 [wandb_init.py:init():606] setting up manager\n2023-04-05 01:59:48,229 INFO    MainThread:8836 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=fork,spawn,forkserver, using: spawn\n2023-04-05 01:59:48,232 INFO    MainThread:8836 [wandb_init.py:init():613] backend started and connected\n2023-04-05 01:59:48,235 INFO    MainThread:8836 [wandb_init.py:init():701] updated telemetry\n2023-04-05 01:59:48,256 INFO    MainThread:8836 [wandb_init.py:init():741] communicating run to backend with 60.0 second timeout\n2023-04-05 01:59:48,699 INFO    MainThread:8836 [wandb_run.py:_on_init():2133] communicating current version\n2023-04-05 01:59:48,750 INFO    MainThread:8836 [wandb_run.py:_on_init():2142] got version response \n2023-04-05 01:59:48,750 INFO    MainThread:8836 [wandb_init.py:init():789] starting run threads in backend\n2023-04-05 01:59:52,623 INFO    MainThread:8836 [wandb_run.py:_console_start():2114] atexit reg\n2023-04-05 01:59:52,623 INFO    MainThread:8836 [wandb_run.py:_redirect():1969] redirect: SettingsConsole.WRAP_RAW\n2023-04-05 01:59:52,687 INFO    MainThread:8836 [wandb_run.py:_redirect():2034] Wrapping output streams.\n2023-04-05 01:59:52,687 INFO    MainThread:8836 [wandb_run.py:_redirect():2059] Redirects installed.\n2023-04-05 01:59:52,688 INFO    MainThread:8836 [wandb_init.py:init():831] run started, returning control to user process\n2023-04-05 01:59:54,368 INFO    MainThread:8836 [pyagent.py:run():314] Starting sweep agent: entity=None, project=None, count=1\n2023-04-05 02:00:03,132 WARNING MsgRouterThr:8836 [router.py:message_loop():77] message_loop has been closed\n2023-04-05 02:00:05,766 INFO    Thread-5  :8836 [wandb_setup.py:_flush():76] Configure stats pid to 8836\n2023-04-05 02:00:05,767 INFO    Thread-5  :8836 [wandb_setup.py:_flush():76] Loading settings from /root/.config/wandb/settings\n2023-04-05 02:00:05,767 INFO    Thread-5  :8836 [wandb_setup.py:_flush():76] Loading settings from /root/src/my_data_dir/wandb/settings\n2023-04-05 02:00:05,767 INFO    Thread-5  :8836 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'project': 'yuzu_vae', 'entity': 'myname', 'root_dir': '/root/src/my_data_dir', 'sweep_id': 'avb3871x', 'run_id': 'pcl80d2k', 'sweep_param_path': '/root/src/my_data_dir/wandb/sweep-avb3871x/config-pcl80d2k.yaml'}\n2023-04-05 02:00:05,767 INFO    Thread-5  :8836 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}\n2023-04-05 02:00:05,767 INFO    Thread-5  :8836 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'vae_sweep.py', 'program': 'vae_sweep.py'}\n2023-04-05 02:00:05,768 INFO    Thread-5  :8836 [wandb_init.py:_log_setup():506] Logging user logs to /root/src/my_data_dir/wandb/run-20230405_020005-pcl80d2k/logs/debug.log\n2023-04-05 02:00:05,768 INFO    Thread-5  :8836 [wandb_init.py:_log_setup():507] Logging internal logs to /root/src/my_data_dir/wandb/run-20230405_020005-pcl80d2k/logs/debug-internal.log\n2023-04-05 02:00:05,768 INFO    Thread-5  :8836 [wandb_init.py:init():546] calling init triggers\n2023-04-05 02:00:05,768 INFO    Thread-5  :8836 [wandb_init.py:init():552] wandb.init called with sweep_config: {'batch_size': 64, 'epochs': 20, 'latent_dims': 132, 'learning_rate': 5.413127424880074e-06, 'optimizer': 'sgd'}\nconfig: {}\n2023-04-05 02:00:05,769 INFO    Thread-5  :8836 [wandb_init.py:init():597] wandb.init() called when a run is still active\n2023-04-05 02:00:05,792 ERROR   Thread-5  :8836 [wandb_init.py:init():1171] error\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\", line 1144, in init\n    run = wi.init()\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\", line 599, in init\n    tel.feature.init_return_run = True\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n    self._run._telemetry_callback(self._obj)\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 691, in _telemetry_callback\n    self._telemetry_flush()\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\", line 702, in _telemetry_flush\n    self._backend.interface._publish_telemetry(self._telemetry_obj)\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n    self._publish(rec)\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n    self.send_server_request(server_req)\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"/opt/conda/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nBrokenPipeError: [Errno 32] Broken pipe\n</code></pre>\n<ol start=\"2\">\n<li>debug-internal.log</li>\n</ol>\n<pre><code class=\"lang-auto\">2023-04-05 01:59:48,237 INFO    StreamThr :8851 [internal.py:wandb_internal():87] W&amp;B internal server running at pid: 8851, started at: 2023-04-05 01:59:48.236369\n2023-04-05 01:59:48,246 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: status\n2023-04-05 01:59:48,247 INFO    WriterThread:8851 [datastore.py:open_for_write():85] open: /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/run-4q1n1gag.wandb\n2023-04-05 01:59:48,248 DEBUG   SenderThread:8851 [sender.py:send():336] send: header\n2023-04-05 01:59:48,258 DEBUG   SenderThread:8851 [sender.py:send():336] send: run\n2023-04-05 01:59:48,694 INFO    SenderThread:8851 [dir_watcher.py:__init__():219] watching files in: /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/files\n2023-04-05 01:59:48,694 INFO    SenderThread:8851 [sender.py:_start_run_threads():1078] run started: 4q1n1gag with start time 1680659988.232314\n2023-04-05 01:59:48,694 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: summary_record\n2023-04-05 01:59:48,695 INFO    SenderThread:8851 [sender.py:_save_file():1332] saving file wandb-summary.json with policy end\n2023-04-05 01:59:48,700 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: check_version\n2023-04-05 01:59:48,700 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: check_version\n2023-04-05 01:59:48,762 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: run_start\n2023-04-05 01:59:48,767 DEBUG   HandlerThread:8851 [system_info.py:__init__():31] System info init\n2023-04-05 01:59:48,767 DEBUG   HandlerThread:8851 [system_info.py:__init__():46] System info init done\n2023-04-05 01:59:48,767 INFO    HandlerThread:8851 [system_monitor.py:start():183] Starting system monitor\n2023-04-05 01:59:48,767 INFO    SystemMonitor:8851 [system_monitor.py:_start():147] Starting system asset monitoring threads\n2023-04-05 01:59:48,768 INFO    HandlerThread:8851 [system_monitor.py:probe():204] Collecting system info\n2023-04-05 01:59:48,768 INFO    SystemMonitor:8851 [interfaces.py:start():187] Started cpu monitoring\n2023-04-05 01:59:48,769 INFO    SystemMonitor:8851 [interfaces.py:start():187] Started disk monitoring\n2023-04-05 01:59:48,771 INFO    SystemMonitor:8851 [interfaces.py:start():187] Started gpu monitoring\n2023-04-05 01:59:48,772 INFO    SystemMonitor:8851 [interfaces.py:start():187] Started memory monitoring\n2023-04-05 01:59:48,773 INFO    SystemMonitor:8851 [interfaces.py:start():187] Started network monitoring\n2023-04-05 01:59:49,594 DEBUG   HandlerThread:8851 [system_info.py:probe():195] Probing system\n2023-04-05 01:59:49,604 DEBUG   HandlerThread:8851 [system_info.py:_probe_git():180] Probing git\n2023-04-05 01:59:49,623 DEBUG   HandlerThread:8851 [system_info.py:_probe_git():188] Probing git done\n2023-04-05 01:59:49,623 DEBUG   HandlerThread:8851 [system_info.py:probe():240] Probing system done\n2023-04-05 01:59:49,623 DEBUG   HandlerThread:8851 [system_monitor.py:probe():213] {'os': 'Linux-5.4.0-131-generic-x86_64-with-glibc2.10', 'python': '3.8.5', 'heartbeatAt': '2023-04-05T01:59:49.594996', 'startedAt': '2023-04-05T01:59:48.218890', 'docker': None, 'cuda': None, 'args': (), 'state': 'running', 'program': 'vae_sweep.py', 'codePath': 'vae_sweep.py', 'git': {'remote': 'https://github.com/codjp/my_data_dir', 'commit': '61814805977cf5b5cd4a1583b97c0c8e76348dfa'}, 'email': None, 'root': '/root/src/my_data_dir', 'host': 'dbe83d4d908b', 'username': 'root', 'executable': '/opt/conda/bin/python3', 'cpu_count': 20, 'cpu_count_logical': 40, 'cpu_freq': {'current': 1271.777825, 'min': 1200.0, 'max': 3600.0}, 'cpu_freq_per_core': [{'current': 1199.494, 'min': 1200.0, 'max': 3600.0}, {'current': 1202.687, 'min': 1200.0, 'max': 3600.0}, {'current': 1202.113, 'min': 1200.0, 'max': 3600.0}, {'current': 1202.12, 'min': 1200.0, 'max': 3600.0}, {'current': 2207.272, 'min': 1200.0, 'max': 3600.0}, {'current': 1202.059, 'min': 1200.0, 'max': 3600.0}, {'current': 1204.13, 'min': 1200.0, 'max': 3600.0}, {'current': 1610.194, 'min': 1200.0, 'max': 3600.0}, {'current': 1202.236, 'min': 1200.0, 'max': 3600.0}, {'current': 1201.727, 'min': 1200.0, 'max': 3600.0}, {'current': 1203.113, 'min': 1200.0, 'max': 3600.0}, {'current': 1202.745, 'min': 1200.0, 'max': 3600.0}, {'current': 1201.371, 'min': 1200.0, 'max': 3600.0}, {'current': 1201.077, 'min': 1200.0, 'max': 3600.0}, {'current': 1199.408, 'min': 1200.0, 'max': 3600.0}, {'current': 1199.291, 'min': 1200.0, 'max': 3600.0}, {'current': 1201.383, 'min': 1200.0, 'max': 3600.0}, {'current': 1202.354, 'min': 1200.0, 'max': 3600.0}, {'current': 1203.227, 'min': 1200.0, 'max': 3600.0}, {'current': 1201.547, 'min': 1200.0, 'max': 3600.0}, {'current': 1202.978, 'min': 1200.0, 'max': 3600.0}, {'current': 1203.072, 'min': 1200.0, 'max': 3600.0}, {'current': 1201.825, 'min': 1200.0, 'max': 3600.0}, {'current': 1202.402, 'min': 1200.0, 'max': 3600.0}, {'current': 2204.793, 'min': 1200.0, 'max': 3600.0}, {'current': 1199.906, 'min': 1200.0, 'max': 3600.0}, {'current': 1199.096, 'min': 1200.0, 'max': 3600.0}, {'current': 1199.317, 'min': 1200.0, 'max': 3600.0}, {'current': 1199.291, 'min': 1200.0, 'max': 3600.0}, {'current': 1199.287, 'min': 1200.0, 'max': 3600.0}, {'current': 1199.292, 'min': 1200.0, 'max': 3600.0}, {'current': 1198.959, 'min': 1200.0, 'max': 3600.0}, {'current': 1199.288, 'min': 1200.0, 'max': 3600.0}, {'current': 1199.291, 'min': 1200.0, 'max': 3600.0}, {'current': 1199.277, 'min': 1200.0, 'max': 3600.0}, {'current': 1199.299, 'min': 1200.0, 'max': 3600.0}, {'current': 1199.295, 'min': 1200.0, 'max': 3600.0}, {'current': 1198.99, 'min': 1200.0, 'max': 3600.0}, {'current': 1199.873, 'min': 1200.0, 'max': 3600.0}, {'current': 1198.496, 'min': 1200.0, 'max': 3600.0}], 'disk': {'total': 1759.7716484069824, 'used': 1582.3762550354004}, 'gpu': 'Tesla V100-DGXS-32GB', 'gpu_count': 3, 'gpu_devices': [{'name': 'Tesla V100-DGXS-32GB', 'memory_total': 34078457856}, {'name': 'Tesla V100-DGXS-32GB', 'memory_total': 34087305216}, {'name': 'Tesla V100-DGXS-32GB', 'memory_total': 34087305216}], 'memory': {'total': 251.62277603149414}}\n2023-04-05 01:59:49,624 INFO    HandlerThread:8851 [system_monitor.py:probe():214] Finished collecting system info\n2023-04-05 01:59:49,624 INFO    HandlerThread:8851 [system_monitor.py:probe():217] Publishing system info\n2023-04-05 01:59:49,624 DEBUG   HandlerThread:8851 [system_info.py:_save_pip():51] Saving list of pip packages installed into the current environment\n2023-04-05 01:59:49,625 DEBUG   HandlerThread:8851 [system_info.py:_save_pip():67] Saving pip packages done\n2023-04-05 01:59:49,625 DEBUG   HandlerThread:8851 [system_info.py:_save_conda():74] Saving list of conda packages installed into the current environment\n2023-04-05 01:59:49,700 INFO    Thread-13 :8851 [dir_watcher.py:_on_file_created():278] file/dir created: /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/files/conda-environment.yaml\n2023-04-05 01:59:49,701 INFO    Thread-13 :8851 [dir_watcher.py:_on_file_created():278] file/dir created: /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/files/wandb-summary.json\n2023-04-05 01:59:49,701 INFO    Thread-13 :8851 [dir_watcher.py:_on_file_created():278] file/dir created: /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/files/requirements.txt\n2023-04-05 01:59:52,599 DEBUG   HandlerThread:8851 [system_info.py:_save_conda():86] Saving conda packages done\n2023-04-05 01:59:52,602 INFO    HandlerThread:8851 [system_monitor.py:probe():219] Finished publishing system info\n2023-04-05 01:59:52,616 DEBUG   SenderThread:8851 [sender.py:send():336] send: files\n2023-04-05 01:59:52,617 INFO    SenderThread:8851 [sender.py:_save_file():1332] saving file wandb-metadata.json with policy now\n2023-04-05 01:59:52,689 DEBUG   SenderThread:8851 [sender.py:send():336] send: telemetry\n2023-04-05 01:59:52,702 INFO    Thread-13 :8851 [dir_watcher.py:_on_file_created():278] file/dir created: /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/files/wandb-metadata.json\n2023-04-05 01:59:52,711 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: stop_status\n2023-04-05 01:59:52,712 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: stop_status\n2023-04-05 01:59:53,228 INFO    wandb-upload_0:8851 [upload_job.py:push():138] Uploaded file /tmp/tmpxt7ytk9nwandb/wysk2xtq-wandb-metadata.json\n2023-04-05 01:59:53,913 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: status_report\n2023-04-05 01:59:54,702 INFO    Thread-13 :8851 [dir_watcher.py:_on_file_created():278] file/dir created: /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/files/output.log\n2023-04-05 01:59:54,952 DEBUG   SenderThread:8851 [sender.py:send():336] send: exit\n2023-04-05 01:59:54,953 INFO    SenderThread:8851 [sender.py:send_exit():559] handling exit code: 0\n2023-04-05 01:59:54,953 INFO    SenderThread:8851 [sender.py:send_exit():561] handling runtime: 6\n2023-04-05 01:59:54,957 INFO    SenderThread:8851 [sender.py:_save_file():1332] saving file wandb-summary.json with policy end\n2023-04-05 01:59:54,958 INFO    SenderThread:8851 [sender.py:send_exit():567] send defer\n2023-04-05 01:59:54,958 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: defer\n2023-04-05 01:59:54,959 INFO    HandlerThread:8851 [handler.py:handle_request_defer():170] handle defer: 0\n2023-04-05 01:59:54,959 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: defer\n2023-04-05 01:59:54,959 INFO    SenderThread:8851 [sender.py:send_request_defer():583] handle sender defer: 0\n2023-04-05 01:59:54,959 INFO    SenderThread:8851 [sender.py:transition_state():587] send defer: 1\n2023-04-05 01:59:54,960 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: defer\n2023-04-05 01:59:54,960 INFO    HandlerThread:8851 [handler.py:handle_request_defer():170] handle defer: 1\n2023-04-05 01:59:54,960 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: defer\n2023-04-05 01:59:54,961 INFO    SenderThread:8851 [sender.py:send_request_defer():583] handle sender defer: 1\n2023-04-05 01:59:54,961 INFO    SenderThread:8851 [sender.py:transition_state():587] send defer: 2\n2023-04-05 01:59:54,961 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: defer\n2023-04-05 01:59:54,961 INFO    HandlerThread:8851 [handler.py:handle_request_defer():170] handle defer: 2\n2023-04-05 01:59:54,961 INFO    HandlerThread:8851 [system_monitor.py:finish():193] Stopping system monitor\n2023-04-05 01:59:54,962 DEBUG   SystemMonitor:8851 [system_monitor.py:_start():161] Starting system metrics aggregation loop\n2023-04-05 01:59:54,963 DEBUG   SystemMonitor:8851 [system_monitor.py:_start():168] Finished system metrics aggregation loop\n2023-04-05 01:59:54,964 DEBUG   SystemMonitor:8851 [system_monitor.py:_start():172] Publishing last batch of metrics\n2023-04-05 01:59:54,966 INFO    HandlerThread:8851 [interfaces.py:finish():199] Joined cpu monitor\n2023-04-05 01:59:54,967 INFO    HandlerThread:8851 [interfaces.py:finish():199] Joined disk monitor\n2023-04-05 01:59:54,993 INFO    HandlerThread:8851 [interfaces.py:finish():199] Joined gpu monitor\n2023-04-05 01:59:54,994 INFO    HandlerThread:8851 [interfaces.py:finish():199] Joined memory monitor\n2023-04-05 01:59:54,994 INFO    HandlerThread:8851 [interfaces.py:finish():199] Joined network monitor\n2023-04-05 01:59:54,995 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: defer\n2023-04-05 01:59:54,995 INFO    SenderThread:8851 [sender.py:send_request_defer():583] handle sender defer: 2\n2023-04-05 01:59:54,995 INFO    SenderThread:8851 [sender.py:transition_state():587] send defer: 3\n2023-04-05 01:59:54,996 DEBUG   SenderThread:8851 [sender.py:send():336] send: stats\n2023-04-05 01:59:54,996 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: defer\n2023-04-05 01:59:54,997 INFO    HandlerThread:8851 [handler.py:handle_request_defer():170] handle defer: 3\n2023-04-05 01:59:54,998 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: defer\n2023-04-05 01:59:54,998 INFO    SenderThread:8851 [sender.py:send_request_defer():583] handle sender defer: 3\n2023-04-05 01:59:54,998 INFO    SenderThread:8851 [sender.py:transition_state():587] send defer: 4\n2023-04-05 01:59:54,998 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: defer\n2023-04-05 01:59:54,998 INFO    HandlerThread:8851 [handler.py:handle_request_defer():170] handle defer: 4\n2023-04-05 01:59:54,999 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: defer\n2023-04-05 01:59:54,999 INFO    SenderThread:8851 [sender.py:send_request_defer():583] handle sender defer: 4\n2023-04-05 01:59:54,999 INFO    SenderThread:8851 [sender.py:transition_state():587] send defer: 5\n2023-04-05 01:59:54,999 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: defer\n2023-04-05 01:59:54,999 INFO    HandlerThread:8851 [handler.py:handle_request_defer():170] handle defer: 5\n2023-04-05 01:59:55,000 DEBUG   SenderThread:8851 [sender.py:send():336] send: summary\n2023-04-05 01:59:55,001 INFO    SenderThread:8851 [sender.py:_save_file():1332] saving file wandb-summary.json with policy end\n2023-04-05 01:59:55,001 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: defer\n2023-04-05 01:59:55,001 INFO    SenderThread:8851 [sender.py:send_request_defer():583] handle sender defer: 5\n2023-04-05 01:59:55,001 INFO    SenderThread:8851 [sender.py:transition_state():587] send defer: 6\n2023-04-05 01:59:55,002 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: defer\n2023-04-05 01:59:55,002 INFO    HandlerThread:8851 [handler.py:handle_request_defer():170] handle defer: 6\n2023-04-05 01:59:55,002 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: defer\n2023-04-05 01:59:55,002 INFO    SenderThread:8851 [sender.py:send_request_defer():583] handle sender defer: 6\n2023-04-05 01:59:55,008 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: status_report\n2023-04-05 01:59:55,256 INFO    SenderThread:8851 [sender.py:transition_state():587] send defer: 7\n2023-04-05 01:59:55,256 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: defer\n2023-04-05 01:59:55,257 INFO    HandlerThread:8851 [handler.py:handle_request_defer():170] handle defer: 7\n2023-04-05 01:59:55,257 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: defer\n2023-04-05 01:59:55,257 INFO    SenderThread:8851 [sender.py:send_request_defer():583] handle sender defer: 7\n2023-04-05 01:59:55,703 INFO    Thread-13 :8851 [dir_watcher.py:_on_file_modified():295] file/dir modified: /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/files/config.yaml\n2023-04-05 01:59:55,704 INFO    Thread-13 :8851 [dir_watcher.py:_on_file_modified():295] file/dir modified: /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/files/wandb-summary.json\n2023-04-05 01:59:55,953 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: poll_exit\n2023-04-05 01:59:56,376 INFO    SenderThread:8851 [sender.py:transition_state():587] send defer: 8\n2023-04-05 01:59:56,377 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: poll_exit\n2023-04-05 01:59:56,377 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: defer\n2023-04-05 01:59:56,378 INFO    HandlerThread:8851 [handler.py:handle_request_defer():170] handle defer: 8\n2023-04-05 01:59:56,378 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: defer\n2023-04-05 01:59:56,378 INFO    SenderThread:8851 [sender.py:send_request_defer():583] handle sender defer: 8\n2023-04-05 01:59:56,389 INFO    SenderThread:8851 [sender.py:transition_state():587] send defer: 9\n2023-04-05 01:59:56,389 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: defer\n2023-04-05 01:59:56,390 DEBUG   SenderThread:8851 [sender.py:send():336] send: artifact\n2023-04-05 01:59:56,390 INFO    HandlerThread:8851 [handler.py:handle_request_defer():170] handle defer: 9\n2023-04-05 01:59:56,704 INFO    Thread-13 :8851 [dir_watcher.py:_on_file_modified():295] file/dir modified: /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/files/output.log\n2023-04-05 01:59:56,954 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: poll_exit\n2023-04-05 01:59:57,943 INFO    wandb-upload_0:8851 [upload_job.py:push():96] Uploaded file /root/.local/share/wandb/artifacts/staging/tmpl5hz4tzp\n2023-04-05 01:59:57,950 INFO    wandb-upload_1:8851 [upload_job.py:push():96] Uploaded file /root/.local/share/wandb/artifacts/staging/tmpydxrxzl1\n2023-04-05 01:59:59,852 INFO    SenderThread:8851 [sender.py:send_artifact():1428] sent artifact job-https___github.com_codjp_my_data_dir_vae_sweep.py - {'id': 'QXJ0aWZhY3Q6NDEzODk0MDU3', 'digest': 'ec88d1c400e70291591f8965d41aea40', 'state': 'PENDING', 'aliases': [], 'artifactSequence': {'id': 'QXJ0aWZhY3RDb2xsZWN0aW9uOjYwNDEzMzY0', 'latestArtifact': None}, 'version': 'latest'}\n2023-04-05 01:59:59,852 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: defer\n2023-04-05 01:59:59,852 INFO    SenderThread:8851 [sender.py:send_request_defer():583] handle sender defer: 9\n2023-04-05 01:59:59,852 INFO    SenderThread:8851 [dir_watcher.py:finish():365] shutting down directory watcher\n2023-04-05 02:00:00,705 INFO    SenderThread:8851 [dir_watcher.py:finish():395] scan: /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/files\n2023-04-05 02:00:00,706 INFO    SenderThread:8851 [dir_watcher.py:finish():409] scan save: /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/files/wandb-metadata.json wandb-metadata.json\n2023-04-05 02:00:00,706 INFO    SenderThread:8851 [dir_watcher.py:finish():409] scan save: /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/files/config.yaml config.yaml\n2023-04-05 02:00:00,706 INFO    SenderThread:8851 [dir_watcher.py:finish():409] scan save: /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/files/conda-environment.yaml conda-environment.yaml\n2023-04-05 02:00:00,717 INFO    SenderThread:8851 [dir_watcher.py:finish():409] scan save: /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/files/wandb-summary.json wandb-summary.json\n2023-04-05 02:00:00,718 INFO    SenderThread:8851 [dir_watcher.py:finish():409] scan save: /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/files/output.log output.log\n2023-04-05 02:00:00,718 INFO    SenderThread:8851 [dir_watcher.py:finish():409] scan save: /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/files/requirements.txt requirements.txt\n2023-04-05 02:00:00,727 INFO    SenderThread:8851 [sender.py:transition_state():587] send defer: 10\n2023-04-05 02:00:00,727 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: poll_exit\n2023-04-05 02:00:00,732 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: defer\n2023-04-05 02:00:00,738 INFO    HandlerThread:8851 [handler.py:handle_request_defer():170] handle defer: 10\n2023-04-05 02:00:00,748 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: defer\n2023-04-05 02:00:00,748 INFO    SenderThread:8851 [sender.py:send_request_defer():583] handle sender defer: 10\n2023-04-05 02:00:00,749 INFO    SenderThread:8851 [file_pusher.py:finish():164] shutting down file pusher\n2023-04-05 02:00:01,262 INFO    wandb-upload_1:8851 [upload_job.py:push():138] Uploaded file /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/files/wandb-summary.json\n2023-04-05 02:00:01,348 INFO    wandb-upload_0:8851 [upload_job.py:push():138] Uploaded file /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/files/config.yaml\n2023-04-05 02:00:01,357 INFO    wandb-upload_2:8851 [upload_job.py:push():138] Uploaded file /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/files/output.log\n2023-04-05 02:00:01,533 INFO    wandb-upload_3:8851 [upload_job.py:push():138] Uploaded file /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/files/requirements.txt\n2023-04-05 02:00:01,733 INFO    Thread-12 :8851 [sender.py:transition_state():587] send defer: 11\n2023-04-05 02:00:01,734 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: defer\n2023-04-05 02:00:01,734 INFO    HandlerThread:8851 [handler.py:handle_request_defer():170] handle defer: 11\n2023-04-05 02:00:01,735 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: defer\n2023-04-05 02:00:01,735 INFO    SenderThread:8851 [sender.py:send_request_defer():583] handle sender defer: 11\n2023-04-05 02:00:01,735 INFO    SenderThread:8851 [file_pusher.py:join():169] waiting for file pusher\n2023-04-05 02:00:01,735 INFO    SenderThread:8851 [sender.py:transition_state():587] send defer: 12\n2023-04-05 02:00:01,735 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: defer\n2023-04-05 02:00:01,735 INFO    HandlerThread:8851 [handler.py:handle_request_defer():170] handle defer: 12\n2023-04-05 02:00:01,736 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: defer\n2023-04-05 02:00:01,736 INFO    SenderThread:8851 [sender.py:send_request_defer():583] handle sender defer: 12\n2023-04-05 02:00:01,922 INFO    SenderThread:8851 [sender.py:transition_state():587] send defer: 13\n2023-04-05 02:00:01,923 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: defer\n2023-04-05 02:00:01,923 INFO    HandlerThread:8851 [handler.py:handle_request_defer():170] handle defer: 13\n2023-04-05 02:00:01,923 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: defer\n2023-04-05 02:00:01,924 INFO    SenderThread:8851 [sender.py:send_request_defer():583] handle sender defer: 13\n2023-04-05 02:00:01,924 INFO    SenderThread:8851 [sender.py:transition_state():587] send defer: 14\n2023-04-05 02:00:01,925 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: defer\n2023-04-05 02:00:01,925 DEBUG   SenderThread:8851 [sender.py:send():336] send: final\n2023-04-05 02:00:01,925 INFO    HandlerThread:8851 [handler.py:handle_request_defer():170] handle defer: 14\n2023-04-05 02:00:01,926 DEBUG   SenderThread:8851 [sender.py:send():336] send: footer\n2023-04-05 02:00:01,926 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: defer\n2023-04-05 02:00:01,926 INFO    SenderThread:8851 [sender.py:send_request_defer():583] handle sender defer: 14\n2023-04-05 02:00:01,928 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: poll_exit\n2023-04-05 02:00:01,928 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: poll_exit\n2023-04-05 02:00:01,929 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: server_info\n2023-04-05 02:00:01,930 DEBUG   SenderThread:8851 [sender.py:send_request():363] send_request: server_info\n2023-04-05 02:00:01,937 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: get_summary\n2023-04-05 02:00:01,939 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: sampled_history\n2023-04-05 02:00:02,129 INFO    MainThread:8851 [wandb_run.py:_footer_history_summary_info():3422] rendering history\n2023-04-05 02:00:02,129 INFO    MainThread:8851 [wandb_run.py:_footer_history_summary_info():3454] rendering summary\n2023-04-05 02:00:02,130 INFO    MainThread:8851 [wandb_run.py:_footer_sync_info():3380] logging synced files\n2023-04-05 02:00:02,130 DEBUG   HandlerThread:8851 [handler.py:handle_request():144] handle_request: shutdown\n2023-04-05 02:00:02,131 INFO    HandlerThread:8851 [handler.py:finish():842] shutting down handler\n2023-04-05 02:00:02,930 INFO    WriterThread:8851 [datastore.py:close():298] close: /root/src/my_data_dir/wandb/run-20230405_015948-4q1n1gag/run-4q1n1gag.wandb\n2023-04-05 02:00:03,129 INFO    SenderThread:8851 [sender.py:finish():1504] shutting down sender\n2023-04-05 02:00:03,129 INFO    SenderThread:8851 [file_pusher.py:finish():164] shutting down file pusher\n2023-04-05 02:00:03,129 INFO    SenderThread:8851 [file_pusher.py:join():169] waiting for file pusher\n</code></pre>\n<p>Thank you!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-06T19:01:16.343Z",
				"Answer_body": "<p>Hello! Looks like it there is a Connection issue between your machine and the <code>wandb</code> server. Is there a load balancer, a VPN, or a proxy that your machine is behind that may be blocking the connection? The reason I ask is because  <code>sent = self._sock.send(data)</code>  is the main error in the stack trace which means that the client is struggling to send data to the server.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-04-07T02:21:59.922Z",
				"Answer_body": "<p>That most likely seems to be the reason. The machine running my code is in a VPN, and it may not be possible for it to access wandb server.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Stable Baselines3: Recording Video and uploading it to WandB",
		"Question_link": "https://community.wandb.ai/t/stable-baselines3-recording-video-and-uploading-it-to-wandb/4179",
		"Question_created_time": "2023-04-04T07:13:34.213Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 87,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello Community,</p>\n<p>I am using the Stable Baslines3 integration and my goal is to record videos of every Nth rollout. I want those videos to appear in my WandB dashboard. I followed the instructions here: <a href=\"https://docs.wandb.ai/guides/integrations/stable-baselines-3\" class=\"inline-onebox\">Stable Baselines 3 | Weights &amp; Biases Documentation</a> and also watched the YT workshop talking about the WandB integration. However, I am still not able to see the recorded videos in my dashboard. The videos are recorded and saved to my local machine, but they are never uploaded. What might be the issue here? Could you provide me with an example?<br>\nAlso if anyone is experienced with stable baslines3 it would be very helpful if you could tell me how to best record videos every Nth rollout (the default is that you record the video every Nth timestep for a fixed amount of steps.) I want to record a video every Nth rollout till the done signal is reached (not a fixed length of steps).</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-06T22:42:13.432Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/erikk\">@erikk</a>,</p>\n<p>The Video recording functionality does not exist directly within the Stable Baselines integration, but does within the OpenAI gym integration.</p>\n<p>It\u2019s important to note that the Gym object logs its own video, which is then logged. If the Gym environment does not expose any video logging functionality, no videos will be logged.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-10T19:46:38.593Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/erikk\">@erikk</a>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-11T17:32:37.672Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/erikk\">@erikk</a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb: Network error (ConnectTimeout), entering retry loop",
		"Question_link": "https://community.wandb.ai/t/wandb-network-error-connecttimeout-entering-retry-loop/4162",
		"Question_created_time": "2023-04-01T00:38:21.318Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 333,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>my code :</p>\n<pre><code class=\"lang-auto\">import wandb\nfor x in range(10):\n    run = wandb.init(settings=wandb.Settings(start_method=\"thread\"))\n    for y in range (100):\n        wandb.log({\"metric\": x+y})\n    run.finish()\n</code></pre>\n<p>output:</p>\n<pre><code class=\"lang-auto\">wandb: W&amp;B API key is configured. Use `wandb login --relogin` to force relogin\nwandb: Tracking run with wandb version 0.14.0\nwandb: Run data is saved locally in /home/xyc/Code/RumorDG/method/CDCL/wandb/run-20230401_083434-fi3tttps\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run clear-firebrand-1\nwandb: \u2b50\ufe0f View project at https://wandb.ai/moailaozi/uncategorized\nwandb: \ud83d\ude80 View run at https://wandb.ai/moailaozi/uncategorized/runs/fi3tttps\nwandb: Waiting for W&amp;B process to finish... (success).\nwandb: Network error (ConnectTimeout), entering retry loop.\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-06T20:24:18.219Z",
				"Answer_body": "<p>Hello! It looks like there is a Connection issue between your client and the <code>wandb</code> server.  There a variety of reasons to why there would be a connection issues but common reasons are</p>\n<ul>\n<li>a Proxy</li>\n<li>VPN</li>\n<li>a load balancer</li>\n<li>weak internet connections</li>\n</ul>\n<p>Are you behind a proxy, VPN, or a load balancer? If not, could you send the debug bundle for the run. They should be located in the  <code>wandb</code> folder in the same directory as where the script was run. The <code>wandb</code> folder has folders formatted as <code>run-DATETIME-ID</code> associated with a single run. Could you retrieve the <code>debug.log</code> and <code>debug-internal.log</code> files from one of these folders specifically from the run that is having issues?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-11T23:29:23.500Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb: ERROR Run xxjba37s errored: FileNotFoundError(2, 'No such file or directory')",
		"Question_link": "https://community.wandb.ai/t/wandb-error-run-xxjba37s-errored-filenotfounderror-2-no-such-file-or-directory/4129",
		"Question_created_time": "2023-03-26T08:21:00.483Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 168,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I am trying to use sweeps for the first time, I am having this issue.</p>\n<p>after exceuting wandb.agent(sweep_id, function=wandb_train_func, count=1), this is the output:</p>\n<p>Create sweep with ID: lg85skzc Sweep URL: <a href=\"https://wandb.ai/victoreduardo-fonsecamedina/KNN_1st_attempt/sweeps/lg85skzc\" class=\"inline-onebox\">Weights &amp; Biases</a></p>\n<p>wandb: Agent Starting Run: xxjba37s with config: wandb: batch_size: 3 wandb: learning_rate: 0.03880829630118215 wandb: momentum: 0.925717097296538 wandb: num_epochs: 10 wandb: optimizer: sgd wandb: WARNING Ignored wandb.init() arg project when running a sweep. wandb: WARNING Ignored wandb.init() arg entity when running a sweep.</p>\n<p>Tracking run with wandb version 0.14.0</p>\n<p>Run data is saved locally in <code>/ibex/scratch/fonsecv/Machine_Learning_Course/Notebooks/KNN/wandb/run-20230325_172833-xxjba37s</code></p>\n<p>Waiting for W&amp;B process to finish\u2026 <strong>(failed 1).</strong> Press Control-C to abort syncing.</p>\n<p>View run <strong>KNN_1</strong> at: <a href=\"https://wandb.ai/victoreduardo-fonsecamedina/KNN_1st_attempt/runs/xxjba37s\" class=\"inline-onebox\">Weights &amp; Biases</a><br>\nSynced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)</p>\n<p>Find logs at: <code>./wandb/run-20230325_172833-xxjba37s/logs</code></p>\n<p>wandb: ERROR Run xxjba37s errored: FileNotFoundError(2, \u2018No such file or directory\u2019)</p>\n<p>I don\u2019t know which file or directory is the error referring to.</p>\n<p>Thank you</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-06T15:55:24.167Z",
				"Answer_body": "<p>Hi!</p>\n<p>Could you send me your debug logs to the sweeps run that failed?</p>\n<p>Cheers,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-11T17:05:03.882Z",
				"Answer_body": "<p>Hi Victor,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-14T19:05:50.397Z",
				"Answer_body": "<p>Hi Victor, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Will each agent always use the same seed?",
		"Question_link": "https://community.wandb.ai/t/will-each-agent-always-use-the-same-seed/4138",
		"Question_created_time": "2023-03-28T15:07:49.172Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 52,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>if I use wandb with sweeps and run an agent with 10 counts but my config file has the same hyperparams, will it also use the same seed?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-06T15:51:14.080Z",
				"Answer_body": "<p>Hi brando! Could I see how you are setting up your multi agent sweep?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-11T17:04:19.960Z",
				"Answer_body": "<p>Hi Brando,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-14T19:05:24.683Z",
				"Answer_body": "<p>Hi Brando, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How do I select a GPU before running a wandb agent?",
		"Question_link": "https://community.wandb.ai/t/how-do-i-select-a-gpu-before-running-a-wandb-agent/4135",
		"Question_created_time": "2023-03-27T16:28:00.682Z",
		"Question_answer_count": 9,
		"Question_score_count": 1,
		"Question_view_count": 248,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I wanted to run a set of wandb agents but the server that I have access to does not have slurm or any workload manager. How do I have the agent code select an CUDA_VISIBLE_DEVICE automatically according to the gpu memory I need and is available?</p>\n<p>I was going to do something hacky like a while loop that checked with a memory error happened after looping all GPUs or the total number of agents the user desired was reached. But was hoping to avoid doing this since this seems the entire reason I am using wandb in the first place.</p>\n<hr>\n<p>Some started code</p>\n<pre><code class=\"lang-auto\">\"\"\"\nMain Idea:\n- create sweep with a sweep config &amp; get sweep_id for the agents (note, this creates a sweep in wandb's website)\n- create agent to run a setting of hps by giving it the sweep_id (that mataches the sweep in the wandb website)\n- keep running agents with sweep_id until you're done\n\nnote:\n    - Each individual training session with a specific set of hyperparameters in a sweep is considered a wandb run.\n\nref:\n    - read: https://docs.wandb.ai/guides/sweeps\n\"\"\"\n\nimport wandb\nfrom pprint import pprint\nimport math\nimport torch\n\nsweep_config: dict = {\n    \"project\": \"playground\",\n    \"entity\": \"your_wanbd_username\",\n    \"name\": \"my-ultimate-sweep\",\n    \"metric\":\n        {\"name\": \"train_loss\",\n         \"goal\": \"minimize\"}\n    ,\n    \"method\": \"random\",\n    \"parameters\": None,  # not set yet\n}\n\nparameters = {\n    'optimizer': {\n        'values': ['adam', 'adafactor']}\n    ,\n    'scheduler': {\n        'values': ['cosine', 'none']}  # todo, think how to do\n    ,\n    'lr': {\n        \"distribution\": \"log_uniform_values\",\n        \"min\": 1e-6,\n        \"max\": 0.2}\n    ,\n    'batch_size': {\n        # integers between 32 and 256\n        # with evenly-distributed logarithms\n        'distribution': 'q_log_uniform_values',\n        'q': 8,\n        'min': 32,\n        'max': 256,\n    }\n    ,\n    # it's often the case that some hps we don't want to vary in the run e.g. num_its\n    'num_its': {'value': 5}\n}\nsweep_config['parameters'] = parameters\npprint(sweep_config)\n\n# create sweep in wandb's website &amp; get sweep_id to create agents that run a single agent with a set of hps\nsweep_id = wandb.sweep(sweep_config)\nprint(f'{sweep_id=}')\n\n\ndef my_train_func():\n    # read the current value of parameter \"a\" from wandb.config\n    # I don't think we need the group since the sweep name is already the group\n    run = wandb.init(config=sweep_config)\n    print(f'{run=}')\n    pprint(f'{wandb.config=}')\n    lr = wandb.config.lr\n    num_its = wandb.config.num_its\n\n    train_loss: float = 8.0 + torch.rand(1).item()\n    for i in range(num_its):\n        # get a random update step from the range [0.0, 1.0] using torch\n        update_step: float = lr * torch.rand(1).item()\n        wandb.log({\"lr\": lr, \"train_loss\": train_loss - update_step})\n    run.finish()\n\n\n# run the sweep, The cell below will launch an agent that runs train 5 times, usingly the randomly-generated hyperparameter values returned by the Sweep Controller.\nwandb.agent(sweep_id, function=my_train_func, count=5)\n</code></pre>\n<p>cross: <a href=\"https://stackoverflow.com/questions/75858165/how-do-i-select-a-gpu-before-running-a-wandb-agent\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">python - How do I select a GPU before running a wandb agent? - Stack Overflow</a></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-28T02:42:12.684Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/brando\">@brando</a>  to select a specific GPU before running a wandb agent, you can set the <code>CUDA_VISIBLE_DEVICES</code> environment variable. This variable determines which GPU(s) will be used by your script. Here\u2019s an example of how to set <code>CUDA_VISIBLE_DEVICES</code> and run a wandb agent with a specific GPU:</p>\n<pre><code class=\"lang-auto\">bash\nCUDA_VISIBLE_DEVICES=0 wandb \nagent sweep_ID\n</code></pre>\n<p>In this example, replace <code>sweep_ID</code> with your actual sweep ID. The <code>CUDA_VISIBLE_DEVICES=0</code> part sets the first GPU (index 0) as the visible device for your script. If you have multiple GPUs and want to use another one, change the index accordingly (e.g., <code>CUDA_VISIBLE_DEVICES=1</code> for the second GPU). Make sure you have the <a href=\"https://developer.nvidia.com/cuda-toolkit\">NVIDIA CUDA Toolkit</a> installed on your system to use <code>CUDA_VISIBLE_DEVICES</code>.</p>\n<p>Here are some references you can check out as well:</p>\n<ul>\n<li>\n<p><a href=\"https://docs.wandb.ai/guides/track/environment-variables\">https://docs.wandb.ai/guides/track/environment-variables</a></p>\n</li>\n<li>\n<p><a href=\"https://docs.wandb.ai/guides/integrations/lightning\" class=\"inline-onebox\">PyTorch Lightning | Weights &amp; Biases Documentation</a></p>\n</li>\n<li>\n<p><a href=\"https://docs.wandb.ai/guides/sweeps/parallelize-agents\" class=\"inline-onebox\">Parallelize agents</a></p>\n</li>\n<li>\n<p><a href=\"https://docs.wandb.ai/guides/launch/getting-started\" class=\"inline-onebox\">Getting started | Weights &amp; Biases Documentation</a></p>\n</li>\n</ul>\n<p>I hope this helps!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-28T15:06:58.751Z",
				"Answer_body": "<p>so it doesn\u2019t do workloading for me basically, like slurm would do?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-28T17:03:16.544Z",
				"Answer_body": "<p>Hi, I just want to distinguish the differences between W&amp;B and SLURM. W&amp;B focuses on experiment tracking, visualization, and collaboration, etc. while SLURM is a workload manager for managing resources and job scheduling on a cluster.  W&amp;B does not handle workload management or job scheduling like SLURM.</p>\n<p>You can <a href=\"https://docs.wandb.ai/guides/sweeps/faq#how-should-i-run-sweeps-on-slurm\">run Sweeps on SLURM</a> and here are a couple of third-party resources that might be able to support this use case:</p>\n<ul>\n<li>\n<p><a href=\"https://wandb-utils.readthedocs.io/en/latest/managing_jobs_on_slurm.html#manging-wandb-agents-on-a-slurm-cluster\">Manging wandb agents on a slurm cluster</a></p>\n</li>\n<li>\n<p><a href=\"https://www.youtube.com/watch?v=LRmnr3LMS-4\">Demo of using Weights &amp; Biases in a slurm cluster</a></p>\n</li>\n</ul>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-29T17:24:47.258Z",
				"Answer_body": "<p>slurm was an analogy. I don\u2019t have slurm (unfortunately, otherwise I wouldn\u2019t be bothering you with it). I know how to use slrum :). I just have access directly to a single A100 server I share with ppl and want to make it painless to allocate gpu jobs.</p>\n<p>Do you think this stratgey is a good idea for the short term:</p>\n<ul>\n<li>select a gpu</li>\n<li>put number of counts to be say 10 or a large number</li>\n<li>only the jobs that have gpu memory will be allocated, the rest will fail</li>\n</ul>\n<p>Done, requires no code except the count flag.</p>\n<pre><code class=\"lang-auto\">wandb.agent(sweep_id, function=my_train_func, count=5)\n</code></pre>\n<p>or</p>\n<pre><code class=\"lang-auto\">wand agent --count 10 $SWEEP_ID\n</code></pre>\n<p>thoughts <a class=\"mention\" href=\"/u/corey-strausman\">@corey-strausman</a> ? Thanks for the help so far btw <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-29T18:45:49.964Z",
				"Answer_body": "<p>This seems reasonable for the short term. By setting the <code>count</code> parameter in <code>wandb.agent()</code> or using <code>wandb agent --count</code> , you can limit the number of trials to run. This way, only the jobs that have GPU memory will be allocated, and the rest will fail.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-30T23:55:29.974Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"corey-strausman\" data-post=\"6\" data-topic=\"4135\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://sea2.discourse-cdn.com/business7/user_avatar/community.wandb.ai/corey-strausman/40/1258_2.png\" class=\"avatar\"> corey-strausman:</div>\n<blockquote>\n<p>This seems reasonable for the short term.</p>\n</blockquote>\n</aside>\n<p>what is a good long term? note I don\u2019t have sudo priveledges in my cluster/servers + GPT4 doesn\u2019t suggest a reasonably easy way to install slurm myself:</p>\n<pre><code class=\"lang-auto\">How do I install slurm locally with minimum configurations on a single server?\n\nTo install Slurm locally with minimum configurations on a single server, follow these steps:\n\nInstall dependencies:\nSlurm has several dependencies that need to be installed before you can install Slurm. On a Debian-based system (e.g., Ubuntu), run the following commands:\nbash\nCopy code\nsudo apt-get update\nsudo apt-get install -y gcc make munge libmunge-dev libmunge2 libpam0g-dev libmysqlclient-dev libssl-dev libncurses5-dev\nCreate a Munge key:\nMunge is an authentication mechanism used by Slurm. You need to create a secret key and distribute it to all nodes. In this case, you only have one node.\nbash\nCopy code\nsudo dd if=/dev/urandom of=/etc/munge/munge.key bs=1 count=1024\nsudo chown munge:munge /etc/munge/munge.key\nsudo chmod 400 /etc/munge/munge.key\nStart the Munge service:\nbash\nCopy code\nsudo systemctl enable munge\nsudo systemctl start munge\nDownload and compile Slurm:\nbash\nCopy code\nwget https://download.schedmd.com/slurm/slurm-21.08.5.tar.bz2\ntar xjf slurm-21.08.5.tar.bz2\ncd slurm-21.08.5\n./configure\nmake\nsudo make install\nCreate a minimal Slurm configuration:\nCreate a minimal slurm.conf file, replacing &lt;your_hostname&gt; with the output of hostname command.\nbash\nCopy code\nsudo mkdir -p /etc/slurm\nsudo nano /etc/slurm/slurm.conf\nPaste the following content into the file, adjusting it to your system:\n\nbash\nCopy code\nControlMachine=&lt;your_hostname&gt;\nAuthType=auth/munge\nCryptoType=crypto/munge\nMpiDefault=none\nProctrackType=proctrack/pgid\nReturnToService=1\nSlurmctldPidFile=/var/run/slurmctld.pid\nSlurmctldPort=6817\nSlurmdPidFile=/var/run/slurmd.pid\nSlurmdPort=6818\nSlurmdSpoolDir=/var/spool/slurmd\nSlurmUser=slurm\nStateSaveLocation=/var/spool/slurmctld\nSwitchType=switch/none\nTaskPlugin=task/none\nInactiveLimit=0\nKillWait=30\nMinJobAge=300\nSlurmctldTimeout=120\nSlurmdTimeout=300\nWaittime=0\n\n# Define a single partition\nPartitionName=debug Nodes=&lt;your_hostname&gt; Default=YES MaxTime=INFINITE State=UP\n\n# Define the single node\nNodeName=&lt;your_hostname&gt; CPUs=1 State=UNKNOWN\nCreate the Slurm directories:\nbash\nCopy code\nsudo mkdir -p /var/spool/slurmctld /var/spool/slurmd /var/log/slurm\nsudo chown slurm: /var/spool/slurmctld /var/spool/slurmd /var/log/slurm\nStart the Slurm services:\nbash\nCopy code\nsudo systemctl enable slurmd.service slurmctld.service\nsudo systemctl start slurmd.service slurmctld.service\nNow Slurm should be installed and running on your single server. To check the status, use the sinfo command.\n\n\n\n\nBrando Miranda\ntry one more time with this constraint. I don't have sudo privileges. So how do I install slurm then on a single server locally? \nIf you don't have sudo privileges, you can still install Slurm locally in your home directory. Here's how you can do it:\n\nInstall dependencies:\nAsk your system administrator to install the necessary dependencies if they aren't already installed on the system:\ngcc\nmake\nmunge\nlibmunge-dev\nlibmunge2\nlibpam0g-dev\nlibmysqlclient-dev\nlibssl-dev\nlibncurses5-dev\nConfigure Munge:\nAsk your system administrator to configure Munge, create a secret key, and start the Munge service. This is necessary for Slurm to work.\n\nDownload and compile Slurm:\n\nbash\nCopy code\nwget https://download.schedmd.com/slurm/slurm-21.08.5.tar.bz2\ntar xjf slurm-21.08.5.tar.bz2\ncd slurm-21.08.5\n./configure --prefix=$HOME/slurm\nmake\nmake install\nUpdate your PATH variable:\nbash\nCopy code\necho 'export PATH=$HOME/slurm/bin:$PATH' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\nCreate a minimal Slurm configuration:\nCreate a minimal slurm.conf file, replacing &lt;your_hostname&gt; with the output of the hostname command.\nbash\nCopy code\nmkdir -p $HOME/slurm/etc\nnano $HOME/slurm/etc/slurm.conf\nPaste the following content into the file, adjusting it to your system:\n\nbash\nCopy code\nControlMachine=&lt;your_hostname&gt;\nAuthType=auth/munge\nCryptoType=crypto/munge\nMpiDefault=none\nProctrackType=proctrack/pgid\nReturnToService=1\nSlurmctldPidFile=$HOME/slurm/var/run/slurmctld.pid\nSlurmctldPort=6817\nSlurmdPidFile=$HOME/slurm/var/run/slurmd.pid\nSlurmdPort=6818\nSlurmdSpoolDir=$HOME/slurm/var/spool/slurmd\nSlurmUser=$(whoami)\nStateSaveLocation=$HOME/slurm/var/spool/slurmctld\nSwitchType=switch/none\nTaskPlugin=task/none\nInactiveLimit=0\nKillWait=30\nMinJobAge=300\nSlurmctldTimeout=120\nSlurmdTimeout=300\nWaittime=0\n\n# Define a single partition\nPartitionName=debug Nodes=&lt;your_hostname&gt; Default=YES MaxTime=INFINITE State=UP\n\n# Define the single node\nNodeName=&lt;your_hostname&gt; CPUs=1 State=UNKNOWN\nCreate the Slurm directories:\nbash\nCopy code\nmkdir -p $HOME/slurm/var/run $HOME/slurm/var/spool/slurmctld $HOME/slurm/var/spool/slurmd $HOME/slurm/var/log\nStart the Slurm services:\nbash\nCopy code\nslurmctld -D -c -f $HOME/slurm/etc/slurm.conf &amp;\nslurmd -D -c -f $HOME/slurm/etc/slurm.conf &amp;\nThe -D flag runs the services in the foreground. If you want to run them in the background, you can remove the -D flag.\n\nNow Slurm should be installed and running locally in your home directory on the single server. To check the status, use the sinfo command.\n\n\n\n\nBrando Miranda\nGive me the commands to install the dependencies locally without sudo priviledges \ngcc\nmake\nmunge\nlibmunge-dev\nlibmunge2\nlibpam0g-dev\nlibmysqlclient-dev\nlibssl-dev\nlibncurses5-dev\nInstalling system-level dependencies without sudo privileges can be challenging. However, you can try to build these dependencies from source and install them locally in your home directory.\n\nKeep in mind that building all these packages from source can be time-consuming and may require additional dependencies. Here is a general outline of the steps to build each dependency from source:\n\nCreate a local directory for the dependencies:\nbash\nCopy code\nmkdir -p $HOME/local\nSet environment variables:\nbash\nCopy code\necho 'export PATH=$HOME/local/bin:$PATH' &gt;&gt; ~/.bashrc\necho 'export LD_LIBRARY_PATH=$HOME/local/lib:$LD_LIBRARY_PATH' &gt;&gt; ~/.bashrc\necho 'export PKG_CONFIG_PATH=$HOME/local/lib/pkgconfig:$PKG_CONFIG_PATH' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\nDownload, build, and install each dependency:\nFor each dependency, you generally follow these steps:\n\nDownload the source code.\nExtract the archive.\nEnter the source directory.\nConfigure the build system, specifying the installation prefix as $HOME/local.\nBuild the software using make.\nInstall the software using make install.\nFor example, here is the process for building and installing gcc locally:\n\nbash\nCopy code\nwget https://ftp.gnu.org/gnu/gcc/gcc-11.2.0/gcc-11.2.0.tar.gz\ntar xzf gcc-11.2.0.tar.gz\ncd gcc-11.2.0\n./contrib/download_prerequisites\nmkdir build &amp;&amp; cd build\n../configure --prefix=$HOME/local --enable-languages=c,c++ --disable-multilib\nmake -j$(nproc)\nmake install\nYou need to follow similar steps for the other dependencies. However, each dependency may have its specific requirements and additional flags for the configure script. Consult the documentation for each dependency for the exact steps to build and install it.\n\nKeep in mind that this process can be complex, and some dependencies may require additional libraries or tools. If you encounter difficulties or are unable to install certain dependencies, consider reaching out to your system administrator for assistance.\n\n\n\n\nBrando Miranda\nalso tell me how to do this step locally myself without sudo priviledges\n\n\"Configure Munge:\nAsk your system administrator to configure Munge, create a secret key, and start the Munge service. This is necessary for Slurm to work.\"\nTo configure Munge locally without sudo privileges, follow these steps:\n\nDownload and compile Munge:\nbash\nCopy code\nwget https://github.com/dun/munge/releases/download/munge-0.5.14/munge-0.5.14.tar.xz\ntar xf munge-0.5.14.tar.xz\ncd munge-0.5.14\n./configure --prefix=$HOME/local --sysconfdir=$HOME/local/etc --localstatedir=$HOME/local/var\nmake\nmake install\nUpdate your PATH variable:\nbash\nCopy code\necho 'export PATH=$HOME/local/sbin:$PATH' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\nCreate a Munge key:\nbash\nCopy code\ndd if=/dev/urandom of=$HOME/local/etc/munge.key bs=1 count=1024\nchmod 400 $HOME/local/etc/munge.key\nCreate necessary directories:\nbash\nCopy code\nmkdir -p $HOME/local/etc/munge $HOME/local/var/run/munge $HOME/local/var/log/munge\nSet up Munge environment variables:\nbash\nCopy code\necho 'export MUNGEUSER=$(whoami)' &gt;&gt; ~/.bashrc\necho 'export MUNGE_PID_FILE=$HOME/local/var/run/munge/munged.pid' &gt;&gt; ~/.bashrc\necho 'export MUNGE_LOG_FILE=$HOME/local/var/log/munge/munged.log' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\nStart the Munge service:\nbash\nCopy code\nmunged --sysconfdir=$HOME/local/etc --key-file=$HOME/local/etc/munge.key --socket=$HOME/local/var/run/munge/munge.socket.2 --nthreads=2 --pidfile=$MUNGE_PID_FILE --log-file=$MUNGE_LOG_FILE --user=$MUNGEUSER\nMunge should now be running locally in your home directory. Keep in mind that since you don't have sudo privileges, you'll need to use different port numbers for Slurm, which you can configure in your slurm.conf file. Make sure to update the SlurmctldPort and SlurmdPort settings to use unused, high-numbered ports (e.g., 50000 and 50001).\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-02T03:49:33.434Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/brando\">@brando</a>,</p>\n<p>In case you have a static set of GPUs you are trying to allocate, You should be able to use your sweep\u2019s <code>config.yaml</code> to supply the <code>CUDA_VISIBLE_DEVICES</code> environment variable as an <code>$envvar</code> to each agent.</p>\n<p>I would suggest checking our documentation here:</p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/guides/sweeps/define-sweep-configuration#command-\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/c/c74534a2df0c93028c85f5aa85cbe3b185c39893.png\" class=\"site-icon\" width=\"132\" height=\"132\">\n\n      <a href=\"https://docs.wandb.ai/guides/sweeps/define-sweep-configuration#command-\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    \n\n<h3><a href=\"https://docs.wandb.ai/guides/sweeps/define-sweep-configuration#command-\" target=\"_blank\" rel=\"noopener\">Define sweep configuration | Weights &amp; Biases Documentation</a></h3>\n\n  <p>Learn how to create configuration files for sweeps.</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>Unfortunately, W&amp;B does not support resource management directly from within the SDK at the time.</p>\n<p>For a more long term solution, you could the <code>wandb agent</code> call around a bash script to check available GPUs and allocate them as such. I don\u2019t have a server with multiple GPU\u2019s to test this on, but here is a script I whipped up (with some help from our friend GPT-4), which should give you a reasonable starting point:</p>\n<pre><code class=\"lang-auto\">#!/bin/bash\n\n# Check if the nvidia-smi command exists\nif ! command -v nvidia-smi &amp;&gt; /dev/null; then\n  echo \"nvidia-smi command not found. Please install the NVIDIA drivers.\"\n  exit 1\nfi\n\n# Check if a memory limit argument is provided\nif [ -z \"$1\" ]; then\n  echo \"Usage: $0 &lt;minimum_memory_in_MB&gt;\"\n  exit 1\nfi\n\nminimum_memory_in_MB=$1\n\n# List the available NVIDIA GPUs with their memory size\nnvidia-smi --query-gpu=index,name,memory.total --format=csv,noheader | while IFS=',' read -r index name memory; do\n  memory_in_MB=${memory% MiB*}\n  \n  if [ \"$memory_in_MB\" -gt \"$minimum_memory_in_MB\" ]; then\n    echo \"Index: $index, Name: $name, Memory: $memory\"\n  fi\ndone\n</code></pre>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-05T17:16:00.068Z",
				"Answer_body": "<p>Hey Brando,</p>\n<p>I wanted to check in here if there is anything else I can help out with here?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-07T22:02:43.864Z",
				"Answer_body": "<p>Hi Brando, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Editing code during sweep",
		"Question_link": "https://community.wandb.ai/t/editing-code-during-sweep/4161",
		"Question_created_time": "2023-03-31T21:00:24.976Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 57,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I was curious about the expected behavior if code is modified during a sweep. It would seem that since each run is launched from the command line that python would re-compile my code for each of those runs. Therefore, if I changed code during a sweep, the next run that starts will use the new code. Is that correct?</p>\n<p>My particular use case is that I would like to launch a large sweep and, while that is running, work on my codebase - potentially in a different git branch than the one I launched the sweep from.</p>\n<p>Any clarification on how sweeps (and runs) interact with the codebase during runs would be appreciated.</p>\n<p>Thanks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-05T17:13:41.402Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/shababo-sci\">@shababo-sci</a> ,</p>\n<p>You have the correct idea - if you edit the code during a sweep run, the next run will use the new source code.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb fails at init (assert ports_found)",
		"Question_link": "https://community.wandb.ai/t/wandb-fails-at-init-assert-ports-found/3446",
		"Question_created_time": "2022-11-21T05:08:28.866Z",
		"Question_answer_count": 7,
		"Question_score_count": 3,
		"Question_view_count": 1826,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>I am running into an inconsistent issue where some of my training runs (the exact same code run twice) fail. I get the following error:</p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"/project_dir/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 1040, in init\n    wi.setup(kwargs)\n  File \"/project_dir/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 151, in setup\n    self._wl = wandb_setup.setup()\n  File \"/project_dir/lib/python3.9/site-packages/wandb/sdk/wandb_setup.py\", line 320, in setup\n    ret = _setup(settings=settings)\n  File \"/project_dir/lib/python3.9/site-packages/wandb/sdk/wandb_setup.py\", line 315, in _setup\n    wl = _WandbSetup(settings=settings)\n  File \"/project_dir/lib/python3.9/site-packages/wandb/sdk/wandb_setup.py\", line 301, in __init__\n    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n  File \"/project_dir/lib/python3.9/site-packages/wandb/sdk/wandb_setup.py\", line 114, in __init__\n    self._setup()\n  File \"/project_dir/lib/python3.9/site-packages/wandb/sdk/wandb_setup.py\", line 242, in _setup\n    self._setup_manager()\n  File \"/project_dir/lib/python3.9/site-packages/wandb/sdk/wandb_setup.py\", line 273, in _setup_manager\n    self._manager = wandb_manager._Manager(\n  File \"/project_dir/lib/python3.9/site-packages/wandb/sdk/wandb_manager.py\", line 106, in __init__\n    self._service.start()\n  File \"/project_dir/lib/python3.9/site-packages/wandb/sdk/service/service.py\", line 106, in start\n    self._launch_server()\n  File \"/project_dir/lib/python3.9/site-packages/wandb/sdk/service/service.py\", line 102, in _launch_server\n    assert ports_found\nAssertionError\n</code></pre>\n<p>Unfortunately, this error occurs before a folder is created in <code>/project_dir/wandb/</code>, and as a result I cannot find a more descriptive error message in <code>debug-internal.log</code>. As mentioned, this issue only periodically happens. My code is being run on a compute cluster.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-23T00:30:06.672Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kfallah\">@kfallah</a> happy to look into this for you. Could you please provide a bit more context on the training environment</p>\n<ul>\n<li>Brief description of your experiment setup and how you are using wandb to track your experiments</li>\n<li>Example code block of this setup that might help us reproduce</li>\n<li>Wandb Client Version you are using</li>\n</ul>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-23T01:32:30.035Z",
				"Answer_body": "<p>Hello, thank you! I am using wandb 0.13.5 with python 3.9. Note that this is run on my school\u2019s compute cluster with other potential wandb users. Also, note that this issue inconsistently occurs (same code run twice sometimes fails and sometimes does not). My original workflow was an ML script with a PyTorch training loop, where after reading a .json config file, I initialize wandb with the following:</p>\n<pre><code class=\"lang-auto\">    wandb.init(\n        project=..., entity=... config=config, mode=\"offline\" if args.disable_wandb else \"online\"\n    )\n</code></pre>\n<p>I also set the <code>WANDB_API_KEY</code> environmental variable with my API key. My program would throw an error on this line.</p>\n<p>To try and fix this, I deleted the <code>wandb</code> folder in my project directory and ran <code>wandb login --relogin</code> in the command line, and then got the following error:</p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/bin/wandb\", line 8, in &lt;module&gt;\n    sys.exit(cli())\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/click/core.py\", line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/click/core.py\", line 1055, in main\n    rv = self.invoke(ctx)\n  File \"/storage/home/hcoda1/0/kfallah3/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/click/core.py\", line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/click/core.py\", line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/click/core.py\", line 760, in invoke\n    return __callback(*args, **kwargs)\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/wandb/cli/cli.py\", line 97, in wrapper\n    return func(*args, **kwargs)\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/wandb/cli/cli.py\", line 236, in login\n    wandb.setup(settings=login_settings)\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/wandb/sdk/wandb_setup.py\", line 312, in setup\n    ret = _setup(settings=settings)\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/wandb/sdk/wandb_setup.py\", line 307, in _setup\n    wl = _WandbSetup(settings=settings)\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/wandb/sdk/wandb_setup.py\", line 293, in __init__\n    _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/wandb/sdk/wandb_setup.py\", line 106, in __init__\n    self._setup()\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/wandb/sdk/wandb_setup.py\", line 234, in _setup\n    self._setup_manager()\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/wandb/sdk/wandb_setup.py\", line 265, in _setup_manager\n    self._manager = wandb_manager._Manager(\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/wandb/sdk/wandb_manager.py\", line 108, in __init__\n    self._service.start()\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/wandb/sdk/service/service.py\", line 112, in start\n    self._launch_server()\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/wandb/sdk/service/service.py\", line 108, in _launch_server\n    assert ports_found\nAssertionError\n [kfallah@login-phoenix-slurm-3]% Traceback (most recent call last):\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/wandb/__main__.py\", line 3, in &lt;module&gt;\n    cli.cli(prog_name=\"python -m wandb\")\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/click/core.py\", line 1130, in __call__\n    return self.main(*args, **kwargs)\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/click/core.py\", line 1055, in main\n    rv = self.invoke(ctx)\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/click/core.py\", line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/click/core.py\", line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/click/core.py\", line 760, in invoke\n    return __callback(*args, **kwargs)\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/wandb/cli/cli.py\", line 97, in wrapper\n    return func(*args, **kwargs)\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/wandb/cli/cli.py\", line 282, in service\n    server.serve()\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/wandb/sdk/service/server.py\", line 130, in serve\n    self._inform_used_ports(grpc_port=grpc_port, sock_port=sock_port)\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/wandb/sdk/service/server.py\", line 65, in _inform_used_ports\n    pf.write(self._port_fname)\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/site-packages/wandb/sdk/service/port_file.py\", line 25, in write\n    f = tempfile.NamedTemporaryFile(prefix=bname, dir=dname, mode=\"w\", delete=False)\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/tempfile.py\", line 545, in NamedTemporaryFile\n    (fd, name) = _mkstemp_inner(dir, prefix, suffix, flags, output_type)\n  File \"/home_dir_path/.conda/envs/manifold-contrastive/lib/python3.9/tempfile.py\", line 255, in _mkstemp_inner\n    fd = _os.open(file, flags, 0o600)\nFileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpcmvswfcr/port-105577.txt0fmtukes'\n</code></pre>\n<p>Potentially a duplicate of <a href=\"https://github.com/wandb/wandb/issues/3911\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">[CLI]: Can't find port file when using wandb.require(\"service\") \u00b7 Issue #3911 \u00b7 wandb/wandb \u00b7 GitHub</a><br>\nI have pointed this issue out to the compute cluster administrators. Any potential workarounds I could use for now would be very helpful.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-02T21:57:51.564Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kfallah\">@kfallah</a>,</p>\n<p>Thank you for the follow up. I reviewed the Github issue you referenced and as you have very similar setup as others on that thread:</p>\n<ul>\n<li>Running experiments through a cluster node (possible slow node)</li>\n<li>You are hitting an error with <a href=\"https://docs.wandb.ai/guides/track/advanced/distributed-training#enable-w-and-b-service\">wandb service</a> trying to establish port connections</li>\n</ul>\n<p>Try the following:</p>\n<ul>\n<li>Increase the port wait timeout of wandb service. Change the <a href=\"https://github.com/wandb/wandb/blob/bb45a536bfba19971df0514f6e50c34a1dbb9c57/wandb/sdk/service/service.py#L48\" rel=\"noopener nofollow ugc\">30 to 300</a> for example,  <code>time_max = time.time() + 300</code>\n</li>\n<li>Or disabling wandb service by setting the env variable <code>WANDB_</code> <code>DISABLE_SERVICE</code> <code>=True</code>. Wandb service was developed to <a href=\"https://docs.wandb.ai/guides/track/advanced/distributed-training#use-w-and-b-service-to-avoid-common-distributed-training-issues\">improve</a> the reliability of distributed jobs, and is on by default in client versions <strong>0.13.0+</strong>. If you can execute without it, disable it if it become apparent there are network related interferences.</li>\n</ul>\n<p>What happens when you try the above?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-08T17:13:15.965Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kfallah\">@kfallah</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-26T16:41:43.778Z",
				"Answer_body": "<p>Hi, I have the same issue as the OP. I increased the timeout and it did help (at least in one case right now). Context - I run some experiments on a shared server which is sometimes under heavy load (lots processes on CPU from other users). In that case the wandb.init typically fails (I can post traceback if interested). When running the same code on not so busy server it works fine.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-20T18:06:46.411Z",
				"Answer_body": "<p>hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> is there a better way to increase the timeout value without changing the source code? like an environment variable or something else?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-04T11:04:47.923Z",
				"Answer_body": "<p>A feature where we can increase the timeout value without changing the source code would be useful.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Tensorboard sync shows incorrect number of steps",
		"Question_link": "https://community.wandb.ai/t/tensorboard-sync-shows-incorrect-number-of-steps/881",
		"Question_created_time": "2021-10-07T14:37:22.784Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 309,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello!</p>\n<p>I have observed a strange behavior when synchronizing tensorboard runs. Two runs have different lengths in steps when uploaded on wandb. And both are wrong. They are probably different due to multiprocessing. Although, if I open the tensorboard tab in the wandb interface it shows both results correctly.</p>\n<p>I can provide the files if I figure out how to attach them here. Or should I upload it somewhere else?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-07T15:49:08.654Z",
				"Answer_body": "<p>Since I haven\u2019t figured out how to paste log files here, I uploaded them to the third-party website.<br>\n<a href=\"https://turb.cc/0u2o0f8crljr.html\" rel=\"noopener nofollow ugc\">first</a><br>\n<a href=\"https://turb.cc/57d3s8c2fbd1.html\" rel=\"noopener nofollow ugc\">second</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-27T19:58:09.480Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/martslaaf\">@martslaaf</a> , apologies for the delay here. I couldn\u2019t find the files you attached above.</p>\n<p>Are you using <code>sync_tensorboard</code> and making calls to <code>wandb.log</code> as well in your script? If yes, this makes the default <code>step</code> to be incorrect, but the <code>global_step</code> <strong>x-axis</strong> trick should work for the tensorboard metrics.  Also, you might want to add <code>global_step</code> to the <code>wandb.log</code> calls you make if you want to line them up with the tensorboard metrics.</p>\n<p>However, if this doesn\u2019t fix your issue, could you please share:</p>\n<ol>\n<li>your debug bundle log (debug.log and debug-internal.log) for the runs having different steps?</li>\n<li>a minimal script as in how you\u2019re logging, this could help us in reproducing the issue on our side.</li>\n</ol>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-30T20:41:40.095Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/martslaaf\">@martslaaf</a> , we wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-04T07:04:58.638Z",
				"Answer_body": "<p>Hello,<br>\ndoes that mean I should NOT call wandb.log but instead log everything directly to tensorboard, so that wandb can extract the information in the background automatically (sync_tensorboard = True) ?</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Mention a member on report not available",
		"Question_link": "https://community.wandb.ai/t/mention-a-member-on-report-not-available/4097",
		"Question_created_time": "2023-03-22T12:34:04.060Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 70,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I have a report created within a team and I cannot mention members on a comment.<br>\nThe sentence \u201c@ to mention a user\u201d does not appear.<br>\nHow so?</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/1/108393fb2785ee51505faae38fd4a433ab622848.png\" alt=\"Screenshot 2023-03-22 at 12.47.54\" data-base62-sha1=\"2m5xJUrxAoEP6UK6xEvumbFKuY8\" width=\"405\" height=\"307\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-24T00:13:07.709Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tommasodelorenzo\">@tommasodelorenzo</a> , I verified the functionality works on chrome browser. Could try clearing the cache/history for that report and try again.  In chrome:</p>\n<ol>\n<li>Right Click &gt; Inspect</li>\n<li>Move mouse cursor over refresh button in top left corner of your browser window. Right Click &gt; Empty Cache and Hard Reload</li>\n</ol>\n<p>If you are using a different browser, which one are you using?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-24T09:54:46.457Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> Thanks for the reply. However I had already tried the hard reload in chrome, but nothing. Not working.<br>\nI tried also with Safari: same story.<br>\nHere is the screenshot of the sharing panel. It should be ok, shouldn\u2019t it?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/6/63fee853952e2e0862db8ca16b2e9cb5c7345044.png\" data-download-href=\"/uploads/short-url/egBpcjmD2JkDutas5fgjdUEaQHq.png?dl=1\" title=\"Screenshot 2023-03-24 at 10.57.56\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/6/63fee853952e2e0862db8ca16b2e9cb5c7345044_2_690x401.png\" alt=\"Screenshot 2023-03-24 at 10.57.56\" data-base62-sha1=\"egBpcjmD2JkDutas5fgjdUEaQHq\" width=\"690\" height=\"401\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/6/63fee853952e2e0862db8ca16b2e9cb5c7345044_2_690x401.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/6/63fee853952e2e0862db8ca16b2e9cb5c7345044_2_1035x601.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/6/63fee853952e2e0862db8ca16b2e9cb5c7345044.png 2x\" data-dominant-color=\"F2F3F5\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2023-03-24 at 10.57.56</span><span class=\"informations\">1084\u00d7630 38.4 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-03T22:00:31.597Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tommasodelorenzo\">@tommasodelorenzo</a> , appreciate your patience. I am able to verify this behavior. It appears when a team has only 2 users, you cannot @ mention users in the report. With teams having &gt;= 3 users, the mentions will work. I\u2019m flagging this as a bug for our app team to review. I will keep you updated once I\u2019ve heard back from them.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-03T22:35:09.667Z",
				"Answer_body": "<p>Great! Thank you. Glad to contribute getting WandB better <img src=\"https://emoji.discourse-cdn.com/twitter/wink.png?v=12\" title=\":wink:\" class=\"emoji\" alt=\":wink:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to watch the activations of a model?",
		"Question_link": "https://community.wandb.ai/t/how-to-watch-the-activations-of-a-model/4101",
		"Question_created_time": "2023-03-22T19:32:51.262Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 81,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I feel divergence is better predicted by activations (or update step) than weights or gradients. How to watch that?</p>\n<p>ref: <a href=\"https://github.com/wandb/wandb/issues/5218\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">[Feature]: watch activations &amp; update value, besides weights and gradients \u00b7 Issue #5218 \u00b7 wandb/wandb \u00b7 GitHub</a></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-03T21:19:55.996Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/brando\">@brando</a> , thanks for writing in. Here\u2019s an <a href=\"https://wandb.ai/ayush-thakur/interpretability/reports/Interpretability-in-Deep-Learning-With-W-B-CAM-and-GradCAM--Vmlldzo5MTIyNw?galleryTag=posts#implement-feature-logger\">example</a> report in which the activations are logged in TensorFlow.<br>\nWe don\u2019t have any examples w.r.t. gradients of activations yet, but if you\u2019re looking for model explainability - this <a href=\"https://wandb.ai/ayush-thakur/interpretability/reports/Interpretability-in-Deep-Learning-With-W-B-CAM-and-GradCAM--Vmlldzo5MTIyNw?galleryTag=posts\">GradCAM</a> report might be of interest to you. Currently, we don\u2019t have any way of using <code>wandb.watch</code> for this use-case, however, I\u2019ll file a feature request to extend the functionality of <code>wandb.watch</code> .<br>\nAlso, if you could provide some additional details/context about the use case would be very helpful as well.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "I wonder if the utility to aggregate over multiple seeds was added or not in later releases",
		"Question_link": "https://community.wandb.ai/t/i-wonder-if-the-utility-to-aggregate-over-multiple-seeds-was-added-or-not-in-later-releases/4169",
		"Question_created_time": "2023-04-02T22:57:29.445Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 58,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Based on this question posted 2 years back : <a href=\"https://community.wandb.ai/t/sweeps-with-multiple-seeds-for-the-same-config-values/1077\">Sweeps with multiple seeds for the same config values</a>, I wonder if the utility to sweep over different parameters meanwhile also being able to aggregate over different seeds was added to wandb or not. If yes, is there a tutorial/helper link which I can follow to use this facility.</p>\n<p>Thanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-10T17:52:50.749Z",
				"Answer_body": "<p>Hi Dhawal,</p>\n<p>This feature is still in development because it was backlogged for a while. Would you mind talking a bit about your use case, so I can submit it directly to our eng team so they can see that it is still in demand?</p>\n<p>Cheers,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-14T00:29:57.490Z",
				"Answer_body": "<p>Hi Dhawal,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-19T15:11:11.035Z",
				"Answer_body": "<p>Hi Dhawal, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Could not add summary columns for display in Table",
		"Question_link": "https://community.wandb.ai/t/could-not-add-summary-columns-for-display-in-table/3841",
		"Question_created_time": "2023-02-08T04:57:53.139Z",
		"Question_answer_count": 4,
		"Question_score_count": 2,
		"Question_view_count": 205,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Related: <a href=\"https://community.wandb.ai/t/unable-to-manage-columns-in-project-run-table/3551/4\" class=\"inline-onebox\">Unable to manage columns in project run table - #4 by artsiom</a></p>\n<p>I was unable to make step metric columns visible in the Table view. I tried logging metrics both via <code>run.log</code> and <code>wandb.log</code>, as well as refreshing the page in my browser. When attempting to drag and drop a column name from \u201cHidden Columns\u201d to \u201cVisible Columns\u201d (see the screenshot), a gap is created, but on mouse release the column name returns to \u201cHidden Columns\u201d. Clicking on column names to move them to \u201cVisible\u201d does not work either. The logged values appear in the web interface elsewhere. Manipulation with non-metric columns (e.g. config values, name, state etc) worked flawlessly as expected.</p>\n<p>The problem remained <em>for a fraction of a minute</em> after I logged a summary metric using <code>wandb.summary[...] = ...</code>. In particular, I tried moving all columns by pressing \u201cShow all\u201d, but without any visible result, and I closed the pop-up (on the screenshot). Suddenly, after 10 or so seconds, all columns became visible.</p>\n<p>The problem is similar to the one in the linked post. Unlike there, in my case, refreshing the web-page did not seem to help. I\u2019ll take a wild guess and suggest possible reasons for the bug:</p>\n<ol>\n<li>Something was going on in your back-end, and I had to wait till all necessary data validation or calculations are completed that would enable adding metric columns. This is unacceptably long time (several minutes), within which I was able to read relevant reference, search issues, and do a couple of empty test runs to see what\u2019s going on.</li>\n<li>There is a bug which prevents conversion step metrics to summary metrics unless at least one summary metric is explicitly added via <code>wandb.summary</code>.</li>\n</ol>\n<p>I hope you will be able to get to the bottom of it and fix it.</p>\n<p>I hope this helps.</p>\n<p>Regards,</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/2ee6cd9cf398c018ac88a42196119a096fc12763.png\" data-download-href=\"/uploads/short-url/6GUslld1E38x1uAv9m6acBIMSwH.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/2ee6cd9cf398c018ac88a42196119a096fc12763.png\" alt=\"image\" data-base62-sha1=\"6GUslld1E38x1uAv9m6acBIMSwH\" width=\"518\" height=\"500\" data-dominant-color=\"F7F8F8\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">667\u00d7643 8.92 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-08T16:33:21.045Z",
				"Answer_body": "<p>Just to clarify. Treat this message as an incomplete bug report. The problem caused me some trouble, but disappeared on its own. Other people experienced the same problem in the past, so it is real.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-10T01:16:20.254Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/avm21\">@avm21</a> , thank you for writing in with your observations and providing a detailed report. This was a known issue in the past that was addressed by our app team. We will run some tests on our end and flag this for review. I will keep you updated with our findings.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-10T20:51:21.055Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/avm21\">@avm21</a> , I\u2019ve been able to to consistently  reproduce this behavior on my end and flagged it as a bug. I will update you on a timeline for a fix once I have additional info. Thanks again for the insight!</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-04-02T17:38:59.815Z",
				"Answer_body": "<p>This actually happened to me when I used the Edge browser, reloading the page or restarting the project did not solve the issue. However, the issue disappeared somehow after reloading the table again after around 30 mins. So maybe it has to do with the browser? I never had this issue while using Chrome/Brave.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Parse additional arguments to the program when running the wandb agent command from the command line",
		"Question_link": "https://community.wandb.ai/t/parse-additional-arguments-to-the-program-when-running-the-wandb-agent-command-from-the-command-line/4010",
		"Question_created_time": "2023-03-06T20:09:58.859Z",
		"Question_answer_count": 8,
		"Question_score_count": 0,
		"Question_view_count": 315,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Is it possible to parse additional arguments to the program when running the wandb agent command from the command line?</p>\n<p>For example, suppose I have a script <code>train.py</code> that takes a <code>--gpu_idx</code> argument to specify the GPU index, and I want to run the script with different GPUs using the WandB agent. Can I pass the <code>--gpu_idx</code> argument as a key-value pair when running the <code>wandb agent</code> command?</p>\n<p><code>wandb agent &lt;ID&gt;  --gpu_idx 1</code></p>\n<p>In the training script, I have something like:</p>\n<pre><code class=\"lang-auto\">import wandb\nimport argparse\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--gpu_idx', type=int, default=1)\nargs = parser.parse_args()\n\nwandb.init()\nwandb.config.update(args)\n\n# train model with the learning rate\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-09T23:24:18.133Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/liu97\">@liu97</a> thank you for writing in! You could parse arguments to your <code>train.py</code> script, you will need to edit your <code>yaml</code> file such that it contains the <code>command</code> field too as follows:</p>\n<pre><code class=\"lang-auto\">program:\n  train.py\nmethod: grid\nparameters:\n  batch_size:\n    value: 8\n  lr:\n    value: 0.0001\ncommand:\n  - ${env}\n  - python\n  - ${program}\n  - \"--gpu_idx=1\"\n</code></pre>\n<p>Would this work for you? Please also check our <a href=\"https://docs.wandb.ai/guides/sweeps/define-sweep-configuration#command-\">documentation here</a> on the <code>command</code>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-10T01:45:38.328Z",
				"Answer_body": "<p>Thank you very much! I will try it out.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-15T10:10:28.087Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/liu97\">@liu97</a> just checking in here to see if that resolved the issue, and if you had any other questions? thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-15T14:52:46.587Z",
				"Answer_body": "<p>Hi, I didn\u2019t run hyper-parameter search with wandb sweep recently, so did not have the chance to test it. I will post updates here.</p>\n<p>Just a question, after creating a sweep agent using the above example yaml file,  it will use --gpu_idx=1 to sweep through hyper parameters by default. If I run this agent on other machines, where GPU 0 instead of GPU 1 is available, would I be able to parse this --gpu_idx=0 when running <code>wandb agent sweep_id --gpu_idx=0</code>?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-20T20:37:48.277Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/liu97\">@liu97</a> thanks for the additional context. In that case you won\u2019t be able to do this as you will be using the same <code>yaml</code> for all agents. What you could do though in a multi-gpu environment is to specify the GPU as follows:</p>\n<pre><code class=\"lang-auto\">CUDA_VISIBLE_DEVICES=0 wandb agent sweep_ID\n</code></pre>\n<p>Would this work for you? Please also check <a href=\"https://docs.wandb.ai/guides/sweeps/parallelize-agents#parallelize-on-a-multi-gpu-machine\">this docs page</a> for more information.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-03-24T10:22:03.039Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/liu97\">@liu97</a> I wanted to follow up with you and see if you\u2019ve managed to run the <code>wandb agent</code> in multiple GPUs? and if there are any further questions that we could help with.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-29T18:31:47.694Z",
				"Answer_body": "<p>Hi Thanos, thank you very much for the help all the way! I appreciate it. Setting CUDA_VISIBLE_DEVICES is a viable way for me.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-02T13:32:45.550Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/liu97\">@liu97</a> perfect, glad to hear this! I will now close this ticket, and please feel free to contact us again if you have any other questions.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sweeps: Waiting for W&B process to finish... (failed 1)",
		"Question_link": "https://community.wandb.ai/t/sweeps-waiting-for-w-b-process-to-finish-failed-1/4012",
		"Question_created_time": "2023-03-07T03:01:12.571Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 569,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi everyone,<br>\nI am trying to sweep my hyperparameters for my TensorFlow model. I am using Bayes as the sweeping method.</p>\n<p>In my <code>train()</code> function, I have several <code>.fit()</code> methods as I am training a progressive GAN and I am required to call <code>model.fit()</code> several times.</p>\n<p>After completing the first <code>model.fit()</code> successfully, the error</p>\n<pre><code class=\"lang-auto\">Waiting for W&amp;B process to finish... (failed 1)\n</code></pre>\n<p>What should I do?</p>\n<p>I followed this tutorial here to use Wandb sweeps: <a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/tensorflow/Hyperparameter_Optimization_in_TensorFlow_using_W%26B_Sweeps.ipynb#scrollTo=_7eXIA019vAG\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Google Colab</a></p>\n<p>And here is a look at my <code>sweep_train()</code> function:</p>\n<pre><code class=\"lang-auto\">def sweep_train(config_defaults=None):\n\n    # Initialize wandb with a sample project name\n    run = wandb.init(config=config_defaults, resume=True)  \n    \n    pgan = PGAN(latent_dim = NOISE_DIM, d_steps =  wandb.config.D_STEPS)\n    \n\n    cbk = GANMonitor(num_img = NUM_IMGS_GENERATE, latent_dim = NOISE_DIM)\n\n    cbk.set_steps(steps_per_epoch = STEPS_PER_EPOCH, epochs = wandb.config.EPOCHS) # 110, 6\n    cbk.set_prefix(prefix='0_init')\n\n    \n    \n    train(wandb.config.G_LR, wandb.config.D_LR, wandb.config.R_LR, wandb.config.EPOCHS, wandb.config.D_STEPS, cbk, pgan)\n\n    run.finish()\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-09T21:27:38.403Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/aryamohan23\">@aryamohan23</a>!</p>\n<p>Is there more details to the traceback such as right before <code>Waiting for W&amp;B process to finish... (failed 1)</code>? There should be a traceback into the code detailing what error is causing the project to fail.  W&amp;B will also upload all runs regardless of status (success, failed, crashed, etc.) so the <code>(failed 1)</code> message is indicating the state of the run.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-14T23:03:58.919Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-15T10:50:16.432Z",
				"Answer_body": "<p>Hello, sorry for the delay. I get this error:</p>\n<p><code>wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)</code></p>\n<p>I realized it was a network issue and so i set my wandb to offline mode. But even when I try to sync it with a <code>wandb sync</code> i get the same error.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-20T21:25:41.379Z",
				"Answer_body": "<p>Hello Arya!</p>\n<p>Could you provide the <code>debug.log</code> and <code>debug-internal.log</code> fore the run? They should be located in the <code>wandb</code> folder in the same directory as where the script was run. The <code>wandb</code> folder has folders formatted as <code>run-DATETIME-ID</code> associated with a single run. Could you retrieve the <code>debug.log</code> and <code>debug-internal.log</code> files from one of these folders specifically from the run that is having issues?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-23T23:45:19.022Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-01T13:23:11.171Z",
				"Answer_body": "<p>Hello, sorry to come back to this late.<br>\nI seem to have resolved this one issue, it seems to just a VPN issue.<br>\nHowever, now my logged images are not reflectibng on the \u2018Charts\u2019 tab on my dashboard, even though all my images can be seen in the \u2018files\u2019 tab.<br>\nThe run also shows as \u2018crashed\u2019 even though the files are logged.</p>\n<p>Attached the debug and debug-internal files:<br>\n<a href=\"https://drive.google.com/file/d/1V692jCGDPkgrtJOVM7bGPrqFEi2GikYZ/view?usp=sharing\" rel=\"noopener nofollow ugc\">debug-internal</a><br>\n<a href=\"https://drive.google.com/file/d/1dG6-PWeJhRLVzDhTOBLIpi9N20tVMk6-/view?usp=sharing\" rel=\"noopener nofollow ugc\">debug</a></p>\n<p>Thanks in advance</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How do I print the wandb sweep url in python?",
		"Question_link": "https://community.wandb.ai/t/how-do-i-print-the-wandb-sweep-url-in-python/4133",
		"Question_created_time": "2023-03-27T04:42:56.317Z",
		"Question_answer_count": 5,
		"Question_score_count": 2,
		"Question_view_count": 210,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>For runs I do:</p>\n<pre><code class=\"lang-auto\">wandb.run.get_url()\n</code></pre>\n<p>how do I do the same but for sweeps given the <code>sweep_id</code>?</p>\n<hr>\n<p>fulls sample run:</p>\n<pre><code class=\"lang-auto\">\"\"\"\nMain Idea:\n- create sweep with a sweep config &amp; get sweep_id for the agents (note, this creates a sweep in wandb's website)\n- create agent to run a setting of hps by giving it the sweep_id (that mataches the sweep in the wandb website)\n- keep running agents with sweep_id until you're done\n\nnote:\n    - Each individual training session with a specific set of hyperparameters in a sweep is considered a wandb run.\n\nref:\n    - read: https://docs.wandb.ai/guides/sweeps\n\"\"\"\n\nimport wandb\nfrom pprint import pprint\nimport math\nimport torch\n\nsweep_config: dict = {\n    \"project\": \"playground\",\n    \"entity\": \"your_wanbd_username\",\n    \"name\": \"my-ultimate-sweep\",\n    \"metric\":\n        {\"name\": \"train_loss\",\n         \"goal\": \"minimize\"}\n    ,\n    \"method\": \"random\",\n    \"parameters\": None,  # not set yet\n}\n\nparameters = {\n    'optimizer': {\n        'values': ['adam', 'adafactor']}\n    ,\n    'scheduler': {\n        'values': ['cosine', 'none']}  # todo, think how to do\n    ,\n    'lr': {\n        \"distribution\": \"log_uniform_values\",\n        \"min\": 1e-6,\n        \"max\": 0.2}\n    ,\n    'batch_size': {\n        # integers between 32 and 256\n        # with evenly-distributed logarithms\n        'distribution': 'q_log_uniform_values',\n        'q': 8,\n        'min': 32,\n        'max': 256,\n    }\n    ,\n    # it's often the case that some hps we don't want to vary in the run e.g. num_its\n    'num_its': {'value': 5}\n}\nsweep_config['parameters'] = parameters\npprint(sweep_config)\n\n# create sweep in wandb's website &amp; get sweep_id to create agents that run a single agent with a set of hps\nsweep_id = wandb.sweep(sweep_config)\nprint(f'{sweep_id=}')\n\n\ndef my_train_func():\n    # read the current value of parameter \"a\" from wandb.config\n    # I don't think we need the group since the sweep name is already the group\n    run = wandb.init(config=sweep_config)\n    print(f'{run=}')\n    pprint(f'{wandb.config=}')\n    lr = wandb.config.lr\n    num_its = wandb.config.num_its\n\n    train_loss: float = 8.0 + torch.rand(1).item()\n    for i in range(num_its):\n        # get a random update step from the range [0.0, 1.0] using torch\n        update_step: float = lr * torch.rand(1).item()\n        wandb.log({\"lr\": lr, \"train_loss\": train_loss - update_step})\n    run.finish()\n\n\n# run the sweep, The cell below will launch an agent that runs train 5 times, usingly the randomly-generated hyperparameter values returned by the Sweep Controller.\nwandb.agent(sweep_id, function=my_train_func, count=5)\n</code></pre>\n<p>cross: <a href=\"https://stackoverflow.com/questions/75852199/how-do-i-print-the-wandb-sweep-url-in-python\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">machine learning - How do I print the wandb sweep url in python? - Stack Overflow</a></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-27T13:26:08.164Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/brando\">@brando</a> thank you for your question. Here is how you can get_sweep_url:</p>\n<pre><code class=\"lang-auto\">get_sweep_url() -&gt; Optional[str]\n</code></pre>\n<p>You can find more <a href=\"https://docs.wandb.ai/ref/python/run#get_sweep_url\">in our docs</a>. I hope this helps!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-27T16:27:29.666Z",
				"Answer_body": "<p>like <code>wandb.get_sweep_url()</code>? Thanks!</p>\n<p><a href=\"https://docs.wandb.ai/ref/python/run?_gl=1*uk130d*_ga*MTYwMTE3MDYzNS4xNjUyMjI2MTE1*_ga_JH1SJHJQXJ*MTY4MDAxNTk2Ny4yNjguMS4xNjgwMDE2MTMyLjQ3LjAuMA\" class=\"inline-onebox\">Run | Weights &amp; Biases Documentation</a>\u2026<span class=\"hashtag\">#get_sweep_url</span></p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-03-31T00:29:01.105Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/corey-strausman\">@corey-strausman</a></p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py\", line 1496, in _exec\n    pydev_imports.execfile(file, globals, locals)  # execute the script\n  File \"/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\n  File \"/Users/brandomiranda/ultimate-utils/tutorials_for_myself/my_wandb_uu/my_wandb_sweeps_uu/sweep_everything_in_python_even_config/sweep_everything_in_python.py\", line 64, in &lt;module&gt;\n    wandb.get_sweep_url()\nAttributeError: module 'wandb' has no attribute 'get_sweep_url'\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-31T00:33:20.671Z",
				"Answer_body": "<p>didn\u2019t work even after pip install --upgrade wandb</p>\n<pre><code class=\"lang-auto\">(pycoq-ejgallego) brandomiranda~/pycoq-ejgallego \u276f pip install --upgrade wandb\n\nRequirement already satisfied: wandb in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (0.13.10)\nCollecting wandb\n  Using cached wandb-0.14.0-py3-none-any.whl (2.0 MB)\nRequirement already satisfied: typing-extensions in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (from wandb) (4.5.0)\nRequirement already satisfied: protobuf!=4.21.0,&lt;5,&gt;=3.19.0 in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (from wandb) (4.22.0)\nRequirement already satisfied: docker-pycreds&gt;=0.4.0 in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: GitPython!=3.1.29,&gt;=1.0.0 in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (from wandb) (3.1.31)\nRequirement already satisfied: sentry-sdk&gt;=1.0.0 in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (from wandb) (1.15.0)\nRequirement already satisfied: Click!=8.0.0,&gt;=7.0 in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (from wandb) (8.1.3)\nRequirement already satisfied: setuptools in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (from wandb) (65.6.3)\nRequirement already satisfied: PyYAML in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (from wandb) (6.0)\nRequirement already satisfied: pathtools in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: setproctitle in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (from wandb) (1.3.2)\nRequirement already satisfied: requests&lt;3,&gt;=2.0.0 in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (from wandb) (2.28.2)\nRequirement already satisfied: psutil&gt;=5.0.0 in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (from wandb) (5.9.4)\nRequirement already satisfied: appdirs&gt;=1.4.3 in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: six&gt;=1.4.0 in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (from docker-pycreds&gt;=0.4.0-&gt;wandb) (1.16.0)\nRequirement already satisfied: gitdb&lt;5,&gt;=4.0.1 in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (from GitPython!=3.1.29,&gt;=1.0.0-&gt;wandb) (4.0.10)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (3.4)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (3.0.1)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (1.26.14)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (2022.12.7)\nRequirement already satisfied: smmap&lt;6,&gt;=3.0.1 in /Users/brandomiranda/opt/anaconda3/envs/pycoq-ejgallego/lib/python3.9/site-packages (from gitdb&lt;5,&gt;=4.0.1-&gt;GitPython!=3.1.29,&gt;=1.0.0-&gt;wandb) (5.0.0)\nInstalling collected packages: wandb\n  Attempting uninstall: wandb\n    Found existing installation: wandb 0.13.10\n    Uninstalling wandb-0.13.10:\n      Successfully uninstalled wandb-0.13.10\nSuccessfully installed wandb-0.14.0\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-01T09:49:22.236Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/brando\">@brando</a>, you can get the sweep id by using our <a href=\"https://docs.wandb.ai/ref/python/public-api/sweep\">public API</a> like:</p>\n<pre><code class=\"lang-auto\">import wandb\napi = wandb.Api()\nsweep = api.sweep('entity/project/sweep_id')\nsweep.url\n</code></pre>\n<p>Please let me know if this works!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Confused about wandb launch usage with docker",
		"Question_link": "https://community.wandb.ai/t/confused-about-wandb-launch-usage-with-docker/4119",
		"Question_created_time": "2023-03-24T13:34:34.173Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 100,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Sorry if this is covered by docs  couldn\u2019t understand something about wandb jobs (wandb launch);</p>\n<p>Basically, does the Dockerfile itself must have an <code>Entrypoint</code> attr, which runs a program? Or is it enough to have a docker image which has WANDB_DOCKER, wandb_api_key env variable set, having a python directory codebase which can start wandb runs?? (can\u2019t create a job this way though\u2026), if possible without logging the code.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-24T21:12:02.111Z",
				"Answer_body": "<p>Cleared:<br>\nYeah, the Dockerfile should be complete end to end such that just running the docker file should run the program, it must have <code>Entrypoint</code> attr in the Dockerfile, which actually can be changed from the overrides when we pass it to queue.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-04-01T03:56:51.337Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/saishreddyk\">@saishreddyk</a>, great to see you\u2019re using Launch and you found the answer! Just for reference, I\u2019m sharing two links to our docs <a href=\"https://docs.wandb.ai/ref/cli/wandb-launch\">here</a> and <a href=\"https://docs.wandb.ai/guides/launch\">here</a> in case they\u2019re useful.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to enable logging of each trial separately?",
		"Question_link": "https://community.wandb.ai/t/how-to-enable-logging-of-each-trial-separately/4115",
		"Question_created_time": "2023-03-24T08:25:15.454Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 99,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Within my optuna study, I want that each trial is separately logged by wandb. Currently, the study is run and the end result is tracked in my wandb dashboard. Instead of showing each trial run separately, the end result over all epochs is shown. So, wandb makes one run out of multiple runs.</p>\n<p>I found the following <a href=\"https://optuna.readthedocs.io/en/stable/_modules/optuna/integration/wandb.html\" rel=\"noopener nofollow ugc\">docs</a> in optuna:</p>\n<pre><code>Weights &amp; Biases logging in multirun mode.\n\n    .. code::\n</code></pre>\n<pre><code class=\"lang-auto\">            import optuna\n            from optuna.integration.wandb import WeightsAndBiasesCallback\n\n            wandb_kwargs = {\"project\": \"my-project\"}\n            wandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs, as_multirun=True)\n\n\n            @wandbc.track_in_wandb()\n            def objective(trial):\n                x = trial.suggest_float(\"x\", -10, 10)\n                return (x - 2) ** 2\n\n\n            study = optuna.create_study()\n            study.optimize(objective, n_trials=10, callbacks=[wandbc])\n\n</code></pre>\n<p>I implemented this line of code yet it produces the following error:</p>\n<p><code>ConfigError: Attempted to change value of key \"learning_rate\" from 5e-05 to     0.0005657929921495451 If you really want to do this, pass allow_val_change=True to config.update()    wandb: Waiting for W&amp;B process to finish... (failed 1).</code></p>\n<p>Did anyone succeed in implementing logging per trial in a multi-trial study?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-24T09:38:02.813Z",
				"Answer_body": "<p>I actually solved it now:<br>\nIt seems that the optimizer that i used caused errors in the generation of a value for the learning rate when starting a new trial. Once I took the optimizer back out, the follwing implementation worked and generated separate logs in my wandb dashboard:</p>\n<pre><code class=\"lang-auto\">wandb_kwargs = {\"project\": \"my-project\"}\nwandbc = WeightsAndBiasesCallback(wandb_kwargs=wandb_kwargs, as_multirun=True)\n\n@wandbc.track_in_wandb()\ndef objective(trial):\n    \n    training_args = Seq2SeqTrainingArguments( \n        \"tuning\", \n        num_train_epochs=1,            \n        # num_train_epochs = trial.suggest_categorical('num_epochs', [3, 5, 8]),\n        per_device_eval_batch_size=3, \n        per_device_train_batch_size=3, \n        learning_rate=  trial.suggest_float('learning_rate', low=0.00004, high=0.0001, step=0.0005, log=False),             \n        # per_device_train_batch_size= trial.suggest_categorical('batch_size', [6, 8, 12, 18]),       \n        # per_device_eval_batch_size= trial.suggest_categorical('batch_size', [6, 8, 12, 18]),  \n        disable_tqdm=True, \n        predict_with_generate=True,\n        gradient_accumulation_steps=4,\n        # gradient_checkpointing=True,\n        # weight_decay= False\n        seed = 12, \n        warmup_steps=5,\n        # evaluation and logging\n        evaluation_strategy = \"epoch\",\n        save_strategy = \"epoch\",\n        save_total_limit=1,\n        logging_strategy=\"epoch\",\n        logging_steps = 1, \n        load_best_model_at_end=True,\n        metric_for_best_model = \"eval_loss\",\n        # use_cache=False,\n        push_to_hub=False,\n        fp16=False,\n        remove_unused_columns=True\n    )\n    # optimizer = Adafactor(\n    #     t5dmodel.parameters(),\n    #     lr=trial.suggest_float('learning_rate', low=4e-5, high=0.0001),  #   ('learning_rate', 1e-6, 1e-3),\n    #     # weight_decay=trial.suggest_float('weight_decay', WD_MIN, WD_CEIL),   \n    #     # lr=1e-3,\n    #     eps=(1e-30, 1e-3),\n    #     clip_threshold=1.0,\n    #     decay_rate=-0.8,\n    #     beta1=None,\n    #     # weight_decay= False\n    #     weight_decay=0.1,\n    #     relative_step=False,\n    #     scale_parameter=False,\n    #     warmup_init=False,\n    # )\n    \n    # lr_scheduler = AdafactorSchedule(optimizer)\n    data_collator = DataCollatorForSeq2Seq(tokenizer, model=t5dmodel)\n    trainer = Seq2SeqTrainer(model=t5dmodel,\n                            args=training_args,\n                            train_dataset=tokenized_train_dataset['train'],\n                            eval_dataset=tokenized_val_dataset['validation'],\n                            data_collator=data_collator,\n                            tokenizer=tokenizer,\n                           #  optimizers=(optimizer, lr_scheduler)\n                            )       \n    \n    trainer.train()\n    scores = trainer.evaluate() \n    return scores['eval_loss']\n\nif __name__ == '__main__':\n    t5dmodel = AutoModelForSeq2SeqLM.from_pretrained(\"yhavinga/t5-base-dutch\",  use_cache=False) \n    tokenizer = AutoTokenizer.from_pretrained(\"yhavinga/t5-base-dutch\", additional_special_tokens=None)\n    \n    features = {\n    'WordRatioFeature': {'target_ratio': 0.8},\n    'CharRatioFeature': {'target_ratio': 0.8},\n    'LevenshteinRatioFeature': {'target_ratio': 0.8},\n    'WordRankRatioFeature': {'target_ratio': 0.8},\n    'DependencyTreeDepthRatioFeature': {'target_ratio': 0.8}\n    }\n    \n    trainset_processed = get_train_data(WIKILARGE_PROCESSED, 0, 10)  \n    print(trainset_processed)\n    valset_processed = get_validation_data(WIKILARGE_PROCESSED, 0,7)\n    print(valset_processed)\n    tokenized_train_dataset = trainset_processed.map((tokenize_train), batched=True, batch_size=1)\n    tokenized_val_dataset =  valset_processed.map((tokenize_train), batched=True, batch_size=1)   \n    print('Triggering Optuna study')\n    study = optuna.create_study( direction='minimize', pruner=optuna.pruners.MedianPruner()) \n    study.optimize(objective, n_trials=4,callbacks=[wandbc],  gc_after_trial=True)\n</code></pre>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-04-01T03:50:35.267Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/there-seidl\">@there-seidl</a>, great to see you actually solved the issue! Thanks a lot for sharing the solution as well!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Histogram produced by wandb.plot.histogram is incorrect",
		"Question_link": "https://community.wandb.ai/t/histogram-produced-by-wandb-plot-histogram-is-incorrect/4113",
		"Question_created_time": "2023-03-24T06:25:32.422Z",
		"Question_answer_count": 1,
		"Question_score_count": 1,
		"Question_view_count": 62,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am trying to plot a histogram over a score I am computing. I followed these guidelines to log a single histogram at the end of training:</p>\n<ul>\n<li><a href=\"https://wandb.ai/wandb/plots/reports/Creating-Custom-Histograms-With-Weights-Biases--VmlldzoyNzE0NzM\" class=\"inline-onebox\">Weights &amp; Biases</a></li>\n<li><a href=\"https://docs.wandb.ai/guides/track/log/plots\" class=\"inline-onebox\">Log and Track Plots from W&amp;B Experiments.</a></li>\n</ul>\n<p>The underlying data table is correctly uploaded to my run but the displayed histogram (figure left side) is clearly wrong as verified by both Excel (figure top right side) and matplotlib (figure bottom right side).</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/5/52885b1751484d6ea113becd22b13762ef119f60.jpeg\" data-download-href=\"/uploads/short-url/bM7icxbxnxRxjaK1cAFVeOkdgmQ.jpeg?dl=1\" title=\"Screenshot 2023-03-24 at 2.24.38 AM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/52885b1751484d6ea113becd22b13762ef119f60_2_690x357.jpeg\" alt=\"Screenshot 2023-03-24 at 2.24.38 AM\" data-base62-sha1=\"bM7icxbxnxRxjaK1cAFVeOkdgmQ\" width=\"690\" height=\"357\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/52885b1751484d6ea113becd22b13762ef119f60_2_690x357.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/52885b1751484d6ea113becd22b13762ef119f60_2_1035x535.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/52885b1751484d6ea113becd22b13762ef119f60_2_1380x714.jpeg 2x\" data-dominant-color=\"97A6B5\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2023-03-24 at 2.24.38 AM</span><span class=\"informations\">1920\u00d7994 73.5 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Any hints towards debugging this would be highly appreciated!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-04-01T03:39:29.490Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/stephan-rabanser\">@stephan-rabanser</a>, thanks for reporting this! It is actually an already know bug on our end related to the vega spec so I\u2019ll add you to the ticket as well. Thanks!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Even though I'm active in university, I'm blocked by the 250 hour limit",
		"Question_link": "https://community.wandb.ai/t/even-though-im-active-in-university-im-blocked-by-the-250-hour-limit/4152",
		"Question_created_time": "2023-03-29T20:32:35.857Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 56,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, currently experiencing restrictions due to 250 hour tracking.</p>\n<aside class=\"quote\" data-post=\"1\" data-topic=\"4029\">\n  <div class=\"title\">\n    <div class=\"quote-controls\"></div>\n    <img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/v/f6c823/40.png\" class=\"avatar\">\n    <a href=\"https://community.wandb.ai/t/how-to-delete-a-project-in-an-organization-that-has-exceeded-the-250-hour-limit/4029\">How to delete a project in an organization that has exceeded the 250 hour limit?</a> <a class=\"badge-wrapper  bullet\" href=\"/c/w-b-support/36\"><span class=\"badge-category-bg\" style=\"background-color: #0088CC;\"></span><span style=\"\" data-drop-close=\"true\" class=\"badge-category clear-badge\" title=\"Ask your W&amp;B questions here. Let us know if you have an issue and one of our engineers or community experts will get back to you ASAP. If you have an urgent W&amp;B issue, please contact our support team at support@wandb.com\">W&amp;B Help</span></a>\n  </div>\n  <blockquote>\n    I have an organization that has exceeded the 250 hour limit. I am trying to go into the organization, to delete \nan old project so I can stop exceeding the limit. But it looks like the UI is not letting me. \nIs there a way I delete old projects in my organization to go back under the limit?\n  </blockquote>\n</aside>\n\n<p>Looking at it here, I know that I can use it as free if it\u2019s a student account, but I wonder if it\u2019s possible to check it.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-31T16:02:26.157Z",
				"Answer_body": "<p>Hi there! I have updated your account to academic which will not have a tracked hour limit. Please let me know if you have any other questions.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Tensorflow + Transformers Hyperparameter Sweeping Example(s)",
		"Question_link": "https://community.wandb.ai/t/tensorflow-transformers-hyperparameter-sweeping-example-s/4121",
		"Question_created_time": "2023-03-24T18:50:36.386Z",
		"Question_answer_count": 3,
		"Question_score_count": 3,
		"Question_view_count": 80,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello all,</p>\n<p>I followed along with the new MLOps course and I am trying to adapt what I learned there to a different framework/scenario. I am working with a sequence-to-sequence transformer model (NLP), utilizing Tensorflow as the framework. I am at the point where I would like to leverage a sweep to optimize hyperparameters. I am struggling to find a good example. Can anyone point me to something that is close to what I am trying to achieve? Mainly how to perform sweeps with TF and then I can go from there. Thank you!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-25T11:26:49.838Z",
				"Answer_body": "<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://wandb.ai/matt24/vit-snacks-sweeps/reports/Hyperparameter-Search-for-HuggingFace-Transformer-Models--VmlldzoyMTUxNTg0#exploring-hyperparameter-combinations-with-sweeps\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/7a7a7077833cb4ec4be6e63ad7c2db322d3e15a6.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https://wandb.ai/matt24/vit-snacks-sweeps/reports/Hyperparameter-Search-for-HuggingFace-Transformer-Models--VmlldzoyMTUxNTg0#exploring-hyperparameter-combinations-with-sweeps\" target=\"_blank\" rel=\"noopener\" title=\"01:29PM - 11 June 2022\">W&amp;B \u2013 11 Jun 22</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/b/b408ee6ebfad13993f303a606680131b22cbf628.png\" class=\"thumbnail onebox-avatar\" width=\"300\" height=\"300\">\n\n<h3><a href=\"https://wandb.ai/matt24/vit-snacks-sweeps/reports/Hyperparameter-Search-for-HuggingFace-Transformer-Models--VmlldzoyMTUxNTg0#exploring-hyperparameter-combinations-with-sweeps\" target=\"_blank\" rel=\"noopener\">Hyperparameter Search for HuggingFace Transformer Models</a></h3>\n\n  <p>In this article, we will explore how to perform hyperparameter search for pre-trained HuggingFace transformer models, making use of Weights &amp; Biases Sweeps.</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>Here\u2019s a post from the a W&amp;B community member that is close to what you want. It uses PyTorch with HF but the concepts are very similar. Hope that helps.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-25T11:29:01.082Z",
				"Answer_body": "<p>Here\u2019s a Tensorflow &amp; sweeps example too:</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/tensorflow/Hyperparameter_Optimization_in_TensorFlow_using_W%26B_Sweeps.ipynb\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/3/3e5c2051302f053e1cd296bf3253621e8845d4fd.png\" class=\"site-icon\" width=\"16\" height=\"16\">\n\n      <a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/tensorflow/Hyperparameter_Optimization_in_TensorFlow_using_W%26B_Sweeps.ipynb\" target=\"_blank\" rel=\"noopener\">colab.research.google.com</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/5/5b77e9737d5f8f8bc5f7b35e7fc0f8088fd1ebd8.png\" class=\"thumbnail onebox-avatar\" width=\"260\" height=\"260\">\n\n<h3><a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/tensorflow/Hyperparameter_Optimization_in_TensorFlow_using_W%26B_Sweeps.ipynb\" target=\"_blank\" rel=\"noopener\">Google Colaboratory</a></h3>\n\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-27T17:17:20.663Z",
				"Answer_body": "<p>Thank you <a class=\"mention\" href=\"/u/_scott\">@_scott</a> - very helpful!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "With TB SummaryWriter only getting sys logs, no log_scalar shows up",
		"Question_link": "https://community.wandb.ai/t/with-tb-summarywriter-only-getting-sys-logs-no-log-scalar-shows-up/4089",
		"Question_created_time": "2023-03-21T17:31:01.821Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 103,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I have an OS stable diffusion fine tuner and use Tensorboard locally and am trying to integrate wandb with existing code that is largely just calling writer.log_scalar(\u2026).  I setup my SummaryWriter then call wandb.init, but I\u2019m having all sorts of odd behavior where most of the time only system monitors (gpu temp, memory etc) are logged to wandb and my calls to writer.log_scalar simply never get recorded to wandb.</p>\n<p>Everything seems to be failing silently and I don\u2019t know why nothing gets recorded.  The other day testing on two machines it works from one but not the other, and it is also now working from Colab notebook instances or docker container runs.</p>\n<p>The runs on <a href=\"http://wandb.com\" rel=\"noopener nofollow ugc\">wandb.com</a> are there and created, console output shows it fires up and links me to the run and the run URL works, etc.  But, only system monitors are showing up, none of my items logged with summarywriter, at least a vast majority of instances.</p>\n<p>At one point it was working fine, then started to stop working.  I had thought it was an issue with trying to pass in a dict of dicts to config={main: args, opt_cfg: optimizer_cfg} but even passing in dummy objects or simply config=args it fails.  At one point wanb.init was done before writer instantiation, and that was fixed, so I\u2019m not sure at what point things went sideways as I mostly run locally but many users use Colab/Vast, etc and wandb is a significantly better solution for those cases.</p>\n<p>Is there any log file or debugging I can use to troubleshoot this?  Unfortunately it is just not working and doing so silently without any feedback.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-24T14:56:17.747Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/panopstor\">@panopstor</a> are you using <code>wandb.init(project='my-project', sync_tensorboard=True)</code> or are using <code>wandb.tensorboard.patch(root_logdir=\"&lt;logging_directory&gt;\")</code>to enable Tensorboard syncing?</p>\n<p>When using <code>sync_tensorboard=True</code> we attempt to find the event files but if the SDK can\u2019t find them then you end up with runs similar to what you are seeing. System metrics logged but no model metrics. I would recommend switching to <code>wandb.tensorboard.patch(root_logdir=\"&lt;logging_directory&gt;\"</code> so you can explicitly point to the TB files. Here are the <a href=\"https://docs.wandb.ai/guides/integrations/tensorboard#how-do-i-configure-tensorboard-when-im-using-it-with-wandb\">docs</a> for this.</p>\n<p>Also, you can sync the runs that didn\u2019t upload model metrics by using the CLI command <code>wandb sync --sync-tensorboard &lt;path/to/tb/files&gt;</code></p>\n<p>Let me know if this helps or if you still see the issue.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-25T20:37:07.765Z",
				"Answer_body": "<p>Hi thanks for the help.</p>\n<p>I got it working with the patch instead of init with sync, but now all my logged parameters are prepended with the logdir, ex.<br>\n<code>vg_sd15_wandb5_20230325-154049/loss/log_step</code><br>\nwhen I\u2019m calling<br>\n<code>log_writer.add_scalar(tag=\"loss/log_step\", scalar_value=loss_local, global_step=global_step)</code></p>\n<p>and where \u201cvg_sd15_wandb5_20230325-154049\u201d must be picked up from the root_logdir I suppose.  Is there any way to suppress this?  It\u2019s a lot of noise.</p>\n<p>I\u2019m still passing in project_name and run_name to init which WandB respects so the prefix to the parameters doesn\u2019t serve much purpose.  I tried toggling tensorboard_x, torch, and save args on patch(\u2026).  I pulled wandb off github and its not obvious where the prefix is being applied.  Is that by design?</p>\n<p>I\u2019m using the latest tensorboard 2.12.0 and wandb 0.14.0.  This was working a while back just using sync_tensorboard and broke, the previous behavior was as desired.</p>\n<p>Or maybe you can provide hints on why normal <code>sync_tensorboard=True</code> wouldn\u2019t work?  I\u2019m currently trying to dig through the wandb code to see if I can figure it out\u2026  If there are any debug log flags I could send into wandb maybe that would help me.  I\u2019d like to know why it isn\u2019t picking anything up on its own with normal sync.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-25T21:41:27.814Z",
				"Answer_body": "<p>Ah I think I found the magic combination to work for my training script.  For posterity in case anyone else has the issues and stumbles on this post.  This is a raw torch trainer.</p>\n<p>(ex log_folder = \u201clogs/projectname20230325_124523\u201d and contains the events.out.tfevents\u2026 file)</p>\n<pre><code class=\"lang-auto\">        wandb.tensorboard.patch(root_logdir=log_folder, pytorch=False, tensorboard_x=False, save=False)\n        wandb_run = wandb.init(\n            project=args.project_name,\n            config={\"main_cfg\": vars(args), \"optimizer_cfg\": optimizer_config},\n            name=args.run_name\n            )\n        log_writer = SummaryWriter(log_dir=log_folder...)\n\n        log_writer.add_scalar(...)\n</code></pre>\n<p>tensorboard 2.12.0<br>\nwandb 0.14.0</p>",
				"Answer_has_accepted": true
			}
		]
	},
	{
		"Question_title": "Custom Tooltip",
		"Question_link": "https://community.wandb.ai/t/custom-tooltip/3750",
		"Question_created_time": "2023-01-25T16:33:09.701Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 172,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello!</p>\n<p>I am trying to plot a ROC curve and is working nicely! Now I want to modify the tooltip to add the Threshold value. I think that can be done with Weave and the Table of Thresholds, False and True Positive Rates but I don\u2019t have too much knowledge about Weave.</p>\n<p>Example run with Plot and Table: <a href=\"https://wandb.ai/marioparreno/personal-test/runs/n0nlj2l6?workspace=user-marioparreno\" class=\"inline-onebox\">Weights &amp; Biases</a></p>\n<p>Weave expression here (at Tooltip field)?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/205eb72f31cdc9af99a39aee3af3e0072dcc9005.png\" data-download-href=\"/uploads/short-url/4CmcMGALP0orfkQwaBtzXnvcRlH.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/205eb72f31cdc9af99a39aee3af3e0072dcc9005_2_353x500.png\" alt=\"image\" data-base62-sha1=\"4CmcMGALP0orfkQwaBtzXnvcRlH\" width=\"353\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/205eb72f31cdc9af99a39aee3af3e0072dcc9005_2_353x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/205eb72f31cdc9af99a39aee3af3e0072dcc9005.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/205eb72f31cdc9af99a39aee3af3e0072dcc9005.png 2x\" data-dominant-color=\"F9F9F9\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">387\u00d7547 23.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-25T17:34:44.042Z",
				"Answer_body": "<p>The code I used to generate the tables:</p>\n<pre><code class=\"lang-python\">def roc_curve_multilabel(\n    y_true=None, y_probas=None, labels=None, title=None\n):\n    y_true = np.array(y_true)\n    y_probas = np.array(y_probas)\n    \n    classes = np.arange(0, y_true.shape[1])\n    \n    fpr, tpr, thr = dict(), dict(), dict()\n    \n    for c in classes:\n        if labels is not None and (\n            isinstance(classes[c], int) or isinstance(classes[0], np.integer)\n        ):\n            class_label = labels[classes[c]]\n        else:\n            class_label = classes[c]\n        fpr[class_label], tpr[class_label], thr[class_label] = sklearn_metrics.roc_curve(\n            y_true[..., c], y_probas[..., c]\n        )\n    \n    df = pd.DataFrame(\n        {\n            \"class\": np.hstack([[k] * len(v) for k, v in fpr.items()]),\n            \"fpr\": np.hstack(list(fpr.values())),\n            \"tpr\": np.hstack(list(tpr.values())),\n            \"thr\": np.hstack(list(thr.values())),\n        }\n    )\n    \n    df = df.round(3)\n\n    if len(df) &gt; wandb.Table.MAX_ROWS:\n        wandb.termwarn(\n            \"wandb uses only %d data points to create the plots.\" % wandb.Table.MAX_ROWS\n        )\n        # different sampling could be applied, possibly to ensure endpoints are kept\n        df = sklearn_utils.resample(\n            df,\n            replace=False,\n            n_samples=wandb.Table.MAX_ROWS,\n            random_state=42,\n            stratify=df[\"class\"],\n        ).sort_values([\"fpr\", \"tpr\", \"class\"])\n\n    table = wandb.Table(dataframe=df)\n    title = title or \"ROC\"\n    return wandb.plot_table(\n        \"wandb/area-under-curve/v0\",\n        table,\n        {\"x\": \"fpr\", \"y\": \"tpr\", \"class\": \"class\"},\n        {\n            \"title\": title,\n            \"x-axis-title\": \"False positive rate\",\n            \"y-axis-title\": \"True positive rate\",\n        },\n    )\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-27T22:48:54.037Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/marioparreno\">@marioparreno</a>, it looks like this is a bug affecting just line plots in Weave. The tooltip expression should be <code>row[\"thr\"]</code> but this isn\u2019t currently working with line plots. If you change the mark to \u201cpoint\u201d you will get the expected behavior. I\u2019ve reported this to our engineering team so we can get a fix on this.</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/b/bc0b60e829efe3943c642c37d57d61e2ccc25e81.png\" alt=\"Screen Shot 2023-01-27 at 3.47.59 PM\" data-base62-sha1=\"qPw8R9obwJu3b5epYhIx9aWVG25\" width=\"280\" height=\"139\"></p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/f/f75a22414abe87b79e1b925246cb879eef97b7cf.png\" alt=\"Screen Shot 2023-01-27 at 3.47.48 PM\" data-base62-sha1=\"zib2QO2tasOxusEECbtUCL99bQz\" width=\"462\" height=\"102\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-28T08:22:55.955Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nathank\">@nathank</a> , thanks! In the meantime could you help me with something related?</p>\n<p>At the tooltip I would like to put more info, as the fpr, tpr and class. I can add expressions simply with \u2018+\u2019, but I want to add new lines. I tried \u2018\\n\u2019 and \u2018<br>\u2019 but not works. Examples:</p>\n<pre><code class=\"lang-auto\">row[\"fpr\"].toString.prepend(\"FPR: \") + \"\\n\" + row[\"thr\"].toString.prepend(\"Threshold: \")\n</code></pre>\n<p>I understand the \u2018<br>\u2019 is not treated as HTML but with \u2018\\n\u2019 something strange occurs too, the tooltip is just \u2018-\u2019.</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/e/e7c0a2bea9d2acac4e72a60c38346208007b19a9.png\" alt=\"err\" data-base62-sha1=\"x4b0YKAyprj2ZKOmUESfpx58Y09\" width=\"250\" height=\"170\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-25T18:19:41.130Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/nathank\">@nathank</a>, sorry for the ping, but do we have any advance? <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to log the learning rate with pytorch lightning when using a scheduler?",
		"Question_link": "https://community.wandb.ai/t/how-to-log-the-learning-rate-with-pytorch-lightning-when-using-a-scheduler/3964",
		"Question_created_time": "2023-02-27T17:20:25.190Z",
		"Question_answer_count": 5,
		"Question_score_count": 4,
		"Question_view_count": 462,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I\u2019ve been trying to find some documentation, I don\u2019t want to save all the hyperparameters each epoch, just the learning rate.<br>\nWould be so great if you can help me out.</p>\n<p>Cheers,</p>\n<p>Oli</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-01T21:11:46.963Z",
				"Answer_body": "<p>Hi Oli,</p>\n<p>Just double checking, are you talking about running sweeps?</p>\n<p>Cheers,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-07T15:15:46.872Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-10T17:04:43.048Z",
				"Answer_body": "<p>Hi Oliver, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-23T20:20:46.363Z",
				"Answer_body": "<p>I\u2019m also wondering how this is done! Whether within a sweep configuration or not - when using a lr scheduler, I am trying to track the lr at epoch during training, as it is now dynamic. Even within a sweep, you will have some initial lr  determined during the sweep, but it will not stay constant for the duration of training.</p>\n<p>edit:</p>\n<p>The example on the <a href=\"https://pytorch-lightning.readthedocs.io/en/1.2.10/api/pytorch_lightning.callbacks.lr_monitor.html#learning-rate-monitor\" rel=\"noopener nofollow ugc\">lightning site here</a> worked for me:</p>\n<pre><code class=\"lang-auto\">&gt;&gt;&gt; from pytorch_lightning.callbacks import LearningRateMonitor\n&gt;&gt;&gt; lr_monitor = LearningRateMonitor(logging_interval='step')\n&gt;&gt;&gt; trainer = Trainer(callbacks=[lr_monitor])\n</code></pre>\n<p>Passing the <code>WandBLogger</code> to the trainer I see my lr is logged on the <code>wandb</code> dashboard.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-03-24T16:36:06.155Z",
				"Answer_body": "<p>Hi there, yes,<br>\nsorry for the late reply, I didn\u2019t get any notification from your answers, but now I got one from Chris\u2019s.</p>\n<p>What worked for chris also worked for me.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Access local filesystem artifacts without downloading",
		"Question_link": "https://community.wandb.ai/t/access-local-filesystem-artifacts-without-downloading/4092",
		"Question_created_time": "2023-03-21T20:04:30.135Z",
		"Question_answer_count": 2,
		"Question_score_count": 1,
		"Question_view_count": 57,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I would like to use Artifacts to log and track the usage of my datasets. These datasets live on a local filesystem. I was able to create a reference artifact, but the problem I encounter is that the only way to access the original local filepath is to call <code>artifact.download()</code> or <code>artifact.get_path(name).ref</code>.</p>\n<p>Calling <code>download()</code> doesn\u2019t work for me because the files are <em>aleady</em> local and very large. I definitely do not want to make a copy.</p>\n<p>On the other hand, <code>artifact.get_path(name).ref</code> works, but this entails <em>already</em> knowing the path of the file since that is what is used for <code>name</code> as far as I can tell. I suppose even if I could set a custom <code>name</code> for each file in the directory (can you?), I\u2019m not sure one can retrieve those names from the artifact itself and therefore they would need to be known by anyone using the artifact. Ideally one would <em>only</em> need the artifact\u2019s name and from there you can see the local file paths for all of the files in that artifact.</p>\n<p>In case it\u2019s helpful, I add these files to the artifact by doing:</p>\n<p><code>artifact.add_reference(name='data_folder',uri='file://path/to/directory')</code></p>\n<p>When I use the artifact, I can do</p>\n<p><code>files = artifact.files()</code>,</p>\n<p>which returns an iterable of all of the files, but these <code>File</code> objects do not have a way to get the path/uri either.</p>\n<p>Is there anyway to do this?</p>\n<p>Thanks and let me know if you have any questions that will help you understand or solve this.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-21T20:58:03.728Z",
				"Answer_body": "<p>Ope\u2026 I just figured it out\u2026 seems like you can introspectively obtain the <code>ref</code>s by looking through the <code>manifest</code>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-23T19:49:06.006Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/shababo-sci\">@shababo-sci</a> thanks for writing in, and glad to hear you figure this out! I will also post a code snippet here for any future reference.</p>\n<pre><code class=\"lang-auto\">api = wandb.Api()\nartifact = api.artifact('entity/project/artifact-name:alias', type='artifact-type')\n\n# First option\nfor k,v in artifact.manifest.entries.items():\n  print(v.ref)\n\n# Second option\nfor f in artifact.files():\n  print(f.url)\n</code></pre>\n<p>I hope this helps, feel free to ask us any further questions!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "GPU utilization on wandb",
		"Question_link": "https://community.wandb.ai/t/gpu-utilization-on-wandb/4108",
		"Question_created_time": "2023-03-23T17:25:52.393Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 54,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi there, My wandb report shows I  have a GPU utilization of 20%<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/5/52a56bccd41a7994da3efe429526490a257be7e8.png\" data-download-href=\"/uploads/short-url/bN7z4j28TJlXjIAXwCs9IrIhbqo.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/52a56bccd41a7994da3efe429526490a257be7e8_2_690x408.png\" alt=\"image\" data-base62-sha1=\"bN7z4j28TJlXjIAXwCs9IrIhbqo\" width=\"690\" height=\"408\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/52a56bccd41a7994da3efe429526490a257be7e8_2_690x408.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/52a56bccd41a7994da3efe429526490a257be7e8_2_1035x612.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/52a56bccd41a7994da3efe429526490a257be7e8_2_1380x816.png 2x\" data-dominant-color=\"FDFCFC\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1699\u00d71006 86.2 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nwhile  my nvidia-smi prints the below<br>\n\u00b1----------------------------------------------------------------------------+<br>\n| Processes:                                                                  |<br>\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |<br>\n|        ID   ID                                                   Usage      |<br>\n|=============================================================================|<br>\n|    0   N/A  N/A      1296      G   /usr/lib/xorg/Xorg                 56MiB |<br>\n|    0   N/A  N/A      1591      G   /usr/bin/gnome-shell               10MiB |<br>\n|    0   N/A  N/A    203353      C   python3                          3432MiB |<br>\nI use gunpowder and pytorch for training, not sure if anyone has encountered this and have a solution. Any insight on this appreciated.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-28T19:21:56.947Z",
				"Answer_body": "<p>Hey Pranathi,</p>\n<p>Thanks so much for your question and for highlighting this.</p>\n<p>Can you attach debug logs from your wandb run directory and a URL to your workspace where you are seeing this?</p>\n<p>Would you also be able to give some detail on what environment?</p>\n<p>look forward to hearing back from you.</p>\n<p>WandB support.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-05T15:20:37.951Z",
				"Answer_body": "<p>Hey Pranathi,</p>\n<p>Wanted to check in and see if this was still an issue for you.</p>\n<p>Look forward to hearing back,</p>\n<p>Best wishes,</p>\n<p>Frida</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Setting panel style for a whole project",
		"Question_link": "https://community.wandb.ai/t/setting-panel-style-for-a-whole-project/4095",
		"Question_created_time": "2023-03-22T09:56:57.991Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 48,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m tracking a whole bunch of metrics for deep RL experiments I\u2019m running. These are high variance, as is the nature in deep RL.</p>\n<p>Per default, wandb will produce shaded error bands based on min/max values. This is sort of pointless for my experiments due to the outliers, so I\u2019m switching to standard error based bands.</p>\n<p>Right now I\u2019m doing this manually for each individual plot. This can get pretty annoying, e.g. when running hyperparameter sweeps. Is there a way to set a specific panel style as default for a project that I\u2019m just not finding?</p>\n<p>If this is not possible, I think it would be a nice quality-of-life improvement to add.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-23T10:15:42.914Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/timo_kk\">@timo_kk</a>, thanks for writing in! You can use <a href=\"https://docs.wandb.ai/guides/app/features/custom-charts\">custom charts</a> to log  your plots with your desired layout so you don\u2019t need to modify it manually in the UI. Please let me know if this would work for you!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-28T21:36:55.965Z",
				"Answer_body": "<p>Hi Timo,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Set the WANDB_PROJECT environment variable cannot name the project properly",
		"Question_link": "https://community.wandb.ai/t/set-the-wandb-project-environment-variable-cannot-name-the-project-properly/4055",
		"Question_created_time": "2023-03-14T03:42:40.341Z",
		"Question_answer_count": 3,
		"Question_score_count": 2,
		"Question_view_count": 228,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi everyone, I am using wandb with Huggingface in a AWS Sagemaker notebook and I am refering to the tutorial here: <a href=\"https://docs.wandb.ai/guides/integrations/huggingface\" class=\"inline-onebox\">Hugging Face Transformers | Weights &amp; Biases Documentation</a>.</p>\n<p>I tried to set the <code>WANDB_PROJECT</code> environment variable before setting up the <code>huggingface_estimator</code>, which will call <code>train.py</code>.</p>\n<p><code>train.py</code> is where I initialize the <code>Trainer</code>. The above tutorial mentions to make sure to set the project name before initializing the <code>Trainer</code>, and I think I am doing this correctly here.</p>\n<p>Here are some useful snippets of my code.</p>\n<pre><code class=\"lang-auto\">import wandb\nwandb.login()\n\nWANDB_PROJECT=my_project_name\n\n...\n\nhuggingface_estimator = HuggingFace(\n  image_uri=image_uri,\n  entry_point='train.py',\n  source_dir='./scripts',\n  instance_type='ml.g4dn.xlarge',\n  instance_count=1,\n  role=role,\n  py_version='py39',\n  hyperparameters=hyperparameters,\n)\n</code></pre>\n<p>train.py</p>\n<pre><code class=\"lang-auto\">    training_args = TrainingArguments(\n        output_dir=args.output_dir,\n        per_device_train_batch_size=args.per_device_train_batch_size,\n        num_train_epochs=args.epochs,\n        learning_rate=args.learning_rate,\n        save_strategy=\"epoch\",\n        logging_strategy='epoch',\n        report_to=\"wandb\",\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        data_collator=collate_fn,\n        tokenizer=image_processor,\n    )\n\n    trainer.train()\n</code></pre>\n<p>I would greatly appreciate any guidance or advice on how to resolve this issue. Thank you very much in advance for your help!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-14T13:09:43.235Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/oschan77\">@oschan77</a> ,</p>\n<p>You can set the project name in your script like so:</p>\n<pre><code class=\"lang-auto\">import os\nos.environ[\"WANDB_PROJECT\"] = \"sentiment-analysis\"\n</code></pre>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-03-14T13:27:14.603Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/oschan77\">@oschan77</a> thanks for writing in! The <code>WANDB_PROJECT</code> needs to be exported as an environment variable as Morgan suggested above. Since you\u2019ve mentioned you\u2019re working in AWS Sagemaker notebook, another alternative would be:<br>\n<code>%env WANDB_PROJECT=project_name</code></p>\n<p>Please let us know if these would work for you, and if you have any other questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-22T23:38:16.365Z",
				"Answer_body": "<p>I\u2019m having some similar issues\u2026 in my case I am using a huggingfaces trainer class, and using a RAY backend.  I am getting the (very annoying) case where the project name is set properly on the head node, but I think the wandb instances on the worker nodes are just defaulting to huggingface, making it very confusing.  I\u2019ve tried several iterations, but I am still confused.  I would like to be able to change the  WANDB_PROJECT when I execute the code.  I am running things as docker containers, so as a sanity check, I restarted everything, made sure the environment variable was set before I started things, and I got one run to work.  But this is brittle, as having to restart all my nodes to change an environment variable is not ideal.</p>\n<p>I\u2019ve seen some (confusing) posts regarding wandb ignoring certain environment variables if wandb.init() is run as well.  What\u2019s been happening is that I\u2019ll see my hyper parameter sweep start, and the first job gets the proper name, but the 5 other processes (running on other nodes), have the default hugging faces name.   I realize using backend=\u201cray\u201d may add another layer of complexity, but I didn\u2019t think running ray from more than one machine should be considered an edge case.  I have basically pieced this together from several of the docs I saw online ( including <a href=\"https://docs.ray.io/en/latest/tune/examples/pbt_transformers.html\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Using |\ud83e\udd17| Huggingface Transformers with Tune \u2014 Ray 2.3.0</a> )</p>\n<p>os.environ[\u2018WANDB_PROJECT\u2019] = \u201cstainParamSweep\u201d</p>\n<p>wandb.login()<br>\nwandb.init(project=\u2018stainParamSweep\u2019)</p>\n<p>gpus_per_trial=0.5<br>\nbest_model = trainer.hyperparameter_search(<br>\nhp_space=lambda _: tune_config,<br>\nbackend=\u201cray\u201d,<br>\nresources_per_trial={\u201ccpu\u201d: 8, \u201cgpu\u201d: gpus_per_trial},<br>\ncheckpoint_score_attr=\u201ctraining_iteration\u201d,<br>\nlocal_dir=\u201c/data/ray_results_tuning/\u201d,<br>\nname=\u201ctune_transformer_pbt\u201d,<br>\nlog_to_file=True,<br>\nn_trials=100,<br>\nprogress_reporter= reporter)</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "ROC and PR curves logging",
		"Question_link": "https://community.wandb.ai/t/roc-and-pr-curves-logging/3686",
		"Question_created_time": "2023-01-11T23:43:03.638Z",
		"Question_answer_count": 13,
		"Question_score_count": 0,
		"Question_view_count": 230,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi!<br>\nI am using (and loving) Wandb so far <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<p>Today I wanted to log my validation roc and pr curves, and I used the command:</p>\n<pre><code class=\"lang-auto\">wandb.log({\"val_roc\" : wandb.plot.roc_curve(target_list.numpy(), pred_list.numpy(), labels=None, classes_to_plot=None)})\n</code></pre>\n<p>My task is a binary classification, and my data is in numpy array in the format [m,n], with m the number of samples and n the number of classes, my case 1 (i.e. [128,1]).</p>\n<p>I am encountering the following error:</p>\n<pre><code class=\"lang-auto\">  File \"/home/mgiordano/.pyenv/versions/3.8.11/envs/sepsis/lib/python3.8/site-packages/wandb/plot/roc_curve.py\", line 74, in roc_curve\n    y_true, y_probas[..., i], pos_label=classes[i]\nIndexError: index 1 is out of bounds for axis 1 with size 1\n</code></pre>\n<p>I think Wandb is trying to compute the curves on other classes, that are not there. Am I missing something?</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-17T21:09:02.303Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mgiordy\">@mgiordy</a>, happy to help. Could you verify the shape of your arrays that you are passing to the plotting function. We\u2019ll review the roc chart function for any errors and get back to you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-18T00:17:44.982Z",
				"Answer_body": "<p>Hey, thanks for replying! The dimension is (430,1)  <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-23T18:01:21.715Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/mgiordy\">@mgiordy</a> !</p>\n<p>The ROC curve expects a <code>[n, 2]</code> array  - A value for positive classification and a value for negative classification.</p>\n<p>You most likely want to create a second axis with value <code>1 - axis_1</code>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-24T17:33:50.829Z",
				"Answer_body": "<p>Hey thanks for getting back <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><br>\nCan it be that it expects a <code>[n,2]</code> array for the prediction and a <code>[n]</code> array with the ground truth? In that case no error is reported, otherwise if I pass the same format to both I get the following error: <code>ValueError: multilabel-indicator format is not supported</code>.</p>\n<p>Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-25T16:28:14.162Z",
				"Answer_body": "<p>I think for your case the <code>y_true </code> array must be flattened =&gt; (430,)</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-30T03:41:23.056Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/mgiordy\">@mgiordy</a>, wanted to check in if this is resolved or if there is anything else that I can do for you.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-31T13:13:12.166Z",
				"Answer_body": "<p>Hey! Yeah now it works <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><br>\nHowever, the visualisation on the wandb website is kinda off\u2026 The ROC curves had fpr and tpr on the wrong axes (I\u2019ve fixed it, but shouldn\u2019t the software be able to show it by default?), while the PR curve just looks wrong. Please note that sklearn is showing them correctly\u2026</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/8/874d0a18d925f088aca0eead3d429fbcfbd12484.jpeg\" data-download-href=\"/uploads/short-url/jiVvUI5gWSQNBN78U7RSEexX6ks.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/874d0a18d925f088aca0eead3d429fbcfbd12484_2_690x390.jpeg\" alt=\"image\" data-base62-sha1=\"jiVvUI5gWSQNBN78U7RSEexX6ks\" width=\"690\" height=\"390\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/874d0a18d925f088aca0eead3d429fbcfbd12484_2_690x390.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/8/874d0a18d925f088aca0eead3d429fbcfbd12484.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/8/874d0a18d925f088aca0eead3d429fbcfbd12484.jpeg 2x\" data-dominant-color=\"F9FAFB\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">888\u00d7502 41.7 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-01T17:39:12.920Z",
				"Answer_body": "<p>Thanks for letting us know! Could you share a code snippet with a reproduction of the broken PR chart and what you would have expected to see? I can take that information back to our engineering team to have this fixed.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-05T19:51:55.388Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/mgiordy\">@mgiordy</a>,</p>\n<p>I hope you\u2019re doing well. Wanted to check in if you have had a chance to look into the PR chart issue. Looking forward to hearing from you soon.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-07T16:24:48.585Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mgiordy\">@mgiordy</a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-27T22:24:41.447Z",
				"Answer_body": "<p>Hi Ramit,</p>\n<p>Sorry for my late reply!</p>\n<p>Running the script on the right is the expected behaviour, on the left what I get from the wandb online interface:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/3/3b903709be94c67e66b74711b5f244da83c37704.png\" data-download-href=\"/uploads/short-url/8uV9ipWUGh0QWDVE6JJIFKqFxI0.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/3b903709be94c67e66b74711b5f244da83c37704_2_690x394.png\" alt=\"image\" data-base62-sha1=\"8uV9ipWUGh0QWDVE6JJIFKqFxI0\" width=\"690\" height=\"394\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/3b903709be94c67e66b74711b5f244da83c37704_2_690x394.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/3b903709be94c67e66b74711b5f244da83c37704_2_1035x591.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/3b903709be94c67e66b74711b5f244da83c37704_2_1380x788.png 2x\" data-dominant-color=\"FCFCFC\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1730\u00d7990 77.3 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Please find the code snippet to reproduce the problem at the end of this message.<br>\nI hope we can sort out the issue <img src=\"https://emoji.discourse-cdn.com/twitter/wink.png?v=12\" title=\":wink:\" class=\"emoji\" alt=\":wink:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<p>Best,<br>\nMarco</p>\n<pre><code class=\"lang-auto\"># Importing stuff\nimport numpy as np\n\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import PrecisionRecallDisplay\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import LinearSVC\n\nimport matplotlib.pyplot as plt\n\nimport wandb\nwandb_project = \"test_proj\"\nwandb.init(project=wandb_project)\n\n# Loading dataset\nX, y = load_iris(return_X_y=True)\n\n# Add noisy features\nrandom_state = np.random.RandomState(0)\nn_samples, n_features = X.shape\nX = np.concatenate([X, random_state.randn(n_samples, 200 * n_features)], axis=1)\n\n# Limit to the two first classes, and split into training and test\nX_train, X_test, y_train, y_test = train_test_split(\n    X[y &lt; 2], y[y &lt; 2], test_size=0.5, random_state=random_state\n)\n\n# Scaling data and fitting classifier\nclassifier = make_pipeline(StandardScaler(), LinearSVC(random_state=random_state))\nclassifier.fit(X_train, y_train)\n\n# Getting the prediction on test set\ny_score = classifier.decision_function(X_test)\n\n# Displaying PR curve with matplotlib\ndisplay = PrecisionRecallDisplay.from_predictions(y_test, y_score, name=\"LinearSVC\")\n_ = display.ax_.set_title(\"2-class Precision-Recall curve\")\n\n# Adding one dimension to the prediction array as discussed\nones = np.ones(y_test.shape)\npred_wandb = np.stack((y_score, ones - y_score), axis=1)\ny_test = y_test[:, None]\nprint(\"Y test and Y pred dimensions:\", y_test.shape, pred_wandb.shape)\n# Logging the PR with wandb\nwandb.log({\"val_pr\" : wandb.plot.pr_curve(y_test, pred_wandb, labels=None, classes_to_plot=None)})\n\nplt.show()\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-07T11:46:52.237Z",
				"Answer_body": "<p>Hey Ramit,</p>\n<p>Any chance you had a look at this issue? <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<p>Thanks and best!</p>\n<p>Marco</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-22T12:31:16.449Z",
				"Answer_body": "<p>Hello!</p>\n<p>Any chance you had a look at this issue? <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<p>Best,<br>\nMarco</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Log in a custom panel",
		"Question_link": "https://community.wandb.ai/t/log-in-a-custom-panel/4046",
		"Question_created_time": "2023-03-10T19:45:23.179Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 90,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019d like to log directly in a given panel instead of having to create the panel manually and add the graphs manually. Is it possible ?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-13T13:14:28.024Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/rodolphelampe\">@rodolphelampe</a> thank you for writing in! Is this question specific to Custom Charts? Have you created a custom Vega preset? You could indeed log directly this chart as explained in <a href=\"https://docs.wandb.ai/guides/app/features/custom-charts#custom-presets\">this section</a> from our docs. Please also check <a href=\"https://colab.research.google.com/drive/1uXLKDmsYg7QMRVFyjUAlg-eZH2MW8yWH?usp=sharing\" rel=\"noopener nofollow ugc\">this Colab</a> with a working example. Would this work for you? if not, could you please provide a screenshot of the panel you would want to create using our Python SDK?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-16T15:06:24.344Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/rodolphelampe\">@rodolphelampe</a> just checking in here to see if you had any other questions that we could further help you with? thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-21T17:11:17.467Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/rodolphelampe\">@rodolphelampe</a> since we haven\u2019t heard back from you, I will go ahead and close this ticket for now. If you\u2019re still having any questions, please let us know and we will be happy to assist you further.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-20T17:11:20.433Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to access an organization which has completed '250' tracked hours?",
		"Question_link": "https://community.wandb.ai/t/how-to-access-an-organization-which-has-completed-250-tracked-hours/4081",
		"Question_created_time": "2023-03-18T07:27:14.564Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 143,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am a student of an organization who is working on with other persons on one of my projects. I was using wandb to log my training results but it seems like my free subscription has passed. Now, I cannot retrieve any of my previous work. It is very critical to me since I had logged everything there including Models. If you can assist in it or make this account \u2018academic\u2019, Since I am a university student. Thanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-21T16:49:03.317Z",
				"Answer_body": "<p>That\u2019s done now. Sorry for the inconvenience. Good luck with your project!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-22T14:35:54.192Z",
				"Answer_body": "<p>Let us know if this has fixed your concern <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-28T18:58:21.349Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-20T16:49:25.218Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sweep calls program with command line parameter in quotes",
		"Question_link": "https://community.wandb.ai/t/sweep-calls-program-with-command-line-parameter-in-quotes/4016",
		"Question_created_time": "2023-03-07T12:19:39.472Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 93,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>So\u2026 I found out myself during drafting this, but keep it here for reference/documentation. It\u2019s a little thing, maybe of help to someone.</p>\n<p>My <code>train.py</code> reads arguments from the command line and I want to use <code>wandb sweeps</code>.</p>\n<p>One of the arguments is <code>--config_file overwrite.args</code>. I can pass this to <code>train.py</code> and process it with <code>ArgumentParser()</code> and <code>HfArgumentParser()</code> (from Hugging Face). If I use it as part of a <code>sweep config</code>, like so:</p>\n<pre><code class=\"lang-yaml\">command:\n  - python3\n  - ${program}\n  - --config_file overwrite.args\n  - ${args}\nprogram: train.py\n</code></pre>\n<p>\u2026 <code>train.py</code> is called as <code>train.py \"--config_file overwrite.args\"</code> (<em>with</em> quotes). This is represented differently in <code>sys.argv</code> and function calls like this treat it differently as well:</p>\n<pre><code class=\"lang-python\">config_file_parser = argparse.ArgumentParser()\n    config_file_parser.add_argument(\n        \"config_file\", type=str, action=\"append\"\n    )\n    known_args, remaining_args = config_file_parser.parse_known_args()\n</code></pre>\n<p><em>Without</em> quotes, it\u2019s a <code>known_args</code>, <em>with</em> quotes it\u2019s a <code>remaining_args</code>. Additionally, at some point, the <code>HfArgumentParser()</code>throws an error <code>ValueError: Unknown configuration arguments</code> with the quoted argument.</p>\n<p>Therefore, my question/request: (how) can I get rid of the added quotes?</p>\n<p>And the simple answer is: change the sweep config to put the flag/argument on <em>two</em> lines, like so:</p>\n<pre><code class=\"lang-yaml\">command:\n  - python3\n  - ${program}\n  - --config_file\n  - overwrite.args\n  - ${args}\nprogram: train.py\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-09T15:21:24.687Z",
				"Answer_body": "<p>Hi Stephan!</p>\n<p>This is very curious. Thank you for sharing this. To confirm, instead of having this as a single arg - --config_file overwrite.args<br>\nYou split it into two and it starts working for you, right? - --config_file - overwrite.args</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-14T16:19:27.547Z",
				"Answer_body": "<p>Hi Stephan,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-17T18:22:19.746Z",
				"Answer_body": "<p>Hi Stephan, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-21T07:59:49.846Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/artsiom\">@artsiom</a>,</p>\n<p>I was not notified about your responses and only saw it by chance in the community summary e-mail. And yes, I split the arg into two, exactly the way my sweep config snippet shows. Btw, there IS an example in the docs showing that <a href=\"https://docs.wandb.ai/guides/sweeps/faq#how-do-i-use-custom-cli-commands-with-sweeps\">here</a>.</p>\n<p>Best,<br>\nStephan</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-20T08:00:43.393Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Programmatically running Sweeps using Hydra",
		"Question_link": "https://community.wandb.ai/t/programmatically-running-sweeps-using-hydra/3960",
		"Question_created_time": "2023-02-27T13:21:48.159Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 135,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>I want to write a python script which runs multiple sweeps after another.  My train.py works with hydra, which I want to keep that way. Until now I was able to run sweeps using the command line and a config.yaml file which has at the end:<br>\ncommand:</p>\n<ul>\n<li>${env}</li>\n<li>python</li>\n<li>${program}</li>\n<li>${args_no_hyphens}<br>\nIs there a way to bring this into the dictionary used in the function wandb.sweep in python?</li>\n</ul>\n<p>Thanks in advance and best regards</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-02T17:23:58.168Z",
				"Answer_body": "<p>Hi Kai,</p>\n<p>Unfortunately, there is no way of bringing that to a dictionary.</p>\n<p>The YAML-based sweep starts a whole process and a dictionary-based sweep starts a function.</p>\n<p>So, there is no \u201ccommand\u201d parameter for dictionary-based sweeps, since you call <code>wandb.agent</code> and pass a function to it.</p>\n<p>Warmly,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-08T16:47:40.980Z",
				"Answer_body": "<p>Hi Kai,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-14T14:38:49.914Z",
				"Answer_body": "<p>Hi Kai,<br>\nSince we have not heard back from you, we are going to close this request. If you would like to re-open the conversation, please let us know!</p>\n<p>Best,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-20T20:29:28.577Z",
				"Answer_body": "<p>Hi Artisom,<br>\nsorry, it seems that I didn\u2019t get a notification for your answer, thank you very much. I think I found a workaround for my problem, by adding this line to my dictionary it worked:</p>\n<p>\u201ccommand\u201d: [<br>\n\u201c${env}\u201d,<br>\n\u2018python\u2019,<br>\n\u2018${program}\u2019,<br>\n\u2018${args_no_hyphens}\u2019<br>\n],</p>\n<p>Best regards and sorry for the late reply</p>\n<p>Kai</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-19T20:29:49.125Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Server socket closed",
		"Question_link": "https://community.wandb.ai/t/server-socket-closed/4042",
		"Question_created_time": "2023-03-10T07:21:40.353Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 307,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>RUNNING VERSION 0.13.11</p>\n<p>ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine</p>\n<p>BrokenPipeError: [Errno 32] Broken pipe</p>\n<p>receiving a very long traceback error resulting in either of the above messages (windows/linux). Occurs when trying to run any sweep.  Occurs when connecting from various machines/IP addresses</p>\n<pre><code class=\"lang-auto\">def train():\n    print(1)\n\nsweep_configuration = {\n    'method' : 'grid',\n    'name' : 'Sweep',\n    'metric': {\n        'goal': 'maximize',\n        'name': 'AUC'\n    },\n    'parameters': {\n        'learn': {'values': [1, 0.1]}\n    }\n}\nsweep_id = wandb.sweep(sweep_configuration)\nwandb.agent(sweep_id, function=train, count=1)\n</code></pre>\n<pre><code class=\"lang-auto\">wandb: Agent Starting Run: gwiij466 with config:\nwandb: \tlearn: 1\nException in thread Thread-9 (_run_job):\nTraceback (most recent call last):\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 299, in _run_job\n    wandb.finish()\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 3669, in finish\n    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 368, in wrapper\n    return func(self, *args, **kwargs)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 331, in wrapper\n    return func(self, *args, **kwargs)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1843, in finish\n    return self._finish(exit_code, quiet)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1850, in _finish\n    with telemetry.context(run=self) as tel:\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\lib\\telemetry.py\", line 42, in __exit__\n    self._run._telemetry_callback(self._obj)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 689, in _telemetry_callback\n    self._telemetry_flush()\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 700, in _telemetry_flush\n    self._backend.interface._publish_telemetry(self._telemetry_obj)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 101, in _publish_telemetry\n    self._publish(rec)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n    self.send_server_request(server_req)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n\nDuring handling of the above exception, another exception occurred:\n\nConnectionAbortedError                    Traceback (most recent call last)\nFile ~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\backcall\\backcall.py:104, in callback_prototype.&lt;locals&gt;.adapt.&lt;locals&gt;.adapted(*args, **kwargs)\n    102                 kwargs.pop(name)\n    103 #            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\n--&gt; 104             return callback(*args, **kwargs)\n\nFile ~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:418, in _WandbInit._pause_backend(self)\n    416 if self.backend.interface is not None:\n    417     logger.info(\"pausing backend\")  # type: ignore\n--&gt; 418     self.backend.interface.publish_pause()\n\nFile ~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py:665, in InterfaceBase.publish_pause(self)\n    663 def publish_pause(self) -&gt; None:\n    664     pause = pb.PauseRequest()\n--&gt; 665     self._publish_pause(pause)\n\nFile ~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py:340, in InterfaceShared._publish_pause(self, pause)\n    338 def _publish_pause(self, pause: pb.PauseRequest) -&gt; None:\n    339     rec = self._make_request(pause=pause)\n--&gt; 340     self._publish(rec)\n\nFile ~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py:51, in InterfaceSock._publish(self, record, local)\n     49 def _publish(self, record: \"pb.Record\", local: Optional[bool] = None) -&gt; None:\n     50     self._assign(record)\n---&gt; 51     self._sock_client.send_record_publish(record)\n\nFile ~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:221, in SockClient.send_record_publish(self, record)\n    219 server_req = spb.ServerRequest()\n    220 server_req.record_publish.CopyFrom(record)\n--&gt; 221 self.send_server_request(server_req)\n\nFile ~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:155, in SockClient.send_server_request(self, msg)\n    154 def send_server_request(self, msg: Any) -&gt; None:\n--&gt; 155     self._send_message(msg)\n\nFile ~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:152, in SockClient._send_message(self, msg)\n    150 header = struct.pack(\"&lt;BI\", ord(\"W\"), raw_size)\n    151 with self._lock:\n--&gt; 152     self._sendall_with_error_handle(header + data)\n\nFile ~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:130, in SockClient._sendall_with_error_handle(self, data)\n    128 start_time = time.monotonic()\n    129 try:\n--&gt; 130     sent = self._sock.send(data)\n    131     # sent equal to 0 indicates a closed socket\n    132     if sent == 0:\n\nConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\nwandb: Agent Starting Run: 4maabb7r with config:\nwandb: \tlearn: 0.1\nException in thread Thread-10 (_run_job):\n### same error continuing forwards\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-10T07:42:31.482Z",
				"Answer_body": "<p>There seems to be some amount of minimal communication between the server and client, as the agent will run through multiple parameters in the sweep_configuration, but no useful data is sent back to the server and the wandb.config field is always empty in the client.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-15T13:59:05.009Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/finnhad\">@finnhad</a>,  I\u2019m able to run your code so it may be related to your network environment. Are you trying to run your experiments to <a href=\"http://wandb.ai\">wandb.ai</a> or have you setup a wandb server?</p>\n<p>Also, are all of the machines you have tried on the same network?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-20T20:21:56.284Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/finnhad\">@finnhad</a>, I just wanted to follow up and see if you were still seeing this issue? If so, could you let us know what your network infrastructure looks like and if you are using <a href=\"http://wandb.ai\">wandb.ai</a> for logging?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-19T20:22:46.040Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to delete only one billing seat?",
		"Question_link": "https://community.wandb.ai/t/how-to-delete-only-one-billing-seat/3971",
		"Question_created_time": "2023-03-01T09:58:49.548Z",
		"Question_answer_count": 8,
		"Question_score_count": 0,
		"Question_view_count": 81,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I use it in my team.<br>\nWhat should I do to reduce the bill by one person this time by reducing one person?<br>\nI can delete members, but I can\u2019t find the item for deleting sheets\u3002</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-06T16:37:16.764Z",
				"Answer_body": "<p>Hello,</p>\n<p>I am not understanding your request well enough. What team are you a part of and what is your username?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-07T11:56:12.785Z",
				"Answer_body": "<p>our team is spaceshift (company). There are 5 members.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-08T19:27:27.888Z",
				"Answer_body": "<p>Thank you! Please what is your username on your wandb account?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-09T23:09:54.848Z",
				"Answer_body": "<p>Hello,</p>\n<p>As I mentioned before I am not understanding your request. Could you please elaborate further? What do you mean by reducing the bill by one person? Do you mean deleting seats?<br>\nAlso I couldn\u2019t find spaceshift as an organization on the platform. Could you please let me know your username?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-14T19:34:56.546Z",
				"Answer_body": "<p>Hello,</p>\n<p>Could you please get back to me on your username?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-18T04:22:22.136Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"bill-morrisson\" data-post=\"5\" data-topic=\"3971\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/b/90ced4/40.png\" class=\"avatar\"> bill-morrisson:</div>\n<blockquote>\n<p>What do you mean by reducing the bill by one person?</p>\n</blockquote>\n</aside>\n<blockquote>\n<p>What do you mean by reducing the bill by one person?</p>\n</blockquote>\n<p>yes!  my username is  <code>syuchimu</code></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-18T04:23:02.220Z",
				"Answer_body": "<p>sorry, too late response.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-17T04:23:16.322Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb videos in logged tables often stop playback with error message",
		"Question_link": "https://community.wandb.ai/t/wandb-videos-in-logged-tables-often-stop-playback-with-error-message/3978",
		"Question_created_time": "2023-03-01T21:18:35.374Z",
		"Question_answer_count": 4,
		"Question_score_count": 2,
		"Question_view_count": 143,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m logging some pretty big videos in tables  (each 20-80MB) with about 50 rows with such videos. When I\u2019m looking through these on the run dashboard, they sometimes go blank with an error message: pipeline_ERROR_READ: FFmpegDemuxer: data source error</p>\n<p>I\u2019m saving the videos locally first as a webm and then wrapping the wandb video object with the filepath name to the constructor and logging the video to a row in a table.</p>\n<p>Is this a filesize issue as I\u2019m guessing? Or something else? How would I attempt to fix this issue if not a filesize related issue?</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-06T15:26:53.146Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/serialexperimentsleo\">@serialexperimentsleo</a>, sorry you are running in to this. Could you send a link to the workspace where this is happening and I can take a look?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-14T03:33:08.775Z",
				"Answer_body": "<p>Thank you for the response! If it\u2019s a private project, is there a way I can still send you the workspace/run? In the meantime, I can send you a <a href=\"https://wandb.ai/contact-estimation/contact_estimation/reports/Untitled-Report--VmlldzozNzc4MjY1?accessToken=fuyedmxqm9q1ymdhnp90xlm3ps0gsg1d77xrz2svyjrqpt3cgt5b0etjlant91gy\">public report</a> with the table of large videos where I still get the issue. The error message doesn\u2019t appear immediately, only after the videos have autoplayed for a minute or so which is the annoying part\u2026 I assumed at first it was a timeout due to video not being loaded quickly enough, but now im not so sure\u2026</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-17T21:38:28.074Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/serialexperimentsleo\">@serialexperimentsleo</a>, I see the issue. Unfortunately, I\u2019ll have to have our app team look into it to get a fix on this. I can follow up as soon as we are able to get a fix.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-16T21:38:44.403Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb cannot upload files",
		"Question_link": "https://community.wandb.ai/t/wandb-cannot-upload-files/4074",
		"Question_created_time": "2023-03-17T08:52:35.287Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 122,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>As far as I understand wandb cannot finish uploading a file after the training process ends.<br>\nLogs are like the following:</p>\n<pre><code class=\"lang-auto\">2023-03-17 10:58:41,519 INFO    SenderThread:38526 [sender.py:transition_state():587] send defer: 14\n2023-03-17 10:58:41,519 DEBUG   HandlerThread:38526 [handler.py:handle_request():144] handle_request: defer\n2023-03-17 10:58:41,520 DEBUG   SenderThread:38526 [sender.py:send():336] send: final\n2023-03-17 10:58:41,520 INFO    HandlerThread:38526 [handler.py:handle_request_defer():170] handle defer: 14\n2023-03-17 10:58:41,520 DEBUG   SenderThread:38526 [sender.py:send():336] send: footer\n2023-03-17 10:58:41,521 DEBUG   SenderThread:38526 [sender.py:send_request():363] send_request: defer\n2023-03-17 10:58:41,521 INFO    SenderThread:38526 [sender.py:send_request_defer():583] handle sender defer: 14\n2023-03-17 10:58:41,522 DEBUG   HandlerThread:38526 [handler.py:handle_request():144] handle_request: poll_exit\n2023-03-17 10:58:41,523 DEBUG   HandlerThread:38526 [handler.py:handle_request():144] handle_request: server_info\n2023-03-17 10:58:41,523 DEBUG   SenderThread:38526 [sender.py:send_request():363] send_request: poll_exit\n2023-03-17 10:58:41,524 DEBUG   HandlerThread:38526 [handler.py:handle_request():144] handle_request: get_summary\n2023-03-17 10:58:41,525 DEBUG   SenderThread:38526 [sender.py:send_request():363] send_request: server_info\n2023-03-17 10:58:41,525 DEBUG   HandlerThread:38526 [handler.py:handle_request():144] handle_request: sampled_history\n2023-03-17 10:58:42,143 DEBUG   HandlerThread:38526 [handler.py:handle_request():144] handle_request: shutdown\n2023-03-17 10:58:42,144 INFO    HandlerThread:38526 [handler.py:finish():842] shutting down handler\n2023-03-17 10:58:42,525 INFO    WriterThread:38526 [datastore.py:close():298] close: /home/batu/wandb/run-20230317_105832-lvhco0to/run-lvhco0to.wandb\n2023-03-17 10:58:43,142 INFO    SenderThread:38526 [sender.py:finish():1504] shutting down sender\n2023-03-17 10:58:43,142 INFO    SenderThread:38526 [file_pusher.py:finish():164] shutting down file pusher\n2023-03-17 10:58:43,143 INFO    SenderThread:38526 [file_pusher.py:join():169] waiting for file pusher\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-21T17:59:41.992Z",
				"Answer_body": "<p>Hi Batuhan,</p>\n<p>Could you send me your debug logs for the run that is not uploading files?</p>\n<p>Also the workspace to the run that this is happening to?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-24T23:19:29.728Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-16T08:53:35.115Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Table with images much larger than originals",
		"Question_link": "https://community.wandb.ai/t/table-with-images-much-larger-than-originals/4018",
		"Question_created_time": "2023-03-07T16:32:24.249Z",
		"Question_answer_count": 9,
		"Question_score_count": 1,
		"Question_view_count": 145,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am uploading images to artifact by loading a table with an <code>image</code> column, as shown in lesson 1 of your mlops course. However, if I create the image values as <code>wandb.Image(PIL.Image.open(path))</code> , my 3GB image folder becomes &gt;30Gb <code>media/images</code> folder in the artifact. If instead I use <code>wandb.Image(path)</code> , the artifact\u2019s <code>media/images</code> folder is about 3GB, but each image is loaded into a subfolder with a random name, making difficult to retrieve the image when I download the artifact for training. How can I have the images loaded simply into <code>media/images</code>, with the latter not being enormously bigger than the original one?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-09T23:15:42.699Z",
				"Answer_body": "<p>Hello Tommaso, thank you for contacting us and sorry this is happening to you.<br>\nCould you please let me know you wandb client version number and also the exact snippet of code you used to try to upload the artifact which resulted in the 30Gb folder?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-12T13:33:21.107Z",
				"Answer_body": "<p><code>wandb version 0.13.10</code></p>\n<p>Here is the snippet</p>\n<pre><code class=\"lang-auto\">def _create_table(df):\n    \"Create a wandb table given the input df\"\n    table = wandb.Table(columns=[\"filename\", \"image\", \"card_name\", \"set_name\", \"stage\", \"baseline_stage\"])\n    \n    for _index, _row in tqdm(df.iterrows(), total=df.shape[0]):\n        table.add_data(\n            _row.filename,\n            wandb.Image( PIL.Image.open(_row.filename) ),\n            _row.card_name,\n            _row.set_name,\n            \"None\", # we don't have a dataset split yet\n            _row.baseline_stage\n        )\n    \n    return table\n</code></pre>\n<p>I also tried to convert the PIL image to array with no success in reducing the size <code>wand.Image( np.asarray(PIL.image.open(_row.filename)))</code></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-14T19:13:03.098Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/bill-morrisson\">@bill-morrisson</a> Any idea? Thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-15T14:40:41.388Z",
				"Answer_body": "<p>Hello <span class=\"mention\">@tommaso</span> let me look into it today and get back to you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-17T08:26:22.577Z",
				"Answer_body": "<p>I have also tried to log the images with <code>img = artifact.add_file(filepath)</code> and add <code>img.path</code> to a column of the table, but the image is not rendered in wandb UI</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-05T20:47:39.755Z",
				"Answer_body": "<p>Hey Tommaso, could you send a link to your workspace here where you are uploading the artifacts?</p>\n<p>What happens is wandb.Image(PIL.Image.open(path)) uploads a full PIL object with cache and because of that it takes up a loot more space than using wandb.Image(path) because that one just simply uploads an image.</p>\n<p>From my understanding, when you do use PIL.Image.open(path) you get the desired folder right?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-11T15:46:32.897Z",
				"Answer_body": "<p>Hi Tommaso,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-14T17:04:01.828Z",
				"Answer_body": "<p>Hi Tommaso, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-16T08:26:38.371Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Academic account",
		"Question_link": "https://community.wandb.ai/t/academic-account/3921",
		"Question_created_time": "2023-02-21T01:37:32.575Z",
		"Question_answer_count": 11,
		"Question_score_count": 0,
		"Question_view_count": 130,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I am facing an issue with an academic account. I added the email where the domain is <span class=\"mention\">@diag.uniroma1.it</span>, as any domain ending with uniroma1.it is from different faculties in Sapienza. DIAG is the department of computer engineering and automation.</p>\n<p>However the account seems to still be considered non-academic. Is there any step necessary from my side?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-21T18:31:13.616Z",
				"Answer_body": "<p>Hi Pere-Lluis!</p>\n<p>What is the full email you are trying to mark as academic?</p>\n<p>Cheers,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-22T14:14:10.298Z",
				"Answer_body": "<p>huguetcabot@diag.uniroma1.it</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-24T20:53:43.478Z",
				"Answer_body": "<p>Thank you! Does it not let you create an academic team?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-02T01:22:12.115Z",
				"Answer_body": "<p>Hi Pere-Lluis, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-02T08:10:31.805Z",
				"Answer_body": "<p>Hi there,</p>\n<p>I wasn\u2019t able, now instead it shows a message saying I couldn\u2019t due to belonging already to a different academic team.</p>\n<p>I guess there is a limit of 1 academic team per account?</p>\n<p>Thanks.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-08T16:47:27.606Z",
				"Answer_body": "<p>Hi Pere-Lluis,</p>\n<p>Unfortunately yes, as of right now an account can have only a single academic team.</p>\n<p>Warmly,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-10T15:33:34.097Z",
				"Answer_body": "<p>Thanks. I am facing an issue due to that, i mistakenly created a new team instead of using the academic one, and now the runs I transfered to that team are \u201chostage\u201d since i have no access to them (it\u2019s reached the max hours), nor can I move them to the academic team.</p>\n<p>Is there anyway to fix that?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-14T15:01:34.263Z",
				"Answer_body": "<p>Hi Pere-Lluis,</p>\n<p>Are you currently paying for your team\u2019s trial? This seems to be the name right, alby-re-org?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-16T10:24:52.729Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"artsiom\" data-post=\"9\" data-topic=\"3921\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://sea2.discourse-cdn.com/business7/user_avatar/community.wandb.ai/artsiom/40/1001_2.png\" class=\"avatar\"> artsiom:</div>\n<blockquote>\n<p>alby-re-org</p>\n</blockquote>\n</aside>\n<p>No, I am not paying. I created it by mistake since we use another  in our research group, but now the runs in that team (alby-re-org) were unaccessible. I see now I have recovered access, I will just move the runs and remove that org. Thanks for the assistance.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-17T18:28:55.342Z",
				"Answer_body": "<p>Sounds like a plan!<br>\nLet me know if you need help deleting the org!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-15T10:25:32.391Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Graphs drawn using matplotlib have discontinuous subscripts",
		"Question_link": "https://community.wandb.ai/t/graphs-drawn-using-matplotlib-have-discontinuous-subscripts/3908",
		"Question_created_time": "2023-02-18T09:17:38.949Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 106,
		"Question_has_accepted_answer": false,
		"Question_body": "<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/2c2e61fa5ae1ac5b0afc509f77d71de219791970.png\" data-download-href=\"/uploads/short-url/6iQnL94TqoMJVWBZO4La5dsrGKs.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/2c2e61fa5ae1ac5b0afc509f77d71de219791970_2_690x306.png\" alt=\"image\" data-base62-sha1=\"6iQnL94TqoMJVWBZO4La5dsrGKs\" width=\"690\" height=\"306\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/2c2e61fa5ae1ac5b0afc509f77d71de219791970_2_690x306.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/2c2e61fa5ae1ac5b0afc509f77d71de219791970_2_1035x459.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/2c2e61fa5ae1ac5b0afc509f77d71de219791970.png 2x\" data-dominant-color=\"EEF0F4\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1178\u00d7523 38.2 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-23T14:49:07.935Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/moailaozi\">@moailaozi</a>, could you possibly send me a link to your workspace so I can take a look real at this?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-02T02:08:13.688Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/moailaozi\">@moailaozi</a>, I wanted to follow up and see if you were still looking for help with this?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-02T02:21:03.569Z",
				"Answer_body": "<p>Hi  nathank, Yes, I still can\u2019t solve this problem.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-08T00:06:00.094Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/moailaozi\">@moailaozi</a>, could you send a link to your workspace so I can take a look? I think I\u2019ll need to play around with this some so that I can understand what may be causing this.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-15T14:59:17.947Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/moailaozi\">@moailaozi</a>, let us know if this is still something you would like help with. If so, could you send a link to the workspace where you are seeing this issue?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-14T15:00:05.309Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Custom plot: numerical derivative",
		"Question_link": "https://community.wandb.ai/t/custom-plot-numerical-derivative/4036",
		"Question_created_time": "2023-03-08T21:10:10.024Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 99,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>In W&amp;B is it possible to plot something like a numerical derivative?<br>\nie plot something like: loss_{i-1} - loss_i<br>\nI\u2019m trying to define like a \u201cplateau rate\u201d curve to help me see if something is getting close to converging.</p>\n<p>Alternatively , is there some notion of \u201ctime\u201d which can be used to define a numerical derivative?<br>\nie can I do something like ${loss@_step-1} or ${loss:_step-1}</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-09T22:58:47.159Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/vchiley\">@vchiley</a> , happy to help. You could:</p>\n<ol>\n<li>Attempt to add a custom expression to on of your charts,<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/addeb00b78434540a96234615e93ee5954d605c2.png\" data-download-href=\"/uploads/short-url/oO7HVAMlVoY8aK3MwPmG9g72T9o.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/addeb00b78434540a96234615e93ee5954d605c2_2_305x250.png\" alt=\"image\" data-base62-sha1=\"oO7HVAMlVoY8aK3MwPmG9g72T9o\" width=\"305\" height=\"250\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/addeb00b78434540a96234615e93ee5954d605c2_2_305x250.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/addeb00b78434540a96234615e93ee5954d605c2_2_457x375.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/addeb00b78434540a96234615e93ee5954d605c2_2_610x500.png 2x\" data-dominant-color=\"F7F6F8\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">705\u00d7576 32.5 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div>\n</li>\n<li>Perform any custom calculations offline and log them to wandb via wandb.log()</li>\n<li>As wandb custom charts are built over <a href=\"https://vega.github.io/vega-lite/\" rel=\"noopener nofollow ugc\">Vega</a>, you could log your data then generate a custom chart where within the vega spec perform custom calculations</li>\n</ol>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-10T03:03:32.029Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"mohammadbakir\" data-post=\"2\" data-topic=\"4036\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/m/a9a28c/40.png\" class=\"avatar\"> mohammadbakir:</div>\n<blockquote>\n<p>Attempt to add a custom expression to on of your charts</p>\n</blockquote>\n</aside>\n<p>Yes this gets to the heart of my question: how would I create a custom expression where I can do something like <code>${loss @ _step-1} - ${loss @ _step}</code>? is there some notion of \u201cmeasure at step index\u201d?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-15T02:38:34.688Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/vchiley\">@vchiley</a> , the \u201cExpressions\u201d input will evaluate to a numeric value per logged step. While the \u201cX Axis Expression\u201d input will rescale your axis. You can\u2019t specifically evaluate expressions at specific step values. For more control I would recommend either performing custom calculations prior to logging metrics, or using a <a href=\"https://vega.github.io/vega-lite/docs/calculate.html\" rel=\"noopener nofollow ugc\">custom vega  calculation</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-14T02:39:33.424Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Using sweeps for custom data generator in keras",
		"Question_link": "https://community.wandb.ai/t/using-sweeps-for-custom-data-generator-in-keras/3957",
		"Question_created_time": "2023-02-27T10:46:20.269Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 96,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Am using custom data generator as part of my image augmentation. Are you able to use sweeps to try different parameters for such augmentation?</p>\n<p>for example:</p>\n<pre><code class=\"lang-auto\">idg = CustomDataGenerator(rescale = 1 / 255.,\n                             horizontal_flip = False, \n                             vertical_flip = False,\n                             v_kernel_size=config.v_kernel_size,\n                              h_kernel_size=config.h_kernel_size,  \n                             height_shift_range = config.height_shift_range, \n                             width_shift_range = config.width_shift_range, \n                             rotation_range = config.rotation_range, \n                             shear_range = config.shear_range,\n                             zoom_range = config.zoom_range,)\n    return idg\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-01T21:07:59.785Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/zookcx\">@zookcx</a> thanks for writing in! Is in your example the <code>CustomDataGenerator</code> a function that you could call from the main training function? Would something like the following work for you?</p>\n<pre><code class=\"lang-auto\">import wandb\ndef main():\n    wandb.init(project='custom-data-sweep')\n    data = CustomDataGenerator(rescale = 1 / 255.,\n                             horizontal_flip = False, \n                             vertical_flip = False,\n                             v_kernel_size=wandb.config.v_kernel_size,\n                              h_kernel_size=wandb.config.h_kernel_size)\n    wandb.log({'data': data})\n    wandb.finish()\n\n\ndef CustomDataGenerator(rescale = 1 / 255.,\n                             horizontal_flip = False, \n                             vertical_flip = False,\n                             v_kernel_size=0,\n                             h_kernel_size=0,\n                          ):\n  \n    # add your own custom data generator logic\n    idg = v_kernel_size + h_kernel_size\n\n    return idg\n</code></pre>\n<pre><code class=\"lang-auto\">\nsweep_config = {\n    'method': 'grid',\n    'project': 'sweep-configs',\n    'parameters': {\n        'v_kernel_size': {\n            'values': [32, 64, 96, 128, 256]\n        },\n        'h_kernel_size': {\n            'values': [32, 64, 96, 128, 256]\n        }\n    }\n}\n\nsweep_id = wandb.sweep(sweep_config)\nwandb.agent(sweep_id, function=main)\n</code></pre>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-03-07T11:55:33.225Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/zookcx\">@zookcx</a> just checking in here to see if the above snippet would work for you and if you had any further questions? thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-10T13:32:54.222Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/zookcx\">@zookcx</a> since we haven\u2019t heard back from you, I will close this ticket for now. Please let us know though if you had any other questions, and we will be happy to keep investigating.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-09T13:33:19.570Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Add file to artifact without downloading it",
		"Question_link": "https://community.wandb.ai/t/add-file-to-artifact-without-downloading-it/3989",
		"Question_created_time": "2023-03-02T23:13:21.912Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 220,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I have a large artifact containing a table with 6K images and other columns.<br>\nIs it possible to add another file, for instance a csv, without having to download the artifact, get the table, add the file and the table to a new version of the artifact and log it to wandb?</p>\n<p>A possibility would be to create a new version of the artifact with only the csv file and then merge the two versions (from the UI?), but I am sure this is possible.</p>\n<p>Thanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-03T14:17:42.840Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tommasodelorenzo\">@tommasodelorenzo</a> thanks for writing in! It sounds like that you\u2019re looking for the <code>incremental</code> argument that would allow you to add files to existing artifacts. Please have a look to <a href=\"https://github.com/wandb/artifacts-examples/blob/master/incremental-artifacts/add_to_existing_artifact.py\" rel=\"noopener nofollow ugc\">this</a> example, but also more specifically for your case the following snippet should work:</p>\n<pre><code class=\"lang-auto\">import wandb\n\nrun = wandb.init(entity=ENTITY, project=PROJECT)\nartifact = wandb.Artifact('ARTIFACT-NAME', type='ARTIFACT-TYPE', incremental=True)\nartifact.add_file('/path/to/file.format') #add_dir works too\nrun.log_artifact(artifact)\nrun.finish()\n</code></pre>\n<p>This  will create a new version with the new files, plus the files from previous version. Would this work for you?</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-03-04T07:41:29.479Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a> Yes, exactly! I didn\u2019t know about this argument. Super useful.<br>\nI get a warning about it being experimental. Is it going to become a stable feature soon?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-07T12:15:28.149Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tommasodelorenzo\">@tommasodelorenzo</a> glad to hear this works for you! This is indeed an experimental feature, hence the warning message,  and it\u2019s on our roadmap to be further developed. As of right now it\u2019s not possible to remove or update files in existing artifacts, but we will be adding that soon. I hope this helps! Let me know if you have any further questions about this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-08T09:40:29.647Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a> . I posted a somewhat related question <a href=\"https://community.wandb.ai/t/table-with-images-much-larger-than-originals/4018\">here</a>. Hope you can solve that too <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-09T23:50:56.550Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/tommasodelorenzo\">@tommasodelorenzo</a> feel free to ask us any questions or report any issues, and someone from our team will be happy to investigate and help you with this! I will now close this ticket, and feel free to reopen it if you had any follow-up questions on this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-08T23:51:00.306Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Getting error <class 'wandb.sdk.wandb_config.Config'> object has no attribute 'max_depth'",
		"Question_link": "https://community.wandb.ai/t/getting-error-class-wandb-sdk-wandb-config-config-object-has-no-attribute-max-depth/3859",
		"Question_created_time": "2023-02-10T14:24:50.033Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 390,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I run this code but gives me the mentioned error:</p>\n<pre data-code-wrap=\"py\"><code class=\"lang-plaintext\">def train_model(ver=None):\n\n    run = wandb.init(\n    project=\"sdg_test_case1\",\n    name=f\"advanced_analytic_EDA_model_v{ver}\",\n    # config=param,\n    )\n\n\n    param = {\n    \"objective\" : \"binary:logistic\",\n    \"eval_metric\": 'auc',\n    \"predictor\":\"gpu_predictor\",\n    \"random_state\": seed,\n    \"scale_pos_weight\": 2.66,\n    \"max_depth \": wandb.config.max_depth,\n    \"learning_rate\": wandb.config.learning_rate,\n    \"gamma\": wandb.config.gamma,\n    \"min_child_weight\": wandb.config.min_child_weight,\n    \"subsample\": wandb.config.subsample\n\n    }\n\n    bst = xgb.train(\n        param,\n        xg_train,\n        evals=watchlist,\n        verbose_eval=5,\n        callbacks=[WandbCallback()],\n        num_boost_round=50,\n        early_stopping_rounds=3\n    )\n\n    pred = bst.predict(xg_val)\n    pred_class = pred.round()\n\n\n    auc = roc_auc_score(y_test, pred)\n    acc = accuracy_score(y_test, pred_class)\n\n    conf = confusion_matrix(y_test, pred_class)\n    tn, fp, fn, tp=conf.ravel()\n    precision = tp / (tp + fp)\n    recall = tp / (tp + fn)\n    specificity = tn / (tn + fp)\n\n    # print(f\"AUC of ROC: {(auc)}\")\n    # print(f\"accuracy: {(acc)}\")\n    # print(f\"precision: {(precision)}\")\n    # print(f\"recall: {(recall)}\")\n    # print(f\"specificity: {(specificity)}\")\n\n    wandb.log({\n        \"accuracy\":acc,\n        \"precision\":precision,\n        \"recall\":recall,\n        \"specificity\":specificity,\n    })\n    wandb.summary[\"AUC\"] = auc\n\nsweep_config = {\n    \"method\": \"random\",\n    \"metric\": {\"name\": \"AUC\", \"goal\": \"maximize\"},\n    \"parameters\":{\n        \"max_depth\": {\"values\":[2,3,4,5,6,7,8]},\n        \"subsample\": {'distribution': 'uniform','min': 0.7,'max': 1},\n        \"gamma\": {'distribution': 'uniform','min': 0,'max': 0.1},\n        \"learning_rate\": {'distribution': 'uniform','min': 0,'max': 0.1},\n        \"min_child_weight\" : {'distribution': 'uniform','min': 0.9,'max': 1.3}\n\n    }\n}\n\nver = 1\nsweep_id = wandb.sweep(sweep_config,project=\"sdg_test_case\")\nwandb.agent(sweep_id=sweep_id, function=train_model(ver), count=10)\nwandb.finish()\n\n</code></pre>\n<p>I ran the example <a href=\"https://docs.wandb.ai/guides/sweeps/quickstart\">here</a> and it ran flawlessly, I don\u2019t know where is the issue is, the two codes are similar.<br>\nThank you for your time!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-10T15:46:36.420Z",
				"Answer_body": "<p>solved it by not giving any arguments to the train_model function.<br>\n<code>wandb.agent(sweep_id=sweep_id, function=train_model, count=10) </code></p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-02-10T21:54:37.992Z",
				"Answer_body": "<p>Hello Mohamed!<br>\nHappy to hear you were able to solve your issue. Please feel free to reach out again if you have any more questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-09T20:37:17.153Z",
				"Answer_body": "<p>Hi, I am having the same issue but not for the same reason I believe. Here\u2019s part of my code:</p>\n<pre><code class=\"lang-auto\">sweep_config = {\n    'method': 'random',\n    'metric': {'goal': 'maximize', 'name': 'dev_acc'},\n    'parameters':\n        {\n            'hidden_dropout_prob': {'min': 0, 'max': 1, 'distribution': 'uniform'},\n            'lr': {'min': 0, 'max': 0.1, 'distribution': 'uniform'}\n        }\n}\n\ndef train_multitask(sweep_config, args):\n    wandb.init(project='hpt-multitask', config=sweep_config)\n\n    device = torch.device('cuda') if args.use_gpu else torch.device('cpu')\n    # Load data\n    # Create the data and its corresponding datasets and dataloader\n    sst_train_data, num_labels, para_train_data, sts_train_data = load_multitask_data(args.sst_train, args.para_train, args.sts_train, split='train')\n    sst_dev_data, num_labels, para_dev_data, sts_dev_data = load_multitask_data(args.sst_dev, args.para_dev, args.sts_dev, split='train')\n    \n    sst_train_data = SentenceClassificationDataset(sst_train_data, args)\n    sst_dev_data = SentenceClassificationDataset(sst_dev_data, args)\n\n    sst_train_dataloader = DataLoader(sst_train_data, shuffle=True, batch_size=args.batch_size, \n            collate_fn=sst_train_data.collate_fn)\n    sst_dev_dataloader = DataLoader(sst_dev_data, shuffle=False, batch_size=args.batch_size, \n            collate_fn=sst_dev_data.collate_fn)\n\n    # Init model\n    config = {'hidden_dropout_prob': sweep_config.hidden_dropout_prob, \n            'num_labels': num_labels,\n            'hidden_size': 768,\n            'data_dir': '.',\n            'option': args.option}\n\n    config = SimpleNamespace(**config)\n\n    model = MultitaskBERT(config)\n    model = model.to(device)\n\n    lr = sweep_config.lr\n    optimizer = AdamW(model.parameters(), lr=lr)\n    best_dev_acc = 0\n\n    ## new code by Riya\n    para_train_data = SentencePairDataset(para_train_data, args)\n    para_dev_data = SentencePairDataset(para_dev_data, args)\n    para_train_dataloader = DataLoader(para_train_data, shuffle=False, batch_size=args.batch_size,\n                                     collate_fn=para_dev_data.collate_fn)\n    para_dev_dataloader = DataLoader(para_dev_data, shuffle=False, batch_size=args.batch_size,\n                                     collate_fn=para_dev_data.collate_fn)\n\n    sts_train_data = SentencePairDataset(sts_train_data, args, isRegression=True)\n    sts_dev_data = SentencePairDataset(sts_dev_data, args, isRegression=True)\n    sts_train_dataloader = DataLoader(sts_train_data, shuffle=False, batch_size=args.batch_size,\n                                       collate_fn=sts_dev_data.collate_fn)\n    sts_dev_dataloader = DataLoader(sts_dev_data, shuffle=False, batch_size=args.batch_size,\n                                     collate_fn=sts_dev_data.collate_fn)\n\n    for epoch in range(args.epochs):\n        model.train()\n        train_loss_sst = 0\n        train_loss_para = 0\n        train_loss_sts = 0\n\n        num_batches_sst = 0\n        num_batches_para = 0\n        num_batches_sts = 0\n\n        for batch in tqdm(sts_train_dataloader, desc=f'train-{epoch}', disable=TQDM_DISABLE):\n            b_ids1, b_mask1, b_ids2, b_mask2, b_labels, b_sent_ids = (batch['token_ids_1'], batch['attention_mask_1'],\n                                                                      batch['token_ids_2'], batch['attention_mask_2'],\n                                                                      batch['labels'], batch['sent_ids'])\n            b_ids1 = b_ids1.to(device)\n            b_mask1 = b_mask1.to(device)\n            b_ids2 = b_ids2.to(device)\n            b_mask2 = b_mask2.to(device)\n            b_labels = b_labels.to(device)\n\n            optimizer.zero_grad()\n            logit = model.predict_similarity(b_ids1, b_mask1, b_ids2, b_mask2)\n            # ASK ON ED: DO WE CHANGE IF JUST ONE LOGIT\n            loss = F.mse_loss(logit.view(-1).float(), b_labels.view(-1).float(), reduction='sum') / args.batch_size\n            loss.backward()\n            optimizer.step()\n\n            train_loss_sts += loss.item()\n            num_batches_sts += 1\n\n        train_loss_sts = train_loss_sts / (num_batches_sts)\n\n        for batch in tqdm(sst_train_dataloader, desc=f'train-{epoch}', disable=TQDM_DISABLE):\n            b_ids, b_mask, b_labels = (batch['token_ids'],\n                                       batch['attention_mask'], batch['labels'])\n\n            b_ids = b_ids.to(device)\n            b_mask = b_mask.to(device)\n            b_labels = b_labels.to(device)\n\n            optimizer.zero_grad()\n            logits = model.predict_sentiment(b_ids, b_mask)\n            loss = F.cross_entropy(logits, b_labels.view(-1), reduction='sum') / args.batch_size\n\n            loss.backward()\n            optimizer.step()\n\n            train_loss_sst += loss.item()\n            num_batches_sst += 1\n\n        train_loss_sst = train_loss_sst / (num_batches_sst)\n\n        for batch in tqdm(para_train_dataloader, desc=f'train-{epoch}', disable=TQDM_DISABLE):\n            b_ids1, b_mask1, b_ids2, b_mask2, b_labels, b_sent_ids = (batch['token_ids_1'], batch['attention_mask_1'],\n                          batch['token_ids_2'], batch['attention_mask_2'],\n                          batch['labels'], batch['sent_ids'])\n            b_ids1 = b_ids1.to(device)\n            b_mask1 = b_mask1.to(device)\n            b_ids2 = b_ids2.to(device)\n            b_mask2 = b_mask2.to(device)\n            b_labels = b_labels.to(device)\n\n            optimizer.zero_grad()\n            logit = model.predict_paraphrase(b_ids1, b_mask1, b_ids2, b_mask2)\n            # ASK ON ED: DO WE CHANGE IF JUST ONE LOGIT\n            loss = F.binary_cross_entropy_with_logits(logit.view(-1).float(), b_labels.view(-1).float(), reduction='sum') / args.batch_size\n            loss.backward()\n            optimizer.step()\n\n            train_loss_para += loss.item()\n            num_batches_para += 1\n\n        train_loss_para = train_loss_para / (num_batches_para)\n\n\n        para_train_accuracy, para_y_pred, para_sent_ids, sst_train_accuracy, sst_y_pred, sst_sent_ids, sts_train_corr, \\\n        sts_y_pred, sts_sent_ids = model_eval_multitask(sst_train_dataloader, para_train_dataloader, sts_train_dataloader, model, device)\n\n        para_dev_accuracy, para_y_pred, para_sent_ids, sst_dev_accuracy, sst_y_pred, sst_sent_ids, sts_dev_corr, \\\n        sts_y_pred, sts_sent_ids = model_eval_multitask(sst_dev_dataloader, para_dev_dataloader,\n                                                        sts_dev_dataloader, model, device)\n\n        dev_acc = para_dev_accuracy + sst_dev_accuracy + (1+sts_dev_corr)/2 # tranform correlation so that on scale 0 to 1\n\n        if dev_acc &gt; best_dev_acc:\n            best_dev_acc = dev_acc\n            save_model(model, optimizer, args, config, args.filepath)\n\n        print(\n            f\"Epoch {epoch}: train loss sst:: {train_loss_sst :.3f}, train acc :: {sst_train_accuracy :.3f}, dev acc :: {sst_dev_accuracy :.3f}\")\n        print(\n            f\"Epoch {epoch}: train loss sts:: {train_loss_sts :.3f}, train corr :: {sts_train_corr :.3f}, dev acc :: {sts_dev_corr :.3f}\")\n        print(\n            f\"Epoch {epoch}: train loss para:: {train_loss_para :.3f}, train acc :: {para_train_accuracy :.3f}, dev acc :: {para_dev_accuracy :.3f}\")\n\n        wandb.log({'dev_acc': dev_acc})\n\nif __name__ == \"__main__\":\n    args = get_args()\n    args.filepath = f'{args.option}-{args.epochs}-{sweep_config.lr}-multitask.pt'  # save path\n    seed_everything(args.seed)  # fix the seed for reproducibility\n\n    train_multitask(sweep_config, args)\n\n    test_model(args)\n\nsweep_id = wandb.sweep(sweep=sweep_config, project='hpt-multitask')\nwandb.agent(sweep_id, function=train_multitask)\n</code></pre>\n<p>I get that dict object has no attribute lr and same for hidden_dropout_probs</p>\n<p>Any help would be much appreciated!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-08T20:37:37.267Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Logged tables in reverse chronological order?",
		"Question_link": "https://community.wandb.ai/t/logged-tables-in-reverse-chronological-order/4006",
		"Question_created_time": "2023-03-06T11:37:44.825Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 88,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>We have many logged tables. The table panel always appears in a chaotic order, making it very hard to find the desired table. Even A-Z sorting doesn\u2019t really work as expected, the order is still chaotic.</p>\n<p>Would there be a possibility for reverse chronological ordering? And/or accurate A-Z ordering according to the table title I presume?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-08T15:06:04.349Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/turian\">@turian</a>, I\u2019m seeing the same behavior as you. It looks like the order is determined by when the table data actually hits the server because I\u2019m seeing the tables roughly in the order they are logged but several are out of order as you mentioned.</p>\n<p>I believe any sort of chronological order sorting would require us to store additional metadata to the Table about when it was logged. I can request this if you\u2019d like but I think the simpler solution would be to have Table panels respect the A-Z sorting since that would only require changes in the UI. Do you think this would be an acceptable solution?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-09T15:45:48.368Z",
				"Answer_body": "<p>Proper A-Z sorting would be a good workaround, yes.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-08T15:46:46.385Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to delete a project in an organization that has exceeded the 250 hour limit?",
		"Question_link": "https://community.wandb.ai/t/how-to-delete-a-project-in-an-organization-that-has-exceeded-the-250-hour-limit/4029",
		"Question_created_time": "2023-03-08T02:42:41.102Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 137,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have an organization that has exceeded the 250 hour limit. I am trying to go into the organization, to delete<br>\nan old project so I can stop exceeding the limit. But it looks like the UI is not letting me.</p>\n<p>Is there a way I delete old projects in my organization to go back under the limit?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-08T21:56:06.021Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/vroomerify\">@vroomerify</a>,</p>\n<p>Tracked hours are cumulative and cannot be deleted from your account. If you have exceeded the limit, we ask that you upgrade to Tier 1. If you would like to chat more about this with our sales team, please let us know.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-09T11:12:50.367Z",
				"Answer_body": "<p>W&amp;B is free for academic and personal projects. If you\u2019re active in university, you can add a university email to your account to qualify for a free academic team.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-09T15:06:24.242Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/vroomerify\">@vroomerify</a> Your team is now an academic team. Let us know if you have any other issues.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-08T15:06:48.657Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Hugging Face Accelerate + Sweeps",
		"Question_link": "https://community.wandb.ai/t/hugging-face-accelerate-sweeps/3973",
		"Question_created_time": "2023-03-01T12:24:12.119Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 210,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I am struggling to get sweeps to work with Hugging Face\u2019s Accelerate library. Specifically, the first run of the sweep works fine, but every run thereafter fails due to re-initialising the Accelerator for every run. In every run from the 2nd, I get the error: <code>AcceleratorState has already been initialized and cannot be changed, restart your runtime completely and pass mixed_precision='bf16' to Accelerate().</code></p>\n<p>Below is a minimal example of a script which I\u2019m launching using <code>accelerate launch</code>. I\u2019d appreciate any suggestions. Thanks!</p>\n<pre><code class=\"lang-auto\">import os\nfrom typing import Any, List, Tuple\n\nfrom accelerate import Accelerator\nfrom torch import Tensor\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import (\n    Adafactor,\n    PreTrainedTokenizerFast,\n    T5ForConditionalGeneration,\n    T5TokenizerFast,\n)\nimport wandb\n\n\nclass TestDataset(Dataset[Any]):\n    def __init__(self, tokenizer: PreTrainedTokenizerFast) -&gt; None:\n        super().__init__()\n        self._str_prompt = \"This is a \"\n        self._str_target = \"test.\"\n        \n        self._tokenizer = tokenizer\n    \n    def __len__(self) -&gt; int:\n        return 1\n\n    def __getitem__(self, idx: int) -&gt; Tuple[str, str]:\n        return self._str_prompt, self._str_target\n    \n    def collate(self, batch: List[Tuple[str, str]]) -&gt; Tuple[Tensor, Tensor]:\n        prompts = [b[0] for b in batch]\n        targets = [b[1] for b in batch]\n        \n        prompts_tokenized = self._tokenizer(prompts, return_tensors=\"pt\")\n        targets_tokenized = self._tokenizer(targets, return_tensors=\"pt\")\n        \n        return prompts_tokenized[\"input_ids\"], targets_tokenized[\"input_ids\"]\n\n\ndef main() -&gt; None:\n    accelerator = Accelerator(log_with=\"wandb\", mixed_precision=\"bf16\")\n    \n    if accelerator.is_main_process:\n        accelerator.init_trackers(os.environ.get(\"WANDB_PROJECT\"))\n    \n    accelerator.wait_for_everyone()\n    \n    wandb_tracker = accelerator.get_tracker(\"wandb\")\n    multiplier = wandb_tracker.config[\"multiplier\"]\n    \n    model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n    tokenizer = T5TokenizerFast.from_pretrained(\"t5-small\")\n    opt = Adafactor(params=model.parameters())\n    \n    dataset = TestDataset(tokenizer=tokenizer)\n    data_loader = DataLoader(dataset=dataset, collate_fn=dataset.collate)\n    \n    model, opt, data_loader = accelerator.prepare(model, opt, data_loader)\n    \n    input_ids, labels = next(iter(data_loader))\n    \n    loss = model(input_ids=input_ids, labels=labels).loss\n    \n    loss_gathered = accelerator.gather_for_metrics(loss).mean()\n    accelerator.log({\"loss\": loss_gathered.item() * multiplier})\n    \n    accelerator.end_training()\n\n\nif __name__ == \"__main__\":\n    sweep_configuration = {\n        \"method\": \"random\",\n        \"metric\": {\"goal\": \"maximize\", \"name\": \"loss\"},\n        \"parameters\": {\"multiplier\": {\"values\": list(range(100))}},\n    }\n    \n    sweep_id = wandb.sweep(\n        sweep=sweep_configuration,\n        project=os.environ.get(\"WANDB_PROJECT\"),\n    )\n    wandb.agent(sweep_id, function=main, count=3)\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-03T12:33:07.073Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/harshil\">@harshil</a>, thanks for reporting this! I\u2019ve tested your code in<a href=\"https://colab.research.google.com/drive/1J_hg3D6iNupr_0Wi9uZhrM0LGoVykvyn#scrollTo=DleJaf8Obcye\" rel=\"noopener nofollow ugc\"> this colab</a> and it seems to be working properly for me. Could you try upgrading wandb, accelerate and transformers to the latestversion? Also, would it be possible for you to share with me the debug files under your local wandb folder and so I can have a look at them and see what\u2019s hapening here? Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-07T10:34:03.965Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/harshil\">@harshil</a>, I just wanted to follow up here! Would it be possible for you to try upgrading wandb, accelerate and transformers to the latest version? In case the issue is still raising, would it be possible to share the debug files under your local wandb folder? Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-07T11:05:10.171Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/luis_bergua1\">@luis_bergua1</a>, thanks for your reply! Actually I also shared this <a href=\"https://github.com/huggingface/accelerate/issues/1131\" rel=\"noopener nofollow ugc\">issue</a> in the Accelerate repo and was advised that the Accelerator must be instantiated outside the <code>main</code> function, which then worked for me. So it\u2019s interesting that it worked for you without doing so\u2026</p>\n<p>However I will indeed try upgrading all libraries to the latest version and get back to you on this <img src=\"https://emoji.discourse-cdn.com/twitter/+1.png?v=12\" title=\":+1:\" class=\"emoji\" alt=\":+1:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-07T11:29:31.889Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/harshil\">@harshil</a>, great to hear this worked for you! Yes feel free to reach out to me if you need something else.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-09T14:10:44.789Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/luis_bergua1\">@luis_bergua1</a>,</p>\n<p>Just to let you know, with <code>accelerate-0.16.0</code>, <code>transformers-4.26.1</code> &amp; <code>wandb-0.13.11</code> I still get the same issue as above - <code>AcceleratorState has already been initialized and cannot be changed, restart your runtime completely and pass mixed_precision='bf16' to Accelerate().</code></p>\n<p>It works when instantiating the Accelerator outisde the <code>main</code> function.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-09T14:15:11.313Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/luis_bergua1\">@luis_bergua1</a> Related to this, I\u2019m having an issue running on multiple GPUs. I would like to run a sweep where each run of the sweep uses all the GPUs on my machine (i.e. I do not want to parallelise over GPUs).</p>\n<p>The issue is that when I try to run this with e.g. 2 GPUs, W&amp;B actually creates 2 sweeps and in total, twice as many runs are performed as I requested with <code>count</code>. So e.g. with the script above where I specified <code>count=3</code>, I get 2 sweeps each with 3 runs, rather than just 1 sweep.</p>\n<p>Is there a way around this where instead I  only get one sweep, and each run uses all the GPUs?</p>\n<p>My <code>accelerate</code> config is as follows, in case it\u2019s useful:</p>\n<pre><code class=\"lang-auto\">compute_environment: LOCAL_MACHINE\ndeepspeed_config: {}\ndistributed_type: MULTI_GPU\ndowncast_bf16: 'no'\ndynamo_backend: 'NO'\nfsdp_config: {}\ngpu_ids: all\nmachine_rank: 0\nmain_training_function: main\nmegatron_lm_config: {}\nmixed_precision: 'no'\nnum_machines: 1\nnum_processes: 2\nrdzv_backend: static\nsame_network: true\nuse_cpu: false\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-08T14:16:02.404Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Only one plotly plot is showing despite many uploaded",
		"Question_link": "https://community.wandb.ai/t/only-one-plotly-plot-is-showing-despite-many-uploaded/3988",
		"Question_created_time": "2023-03-02T19:31:34.765Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 111,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am trying to log a 3d scatter plotly plot every nth iteration. I followed this tutorial <a href=\"https://docs.wandb.ai/guides/track/log/plots\" class=\"inline-onebox\">Log and Track Plots from W&amp;B Experiments.</a> to convert the plot into an HTML, add it to a table and then log it. However, in my wandb dashboard, only a single row shows up, so it seems like the table gets overwritten.  Ideally, I would like a slider to go through the plots, but having them all in a table would already be better than what I have right now. Here is my code:</p>\n<pre><code class=\"lang-auto\">density_plot_wandb_table = wandb.Table(columns=[\"electron_densities\"])\nfor step in trange(init_step, config.train.n_steps):\n    ...\n     if step%config.plotting.n_plotting_frequency==0:\n            # Create plot\n            fig = go.Figure(data=[go.Scatter3d(x=samples[:config.plotting.n_samples, 0],\n                                           y=samples[:config.plotting.n_samples, 1],\n                                           z=samples[:config.plotting.n_samples,  2],\n                                           mode='markers',\n                                           marker=dict(\n                                             size=1,\n                                             color='#636EFA',\n                                             opacity=0.2\n                                           )\n                                           ),\n                              go.Scatter3d(x=mol.nuclei_position[:, 0],\n                                           y=mol.nuclei_position[:, 1],\n                                           z=mol.nuclei_position[:, 2],\n                                           mode='markers',\n                                           marker=dict(\n                                             size=7,\n                                             color='crimson',\n                                             opacity=1.0\n                                           )\n                                           )\n\n                              ])\n           fig.write_html('{}plots_{}'.format(workdir, step), auto_play=False)\n           density_plot_wandb_table.add_data(wandb.Html('{}plots_{}'.format(workdir, step)))\n           wandb.log({'Mol': density_plot_wandb_table})\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-03T15:21:16.444Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/binbose\">@binbose</a> thanks for writing in, and the detailed information! Luckily both options are feasible so feel free to choose the one you prefer <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<p>The reason that the table rows are overwritten in your case, it\u2019s because inside the loop you can add rows with <code>add_data</code> method, but you only need to log the table once (outside the loop). For the slider option, you will need to omit logging to the table and log the <code>html</code> object directly as: <code>wandb.log({'Mol': wandb.Html(..))</code></p>\n<p>I have adjusted our documentation example to be inside a loop, so that you could accordingly adapt your code:</p>\n<pre><code class=\"lang-auto\"># Initialize a new run\nrun = wandb.init(project=\"log-plotly-fig-tables\", name=\"plotly_html\")\n\n# Create a table\ntable = wandb.Table(columns = [\"plotly_figure\"])\n\n# Create path for Plotly figure\npath_to_plotly_html = \"./plotly_figure.html\"\n\nfor i in range(10):\n\n  # Example Plotly figure\n  fig = px.scatter(x = [0, 1, 2, 3, 4], y = [0, 1, 4, 9, 16])\n\n  # Write Plotly figure to HTML\n  fig.write_html(path_to_plotly_html, auto_play = False) # Setting auto_play to False prevents animated Plotly charts from playing in the table automatically\n\n  # Add Plotly figure as HTML file into Table\n  table.add_data(wandb.Html(path_to_plotly_html))\n\n# Log Table\nrun.log({\"test_table\": table})\nwandb.finish()\n</code></pre>\n<p>Slider option:</p>\n<pre><code class=\"lang-auto\"># Initialize a new run\nrun = wandb.init(project=\"log-plotly-fig-tables\", name=\"plotly_html\")\n\n# Create path for Plotly figure\npath_to_plotly_html = \"./plotly_figure.html\"\n\nfor i in range(10):\n\n  # Example Plotly figure\n  fig = px.scatter(x = [0, 1, 2, 3, 4], y = [0, 1, 4, 9, 16])\n\n  # Write Plotly figure to HTML\n  fig.write_html(path_to_plotly_html, auto_play = False) # Setting auto_play to False prevents animated Plotly charts from playing in the table automatically\n\n  # Log Table\n  run.log({\"test_slider\": wandb.Html(path_to_plotly_html)})\n\nwandb.finish()\n</code></pre>\n<p>I hope this helps, please let us know if you have any further issues or questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-03T20:39:51.364Z",
				"Answer_body": "<p>Hey, thank you for the quick response! With the latter solution, I do get a slider, but the plot is unfortunately not displayed. Instead, it just says: \u2018results/plots\u2019 (where I saved the HTML). See the image:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/4/42538a8c02485f9a59d41e6b06305e7929c3d2a3.png\" data-download-href=\"/uploads/short-url/9sKuX5wnlYyBY55YNW0LH7uuYi7.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/42538a8c02485f9a59d41e6b06305e7929c3d2a3_2_690x263.png\" alt=\"image\" data-base62-sha1=\"9sKuX5wnlYyBY55YNW0LH7uuYi7\" width=\"690\" height=\"263\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/42538a8c02485f9a59d41e6b06305e7929c3d2a3_2_690x263.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/42538a8c02485f9a59d41e6b06305e7929c3d2a3_2_1035x394.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/42538a8c02485f9a59d41e6b06305e7929c3d2a3_2_1380x526.png 2x\" data-dominant-color=\"FEFEFE\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1765\u00d7673 13.5 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-07T01:59:49.809Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a> , just wondering if you could take another look to see if you know what\u2019s wrong here?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-07T12:18:37.580Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/binbose\">@binbose</a> thanks for the update, I\u2019ve looked into this and it seems if you check the <code>Files</code>/<code>media</code> folder from the App that your <code>html</code> files are empty, or won\u2019t include any data to be plotted. Could you please check the contents of the generated files in your local disk, do they contain the plot data?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-07T16:33:55.384Z",
				"Answer_body": "<p>Hey, sorry I found my bug; the file names didn\u2019t end in .html<br>\nThank you for the help!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-08T19:47:13.123Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/binbose\">@binbose</a> thanks for the update, glad to hear this is now fixed for you! I will close this ticket, and feel free to post here any further questions or issues.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-07T19:48:12.398Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Matplotlib drawing, please can you set the subscript to start at 1 instead of 36",
		"Question_link": "https://community.wandb.ai/t/matplotlib-drawing-please-can-you-set-the-subscript-to-start-at-1-instead-of-36/3927",
		"Question_created_time": "2023-02-22T01:36:03.995Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 162,
		"Question_has_accepted_answer": false,
		"Question_body": "<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/d90cdbb2e0a509504a054f682f89557c60393270.png\" data-download-href=\"/uploads/short-url/uY79TH4Hvfbkf7OvkKIHtqppHHi.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/d90cdbb2e0a509504a054f682f89557c60393270_2_690x351.png\" alt=\"image\" data-base62-sha1=\"uY79TH4Hvfbkf7OvkKIHtqppHHi\" width=\"690\" height=\"351\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/d90cdbb2e0a509504a054f682f89557c60393270_2_690x351.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/d90cdbb2e0a509504a054f682f89557c60393270_2_1035x526.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/d90cdbb2e0a509504a054f682f89557c60393270.png 2x\" data-dominant-color=\"EBEEF4\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1136\u00d7578 38.2 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<pre><code class=\"lang-auto\">def plot_embeddings(embeddings, label,dataset_name,epoch):\n    len_embedding = len(embeddings)\n    emb_list = np.array(embeddings.tolist())\n    label = np.array(label.tolist())\n\n    color_idx = {}\n    for i in range(len_embedding):\n        color_idx.setdefault(label[i], [])\n        color_idx[label[i]].append(i)\n\n    fig, ax = plt.subplots(figsize=(20,10), dpi= 120)\n    for c, idx in color_idx.items():\n        ax.scatter(emb_list[idx, 0], emb_list[idx, 1], label=c)\n\n    wandb.log({f\"visualization/Embedding\u2014\u2014{dataset_name}\": fig,\n               f\"visualization/epoch\": epoch,\n               })\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-23T18:33:51.309Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/moailaozi\">@moailaozi</a> , happy to help. From the screenshot provided this indicates that you began logging your charts at step 36. When executing your code did you make previous <code>wandb.log</code> calls in your script prior to creating the charts above? With every call to <code>log()</code>, wandb monotonically increase the step value. I checked one of your other projects and you were successful in logging similar charts that began at step 1 of the slider. More on bundle metrics into the same log() call <a href=\"https://docs.wandb.ai/guides/track/log/logging-faqs#why-am-i-seeing-fewer-data-points-than-i-logged\">here</a>. Please let me know if you have any questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-26T03:58:22.441Z",
				"Answer_body": "<p>Thank you for your reply, but I still can\u2019t solve this problem. I tried the following methods but nothing worked.</p>\n<p>1\uff1a</p>\n<pre><code class=\"lang-auto\">    with wandb.init(project=project_name,config=args,name= model_name):\n        # define our custom x axis metric\n        wandb.define_metric(\"visualization/epoch\")\n        # define which metrics will be plotted against it\n        wandb.define_metric(f\"visualization/T-SNE\u2014\u2014{args.target_dataset_name}\", step_metric=\"visualization/epoch\")\n        wandb.define_metric(f\"visualization/Embedding\u2014\u2014{args.target_dataset_name}\", step_metric=\"visualization/epoch\")\n        train(model_name,args)\n</code></pre>\n<p>2\uff1a</p>\n<pre><code class=\"lang-auto\">def plot_embeddings(embeddings, label,dataset_name,epoch):\n    len_embedding = len(embeddings)\n    emb_list = np.array(embeddings.tolist())\n    label = np.array(label.tolist())\n\n    color_idx = {}\n    for i in range(len_embedding):\n        color_idx.setdefault(label[i], [])\n        color_idx[label[i]].append(i)\n\n    fig, ax = plt.subplots(figsize=(20,10), dpi= 120)\n    for c, idx in color_idx.items():\n        ax.scatter(emb_list[idx, 0], emb_list[idx, 1], label=c)\n\n    wandb.log({f\"visualization/Embedding\u2014\u2014{dataset_name}\": fig,\n               \"visualization/epoch\": epoch\n               })\n    return\n</code></pre>\n<p>By changing the coordinates, it still doesn\u2019t change the index<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/adfa184333c081dbbe5678b482055a76bd870598.png\" data-download-href=\"/uploads/short-url/oP4qx7UkJRgeqJDmqwAQhlLG3Co.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/adfa184333c081dbbe5678b482055a76bd870598_2_690x240.png\" alt=\"image\" data-base62-sha1=\"oP4qx7UkJRgeqJDmqwAQhlLG3Co\" width=\"690\" height=\"240\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/adfa184333c081dbbe5678b482055a76bd870598_2_690x240.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/adfa184333c081dbbe5678b482055a76bd870598_2_1035x360.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/adfa184333c081dbbe5678b482055a76bd870598_2_1380x480.png 2x\" data-dominant-color=\"F2F3F6\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1785\u00d7623 49.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-08T18:59:28.472Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/moailaozi\">@moailaozi</a> , thank you for providing a code example. There isn\u2019t a specific issue with your functions, but rather I believe you are not nesting your log calls. I reviewed a recent project and noticed the following. Three of your visualizations begin at different steps. This is due to when creating each visualization you either did not initialize a new wandb run, or you logged each one with separate log calls. As mentioned above, With every call to <code>log()</code> , wandb monotonically increase the step value.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/8/8f9da1ca316499529893fd10c6e8e7dde873f5f7.png\" data-download-href=\"/uploads/short-url/kuu0cwyIUV9iWTZLYqkRyhMOCNN.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/8f9da1ca316499529893fd10c6e8e7dde873f5f7_2_690x37.png\" alt=\"image\" data-base62-sha1=\"kuu0cwyIUV9iWTZLYqkRyhMOCNN\" width=\"690\" height=\"37\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/8f9da1ca316499529893fd10c6e8e7dde873f5f7_2_690x37.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/8f9da1ca316499529893fd10c6e8e7dde873f5f7_2_1035x55.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/8f9da1ca316499529893fd10c6e8e7dde873f5f7_2_1380x74.png 2x\" data-dominant-color=\"F9FAFB\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1483\u00d781 4.39 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>To prevent unintended behavior with logging steps, we recommend you nest your log calls. e.g <code>wandb.log({\"Viz1\": &lt;vizualization-logic&gt;, \"Viz2\": &lt;vizualization-logic&gt;)</code>. This ensures with every log call the graphs step are incremented together.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-07T19:00:20.330Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Traceback error BrokenPipeError: [Errno 32] Broken pipe",
		"Question_link": "https://community.wandb.ai/t/traceback-error-brokenpipeerror-errno-32-broken-pipe/3951",
		"Question_created_time": "2023-02-26T05:56:50.979Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 1128,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey guys,</p>\n<p>I am getting a Traceback error when I want to run\"wandb.log()\".Any tips what to do?? Thank you so much.</p>\n<p>Traceback (most recent call last):<br>\nFile \u201ctrain_spn_voc.py\u201d, line 275, in <br>\nmain(name=args.name)<br>\nFile \u201ctrain_spn_voc.py\u201d, line 180, in main<br>\n\u2018train_acc\u2019: train_acc.avg,<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_run.py\u201d, line 371, in wrapper<br>\nreturn func(self, *args, **kwargs)<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_run.py\u201d, line 334, in wrapper<br>\nreturn func(self, *args, **kwargs)<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_run.py\u201d, line 1713, in log<br>\nself._log(data=data, step=step, commit=commit)<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_run.py\u201d, line 1495, in _log<br>\nself._partial_history_callback(data, step, commit)<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_run.py\u201d, line 1370, in _partial_history_callback<br>\npublish_step=not_using_tensorboard,<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/interface/interface.py\u201d, line 586, in publish_partial_history<br>\nself._publish_partial_history(partial_history)<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/interface/interface_shared.py\u201d, line 89, in _publish_partial_history<br>\nself._publish(rec)<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/interface/interface_sock.py\u201d, line 51, in _publish<br>\nself._sock_client.send_record_publish(record)<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/lib/sock_client.py\u201d, line 221, in send_record_publish<br>\nself.send_server_request(server_req)<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/lib/sock_client.py\u201d, line 155, in send_server_request<br>\nself._send_message(msg)<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/lib/sock_client.py\u201d, line 152, in _send_message<br>\nself._sendall_with_error_handle(header + data)<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/lib/sock_client.py\u201d, line 130, in _sendall_with_error_handle<br>\nsent = self._sock.send(data)<br>\nBrokenPipeError: [Errno 32] Broken pipe<br>\nwandb: While tearing down the service manager. The following error has occurred: [Errno 32] Broken pipe</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-28T23:01:04.302Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/eveleaf\">@eveleaf</a> , happy to look into this for you. Could you provide us a few more details about your project.</p>\n<ul>\n<li>What type of environment are you working in?</li>\n<li>In your main script, are you executing a single run or spinning up multiple runs (multiprocessing? Distributed Training)</li>\n<li>What wandb client version are you using?</li>\n<li>If possible, could you provide us a simple reproducible example we could work through?</li>\n</ul>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-06T23:15:32.713Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/eveleaf\">@eveleaf</a> ,  since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-08T03:21:28.780Z",
				"Answer_body": "<p>Hi, I ran into the same error.</p>\n<ul>\n<li>What type of environment are you working in?<br>\ngoogle colab + miniconda + packages installed in the base env with <code>conda-environment.yaml</code>\n</li>\n<li>In your main script, are you executing a single run or spinning up multiple runs (multiprocessing? Distributed Training)<br>\na single run (here is the <a href=\"https://github.com/Nov05/wandb-edu/tree/main/mlops-001/lesson2\" rel=\"noopener nofollow ugc\">code</a>, cloned from repo <code>wandb/edu</code>)</li>\n<li>What wandb client version are you using?<br>\nwandb 0.13.11</li>\n<li>If possible, could you provide us a simple reproducible example we could work through?<br>\nhere is the <a href=\"https://drive.google.com/file/d/15HMgh51T_7b0tG82jdW2xGJ99valmTyL\" rel=\"noopener nofollow ugc\">notebook</a>. <code>ENTITY</code> and <code>RAW_DATA_AT</code> values in <code>params.py</code>, <code>entity</code> value in <code>sweep.yaml</code> need to be updated for execution.</li>\n</ul>\n<p>Would appreciate any help. Thanks!</p>\n<pre><code class=\"lang-plaintext\">Problem at: &lt;ipython-input-13-0fcfc7426e19&gt; 3 train\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\", line 1144, in init\n    run = wi.init()\n  File \"/usr/local/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\", line 607, in init\n    manager._inform_init(settings=self.settings, run_id=self.settings.run_id)\n  File \"/usr/local/lib/python3.8/site-packages/wandb/sdk/wandb_manager.py\", line 209, in _inform_init\n    svc_iface._svc_inform_init(settings=settings, run_id=run_id)\n  File \"/usr/local/lib/python3.8/site-packages/wandb/sdk/service/service_sock.py\", line 38, in _svc_inform_init\n    self._sock_client.send(inform_init=inform_init)\n  File \"/usr/local/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 211, in send\n    self.send_server_request(server_req)\n  File \"/usr/local/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"/usr/local/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"/usr/local/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nBrokenPipeError: [Errno 32] Broken pipe\nwandb: ERROR Abnormal program exit\n---------------------------------------------------------------------------\nBrokenPipeError                           Traceback (most recent call last)\n/usr/local/lib/python3.8/site-packages/wandb/sdk/wandb_init.py in init(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\n   1143         try:\n-&gt; 1144             run = wi.init()\n   1145             except_exit = wi.settings._except_exit\n\n9 frames\nBrokenPipeError: [Errno 32] Broken pipe\n\nThe above exception was the direct cause of the following exception:\n\nException                                 Traceback (most recent call last)\n/usr/local/lib/python3.8/site-packages/wandb/sdk/wandb_init.py in init(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\n   1179             if except_exit:\n   1180                 os._exit(1)\n-&gt; 1181             raise Exception(\"problem\") from error_seen\n   1182     return run\n\nException: problem\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-07T03:22:21.201Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Conditional sweep config",
		"Question_link": "https://community.wandb.ai/t/conditional-sweep-config/4017",
		"Question_created_time": "2023-03-07T13:12:53.379Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 99,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I guess the answer to this is \u201cnot supported\u201d when looking at similar requests, but at least\u2026 let me add a +1 to the feature request. Simplified, presume I have two approaches to training a model, each with its own sub-approaches. Is there a way to define a sweep config in a way that I can do a search over sub-approaches that depend on the main approach, i.e., how to build something like:</p>\n<pre><code class=\"lang-bash\">python3 train.py --approach a --sub_approach a1\npython3 train.py --approach a --sub_approach a2\npython3 train.py --approach b --sub_approach b1\npython3 train.py --approach b --sub_approach b2\n</code></pre>\n<p>I could\u2026</p>\n<ul>\n<li>do 2 sweeps for a anb b in that toy example, but I think I cannot combine the results of different sweeps into a single graph, right?</li>\n<li>Or I could check in <code>train.py</code> and abort the program for invalid combinations; in this case I think I need to tell wandb to continue with the sweep since there would be a number of \u201ccrashes\u201d</li>\n<li>Or use a different hyper param optimizer and integrate into wandb (but would like to avoid that).</li>\n</ul>\n<p>Any other options? If different hyper param optimizer, any recommendation because of better/easier integration with wandb? Thanks for your input/ideas.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-08T16:41:01.003Z",
				"Answer_body": "<p>Hi Stephan!</p>\n<p>This is a very popular feature request. I just +1\u2019ed it and raised the priority on it for you. Hopefully, we\u2019ll see this feature asap!</p>\n<p>Cheers,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-06T13:13:30.341Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Min loss using Weave panel",
		"Question_link": "https://community.wandb.ai/t/min-loss-using-weave-panel/3874",
		"Question_created_time": "2023-02-13T17:36:17.932Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 217,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I logged loss in my run. I would like to compare runs by min loss. I found <a href=\"https://github.com/wandb/wandb/issues/736\" rel=\"noopener nofollow ugc\">this</a> feature request, which suggests using a Weave panel with:</p>\n<pre><code class=\"lang-auto\">runs.map((row) =&gt; row.history[\"loss\"].min)\n</code></pre>\n<p>This works when I add the panel on the run page (i.e. <code>/&lt;team&gt;/&lt;project&gt;/runs/&lt;run id&gt;</code>). However, when I add the panel on the project page (i.e. <code>/&lt;team&gt;/&lt;project&gt;</code>), all runs show an empty value.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-15T20:49:35.671Z",
				"Answer_body": "<p>Hello Szymon!</p>\n<p>If you want to compare runs by min loss in the project page, I would recommend making a bar chart panel by going to <code>Add panel</code> \u2192 <code>Bar chart</code> \u2192 set the <code>Metric</code> to <code>training/loss.min</code>.</p>\n<p>Does this answer your question?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-21T21:07:11.701Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-06T21:49:29.522Z",
				"Answer_body": "<p>That only works if you set the metric aggregation to min, e.g.:</p>\n<pre><code class=\"lang-auto\">wandb.define_metric(\"training/loss\", summary=\"min\")\n</code></pre>\n<p>I did not do that in my run, and I was hoping I could use Weave to perform the aggregation for me.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-07T12:42:16.520Z",
				"Answer_body": "<p>You can add a new column and use <code>row.run.history[\"loss\"].min</code><br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/c/c0c47df699223fb68f2b07f24fa80492015dc90f.jpeg\" data-download-href=\"/uploads/short-url/rviEHVy1FtRwgCNT0gNF0hN2JVJ.jpeg?dl=1\" title=\"image\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/c0c47df699223fb68f2b07f24fa80492015dc90f_2_529x500.jpeg\" alt=\"image\" data-base62-sha1=\"rviEHVy1FtRwgCNT0gNF0hN2JVJ\" width=\"529\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/c0c47df699223fb68f2b07f24fa80492015dc90f_2_529x500.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/c0c47df699223fb68f2b07f24fa80492015dc90f_2_793x750.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/c/c0c47df699223fb68f2b07f24fa80492015dc90f.jpeg 2x\" data-dominant-color=\"F9F9F8\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1038\u00d7980 64.8 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-10T23:16:10.693Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-06T12:42:32.305Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Nested Log structure which is visible in the UI",
		"Question_link": "https://community.wandb.ai/t/nested-log-structure-which-is-visible-in-the-ui/3938",
		"Question_created_time": "2023-02-23T11:42:25.691Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 174,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>i have a model with some somemodules. I want to log the  weights and gradients using a nested \u201cfolder\u201d-strukture so that i can for example navigate like this:</p>\n<p>gradients-modeltype1 -model1<br>\ngradietns-modeltype1-model2<br>\ngradients-model2<br>\ngradietns-parameters</p>\n<p>and the same with the weights. preferably like a dropdown navigation</p>\n<p>your doku states:</p>\n<pre><code class=\"lang-auto\">Logging nested metrics is encouraged and is supported in the W&amp;B UI. If you log with a nested dictionary like wandb.log({\"train\": {\"acc\": 0.9}, \"val\": {\"acc\": 0.8}}), the metrics will be organized into train and val sections in the W&amp;B UI.\n</code></pre>\n<p>so i tried to use the nested dict stucture with:</p>\n<pre><code class=\"lang-auto\">..\n                     weights = layer.get_weights()\n                        if len(weights) == 1:\n                            metrics.update(flatten_dict.flatten({\n                                \"weights\": {\n                                    model_type: {\n                                        model.name: {\n                                            layer.name + \".weights\": _convert_weights(weights[0], histogram=histogram)\n                                        }\n                                    }\n                                }\n                            }))\n....\nreturn flatten_dict.unflatten(metrics)\n</code></pre>\n<p>but all i get are pathnames with dots in the middle. no folding stucture.  like this I even only get single histograms for all the biases and weights as a list of 300 elements. Not very usefull.</p>\n<p>is there a way  to get this working? It realy would help me a lot . I realy hope this feature exists!!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-23T16:35:41.500Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/samdabadei\">@samdabadei</a>, thank you for raising this as it looks like we need to update the documentation there. We now use the <code>/</code> character for logging nested metrics so this would be done in a flattened dictionary like this:</p>\n<pre><code class=\"lang-auto\">wandb.log({\n    \"train/acc\" : 0.9,\n    \"train/loss\" : 5.1, \n    \"val/acc\" : 0.8,\n    \"val/loss\" : 6.7\n    })\n</code></pre>\n<p>In the UI this would result in all metrics with the <code>train/</code> prefix being in the same panel and then all metrics with the <code>val/</code> being in a separate panel.</p>\n<p>Note that there is only one level of nesting available with this so logging a metrics like <code>train/dataset_2/acc</code> would just end up in the <code>train</code> group of panels and wouldn\u2019t be divided into a <code>dataset_2</code> subgroup.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/4/4f7226f00e6a54c325bd6c2cf279dc6fd7c36d9a.jpeg\" data-download-href=\"/uploads/short-url/bkOhYqkJhvwYrgjB8zjntgKWIJQ.jpeg?dl=1\" title=\"Screen Shot 2023-02-23 at 8.33.36 AM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/4f7226f00e6a54c325bd6c2cf279dc6fd7c36d9a_2_622x500.jpeg\" alt=\"Screen Shot 2023-02-23 at 8.33.36 AM\" data-base62-sha1=\"bkOhYqkJhvwYrgjB8zjntgKWIJQ\" width=\"622\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/4f7226f00e6a54c325bd6c2cf279dc6fd7c36d9a_2_622x500.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/4f7226f00e6a54c325bd6c2cf279dc6fd7c36d9a_2_933x750.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/4f7226f00e6a54c325bd6c2cf279dc6fd7c36d9a_2_1244x1000.jpeg 2x\" data-dominant-color=\"FCFCFC\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2023-02-23 at 8.33.36 AM</span><span class=\"informations\">1864\u00d71498 103 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Let me know if you have any other questions!<br>\nThank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-01T17:53:09.373Z",
				"Answer_body": "<p>Thanks for the clarificatin. Are your working on deeper nested structures? I think it would be a great improvement!<br>\nIs there any other way to get a deeper nested structure? espacially for weight-logging.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-03T22:43:52.743Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/samdabadei\">@samdabadei</a> currently there is not a way to add deeper layers of nesting but I will go ahead and make an internal feature request for this. I can follow up here once the team has had a chance to look into this.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-02T22:44:03.319Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb.watch doesnt log anything for me",
		"Question_link": "https://community.wandb.ai/t/wandb-watch-doesnt-log-anything-for-me/3996",
		"Question_created_time": "2023-03-03T15:09:40.398Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 115,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, despite trying many variations and looking through similar issues including <span class=\"hashtag\">#1197</span> and <span class=\"hashtag\">#2096</span>, I cannot manage to get wandb to log anything about parameters and gradients using wandb.watch(). The documentation has not been helpful. Here\u2019s a sample of what I\u2019m trying to do:</p>\n<pre><code class=\"lang-auto\">from torchvision.models import resnet18\nimport torch\n\nm = resnet18()\nm.train()\n\nopt = torch.optim.SGD(m.parameters(),lr=0.1)\n\nloss_fn = torch.nn.BCEWithLogitsLoss()\n\n#track with wandb\nwandb_session = wandb.init(\n    entity='kitzeslab',\n    project=\"trying wandb in opensoundscape\", \n    name='try basic gradient logging',\n)\n\n\n#tried various version of this line, with no criterion argumnet, criterion=loss_fn, etc\n# tried both wandb.watch() and wandb_session.watch()\n# tried 'all' and 'gradients' for log\nwandb_session.watch(models=m,log='all')#,criterion=loss_fn)#,crieterion=torch.nn.BCEWithLogitsLoss)\n\n#train one epoch:\n\nfor samples in train_loader:\n    #please just trust that this is how I get samples from my dataloader\n    samples = collate_samples(samples)\n    tensors = samples['samples']\n    labels = samples['labels']\n\n    #tried both forward() and __call__()\n    logits = m.__call__(tensors) \n\n    # calculate loss\n    loss = loss_fn(logits,labels.float())\n\n    opt.zero_grad()\n    # backward pass: calculate the gradients\n    loss.backward()\n    # update the network using the gradients*lr\n    opt.step()\n    wandb_session.log({'loss':loss})\n    \nwandb_session.finish()\n</code></pre>\n<p>The loss logs to wandb fine, but I don\u2019t have panels for Parameters or Gradients. Am I doing something wrong?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-03T15:15:17.043Z",
				"Answer_body": "<p>The issue was with log_freq, which defaults to 1000(!) When I specified log_freq=1, it logged everything.</p>\n<p>Counter-intuitively, logging occurs after 1000 steps. I expected that it would log after the first step, then once every 1000 steps after that.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-06T21:15:59.973Z",
				"Answer_body": "<p>Hello Sam!</p>\n<p>Looks like you found the solution for your issue, which is great! For transparency (and for others who may come across this thread), here is our documentation on <code>watch</code> saying that our default is <code>log_freq: int = 1000</code>. Unfortunately, there is no current way to set the logging to start at the firs step (besides setting <code>log_freq = 1</code>). Would you like me to write in a feature request for logging to start at the first step?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-09T23:30:43.742Z",
				"Answer_body": "<p>Hello! I wanted to follow up with you regarding your support request as I have not heard back from you. Please let me know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-02T15:15:58.755Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Rerun a deleted run in wandb sweep",
		"Question_link": "https://community.wandb.ai/t/rerun-a-deleted-run-in-wandb-sweep/3860",
		"Question_created_time": "2023-02-10T15:19:56.664Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 156,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi,</p>\n<p>Assuming I have a sweep of runs. For some reason, I wanna rerun a few of the runs. So I go ahead and delete those runs in the dashboard. But then even if I rerun the command (<code>wandb agent ...</code>), wandb is not able to rerun those runs. It will show all runs have been completed. Could wandb add the feature to rerun the runs that are not in the dashboards (for example, those that are deleted)?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-10T23:12:55.536Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/taochen\">@taochen</a>, rerunning deleted runs of a sweep is supported for grid search only. Please see the <a href=\"https://docs.wandb.ai/guides/sweeps/faq#can-i-rerun-a-grid-search\">following guide</a> on the steps to take to execute correctly. If you find that does not work for you, provide a link to your workspace and we\u2019ll take a closer look.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-04-28T20:02:06.312Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Not displaying class labels/captions in BoundingBoxes2D images",
		"Question_link": "https://community.wandb.ai/t/not-displaying-class-labels-captions-in-boundingboxes2d-images/3864",
		"Question_created_time": "2023-02-11T17:18:27.239Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 132,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi all! I\u2019m logging some images to my dashboard using this code:</p>\n<pre><code class=\"lang-auto\">box_data = [{\n  \"position\": {\n  \"minX\": xywh[0] - 3,  # ignore the weird  -3/+3 hardcoded offsets\n  \"minY\": xywh[1] - 3,\n  \"maxX\": xywh[0] + 3,\n  \"maxY\": xywh[1] + 3},\n  \"class_id\": int(cls),\n  \"scores\": {\n  \"class_score\": conf},\n  \"domain\": \"pixel\"} for *xywh, conf, cls in pred.tolist()]\nboxes = {\"predictions\": {\"box_data\": box_data, \"class_labels\": names}}  # inference-space\nself.bbox_media_panel_images.append(wandb.Image(im, boxes=boxes, caption=path.name))\n</code></pre>\n<p>My images are filled with tiny cells and I want to have the cleanest visualization of my bounding boxes, without any captions/class labels. Therefore I\u2019m purposefully not filling in the <code>box_caption</code> arg, but the visualization seems to default back to the <code>class_id</code> label, which is mandatory. I then still get images where the labels obscure other cells:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/27f98321b3c1510c054aa0b9571e50889e7a584d.jpeg\" data-download-href=\"/uploads/short-url/5HDcklryLT5O91Ofq1miO941zSl.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/27f98321b3c1510c054aa0b9571e50889e7a584d_2_504x499.jpeg\" alt=\"image\" data-base62-sha1=\"5HDcklryLT5O91Ofq1miO941zSl\" width=\"504\" height=\"499\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/27f98321b3c1510c054aa0b9571e50889e7a584d_2_504x499.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/27f98321b3c1510c054aa0b9571e50889e7a584d_2_756x748.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/27f98321b3c1510c054aa0b9571e50889e7a584d.jpeg 2x\" data-dominant-color=\"83A4A0\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">985\u00d7976 125 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Any way of <em>just</em> visualizing the bounding boxes without captions or labels?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-14T17:32:10.825Z",
				"Answer_body": "<p>Bump, this is getting buried <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-15T20:58:28.327Z",
				"Answer_body": "<p>Hi Leander,</p>\n<p>Thank you for your patience and for contacting us about this.<br>\nIf I understand correctly what you are trying to do and from your code and visualization, I see that you have assigned a value to the <code>class_id\u00a0</code> label but I do not see any <code>box_caption</code> label. I suppose that can be the reason?<br>\nPlease add the option and let me know if there is still an issue?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-21T21:24:10.458Z",
				"Answer_body": "<p>Hi Leander,</p>\n<p>Checking out if you tried my suggestion?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-03T13:11:01.842Z",
				"Answer_body": "<p>Hi Bill! Sorry for the slow response. I filled in <code>box_caption</code> with an empty string <code>\"\"</code>, but this just makes the visualization show empty label boxes of arguably the same size as when I had filled them with the class_ids:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/7/75d35409d004b359219e7d9968b3ab24a91d7c37.jpeg\" data-download-href=\"/uploads/short-url/gOkDepUaV2oAgrD3fYUsYb77fWn.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/7/75d35409d004b359219e7d9968b3ab24a91d7c37_2_502x500.jpeg\" alt=\"image\" data-base62-sha1=\"gOkDepUaV2oAgrD3fYUsYb77fWn\" width=\"502\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/7/75d35409d004b359219e7d9968b3ab24a91d7c37_2_502x500.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/7/75d35409d004b359219e7d9968b3ab24a91d7c37_2_753x750.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/7/75d35409d004b359219e7d9968b3ab24a91d7c37.jpeg 2x\" data-dominant-color=\"88A394\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">981\u00d7977 110 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p><code>box_caption=None</code> throws an error (it <em>has</em> to be a string).</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-02T13:11:44.020Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Is the wandb.ai server down right now in Germany?",
		"Question_link": "https://community.wandb.ai/t/is-the-wandb-ai-server-down-right-now-in-germany/3993",
		"Question_created_time": "2023-03-03T11:27:06.554Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 108,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\nIt seems like wandb server is down right now in Germany. Do you all are facing the same issue?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-06T20:43:33.818Z",
				"Answer_body": "<p>Hello Shreya!</p>\n<p>We had ~2 minute outage last Friday but aside from that nothing else at the time. Are you still experiencing issues?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-02T11:28:04.145Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "KeyError: \u2018fasterrcnn_resnet50\u2019",
		"Question_link": "https://community.wandb.ai/t/keyerror-fasterrcnn-resnet50/3983",
		"Question_created_time": "2023-03-02T10:48:37.188Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 49,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am trying to run this GitHub repository <a href=\"https://github.com/sovit-123/fasterrcnn-pytorch-training-pipeline#Train-on-Custom-Dataset\" rel=\"noopener nofollow ugc\">faster rcnn-pytorch-custom-dataset </a> but I got this error.</p>\n<pre><code class=\"lang-auto\">Building model from scratch...\nTraceback (most recent call last):\n  File \"train.py\", line 491, in &lt;module&gt;\n    main(args)\n  File \"train.py\", line 248, in main\n    build_model = create_model[args['model']]\nKeyError: 'fasterrcnn_resnet50'\nwandb: Waiting for W&amp;B process to finish... (failed 1). Press Control-C to abort syncing.\nwandb: Synced smoke_training: https://wandb.ai/samahwa/fastercnn-pytorch-training-pipeline/runs/ejy5jyw8\nwandb: Synced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nwandb: Find logs at: ./wandb/run-20221128_113545-ejy5jyw8/logs\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-07T13:36:37.974Z",
				"Answer_body": "<p>Hello Abubakar,</p>\n<p>Thank you for your patience and sorry this is happening to you. Could you please let me know;</p>\n<p>What is your wandb cli version?<br>\nAre there any other errors shown except these?<br>\nCould you please share with me the <code>debug.log</code> and <code>debug-internal.log</code> files located in the working directory of the project under wandb//logs/?<br>\nAre you running your script in jupyter notebook or terminal or through colab, etc.? Can I have an example training script of what you did exactly?</p>\n<p>Thank you</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-10T03:04:42.898Z",
				"Answer_body": "<p>Hello Abubakar,</p>\n<p>Could you please get back to me with an answer to my questions? That would enable me to have more information on what might be going wrong.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-05-01T10:49:01.396Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Custom plot based on a default one",
		"Question_link": "https://community.wandb.ai/t/custom-plot-based-on-a-default-one/3912",
		"Question_created_time": "2023-02-18T13:06:19.802Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 147,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\nI\u2019m finding really difficult to follow the documentation about custom plots. I am doing reinforcement learning and using the default plots that group the runs, to compare the rewards, etc. What would be the best way to replicate a default plot and change something about it? In fact, I just want to add a horizontal line (my baseline) but doing it by adding an calculated expression removes the default information.<br>\nMany thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-22T21:46:31.867Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/jorgecsilva\">@jorgecsilva</a>, you could add something like the following to your Vega spec:</p>\n<pre><code class=\"lang-auto\">\"mark\": \"rule\",\n      \"encoding\": {\n        \"y\": {\"value\": 10},\n        \"size\": {\"value\": 2},\n        \"color\": {\"field\": \"symbol\"}\n</code></pre>\n<p>In this example 10 would be the Y-value for the line.</p>\n<p>If your question is more around how the custom chart query works I\u2019d be happy to go into that more as well. One thing I want to note is that our default charts are not written in Vega so there is no 1:1 way to just copy the code into a custom chart and using the <a href=\"https://vega.github.io/vega/examples/\" rel=\"noopener nofollow ugc\">examples on the Vega website</a> is probably the best way to get started creating your own grouped charts.<br>\nThank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-28T21:20:58.714Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/jorgecsilva\">@jorgecsilva</a>, I just wanted to follow up and see if you were still looking for help with this or if the above answered your question?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-01T12:59:20.829Z",
				"Answer_body": "<p>Hi Nate</p>\n<p>Many thanks for your help, and sorry for my late answer! By now, my approach is to use the api to download the results and plot with matplotlib locally. The only reason for that is not being able to replicate a default plot and just add a horizontal line. So, it would be really great if the documentation could cover this kind scenario. To familiarize myself with the vega syntax would, I guess, take longer than what I\u2019m doing now.<br>\nThanks again!<br>\nJorge</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-30T12:59:51.540Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to create Parallel Coordinates plot without sweeps",
		"Question_link": "https://community.wandb.ai/t/how-to-create-parallel-coordinates-plot-without-sweeps/3566",
		"Question_created_time": "2022-12-18T20:15:17.195Z",
		"Question_answer_count": 10,
		"Question_score_count": 0,
		"Question_view_count": 273,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>It would be great to plot hparams without doing sweeps, most of the time I\u2019m doing experiments and I would love the plot to be across runs and not as a sweep. It might be complex to make this feature automated, but I\u2019m fine if it\u2019s within one run, would be great to have something like <code>wandb.plots.ParallelCoordinates</code></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-19T04:49:34.290Z",
				"Answer_body": "<p>Hi Faris!</p>\n<p>You absolutely can use Parallel coordinates plots without sweeps. The web UI has an option to add additional plots on the top right of the graph section which contains the Parallel Coordinates Plot.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-12-21T18:17:04.195Z",
				"Answer_body": "<p>Hi Faris,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-23T17:55:49.906Z",
				"Answer_body": "<p>Hi Faris , since we have not heard back from you we are going to close this request. If you would like to re-open this conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-13T13:36:47.336Z",
				"Answer_body": "<p>I ran on exactly the same issue, and for me it was the browser. When I switched from Safari to Chrome the \u201cpattern\u201d disappared.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-14T09:56:42.381Z",
				"Answer_body": "<p>hello and sorry for not responding earlier.</p>\n<p>Yes I found it, this is indeed what I\u2019m looking for but I\u2019d like to be able to do it programmatically as well, I took some time to play around with it but it seems that I\u2019ll have to add each HParam manually (one at a time). It would be great to be able to add them all because there could be 10s or 100s of hparams, also would be great to have the magic wand that will reduce to only the important hparams</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-14T13:00:13.108Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"farishijazi\" data-post=\"6\" data-topic=\"3566\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/f/da6949/40.png\" class=\"avatar\"> farishijazi:</div>\n<blockquote>\n<p>also would be great to have the magic wand that will reduce to only the important hparams</p>\n</blockquote>\n</aside>\n<p>You can use the parameter importance plot to find the most important parameters and then only use those Hparams when creating the parallel coordinates plot. That said, I understand it would be nice to wave a magic wand and have the parallel coordinate plot do that magically.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-22T19:42:48.957Z",
				"Answer_body": "<p>Hello Ramit,</p>\n<p>I am also interested in using the Parallel Coordinates feature but without the hyperparameter sweeps. I\u2019d like to be able to add the \u201cparameters\u201d vertical lines myself and plot data according to experimental results. I couldn\u2019t find the web UI feature you described.</p>\n<p>Also, is there a way to do this programatically from python? Please let me know.</p>\n<p>Best,<br>\nAhmed</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-27T12:11:31.809Z",
				"Answer_body": "<p>having a regex option would solve this issue, like adding all of them with \u201c<em>\" or adding \"augment_</em>\u201d to add augmentations only etc. My pain is not in the magic wand not being there, but rather I would probably want to plot this using code, and there doesn\u2019t seem to be an option. The second pain is in adding the options, using a regex search feature would solve this issue</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-28T14:30:47.856Z",
				"Answer_body": "<blockquote>\n<p>I couldn\u2019t find the web UI feature you described.</p>\n</blockquote>\n<p>You click \u201c+ Add Panel\u201d in the upper right of your W&amp;B dashboard and click \u201cParallel Coordinates Plot\u201d.</p>\n<blockquote>\n<p>programatically from python</p>\n</blockquote>\n<p>You can use the Reports API like:</p>\n<pre><code class=\"lang-auto\">report = wr.Report(\n    project=PROJECT,\n    blocks=[\n        wr.PanelGrid(\n       \n            panels=[\n                wr.ParallelCoordinatesPlot(\n                    columns=[\n                        wr.PCColumn(\"c::model\"),\n                        wr.PCColumn(\"val_acc\"),\n                        wr.PCColumn(\"val_loss\"),\n                    ],\n                ),\n            ],\n        ),\n    ]\n)\nreport.save()\n</code></pre>\n<p>See a full example and explanation here: <a href=\"http://wandb.me/report_api\">http://wandb.me/report_api</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-29T14:31:33.446Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to track perplexity?",
		"Question_link": "https://community.wandb.ai/t/how-to-track-perplexity/3967",
		"Question_created_time": "2023-02-28T12:55:24.604Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 71,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,<br>\nI\u2019m training some nlp models with huggingface, and I\u2019d like wandb to track the perplexity. How do I do this?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-01T21:16:02.727Z",
				"Answer_body": "<p>Hello Francis,</p>\n<p>Thank you for contacting support! I will get back to you on that!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-09T19:25:11.982Z",
				"Answer_body": "<p>Hello Francis,</p>\n<p>Thank you for your patience! Are you looking to log perplexity during training cycles or across various fully trained language models for comparison?<br>\nYou can report perplexity like it is done here and put in a wandb.log() for tracking perplexity.</p>\n<p>Please let me know.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-14T19:32:16.605Z",
				"Answer_body": "<p>Hello Francis,</p>\n<p>Have you tried my suggestion?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-29T12:56:20.574Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Impossible to sync offline runs (.wandb file is empty)",
		"Question_link": "https://community.wandb.ai/t/impossible-to-sync-offline-runs-wandb-file-is-empty/3904",
		"Question_created_time": "2023-02-17T14:02:19.795Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 202,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\nI perform hyperparameter optimization on a SLURM-based cluster and I\u2019d like to use w&amp;b to monitor my experiments. The thing is there is no internet access on the nodes so I have to use <code>WANDB_MODE=offline</code> and sync manually.</p>\n<p>However, when I run <code>wandb sync</code>, nothing syncs and I get the following error:</p>\n<pre><code class=\"lang-auto\">$ for dir in $WORK/wandb/offline-run-20230217_142*; do  wandb sync --include-offline --include-synced $dir; done\nFind logs at: /tmp/debug-cli.uxr88bs.log\n.wandb file is empty (header is 0 bytes instead of the expected 7), skipping: /gpfswork/rech/xsc/uxr88bs/wandb/offline-run-20230217_142720-t3kpu7v1/run-t3kpu7v1.wandb\nFind logs at: /tmp/debug-cli.uxr88bs.log\n.wandb file is empty (header is 0 bytes instead of the expected 7), skipping: /gpfswork/rech/xsc/uxr88bs/wandb/offline-run-20230217_142735-855zx96s/run-855zx96s.wandb\nFind logs at: /tmp/debug-cli.uxr88bs.log\n.wandb file is empty (header is 0 bytes instead of the expected 7), skipping: /gpfswork/rech/xsc/uxr88bs/wandb/offline-run-20230217_142753-gr9l3rct/run-gr9l3rct.wandb\nFind logs at: /tmp/debug-cli.uxr88bs.log\n.wandb file is empty (header is 0 bytes instead of the expected 7), skipping: /gpfswork/rech/xsc/uxr88bs/wandb/offline-run-20230217_142808-cq0a5u27/run-cq0a5u27.wandb\nFind logs at: /tmp/debug-cli.uxr88bs.log\n.wandb file is empty (header is 0 bytes instead of the expected 7), skipping: /gpfswork/rech/xsc/uxr88bs/wandb/offline-run-20230217_142830-51b47xny/run-51b47xny.wandb\nFind logs at: /tmp/debug-cli.uxr88bs.log\n.wandb file is empty (header is 0 bytes instead of the expected 7), skipping: /gpfswork/rech/xsc/uxr88bs/wandb/offline-run-20230217_142830-cad80jxd/run-cad80jxd.wandb\nFind logs at: /tmp/debug-cli.uxr88bs.log\n.wandb file is empty (header is 0 bytes instead of the expected 7), skipping: /gpfswork/rech/xsc/uxr88bs/wandb/offline-run-20230217_142847-pty3usj9/run-pty3usj9.wandb\nFind logs at: /tmp/debug-cli.uxr88bs.log\n.wandb file is empty (header is 0 bytes instead of the expected 7), skipping: /gpfswork/rech/xsc/uxr88bs/wandb/offline-run-20230217_142904-py7ltka6/run-py7ltka6.wandb\nFind logs at: /tmp/debug-cli.uxr88bs.log\n.wandb file is empty (header is 0 bytes instead of the expected 7), skipping: /gpfswork/rech/xsc/uxr88bs/wandb/offline-run-20230217_142904-w9yba4gv/run-w9yba4gv.wandb\nFind logs at: /tmp/debug-cli.uxr88bs.log\n.wandb file is empty (header is 0 bytes instead of the expected 7), skipping: /gpfswork/rech/xsc/uxr88bs/wandb/offline-run-20230217_142904-xg1memac/run-xg1memac.wandb\n</code></pre>\n<p>Does anybody knows why I have this issue?</p>\n<p>Thanks a lot!</p>\n<p>EDIT:<br>\non a new experiment, seeems that the folder <code>wandb</code> is arbitrarily created or not  depending on the trials, here is the output of <code>ls</code>in the folder:</p>\n<pre><code class=\"lang-auto\">$ ls $WORK/wandb/offline-run-*\n/gpfswork/rech/xsc/uxr88bs/wandb/offline-run-20230217_151514-8b2zeypo:\nfiles  logs  run-8b2zeypo.wandb  run-8b2zeypo.wandb.synced  tmp  wandb\n\n/gpfswork/rech/xsc/uxr88bs/wandb/offline-run-20230217_151528-vet88jij:\nfiles  logs  run-vet88jij.wandb  tmp\n\n/gpfswork/rech/xsc/uxr88bs/wandb/offline-run-20230217_151542-kpxxwmdn:\nfiles  logs  run-kpxxwmdn.wandb  tmp\n\n/gpfswork/rech/xsc/uxr88bs/wandb/offline-run-20230217_151557-yt9fz2o1:\nfiles  logs  run-yt9fz2o1.wandb  tmp\n\n/gpfswork/rech/xsc/uxr88bs/wandb/offline-run-20230217_151622-ruz8rrrk:\nfiles  logs  run-ruz8rrrk.wandb  tmp\n\n/gpfswork/rech/xsc/uxr88bs/wandb/offline-run-20230217_151622-taa9hzpw:\nfiles  logs  run-taa9hzpw.wandb  tmp\n\n/gpfswork/rech/xsc/uxr88bs/wandb/offline-run-20230217_151635-nrmgrly9:\nfiles  logs  run-nrmgrly9.wandb  tmp\n\n/gpfswork/rech/xsc/uxr88bs/wandb/offline-run-20230217_151652-10xqq0oi:\nfiles  logs  run-10xqq0oi.wandb  run-10xqq0oi.wandb.synced  tmp  wandb\n\n/gpfswork/rech/xsc/uxr88bs/wandb/offline-run-20230217_151652-cfvzpnaw:\nfiles  logs  run-cfvzpnaw.wandb  run-cfvzpnaw.wandb.synced  tmp  wandb\n\n/gpfswork/rech/xsc/uxr88bs/wandb/offline-run-20230217_151652-ldlx0fun:\nfiles  logs  run-ldlx0fun.wandb  tmp\n</code></pre>\n<p>the 3 runs that have a <code>wandb</code> folder are actually synced, so it seems that the issue is that this folder is not always created.</p>\n<p>Do you have an idea why?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-22T21:12:31.320Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ari0u\">@ari0u</a> , happy to help. One thing you could experiencing is you don\u2019t have read/write permissions in your working directory. Wandb will always generate a run file if executed correctly. One thing you can try is to set the directory wandb should save run files to, <strong>WANDB_DIR</strong>, more on this <a href=\"https://docs.wandb.ai/guides/track/environment-variables\">here</a>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-27T22:12:18.332Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ari0u\">@ari0u</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-28T22:13:16.231Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Explain metrics displayed in WandB",
		"Question_link": "https://community.wandb.ai/t/explain-metrics-displayed-in-wandb/3963",
		"Question_created_time": "2023-02-27T17:14:08.303Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 99,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello there!</p>\n<p>I\u2019m looking for a thorough explanation of all the plots displayed in a basic WandB dashboard, such as:</p>\n<ul>\n<li>train/loss</li>\n<li>train/global_step</li>\n<li>train/train_samples_per_second</li>\n<li>train/train_loss<br>\nMainly, I\u2019m looking for practical info, e.g. \u201ca lower train/train_loss is better\u201d, to be able to diagnose my model runs.</li>\n</ul>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-03-01T20:19:18.400Z",
				"Answer_body": "<p>Hi Francis!</p>\n<p>Are you using any integrations with wandb? <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><br>\nAre those the only three plots you are curious about?</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-06T22:07:39.103Z",
				"Answer_body": "<p>Hi Francis,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-10T17:03:37.007Z",
				"Answer_body": "<p>Hi Francis, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-28T17:14:09.495Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb background services keep running even after my code ends",
		"Question_link": "https://community.wandb.ai/t/wandb-background-services-keep-running-even-after-my-code-ends/3946",
		"Question_created_time": "2023-02-24T21:10:12.676Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 85,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>When I try running parallelized sweep runs, the wandb keeps waiting and doesn\u2019t terminate even when all the runs show status finished and everything has been logged. What could be the reason for this and how can I resolve this?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-25T00:49:41.801Z",
				"Answer_body": "<p>Hello Banooqa!</p>\n<p><code>wandb</code> asynchronously uploads your sweeps/runs to the <code>wandb</code> server which means larger sweeps/runs will still be uploading the runs to <code>wandb</code> despite your training being finished. Depending on how large the run is, you may also be hitting our rate limits which restrict the amount of API calls and parallel agents each IP and API key has. In terms of preventing this, reducing the size of your data or decreasing the amount of <code>wandb.log</code> calls you have in your script per second can also increase performance as outlined here.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-02T18:03:01.049Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-25T21:10:49.486Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Deleting a project",
		"Question_link": "https://community.wandb.ai/t/deleting-a-project/3942",
		"Question_created_time": "2023-02-24T12:40:50.116Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 162,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>Do you know I cannot remove any project? All I get is the error below.</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/3/32cde7edf7c21bdf47a0cbdf8d1f6cceee469985.png\" alt=\"Screenshot 2023-02-24 at 13.38.16\" data-base62-sha1=\"7fr1yfuGSLYlugWpRB5LtXmQNaR\" width=\"381\" height=\"161\"></p>\n<p>It might be foolish, but I cannot sort it out.<br>\nP</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-24T12:53:05.044Z",
				"Answer_body": "<p>Ok, maybe because I am not the owner of the entity\u2026 In fact, I can delete projects on my personal entity</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-24T15:05:04.575Z",
				"Answer_body": "<p>Hi Paolo!</p>\n<p>Thats right! If you are not an admin on the entity, it will not let you delete your project.</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-01T17:25:45.067Z",
				"Answer_body": "<p>Hi Paolo,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-06T21:10:49.176Z",
				"Answer_body": "<p>Hi Paolo, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-25T12:53:57.474Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb gray scale image does not show the black color",
		"Question_link": "https://community.wandb.ai/t/wandb-gray-scale-image-does-not-show-the-black-color/3932",
		"Question_created_time": "2023-02-22T18:51:40.839Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 98,
		"Question_has_accepted_answer": false,
		"Question_body": "<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/ae1cc805b9214fb901fa6efe4ffadea5217cd402.jpeg\" data-download-href=\"/uploads/short-url/oQgK6m4umuMzubtYCAHr0COqijg.jpeg?dl=1\" title=\"\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2023-02-23 03.48.05\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/ae1cc805b9214fb901fa6efe4ffadea5217cd402_2_690x143.jpeg\" alt=\"\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2023-02-23 03.48.05\" data-base62-sha1=\"oQgK6m4umuMzubtYCAHr0COqijg\" width=\"690\" height=\"143\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/ae1cc805b9214fb901fa6efe4ffadea5217cd402_2_690x143.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/ae1cc805b9214fb901fa6efe4ffadea5217cd402_2_1035x214.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/ae1cc805b9214fb901fa6efe4ffadea5217cd402_2_1380x286.jpeg 2x\" data-dominant-color=\"C5C1B7\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2023-02-23 03.48.05</span><span class=\"informations\">3028\u00d7628 213 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>I\u2019m trying to make a mask from the first image.<br>\nThe mask consists of 0, 1 values and it has only one channel.<br>\nTo check the image on Wandb, I used <code>wandb.Image(image)</code>.<br>\nBut the mask image do not show the black color, instead it describe the 0 value as gray color like second image.</p>\n<p>How can I make the 0 value to the black color?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-23T18:57:46.518Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hyuntae93\">@hyuntae93</a> , happy to help. I checked your segmentation project and it appears you did not assign masks to your images. Wandb will log the exact image provided to wandb.Image call. Were you intending to create <a href=\"https://docs.wandb.ai/guides/track/log/media#image-overlays\">overlays over the images</a>?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-24T07:27:07.625Z",
				"Answer_body": "<p>Thanks for help <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> .</p>\n<p>I didn\u2019t intend to overlay the mask over the image.<br>\nI intended to multiply the mask to the image for segmentation the image as the foreground and the background.</p>\n<p>The third image is the result of   <code>mask \\times input </code> and the last image is the result of <code>(1-mask) \\times input</code>.</p>\n<p>Then is the gray color intended result for the 0 value? instead of black color?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-25T07:27:36.666Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Getting ConnectTimeout in offline mode when trying to log an image",
		"Question_link": "https://community.wandb.ai/t/getting-connecttimeout-in-offline-mode-when-trying-to-log-an-image/3844",
		"Question_created_time": "2023-02-08T13:34:02.911Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 145,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am running wandb in offline mode since I don\u2019t have an internet connection on the compute nodes that I use for my experiments.<br>\nThis works fine when I\u2019m logging training loss and other things.<br>\nWhen I try to log images, however, I get the following warning <code>wandb: Network error (ConnectTimeout), entering retry loop.</code>  and the run waits forever.</p>\n<p>The logging happens through:</p>\n<pre><code class=\"lang-python\">images = []\nfor i in range(10):\n    images.append(wandb.Image(image[i], caption=f\"{caption}.{i}\"))\nwandb.log({category: images})\n</code></pre>\n<p>I can even see that the offline mode is active since I get the following output when I stop the run:</p>\n<pre><code class=\"lang-auto\">wandb: You can sync this run to the cloud by running:\nwandb: wandb sync /scratch_emmy/outputs/wandb/offline-run-20230208_142336-9685bcf5ea8d5d35ccc9d93b2d035832\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-10T19:43:42.600Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/arnenix\">@arnenix</a> , happy to look into this for you. I ran a test on my end and did not run into the same issue you face. I was successful in logging i<a href=\"https://wandb.ai/mohammadbakir/jira-offline-imgs/runs/1fae84wm/overview?workspace=user-mohammadbakir\">mages offline then syncing the run to wandb</a> using the same code example you provided.</p>\n<p>Which version of wandb are you using? If not <a href=\"https://github.com/wandb/wandb/releases\" rel=\"noopener nofollow ugc\">our latest</a>,  upgrade and try again.  If the problem persists, provide me a copy of your <code>debug.log</code> and <code>debug-internal.log</code> files of the runs that are failing. These are located in the run/logs folder under the wandb folder of your working directory. Thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-15T23:38:10.521Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/arnenix\">@arnenix</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-21T07:37:56.683Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> ,</p>\n<p>sorry for not responding earlier.<br>\nI also opened an issue on github and they were able to reproduce my issue and are working on a fix.<br>\nFor further info see: <a href=\"https://github.com/wandb/wandb/issues/4946\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">[CLI]: Getting ConnectTimeout in offline mode when trying to log an image \u00b7 Issue #4946 \u00b7 wandb/wandb \u00b7 GitHub</a></p>\n<p>I think this thread can be closed.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-22T07:38:37.405Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Scan_history() is empty",
		"Question_link": "https://community.wandb.ai/t/scan-history-is-empty/3811",
		"Question_created_time": "2023-02-03T10:24:00.337Z",
		"Question_answer_count": 9,
		"Question_score_count": 0,
		"Question_view_count": 220,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, when I run <code>run.history()</code>, I get a sampled version of the history as expected (although the number of samples fluctuates). But when I run <code>run.scan_history()</code>, I get an empty object (i.e. 0 rows).</p>\n<p>Any idea why this is happening or how it could be fixed?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-03T16:11:05.149Z",
				"Answer_body": "<p>Hi Christian,<br>\nHappy Friday!</p>\n<p>Could you send me some code I can try reproducing this with?</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-07T11:08:30.162Z",
				"Answer_body": "<p>Hi Artsiom, thanks for your reply!</p>\n<p>Sure, here is an API call to my project:</p>\n<pre><code class=\"lang-auto\">import wandb\napi = wandb.Api()\nruns = api.runs('chs20/scratch-public')\nfor run in runs:\n    history = run.history()\n    scan_history = run.scan_history()\n    print(f'run: {run.name}')\n    print(f'history columns: {len(history.columns)}')\n    print(f'scan_history rows: {len(scan_history.rows)}')\n</code></pre>\n<p>This outputs for me:</p>\n<pre><code class=\"lang-auto\">run: 2023-02-07_10:48:43\nhistory columns: 13\nscan_history rows: 0\n</code></pre>\n<p>I would have expected the number of <code>history</code> columns  to match the number of <code>scan_history</code> rows.  In particular I would not expect <code>scan_history</code> to have zero rows.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-10T09:04:57.998Z",
				"Answer_body": "<p>Any ideas what is causing this?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-10T21:36:11.943Z",
				"Answer_body": "<p>Sorry for the delay in response! So far I haven\u2019t been able to reproduce this on my side so trying a few things <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-20T08:56:15.814Z",
				"Answer_body": "<p>Does the code snippet yield a different output for you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-24T21:47:58.578Z",
				"Answer_body": "<p>Hi Christian, sorry it took so long to get back to you, had to try a few things out.<br>\nCan you see if something like this works for you?</p>\n<pre><code>import wandbapi = wandb.Api()runs = api.runs('chs20/scratch-public')for run in runs: history = run.scan_history() losses = [row for row in history] print(losses)\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-02T01:21:28.883Z",
				"Answer_body": "<p>Hi Christian,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-07T16:12:37.936Z",
				"Answer_body": "<p>Hi Christian, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-21T08:56:49.373Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Workspace table doesn\u2019t load",
		"Question_link": "https://community.wandb.ai/t/workspace-table-doesn-t-load/3916",
		"Question_created_time": "2023-02-19T09:07:08.490Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 225,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I have a problem with the table view of my Wandb project. It\u2019s made of several different sweeps running in parallel. Runs count goes on, and execution goes on smoothly, but the table won\u2019t load (see attachment). This happens both on mobile and on my pc.</p>\n<p>What\u2019s causing this? I\u2019m logging 30 values, and 3 confusion matrices. Could it be for what I\u2019m logging? Thanks.</p>\n<p>[<strong>update</strong> one of the three parallel processes launching sweeps were killed automatically, without a reason.]</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/b/b5a223e92b9b824e4db5b42554519fb203a2f320.jpeg\" data-download-href=\"/uploads/short-url/pUNNYCgqrPSvf5SPvmR4Xxu3Ch2.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b5a223e92b9b824e4db5b42554519fb203a2f320_2_230x500.jpeg\" alt=\"image\" data-base62-sha1=\"pUNNYCgqrPSvf5SPvmR4Xxu3Ch2\" width=\"230\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b5a223e92b9b824e4db5b42554519fb203a2f320_2_230x500.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b5a223e92b9b824e4db5b42554519fb203a2f320_2_345x750.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b5a223e92b9b824e4db5b42554519fb203a2f320_2_460x1000.jpeg 2x\" data-dominant-color=\"232425\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1179\u00d72556 126 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-23T18:18:11.725Z",
				"Answer_body": "<p>Hello Matteo,</p>\n<p>I looked into your workspace (both in Chrome in a desktop and in Safari on a mobile device) and wasn\u2019t able to reproduce the error that you are referencing. Could you let me know if this error also occurs on a desktop? If so, could you provide me the console logs? You can obtain the logs by right-clicking on the page, selecting \u201cInspect,\u201d clicking on the \u201cConsole\u201d tab, and reproducing the issue.</p>\n<p>Best,<br>\nRaphael</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-28T21:21:50.071Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-20T09:07:48.576Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "OSError: Could not find a suitable TLS CA certificate",
		"Question_link": "https://community.wandb.ai/t/oserror-could-not-find-a-suitable-tls-ca-certificate/3913",
		"Question_created_time": "2023-02-18T17:28:30.448Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 159,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am using wandb with transformers library on a conda environment created on an HPC machine. When I create the environment and install the libraries, the certificate exists under the path /conda_environments//lib/python3.8/site-packages/certifi/cacert.pem<br>\nThen after a specific time of training monitoring (around 10 hours), the certificate disappears, and I get the following error, and then the training and the monitoring are stopped.</p>\n<p>OSError: Could not find a suitable TLS CA certificate bundle, invalid path: /scratch/hpc//conda_environments//lib/python3.8/site-packages/certifi/cacert.pem<br>\nwandb: ERROR Internal wandb error: file data was not synced</p>\n<p>There is a similar issue on the GitHub repo of wandb</p><aside class=\"onebox githubissue\" data-onebox-src=\"https://github.com/wandb/wandb/issues/1488\">\n  <header class=\"source\">\n\n      <a href=\"https://github.com/wandb/wandb/issues/1488\" target=\"_blank\" rel=\"noopener nofollow ugc\">github.com/wandb/wandb</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"github-row\">\n  <div class=\"github-icon-container\" title=\"Issue\">\n\t  <svg width=\"60\" height=\"60\" class=\"github-icon\" viewbox=\"0 0 14 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z\"></path></svg>\n  </div>\n\n  <div class=\"github-info-container\">\n    <h4>\n      <a href=\"https://github.com/wandb/wandb/issues/1488\" target=\"_blank\" rel=\"noopener nofollow ugc\">OSError: Could not find a suitable TLS CA certificate bundle, invalid path</a>\n    </h4>\n\n    <div class=\"github-info\">\n      <div class=\"date\">\n        opened <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2020-11-12\" data-time=\"19:35:10\" data-timezone=\"UTC\">07:35PM - 12 Nov 20 UTC</span>\n      </div>\n\n        <div class=\"date\">\n          closed <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2020-11-12\" data-time=\"23:16:45\" data-timezone=\"UTC\">11:16PM - 12 Nov 20 UTC</span>\n        </div>\n\n      <div class=\"user\">\n        <a href=\"https://github.com/oliviersalaun\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n          <img alt=\"oliviersalaun\" src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/c/cb6e0eab1644203dd4be4823241aa3788c2ccc2b.png\" class=\"onebox-avatar-inline\" width=\"20\" height=\"20\">\n          oliviersalaun\n        </a>\n      </div>\n    </div>\n\n    <div class=\"labels\">\n    </div>\n  </div>\n</div>\n\n  <div class=\"github-row\">\n    <p class=\"github-body-container\">wandb            0.10.10\nPython 3.8.3\nDebian GNU/Linux 9 (stretch)\n\nHello,\n<span class=\"show-more-container\"><a href=\"\" rel=\"noopener\" class=\"show-more\">\u2026</a></span><span class=\"excerpt hidden\">\nIt seems that whenever I have a model running after a certain number of hours or iterations (in my case, it's beyond 13 hours), my script gets a problem related to some TLS CA certificate. So far, I have not found an issue similar to mine in this repository. I run my script inside a tmux pane. The output is shown below. For some reason, the process did not crash or stop, I had to terminate it manually.\n\n\n\n```\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send                                                           [1814/1814]\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send                                                                      \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify                                                               \nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem   \n                                                                                                                                                                                     \nDuring handling of the above exception, another exception occurred:                                                                                                                  \n                                                                                                                                                                                     \nTraceback (most recent call last):                                                                                                                                                   \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit                                                                                    \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush                                                                                   \nPermissionError: [Errno 13] Permission denied                                                                                                                                        \nCall stack:                                                                                                                                                                          \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap                                                                                      \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner                                                                                \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run                                                         \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run                                                        \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process                                                        \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send                                                               \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 101, in send_request                                                      \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 144, in send_request_status                                               \nMessage: 'Failed to check stop requested status: %s'                                                                                                                                 \nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem'),)      \n--- Logging error ---                                                                                                                                                                \nTraceback (most recent call last):                                                                                                                                                   \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit                                                                                    \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush                                                                                   \nPermissionError: [Errno 13] Permission denied                                                                                                                                        \nCall stack:                                                                                                                                                                          \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap                                                                                      \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner                                                                                \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run                                                         \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run                                                        \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process                                                        \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send                                                               \nMessage: 'send: stats'                                                                                                                                                               \nArguments: ()                                                                                                                                                                        \n--- Logging error ---                                                                                                                                                                \nTraceback (most recent call last):                                                                                                                                                   \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit                                                                                    \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush                                                                                   \nPermissionError: [Errno 13] Permission denied                                                                                                                                        \nCall stack:                                                                                                                                                                          \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap                                                                                      \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner                                                                                \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run                                                         \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run                                                        \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process                                                        \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send                                                               \nMessage: 'send: stats'                                                                                                                                                               \nArguments: ()                                                                                                                                                                        \n--- Logging error ---                                                                                                                                                                \nTraceback (most recent call last):                                                                                                                                                   \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit                                                                                    \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush                                                                                   \nPermissionError: [Errno 13] Permission denied                        \nCall stack:                                                                                                                                                               [1759/1814]\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 203, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 48, in handle\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 55, in handle_request\nMessage: 'handle_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: request'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush                                                                        [1704/1814]\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 99, in send_request\nMessage: 'send_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 24, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 768, in check_stop_requested\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/old/retry.py\", line 96, in __call__\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 130, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 52, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 60, in _get_result\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py\", line 38, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify\nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 140, in send_request_status\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 62, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/six.py\", line 702, in reraise\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 24, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 768, in check_stop_requested\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/old/retry.py\", line 96, in __call__\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 130, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 52, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 60, in _get_result\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py\", line 38, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify\nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied                                                                                                                             [1649/1814]\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 101, in send_request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 144, in send_request_status\nMessage: 'Failed to check stop requested status: %s'\nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem'),)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):                                                                                                                                        [1594/1814]\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 203, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 48, in handle\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 55, in handle_request\nMessage: 'handle_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: request'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 99, in send_request\nMessage: 'send_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 24, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 768, in check_stop_requested\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/old/retry.py\", line 96, in __call__\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 130, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 52, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 60, in _get_result\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py\", line 38, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send                                                           [1526/1801]\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send                                              \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify                                       \nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem\n                                                                                                                                             \nDuring handling of the above exception, another exception occurred:                                                                          \n                                                                                                                                             \nTraceback (most recent call last):                                                                                                           \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 140, in send_request_status       \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 62, in wrapper                         \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/six.py\", line 702, in reraise                                         \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 24, in wrapper                                                              \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 768, in check_stop_requested                                     \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/old/retry.py\", line 96, in __call__                                                                  \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 130, in execute                                                  \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 52, in execute                                                 \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 60, in _get_result                                             \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py\", line 38, in execute                                     \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 119, in post                                                                        \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 61, in request                                                                      \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request                                                                \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send                                                                   \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send                                                                   \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify                                                            \nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem\n                                                                                                                             \nDuring handling of the above exception, another exception occurred:                                                            \n                                                                                                                                      \nTraceback (most recent call last):                                                                                                    \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit                                                                              \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush                                                                             \nPermissionError: [Errno 13] Permission denied                                                                                                                                  \nCall stack:                                                                                                                                                                    \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap                                                                                \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner                                                                          \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run                                                   \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run                                                  \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process                                                  \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send                                                         \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 101, in send_request                                                \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 144, in send_request_status                                         \nMessage: 'Failed to check stop requested status: %s'                                                                                                                           \nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem'),)\n--- Logging error ---                                                                                                        \nTraceback (most recent call last):                                                                                           \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit                            \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush                           \nPermissionError: [Errno 13] Permission denied                                                                                \nCall stack:                                                                                                                  \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap                              \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner                        \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run \n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send                                                    [1458/1801]\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 203, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 48, in handle\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 55, in handle_request\nMessage: 'handle_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: request'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 99, in send_request\nMessage: 'send_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 24, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 768, in check_stop_requested\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/old/retry.py\", line 96, in __call__\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 130, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 52, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 60, in _get_result                                     [1390/1801]\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py\", line 38, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify\nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 140, in send_request_status\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 62, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/six.py\", line 702, in reraise\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 24, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 768, in check_stop_requested\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/old/retry.py\", line 96, in __call__\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 130, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 52, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 60, in _get_result\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py\", line 38, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify\nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 101, in send_request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 144, in send_request_status\nMessage: 'Failed to check stop requested status: %s'\nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem'),)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap                                                                           [1322/1801]\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 203, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 48, in handle\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 55, in handle_request\nMessage: 'handle_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: request'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush                                                                        [1254/1801]\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 99, in send_request\nMessage: 'send_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 24, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 768, in check_stop_requested\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/old/retry.py\", line 96, in __call__\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 130, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 52, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 60, in _get_result\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py\", line 38, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify\nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 140, in send_request_status\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 62, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/six.py\", line 702, in reraise\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 24, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 768, in check_stop_requested\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/old/retry.py\", line 96, in __call__\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 130, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 52, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 60, in _get_result\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py\", line 38, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify\nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 101, in send_request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 144, in send_request_status\nMessage: 'Failed to check stop requested status: %s'\nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem'),)\n--- Logging error ---\nTraceback (most recent call last):                                                                                                                                        [1186/1801]\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 203, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 48, in handle\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 55, in handle_request\nMessage: 'handle_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: request'                                                                                                                                                  [1118/1801]\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 99, in send_request\nMessage: 'send_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 24, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 768, in check_stop_requested\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/old/retry.py\", line 96, in __call__\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 130, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 52, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 60, in _get_result\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py\", line 38, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify\nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 140, in send_request_status\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 62, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/six.py\", line 702, in reraise\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 24, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 768, in check_stop_requested\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/old/retry.py\", line 96, in __call__\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 130, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 52, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 60, in _get_result\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py\", line 38, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify\nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 101, in send_request                                           [1050/1801]\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 144, in send_request_status\nMessage: 'Failed to check stop requested status: %s'\nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem'),)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 203, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 48, in handle\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 55, in handle_request\nMessage: 'handle_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner                                                                      [982/1801]\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: request'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 99, in send_request\nMessage: 'send_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 24, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 768, in check_stop_requested\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/old/retry.py\", line 96, in __call__\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 130, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 52, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 60, in _get_result\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py\", line 38, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify\nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 140, in send_request_status\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 62, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/six.py\", line 702, in reraise\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 24, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 768, in check_stop_requested\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/old/retry.py\", line 96, in __call__\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 130, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 52, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 60, in _get_result\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py\", line 38, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify\nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner                                                                      [914/1801]\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 101, in send_request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 144, in send_request_status\nMessage: 'Failed to check stop requested status: %s'\nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem'),)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush                                                                         [846/1801]\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 203, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 48, in handle\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 55, in handle_request\nMessage: 'handle_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: request'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 99, in send_request\nMessage: 'send_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 24, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 768, in check_stop_requested\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/old/retry.py\", line 96, in __call__\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 130, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 52, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 60, in _get_result\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py\", line 38, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify\nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 140, in send_request_status\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 62, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/six.py\", line 702, in reraise\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 24, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 768, in check_stop_requested\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/old/retry.py\", line 96, in __call__\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 130, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 52, in execute                                          [778/1801]\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 60, in _get_result\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py\", line 38, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify\nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 101, in send_request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 144, in send_request_status\nMessage: 'Failed to check stop requested status: %s'\nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem'),)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'                                                                                                                                                     [710/1801]\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 203, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 48, in handle\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 55, in handle_request\nMessage: 'handle_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: request'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 99, in send_request\nMessage: 'send_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 24, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 768, in check_stop_requested\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/old/retry.py\", line 96, in __call__\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 130, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 52, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 60, in _get_result\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py\", line 38, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify\nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 140, in send_request_status\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 62, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/six.py\", line 702, in reraise                                                                       [642/1801]\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 24, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 768, in check_stop_requested\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/old/retry.py\", line 96, in __call__\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 130, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 52, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 60, in _get_result\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py\", line 38, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify\nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 101, in send_request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 144, in send_request_status\nMessage: 'Failed to check stop requested status: %s'\nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem'),)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner                                                                      [574/1801]\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 203, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 48, in handle\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 55, in handle_request\nMessage: 'handle_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: request'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 99, in send_request\nMessage: 'send_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 24, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 768, in check_stop_requested                              [506/1801]\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/old/retry.py\", line 96, in __call__\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 130, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 52, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 60, in _get_result\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py\", line 38, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify\nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 140, in send_request_status\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 62, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/six.py\", line 702, in reraise\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 24, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 768, in check_stop_requested\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/old/retry.py\", line 96, in __call__\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 130, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 52, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 60, in _get_result\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py\", line 38, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify\nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 101, in send_request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 144, in send_request_status\nMessage: 'Failed to check stop requested status: %s'\nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem'),)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit                                                                          [438/1801]\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: stats'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 203, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 48, in handle\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 55, in handle_request\nMessage: 'handle_request: status'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: request'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 99, in send_request\nMessage: 'send_request: status'                                                                                                                                            [370/1801]\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 24, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 768, in check_stop_requested\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/old/retry.py\", line 96, in __call__\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 130, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 52, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 60, in _get_result\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py\", line 38, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify\nOSError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 140, in send_request_status\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 62, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/six.py\", line 702, in reraise\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 24, in wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 768, in check_stop_requested\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/old/retry.py\", line 96, in __call__\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 130, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 52, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\", line 60, in _get_result\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/transport/requests.py\", line 38, in execute\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 119, in post\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 530, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/sessions.py\", line 643, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 416, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/requests/adapters.py\", line 227, in cert_verify\nwandb.errors.error.CommError: Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 101, in send_request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 144, in send_request_status\nMessage: 'Failed to check stop requested status: %s'\nArguments: (CommError('Could not find a suitable TLS CA certificate bundle, invalid path: /u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/certifi/cacert.pem'),)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send                                                     [302/1801]\nMessage: 'send: stats'\nArguments: ()\nValidation loss: 0.1446361123191008\n\nException in thread stdout:\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: history'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 90, in send\nMessage: 'send: summary'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 61, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 260, in _finish\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/writer.py\", line 38, in finish\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/datastore.py\", line 257, in close\nMessage: 'close: %s'\nArguments: ('/u/salaunol/Documents/_2020_automne/1_PREDICT_ARTICLES/wandb/run-20201111_132925-2qrgmr2k/run-2qrgmr2k.wandb',)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 61, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 206, in _finish\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 271, in finish\nMessage: 'shutting down handler'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:                                                                                                                                                                [234/1801]\n  File \"&lt;string&gt;\", line 1, in &lt;module&gt;\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/multiprocessing/spawn.py\", line 129, in _main\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/multiprocessing/process.py\", line 108, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 129, in wandb_internal\nMessage: 'Thread SenderThread:'\nArguments: ()\nThread SenderThread:\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 33, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 60, in _run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 233, in _process\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 92, in send\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 509, in send_summary\nOSError: [Errno 127] Key has expired: '/u/salaunol/Documents/_2020_automne/1_PREDICT_ARTICLES/wandb/run-20201111_132925-2qrgmr2k/files/wandb-summary.json'\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 870, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/worker.py\", line 137, in _target\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 311, in send_event_wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 229, in _send_event\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 174, in _send_request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/request.py\", line 79, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/request.py\", line 171, in request_encode_body\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/poolmanager.py\", line 336, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 659, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 279, in _get_conn\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 937, in _new_conn\nMessage: 'Starting new HTTPS connection (%d): %s:%s'\nArguments: (1, 'o151352.ingest.sentry.io', 443)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/util/ssl_.py\", line 343, in ssl_wrap_socket\nOSError: [Errno 127] Key has expired\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 670, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 381, in _make_request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 976, in _validate_conn\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connection.py\", line 361, in connect\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/util/ssl_.py\", line 345, in ssl_wrap_socket\nurllib3.exceptions.SSLError: [Errno 127] Key has expired\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 870, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/worker.py\", line 137, in _target\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 311, in send_event_wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 229, in _send_event\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 174, in _send_request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/request.py\", line 79, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/request.py\", line 171, in request_encode_body                                               [166/1801]\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/poolmanager.py\", line 336, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 724, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/util/retry.py\", line 441, in increment\nMessage: \"Incremented Retry for (url='%s'): %r\"\nArguments: ('/api/5288891/store/', Retry(total=2, connect=None, read=None, redirect=None, status=None))\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 870, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/worker.py\", line 137, in _target\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 311, in send_event_wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 229, in _send_event\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 174, in _send_request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/request.py\", line 79, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/request.py\", line 171, in request_encode_body\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/poolmanager.py\", line 336, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 749, in urlopen\nMessage: \"Retrying (%r) after connection broken by '%r': %s\"\nArguments: (Retry(total=2, connect=None, read=None, redirect=None, status=None), SSLError(OSError(127, 'Key has expired')), '/api/5288891/store/')\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 870, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/worker.py\", line 137, in _target\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 311, in send_event_wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 229, in _send_event\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 174, in _send_request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/request.py\", line 79, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/request.py\", line 171, in request_encode_body\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/poolmanager.py\", line 336, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 752, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 659, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 279, in _get_conn\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 937, in _new_conn\nMessage: 'Starting new HTTPS connection (%d): %s:%s'\nArguments: (2, 'o151352.ingest.sentry.io', 443)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/util/ssl_.py\", line 343, in ssl_wrap_socket\nOSError: [Errno 127] Key has expired\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 670, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 381, in _make_request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 976, in _validate_conn\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connection.py\", line 361, in connect\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/util/ssl_.py\", line 345, in ssl_wrap_socket\nurllib3.exceptions.SSLError: [Errno 127] Key has expired\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:                                                                                                                                                                 [98/1801]\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 870, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/worker.py\", line 137, in _target\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 311, in send_event_wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 229, in _send_event\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 174, in _send_request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/request.py\", line 79, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/request.py\", line 171, in request_encode_body\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/poolmanager.py\", line 336, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 752, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 724, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/util/retry.py\", line 441, in increment\nMessage: \"Incremented Retry for (url='%s'): %r\"\nArguments: ('/api/5288891/store/', Retry(total=1, connect=None, read=None, redirect=None, status=None))\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 870, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/worker.py\", line 137, in _target\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 311, in send_event_wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 229, in _send_event\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 174, in _send_request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/request.py\", line 79, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/request.py\", line 171, in request_encode_body\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/poolmanager.py\", line 336, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 752, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 749, in urlopen\nMessage: \"Retrying (%r) after connection broken by '%r': %s\"\nArguments: (Retry(total=1, connect=None, read=None, redirect=None, status=None), SSLError(OSError(127, 'Key has expired')), '/api/5288891/store/')\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 870, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/worker.py\", line 137, in _target\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 311, in send_event_wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 229, in _send_event\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 174, in _send_request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/request.py\", line 79, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/request.py\", line 171, in request_encode_body\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/poolmanager.py\", line 336, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 752, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 752, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 659, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 279, in _get_conn\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 937, in _new_conn\nMessage: 'Starting new HTTPS connection (%d): %s:%s'\nArguments: (3, 'o151352.ingest.sentry.io', 443)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/util/ssl_.py\", line 343, in ssl_wrap_socket\nOSError: [Errno 127] Key has expired\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 670, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 381, in _make_request                                               [30/1801]\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 976, in _validate_conn\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connection.py\", line 361, in connect\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/util/ssl_.py\", line 345, in ssl_wrap_socket\nurllib3.exceptions.SSLError: [Errno 127] Key has expired\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 870, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/worker.py\", line 137, in _target\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 311, in send_event_wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 229, in _send_event\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 174, in _send_request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/request.py\", line 79, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/request.py\", line 171, in request_encode_body\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/poolmanager.py\", line 336, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 752, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 752, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 724, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/util/retry.py\", line 441, in increment\nMessage: \"Incremented Retry for (url='%s'): %r\"\nArguments: ('/api/5288891/store/', Retry(total=0, connect=None, read=None, redirect=None, status=None))\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 870, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/worker.py\", line 137, in _target\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 311, in send_event_wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 229, in _send_event\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 174, in _send_request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/request.py\", line 79, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/request.py\", line 171, in request_encode_body\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/poolmanager.py\", line 336, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 752, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 752, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 749, in urlopen\nMessage: \"Retrying (%r) after connection broken by '%r': %s\"\nArguments: (Retry(total=0, connect=None, read=None, redirect=None, status=None), SSLError(OSError(127, 'Key has expired')), '/api/5288891/store/')\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 890, in _bootstrap\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/threading.py\", line 870, in run\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/worker.py\", line 137, in _target\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 311, in send_event_wrapper\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 229, in _send_event\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/sentry_sdk/transport.py\", line 174, in _send_request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/request.py\", line 79, in request\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/request.py\", line 171, in request_encode_body\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/poolmanager.py\", line 336, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 752, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 752, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 752, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 659, in urlopen\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 279, in _get_conn\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 937, in _new_conn\nMessage: 'Starting new HTTPS connection (%d): %s:%s'\nArguments: (4, 'o151352.ingest.sentry.io', 443)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1085, in emit\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/logging/__init__.py\", line 1065, in flush\nPermissionError: [Errno 13] Permission denied\nCall stack:\n  File \"/u/salaunol/anaconda3/envs/cuda101/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 138, in handle_exit\nMessage: 'Internal process exited'\nArguments: ()\n```</span></p>\n  </div>\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>I reproduced this issue several times with different models and different pipelines to check that it was not something related to my code. The common pattern is that this happened only for long training (more than 10 hours)</p>\n<p>Thank you</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-23T20:15:16.104Z",
				"Answer_body": "<p>Hello Nadhem!</p>\n<p>Just some questions to get a better understanding of the issue:</p>\n<ul>\n<li>Are you on Public Cloud or a Local Instance?\n<ul>\n<li>If you are on a Local Instance, could you send the Debug Bundle? An admin of the instance can get it from the <code>/system-admin</code> page \u2192 top right corner W&amp;B icon \u2192 <code>Debug Bundle</code>.</li>\n<li>If you are on the Public Cloud, could you send your <code>debug.log</code> and <code>debug-internal.log</code> for the run? To get the <code>debug.log</code> and <code>debug-internal.log</code> files, go to the wandb folder in your computer\u2019s working directory. The folder has subfolders named run-DATETIME-ID, which correspond to specific runs. Could you retrieve the debug logs for a run that stopped?</li>\n</ul>\n</li>\n</ul>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-28T23:05:22.943Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-19T17:28:50.572Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to get all stdout from log",
		"Question_link": "https://community.wandb.ai/t/how-to-get-all-stdout-from-log/3895",
		"Question_created_time": "2023-02-16T19:02:49.175Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 362,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am trying to get all the standard output of my run in log. I can see this screen on the web console:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/5/5fbacd8534d6292b5ce0a30a167fe896d30488a9.png\" data-download-href=\"/uploads/short-url/dERA8zxAjiNltMHn8FqM9a3SvUt.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/5/5fbacd8534d6292b5ce0a30a167fe896d30488a9.png\" alt=\"image\" data-base62-sha1=\"dERA8zxAjiNltMHn8FqM9a3SvUt\" width=\"690\" height=\"337\" data-dominant-color=\"494B4D\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">776\u00d7380 69.4 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>However, I can\u2019t copy and paste all of the text (it only copies the current screen) and inspect element also shows that when I scroll down, other things are cleared from memory</p>\n<p>I would also be interested if there\u2019s a way to get this stdout from the API, too</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-17T00:27:53.547Z",
				"Answer_body": "<p>Ah, I now see there\u2019s a download button top right:</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/231873544bd099d36a0fefeb254f4dc66e4bea8b.png\" alt=\"image\" data-base62-sha1=\"50t5YGeiOCpCcEFcULgzy4GOJu3\" width=\"195\" height=\"239\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-17T18:07:08.204Z",
				"Answer_body": "<p>Hello Arthur!</p>\n<p>Looks like you were able to find the solution! Is there anything else that you need help with?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-18T12:11:13.319Z",
				"Answer_body": "<p>Actually yes - is there any way to get this from an API call?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-23T22:08:59.405Z",
				"Answer_body": "<p>The output log can be located in the <code>wandb</code> folder in your computer\u2019s working directory. That folder has folders formatted as <code>run-DATETIME-ID</code> - each of which is associated with an individual run. In there should be an <code>output.log</code>.</p>\n<p>If the <code>ourput.log</code> file is not there, you can download the file via the following code snippet (derived from the Api and File documentation)</p>\n<pre><code>api = wandb.Api()run = api.run('&lt;entity&gt;/&lt;project&gt;/&lt;id&gt;')file = run.file('output.log')file.download()\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-01T17:35:19.423Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-19T12:11:31.737Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Using the python API to delete runs without a particular tag",
		"Question_link": "https://community.wandb.ai/t/using-the-python-api-to-delete-runs-without-a-particular-tag/3818",
		"Question_created_time": "2023-02-04T07:38:33.565Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 199,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>How do I use the Python API to find and delete runs without a particular tag?</p>\n<p>I tried writing this MongoDB query, but it doesn\u2019t appear to work:</p>\n<pre><code class=\"lang-auto\">for r in (api.runs(\n    path...\n    filters={\"tags\": {\"$in\": \"keep\"}}\n)):\n</code></pre>\n<p>This is similar to <a href=\"https://community.wandb.ai/t/using-the-python-api-to-delete-models-with-no-tag-minimal/1498\">this post</a></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-04T08:51:04.845Z",
				"Answer_body": "<p>According to ChatGPT, I can use the following:</p>\n<pre><code class=\"lang-auto\">api.runs(entity_project, filters={\"tags\": \"keep\"}\n</code></pre>\n<p>However, it is not clear to me whether that means the tags must be \u201ckeep\u201d and nothing else, or whether it matches all runs with \u201ckeep\u201d in the list.  I would love an example of this kind of query in the [code]( <a href=\"https://github.com/wandb/wandb/blob/latest/wandb/apis/public.py#L782\" rel=\"noopener nofollow ugc\">wandb/public.py at latest \u00b7 wandb/wandb (github.com)</a>)</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-06T13:16:24.206Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/turian\">@turian</a>, thanks for your question! You can delete runs without a concrete tag with a code like:</p>\n<pre><code class=\"lang-auto\">import wandb\napi = wandb.Api()\nruns = api.runs('entity_name/project_name')\nfor run in runs:\n  if \"keep\" not in run.tags:\n    run.delete()\n</code></pre>\n<p>Could you please try it and see if it works?</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-02-09T15:21:13.877Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/turian\">@turian</a>  , I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-17T22:10:29.172Z",
				"Answer_body": "<p>Looks good! Marking as the solution</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-18T22:11:22.723Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Batch size and other config parameters are inaccessible in the dashboard",
		"Question_link": "https://community.wandb.ai/t/batch-size-and-other-config-parameters-are-inaccessible-in-the-dashboard/3897",
		"Question_created_time": "2023-02-16T21:31:43.752Z",
		"Question_answer_count": 2,
		"Question_score_count": 1,
		"Question_view_count": 136,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I run this line right before the training loop:</p>\n<pre><code class=\"lang-auto\">wandb.config = {\n\"train_steps\": train_steps,\n\"batch_size\": batch_size,\n\"unet1_dim\": unet1_dim,\n\"unet2_dim\": unet2_dim,\n\"unet_training\": unet_training,\n}\n</code></pre>\n<p>But on the dashboard, I can\u2019t seem to find anything related to batch size. All of the data logged with <code>wandb.log</code> is present, but nothing about my hyperparameters. It may be relevant that I\u2019m running offline and syncing with the command <code>wandb sync --sync-all</code>.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-17T22:04:09.997Z",
				"Answer_body": "<p>Hello Jaden!</p>\n<p>Could try logging your  <code>wandb.config</code>  using the following code snippet? Just in case, some further documentation on logging your config can be found <a href=\"https://docs.wandb.ai/guides/track/config#overview\">here</a>.</p>\n<pre><code class=\"lang-auto\">config = { \"train_steps\": train_steps, \"batch_size\": batch_size, \"unet1_dim\": unet1_dim, \"unet2_dim\": unet2_dim, \"unet_training\": unet_training }\nwandb.init(project = '&lt;your-project&gt;', config = config)\n</code></pre>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-04-18T22:04:26.039Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Archive runs",
		"Question_link": "https://community.wandb.ai/t/archive-runs/3793",
		"Question_created_time": "2023-02-01T17:46:25.873Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 311,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Thanks for your good product.</p>\n<p>It would be good to add an archive feature for runs.</p>\n<p>In a project, we may try many ideas. But most of them result in no outcomes. It would be good to archive those runs to keep the workspace clean.</p>\n<p>It is not a good option to delete them, because we may check them in future for some cases, such as ablation study.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-01T17:54:51.728Z",
				"Answer_body": "<p>Currently, i\u2019m using an \u2018archive\u2019 tag with filtering to do this. But it is not decent.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-01T22:46:17.181Z",
				"Answer_body": "<p>Hi Geo, thank you for the feature request! I can put in a ticket for this, but first can you tell me why putting an \u2018archive\u2019 tag isn\u2019t a good workaround for you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-02T11:07:42.585Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lesliewandb\">@lesliewandb</a> , it\u2019s ok but not decent and efficient.</p>\n<p>I think we can still use tags to do this archive feature, but it would be good to add a multi-selection feature for runs and tag them all at once. It is very useful for users who deal with hundreds of experiments, such as hyperparameter searching.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-07T01:08:41.056Z",
				"Answer_body": "<p>I see, this makes sense. Thank you for the clarification here! I\u2019ll create the ticket and let you know when there\u2019s any update on it</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-17T21:51:42.465Z",
				"Answer_body": "<p>I believe currently wandb does support multiple selection. But not in the workspace view. In the table view I can select and tag multiple runs at once.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-04-18T21:52:19.289Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Team members can not access moved runs",
		"Question_link": "https://community.wandb.ai/t/team-members-can-not-access-moved-runs/3903",
		"Question_created_time": "2023-02-17T08:07:29.270Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 253,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I moved several runs to an existing team following the description here: <a href=\"https://docs.wandb.ai/ref/app/features/teams#move-runs-to-a-team\" class=\"inline-onebox\">Teams - Documentation</a>. I can see the runs in the team workspace, however the other members of the team still can not access these runs, despite the privacy of these runs showing as \u2018team\u2019. What can I do to share the runs with other members of the team?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-17T10:46:13.311Z",
				"Answer_body": "<p>Hi Tom, thank you for reporting this issue. I will close this ticket here in the forum, as I have followed up with you by email, as more information regarding your account is needed - and we can continue the resolution from there.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-18T10:47:12.521Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "--exclude-globs doesn't work in sync",
		"Question_link": "https://community.wandb.ai/t/exclude-globs-doesnt-work-in-sync/3899",
		"Question_created_time": "2023-02-17T01:30:06.406Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 366,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I use the command to sync offline-run:</p>\n<pre><code class=\"lang-shell\">wandb sync --exclude-globs \"**/*.npy\" --sync-all\n</code></pre>\n<p>However, the *.npy files are still uploaded. The path of these files are in wandb/run_id/files/array . Is the way I use --exclude-globs incorrect?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-17T02:17:51.431Z",
				"Answer_body": "<p>Find the same question here</p><aside class=\"onebox githubissue\" data-onebox-src=\"https://github.com/wandb/wandb/issues/3454\">\n  <header class=\"source\">\n\n      <a href=\"https://github.com/wandb/wandb/issues/3454\" target=\"_blank\" rel=\"noopener nofollow ugc\">github.com/wandb/wandb</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"github-row\">\n  <div class=\"github-icon-container\" title=\"Issue\">\n\t  <svg width=\"60\" height=\"60\" class=\"github-icon\" viewbox=\"0 0 14 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z\"></path></svg>\n  </div>\n\n  <div class=\"github-info-container\">\n    <h4>\n      <a href=\"https://github.com/wandb/wandb/issues/3454\" target=\"_blank\" rel=\"noopener nofollow ugc\">[Q] How to use `wandb sync --exclude-globs` properly?</a>\n    </h4>\n\n    <div class=\"github-info\">\n      <div class=\"date\">\n        opened <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2022-04-01\" data-time=\"05:52:27\" data-timezone=\"UTC\">05:52AM - 01 Apr 22 UTC</span>\n      </div>\n\n\n      <div class=\"user\">\n        <a href=\"https://github.com/JinchaoLove\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n          <img alt=\"JinchaoLove\" src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/1/1c4fbc24ed8493cf5d20cb695405d36a1ad9781f.png\" class=\"onebox-avatar-inline\" width=\"20\" height=\"20\">\n          JinchaoLove\n        </a>\n      </div>\n    </div>\n\n    <div class=\"labels\">\n    </div>\n  </div>\n</div>\n\n  <div class=\"github-row\">\n    <p class=\"github-body-container\">Hi, I want to exclude some large files, such as `*.pt`, when uploading an offlin<span class=\"show-more-container\"><a href=\"\" rel=\"noopener\" class=\"show-more\">\u2026</a></span><span class=\"excerpt hidden\">e training directory to W&amp;B. I've tried the command lines `wandb sync --exclude-globs \\*.pt offline-run-xxx` and `wandb sync --exclude-globs \"*.pt\" offline-run-xxx`,  but they doesn't seem to work. May I ask how to use the `--exclude-globs` option properly?</span></p>\n  </div>\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-02-17T20:29:09.007Z",
				"Answer_body": "<p>Hello Yao!</p>\n<p>Looks like you got the solution for your question, which is great! Is there anything else that you need?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-18T02:17:56.469Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Could someone please optimize the wandb Table and set the content in the center",
		"Question_link": "https://community.wandb.ai/t/could-someone-please-optimize-the-wandb-table-and-set-the-content-in-the-center/3891",
		"Question_created_time": "2023-02-16T13:03:36.577Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 70,
		"Question_has_accepted_answer": false,
		"Question_body": "<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/e/ea5ee2c35582498d65511b7c76629322ab82b905.png\" data-download-href=\"/uploads/short-url/xrl1eIOWcCl9XiR78obN26zz8PP.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ea5ee2c35582498d65511b7c76629322ab82b905_2_690x162.png\" alt=\"image\" data-base62-sha1=\"xrl1eIOWcCl9XiR78obN26zz8PP\" width=\"690\" height=\"162\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ea5ee2c35582498d65511b7c76629322ab82b905_2_690x162.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ea5ee2c35582498d65511b7c76629322ab82b905_2_1035x243.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ea5ee2c35582498d65511b7c76629322ab82b905_2_1380x324.png 2x\" data-dominant-color=\"F2F9F0\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1761\u00d7415 18.5 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-16T23:50:37.441Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/moailaozi\">@moailaozi</a> , happy to help and thank you for raising this. I will flag it for our app team to review and keep you updated once a fix is implemented.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-17T23:51:14.495Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Configuration sweep key not appearing during sweep run nor changing values",
		"Question_link": "https://community.wandb.ai/t/configuration-sweep-key-not-appearing-during-sweep-run-nor-changing-values/3868",
		"Question_created_time": "2023-02-12T20:55:21.750Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 61,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m using stable baselines 3 (SB3) and in order to use one activation function or another, you must pass it to the SB3 algo as kwargs, that is:</p>\n<pre><code class=\"lang-auto\">model = A2C(\n            policy=config['policy'],\n            env=env,\n            learning_rate=config['learning_rate'],\n            gae_lambda=config['gae_lambda'],\n            ent_coef=config['ent_coef'],\n            tensorboard_log=LOGS_DIR,\n            device=config['device'],\n            verbose=config['verbose'],\n\n            policy_kwargs=dict(\n                net_arch=dict(\n                    pi=config['policy_nn'],\n                    vf=config['value_nn']),\n                activation_fn=config['activation_fn'],\n                optimizer_class=config['optimizer_class'])\n        )\n</code></pre>\n<p>where:</p>\n<pre><code class=\"lang-auto\">config['activation_fn']  = th.nn.ReLU\n</code></pre>\n<p>or</p>\n<pre><code class=\"lang-auto\">config['activation_fn']  = th.nn.Tanh\n</code></pre>\n<p>If I configure the sweep dictionary key for the \u2018activation_fn\u2019 as:</p>\n<pre><code class=\"lang-auto\">'optimizer_fn':{\n    'values': [th.nn.ReLU, th.nn.Tanh]\n}\n</code></pre>\n<p>Afterwards when running sweeps, those values are not seen by wandb, neither in the plots appears the optimizer_fn been used nor changes to the other option.</p>\n<p>Is it because the sweep config dictionary only accepts string for that kind of values?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-15T21:46:54.641Z",
				"Answer_body": "<p>Hey Carlos,</p>\n<p>Thank you for your contacting us!</p>\n<p>Is the value for th.nn.ReLU or th.nn.Tanh in this case a tuple or a single value or a list of values?</p>\n<p>If it is more than one value for each of them I suggest trying this</p>\n<p>\u2018optimizer_fn\u2019: {</p>\n<pre><code>         'values': {'relu_values': [th.nn.ReLU], 'tanh_value':[tn.nn.Tanh]\n</code></pre>\n<p>Let me know if it still doesn\u2019t show anything.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-16T19:57:32.786Z",
				"Answer_body": "<p>Thanks for the reply bill-morrison,  I finally sort it out doing the following:</p>\n<pre><code class=\"lang-auto\"># Activation function\n        if config['activation_fn'] == 'Relu':\n            activation_fn = th.nn.ReLU\n        elif config['activation_fn'] == 'Tanh':\n            activation_fn = tn.nn.Tanh\n</code></pre>\n<p>That way I can just pass the string to the sweep config, does the job.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-17T19:57:47.176Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Very Large numbers in Logged Metrics in Runs Table",
		"Question_link": "https://community.wandb.ai/t/very-large-numbers-in-logged-metrics-in-runs-table/3853",
		"Question_created_time": "2023-02-09T09:20:42.253Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 84,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m running physics experiments and tracking it with WandB.</p>\n<p>I\u2019m tracking the logarithm of a very large number (logmetric) and a very large number directly (metric).</p>\n<p>The logarithmic value of the metric has a numerical value of logmetric=140, but when I track the exponentiated metric which is metric=1.3e+65, the dashboard says \u2018Infinity\u2019.</p>\n<p>Is my assumption correct that the dashboard simply translates very large numbers to \u2018Infinity\u2019 (which makes sense)?<br>\nIs there a way to enable scientific number representation?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-10T01:13:04.075Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ludwigwinkler\">@ludwigwinkler</a> , that is is correct, very large numbers are represented as infinity and there isn\u2019t currently a method to prevent this from happening in the workspace. I\u2019ll be happy to submit a feature request in for you to all users the option to choose how to represent very large numbers.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-10T12:08:59.076Z",
				"Answer_body": "<p>Thank yo for your reply.<br>\nThe distinction to real infinity values like np.inf is currently not clear.<br>\nYou\u2019d quickly get the impression that your algorithm/prediction/metric has diverged but instead it\u2019s still valid, albeit very large.<br>\n\u2018(Infinity)\u2019 in brackets or some other visual hint that it\u2019s just WandB that\u2019s portraying it as \u2018Infinity\u2019 would be helpful.</p>\n<p>I\u2019d be glad if you\u2019d submit a feature request for some visual clarification of the \u2018Infinity\u2019 vs \u2018np.inf\u2019 clarification.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-10T19:22:21.424Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ludwigwinkler\">@ludwigwinkler</a> , following back on this. Do you have an example workspace or brief code snippet to reproduce this behavior. I was successful in <a href=\"https://wandb.ai/mohammadbakir/jira-inf-test/table?workspace=user-mohammadbakir\">logging the following</a> without wandb modify the representation of the data.</p>\n<p><code>wandb.init(project=project, entity=entity, config ={\"np.inf\": np.inf, \"exp-num\": 2.5e35, \"very-lrg-num\": 1.3e+65, \"null-col\": None})</code></p>\n<p>When you logged your large values, were they logged in scientific notation?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-15T12:17:17.947Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> ,</p>\n<p>I could successfully log the quantities as shown in the attached screenshot.<br>\nI also logged the values as metrics as compared to configs.<br>\nI think the representation bug lies with pytorch, as tensors are evaluated to infinity internally in PyTorch.</p>\n<pre><code class=\"lang-auto\">torch.scalar_tensor(141.).exp()=tensor(inf)\n</code></pre>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/26840458970f9dfc095a82fa6aac575278f36088.png\" data-download-href=\"/uploads/short-url/5uIZjvmEVMJbroMdtNef9tFV9ag.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/26840458970f9dfc095a82fa6aac575278f36088_2_690x38.png\" alt=\"image\" data-base62-sha1=\"5uIZjvmEVMJbroMdtNef9tFV9ag\" width=\"690\" height=\"38\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/26840458970f9dfc095a82fa6aac575278f36088_2_690x38.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/26840458970f9dfc095a82fa6aac575278f36088_2_1035x57.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/26840458970f9dfc095a82fa6aac575278f36088_2_1380x76.png 2x\" data-dominant-color=\"F4F4F4\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1991\u00d7110 15.8 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>So I guess WandB is doing everything correctly and surprisingly, PyTorch is \u2018cutting corners\u2019 due to numerical overflows. <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-15T23:34:48.888Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ludwigwinkler\">@ludwigwinkler</a> , thank you for confirming your findings! Please do write in again anytime we could be of help.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-16T23:35:05.418Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Why I am logging same plot all over again?",
		"Question_link": "https://community.wandb.ai/t/why-i-am-logging-same-plot-all-over-again/3878",
		"Question_created_time": "2023-02-14T08:47:12.266Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 140,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I am trying to log plt plot as wandb.Image in my sweep, but I have an issue. Wandb.log will log only one first one and then it logs it all over again. Can you help me guys? Pasting my log plot code.</p>\n<pre><code class=\"lang-python\">        for name, index in zip(names, indexes):\n            print(index)\n            pca_values = PCA().fit_transform(np.append(y_pred[:,index], y_valid[:,index],0))\n            c_map = [\"red\"] * y_pred.shape[0] + [\"green\"] * y_valid.shape[0]\n\n\n            plt.scatter(pca_values[:,0], pca_values[:,1],c=c_map, s=400,alpha=0.3)\n            for i in range(pca_values.shape[0]):\n                label = f\"P-{i}\" if i &lt; y_pred.shape[0] else str(i - y_pred.shape[0])\n                plt.text(pca_values[i,0], pca_values[i,1], label, ha=\"center\", va=\"center\", color='black')\n            plt.grid('minor')\n            plt.title(name)\n\n            wandb.log(\n                {\n                    f\"{name}_plot\" : wandb.Image(plt)\n                }\n            )\n</code></pre>\n<p>Can someone help me? It is possible that I have an issue not understanding plt correctly\u2026</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-14T16:27:25.047Z",
				"Answer_body": "<p>Hi William!</p>\n<p>When you are talking about plt, are you talking about the <code>matplotlib</code> library?</p>\n<p>Cheers,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-15T14:37:10.639Z",
				"Answer_body": "<p>yes, I am using matplotlib.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-21T16:04:31.627Z",
				"Answer_body": "<p>Hi William!<br>\nAlthough <code>maltplotlib</code> does create an image of the graph, we do have an integration with their library to where you should be able to log it directly like this from our documentation:</p>\n<pre><code>import matplotlib.pyplot as pltplt.plot([1, 2, 3, 4])plt.ylabel(\"some interesting numbers\")wandb.log({\"chart\": plt})\n</code></pre>\n<p>Also, I would advise you to check if your step/global step is going up if you are running into an issue with your plot being overwritten.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-24T19:12:04.396Z",
				"Answer_body": "<p>Hi William,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-01T21:03:08.246Z",
				"Answer_body": "<p>Hi William, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-16T14:37:41.471Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sweep when each experiment consists on 2 trains?",
		"Question_link": "https://community.wandb.ai/t/sweep-when-each-experiment-consists-on-2-trains/3885",
		"Question_created_time": "2023-02-15T09:40:15.003Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 110,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi! I need to create a sweep where, for each run I actually need the script to run 2 separate training processes, as I need to pre-train some modules (one call to train.py) and then I need to train the actual model using the pre-trained parts (another call to train.py)<br>\nIs there a way of doing this?<br>\nThanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-15T12:28:01.911Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/arcmle\">@arcmle</a>, thanks for your question! If I\u2019m understanding you properly, this should be doable by specifying these instructions inside the function you\u2019re passing to the agent like:</p>\n<pre><code class=\"lang-auto\">def main():\n  pretrained_model = train()\n  final_model = train(pretrained_model)\nwandb.agent(id, function=main, count=1)\n</code></pre>\n<p>Please let me know if this would work for you and feel free to ask any questions!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-21T09:45:52.047Z",
				"Answer_body": "<p>Hi arcmle,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-16T12:28:29.682Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Logging a tensor of best model residuals",
		"Question_link": "https://community.wandb.ai/t/logging-a-tensor-of-best-model-residuals/3846",
		"Question_created_time": "2023-02-08T14:43:00.259Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 77,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I try to log the residuals of the best model of the run and I cannot do it with the wandb_logger (lightning).</p>\n<p>I do:</p>\n<pre><code class=\"lang-auto\">self.log(\"%s_residuals\" % mode, residuals)\n</code></pre>\n<p>And I get:</p>\n<pre><code class=\"lang-auto\">Exception has occurred: ValueError\n`self.log(val_residuals, tensor([ 922.9688,  892.0009, 1414.1432, 1549.3324, 1341.1199,  902.2733,\n        1103.2998, 1066.6083,  837.4913,  921.2358, 1132.7634, 1488.9233,\n        1219.2042,  640.6171,  875.3945, 1070.0031,  917.9532, 1288.4425,\n        1154.5270, 1156.2522,  914.9966, 1250.5038, 1070.0439, 1272.7135,\n         936.7913,  703.1593,  726.7241, 1387.6118, 1317.7161,  959.2494,\n         727.7173,  912.6650], device='cuda:0'))` was called, but the tensor must have a single element. You can try doing `self.log(val_residuals, tensor([ 922.9688,  892.0009, 1414.1432, 1549.3324, 1341.1199,  902.2733,\n        1103.2998, 1066.6083,  837.4913,  921.2358, 1132.7634, 1488.9233,\n        1219.2042,  640.6171,  875.3945, 1070.0031,  917.9532, 1288.4425,\n        1154.5270, 1156.2522,  914.9966, 1250.5038, 1070.0439, 1272.7135,\n         936.7913,  703.1593,  726.7241, 1387.6118, 1317.7161,  959.2494,\n         727.7173,  912.6650], device='cuda:0').mean())`\n  File \"C:\\github\\absdabsde\\absdabsde\\absdabsde.py\", line 241, in _calculate_loss\n    self.log(\"%s_residuals\" % mode, residuals)\n  File \"C:\\github\\absdabsde\\absdabsde\\absdabsde.py\", line 209, in validation_step\n    self._calculate_loss(batch, mode=\"val\")\n  File \"C:\\github\\absdabsde\\absdabsde\\absdabsde.py\", line 270, in train_model\n    trainer.fit(model, train_loader, val_loader)\n  File \"C:\\github\\absdabsde\\absdabsde\\absdabsde.py\", line 290, in &lt;module&gt;\n    model, results = train_model(\nValueError: `self.log(val_residuals, tensor([ 922.9688,  892.0009, 1414.1432, 1549.3324, 1341.1199,  902.2733,\n        1103.2998, 1066.6083,  837.4913,  921.2358, 1132.7634, 1488.9233,\n        1219.2042,  640.6171,  875.3945, 1070.0031,  917.9532, 1288.4425,\n        1154.5270, 1156.2522,  914.9966, 1250.5038, 1070.0439, 1272.7135,\n         936.7913,  703.1593,  726.7241, 1387.6118, 1317.7161,  959.2494,\n         727.7173,  912.6650], device='cuda:0'))` was called, but the tensor must have a single element. You can try doing `self.log(val_residuals, tensor([ 922.9688,  892.0009, 1414.1432, 1549.3324, 1341.1199,  902.2733,\n        1103.2998, 1066.6083,  837.4913,  921.2358, 1132.7634, 1488.9233,\n        1219.2042,  640.6171,  875.3945, 1070.0031,  917.9532, 1288.4425,\n        1154.5270, 1156.2522,  914.9966, 1250.5038, 1070.0439, 1272.7135,\n         936.7913,  703.1593,  726.7241, 1387.6118, 1317.7161,  959.2494,\n         727.7173,  912.6650], device='cuda:0').mean())\n</code></pre>\n<p>Any suggestion on how I can log my best model\u2019s residuals will be helpful!!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-09T22:35:32.352Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sashapiv\">@sashapiv</a> , happy to help. This error is stemming from the <a href=\"https://pytorch-lightning.readthedocs.io/en/stable/common/lightning_module.html\" rel=\"noopener nofollow ugc\">LightningModule</a> which accept single value in <code>self.log(val_residuals, &lt;val&gt;)</code>, thus the recommendation of taking the average across your tensor per log call, \u201cYou can try doing <code>self.log(val_residuals, &lt;tensor&gt;).mean()</code>\u201d.  How are you currently calculating your residuals?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-15T01:05:09.356Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sashapiv\">@sashapiv</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-15T08:35:39.531Z",
				"Answer_body": "<p>Thank you <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> , currently I calculate residuals inside a step:</p>\n<pre><code class=\"lang-auto\">predictions = self.model(data1, data2)\nresiduals = targets - predictions\n</code></pre>\n<p>I perform additional metric on the residuals and I want to make an analysis on the best model\u2019s residuals after the run is finished, so logging the mean is not enough for me\u2026</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-16T08:36:05.637Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "TensorFlow 2 Object Detection API with W&B",
		"Question_link": "https://community.wandb.ai/t/tensorflow-2-object-detection-api-with-w-b/3770",
		"Question_created_time": "2023-01-29T19:13:33.564Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 401,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello everyone! Firstime using Weights and biases. Came from 2 minute papers and  was pleasantly surprised when I heard 3 blue 1 brown in the promo video also! Must be a good tool if 2 of my favorite YouTubers are involved!</p>\n<p>Since I\u2019m a new user I included all of my resources links and images in this paste bin:</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://pastebin.com/wQgmjADX\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/0/074c06983b1528839dce1ba4483d63e9070d13fa.png\" class=\"site-icon\" width=\"16\" height=\"16\">\n\n      <a href=\"https://pastebin.com/wQgmjADX\" target=\"_blank\" rel=\"noopener nofollow ugc\">Pastebin</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    \n\n<h3><a href=\"https://pastebin.com/wQgmjADX\" target=\"_blank\" rel=\"noopener nofollow ugc\">[1] TensorFlow 2 Object Detection API:...</a></h3>\n\n  <p>Pastebin.com is the number one paste tool since 2002. Pastebin is a website where you can store text online for a set period of time.</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n<p><em>the last link in the above paste is the link to the imgur images</em></p>\n<p>I\u2019m developing a Car Object Detection model for a university project using the TensorFlow 2 Object Detection API [1].<br>\nTo get to the point I\u2019m at now where I have a trained model for object detection I was following this tutorial: [2]</p>\n<p>My question is how can I Integrate W&amp;B into a \"TensorFlow 2 Object Detection API \" workflow?</p>\n<p>I\u2019ve searched around the internet and only found these 2 related questions:</p>\n<p>[3]</p>\n<p>[4] (first top comment is the same question)</p>\n<p>Both of the above sources are unanswered. So I\u2019m sure that some other people in the future might come across this same unanswered problem.</p>\n<p>From what I understand W&amp;B works based on callbacks from the model.fit function like so:</p>\n<p>[6]</p>\n<p>But the \"TensorFlow 2 Object Detection API \" doesn\u2019t directly use the model.fit function but it calls a python script like so:</p>\n<p>[7]</p>\n<p>(For training I then paste this command into the terminal alternatively I could also just paste it into jupyter)</p>\n<p>I asked chat GPT about this problem and this is the answer it provided me:</p>\n<p>[8]</p>\n<p>I tried Chat GPT\u2019s solution but the results are a bit weird:<br>\nFirst successful run:<br>\nlogs:<br>\n[9]</p>\n<p>Charts:<br>\n[10]</p>\n<p>My question is what is the correct way to integrate W&amp;B into the \"TensorFlow 2 Object Detection API \"  workflow? Have I done it correctly but am I missing something? Also, where do I specify that W&amp;B should keep track of the loss and other variables or is that done automatically?</p>\n<p>Here is what my training looks like in the terminal for more info:</p>\n<p>Executing the training command:<br>\n[11]<br>\n\u2026<br>\n<em>A lot of skipped terminal lines</em><br>\n\u2026<br>\nEpcoh result logging after the training kicks off:<br>\n[12]</p>\n<p>I hope someone can help me out and thanks for all the help I advance!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-02T18:37:51.099Z",
				"Answer_body": "<p>Hi Matija!</p>\n<p>Thank you so much for using Weights and Biases! <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><br>\nI will ask around internally and see if we have any docs or examples on this. So far I haven\u2019t been able to find anything as well\u2026</p>\n<p>I\u2019ll let you know if I find something asap!</p>\n<p>Cheers,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-03T15:59:03.612Z",
				"Answer_body": "<p>Hi Matija,</p>\n<p>I have asked around and it seems like TFOD is deprecated and we will not be creating a new report/example on it any time soon. What some of my engineers did suggest though, if using Tensorflow is not a compulsion for you, is using MMDetection. Which also has a better example for it.</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-07T20:04:03.949Z",
				"Answer_body": "<p>Hi Matija,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-13T19:14:40.271Z",
				"Answer_body": "<p>Hi Matija, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-14T15:38:09.221Z",
				"Answer_body": "<p>Hey,<br>\nI\u2019ve also tried integrating wandb with tensorflow object detection api but couldn\u2019t find any proper resource on it. My organization primarily uses tensorflow object detection api so it would be hard to change to anything else.So please provoide some suggestions or a working example(would be great) for tensorflow object detection api.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-14T15:40:24.085Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/artsiom\">@artsiom</a> ,<br>\nI\u2019ve also tried integrating wandb with tensorflow object detection api but couldn\u2019t find any proper resource on it. My organization primarily uses tensorflow object detection api so it would be hard to change to anything else.So please provoide some suggestions or a working example(would be great) for tensorflow object detection api.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-15T15:40:52.578Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Download report as latex causes js errors",
		"Question_link": "https://community.wandb.ai/t/download-report-as-latex-causes-js-errors/3872",
		"Question_created_time": "2023-02-13T16:48:37.404Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 208,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Trying to download a report as latex causes an instrument.js error, and the waiting symbol turns forever. I use chrome on MacOS.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/4/4c88c4ac7b283a2fef287aa3cd58a712426c2f77.jpeg\" data-download-href=\"/uploads/short-url/aV3jmQ0drwgzx2rJ9iyEpD7TJQj.jpeg?dl=1\" title=\"Bildschirmfoto 2023-02-13 um 17.42.14\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/4c88c4ac7b283a2fef287aa3cd58a712426c2f77_2_690x307.jpeg\" alt=\"Bildschirmfoto 2023-02-13 um 17.42.14\" data-base62-sha1=\"aV3jmQ0drwgzx2rJ9iyEpD7TJQj\" width=\"690\" height=\"307\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/4c88c4ac7b283a2fef287aa3cd58a712426c2f77_2_690x307.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/4c88c4ac7b283a2fef287aa3cd58a712426c2f77_2_1035x460.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/4c88c4ac7b283a2fef287aa3cd58a712426c2f77_2_1380x614.jpeg 2x\" data-dominant-color=\"959190\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Bildschirmfoto 2023-02-13 um 17.42.14</span><span class=\"informations\">1886\u00d7841 173 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-13T18:06:38.268Z",
				"Answer_body": "<p>Found a solution: When carefully loading each graph by scrolling slowly over the whole page, the download finally works.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-02-14T11:07:27.704Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/juliusge\">@juliusge</a>, thanks for reporting this! Could you please share with me a link to the affected report and so I can have a look to see if it\u2019s intended that you need to load each graph slowly? Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-15T11:08:18.847Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Network error (SSLError), entering retry loop",
		"Question_link": "https://community.wandb.ai/t/network-error-sslerror-entering-retry-loop/3641",
		"Question_created_time": "2023-01-05T00:30:47.654Z",
		"Question_answer_count": 6,
		"Question_score_count": 1,
		"Question_view_count": 704,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am getting this error:</p>\n<p>$ python3 wandb-python4.py<br>\nwandb: W&amp;B API key is configured. Use <code>wandb login --relogin</code> to force relogin<br>\nwandb: Network error (SSLError), entering retry loop.<br>\nwandb: Network error (SSLError), entering retry loop.<br>\nProblem at: /home/hp/wandb-python4.py 4 <br>\nwandb: ERROR Error communicating with wandb process<br>\nwandb: ERROR For more info see: <a href=\"https://docs.wandb.ai/library/init#init-start-error\">https://docs.wandb.ai/library/init#init-start-error</a><br>\nTraceback (most recent call last):<br>\nFile \u201c/home/hp/wandb-python4.py\u201d, line 4, in <br>\nrun = wandb.init(project=\u201cwandb-test\u201d)<br>\nFile \u201c/home/hp/.local/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u201d, line 1078, in init<br>\nrun = wi.init()<br>\nFile \u201c/home/hp/.local/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u201d, line 719, in init<br>\nraise UsageError(error_message)<br>\nwandb.errors.UsageError: Error communicating with wandb process<br>\nFor more info see: <a href=\"https://docs.wandb.ai/library/init#init-start-error\">https://docs.wandb.ai/library/init#init-start-error</a><br>\nwandb: Waiting for W&amp;B process to finish\u2026 (failed 1). Press Control-C to abort syncing.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-05T06:38:33.912Z",
				"Answer_body": "<p>Please find the Environment:<br>\n$ lsb_release -a<br>\nNo LSB modules are available.<br>\nDistributor ID: Ubuntu<br>\nDescription:    Ubuntu 20.04.5 LTS<br>\nRelease:        20.04<br>\nCodename:       focal<br>\n$ python3 --version<br>\nPython 3.9.16<br>\n$ wandb --version<br>\nwandb, version 0.13.7</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-10T18:03:55.145Z",
				"Answer_body": "<p>Hi Kranthi, thank you for writing in! Can you tell me more about what you are running when this error appears? For example, does this appear with just <code>wandb.init()</code>?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-13T22:07:38.726Z",
				"Answer_body": "<p>Hi Kranthi, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-30T03:20:10.625Z",
				"Answer_body": "<p>I am also experiencing this issue when i run sweep agent. The weird thing is that I can run it on my local machine. But I got this issue when I try to run it on remote linux machine. No idea about reason.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-14T10:18:03.334Z",
				"Answer_body": "<p>I am also having this issue since weeks and I can\u2019t solve it. It is really annoying.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-15T10:18:21.466Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Trying to run wandb on azure ml, running into issues",
		"Question_link": "https://community.wandb.ai/t/trying-to-run-wandb-on-azure-ml-running-into-issues/3876",
		"Question_created_time": "2023-02-13T22:36:53.326Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 362,
		"Question_has_accepted_answer": false,
		"Question_body": "<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 1133, in init\n    run = wi.init()\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/wandb/sdk/wandb_init.py\", line 787, in init\n    run_start_result = run_start_handle.wait(timeout=30)\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 271, in wait\n    raise MailboxError(\"transport failed\")\nwandb.errors.MailboxError: transport failed\nwandb: ERROR Abnormal program exit\n2023-02-13 22:32:43,972 - mmseg - INFO - Loaded 20000 images\n/mnt/batch/tasks/shared/LS_root/mounts/clusters/vardhan-cvml/code/Users/Vardhan.Dongre/mmsegmentation/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use \"init_cfg\" instead\n  warnings.warn('DeprecationWarning: pretrained is a deprecated, '\n/mnt/batch/tasks/shared/LS_root/mounts/clusters/vardhan-cvml/code/Users/Vardhan.Dongre/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n  warnings.warn(\n2023-02-13 22:32:52,439 - mmseg - INFO - Loaded 2500 images\n2023-02-13 22:32:52,458 - mmseg - INFO - Start running, host: azureuser@vardhan-cvml, work_dir: /mnt/batch/tasks/shared/LS_root/mounts/clusters/vardhan-cvml/code/Users/Vardhan.Dongre/mmsegmentation/work_dirs/logs/deeplabv3plus\n2023-02-13 22:32:52,459 - mmseg - INFO - Hooks will be executed in the following order:\nbefore_run:\n(VERY_HIGH   ) PolyLrUpdaterHook                  \n(NORMAL      ) CheckpointHook                     \n(LOW         ) EvalHook                           \n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \nbefore_train_epoch:\n(VERY_HIGH   ) PolyLrUpdaterHook                  \n(LOW         ) IterTimerHook                      \n(LOW         ) EvalHook                           \n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \nbefore_train_iter:\n(VERY_HIGH   ) PolyLrUpdaterHook                  \n(LOW         ) IterTimerHook                      \n(LOW         ) EvalHook                           \n -------------------- \nafter_train_iter:\n(ABOVE_NORMAL) OptimizerHook                      \n(NORMAL      ) CheckpointHook                     \n(LOW         ) IterTimerHook                      \n(LOW         ) EvalHook                           \n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \nafter_train_epoch:\n(NORMAL      ) CheckpointHook                     \n(LOW         ) EvalHook                           \n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \nbefore_val_epoch:\n(LOW         ) IterTimerHook                      \n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \nbefore_val_iter:\n(LOW         ) IterTimerHook                      \n -------------------- \nafter_val_iter:\n(LOW         ) IterTimerHook                      \n -------------------- \nafter_val_epoch:\n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \nafter_run:\n(VERY_LOW    ) TextLoggerHook                     \n(VERY_LOW    ) TensorboardLoggerHook              \n(VERY_LOW    ) MMSegWandbHook                     \n -------------------- \n2023-02-13 22:32:52,460 - mmseg - INFO - workflow: [('train', 1)], max: 50000 iters\n2023-02-13 22:32:52,460 - mmseg - INFO - Checkpoints will be saved to /mnt/batch/tasks/shared/LS_root/mounts/clusters/vardhan-cvml/code/Users/Vardhan.Dongre/mmsegmentation/work_dirs/logs/deeplabv3plus by HardDiskBackend.\n2023-02-13 22:32:52.816987: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-02-13 22:32:59.646354: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/cv2/../../lib64:\n2023-02-13 22:32:59.646501: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/cv2/../../lib64:\n2023-02-13 22:32:59.646517: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\nwandb: Currently logged in as: don_v. Use `wandb login --relogin` to force relogin\nThread HandlerThread:\nTraceback (most recent call last):\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 280, in _process\n    self._hm.handle(record)\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 136, in handle\n    handler(record)\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 146, in handle_request\n    handler(record)\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 695, in handle_request_run_start\n    self._system_monitor.probe(publish=True)\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 186, in probe\n    self.system_info.publish(system_info)\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/wandb/sdk/internal/system/system_info.py\", line 252, in publish\n    self._save_patches()\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/wandb/sdk/internal/system/system_info.py\", line 134, in _save_patches\n    if self.git.dirty:\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/wandb/sdk/lib/git.py\", line 76, in dirty\n    return self.repo.is_dirty()\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/git/repo/base.py\", line 795, in is_dirty\n    if osp.isfile(self.index.path) and len(self.git.diff(\"--cached\", *default_args)):\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/git/cmd.py\", line 696, in &lt;lambda&gt;\n    return lambda *args, **kwargs: self._call_process(name, *args, **kwargs)\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/git/cmd.py\", line 1270, in _call_process\n    return self.execute(call, **exec_kwargs)\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/git/cmd.py\", line 1064, in execute\n    raise GitCommandError(redacted_command, status, stderr_value, stdout_value)\ngit.exc.GitCommandError: Cmd('git') failed due to: exit code(129)\n  cmdline: git diff --cached --abbrev=40 --full-index --raw\n  stderr: 'error: unknown option `cached'\nusage: git diff --no-index [&lt;options&gt;] &lt;path&gt; &lt;path&gt;\n\nDiff output format options\n    -p, --patch           generate patch\n    -s, --no-patch        suppress diff output\n    -u                    generate patch\n    -U, --unified[=&lt;n&gt;]   generate diffs with &lt;n&gt; lines context\n    -W, --function-context\n                          generate diffs with &lt;n&gt; lines context\n    --raw                 generate the diff in raw format\n    --patch-with-raw      synonym for '-p --raw'\n    --patch-with-stat     synonym for '-p --stat'\n    --numstat             machine friendly --stat\n    --shortstat           output only the last line of --stat\n    -X, --dirstat[=&lt;param1,param2&gt;...]\n                          output the distribution of relative amount of changes for each sub-directory\n    --cumulative          synonym for --dirstat=cumulative\n    --dirstat-by-file[=&lt;param1,param2&gt;...]\n                          synonym for --dirstat=files,param1,param2...\n    --check               warn if changes introduce conflict markers or whitespace errors\n    --summary             condensed summary such as creations, renames and mode changes\n    --name-only           show only names of changed files\n    --name-status         show only names and status of changed files\n    --stat[=&lt;width&gt;[,&lt;name-width&gt;[,&lt;count&gt;]]]\n                          generate diffstat\n    --stat-width &lt;width&gt;  generate diffstat with a given width\n    --stat-name-width &lt;width&gt;\n                          generate diffstat with a given name width\n    --stat-graph-width &lt;width&gt;\n                          generate diffstat with a given graph width\n    --stat-count &lt;count&gt;  generate diffstat with limited lines\n    --compact-summary     generate compact summary in diffstat\n    --binary              output a binary diff that can be applied\n    --full-index          show full pre- and post-image object names on the \"index\" lines\n    --color[=&lt;when&gt;]      show colored diff\n    --ws-error-highlight &lt;kind&gt;\n                          highlight whitespace errors in the 'context', 'old' or 'new' lines in the diff\n    -z                    do not munge pathnames and use NULs as output field terminators in --raw or --numstat\n    --abbrev[=&lt;n&gt;]        use &lt;n&gt; digits to display object names\n    --src-prefix &lt;prefix&gt;\n                          show the given source prefix instead of \"a/\"\n    --dst-prefix &lt;prefix&gt;\n                          show the given destination prefix instead of \"b/\"\n    --line-prefix &lt;prefix&gt;\n                          prepend an additional prefix to every line of output\n    --no-prefix           do not show any source or destination prefix\n    --inter-hunk-context &lt;n&gt;\n                          show context between diff hunks up to the specified number of lines\n    --output-indicator-new &lt;char&gt;\n                          specify the character to indicate a new line instead of '+'\n    --output-indicator-old &lt;char&gt;\n                          specify the character to indicate an old line instead of '-'\n    --output-indicator-context &lt;char&gt;\n                          specify the character to indicate a context instead of ' '\n\nDiff rename options\n    -B, --break-rewrites[=&lt;n&gt;[/&lt;m&gt;]]\n                          break complete rewrite changes into pairs of delete and create\n    -M, --find-renames[=&lt;n&gt;]\n                          detect renames\n    -D, --irreversible-delete\n                          omit the preimage for deletes\n    -C, --find-copies[=&lt;n&gt;]\n                          detect copies\n    --find-copies-harder  use unmodified files as source to find copies\n    --no-renames          disable rename detection\n    --rename-empty        use empty blobs as rename source\n    --follow              continue listing the history of a file beyond renames\n    -l &lt;n&gt;                prevent rename/copy detection if the number of rename/copy targets exceeds given limit\n\nDiff algorithm options\n    --minimal             produce the smallest possible diff\n    -w, --ignore-all-space\n                          ignore whitespace when comparing lines\n    -b, --ignore-space-change\n                          ignore changes in amount of whitespace\n    --ignore-space-at-eol\n                          ignore changes in whitespace at EOL\n    --ignore-cr-at-eol    ignore carrier-return at the end of line\n    --ignore-blank-lines  ignore changes whose lines are all blank\n    -I, --ignore-matching-lines &lt;regex&gt;\n                          ignore changes whose all lines match &lt;regex&gt;\n    --indent-heuristic    heuristic to shift diff hunk boundaries for easy reading\n    --patience            generate diff using the \"patience diff\" algorithm\n    --histogram           generate diff using the \"histogram diff\" algorithm\n    --diff-algorithm &lt;algorithm&gt;\n                          choose a diff algorithm\n    --anchored &lt;text&gt;     generate diff using the \"anchored diff\" algorithm\n    --word-diff[=&lt;mode&gt;]  show word diff, using &lt;mode&gt; to delimit changed words\n    --word-diff-regex &lt;regex&gt;\n                          use &lt;regex&gt; to decide what a word is\n    --color-words[=&lt;regex&gt;]\n                          equivalent to --word-diff=color --word-diff-regex=&lt;regex&gt;\n    --color-moved[=&lt;mode&gt;]\n                          moved lines of code are colored differently\n    --color-moved-ws &lt;mode&gt;\n                          how white spaces are ignored in --color-moved\n\nOther diff options\n    --relative[=&lt;prefix&gt;]\n                          when run from subdir, exclude changes outside and show relative paths\n    -a, --text            treat all files as text\n    -R                    swap two inputs, reverse the diff\n    --exit-code           exit with 1 if there were differences, 0 otherwise\n    --quiet               disable all output of the program\n    --ext-diff            allow an external diff helper to be executed\n    --textconv            run external text conversion filters when comparing binary files\n    --ignore-submodules[=&lt;when&gt;]\n                          ignore changes to submodules in the diff generation\n    --submodule[=&lt;format&gt;]\n                          specify how differences in submodules are shown\n    --ita-invisible-in-index\n                          hide 'git add -N' entries from the index\n    --ita-visible-in-index\n                          treat 'git add -N' entries as real in the index\n    -S &lt;string&gt;           look for differences that change the number of occurrences of the specified string\n    -G &lt;regex&gt;            look for differences that change the number of occurrences of the specified regex\n    --pickaxe-all         show all changes in the changeset with -S or -G\n    --pickaxe-regex       treat &lt;string&gt; in -S as extended POSIX regular expression\n    -O &lt;file&gt;             control the order in which files appear in the output\n    --rotate-to &lt;path&gt;    show the change in the specified path first\n    --skip-to &lt;path&gt;      skip the output to the specified path\n    --find-object &lt;object-id&gt;\n                          look for differences that change the number of occurrences of the specified object\n    --diff-filter [(A|C|D|M|R|T|U|X|B)...[*]]\n                          select files by diff type\n    --output &lt;file&gt;       output to a specific file\n'\nwandb: ERROR Internal wandb error: file data was not synced\nProblem at: /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mmcv/runner/hooks/logger/wandb.py 83 before_run\n---------------------------------------------------------------------------\nMailboxError                              Traceback (most recent call last)\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1133, in init(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\n   1132 try:\n-&gt; 1133     run = wi.init()\n   1134     except_exit = wi.settings._except_exit\n\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:787, in _WandbInit.init(self)\n    786 # TODO: add progress to let user know we are doing something\n--&gt; 787 run_start_result = run_start_handle.wait(timeout=30)\n    788 if run_start_result is None:\n\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py:271, in MailboxHandle.wait(self, timeout, on_probe, on_progress, release, cancel)\n    270     if self._interface._transport_keepalive_failed():\n--&gt; 271         raise MailboxError(\"transport failed\")\n    273 found, abandoned = self._slot._get_and_clear(timeout=wait_timeout)\n\nMailboxError: transport failed\n\nThe above exception was the direct cause of the following exception:\n\nException                                 Traceback (most recent call last)\nInput In [8], in &lt;cell line: 20&gt;()\n     14 model.CLASSES = datasets[0].CLASSES\n     16 # Create work_dir\n     17 # mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n---&gt; 20 train_segmentor(model, datasets, cfg, distributed=False, validate=True, \n     21                 meta=dict())\n\nFile /mnt/batch/tasks/shared/LS_root/mounts/clusters/vardhan-cvml/code/Users/Vardhan.Dongre/mmsegmentation/mmseg/apis/train.py:194, in train_segmentor(model, dataset, cfg, distributed, validate, timestamp, meta)\n    192 elif cfg.load_from:\n    193     runner.load_checkpoint(cfg.load_from)\n--&gt; 194 runner.run(data_loaders, cfg.workflow)\n\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mmcv/runner/iter_based_runner.py:126, in IterBasedRunner.run(self, data_loaders, workflow, max_iters, **kwargs)\n    122 self.logger.info('Hooks will be executed in the following order:\\n%s',\n    123                  self.get_hook_info())\n    124 self.logger.info('workflow: %s, max: %d iters', workflow,\n    125                  self._max_iters)\n--&gt; 126 self.call_hook('before_run')\n    128 iter_loaders = [IterLoader(x) for x in data_loaders]\n    130 self.call_hook('before_epoch')\n\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mmcv/runner/base_runner.py:317, in BaseRunner.call_hook(self, fn_name)\n    310 \"\"\"Call all hooks.\n    311 \n    312 Args:\n    313     fn_name (str): The function name in each hook to be called, such as\n    314         \"before_train_epoch\".\n    315 \"\"\"\n    316 for hook in self._hooks:\n--&gt; 317     getattr(hook, fn_name)(self)\n\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mmcv/runner/dist_utils.py:135, in master_only.&lt;locals&gt;.wrapper(*args, **kwargs)\n    133 rank, _ = get_dist_info()\n    134 if rank == 0:\n--&gt; 135     return func(*args, **kwargs)\n\nFile /mnt/batch/tasks/shared/LS_root/mounts/clusters/vardhan-cvml/code/Users/Vardhan.Dongre/mmsegmentation/mmseg/core/hook/wandblogger_hook.py:106, in MMSegWandbHook.before_run(self, runner)\n    104 @master_only\n    105 def before_run(self, runner):\n--&gt; 106     super(MMSegWandbHook, self).before_run(runner)\n    108     # Check if EvalHook and CheckpointHook are available.\n    109     for hook in runner.hooks:\n\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mmcv/runner/dist_utils.py:135, in master_only.&lt;locals&gt;.wrapper(*args, **kwargs)\n    133 rank, _ = get_dist_info()\n    134 if rank == 0:\n--&gt; 135     return func(*args, **kwargs)\n\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mmcv/runner/hooks/logger/wandb.py:83, in WandbLoggerHook.before_run(self, runner)\n     81     self.import_wandb()\n     82 if self.init_kwargs:\n---&gt; 83     self.wandb.init(**self.init_kwargs)  # type: ignore\n     84 else:\n     85     self.wandb.init()\n\nFile /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:1170, in init(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\n   1168         if except_exit:\n   1169             os._exit(1)\n-&gt; 1170         raise Exception(\"problem\") from error_seen\n   1171 return run\n\nException: problem\n\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-16T00:41:44.530Z",
				"Answer_body": "<p>Hello Vardhan!</p>\n<p>In order to get idea of what the issue may be, could you provide me with your <code>debug.log</code> and <code>debug-internal.log</code> for this specific run? They should be located in the <code>wandb</code> folder in your computer\u2019s working directory. That folder has folders formatted as <code>run-DATETIME-ID</code> - each of which is associated with an individual run.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-22T17:13:25.327Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-27T23:01:21.689Z",
				"Answer_body": "<p>Hi Vardhan, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-14T22:37:21.408Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Cannot create academic team",
		"Question_link": "https://community.wandb.ai/t/cannot-create-academic-team/3849",
		"Question_created_time": "2023-02-08T15:30:47.160Z",
		"Question_answer_count": 8,
		"Question_score_count": 0,
		"Question_view_count": 317,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Unfortunately, I am not able to create an academic team, although my university email address is added in to the profile: b.khaertdinov[at]maastrichtuniversity.nl</p>\n<p>Any tips on how to solve this issue are very welcome!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-08T18:16:34.108Z",
				"Answer_body": "<p>Hi Bulat!</p>\n<p>Thank you for writing in, it looks like your school is not in our database. Could you talk a bit about your school ( a couple of sentences is enough) and I\u2019ll directly make a pr adding your school\u2019s domain to our system?</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-09T14:59:30.886Z",
				"Answer_body": "<p>Hi Artsiom,</p>\n<p>Below is a short intro:</p>\n<p>Maastricht University (UM) is the most international university in the Netherlands and, with over 22,000 students and more than 5,000 employees, is still growing. The university distinguishes itself with its innovative education model, international character and multidisciplinary approach to research and education. Today, it is considered one of the best young universities in the world.</p>\n<p>Thank you in advance,<br>\nBulat</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-10T16:48:54.905Z",
				"Answer_body": "<p>Hi Bulat!</p>\n<p>I have submitted your academic email to our system! The changes should take place by eod! Thank you so much for sending over all of the info.</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-13T10:54:11.560Z",
				"Answer_body": "<p>Dear Artsiom,</p>\n<p>Thanks for your help! Unfortunately, I still cannot create an academic team\u2026</p>\n<p>Best,<br>\nBulat</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-14T06:09:41.886Z",
				"Answer_body": "<p>Hi Bulat!</p>\n<p>Your status should have been changed to Academic on our back-end as well now!</p>\n<p>Cheers,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-21T16:08:55.245Z",
				"Answer_body": "<p>Hi Bulat, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-24T19:11:04.471Z",
				"Answer_body": "<p>Hi Bulat, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-14T10:54:27.245Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Can't toggle button for magic link to share report",
		"Question_link": "https://community.wandb.ai/t/cant-toggle-button-for-magic-link-to-share-report/3847",
		"Question_created_time": "2023-02-08T15:13:28.411Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 118,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi there, I\u2019m new to W&amp;B and was exploring the Report functionality. When trying to share a report publicly I\u2019m unable to toggle the radio button for \u201cAnyone with the magic link can view\u201d, and thus unable to see and share the magic link. From looking through documentation it doesn\u2019t appear as though any other settings are required to be set on my end, but I\u2019ve wondered if I\u2019ve missed something. I\u2019m using W&amp;B through a free personal use account, and I\u2019ve tried this on Chrome and Safari.  I was thinking this feature might have been paywalled recently but I was unable to find if that had been the case. Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-09T14:14:35.177Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nicholaskinnaird\">@nicholaskinnaird</a>, thanks for reporting this! Could you please send me a link to the affected report and so I can have a look at it? It\u2019d be really useful if you could also send me a quick video showing this behaviour with the browser logs (In Chrome, right click \u2192 inspect).</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-09T19:39:27.118Z",
				"Answer_body": "<p>Hi Luis, thanks for the help.</p>\n<p>The html link to the affected report is: <a href=\"https://wandb.ai/nicholaskinnaird/Sizing_Model_Sweep_Training/reports/Example-Report-on-Weights-and-Biases--VmlldzozNTA1MDc1\" class=\"inline-onebox\">Weights &amp; Biases</a></p>\n<p>I switched my account to public in case that would help you see the page, though when I try going to that link in an incognito window it leads to a no-access page.</p>\n<p>Here\u2019s a screen shot with the inspect window open on the right, and then after that is a link to a ~30s video stored in my Google drive. It says \u201cdisabled\u201d so it definitely looks turned off intentionally. When I host wandb locally rather than the cloud I can share a report via the magic link button with no issues.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/f/fce85f01f996556e15a2578068b145c656af5615.png\" data-download-href=\"/uploads/short-url/A5kaSclLlwAR4mtm35aqOUk07tP.png?dl=1\" title=\"Screen Shot 2023-02-09 at 1.26.54 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/f/fce85f01f996556e15a2578068b145c656af5615_2_690x244.png\" alt=\"Screen Shot 2023-02-09 at 1.26.54 PM\" data-base62-sha1=\"A5kaSclLlwAR4mtm35aqOUk07tP\" width=\"690\" height=\"244\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/f/fce85f01f996556e15a2578068b145c656af5615_2_690x244.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/f/fce85f01f996556e15a2578068b145c656af5615_2_1035x366.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/f/fce85f01f996556e15a2578068b145c656af5615_2_1380x488.png 2x\" data-dominant-color=\"818182\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2023-02-09 at 1.26.54 PM</span><span class=\"informations\">1656\u00d7586 121 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<aside class=\"onebox googledrive\" data-onebox-src=\"https://drive.google.com/file/d/1o4RO7gLrfsZ_dPIUGjiOHfFf-5xUW8i4/view?usp=sharing\">\n  <header class=\"source\">\n\n      <a href=\"https://drive.google.com/file/d/1o4RO7gLrfsZ_dPIUGjiOHfFf-5xUW8i4/view?usp=sharing\" target=\"_blank\" rel=\"noopener nofollow ugc\">drive.google.com</a>\n  </header>\n\n  <article class=\"onebox-body\">\n      <a href=\"https://drive.google.com/file/d/1o4RO7gLrfsZ_dPIUGjiOHfFf-5xUW8i4/view?usp=sharing\" target=\"_blank\" rel=\"noopener nofollow ugc\"><span class=\"googledocs-onebox-logo g-drive-logo\"></span></a>\n\n\n\n<h3><a href=\"https://drive.google.com/file/d/1o4RO7gLrfsZ_dPIUGjiOHfFf-5xUW8i4/view?usp=sharing\" target=\"_blank\" rel=\"noopener nofollow ugc\">wandb_magic_link_issue.mov</a></h3>\n\n<p>Google Drive file.</p>\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-10T12:56:43.473Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nicholaskinnaird\">@nicholaskinnaird</a>, thanks for sharing the link and the video! I can see you have a copy of this report which is working properly. Would it work for you to use that copy or clone the existing report and use any of these in the meantime? We\u2019ll keep investigating this to figure out what\u2019s the root cause of the issue.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-10T17:03:02.814Z",
				"Answer_body": "<p>Hey Luis, I made the copy of the report just in case I ended up losing the original report for some reason. I don\u2019t think I ever tried sharing that copy, but like you said it appears to be working properly. I can definitely work with that in the meantime, thanks for the suggestion! Thanks for the help!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-12T18:06:26.321Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/nicholaskinnaird\">@nicholaskinnaird</a>, thanks for your answer and for your patience! Our engineers had a look at the issue and they were able to fix it so the magic link button is working properly now! I tested and I can enable it, could you please confirm me this is also working properly on your end? Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-13T18:07:15.314Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb error by usage of mlflow and hydra regarding protobuf lib",
		"Question_link": "https://community.wandb.ai/t/wandb-error-by-usage-of-mlflow-and-hydra-regarding-protobuf-lib/3866",
		"Question_created_time": "2023-02-12T17:17:38.609Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 192,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi all,<br>\nhaving an issue and need some help for Python project inside a Udacity course.<br>\nWe shall use Python 3.8, therefore I am using 3.8.16 and having created a virtual env starting from that version and activated virtual env.</p>\n<p>Using Jupyter Lab I am trying to use a pipeline for mlflow, hydra and wandb I am getting the same error as mentioned e.g. in</p><aside class=\"onebox githubissue\" data-onebox-src=\"https://github.com/espnet/espnet/issues/3708\">\n  <header class=\"source\">\n\n      <a href=\"https://github.com/espnet/espnet/issues/3708\" target=\"_blank\" rel=\"noopener nofollow ugc\">github.com/espnet/espnet</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"github-row\">\n  <div class=\"github-icon-container\" title=\"Issue\">\n\t  <svg width=\"60\" height=\"60\" class=\"github-icon\" viewbox=\"0 0 14 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z\"></path></svg>\n  </div>\n\n  <div class=\"github-info-container\">\n    <h4>\n      <a href=\"https://github.com/espnet/espnet/issues/3708\" target=\"_blank\" rel=\"noopener nofollow ugc\">Wandb 0.12.6 leads to Import Failure. Works on reverting to 0.12.2</a>\n    </h4>\n\n    <div class=\"github-info\">\n      <div class=\"date\">\n        opened <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2021-10-28\" data-time=\"01:09:34\" data-timezone=\"UTC\">01:09AM - 28 Oct 21 UTC</span>\n      </div>\n\n\n      <div class=\"user\">\n        <a href=\"https://github.com/gdebayan\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n          <img alt=\"gdebayan\" src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/5/587184763eb7c4bb085cf14a54010a65cd8272aa.png\" class=\"onebox-avatar-inline\" width=\"20\" height=\"20\">\n          gdebayan\n        </a>\n      </div>\n    </div>\n\n    <div class=\"labels\">\n        <span style=\"display:inline-block;margin-top:2px;background-color: #B8B8B8;padding: 2px;border-radius: 4px;color: #fff;margin-left: 3px;\">\n          Bug\n        </span>\n    </div>\n  </div>\n</div>\n\n  <div class=\"github-row\">\n    <p class=\"github-body-container\">While Looking up ESPNet using this Tutorial: https://colab.research.google.com/d<span class=\"show-more-container\"><a href=\"\" rel=\"noopener\" class=\"show-more\">\u2026</a></span><span class=\"excerpt hidden\">rive/1L85G7jdhsI1QKs2o0qCGEbhm5X4QV2zN\n\nI came across this issue when the Library \"Wandb\" is imported.\n\n```\n# python3 -m espnet2.bin.asr_train --collect_stats true --use_preprocessor true --bpemodel data/token_list/bpe_unigram30/bpe.model --token_type bpe --token_list data/token_list/bpe_unigram30/tokens.txt --non_linguistic_symbols none --cleaner none --g2p none --train_data_path_and_name_and_type dump/raw/train_nodev/wav.scp,speech,sound --train_data_path_and_name_and_type dump/raw/train_nodev/text,text,text --valid_data_path_and_name_and_type dump/raw/train_dev/wav.scp,speech,sound --valid_data_path_and_name_and_type dump/raw/train_dev/text,text,text --train_shape_file exp/asr_stats_raw_bpe30/logdir/train.32.scp --valid_shape_file exp/asr_stats_raw_bpe30/logdir/valid.32.scp --output_dir exp/asr_stats_raw_bpe30/logdir/stats.32 --frontend_conf fs=16k\u00a0\n# Started at Wed Oct 27 16:36:43 EDT 2021\n```\n\n```\n\u00a0 \u00a0 from .wandb_init import _attach, init \u00a0# noqa: F401\n\u00a0 File \"/home/debayan/.local/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\", line 35, in &lt;module&gt;\n\u00a0 \u00a0 from .backend.backend import Backend\n\u00a0 File \"/home/debayan/.local/lib/python3.8/site-packages/wandb/sdk/backend/backend.py\", line 20, in &lt;module&gt;\n\u00a0 \u00a0 from ..interface import interface\n\u00a0 File \"/home/debayan/.local/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\", line 21, in &lt;module&gt;\n\u00a0 \u00a0 from wandb.proto import wandb_internal_pb2 as pb\n\u00a0 File \"/home/debayan/.local/lib/python3.8/site-packages/wandb/proto/wandb_internal_pb2.py\", line 15, in &lt;module&gt;\n\u00a0 \u00a0 from wandb.proto import wandb_base_pb2 as wandb_dot_proto_dot_wandb__base__pb2\n\u00a0 File \"/home/debayan/.local/lib/python3.8/site-packages/wandb/proto/wandb_base_pb2.py\", line 21, in &lt;module&gt;\n\u00a0 \u00a0 create_key=_descriptor._internal_create_key,\nAttributeError: module 'google.protobuf.descriptor' has no attribute '_internal_create_key\n```\n\nThis was in Wandb version 0.12.6 .\n\nHowever, when I reverted to Wandb version 0.12.2, it started working as expected.\n\nFeel free to reach out if any questions!</span></p>\n  </div>\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>I tried already the mentioned protobuf version 3.20.0 and 3.20.1 and different wandb versions via conda.yml, always getting the same error:</p>\n<pre><code class=\"lang-auto\">name: download_data\nchannels:\n  - conda-forge\n  - defaults\ndependencies:\n  - python=3.8\n  - requests=2.24.0\n  - pip=20.3.3\n  - mlflow=2.1.1\n  - hydra-core=1.3.1      #1.0.6\n#  - wandb=0.13.10\n  - pip:\n      #- wandb==0.10.21\n      - protobuf==3.20.0\n      - wandb==0.12.2\n      - hydra-joblib-launcher==1.1.2\n</code></pre>\n<p>Still getting the following stacktrace for the ML model and its param setting:<br>\n<img src=\"https://emoji.discourse-cdn.com/twitter/sun_with_face.png?v=12\" title=\":sun_with_face:\" class=\"emoji\" alt=\":sun_with_face:\" loading=\"lazy\" width=\"20\" height=\"20\"> <img src=\"https://emoji.discourse-cdn.com/twitter/x.png?v=12\" title=\":x:\" class=\"emoji\" alt=\":x:\" loading=\"lazy\" width=\"20\" height=\"20\">  mlflow run . -P hydra_options=\u201crandom_forest_pipeline.random_forest.max_depth=5\u201d<br>\n2023/02/12 17:55:15 INFO mlflow.utils.conda: === Creating conda environment mlflow-8284cfd5101c5c151da499d35f932662f514265c ===<br>\nCollecting package metadata (repodata.json): \u2026working\u2026 done<br>\nSolving environment: \u2026working\u2026 done<br>\nPreparing transaction: \u2026working\u2026 done<br>\nVerifying transaction: \u2026working\u2026 done<br>\nExecuting transaction: \u2026working\u2026 done<br>\nInstalling pip dependencies: \u2026working\u2026 done<br>\n2023/02/12 18:02:28 INFO mlflow.projects.utils: === Created directory /tmp/tmpcv9ww8ry for downloading remote URIs passed to arguments of type \u2018path\u2019 ===<br>\n2023/02/12 18:02:28 INFO mlflow.projects.backend.local: === Running command \u2018source /home/ilona/miniconda3/bin/\u2026/etc/profile.d/conda.sh &amp;&amp; conda activate mlflow-8284cfd5101c5c151da499d35f932662f514265c 1&gt;&amp;2 &amp;&amp; python main.py $(echo random_forest_pipeline.random_forest.max_depth=5)\u2019 in run with ID \u2018a6d323399b9242c1b227bae18109b69d\u2019 ===<br>\n2023/02/12 18:02:39 INFO mlflow.utils.conda: Conda environment mlflow-70e71a7afdc413046f59e7b87abd03dc50d8745f already exists.<br>\n2023/02/12 18:02:39 INFO mlflow.projects.utils: === Created directory /tmp/tmpsxd_dtnx for downloading remote URIs passed to arguments of type \u2018path\u2019 ===<br>\n2023/02/12 18:02:39 INFO mlflow.projects.backend.local: === Running command \u2018source /home/ilona/miniconda3/bin/\u2026/etc/profile.d/conda.sh &amp;&amp; conda activate mlflow-70e71a7afdc413046f59e7b87abd03dc50d8745f 1&gt;&amp;2 &amp;&amp; python run.py --train_data exercise_6/data_train.csv:latest <br>\n\u2013model_config /home/ilona/MLOps/nd0821-c2-build-model-workflow-exercises/lesson-4-training-validation-experiment-tracking/exercises/exercise_11/starter/outputs/2023-02-12/18-02-33/random_forest_config.yml\u2019 in run with ID \u201859002ca997e54d1dac9fd30e5a418009\u2019 ===<br>\nTraceback (most recent call last):<br>\nFile \u201crun.py\u201d, line 15, in <br>\nimport wandb<br>\nFile \u201c/home/ilona/miniconda3/envs/mlflow-70e71a7afdc413046f59e7b87abd03dc50d8745f/lib/python3.8/site-packages/wandb/<strong>init</strong>.py\u201d, line 38, in <br>\nfrom wandb import sdk as wandb_sdk<br>\nFile \u201c/home/ilona/miniconda3/envs/mlflow-70e71a7afdc413046f59e7b87abd03dc50d8745f/lib/python3.8/site-packages/wandb/sdk/<strong>init</strong>.py\u201d, line 12, in <br>\nfrom .wandb_init import init  # noqa: F401<br>\nFile \u201c/home/ilona/miniconda3/envs/mlflow-70e71a7afdc413046f59e7b87abd03dc50d8745f/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\u201d, line 29, in <br>\nfrom .backend.backend import Backend<br>\nFile \u201c/home/ilona/miniconda3/envs/mlflow-70e71a7afdc413046f59e7b87abd03dc50d8745f/lib/python3.8/site-packages/wandb/sdk/backend/backend.py\u201d, line 17, in <br>\nfrom \u2026interface import interface<br>\nFile \u201c/home/ilona/miniconda3/envs/mlflow-70e71a7afdc413046f59e7b87abd03dc50d8745f/lib/python3.8/site-packages/wandb/sdk/interface/interface.py\u201d, line 18, in <br>\nfrom wandb.proto import wandb_internal_pb2 as pb<br>\nFile \u201c/home/ilona/miniconda3/envs/mlflow-70e71a7afdc413046f59e7b87abd03dc50d8745f/lib/python3.8/site-packages/wandb/proto/wandb_internal_pb2.py\u201d, line 15, in <br>\nfrom wandb.proto import wandb_telemetry_pb2 as wandb_dot_proto_dot_wandb__telemetry__pb2<br>\nFile \u201c/home/ilona/miniconda3/envs/mlflow-70e71a7afdc413046f59e7b87abd03dc50d8745f/lib/python3.8/site-packages/wandb/proto/wandb_telemetry_pb2.py\u201d, line 34, in <br>\n_descriptor.FieldDescriptor(<br>\nFile \u201c/home/ilona/miniconda3/envs/mlflow-70e71a7afdc413046f59e7b87abd03dc50d8745f/lib/python3.8/site-packages/google/protobuf/descriptor.py\u201d, line 560, in <strong>new</strong><br>\n_message.Message._CheckCalledFromGeneratedFile()<br>\nTypeError: Descriptors cannot not be created directly.<br>\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc &gt;= 3.19.0.<br>\nIf you cannot immediately regenerate your protos, some other possible workarounds are:</p>\n<ol>\n<li>Downgrade the protobuf package to 3.20.x or lower.</li>\n<li>Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).</li>\n</ol>\n<p>More information: <a href=\"https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Changes made on May 6, 2022 | Protocol Buffers Documentation</a><br>\n\u2026</p>\n<p>In advance, thank you very much for help and solution proposals,<br>\nIlona</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-16T15:23:23.964Z",
				"Answer_body": "<p>Hey Ilona,</p>\n<p>Thank you for contacting us and bringing this up.<br>\nI have tried reproducing it but don\u2019t get the same error.</p>\n<p>To clear up any misunderstandings I wish to know if you are using virtualenv package in python and/or conda envs? Mixing up both may cause import issues in general.<br>\nCould you check if you have a virtualenv in conda env or vice versa? Let me know if that is not the case.</p>\n<p>Also the error message from the issue sent isn\u2019t exactly the same though it is the same cause.<br>\nDoes the error happen just when you are trying to import wandb or without?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-22T17:26:04.658Z",
				"Answer_body": "<p>Hello Ilona,</p>\n<p>Following up to know if you have tried what I mentioned?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-28T22:38:49.539Z",
				"Answer_body": "<p>Hello Ilona,</p>\n<p>I will be closing this ticket for lack of response. If you encounter the same issue or another one feel free to contact us.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-13T17:18:32.675Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Network error (ConnectTimeout), entering retry loop",
		"Question_link": "https://community.wandb.ai/t/network-error-connecttimeout-entering-retry-loop/3772",
		"Question_created_time": "2023-01-29T19:59:37.391Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 200,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hello,</p>\n<p>After several tries I am getting stuck when finishing a run about data uploading. It always throws the same error and it seems it \u2018kills\u2019 my network, consuming all resources as when I try to access other pages the internet is very slow.</p>\n<p>When I try to do the tests I always have a good connection (around 600Mb), and I tried on different days. I never have connection cuts, just when doing the run finish.</p>\n<p>The error I have is the following:<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/a27d197a4c8825679f7e5c459ef89d5f87a2a192.png\" alt=\"Selection_001\" data-base62-sha1=\"nbrnemiqAtyylTXSAgkOD1SYaSS\" width=\"573\" height=\"182\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-30T08:56:22.185Z",
				"Answer_body": "<p>To give more information, that happens when I try to upload a dir with 11k items and 7Gb.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-31T21:03:27.678Z",
				"Answer_body": "<p>Hey Mario!</p>\n<p>We have been having an influx of traffic lately. Please try again and if you still run into the ConnectTimeout Network error, please send us your debug.log so we can take a closer look.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-02-03T17:37:11.923Z",
				"Answer_body": "<p>Hello Mario!</p>\n<p>Just wanted to follow up and ask if you are still running into issues with uploading your data when finishing a run.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-12T16:17:24.070Z",
				"Answer_body": "<p>Hello, sorry for the late reply. I tried with another machine with better network and worked. I don\u2019t know if my ISP was blocking the upload too. But finally worked, with same code <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"> Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-13T16:18:13.555Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to sync offline run on another computer?",
		"Question_link": "https://community.wandb.ai/t/how-to-sync-offline-run-on-another-computer/3812",
		"Question_created_time": "2023-02-03T10:29:51.263Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 401,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>The offline runs are generated by computer A. Because of the lack of network on A, I copied the whole wandb directory to another computer B and excuted the sync command on B. But I have:</p>\n<pre><code class=\"lang-shell\">wandb: No runs to be synced.\n</code></pre>\n<p>I want to know is this way possible?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-04T02:42:25.316Z",
				"Answer_body": "<p>I found this issue and meet the same problem.</p>\n<aside class=\"onebox githubissue\" data-onebox-src=\"https://github.com/wandb/wandb/issues/3098\">\n  <header class=\"source\">\n\n      <a href=\"https://github.com/wandb/wandb/issues/3098\" target=\"_blank\" rel=\"noopener nofollow ugc\">github.com/wandb/wandb</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"github-row\">\n  <div class=\"github-icon-container\" title=\"Issue\">\n\t  <svg width=\"60\" height=\"60\" class=\"github-icon\" viewbox=\"0 0 14 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z\"></path></svg>\n  </div>\n\n  <div class=\"github-info-container\">\n    <h4>\n      <a href=\"https://github.com/wandb/wandb/issues/3098\" target=\"_blank\" rel=\"noopener nofollow ugc\">[Q]Sync offline metrics on another machine</a>\n    </h4>\n\n    <div class=\"github-info\">\n      <div class=\"date\">\n        opened <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2022-01-03\" data-time=\"13:13:56\" data-timezone=\"UTC\">01:13PM - 03 Jan 22 UTC</span>\n      </div>\n\n\n      <div class=\"user\">\n        <a href=\"https://github.com/THU-syh\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n          <img alt=\"THU-syh\" src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/2549a6b2289161c230e00f7c0f6163dfed32d756.png\" class=\"onebox-avatar-inline\" width=\"20\" height=\"20\">\n          THU-syh\n        </a>\n      </div>\n    </div>\n\n    <div class=\"labels\">\n    </div>\n  </div>\n</div>\n\n  <div class=\"github-row\">\n    <p class=\"github-body-container\">If I train on a gpu machine that cannot be connected to the Internet and use off<span class=\"show-more-container\"><a href=\"\" rel=\"noopener\" class=\"show-more\">\u2026</a></span><span class=\"excerpt hidden\">line wandb to record metrics, can I move the generated offline folder to another machine and synchronize it to the cloud? Which files must I save and move?</span></p>\n  </div>\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-06T22:14:07.406Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/geyao\">@geyao</a> , happy to help. Could you please provide me the command you are using to sync the run(s)? If you try to sync a single run folder, does this execute successfully?</p>\n<p><code>wandb sync --project &lt;PROJECT&gt; --entity &lt;ENTITY&gt; wandb/&lt;run-folder-name&gt;</code></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-10T00:24:04.754Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/geyao\">@geyao</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-11T02:02:17.574Z",
				"Answer_body": "<p>Sorry for late reply. Finally, I successfully sync the run. But I have to remove this before the run starts:</p>\n<pre><code class=\"lang-python\">wandb.run.log_code(...)\n</code></pre>\n<p>The reason is in the above github issue. I don\u2019t know if there is any solution to deal with the exist of <code>log_code</code> operation.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-12T02:02:27.655Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sync runs on server to a local instance",
		"Question_link": "https://community.wandb.ai/t/sync-runs-on-server-to-a-local-instance/3829",
		"Question_created_time": "2023-02-06T05:08:33.525Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 257,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi Everyone.<br>\nI have run wandb in offline mode on a server. However, I don\u2019t want to run <code>wandb.sync</code> on them.  I have downloaded the wandb folder to my local pc. I am wondering if there is anyway to look at the logs stored in this wandb folder maybe through a local wandb instance.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-07T01:00:18.555Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/miladink\">@miladink</a> , happy to help. You can\u2019t currently view the contents of a wandb run file outside of a wandb project. You could still access the config/summary files from your machine. An option would be to sync the runs to your instance and view them this way.  Here is an example call to sync a specific run folder,<code> wandb sync --project &lt;PROJECT&gt; --entity &lt;ENTITY&gt;  &lt;dir&gt;/&lt;run-folder, e.g. run-20220829_191828-3cvxvrbj&gt;</code>. Please let me know if you have any questions</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-10T19:23:05.581Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/miladink\">@miladink</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-11T19:23:35.693Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb.watch() when using mixed precision and torch.cuda.amp.GradScaler()",
		"Question_link": "https://community.wandb.ai/t/wandb-watch-when-using-mixed-precision-and-torch-cuda-amp-gradscaler/3754",
		"Question_created_time": "2023-01-26T09:36:28.461Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 94,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have a PyTorch project where I\u2019m using mixed precision gradient scaling. When using <code>wandb.watch()</code> to log model gradients  is it possible to unscale them using something like scaler.unscale() at some point in the code prior to logging? My code looks something like the below.</p>\n<pre><code class=\"lang-auto\">wandb.init(project=\"my_project\", name='my_run', config=config, mode='online')\nmodel = Net()\nwandb.watch(model, log='all')\noptimiser = my_optim(model.parameters(),lr=lr)\n\nscaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n\nfor epoch in range(epochs):\n    for input, target in train_loader:\n        with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=use_amp):\n             pred = model(input) \n             loss = loss_fn(input, target)\n        scaler.scale(loss).backward()\n        scaler.step(optimiser)\n        scaler.update()\n        optimiser.zero_grad(set_to_none=True)\n\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-31T11:38:05.389Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dt_90\">@dt_90</a> thanks for writing in! I wanted to follow up on this request, and see if you\u2019ve already tried it and if you ran into any issues? also, was wondering what would be the use case to log the unscaled gradients instead?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-03T16:07:15.320Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dt_90\">@dt_90</a> just checking in here to see if you still experience any issues with this, and if you could provide some more information what errors you get? if possible to share a minimal code example would greatly help to reproduce the issue and further assist you with this. Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-08T18:10:12.968Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dt_90\">@dt_90</a> since we haven\u2019t heard back from you any additional information regarding this issue, we will close this ticket for now. However, please let us know if this issue still persists for you and we will be happy to keep investigating.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-09T18:11:12.595Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Accelerate launch and WandB agent , run the main function 4 seperate times for 4 GPUS",
		"Question_link": "https://community.wandb.ai/t/accelerate-launch-and-wandb-agent-run-the-main-function-4-seperate-times-for-4-gpus/3809",
		"Question_created_time": "2023-02-03T08:57:56.045Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 400,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>So I have changed my YAML file environment variable from \u201cpython3\u201d to \u201caccelerate launch\u201d.  I am trying to use this in conjunction with wandb agent &lt;username/proj_name/sweep_id&gt; on a SLURM compute cluster.</p>\n<p>So the error is that it runs the main function 4 times, which then instantiates the arguments 4 times and we error out because it is trying to create a page that was created on the first step. And then inevitably fails.</p>\n<p>I should mention that the script does work with just python3 and so it is a matter of using \u201caccelerate launch\u201d to take advantage of my multiple GPUs.</p>\n<pre><code class=\"lang-bash\">#!/bin/bash\n#SBATCH --job-name=tav_mae\n# Give job a name\n#SBATCH --time 02-20:00 # time (DD-HH:MM)\n#SBATCH --nodes=1\n#SBATCH --gpus-per-node=v100l:4 # request GPU\n#SBATCH --ntasks-per-node=4\n#SBATCH --cpus-per-task=6 # maximum CPU cores per GPU request: 6 on Cedar, 16 on Graham.\n#SBATCH --mem=150G # memory per node\n#SBATCH --account=ctb-whkchun # Runs it on the dedicated nodes we have\n#SBATCH --output=/scratch/prsood/tav_mae/logs/%N-%j.out # %N for node name, %j for jobID # Remember to mae logs-dir\nmodule load StdEnv/2020\nmodule load cuda\nmodule load cudnn/8.0.3\nwandb agent ddi/TAVFormer2/ncdfi75j --count 20\n</code></pre>\n<p>YAML configuration file:</p>\n<pre data-code-wrap=\"YAML\"><code class=\"lang-plaintext\">program: ../tav_nn.py\ncommand:\n  - ${env}\n  - accelerate\n  - launch\n  - ${program}\n  - \"--dataset\"\n\nmethod: bayes\n\nmetric:\n  goal: minimize\n  name: train/train_loss\nparameters:\n  epoch: \n    values: [5 , 7 , 9]\n  learning_rate:\n    distribution: uniform\n    min: 0.000001\n    max: 0.0001\n  batch_size:\n    values: [2 , 4 , 8 , 1]\n  weight_decay:\n    values: [0.0001 , 0.00001 , 0.000001 , 0.0000001, 0.00000001]  \n  seed:\n    values: [32, 64, 96]\n  dropout:\n    values: [0.0,0.1,0.2]\n  early_div:\n    values: [True,False]\n  patience:\n    values: [10]\n  clip:\n    values: [1]\n  T_max:\n   values: [5,10]\n  hidden_layers:\n    values: [\"300\"]\n</code></pre>\n<p>Error output</p>\n<pre data-code-wrap=\"console\"><code class=\"lang-plaintext\">wandb: Starting wandb agent \ud83d\udd75\ufe0f\n2023-02-03 00:32:20,126 - wandb.wandb_agent - INFO - Running runs: []\n2023-02-03 00:32:21,726 - wandb.wandb_agent - INFO - Agent received command: run\n2023-02-03 00:32:21,728 - wandb.wandb_agent - INFO - Agent starting run with config:\n        T_max: 10\n        batch_size: 2\n        clip: 1\n        dropout: 0.1\n        early_div: True\n        epoch: 7\n        hidden_layers: 300\n        label_task: emotion\n        learning_rate: 3.736221739657802e-05\n        model: MAE_encoder\n        patience: 10\n        seed: 96\n        weight_decay: 0.0001\n2023-02-03 00:32:21,736 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env accelerate launch ../tav_nn.py --dataset ../../data/IEMOCAP_df\n2023-02-03 00:32:26,772 - wandb.wandb_agent - INFO - Running runs: ['6fnujhey']\nwandb: Currently logged in as: prsood (ddi). Use `wandb login --relogin` to force relogin\nwandb: Currently logged in as: prsood (ddi). Use `wandb login --relogin` to force relogin\nwandb: Currently logged in as: prsood (ddi). Use `wandb login --relogin` to force relogin\nwandb: Currently logged in as: prsood (ddi). Use `wandb login --relogin` to force relogin\nwandb: WARNING Ignored wandb.init() arg project when running a sweep.\nwandb: WARNING Ignored wandb.init() arg entity when running a sweep.\nwandb: WARNING Ignored wandb.init() arg project when running a sweep.\nwandb: WARNING Ignored wandb.init() arg entity when running a sweep.\nwandb: WARNING Ignored wandb.init() arg project when running a sweep.\nwandb: WARNING Ignored wandb.init() arg entity when running a sweep.\nwandb: WARNING Ignored wandb.init() arg project when running a sweep.\nwandb: WARNING Ignored wandb.init() arg entity when running a sweep.\nThread WriterThread: wandb.init()...\nTraceback (most recent call last):\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/internal/internal_util.py\", line 50, in run\n    self._run()\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n    self._process(record)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/internal/internal.py\", line 351, in _process\n    self._wm.write(record)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/internal/writer.py\", line 28, in write\n    self.open()\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/internal/writer.py\", line 24, in open\n    self._ds.open_for_write(self._settings.sync_file)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/internal/datastore.py\", line 77, in open_for_write\n    self._fp = open(fname, open_flags)\nFileExistsError: [Errno 17] File exists: '/project/6051551/prsood/multi-modal-emotion/TripleModels/run_slurm/wandb/run-20230203_003340-6fnujhey/run-6fnujhey.wandb'\nThread WriterThread:\nTraceback (most recent call last):\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/internal/internal_util.py\", line 50, in run\n    self._run()\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n    self._process(record)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/internal/internal.py\", line 351, in _process\n    self._wm.write(record)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/internal/writer.py\", line 28, in write\n    self.open()\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/internal/writer.py\", line 24, in open\n    self._ds.open_for_write(self._settings.sync_file)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/internal/datastore.py\", line 77, in open_for_write\n    self._fp = open(fname, open_flags)\nFileExistsError: [Errno 17] File exists: '/project/6051551/prsood/multi-modal-emotion/TripleModels/run_slurm/wandb/run-20230203_003340-6fnujhey/run-6fnujhey.wandb'\nThread WriterThread:\nTraceback (most recent call last):\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/internal/internal_util.py\", line 50, in run\n    self._run()\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n    self._process(record)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/internal/internal.py\", line 351, in _process\n    self._wm.write(record)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/internal/writer.py\", line 28, in write\n    self.open()\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/internal/writer.py\", line 24, in open\n    self._ds.open_for_write(self._settings.sync_file)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/internal/datastore.py\", line 77, in open_for_write\n    self._fp = open(fname, open_flags)\nFileExistsError: [Errno 17] File exists: '/project/6051551/prsood/multi-modal-emotion/TripleModels/run_slurm/wandb/run-20230203_003340-6fnujhey/run-6fnujhey.wandb'\nwandb: ERROR Internal wandb error: file data was not synced\nProblem at: ../tav_nn.py 106 main...\nTraceback (most recent call last):\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 1078, in init\n    run = wi.init()\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 739, in init\n    _ = backend.interface.communicate_run_start(run_obj)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\", line 235, in communicate_run_start\n    result = self._communicate_run_start(run_start)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py\", line 484, in _communicate_run_start\n    result = self._communicate(rec)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py\", line 255, in _communicate\n    return self._communicate_async(rec, local=local).get(timeout=timeout)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/interface/interface_sock.py\", line 58, in _communicate_async\n    future = self._router.send_and_receive(rec, local=local)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/interface/router.py\", line 94, in send_and_receive\n    self._send_message(rec)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/interface/router_sock.py\", line 36, in _send_message\n    self._sock_client.send_record_communicate(record)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\", line 216, in send_record_communicate\n    self.send_server_request(server_req)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nBrokenPipeError: [Errno 32] Broken pipe\nwandb: ERROR Abnormal program exit..\nTraceback (most recent call last):\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 1078, in init\n    run = wi.init()\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 739, in init\n    _ = backend.interface.communicate_run_start(run_obj)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\", line 235, in communicate_run_start\n    result = self._communicate_run_start(run_start)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py\", line 484, in _communicate_run_start\n    result = self._communicate(rec)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py\", line 255, in _communicate\n    return self._communicate_async(rec, local=local).get(timeout=timeout)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/interface/interface_sock.py\", line 58, in _communicate_async\n    future = self._router.send_and_receive(rec, local=local)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/interface/router.py\", line 94, in send_and_receive\n    self._send_message(rec)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/interface/router_sock.py\", line 36, in _send_message\n    self._sock_client.send_record_communicate(record)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\", line 216, in send_record_communicate\n    self.send_server_request(server_req)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nBrokenPipeError: [Errno 32] Broken pipe\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"../tav_nn.py\", line 183, in &lt;module&gt;\n    main()\n  File \"../tav_nn.py\", line 106, in main\n    run = wandb.init(project=project_name, entity=\"ddi\" , config = args)\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 1116, in init\n    raise Exception(\"problem\") from error_seen\nException: problem\nProblem at:Problem at:Problem at: ../tav_nn.py 106 main\n ../tav_nn.py  106../tav_nn.py  main106\n main\nTraceback (most recent call last):\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 1078, in init\n    run = wi.init()\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 698, in init\n    timeout=self.settings.init_timeout, on_progress=self._on_progress_init\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/lib/mailbox.py\", line 259, in wait\n    raise MailboxError(\"transport failed\")\nwandb.errors.MailboxError: transport failed\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 1078, in init\n    run = wi.init()\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 1078, in init\n    run = wi.init()\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 698, in init\n    timeout=self.settings.init_timeout, on_progress=self._on_progress_init\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/lib/mailbox.py\", line 259, in wait\n    raise MailboxError(\"transport failed\")\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 698, in init\n    timeout=self.settings.init_timeout, on_progress=self._on_progress_init\nwandb.errors.MailboxError: transport failed\n  File \"/project/6051551/prsood/sarcasm_venv/lib/python3.7/site-packages/wandb/sdk/lib/mailbox.py\", line 259, in wait\n    raise MailboxError(\"transport failed\")\nwandb.errors.MailboxError: transport failed\nWARNING:torch.distributed.elastic.multiprocessing.api:Sending process 213168 closing signal SIGTERM\nWARNING:torch.distributed.elastic.multiprocessing.api:Sending process 213170 closing signal SIGTERM\nWARNING:torch.distributed.elastic.multiprocessing.api:Sending process 213171 closing signal SIGTERM\nERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 1 (pid: 213169) of binary: /project/6051551/prsood/sarcasm_venv/bin/python3\n2023-02-03 00:33:54,480 - wandb.wandb_agent - INFO - Cleaning up finished run: 6fnujhey\n</code></pre>\n<p>accelerate config file:</p>\n<pre><code class=\"lang-bash\">- `Accelerate` version: 0.16.0\n- Platform: Linux-3.10.0-1160.80.1.el7.x86_64-x86_64-with-centos-7.9.2009-Core\n- Python version: 3.7.7\n- Numpy version: 1.21.4\n- PyTorch version (GPU?): 1.10.0 (False)\n- `Accelerate` default config:\n        - compute_environment: LOCAL_MACHINE\n        - distributed_type: FSDP\n        - mixed_precision: no\n        - use_cpu: False\n        - dynamo_backend: NO\n        - num_processes: 4\n        - machine_rank: 0\n        - num_machines: 1\n        - rdzv_backend: static\n        - same_network: True\n        - main_training_function: main\n        - deepspeed_config: {}\n        - fsdp_config: {'fsdp_auto_wrap_policy': 'TRANSFORMER_BASED_WRAP', 'fsdp_backward_prefetch_policy': 'BACKWARD_PRE', 'fsdp_offload_params': True, 'fsdp_sharding_strategy': 2, 'fsdp_state_dict_type': 'SHARDED_STATE_DICT', 'fsdp_transformer_layer_cls_to_wrap': 'TransformerBlock'}\n        - megatron_lm_config: {}\n        - downcast_bf16: no\n</code></pre>\n<p>My initial python script that it can\u2019t get past</p>\n<pre><code class=\"lang-python\">def main():\n    \n    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n    project_name = \"MLP_test_text\"\n    args = arg_parse(project_name)\n    run = wandb.init(project=project_name, entity=\"ddi\" , config = args)\n    config = wandb.config\n    np.random.seed(config.seed)\n    torch.random.manual_seed(config.seed)\n\n    \n\n    param_dict = {\n        'epoch':config.epoch ,\n        'patience':config.patience ,\n        'lr': config.learning_rate ,\n        'clip': config.clip ,\n        'batch_size':8,#config.batch_size ,\n        'weight_decay':config.weight_decay ,\n        'model': config.model,\n        'T_max':config.T_max ,\n        'seed':config.seed,\n        'label_task':config.label_task,\n    }\n\n    df = pd.read_pickle(f\"{args.dataset}.pkl\")\n    if param_dict['label_task'] == \"sentiment\":\n        number_index = \"sentiment\"\n        label_index = \"sentiment_label\"\n    else:\n        number_index = \"emotion\"\n        label_index = \"emotion_label\"\n\n\n    df_train = df[df['split'] == \"train\"] \n    df_test = df[df['split'] == \"test\"] \n    df_val = df[df['split'] == \"val\"] \n\n\n        \n    df = df[~df['timings'].isna()] # Still seeing what the best configuration is for these\n\n    \"\"\"\n    Due to data imbalance we are going to reweigh our CrossEntropyLoss\n    To do this we calculate 1 - (num_class/len(df)) the rest of the functions are just to order them properly and then convert to a tensor\n    \"\"\"\n    \n    \n    weights = torch.Tensor(list(dict(sorted((dict(1 - (df[number_index].value_counts()/len(df))).items()))).values()))\n    label2id = df.drop_duplicates(label_index).set_index(label_index).to_dict()[number_index]\n    id2label = {v: k for k, v in label2id.items()}\n\n    model_param = {\n        'output_dim':len(weights) ,\n        'dropout' : config.dropout,\n        'early_div' : config.early_div\n    }\n    \n    param_dict['weights'] = weights\n    param_dict['label2id'] = label2id\n    param_dict['id2label'] = id2label\n\n    print(f\" in main \\n param_dict = {param_dict} \\n model_param = {model_param} \\n df {args.dataset} , with df_size = {len(df)} \\n \")\n    \n    world_size = torch.cuda.device_count()\n    print(f\"world_size = {world_size}\" , flush=True)\n   \n    runModel(\"cuda\", world_size ,df_train , df_val , df_test ,param_dict , model_param , run )\n    \nif __name__ == '__main__':\n    main()\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-08T11:01:31.653Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/prsood\">@prsood</a>, thanks for reporting this and for the detailed explanation! As discussed <a href=\"https://discuss.huggingface.co/t/weights-biases-sweep-with-multi-gpu-accelerate-launch/26417/2\" rel=\"noopener nofollow ugc\">here</a>, it seems you need to add <code>if main_process:</code> to your code  in order to make the distinction between the main process and the rest of them. Could you please try setting this and see if it works? Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-10T13:13:59.164Z",
				"Answer_body": "<p>Hi prsood,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-09T11:02:16.744Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "AI/Machine Learning Beginner Looking for Guidance",
		"Question_link": "https://community.wandb.ai/t/ai-machine-learning-beginner-looking-for-guidance/3817",
		"Question_created_time": "2023-02-03T22:17:47.800Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 118,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey everyone! I\u2019m not trying to take too much of anyone\u2019s time, but I am a humble video producer extremely fascinated with AI/ML with a few questions.</p>\n<p>I am about to start a graduate program at UT Austin studying AI//ML, and am wondering what path I should take to be able to mix my deep knowledge of creative video production with my nubile AI knowledge. I have completed a Bachelor\u2019s in Video Production, and have been creating video content my entire life. I fully understand this introductory AI course will in no way prepare me to jump into the front lines of AI imaging and video generation, but I am wondering if there\u2019s a market for someone with my video expertise wanting to learn more about AI. Should I be prepared to spend the next few years deep diving into computer science to even be considered in this industry? Or could I build a solid career path with my current knowledge of video production, and a couple more introductory coding/AI/ML courses?</p>\n<p>Thank you all for your time. I wish you luck in bringing the future to us faster than ever!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-03T22:19:14.275Z",
				"Answer_body": "<p>Also, I am asking this question here because I heard K\u00e1roly Zsolnai-Feh\u00e9r from Two Minute Papers plugged this site and how it could help me with AI/ML questions. But if there is a better forum for questions like this please let me know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-08T00:28:57.061Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/natelongvideo\">@natelongvideo</a> , welcome to the W&amp;B community forums. Happy to provide some feedback from experience.</p>\n<p>My career began in industrial automation, where I worked in developing drug manufacturing systems for biopharma companies. A few years into my role, I became interested in ML and decided on a career pivot. I spent multiple months working through online MOOCs via DeepLearning ai, Coursera, Udemy, and Udacity (side note: <a href=\"https://wandb.ai/fully-connected\">wandb blogs</a> are great resources into MLOPs, check some blogs out sometime). Although MOOCs helped me grasp ML concepts and work through simple examples; in my opinion, they don\u2019t help you develop deep intuition into the application of ML in real-world projects.</p>\n<p>Start by identifying which industry (maybe Video AI?)/companies you want to land in and network with individuals to gain an understanding of the type of projects they work on, and the skills/requirements their teams look for in new candidates. In parallel, establish a foundational knowledge base of ML and work through problems that interest you. Build out a solid, very detailed project portfolio and advertise your work online. Consider hosting your projects on wandb <img src=\"https://emoji.discourse-cdn.com/twitter/smile.png?v=12\" title=\":smile:\" class=\"emoji\" alt=\":smile:\" loading=\"lazy\" width=\"20\" height=\"20\">, our new profile page layout is perfect for this. Once you have a few projects, apply for internships/entry-level roles, and eventually with persistence, you will land somewhere.</p>\n<p>An additional approach you could take is to pursue a part-time Master\u2019s program in CS/ML. The merits of which are up for debate based on who you talk to.</p>\n<p>If interested, check out our new case study on <a href=\"https://wandb.ai/wandb_fc/marz/reports/Leveraging-AI-for-Visual-FX-at-MARZ--VmlldzozNDU3MTU3?galleryTag=case-study\">MARZ</a>, a VFX company that leverages AI for visual FX and have worked on wandavision, watchmen, and wednesday. The beauty of of ML is it\u2019s applicable in every industry.</p>\n<p>Cheers!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-09T00:29:54.487Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Academic account registration",
		"Question_link": "https://community.wandb.ai/t/academic-account-registration/3644",
		"Question_created_time": "2023-01-05T16:43:21.368Z",
		"Question_answer_count": 11,
		"Question_score_count": 0,
		"Question_view_count": 326,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Dear community,</p>\n<p>I am trying to add my academic email (from my research institute). However, when I receive a confirmation email and try to open the link - I get en error and can not display the page. My collegue from another institute has the same problem.<br>\nCould you please tell if you had a similar issue and if you solved it?</p>\n<p>Kindly,<br>\nViktoriia</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-05T17:30:07.646Z",
				"Answer_body": "<p>Hi Viktoriia!</p>\n<p>Seems like your school\u2019s domain is not in our system. Can you give me your full academic email and talk a bit about your school so I can add id directly to our code base?</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-09T11:01:45.382Z",
				"Answer_body": "<p>hey Artsiom,</p>\n<p>I dont see an option to send a dm here and would not like to disclose my full email on the web. but my domain is <span class=\"mention\">@mdc-berlin.de</span> . It belongs to the Max Delbr\u00fcck Center Berlin where i do my PhD. We do a lot of molecular biology research both computationly and in a wet lab. In my case I collaborate with people from the Hasso Plattner  Institute (HPI) Postdam. We are working on a ML models to represent  sequencing data. My collegues also can not register with their academic emails.</p>\n<p>Would be amazing if you could add our institutes, where we work, and universities, where we study, to the database:<br>\n[at]mdc-berlin[dot]de - MDC Berlin<br>\n[at]hpi[dot]de - HPI Postdam<br>\n[at]uni-potsdam[dot]de - University of Postdam<br>\n[at]hu-berlin[dot]de - Humboldt University Berlin</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-09T20:19:36.357Z",
				"Answer_body": "<p>Hi Viktoriia!</p>\n<p>The information you have provided about the <a href=\"http://mdc-berlin.de\" rel=\"noopener nofollow ugc\">mdc-berlin.de</a> domain was amazing and we\u2019ve added it to our codebase. The changes should be applied by the EOD or tomorrow morning. Are the other 3 domains not showing up as academic either?</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-10T10:08:42.992Z",
				"Answer_body": "<p>Yes, unfortunatelly other domains also dont work for WandB registration and my collegues are now using their gmail accounts <img src=\"https://emoji.discourse-cdn.com/twitter/pensive.png?v=12\" title=\":pensive:\" class=\"emoji\" alt=\":pensive:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-13T17:46:40.894Z",
				"Answer_body": "<p>Hi Viktoriia!</p>\n<p>I just added the rest of the domains into our system! The changes should take place either by end of today or Mid-Tuesday (bc Monday is a US holiday, so I don\u2019t think we\u2019ll have anyone in the office)</p>\n<p>Let me know how that fix works for you!</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-19T11:47:12.161Z",
				"Answer_body": "<p>Dear Artsiom,</p>\n<p>thank you for adding us. However, I keep having the same problem with confirming my email address. the error message is:</p>\n<pre><code class=\"lang-auto\">This site can\u2019t be reached\n\n**https://u8555476.ct.sendgrid.net/ls/click?upn=FCitFEx746VNJHtoJqCwj8JyVsAI-2F3-2BthpjCZJ-2BUwzl5xpSmbtqItmZldP8RpQaWpKUtku8otqsKhETSjoOo1cdhMYrFQB52924rGP8G8jUbrE526qAtC2QlAuJhHdAASwgL_rzp0vXOhEYP3KwOacdcFcJhva9K0-2FR1sgtDhvUxl2FPuLbXl6Pi4oD-2F55ymPSX4b0wr-2F9owOiurDD-2FLc1UtfpXA45bN4wpl6V8a66G84woaHb-2BGUCBMrOHbYbwNzu2p0lQv6YESpyVyRZT5gvUfG8Ylupd6O6DjbBcURAIsBnMXrQ41RzfWEfiV28b7sqImRJE3TdfWHOcLjvAAasA7EZd6xj4-2BfQfcrw5kpD47seII-3D** is unreachable.\n\nERR_ADDRESS_UNREACHABLE\n</code></pre>\n<p>I tried different networks and devices, and cleared my chache, tried another browser - nothing seem to help <img src=\"https://emoji.discourse-cdn.com/twitter/frowning.png?v=12\" title=\":frowning:\" class=\"emoji\" alt=\":frowning:\" loading=\"lazy\" width=\"20\" height=\"20\"><br>\nDo you know what could be the reason?</p>\n<p>Thank you in advance,<br>\nViktoriia</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-19T18:33:08.158Z",
				"Answer_body": "<p>Hi Viktoriia,</p>\n<p>When do you get this error? Is it when trying to sign up, add a new account, or trying to access the website?</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-24T20:29:35.760Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-29T06:28:01.265Z",
				"Answer_body": "<p>Hi Viktoriia, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-08T00:02:11.909Z",
				"Answer_body": "<p>I\u2019m having the same problem with the domains from my university.</p>\n<p>University of Agder, Grimstad, Norway<br>\nWorking on my master\u2019s thesis this semester on AI.<br>\nthe university domains: <span class=\"mention\">@uia.no</span> and <span class=\"mention\">@student.uia.no</span></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-09T00:02:51.480Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "I would like to access the values in a 'run_table' type artifact without downloading the file",
		"Question_link": "https://community.wandb.ai/t/i-would-like-to-access-the-values-in-a-run-table-type-artifact-without-downloading-the-file/3805",
		"Question_created_time": "2023-02-02T22:36:49.008Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 126,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have tried accessing the artifact in various ways, and I seem to get the artifact name, but then the artifact is not recognized as existing if I use wandb.use_artifact() or if I go through logged artifacts and try to access the table, the table does not exist.  I\u2019ve tried two ways:</p>\n<p>for key, value in run.summary.items():<br>\nprint(f\"{key}: {value}\")<br>\nif desired_string in key:<br>\nname = (see below for possible combinations of key and value)<br>\nwandb.init()<br>\nartifact = wandb.use_artifact(name)  <span class=\"hashtag\">#I</span> get an error here<br>\ntable = artifact.get(name)<br>\ncolumns = table.get_column(\u2018columns\u2019)<br>\nprint(columns)</p>\n<p>I\u2019ve tried the following to get the name that will let me use the artifact and table :<br>\nname = key<br>\nname = value[\u2018path\u2019]<br>\nname = ((value[\u2018path\u2019].split(\u2018:\u2019)[0]).split(\u2018/\u2019)[-1]).split(\u2018.\u2019)[0]<br>\nbecause the path had the format \"media/table/given_file_name.table.json</p>\n<p>I also tried stepping through the logged objects:<br>\nfor artifact in run.logged_artifacts():<br>\nfname = artifact.name<br>\nftype = artifact.type<br>\nif desired_string in fname and ftype == \u2018run_table\u2019:<br>\nname = fname<br>\ntable = artifact.get(name)<br>\ncolumns = table.get_column(\u2018columns\u2019) # get an error here because table is None<br>\nprint(columns)</p>\n<p>I have tried similar string operations as above to get the correct name for the table. I have also tried using the artifact ID instead of the name.</p>\n<p>I have no problems downloading the file containing the table data and then processing it, but I would like to access the data directly without downloading. Please help.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-06T21:52:08.447Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/snuss-warren\">@snuss-warren</a> , happy to look into this for you. You had mentioned running into an error when executing<br>\n<code>artifact = wandb.use_artifact(name)</code> , could you please provide details into what the error message is? As long as a project contains the artifact, you should be able to <a href=\"https://docs.wandb.ai/ref/python/run#use_artifact\">fetch it</a>. Example for one of my projects.</p>\n<pre><code class=\"lang-auto\">import wandb\nwandb.init(project=\"support\")\nartifact = wandb.use_artifact('mnist-preprocess:v0')\n</code></pre>\n<p>In terms of accessing the data directly or for example, downloading only a few files from an artifact. This isn\u2019t currently  an available feature but there is an active feature request out for this functionality.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-07T14:11:05.137Z",
				"Answer_body": "<p>Hi.  Thanks for your help. I believe the error in the use_artifact  command was \u201cfile not found\u201d or similar, and I believe it must have been  difference in the name I read compared to the actual file names.  It would not surprise me if it had to do with the path.  I unfortunately do not have the exact error and found another way to get the information.</p>\n<blockquote>\n<p>In terms of accessing the data directly or for example, downloading only a few files from an artifact. This isn\u2019t currently an available feature but there is an active feature request out for this functionality.</p>\n</blockquote>\n<p>So what I really wanted to do is not possible.  In that case, I have managed to access the needed files by downloading and  I will continue to use that solution. I believe my issue is resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-07T16:40:12.621Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/snuss-warren\">@snuss-warren</a> , thank you for the update. I will add your details to the feature request ticket and keep you updated once there\u2019s been movement on it\u2019s implementation. If you are able to reproduce the errors you originally saw with your artifacts and would like to continue the conversation, please do response and we\u2019ll take a close look. In the meantime I will mark the request resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-08T16:41:10.801Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "LImits of dashboard grouping",
		"Question_link": "https://community.wandb.ai/t/limits-of-dashboard-grouping/3832",
		"Question_created_time": "2023-02-06T11:58:14.250Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 81,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019ve performed a grid sweep over a set of hyper-parameters and collected the results of a few hundred experiments. I would like to analyze the results by grouping the experiments by the different hyper parameters and compare but i\u2019m running into a limitation.<br>\nThere\u2019s a subtitle at each metric that reads \u201cComputing group metrics from first 100 runs\u201d.<br>\nFrom what I could gather, it means that only the first 100 runs that are found in the sweep contribute to the grouped metrics, and not the first 100 runs of each group.<br>\nSince 100 runs doesn\u2019t cover all my groups, some groups are omitted entirely from the plot and I cannot view and compare all the groups in a single plot.<br>\nIs there a solution to this?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-07T14:49:39.832Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/galavineri\">@galavineri</a>, thanks for your question! If you click on Edit panel, you can control both the number of groups to show (maximum 100) in the Data section and the number of runs per group (no limit but large numbers may impact performance) in the Grouping section. Please let me know if this would be useful for you!<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/d8fba9261a8a73b483a6b39be35c5765f6aa8078.png\" data-download-href=\"/uploads/short-url/uXwju18JrdE00xoFWaW84BE6bj2.png?dl=1\" title=\"Screenshot 2023-02-07 at 15.45.15\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/d8fba9261a8a73b483a6b39be35c5765f6aa8078_2_690x203.png\" alt=\"Screenshot 2023-02-07 at 15.45.15\" data-base62-sha1=\"uXwju18JrdE00xoFWaW84BE6bj2\" width=\"690\" height=\"203\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/d8fba9261a8a73b483a6b39be35c5765f6aa8078_2_690x203.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/d8fba9261a8a73b483a6b39be35c5765f6aa8078_2_1035x304.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/d8fba9261a8a73b483a6b39be35c5765f6aa8078_2_1380x406.png 2x\" data-dominant-color=\"DCDDD9\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2023-02-07 at 15.45.15</span><span class=\"informations\">1880\u00d7555 60.8 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/3/33b0b3f0506aaa17062515a6315aa479ca2ddbef.png\" data-download-href=\"/uploads/short-url/7ngVYPr2TWa2NVs9UYv6s91elBB.png?dl=1\" title=\"Screenshot 2023-02-07 at 15.46.34\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/33b0b3f0506aaa17062515a6315aa479ca2ddbef_2_690x402.png\" alt=\"Screenshot 2023-02-07 at 15.46.34\" data-base62-sha1=\"7ngVYPr2TWa2NVs9UYv6s91elBB\" width=\"690\" height=\"402\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/33b0b3f0506aaa17062515a6315aa479ca2ddbef_2_690x402.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/3/33b0b3f0506aaa17062515a6315aa479ca2ddbef.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/3/33b0b3f0506aaa17062515a6315aa479ca2ddbef.png 2x\" data-dominant-color=\"FAFBFC\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2023-02-07 at 15.46.34</span><span class=\"informations\">717\u00d7418 12.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-10T13:13:18.564Z",
				"Answer_body": "<p>Hi Gal,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-08T14:50:16.376Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "If I'm logging metrics for MLOps from a test pipeline, how do I create a separate api key for that?",
		"Question_link": "https://community.wandb.ai/t/if-im-logging-metrics-for-mlops-from-a-test-pipeline-how-do-i-create-a-separate-api-key-for-that/3803",
		"Question_created_time": "2023-02-02T22:07:52.133Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 79,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>How do I create a separate API so that I can log metrics from test pipelines? It doesn\u2019t make sense to use a personal key for that.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-06T12:37:26.565Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/adgudime\">@adgudime</a>, thanks for your question! You can use a <a href=\"https://docs.wandb.ai/guides/technical-faq/general#what-is-a-service-account-and-why-is-it-useful\">service account</a> for this purpose,  could you please check if this would work for you? Thanks!</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-02-07T01:52:50.222Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/luis_bergua1\">@luis_bergua1</a> this would work perfectly. Thank you!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-07T08:40:29.901Z",
				"Answer_body": "<p>Great to hear it <a class=\"mention\" href=\"/u/adgudime\">@adgudime</a>! I\u2019ll then go ahead and close this ticket for now but please feel free to re-open it if you have any other question related. Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-08T08:41:25.491Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Deleting runs in local wandb instance doesn't delete associated entries in the database",
		"Question_link": "https://community.wandb.ai/t/deleting-runs-in-local-wandb-instance-doesnt-delete-associated-entries-in-the-database/3821",
		"Question_created_time": "2023-02-04T17:09:56.088Z",
		"Question_answer_count": 2,
		"Question_score_count": 1,
		"Question_view_count": 156,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Our local wandb instance was taking up a lot of space, so we tried to free up it by deleting old underperforming runs. This included around half of all the runs we had.</p>\n<p>However, deleting them didn\u2019t result in any freed-up space (mysql tables ended up taking the same size as pre-deletion). Is there any way to delete associated entries in the database?</p>\n<p>Thanks for the help!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-07T00:54:13.108Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/oshapio\">@oshapio</a>, happy to help with. Today W&amp;B does not reclaim space for deleted runs in the database. Here\u2019s a <a href=\"https://gist.github.com/vanpelt/0c13c556fa82cabdecb70d5ef90a4ea9\" rel=\"noopener nofollow ugc\">SQL procedure</a> that will delete the metrics and logs from the sql database for any runs that have been deleted in the UI. We\u2019re planning to integrate this logic into our application soon, but this can be used from a mysql shell to clear up data in the mean time.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-04-08T00:54:48.375Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How do handle overlapping segmentation masks?",
		"Question_link": "https://community.wandb.ai/t/how-do-handle-overlapping-segmentation-masks/3836",
		"Question_created_time": "2023-02-06T18:12:06.695Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 104,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>In maskrcnn I\u2019m pretty sure it\u2019s valid to output overlapping segmentation masks, but I\u2019m not sure how to handle this in wandb Masks and I haven\u2019t been able to find an example. The documentation says each \u201cMask\u201d is a 2D numpy array filled with class ids, which implies one class per pixel, right?</p>\n<p>Is there a way to visualize the masks if they\u2019re overlapping?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-06T18:56:27.252Z",
				"Answer_body": "<p>I was told by wandb support this was not possible, posting here for transparency</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-04-07T18:56:52.613Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Compare prediction/summary scores on a table",
		"Question_link": "https://community.wandb.ai/t/compare-prediction-summary-scores-on-a-table/3791",
		"Question_created_time": "2023-02-01T16:57:40.403Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 182,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>At the end of my run, I make predictions on the development set and log these scores to wandb with this command:</p>\n<pre><code class=\"lang-auto\">wandb.log({\"best_epoch\": best_epoch, \"dev_micro_acc\": dev_micro_acc, \"dev_weighted_f1\": dev_weighted_f1,\n               \"dev_f1_label1\": dev_f1_label1,\n               \"dev_f05_score\": dev_f05_score, \"dev_roc_auc\": dev_roc_auc})\n</code></pre>\n<p>These values then appear in the summary section on my overview page for each run. But how can I see them as overview to compare them with other runs? Like, it would be nice to see them as column on the run table such that I can sort there for the best score and therefore identify my best model, but I acknowledge that the config columns probably aren\u2019t the proper place for this.</p>\n<p>So where could I see such an overview on wandb?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-02T12:41:12.581Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/harpiye\">@harpiye</a>, thanks for writing in! These metrics should appear in the Runs table by default but if this isn\u2019t the case, in the top right corner there\u2019s a <code>Columns</code> button and you can manage the visible columns. If you cannot see these metrics there, could you please send me a link to the project and so I can have a look at it?</p>\n<p>To be able to compare runs, I\u2019d recommend you to use the <a href=\"https://docs.wandb.ai/ref/app/features/panels/run-comparer\">Run comparer plot</a> which you can add from <code>Add panel</code> and allows you to compare your different runs. Please let me know if this would work for you!</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-02-03T16:35:51.349Z",
				"Answer_body": "<p>I looked for it before under the columns but didn\u2019t type it in for searching because I thought I were seeing all possible columns  <img src=\"https://emoji.discourse-cdn.com/twitter/woman_facepalming.png?v=12\" title=\":woman_facepalming:\" class=\"emoji\" alt=\":woman_facepalming:\" loading=\"lazy\" width=\"20\" height=\"20\"> So I found them now.</p>\n<p>I didn\u2019t know about the run comparer panel, that will do, thank you!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-06T11:16:00.000Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/harpiye\">@harpiye</a>, great to see this worked! I\u2019ll then go ahead and close this ticket. Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-07T11:16:35.476Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Horrible performance when viewing charts for WandB run",
		"Question_link": "https://community.wandb.ai/t/horrible-performance-when-viewing-charts-for-wandb-run/3827",
		"Question_created_time": "2023-02-05T19:58:31.840Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 75,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019ve got several runs of a Pytorch training pipeline that log stuff to WandB. I\u2019m mostly just following the tutorials, not trying to do anything fancy. Generally, I log basic numeric metrics like loss every batch, and more complex metrics like mAP and images with bounding boxes every epoch. I\u2019m training for 100 epochs.</p>\n<p>However, when I try to look at the charts on <a href=\"http://WandB.ai\" rel=\"noopener nofollow ugc\">WandB.ai</a>, I\u2019m seeing some truly awful performance from the dashboard. CPU use by the browser is pegged at 100% for several minutes just trying to load the page. When things finally load, they are unresponsive, and CPU usage remains high.</p>\n<p>Am I doing something wrong here?  Am I logging too many images? (I\u2019m logging 128 per epoch.) I couldn\u2019t find any guidelines for this in the docs, but maybe I\u2019m just missing them. FWIW, I used to do a similar amount of logging in TensorBoard without an issue. Also, I think that back when I was running YOLOv5 training sessions, it was also doing similar logging, and WandB never seemed to have a problem with that.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-08T15:30:53.241Z",
				"Answer_body": "<p>Hi Daniel,</p>\n<p>Potentially, you are loading too many pictures in. Could you send me a link to your workspace so I could take a peek?</p>\n<p>Cheers,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-13T17:17:40.340Z",
				"Answer_body": "<p>Hi Daniel,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-14T19:07:35.318Z",
				"Answer_body": "<p>Hi Daniel, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-06T19:58:35.376Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb login not working for sweep",
		"Question_link": "https://community.wandb.ai/t/wandb-login-not-working-for-sweep/3822",
		"Question_created_time": "2023-02-05T00:51:26.979Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 317,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi folks<br>\nI have been seeing this since Friday Feb 3 afternoon PST. I am using wandb version <code>0.13.7</code>. I am logged in at wandb, but when I do</p>\n<pre><code class=\"lang-auto\">wandb sweep sweep.yaml\n</code></pre>\n<p>I see below error</p>\n<pre><code class=\"lang-auto\">wandb: ERROR Error while calling W&amp;B API: permission denied (&lt;Response [403]&gt;)\nwandb: ERROR Find detailed error logs at: /tmp/debug-cli.ec2-user.log\nError: permission denied\n</code></pre>\n<p>Below is the complete error log</p>\n<pre><code class=\"lang-auto\">2023-02-05 00:45:38 ERROR 403 response executing GraphQL.\n2023-02-05 00:45:38 ERROR {\"errors\":[{\"message\":\"permission denied\",\"path\":[\"upsertSweep\"],\"extensions\":{\"code\":\"PERMISSION_ERROR\"}}],\"data\":{\"upsertSweep\":null}}\n2023-02-05 00:45:38 ERROR Traceback (most recent call last):\n  File \"/home/ec2-user/anaconda3/envs/clip_env/lib/python3.7/site-packages/wandb/sdk/lib/retry.py\", line 113, in __call__\n    result = self._call_fn(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/clip_env/lib/python3.7/site-packages/wandb/sdk/internal/internal_api.py\", line 209, in execute\n    return self.client.execute(*args, **kwargs)  # type: ignore\n  File \"/home/ec2-user/anaconda3/envs/clip_env/lib/python3.7/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\", line 52, in execute\n    result = self._get_result(document, *args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/clip_env/lib/python3.7/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\", line 60, in _get_result\n    return self.transport.execute(document, *args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/clip_env/lib/python3.7/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/transport/requests.py\", line 39, in execute\n    request.raise_for_status()\n  File \"/home/ec2-user/anaconda3/envs/clip_env/lib/python3.7/site-packages/requests/models.py\", line 1021, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://api.wandb.ai/graphql\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ec2-user/anaconda3/envs/clip_env/lib/python3.7/site-packages/wandb/apis/normalize.py\", line 26, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/clip_env/lib/python3.7/site-packages/wandb/sdk/internal/internal_api.py\", line 2218, in upsert_sweep\n    raise e\n  File \"/home/ec2-user/anaconda3/envs/clip_env/lib/python3.7/site-packages/wandb/sdk/internal/internal_api.py\", line 2215, in upsert_sweep\n    check_retry_fn=util.no_retry_4xx,\n  File \"/home/ec2-user/anaconda3/envs/clip_env/lib/python3.7/site-packages/wandb/sdk/lib/retry.py\", line 129, in __call__\n    retry_timedelta_triggered = check_retry_fn(e)\n  File \"/home/ec2-user/anaconda3/envs/clip_env/lib/python3.7/site-packages/wandb/util.py\", line 969, in no_retry_4xx\n    raise UsageError(body[\"errors\"][0][\"message\"])\nwandb.errors.UsageError: permission denied\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ec2-user/anaconda3/envs/clip_env/lib/python3.7/site-packages/wandb/cli/cli.py\", line 97, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/clip_env/lib/python3.7/site-packages/wandb/cli/cli.py\", line 941, in sweep\n    launch_scheduler=_launch_scheduler_spec,\n  File \"/home/ec2-user/anaconda3/envs/clip_env/lib/python3.7/site-packages/wandb/apis/internal.py\", line 102, in upsert_sweep\n    return self.api.upsert_sweep(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/clip_env/lib/python3.7/site-packages/wandb/apis/normalize.py\", line 62, in wrapper\n    raise CommError(message, err).with_traceback(sys.exc_info()[2])\n  File \"/home/ec2-user/anaconda3/envs/clip_env/lib/python3.7/site-packages/wandb/apis/normalize.py\", line 26, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/ec2-user/anaconda3/envs/clip_env/lib/python3.7/site-packages/wandb/sdk/internal/internal_api.py\", line 2218, in upsert_sweep\n    raise e\n  File \"/home/ec2-user/anaconda3/envs/clip_env/lib/python3.7/site-packages/wandb/sdk/internal/internal_api.py\", line 2215, in upsert_sweep\n    check_retry_fn=util.no_retry_4xx,\n  File \"/home/ec2-user/anaconda3/envs/clip_env/lib/python3.7/site-packages/wandb/sdk/lib/retry.py\", line 129, in __call__\n    retry_timedelta_triggered = check_retry_fn(e)\n  File \"/home/ec2-user/anaconda3/envs/clip_env/lib/python3.7/site-packages/wandb/util.py\", line 969, in no_retry_4xx\n    raise UsageError(body[\"errors\"][0][\"message\"])\nwandb.errors.CommError: permission denied\n</code></pre>\n<p>Please suggest</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-08T15:38:00.938Z",
				"Answer_body": "<p>Hello Nahid,</p>\n<p>Thank you for contacting us and for your patience. Could you please type <code>wandb login --relogin</code> then try to run your sweep command again and let me know if it works? If not please share any error message or result.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-13T14:18:58.004Z",
				"Answer_body": "<p>Hello Nahid,</p>\n<p>Just following up if you tried my suggestion for the issue you had.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-15T20:40:59.030Z",
				"Answer_body": "<p>Hello Nahid,</p>\n<p>I will be closing this ticket as there is no answer. Feel free to contact us any time if you have the same or any other issue.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-06T00:51:39.472Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Find the \"run history at log step\" for a particular artifact using the API?",
		"Question_link": "https://community.wandb.ai/t/find-the-run-history-at-log-step-for-a-particular-artifact-using-the-api/3819",
		"Question_created_time": "2023-02-04T07:43:20.113Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 59,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>In the web UI, for a particular dashboard, under metadata I am interested in the \u201cRun history at log step\u201d information. I\u2019d like to retrieve this using the API.</p>\n<p>If I use run.scan_history, I get rows with model scores and the epoch and step, but not the artifact ID.</p>\n<p>If I have a public API Artifact, I have the artifact ID and version but not the epoch or step. Artifact</p>\n<p>How do I find the run history at log step for a particular artifact? I\u2019ve checked the API code and docs but still can\u2019t figure it out.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-07T18:29:14.634Z",
				"Answer_body": "<p>Hello Joseph!</p>\n<p>Just to get a better understanding of your question:</p>\n<ul>\n<li>Could you share your workspace that you are working on?</li>\n<li>What do you mean by \u201cRun history at log step\u201d?</li>\n<li>Are you trying to pull an artifact generated by a run or an artifact that you have logged?</li>\n</ul>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-10T00:03:04.176Z",
				"Answer_body": "<p>Hi Joseph, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-05T07:43:50.347Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Different history run lengths of a metric",
		"Question_link": "https://community.wandb.ai/t/different-history-run-lengths-of-a-metric/3776",
		"Question_created_time": "2023-01-30T03:56:38.658Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 126,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi everyone,</p>\n<p>I have been using W&amp;B to log my outputs of experiments and in one case I have a set up with fixed code and the hyperparameters change and the same code is run on the same data for the same amount of steps. However, when I use my own function to retrieve the values logged during training, they are of different lengths and it\u2019s causing quite a headache to plot these metrics over time because they don\u2019t align naturally.</p>\n<p>I use my own function to retrieve a metric from a run:</p>\n<pre><code class=\"lang-auto\">def get_wandb_history(identifier, key):\n    run = api.run(identifier)\n    run_history = run.history()\n    key_history = run_history[key]\n    key_history = np.array([x for x in key_history if float(x) &gt; 0.0])\n    return key_history\n</code></pre>\n<p>The penultimate line is because of the NaNs that store info at steps in between epochs.<br>\nI ran 6 different runs where only a single hyperparameter changed. After retrieving the results via the function above, the lengths I have for them are:</p>\n<pre><code class=\"lang-auto\">61\n62\n64\n67\n60\n61\n</code></pre>\n<p>What\u2019s going on here? Is there a better / more reliable way to check the stored outputs? In the visualisation tool online, the runs are aligned perfectly and show the effect I was hoping to find. However, when I want to use those values in my own plots, they are not temporally aligned. So, they are being stored correctly for visualisation on the web interface - just not when I want to retrieve them (?)</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-01T18:08:53.175Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/alxmrphi\">@alxmrphi</a>, thanks for reporting this! Could you please share with me a link to the project where these runs are stored and also what are the runs you are retrieving the results from? It would be great also if you could send me a code snippet to create these runs and try to reproduce the same behaviour you do and see what\u2019s happening here.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-03T06:46:59.257Z",
				"Answer_body": "<p>Hi Luis,</p>\n<p>Sure thing. Regarding sending the link and the code, I\u2019d prefer to do that privately but I can\u2019t find an email address for you. If you could let me know (or Twitter handle, social media info) then I can send via there if that\u2019s what you prefer.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-03T10:04:44.909Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/alxmrphi\">@alxmrphi</a>, thanks for your answer! Of course, could you send an email to <a href=\"mailto:support@wandb.com\">support@wandb.com</a> and so we can track it and have a look at the issue? It\u2019d be great if you could notify me once you do that. Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-03T16:57:44.835Z",
				"Answer_body": "<p>Email has been sent <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"> Thanks.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-03T17:35:26.738Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/alxmrphi\">@alxmrphi</a>, thanks! I\u2019ll have a look at this and get back to you by email.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-03T17:35:50.406Z",
				"Answer_body": "<p>This request was closed and merged into request <span class=\"hashtag\">#40595</span> \u201cReported issue in Forum\u201d.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-04T17:35:53.515Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Histograms over time like tensorboard",
		"Question_link": "https://community.wandb.ai/t/histograms-over-time-like-tensorboard/3709",
		"Question_created_time": "2023-01-17T22:30:02.048Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 190,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello everyone,</p>\n<p>I am trying to reproduce this kind of histogram over time that is available in tensorboard :</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/d1171085f5a5dcd3b87295a7d67d13c7430ef71d.png\" data-download-href=\"/uploads/short-url/tPHcPfG25CLsBmkGDsWiIbz2KDP.png?dl=1\" title=\"Capture d\u2019e\u0301cran 2023-01-17 a\u0300 17.47.08\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/d1171085f5a5dcd3b87295a7d67d13c7430ef71d_2_642x500.png\" alt=\"Capture d\u2019e\u0301cran 2023-01-17 a\u0300 17.47.08\" data-base62-sha1=\"tPHcPfG25CLsBmkGDsWiIbz2KDP\" width=\"642\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/d1171085f5a5dcd3b87295a7d67d13c7430ef71d_2_642x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/d1171085f5a5dcd3b87295a7d67d13c7430ef71d.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/d1171085f5a5dcd3b87295a7d67d13c7430ef71d.png 2x\" data-dominant-color=\"3A3D36\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Capture d\u2019e\u0301cran 2023-01-17 a\u0300 17.47.08</span><span class=\"informations\">864\u00d7672 48.5 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>When I use the histogram function from wandb and collect histograms over time I get a superposition of blurry histograms, which is un-usable (I\u2019m not really sure what I am looking at).<br>\nWhat I would expect to see instead for a multi-histogram visualisation would be  like the plot from tensorboard (see above), the offset accross timesteps is important. What\u2019s even more bizarre is that it seems that these plots are already plotted when I hover over the graph in wandb (where I see a clear histogram with a fitted curve above for every timestep I collected).</p>\n<p>Would it be possible to visualize those with an offset like in tensorboard? I really want to visualize the evolution of distribution of a value across episodes.</p>\n<p>Thanks,</p>\n<p>Yann</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-23T09:54:01.094Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/yann-berthelot\">@yann-berthelot</a> thanks a lot for writing in about this. This might be feasible with one of the following ways:</p>\n<ol>\n<li>If you are using <code>torch.nn</code> modules, just pass them to <code>wandb.watch</code>\n</li>\n<li>If you want to log tensorboard histograms from your code, you could use <code>wandb.init(sync_tensorboard)=True</code> and <code>wandb</code> wil convert the tensorboard histograms into <code>wandb.Histogram</code> objects</li>\n<li>You could pass a tensor of gradients or parameters to <code>wandb.Histogram</code> and <code>wandb.log</code> it in your code.</li>\n</ol>\n<p>Please let me know if you have tried any of these, and if that would work for you? Also, it would help to understand what type of data (and training framework) you would like to visualise in this way, so that I could provide a more customized solution if the above aren\u2019t applicable in your case.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-31T11:17:08.677Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/yann-berthelot\">@yann-berthelot</a> I wanted to check in here and see if any of the above suggestions would work for you, or if that won\u2019t give you the same functionality? Please also let me know if you have any additional questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-03T13:04:01.517Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/yann-berthelot\">@yann-berthelot</a> since we haven\u2019t heard back from you in a while, I will go ahead and close this ticket for now. However please let us know here if the above wouldn\u2019t work for you or if you had further questions about it, and we will be happy to assist you further!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-04T13:04:21.509Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Offline Sync Stalls after Missing Artefact",
		"Question_link": "https://community.wandb.ai/t/offline-sync-stalls-after-missing-artefact/3577",
		"Question_created_time": "2022-12-21T00:22:15.831Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 512,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m using Hydra+PL+WandB (Offline) to log a sweep of runs.</p>\n<p><strong>env</strong>:<br>\n<code>Python 3.7.11</code><br>\n<code>wandb==0.13.7</code><br>\n<code>pytorch-lightning==1.8.4</code><br>\n<code>hydra-core==1.3.0</code></p>\n<p>However, upon seeking to upload my runs to the cloud, I run into some issues:</p>\n<pre><code class=\"lang-auto\">(venv) user@machine:~/***/multirun/2022-12-19/08-18-10$ wandb sync --include-offline ./400/wandb/offline-run-20221219_082002-3ea0vv6x/\nFind logs at: /tmp/debug-cli.aime.log\nSyncing: https://wandb.ai/***/1pyryhlw ... wandb: ERROR Error uploading \"/***/.cache/wandb/artifacts/obj/md5/8b/bd5da60d38836c6f93b0db86b40ade\": FileNotFoundError, [Errno 2] No such file or directory: '/***/.cache/wandb/artifacts/obj/md5/8b/bd5da60d38836c6f93b0db86b40ade'\n</code></pre>\n<p>Two things are puzzling:</p>\n<ol>\n<li>The upload of all other files in the run is successful, but the sync never finishes due to the lacking artifact file</li>\n<li>The artifact has not been logged, at least not deliberately (No checkpoint callbacks) and there <strong>exist no checkpoint file</strong> in the <code>/offline-run-***/</code>-folder</li>\n</ol>\n<p>The log file shows what you expect, except it doesn\u2019t update past the final file and neither does it finish the process.</p>\n<p>I\u2019ve been trying to hack a solution going through the <code>wandb</code>-repository, but I\u2019d love some guidance on where to look and how to solve the above.</p>\n<p>The <code>sync</code>-function should continue execution even if a file is missing in my opinion - However in this particular case, I did not even do any checkpointing.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-22T15:58:00.509Z",
				"Answer_body": "<p>Bumping this</p>\n<p>Anyone <span class=\"mention\">@wandb</span> who can assist here?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-23T16:13:34.971Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/maxim1\">@maxim1</a> sorry to hear you\u2019re experiencing this issue. Would it be please possible to share the log file from the directory mentioned in the stack trace  <code>/tmp/debug-cli.aime.log</code>? also, may I ask if you have specified <code>WANDB_CACHE_DIR</code> environment variable? and do you have access permissions to <code>.cache</code> folder?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-24T12:08:39.340Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a> - Many thanks for your reply!</p>\n<p>Certainly, here\u2019s the log file output:</p>\n<pre><code class=\"lang-auto\">2022-12-19 00:01:20 INFO open for scan: /home/aime/prj_src/multirun/2022-06-09/09-24-25/multirun.yaml\n2022-12-19 00:09:50 INFO open for scan: /home/aime/prj_src/multirun/2022-12-18/10-29-43/0/wandb/offline-run-20221218_104336-2q9y4mow/run-2q9y4mow.wandb\n2022-12-19 00:09:50 INFO watching files in: /home/aime/prj_src/multirun/2022-12-18/10-29-43/0/wandb/offline-run-20221218_104336-2q9y4mow/files\n2022-12-19 00:09:50 INFO run started: 2q9y4mow with start time 1671360216.0\n2022-12-19 00:09:50 INFO saving file wandb-metadata.json with policy now\n2022-12-19 00:09:50 WARNING Seen metric with glob (shouldn't happen)\n2022-12-19 00:09:50 INFO saving file media/graph/graph_0_summary_32c3645b6907704909a4.graph.json with policy now\n2022-12-19 00:09:50 INFO saving file media/images/Valid inference_0_6f3db9012f813fcee5fa.png with policy now\n2022-12-19 00:09:50 INFO saving file media/images/Train inference_1_50658981cb1a79198db3.png with policy now\n2022-12-19 00:09:50 INFO saving file media/images/Valid inference_6_3eaf4f112eaad99349bc.png with policy now\n2022-12-19 00:09:50 INFO saving file media/images/Train inference_7_2640051d53e6690ba7a9.png with policy now\n2022-12-19 00:09:50 INFO saving file media/images/Valid inference_14_e322aa87b86a7f3477c7.png with policy now\n2022-12-19 00:09:50 INFO saving file media/images/Train inference_15_01b242873bf9a7141a86.png with policy now\n2022-12-19 00:09:50 INFO saving file media/images/Valid inference_22_1fb4eec232ff0dbb815a.png with policy now\n2022-12-19 00:09:50 INFO saving file media/images/Train inference_23_ca646b2c1ff110f969f3.png with policy now\n2022-12-19 00:09:50 INFO saving file media/images/Valid inference_30_2c0f12810e6c872d7dda.png with policy now\n2022-12-19 00:09:51 INFO saving file media/images/Train inference_31_7d845a264f5cd896180e.png with policy now\n2022-12-19 00:09:51 INFO saving file media/images/Valid inference_38_8917c31a3b11afd08cce.png with policy now\n2022-12-19 00:09:51 INFO saving file media/images/Train inference_39_1cfc52250bdc56d032e3.png with policy now\n2022-12-19 00:09:51 INFO saving file media/images/Valid inference_46_b6e6a04a61b0f2d0270e.png with policy now\n2022-12-19 00:09:51 INFO saving file media/images/Train inference_47_d63ea6d56909b89c25bf.png with policy now\n2022-12-19 00:09:51 INFO saving file media/images/Valid inference_54_ed3b44ecf811a0f9e828.png with policy now\n2022-12-19 00:09:51 INFO saving file media/images/Train inference_55_66e6a7250c23e30cc11a.png with policy now\n2022-12-19 00:09:51 INFO saving file media/images/Valid inference_62_0301d050ae7ce7824272.png with policy now\n2022-12-19 00:09:51 INFO saving file media/images/Train inference_63_dbe101e091f5f4a188fe.png with policy now\n2022-12-19 00:09:51 INFO saving file media/images/Valid inference_70_7ba836471d85aca11b45.png with policy now\n2022-12-19 00:09:51 INFO saving file media/images/Train inference_71_ca8b17db360be57133ef.png with policy now\n2022-12-19 00:09:51 INFO saving file media/images/Valid inference_78_b8dd0469e3fe5c171214.png with policy now\n2022-12-19 00:09:51 INFO saving file media/images/Train inference_79_0d01cec20f07b80977f1.png with policy now\n2022-12-19 00:09:51 INFO saving file media/images/Valid inference_86_703326494080bc46ef1e.png with policy now\n2022-12-19 00:09:51 INFO saving file media/images/Train inference_87_9458105b13681d9ed707.png with policy now\n2022-12-19 00:09:51 INFO saving file media/images/Valid inference_94_f8acdebbca3a66c3ee50.png with policy now\n2022-12-19 00:09:51 INFO saving file media/images/Train inference_95_8af811372dd5024d5902.png with policy now\n2022-12-19 00:09:51 INFO saving file media/images/Valid inference_102_182b173811a3e223834b.png with policy now\n2022-12-19 00:09:51 INFO saving file media/images/Train inference_103_172496cacfe0e41bca9d.png with policy now\n2022-12-19 00:09:52 INFO saving file media/images/Valid inference_110_b7c938d666dd5968b978.png with policy now\n2022-12-19 00:09:52 INFO saving file media/images/Train inference_111_efeb13d890fc1eacbdc0.png with policy now\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/2jnxp8ks-wandb-metadata.json\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/195cs3cr-media/graph/graph_0_summary_32c3645b6907704909a4.graph.json\n2022-12-19 00:09:52 INFO saving file media/images/Valid inference_118_529fccbb4e76b72ea607.png with policy now\n2022-12-19 00:09:52 INFO saving file media/images/Train inference_119_3924ad963de80a410c1e.png with policy now\n2022-12-19 00:09:52 INFO saving file media/images/Valid inference_126_d5594d092ed6d3b05041.png with policy now\n2022-12-19 00:09:52 INFO saving file media/images/Train inference_127_7035626180fe23c1f635.png with policy now\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/1jlzlrr7-media/images/Valid inference_38_8917c31a3b11afd08cce.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/irqahlgi-media/images/Train inference_55_66e6a7250c23e30cc11a.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/3ous6nz3-media/images/Valid inference_22_1fb4eec232ff0dbb815a.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/2enyfrx2-media/images/Train inference_23_ca646b2c1ff110f969f3.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/21prie98-media/images/Train inference_31_7d845a264f5cd896180e.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/cogv3m3s-media/images/Valid inference_6_3eaf4f112eaad99349bc.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/3egbft62-media/images/Train inference_7_2640051d53e6690ba7a9.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/o39ciyx7-media/images/Train inference_47_d63ea6d56909b89c25bf.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/bu427yan-media/images/Train inference_39_1cfc52250bdc56d032e3.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/2qzq2hn4-media/images/Valid inference_14_e322aa87b86a7f3477c7.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/3l2vpwh2-media/images/Train inference_15_01b242873bf9a7141a86.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/2c3xr1ph-media/images/Valid inference_46_b6e6a04a61b0f2d0270e.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/js5mhez5-media/images/Valid inference_30_2c0f12810e6c872d7dda.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/snl4vsrk-media/images/Train inference_63_dbe101e091f5f4a188fe.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/2z00izar-media/images/Valid inference_54_ed3b44ecf811a0f9e828.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/1d5mn6a7-media/images/Valid inference_62_0301d050ae7ce7824272.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/1xa67w81-media/images/Train inference_1_50658981cb1a79198db3.png\n2022-12-19 00:09:52 INFO saving file media/images/Valid inference_134_3b30f9c078c78eb24fee.png with policy now\n2022-12-19 00:09:52 INFO saving file media/images/Train inference_135_b6bad8609922af13cb18.png with policy now\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/647c2wdu-media/images/Valid inference_70_7ba836471d85aca11b45.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/1e1713zz-media/images/Train inference_71_ca8b17db360be57133ef.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/98a2y0k2-media/images/Train inference_79_0d01cec20f07b80977f1.png\n2022-12-19 00:09:52 INFO saving file media/images/Valid inference_142_fe0e33b7b6e9295af61f.png with policy now\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/1upt8e3y-media/images/Valid inference_78_b8dd0469e3fe5c171214.png\n2022-12-19 00:09:52 INFO saving file media/images/Train inference_143_10f52eb93dd1b2b063c3.png with policy now\n2022-12-19 00:09:52 INFO saving file media/images/Valid inference_150_a415a0585431d5d90a8e.png with policy now\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/3p54b24j-media/images/Valid inference_86_703326494080bc46ef1e.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/ego7my7n-media/images/Train inference_87_9458105b13681d9ed707.png\n2022-12-19 00:09:52 INFO saving file media/images/Train inference_151_6ca90486e7e0d1fb3ce0.png with policy now\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/y5jqbytv-media/images/Valid inference_0_6f3db9012f813fcee5fa.png\n2022-12-19 00:09:52 INFO saving file media/images/Valid inference_158_8b03f4c265e8a0a6955b.png with policy now\n2022-12-19 00:09:52 INFO saving file media/images/Train inference_159_43bd4f5634f7773e6914.png with policy now\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/2wa7xgdw-media/images/Train inference_95_8af811372dd5024d5902.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/1rvsakfu-media/images/Valid inference_102_182b173811a3e223834b.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/46sw1q8d-media/images/Train inference_103_172496cacfe0e41bca9d.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/3n64i2nt-media/images/Valid inference_94_f8acdebbca3a66c3ee50.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/lvu8r1so-media/images/Valid inference_110_b7c938d666dd5968b978.png\n2022-12-19 00:09:52 INFO Uploaded file /tmp/tmpbcxr1go_wandb/a2ihstrz-media/images/Train inference_111_efeb13d890fc1eacbdc0.png\n2022-12-19 00:09:53 INFO Uploaded file /tmp/tmpbcxr1go_wandb/1m9adafm-media/images/Valid inference_126_d5594d092ed6d3b05041.png\n2022-12-19 00:09:53 INFO Uploaded file /tmp/tmpbcxr1go_wandb/1ec36mow-media/images/Valid inference_118_529fccbb4e76b72ea607.png\n2022-12-19 00:09:53 INFO Uploaded file /tmp/tmpbcxr1go_wandb/2cz0cytd-media/images/Train inference_127_7035626180fe23c1f635.png\n2022-12-19 00:09:53 INFO Uploaded file /tmp/tmpbcxr1go_wandb/1em12exy-media/images/Train inference_135_b6bad8609922af13cb18.png\n2022-12-19 00:09:53 INFO Uploaded file /tmp/tmpbcxr1go_wandb/113dt6l2-media/images/Valid inference_142_fe0e33b7b6e9295af61f.png\n2022-12-19 00:09:53 INFO Uploaded file /tmp/tmpbcxr1go_wandb/3stzz7p1-media/images/Valid inference_134_3b30f9c078c78eb24fee.png\n2022-12-19 00:09:53 INFO Uploaded file /tmp/tmpbcxr1go_wandb/diqb3suj-media/images/Train inference_119_3924ad963de80a410c1e.png\n2022-12-19 00:09:53 INFO Uploaded file /tmp/tmpbcxr1go_wandb/1glqip6v-media/images/Train inference_143_10f52eb93dd1b2b063c3.png\n2022-12-19 00:09:53 INFO Uploaded file /tmp/tmpbcxr1go_wandb/gmn2afza-media/images/Train inference_151_6ca90486e7e0d1fb3ce0.png\n2022-12-19 00:09:53 ERROR Failed to upload file: /home/aime/.cache/wandb/artifacts/obj/md5/7a/39c0f0065b44b008aa0937c3dd6028\nTraceback (most recent call last):\n  File \"/home/aime/miniconda3/envs/ds39/lib/python3.9/site-packages/wandb/filesync/upload_job.py\", line 79, in push\n    deduped = self.save_fn(\n  File \"/home/aime/miniconda3/envs/ds39/lib/python3.9/site-packages/wandb/filesync/step_checksum.py\", line 116, in &lt;lambda&gt;\n    return lambda progress_callback: save_fn(\n  File \"/home/aime/miniconda3/envs/ds39/lib/python3.9/site-packages/wandb/sdk/internal/artifacts.py\", line 184, in &lt;lambda&gt;\n    lambda entry, progress_callback: self._manifest.storage_policy.store_file(\n  File \"/home/aime/miniconda3/envs/ds39/lib/python3.9/site-packages/wandb/sdk/wandb_artifacts.py\", line 1009, in store_file\n    shutil.copyfile(entry.local_path, f.name)\n  File \"/home/aime/miniconda3/envs/ds39/lib/python3.9/shutil.py\", line 264, in copyfile\n    with open(src, 'rb') as fsrc:\nFileNotFoundError: [Errno 2] No such file or directory: '/home/aime/.cache/wandb/artifacts/obj/md5/7a/39c0f0065b44b008aa0937c3dd6028'\n2022-12-19 00:09:53 INFO Uploaded file /tmp/tmpbcxr1go_wandb/avu2fr7x-media/images/Train inference_159_43bd4f5634f7773e6914.png\n2022-12-19 00:09:53 INFO Uploaded file /tmp/tmpbcxr1go_wandb/w29moe5o-media/images/Valid inference_158_8b03f4c265e8a0a6955b.png\n2022-12-19 00:09:53 INFO Uploaded file /tmp/tmpbcxr1go_wandb/36kfu59y-media/images/Valid inference_150_a415a0585431d5d90a8e.png\n2022-12-19 00:14:54 INFO open for scan: /home/aime/prj_src/multirun/2022-12-18/10-29-43/0/wandb/debug-internal.log\n2022-12-19 00:18:22 INFO open for scan: /home/aime/prj_src/multirun/2022-12-18/10-29-43/1/wandb/offline-run-20221218_104337-3qb05wuw/run-3qb05wuw.wandb\n2022-12-19 00:18:23 INFO watching files in: /home/aime/prj_src/multirun/2022-12-18/10-29-43/1/wandb/offline-run-20221218_104337-3qb05wuw/files\n2022-12-19 00:18:23 INFO run started: 3qb05wuw with start time 1671360217.0\n2022-12-19 00:18:23 INFO saving file wandb-metadata.json with policy now\n2022-12-19 00:18:23 WARNING Seen metric with glob (shouldn't happen)\n2022-12-19 00:18:23 INFO saving file media/graph/graph_0_summary_5b99ce66cd25ded9df00.graph.json with policy now\n</code></pre>\n<ol start=\"2\">\n<li>\n<p>I have not set <code>WANDB_CACHE_DIR</code> specifically, no - It would be at its default settings if any.</p>\n</li>\n<li>\n<p>Yes I do have access to the <code>.cache</code>-folder and upon double checking the files do not exist. And please keep in mind, I explicitly disabled model checkpointing, so I don\u2019t understand why its looking for an artefact in any case.</p>\n</li>\n</ol>\n<p>Hope we can get to the bottom of this <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-29T11:33:30.886Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/maxim1\">@maxim1</a> thanks a lot for the additional information. I have some further questions to help us get to the bottom of this issue:</p>\n<ul>\n<li>\n<p>This is the debug log of <code>wandb sync</code>, may I ask if you\u2019ve included here any <a href=\"https://docs.wandb.ai/ref/cli/wandb-sync\">arguments</a>?</p>\n</li>\n<li>\n<p>It seems to fail uploading an artifact file, any chance you <a href=\"https://docs.wandb.ai/ref/cli/wandb-artifact/wandb-artifact-cache/wandb-artifact-cache-cleanup\">cleaned up the cache</a>?</p>\n</li>\n<li>\n<p>From your original post this seem to be coming from the run-id <code>1pyryhlw</code>. Would it be please possible to share the <code>debug.log</code> and <code>debug-internal.log</code> from inside this run directory?</p>\n</li>\n<li>\n<p>finally would it work for you to sync all the rest runs with the following command?<br>\n<code>wandb sync --exclude-globs \"*1pyryhlw*\" --sync-all</code></p>\n</li>\n</ul>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-02T10:39:57.471Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a>, thanks for the additional information:</p>\n<ol>\n<li>I\u2019ve used the command <code>wandb sync --include-offline offline-run-&lt;DATE&gt;_&lt;TIME&gt;-&lt;RUNID&gt;/</code> upon attempting to sync the logs</li>\n<li>I\u2019ve tried cleaning the catch yes, there\u2019s no effect: <code>Reclaimed 0.0B of space</code> with a <code>TARGETSIZE=0b</code>\n</li>\n<li>Yes shared here below: <code>debug.log</code> is empty while the <code>debug-internal.log</code> is as given below (with minor redactions to not go above the limit)</li>\n<li>If doing the command you suggest it claims there\u2019s <code>wandb: ERROR Nothing to sync.</code> However, upon manual inspection, there are still all the metrics in the folders.</li>\n</ol>\n<p><strong>Output of <code>debug-internal.log</code></strong></p>\n<pre><code class=\"lang-auto\">2022-12-19 12:29:02,476 INFO    StreamThr :3811302 [internal.py:wandb_internal():92] W&amp;B internal server running at pid: 3811302, started at: 2022-12-19 12:29:02.475848\n2022-12-19 12:29:02,478 DEBUG   HandlerThread:3811302 [handler.py:handle_request():141] handle_request: status\n2022-12-19 12:29:02,479 DEBUG   SenderThread:3811302 [sender.py:send_request():249] send_request: status\n2022-12-19 12:29:02,481 INFO    WriterThread:3811302 [datastore.py:open_for_write():77] open: ./wandb/offline-run-20221219_122902-1pyryhlw/run-1pyryhlw.wandb\n2022-12-19 12:29:02,670 DEBUG   HandlerThread:3811302 [handler.py:handle_request():141] handle_request: run_start\n2022-12-19 12:29:04,512 DEBUG   HandlerThread:3811302 [meta.py:__init__():37] meta init\n2022-12-19 12:29:04,512 DEBUG   HandlerThread:3811302 [meta.py:__init__():51] meta init done\n2022-12-19 12:29:04,512 DEBUG   HandlerThread:3811302 [meta.py:probe():211] probe\n2022-12-19 12:29:04,519 DEBUG   HandlerThread:3811302 [meta.py:_setup_git():201] setup git\n2022-12-19 12:29:04,560 DEBUG   HandlerThread:3811302 [meta.py:_setup_git():208] setup git done\n2022-12-19 12:29:04,560 DEBUG   HandlerThread:3811302 [meta.py:_save_pip():55] save pip\n2022-12-19 12:29:04,561 DEBUG   HandlerThread:3811302 [meta.py:_save_pip():69] save pip done\n2022-12-19 12:29:04,561 DEBUG   HandlerThread:3811302 [meta.py:_save_conda():76] save conda\n2022-12-19 12:29:07,101 DEBUG   HandlerThread:3811302 [meta.py:_save_conda():86] save conda done\n2022-12-19 12:29:07,102 DEBUG   HandlerThread:3811302 [meta.py:probe():249] probe done\n2022-12-19 12:29:11,090 DEBUG   HandlerThread:3811302 [handler.py:handle_request():141] handle_request: partial_history\n&lt;REDACTED REPEATED LINES OF `handle_request: partial history`&gt;\n2022-12-19 16:04:11,087 DEBUG   HandlerThread:3811302 [handler.py:handle_request():141] handle_request: partial_history\n2022-12-19 16:04:13,589 DEBUG   HandlerThread:3811302 [handler.py:handle_request():141] handle_request: poll_exit\n2022-12-19 16:04:13,589 DEBUG   SenderThread:3811302 [sender.py:send():235] send: exit\n2022-12-19 16:04:13,589 INFO    SenderThread:3811302 [sender.py:send_exit():371] handling exit code: 0\n2022-12-19 16:04:13,590 INFO    SenderThread:3811302 [sender.py:send_exit():373] handling runtime: 12910\n2022-12-19 16:04:13,590 INFO    SenderThread:3811302 [sender.py:_save_file():947] saving file wandb-summary.json with policy end\n2022-12-19 16:04:13,590 INFO    SenderThread:3811302 [sender.py:send_exit():379] send defer\n2022-12-19 16:04:13,591 DEBUG   SenderThread:3811302 [sender.py:send_request():249] send_request: poll_exit\n2022-12-19 16:04:13,591 DEBUG   HandlerThread:3811302 [handler.py:handle_request():141] handle_request: defer\n2022-12-19 16:04:13,591 INFO    HandlerThread:3811302 [handler.py:handle_request_defer():164] handle defer: 0\n2022-12-19 16:04:13,591 DEBUG   SenderThread:3811302 [sender.py:send_request():249] send_request: defer\n2022-12-19 16:04:13,592 INFO    SenderThread:3811302 [sender.py:send_request_defer():388] handle sender defer: 0\n2022-12-19 16:04:13,592 INFO    SenderThread:3811302 [sender.py:transition_state():392] send defer: 1\n2022-12-19 16:04:13,592 DEBUG   HandlerThread:3811302 [handler.py:handle_request():141] handle_request: defer\n2022-12-19 16:04:13,592 INFO    HandlerThread:3811302 [handler.py:handle_request_defer():164] handle defer: 1\n2022-12-19 16:04:13,651 DEBUG   SenderThread:3811302 [sender.py:send_request():249] send_request: defer\n2022-12-19 16:04:13,651 INFO    SenderThread:3811302 [sender.py:send_request_defer():388] handle sender defer: 1\n2022-12-19 16:04:13,651 INFO    SenderThread:3811302 [sender.py:transition_state():392] send defer: 2\n2022-12-19 16:04:13,651 DEBUG   HandlerThread:3811302 [handler.py:handle_request():141] handle_request: defer\n2022-12-19 16:04:13,651 INFO    HandlerThread:3811302 [handler.py:handle_request_defer():164] handle defer: 2\n2022-12-19 16:04:13,651 DEBUG   SenderThread:3811302 [sender.py:send_request():249] send_request: defer\n2022-12-19 16:04:13,651 INFO    SenderThread:3811302 [sender.py:send_request_defer():388] handle sender defer: 2\n2022-12-19 16:04:13,652 INFO    SenderThread:3811302 [sender.py:transition_state():392] send defer: 3\n2022-12-19 16:04:13,652 DEBUG   HandlerThread:3811302 [handler.py:handle_request():141] handle_request: defer\n2022-12-19 16:04:13,652 INFO    HandlerThread:3811302 [handler.py:handle_request_defer():164] handle defer: 3\n2022-12-19 16:04:13,652 DEBUG   SenderThread:3811302 [sender.py:send_request():249] send_request: defer\n2022-12-19 16:04:13,652 INFO    SenderThread:3811302 [sender.py:send_request_defer():388] handle sender defer: 3\n2022-12-19 16:04:13,652 INFO    SenderThread:3811302 [sender.py:transition_state():392] send defer: 4\n2022-12-19 16:04:13,652 DEBUG   HandlerThread:3811302 [handler.py:handle_request():141] handle_request: defer\n2022-12-19 16:04:13,652 INFO    HandlerThread:3811302 [handler.py:handle_request_defer():164] handle defer: 4\n2022-12-19 16:04:13,667 DEBUG   SenderThread:3811302 [sender.py:send_request():249] send_request: defer\n2022-12-19 16:04:13,668 INFO    SenderThread:3811302 [sender.py:send_request_defer():388] handle sender defer: 4\n2022-12-19 16:04:13,668 INFO    SenderThread:3811302 [sender.py:transition_state():392] send defer: 5\n2022-12-19 16:04:13,668 DEBUG   HandlerThread:3811302 [handler.py:handle_request():141] handle_request: defer\n2022-12-19 16:04:13,669 INFO    HandlerThread:3811302 [handler.py:handle_request_defer():164] handle defer: 5\n2022-12-19 16:04:13,669 DEBUG   SenderThread:3811302 [sender.py:send_request():249] send_request: defer\n2022-12-19 16:04:13,669 INFO    SenderThread:3811302 [sender.py:send_request_defer():388] handle sender defer: 5\n2022-12-19 16:04:13,669 INFO    SenderThread:3811302 [sender.py:transition_state():392] send defer: 6\n2022-12-19 16:04:13,669 DEBUG   HandlerThread:3811302 [handler.py:handle_request():141] handle_request: defer\n2022-12-19 16:04:13,669 INFO    HandlerThread:3811302 [handler.py:handle_request_defer():164] handle defer: 6\n2022-12-19 16:04:13,669 DEBUG   SenderThread:3811302 [sender.py:send_request():249] send_request: defer\n2022-12-19 16:04:13,669 INFO    SenderThread:3811302 [sender.py:send_request_defer():388] handle sender defer: 6\n2022-12-19 16:04:13,669 INFO    SenderThread:3811302 [sender.py:transition_state():392] send defer: 7\n2022-12-19 16:04:13,669 DEBUG   HandlerThread:3811302 [handler.py:handle_request():141] handle_request: defer\n2022-12-19 16:04:13,670 INFO    HandlerThread:3811302 [handler.py:handle_request_defer():164] handle defer: 7\n2022-12-19 16:04:13,670 DEBUG   SenderThread:3811302 [sender.py:send_request():249] send_request: defer\n2022-12-19 16:04:13,670 INFO    SenderThread:3811302 [sender.py:send_request_defer():388] handle sender defer: 7\n2022-12-19 16:04:13,670 INFO    SenderThread:3811302 [sender.py:transition_state():392] send defer: 8\n2022-12-19 16:04:13,670 DEBUG   HandlerThread:3811302 [handler.py:handle_request():141] handle_request: defer\n2022-12-19 16:04:13,670 INFO    HandlerThread:3811302 [handler.py:handle_request_defer():164] handle defer: 8\n2022-12-19 16:04:13,670 DEBUG   SenderThread:3811302 [sender.py:send_request():249] send_request: defer\n2022-12-19 16:04:13,670 INFO    SenderThread:3811302 [sender.py:send_request_defer():388] handle sender defer: 8\n2022-12-19 16:04:13,670 INFO    SenderThread:3811302 [sender.py:transition_state():392] send defer: 9\n2022-12-19 16:04:13,670 DEBUG   HandlerThread:3811302 [handler.py:handle_request():141] handle_request: defer\n2022-12-19 16:04:13,670 INFO    HandlerThread:3811302 [handler.py:handle_request_defer():164] handle defer: 9\n2022-12-19 16:04:13,671 DEBUG   SenderThread:3811302 [sender.py:send_request():249] send_request: defer\n2022-12-19 16:04:13,671 INFO    SenderThread:3811302 [sender.py:send_request_defer():388] handle sender defer: 9\n2022-12-19 16:04:13,671 INFO    SenderThread:3811302 [sender.py:transition_state():392] send defer: 10\n2022-12-19 16:04:13,671 DEBUG   HandlerThread:3811302 [handler.py:handle_request():141] handle_request: defer\n2022-12-19 16:04:13,671 DEBUG   SenderThread:3811302 [sender.py:send():235] send: final\n2022-12-19 16:04:13,671 INFO    HandlerThread:3811302 [handler.py:handle_request_defer():164] handle defer: 10\n2022-12-19 16:04:13,671 DEBUG   SenderThread:3811302 [sender.py:send_request():249] send_request: defer\n2022-12-19 16:04:13,671 INFO    SenderThread:3811302 [sender.py:send_request_defer():388] handle sender defer: 10\n2022-12-19 16:04:13,692 DEBUG   HandlerThread:3811302 [handler.py:handle_request():141] handle_request: poll_exit\n2022-12-19 16:04:13,693 DEBUG   SenderThread:3811302 [sender.py:send_request():249] send_request: poll_exit\n2022-12-19 16:04:13,794 DEBUG   HandlerThread:3811302 [handler.py:handle_request():141] handle_request: sampled_history\n2022-12-19 16:04:13,797 DEBUG   HandlerThread:3811302 [handler.py:handle_request():141] handle_request: get_summary\n2022-12-19 16:04:13,820 DEBUG   HandlerThread:3811302 [handler.py:handle_request():141] handle_request: shutdown\n2022-12-19 16:04:13,820 INFO    HandlerThread:3811302 [handler.py:finish():790] shutting down handler\n2022-12-19 16:04:14,677 INFO    WriterThread:3811302 [datastore.py:close():281] close: ./wandb/offline-run-20221219_122902-1pyryhlw/run-1pyryhlw.wandb\n2022-12-19 16:04:14,693 INFO    SenderThread:3811302 [sender.py:finish():1107] shutting down sender\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-02T20:58:47.093Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/maxim1\">@maxim1</a> ,</p>\n<p>Apologies for the delay here - This looks like a bug in our integration with Pytorch Lightning, and we shall be looking into this. Could you share how exactly you instantiated your <code>WandbLogger</code> so that I can share it with our engineering team?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-03T20:59:33.982Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Moving runs is stuck at 0%",
		"Question_link": "https://community.wandb.ai/t/moving-runs-is-stuck-at-0/3795",
		"Question_created_time": "2023-02-01T21:33:13.064Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 90,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m trying to move runs between from one project to another but the UI shows \u201cMoving\u2026 0%\u201d and hangs indefinitely. I\u2019ve tried refreshing my browser and moving different subsets of runs but nothing seems to work. Any idea what might be going on?  Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-02T20:12:17.487Z",
				"Answer_body": "<p>Hello!</p>\n<p>I can try to replicate your issue from our side. Just to get the full picture:</p>\n<ul>\n<li>What is the project you want to take runs from?</li>\n<li>What runs of the project are you trying to move ? (If you are using a filter, could you tell me the filter)</li>\n<li>What is the project you want to move your runs to?</li>\n</ul>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-07T16:06:41.237Z",
				"Answer_body": "<p>Hi Haithem, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-02T21:33:33.526Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb: Network error (ConnectionError), entering retry loop",
		"Question_link": "https://community.wandb.ai/t/wandb-network-error-connectionerror-entering-retry-loop/3789",
		"Question_created_time": "2023-02-01T12:18:02.442Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 393,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am using wandb version 0.12.21\u2026 My code was working fine till yesterday, but I am getting this error\u2026</p>\n<p>wandb: Currently logged in as: shashi7679. Use <code>wandb login --relogin</code> to force relogin<br>\nwandb: Appending key for <a href=\"http://api.wandb.ai\">api.wandb.ai</a> to your netrc file: /root/.netrc<br>\nwandb: Network error (ConnectionError), entering retry loop.</p>\n<p>Problem at: train.py 333 <br>\nProcess wandb_internal:<br>\nTraceback (most recent call last):<br>\nFile \u201ctrain.py\u201d, line 333, in <br>\nTraceback (most recent call last):<br>\nFile \u201c/opt/conda/lib/python3.8/multiprocessing/process.py\u201d, line 315, in _bootstrap<br>\nself.run()<br>\nFile \u201c/opt/conda/lib/python3.8/multiprocessing/process.py\u201d, line 108, in run<br>\nself._target(*self._args, **self._kwargs)<br>\nFile \u201c/opt/conda/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\u201d, line 160, in wandb_internal<br>\nthread.join()<br>\nFile \u201c/opt/conda/lib/python3.8/threading.py\u201d, line 1011, in join<br>\nself._wait_for_tstate_lock()<br>\nFile \u201c/opt/conda/lib/python3.8/threading.py\u201d, line 1027, in _wait_for_tstate_lock<br>\nelif lock.acquire(block, timeout):<br>\nKeyboardInterrupt<br>\nwandb.init(project=\u2018Toon-GAN\u2019,config=hyper_parameters)<br>\nFile \u201c/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\u201d, line 1065, in init<br>\nraise e<br>\nFile \u201c/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\u201d, line 1043, in init<br>\nrun = wi.init()<br>\nFile \u201c/opt/conda/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\u201d, line 689, in init<br>\nbackend.cleanup()<br>\nFile \u201c/opt/conda/lib/python3.8/site-packages/wandb/sdk/backend/backend.py\u201d, line 248, in cleanup<br>\nself.wandb_process.join()<br>\nFile \u201c/opt/conda/lib/python3.8/multiprocessing/process.py\u201d, line 149, in join<br>\nres = self._popen.wait(timeout)<br>\nFile \u201c/opt/conda/lib/python3.8/multiprocessing/popen_fork.py\u201d, line 47, in wait<br>\nreturn self.poll(os.WNOHANG if timeout == 0.0 else 0)<br>\nFile \u201c/opt/conda/lib/python3.8/multiprocessing/popen_fork.py\u201d, line 27, in poll<br>\npid, sts = os.waitpid(self.pid, flag)<br>\nKeyboardInterrupt<br>\n^CTraceback (most recent call last):<br>\nFile \u201c\u201d, line 1, in <br>\nError in atexit._run_exitfuncs:<br>\nTraceback (most recent call last):<br>\nFile \u201c/opt/conda/lib/python3.8/multiprocessing/popen_fork.py\u201d, line 27, in poll<br>\npid, sts = os.waitpid(self.pid, flag)<br>\nKeyboardInterrupt<br>\nFile \u201c/opt/conda/lib/python3.8/multiprocessing/spawn.py\u201d, line 116, in spawn_main<br>\nexitcode = _main(fd, parent_sentinel)<br>\nFile \u201c/opt/conda/lib/python3.8/multiprocessing/spawn.py\u201d, line 129, in _main<br>\nreturn self._bootstrap(parent_sentinel)<br>\nFile \u201c/opt/conda/lib/python3.8/multiprocessing/process.py\u201d, line 333, in _bootstrap<br>\nthreading._shutdown()<br>\nFile \u201c/opt/conda/lib/python3.8/threading.py\u201d, line 1388, in _shutdown<br>\nlock.acquire()<br>\nKeyboardInterrupt</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-03T17:54:57.278Z",
				"Answer_body": "<p>Hello!</p>\n<p>Could you send your debug logs so I can get a closer look into your <code>ConnectionError</code>?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-07T23:08:53.273Z",
				"Answer_body": "<p>Hi shashikantprasad1111, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-02T12:18:41.618Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Set y ranges in Parallel Coordinates plot",
		"Question_link": "https://community.wandb.ai/t/set-y-ranges-in-parallel-coordinates-plot/3745",
		"Question_created_time": "2023-01-25T10:48:15.926Z",
		"Question_answer_count": 4,
		"Question_score_count": 2,
		"Question_view_count": 189,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I want to compare many runs through a parallel coordinates plot and I need to evaluate them in terms of different metrics.<br>\nWhat I get by default when creating it manually is the following (where the various kinds of AUC scores is what I am interested in):<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/8/81cde959eb67c03e8cd28d5c2f65b305ce1d20e8.png\" data-download-href=\"/uploads/short-url/iwiKWiM6XBlEBWoJ1rFVitBIl5e.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/81cde959eb67c03e8cd28d5c2f65b305ce1d20e8_2_690x205.png\" alt=\"image\" data-base62-sha1=\"iwiKWiM6XBlEBWoJ1rFVitBIl5e\" width=\"690\" height=\"205\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/81cde959eb67c03e8cd28d5c2f65b305ce1d20e8_2_690x205.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/81cde959eb67c03e8cd28d5c2f65b305ce1d20e8_2_1035x307.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/81cde959eb67c03e8cd28d5c2f65b305ce1d20e8_2_1380x410.png 2x\" data-dominant-color=\"FCFAFA\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1772\u00d7527 130 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>However, as you can see the AUCs columns have different yticks and range depending on the corresponding values, which makes it impossible to interpret them intuitively. Is it possible to set column ranges manually?</p>\n<p><strong>More context:</strong> I think this is related to <a href=\"https://community.wandb.ai/t/scaling-in-the-parelles-coordinates-plot/3274\">another question</a> on this blog. The reason why this would be convenient is when you want to compare different metrics or the same metric for different models.<br>\nIn particular, I want to compare the performance of a baseline solution (<code>Cumulative AUC (MELD)</code> ) VS my model (<code>Cumulative AUC</code>). So intuitively I would see whether the lines go up passing from one column to the other to determin whether the second column shows better performance. Unfortunately, that is misleading if I the two columns have different ranges.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-26T13:19:50.372Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lclissa\">@lclissa</a>, thanks for your feedback! I also answeres the other question, so I am aware of this and currently it is not possible, so I will create a new feature request, thank you very much for providing the context. As I suggested in the other thread, a workaround could be to create two new runs logging the limits for each metric. Please let me know if I can help you in any other way!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-28T08:06:58.603Z",
				"Answer_body": "<p><s>I can confirm that logging the endpoints works, thanks! <img src=\"https://emoji.discourse-cdn.com/twitter/smiley.png?v=12\" title=\":smiley:\" class=\"emoji\" alt=\":smiley:\" loading=\"lazy\" width=\"20\" height=\"20\"> </s></p>\n<p><strong>Edit:</strong><br>\nUnfortunately, the workaround only partially solves the problem. In fact, this approach breaks when I need to perform dynamic filtering.</p>\n<p>For example, I logged 0.5 and 1 as endpoints for all AUC metrics and it works for the \u201cglobal\u201d view.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/f/f2f388e4698ff37a2132169a36cb9b0c407f1f6e.jpeg\" data-download-href=\"/uploads/short-url/yFfjKKjJKcUQfnXgHXEiKuBGCBw.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/f/f2f388e4698ff37a2132169a36cb9b0c407f1f6e_2_690x197.jpeg\" alt=\"image\" data-base62-sha1=\"yFfjKKjJKcUQfnXgHXEiKuBGCBw\" width=\"690\" height=\"197\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/f/f2f388e4698ff37a2132169a36cb9b0c407f1f6e_2_690x197.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/f/f2f388e4698ff37a2132169a36cb9b0c407f1f6e_2_1035x295.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/f/f2f388e4698ff37a2132169a36cb9b0c407f1f6e_2_1380x394.jpeg 2x\" data-dominant-color=\"E7CEE2\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1725\u00d7494 162 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>However, for some reasons I then want to inspect the parallel coordinates plot of the best/worst runs. In this case, the filtered view would have unmatched lower/upper range endpoints respectively.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/dd4de800b4f5e4bef26a446afa0f7d5945b4d7e1.png\" data-download-href=\"/uploads/short-url/vzKqVGUgTpaxrnLne4KZtVVNnod.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/dd4de800b4f5e4bef26a446afa0f7d5945b4d7e1_2_690x197.png\" alt=\"image\" data-base62-sha1=\"vzKqVGUgTpaxrnLne4KZtVVNnod\" width=\"690\" height=\"197\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/dd4de800b4f5e4bef26a446afa0f7d5945b4d7e1_2_690x197.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/dd4de800b4f5e4bef26a446afa0f7d5945b4d7e1_2_1035x295.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/dd4de800b4f5e4bef26a446afa0f7d5945b4d7e1_2_1380x394.png 2x\" data-dominant-color=\"FBF8FB\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1725\u00d7494 132 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Of course, it would be impossible to manually log the endpoints for each possible filter, so I think the only way to handle this situation would be by setting a specified range for each column (unless one could log directly one line per run in the same parallel coordinates plot).</p>\n<p>Ideally, it would be nice if the range could be set:</p>\n<ul>\n<li>programmatically when logging + editable from the dashboard</li>\n<li>optionally for groups of metrics</li>\n<li>with a smart dynamic default (e.g. <code>[min(group_metrics) - offset, max(group_metrics) + offset]</code> )</li>\n</ul>\n<p>I would be happy to contribute if needed, although I would need some guidance as I am not so expert of a programmer <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><br>\nP.S. Can you link me the feature request so I can track it?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-31T13:30:10.704Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lclissa\">@lclissa</a>, thanks for explaining this! I\u2019ll share this feedback with our Product Team. Regarding the feature request, unfortunately this is something internal, so I cannot share the link to it. We\u2019ll notify you if this is implemented in the future.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-01T13:31:06.720Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Different run sets within a panel grid",
		"Question_link": "https://community.wandb.ai/t/different-run-sets-within-a-panel-grid/3721",
		"Question_created_time": "2023-01-19T12:16:22.264Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 204,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hello, I want to create a grid panel containing several linecharts but the selected runs are different.<br>\nTo elaborate on my need: I have several algorithms, evaluated across timesteps on several environments. I want one line chart per environment. To illustrate, my final requirement is to get something that looks like this:</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/f/f2059dafd12562e424e2b66a3e2aabb2b4e1b204.png\" alt=\"Screenshot from 2023-01-19 13-12-26\" data-base62-sha1=\"yx1zXviDcru4wcBIHNfwKEhCyFK\" width=\"435\" height=\"213\"></p>\n<p>How would you do that?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-20T18:42:33.197Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/qgallouedec\">@qgallouedec</a>, thanks for writing in! As you\u2019d like to have a figure with independent charts inside, one option would be to use <a href=\"https://docs.wandb.ai/ref/app/features/custom-charts\">custom charts</a>. I let you <a href=\"https://vega.github.io/vega/examples/barley-trellis-plot/\" rel=\"noopener nofollow ugc\">here</a> and <a href=\"https://vega.github.io/vega/examples/brushing-scatter-plots/\" rel=\"noopener nofollow ugc\">here</a> two Vega examples that may be useful in order to build your figure. Other way I can think of for this is rendering the chart through <a href=\"https://docs.wandb.ai/guides/track/log/plots#matplotlib-and-plotly-plots\">Plotly/Matplotlib</a> and then log it. Please let me know if any of these would be useful!</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-01-26T11:04:05.664Z",
				"Answer_body": "<p>Hi Quentin,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-26T17:13:06.886Z",
				"Answer_body": "<p>Thanks very much for your answer <a class=\"mention\" href=\"/u/luis_bergua1\">@luis_bergua1</a>! Indeed, that\u2019s what I was looking for. With a reasonable effort, the custom chat can do what I want. However, I\u2019m not a big fan of the integration with Vega, the rendering is not the same as with Wandb charts, and we don\u2019t have access to the same options (or at least, not in the same way). I think it\u2019s a pity that we can\u2019t dissociate the runset within a panel grid , it would allow me to do exactly that, with lower effort and taking advantage of all the nice wandb options.<br>\nBest,</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-31T13:23:07.648Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/qgallouedec\">@qgallouedec</a>, thanks for your answer! Happy to hear that the custom chart would work for you. I\u2019ll also share your feedback about having this available without using Vega with our Team. Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-01T13:23:10.482Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "My wandb page is extremely slow",
		"Question_link": "https://community.wandb.ai/t/my-wandb-page-is-extremely-slow/3784",
		"Question_created_time": "2023-01-31T02:03:32.553Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 105,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>when i try to look at evaluation graph, it loads extremely slowly for some reason.</p>\n<p>Is  there anythin i can do to speed up this process?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-01T22:45:18.281Z",
				"Answer_body": "<p>Hi Abe, thank you for writing in! Can you make sure that the data you are sending to wandb follows the recommended practices stated here please? Also, can you tell me whether this is happening on multiple different browsers or just the one you\u2019re currently using?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-07T01:04:23.254Z",
				"Answer_body": "<p>Hi Abe, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-01T02:03:41.296Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Using WandB in Visual Studio Code",
		"Question_link": "https://community.wandb.ai/t/using-wandb-in-visual-studio-code/3752",
		"Question_created_time": "2023-01-25T23:44:11.711Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 122,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Dear community,</p>\n<p>I want to use WandB locally in my VSCode project, but my Ipython kernel keeps dying. After restarting the kernel it always prints out the errore message: \u201cFailed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\u201d and \u201cwandb: Currently logged in as: XXX. Use <code>wandb login --relogin</code> to force relogin\u201d</p>\n<p>I already tried to import os, as well as setting the environment variabele to my local notebook, but this didnt change a thing. I am using python 3.9.12</p>\n<p>I hope you can help me in this matter</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-27T08:48:31.766Z",
				"Answer_body": "<p>I don\u2019t think this is related to W&amp;B. You should try to fix your kernel crashing. Good luck <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-30T18:51:36.691Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/martin-woschitz\">@martin-woschitz</a> thank you for reporting this issue. This first message is just a warning so it shouldn\u2019t cause any issues running your code, also the second message  is an informatio output about the user account that you\u2019ve logged in. When does the Ipython kernel stops working, is it when you\u2019re running a python script? would it be possible to make a new virtual environment and install <code>wandb</code> only there to test if that\u2019s what\u2019s causing the issue for you?</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-03-31T18:52:21.787Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Define_metric parameter 'hidden' not working?",
		"Question_link": "https://community.wandb.ai/t/define-metric-parameter-hidden-not-working/3748",
		"Question_created_time": "2023-01-25T15:38:05.424Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 87,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I\u2019m new to W&amp;B and was setting up my metrics like this:</p>\n<pre><code class=\"lang-auto\"># define x-axes\nwandb.define_metric(\"batch#\", hidden=True)   # \"hidden\" not working\nwandb.define_metric(\"epoch#\", hidden=True)\n# define metrics and match to x-axis\nwandb.define_metric(\"loss\", step_metric=\"#batch#\")\nwandb.define_metric(\"f1\", step_metric=\"epoch#\")\n</code></pre>\n<p>I want graphs of loss/batch# and f1/epoch# on my dashboard, but not graphs of batch#/step or epoch#/step. Therefore, I set the function parameter \u2018hidden\u2019 to True for these. It does not work, I still get automatically generated panels of them. Any advice?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-30T18:41:09.863Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tim123\">@tim123</a> thanks so much for spotting and reporting this issue. We were able to reproduce it on our end, and I have reported it to our engineering team. I also linked this discussion with the internal ticket, so that we can reach out to you here if there are any further updates. In the meantime, these plots can be only manually deleted from the UI.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-31T18:41:27.676Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Control knobs for sending commands back to the running job / controlling live variables from the das",
		"Question_link": "https://community.wandb.ai/t/control-knobs-for-sending-commands-back-to-the-running-job-controlling-live-variables-from-the-das/3710",
		"Question_created_time": "2023-01-18T12:57:43.876Z",
		"Question_answer_count": 3,
		"Question_score_count": 2,
		"Question_view_count": 118,
		"Question_has_accepted_answer": false,
		"Question_body": "<h2>\n<a name=\"feature-1\" class=\"anchor\" href=\"#feature-1\"></a><img src=\"https://emoji.discourse-cdn.com/twitter/rocket.png?v=12\" title=\":rocket:\" class=\"emoji\" alt=\":rocket:\" loading=\"lazy\" width=\"20\" height=\"20\"> Feature</h2>\n<p>There should be a way to attach variables to the logger, that you can modify live from from controls in the dashboard.</p>\n<h3>\n<a name=\"motivation-2\" class=\"anchor\" href=\"#motivation-2\"></a>Motivation</h3>\n<p>When you have a running job and are monitoring the progress, you sometimes want to adjust the learning rate or other hyperparameter (should we switch to fine-tuning mode, etc.).</p>\n<h3>\n<a name=\"pitch-3\" class=\"anchor\" href=\"#pitch-3\"></a>Pitch</h3>\n<p>This is a bit of a unspoken black-magic deep learning technique. However, if you read papers from Meta, etc. or talk to hardcore old-school practitioners, they have these super long-running difficult optimization problems, and say something like: \u201cWell we trained the generator for X thousand epochs, then we enabled the discriminator, then Y thousand epochs later we dropped the learning rate, etc.\u201d This is ideally done by monitoring a live, running job and modifying the variables in situ.</p>\n<h3>\n<a name=\"alternatives-4\" class=\"anchor\" href=\"#alternatives-4\"></a>Alternatives</h3>\n<ul>\n<li>The non-agile way to do this is let your run go for a while, decide afterwards that you should have changed something at some point in time, code that, run it again and cross your fingers. This is obviously pretty slow and requires luck.</li>\n<li>A hacky way to do this is to create a DSL with sentinel files that the running job reads and applies. However, the workflow is useful enough that there should be a common way to do this.</li>\n</ul>\n<h3>\n<a name=\"additional-context-5\" class=\"anchor\" href=\"#additional-context-5\"></a>Additional context</h3>\n<p>I\u2019m not aware of any logging library that does this. So it would make great blog posts to show off and attract more users.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-27T20:33:49.173Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/turian\">@turian</a>, thank you for the feature request as well as the use-case this would unlock! I will go ahead and submit this to engineering team and follow up once they have a chance to look into this.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-27T20:50:18.560Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/nathank\">@nathank</a> Thanks. Here is another simple example, which would make a nice demonstration for a blog post:</p>\n<p>I was recently doing a randomized grid search, running 8 jobs simultaneously. After looking at a few training runs, it was clear that any model that did not achieve loss of 0.1 by batch 1000 should be stopped and restarted with new hyperparameters. So this is something that would be useful to control from the dashboard.</p>\n<p>(Another similar example is that I would then go manually adjust the grid script by hand, to remove learning rates that were too high or too low. I would prefer to do that from the dashboard.)</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-28T20:51:06.597Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Unable to initialise wandb on Colab even after setting up login and project name",
		"Question_link": "https://community.wandb.ai/t/unable-to-initialise-wandb-on-colab-even-after-setting-up-login-and-project-name/3740",
		"Question_created_time": "2023-01-24T04:15:26.372Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 115,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>On python3.8 , and using wandb==0.9.7, on google Colab<br>\nI am getting this error</p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"/usr/local/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\", line 1105, in init\n  File \"/usr/local/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\", line 167, in setup\n  File \"/usr/local/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py\", line 307, in setup\n  File \"/usr/local/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py\", line 302, in _setup\n  File \"/usr/local/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py\", line 288, in __init__\n  File \"/usr/local/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py\", line 106, in __init__\n  File \"/usr/local/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py\", line 234, in _setup\n  File \"/usr/local/lib/python3.8/site-packages/wandb/sdk/wandb_setup.py\", line 262, in _setup_manager\n  File \"/usr/local/lib/python3.8/site-packages/wandb/sdk/wandb_manager.py\", line 112, in __init__\n  File \"/usr/local/lib/python3.8/site-packages/wandb/sdk/service/service.py\", line 137, in start\n  File \"/usr/local/lib/python3.8/site-packages/wandb/sdk/service/service.py\", line 132, in _launch_server\nAssertionError\nwandb: ERROR Abnormal program exit\nproc exited with 1\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-24T15:32:06.749Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/romajain\">@romajain</a> thanks for reporting this issue. Could you please provide more details, such as a code snippet of the lines where it fails, or other packages you\u2019ve installed? Is there any reason you\u2019re using wandb v0.9.7? It would be recommended that you upgrade to the most recent (currently 0.13.9) as it includes many bug fixes and features since then. You can upgrade with <code>pip install --upgrade wandb</code>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-27T17:25:15.843Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/romajain\">@romajain</a> just checking in here to see if that issue still occurs for you or if you\u2019ve upgraded to a newer version? could you please provide any additional information to help us understand what\u2019s causing this issue? thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-28T17:26:00.562Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Best Practices for WandB Artifacts",
		"Question_link": "https://community.wandb.ai/t/best-practices-for-wandb-artifacts/3536",
		"Question_created_time": "2022-12-12T14:10:19.554Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 161,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi there, I am currently exploring a best practices for wandb artifacts.  Can anybody let me know there best way to create artifacts rather than saving each runs as artifacts</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-30T18:38:00.987Z",
				"Answer_body": "<p>Hi Supriya,</p>\n<p>Runs produce artifacts, but that doesn\u2019t mean that runs are artifacts.</p>\n<p>Here (ttps://docs.wandb.ai/guides/artifacts/artifacts-faqs) are our documents on artifacts. When you start a run you can upload an artifact/multiple artifacts during it, in order to keep version control of that artifact. For example, you can upload your dataset to artifacts and every time your dataset changes you will be able to see its new version inside of the artifact and control that dataset\u2019s different versions. Or you could upload your model.</p>\n<p>Think of artifacts as a version control system something similar to github.</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-02T20:15:21.796Z",
				"Answer_body": "<p>Hi Supriya,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-06T21:50:45.205Z",
				"Answer_body": "<p>Hi Supriya, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-10T14:11:05.374Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "API and Website out of sync",
		"Question_link": "https://community.wandb.ai/t/api-and-website-out-of-sync/3730",
		"Question_created_time": "2023-01-21T00:39:32.135Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 83,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I ran a sweep and I\u2019m finding the API (using python) and the website dashboard report different data regarding the runs. For example, the API says that the sweep contains a different number of runs than the website dashboard says. Also, the status for certain runs is also out of sync (e.g. according to API the run is still \u201crunning\u201d but according website the run finished 4hrs ago). I\u2019m wondering why the two are so out of sync? Is there anything I can do to sync them? I\u2019ve deleted all the run files locally so I assume both would be calling the same backend\u2026 It\u2019s also been several hours so I don\u2019t think it\u2019s just a momentary lapse.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-26T21:50:29.160Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/omar-s\">@omar-s</a> could you send me a link to the run and I can take a look?</p>\n<p>Also, could you send me the code snippet you are using to access the run vie the API?</p>\n<p>These should be in sync since they both are polling their data from the same source but I\u2019d like to test this and see if I see the same behavior you are seeing.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-27T21:50:45.424Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb to download models to a container",
		"Question_link": "https://community.wandb.ai/t/wandb-to-download-models-to-a-container/3738",
		"Question_created_time": "2023-01-23T23:43:33.620Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 80,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>We want to containerize our models using a CI/CD pipeline in bitbucket.  This means i need to install and run wandb in a temporary/interim container just long enough to download several models.  Then the models can be copied into a container using a DockerFile.  Is there a recommended method for setting up wandb for this scenario?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-25T18:32:33.651Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a>,</p>\n<p>The easiest and best way here is probably to use something like <code>wandb artifact get</code> in your Dockerfile to download the artifact into your container. Here are some <a href=\"https://docs.wandb.ai/ref/cli/wandb-artifact/wandb-artifact-get\">docs</a> to get you started! Let me know if this helps or if I can do anything else.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-25T19:11:37.171Z",
				"Answer_body": "<p>This is very helpful.<br>\nI had been thinking too much of working Python and was unaware of the CLI interface.<br>\nThank you. -K</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-26T17:43:44.998Z",
				"Answer_body": "<p>Of course! Is there anything else I can help out with?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-27T17:44:33.547Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Run.history(keys=key_list) returns empty history",
		"Question_link": "https://community.wandb.ai/t/run-history-keys-key-list-returns-empty-history/3746",
		"Question_created_time": "2023-01-25T13:16:39.969Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 108,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi everyone,</p>\n<p>when calling <code>run.history(keys=key_list)</code> with a <code>key_list</code> that contains more than one key with a \u2018/\u2019 character in it,  an empty history is returned:</p>\n<pre><code class=\"lang-auto\">history = run.history(keys=[\"hierarchy_1/metric_1\", \"hierarchy_1/metric_2\"], samples=n_samples)\nprint(history)\n</code></pre>\n<p>yields this output:</p>\n<pre><code class=\"lang-auto\">Empty DataFrame\nColumns: []\nIndex: []\n</code></pre>\n<p>However, calling it with only one key in the list yields the full history:</p>\n<pre><code class=\"lang-auto\">history_metric_1 = run.history(keys=[\"hierarchy_1/metric_1\"], samples=n_samples)\nhistory_metric_2 = run.history(keys=[\"hierarchy_1/metric_2\"], samples=n_samples)\n</code></pre>\n<p>both work and return <code>n_samples</code> steps of the run history.</p>\n<p>Calling <code>run.history()</code> without any keys and extracting them afterwards is not an option for me due to another bug in the API, discussed <a href=\"https://community.wandb.ai/t/calling-run-history-samples-n-samples-returns-a-sample-size-different-from-n-samples/3414\">here</a>.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-26T13:49:51.569Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kolja\">@kolja</a>, thanks a lot for reporting this! I have checked this but it seems I am not getting the same behaviour as you do, by running a code like this:</p>\n<pre><code class=\"lang-auto\">import wandb\n\nentity = entity_name\nproject = project_name\n\nrun = wandb.init(entity=entity, project=project)\nfor i in range(5):\n  run.log({'hierarchy_1/metric_1':i, 'hierarchy_1/metric_2':1/(i+1)})\nid = run.id\nrun.finish()\n\napi = wandb.Api()\nrun = api.run(f'{entity}/{project}/{id}')\nhistory = run.history(keys=[\"hierarchy_1/metric_1\", \"hierarchy_1/metric_2\"], samples=5)\nprint(history)\n</code></pre>\n<p>I can see both metrics properly:</p>\n<pre><code class=\"lang-auto\">  _step  hierarchy_1/metric_1  hierarchy_1/metric_2\n0      0                     0              1.000000\n1      1                     1              0.500000\n2      2                     2              0.333333\n3      3                     3              0.250000\n4      4                     4              0.200000\n</code></pre>\n<p>Could you please try this code and see if it works? Also, could you send me the link of the run and so I can have a look at it and see what type of data are you using because maybe this is affecting? Thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-30T12:49:12.794Z",
				"Answer_body": "<p>Hi Kolja,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-27T13:50:47.450Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Renaming columns in the runs table?",
		"Question_link": "https://community.wandb.ai/t/renaming-columns-in-the-runs-table/3592",
		"Question_created_time": "2022-12-23T14:16:46.773Z",
		"Question_answer_count": 5,
		"Question_score_count": 1,
		"Question_view_count": 349,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello!</p>\n<p>I\u2019ve got a large nested config file that I usually log with each runs. The problem is that I only see the beginning of each of the path of the hyperparameters, which isn\u2019t so useful.</p>\n<p>See this picture:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/4/4feef90ca3c84455b4d4181120295a389faca498.png\" data-download-href=\"/uploads/short-url/bp7IsEY9jp884hM6YlobtiDLMyA.png?dl=1\" title=\"Screenshot from 2022-12-23 15-15-24\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/4feef90ca3c84455b4d4181120295a389faca498_2_690x157.png\" alt=\"Screenshot from 2022-12-23 15-15-24\" data-base62-sha1=\"bp7IsEY9jp884hM6YlobtiDLMyA\" width=\"690\" height=\"157\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/4feef90ca3c84455b4d4181120295a389faca498_2_690x157.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/4feef90ca3c84455b4d4181120295a389faca498_2_1035x235.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/4feef90ca3c84455b4d4181120295a389faca498_2_1380x314.png 2x\" data-dominant-color=\"F9FAFA\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot from 2022-12-23 15-15-24</span><span class=\"informations\">4268\u00d7976 309 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Is there a way to automatically rename every columns so that only the last word in the hyperparameter path is displayed?</p>\n<p>Like if my hyperparameter path is something like:<br>\nconfig.model.autoencoder.layer I want to only see layer</p>\n<p>Best,</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-27T12:24:07.186Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lthiet\">@lthiet</a>, thanks for writing in! Currently this isn\u2019t possible as you need to have one unique identifier for each column so that\u2019s why the full path is showed. I can create a new feature request for being able to change the name of columns in the Runs Table if you want, could you explain me a little bit about your use-case? Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-29T17:57:20.584Z",
				"Answer_body": "<p>Sure. To configure my runs, I use a JSON file. It has some levels of indirection. For example at the top level I have two nested JSON objects that describes the configuration of the training pipeline (e.g. epoch, etc.) and the configuration of the model (layer size, learning rate, etc.). This is a trivial example and in reality I must have 3 or 4 nested objects until I get to an actual parameters. For example the path to learning rate in my configuration file is as such: vdbae_config.model_config.unet_model_config.optimizer_scheduler_config.learning rate. Usually, only the last part of the path matters to me (learning rate) so it would be nice to display that instead of the whole path.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-30T10:58:25.407Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lthiet\">@lthiet</a>, thanks a lot for sharing this! I have submitted your feedback to our Engineering Team, thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-26T12:18:35.908Z",
				"Answer_body": "<p>I would also like to have this feature in wandb.  I had 2 tensorboard runs with their directory names different and so after uploading, when going to the runs table to compare different logged metrics, the column names are different (prefixed by the folder name). So we can\u2019t see the results of the same metric under one column.</p>\n<p>Is would be great if it is possible to rename a column to some generic name like accuracy, so that the column can have values for both.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-27T12:18:49.538Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Log images during mmdetection training",
		"Question_link": "https://community.wandb.ai/t/log-images-during-mmdetection-training/3606",
		"Question_created_time": "2022-12-27T14:23:26.556Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 122,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am using the mmdetection platform.<br>\nFor training I am using a .py config file that contains the log configuration from W&amp;B documentation:<br>\nlog_config = dict(<br>\nhooks = [<br>\ndict(type=\u2018TextLoggerHook\u2019),<br>\ndict(type=\u2018MMDetWandbHook\u2019,<br>\ninit_kwargs={\u2018project\u2019: \u2018\u2026\u2019, \u2018entity\u2019: \u2018\u2026\u2019, \u2018name\u2019: \u2018\u2026\u2019},<br>\ninterval=10,<br>\nlog_checkpoint=True,<br>\nlog_checkpoint_metadata=True,<br>\nnum_eval_images=200,<br>\nbbox_score_thr=0.3)]<br>\n)<br>\nFor some reason, I can\u2019t log images of the train, validation, and their ground truth and predictions during training.<br>\nDid someone do it and can give me a good tip for that?<br>\nThanks,<br>\nZiv</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-28T22:28:12.920Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/zivpumba\">@zivpumba</a>, could you send me a link to the run in the UI?</p>\n<p>Also, after you run:</p>\n<pre><code class=\"lang-auto\">config_file = 'mmdetection/configs/path/to/config.py'\ncfg = Config.fromfile(config_file)\n</code></pre>\n<p>can you verify that:</p>\n<pre><code class=\"lang-auto\">cfg.log_config.hooks\n</code></pre>\n<p>Returns the hooks list correctly?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-01T16:08:40.927Z",
				"Answer_body": "<p>Hi  Nate,<br>\nThis is how my cfg.log_config.hooks looks like:</p>\n<p>[{\u2018type\u2019: \u2018TextLoggerHook\u2019}, {\u2018type\u2019: \u2018MMDetWandbHook\u2019, \u2018init_kwargs\u2019: {\u2018project\u2019: \u2018Cars_Detector\u2019, \u2018entity\u2019: \u2018pumba\u2019, \u2018name\u2019: \u2018exp23\u2019}, \u2018interval\u2019: 10, \u2018log_checkpoint\u2019: True, \u2018log_checkpoint_metadata\u2019: True, \u2018num_eval_images\u2019: 200, \u2018bbox_score_thr\u2019: 0.3}]</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-18T19:13:56.416Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/zivpumba\">@zivpumba</a>, sorry for the delay on this. Could you send me a link to your run? The image table is likely being logged but is available in the Artifacts tab and isn\u2019t getting sent to your workspace by default.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-25T20:11:44.952Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/zivpumba\">@zivpumba</a>, I wanted to follow up on this and see if you still needed help with this? If so, could you send a link to your workspace and I can take a look?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-26T20:12:35.431Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Problems about Error Run when using wandb.agent",
		"Question_link": "https://community.wandb.ai/t/problems-about-error-run-when-using-wandb-agent/3718",
		"Question_created_time": "2023-01-19T08:23:59.129Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 177,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello, I have some problems when reproducing the results using code here: <a href=\"https://github.com/oscarclivio/\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">oscarclivio (Oscar Clivio) \u00b7 GitHub</a> neuralscorematching.<br>\nWhen I run the file: sweep_config.py, I get the error like: ERROR Run ur2vuu27 errored: FileNotFoundError(2, \u2018No such file or directory\u2019)</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/3/3471020e22eb5bc852365c5bbca143f9f7a2dcd5.png\" data-download-href=\"/uploads/short-url/7tUWIrQKbqa3T8bEGfIXUjbnBhb.png?dl=1\" title=\"problem\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/3471020e22eb5bc852365c5bbca143f9f7a2dcd5_2_690x303.png\" alt=\"problem\" data-base62-sha1=\"7tUWIrQKbqa3T8bEGfIXUjbnBhb\" width=\"690\" height=\"303\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/3471020e22eb5bc852365c5bbca143f9f7a2dcd5_2_690x303.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/3471020e22eb5bc852365c5bbca143f9f7a2dcd5_2_1035x454.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/3471020e22eb5bc852365c5bbca143f9f7a2dcd5_2_1380x606.png 2x\" data-dominant-color=\"272728\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">problem</span><span class=\"informations\">1485\u00d7653 64.8 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nI ran the codes via vscode and using one cloud service autodl considering the hardware of my computer.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-19T08:25:06.605Z",
				"Answer_body": "<p>the link is <a href=\"https://github.com/oscarclivio/neuralscorematching\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">GitHub - oscarclivio/neuralscorematching</a>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-19T08:48:20.617Z",
				"Answer_body": "<p>I just want to know whether the reason is that these are not in the same folder.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/4/490ddf198a4dd2a5c1155cbbf693bdbf3c9f8cf1.png\" data-download-href=\"/uploads/short-url/aqgzDL0gF9eXZRQre3J3Q2miVgt.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/490ddf198a4dd2a5c1155cbbf693bdbf3c9f8cf1_2_504x500.png\" alt=\"image\" data-base62-sha1=\"aqgzDL0gF9eXZRQre3J3Q2miVgt\" width=\"504\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/490ddf198a4dd2a5c1155cbbf693bdbf3c9f8cf1_2_504x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/490ddf198a4dd2a5c1155cbbf693bdbf3c9f8cf1_2_756x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/4/490ddf198a4dd2a5c1155cbbf693bdbf3c9f8cf1.png 2x\" data-dominant-color=\"2B292A\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">778\u00d7771 43.4 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-20T10:48:05.903Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/yangby35\">@yangby35</a>, thanks for reporting this! Could you please share with me the debug files under <code>wandb/run_date_time-ur2vuu27/logs</code> and the full trace of the error that raises? As this issue seems to be raising when initializing the run, it could be caused because of a wrong <code>dir</code> argument in <a href=\"https://github.com/oscarclivio/neuralscorematching/blob/37f4c5a4480150e6debf1c7f5b0f9f1b9f4d8816/codes/train.py#L192\" rel=\"noopener nofollow ugc\">this</a> line, could you please check? Regarding the wandb folder, it\u2019s created when initializing a project and we store there all the files created by the project, but it shouldn\u2019t be affecting the execution.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-25T13:42:03.712Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/yangby35\">@yangby35</a>, I just wanted to follow up here!  Would it be possible for you to share with me the debug files under <code>wandb/run_date_time-ur2vuu27/logs</code> and the full trace of the error that raises? As the issue seems to raise when starting the run, it may be caused because of a wrong <code>dir</code> argument in <a href=\"https://github.com/oscarclivio/neuralscorematching/blob/37f4c5a4480150e6debf1c7f5b0f9f1b9f4d8816/codes/train.py#L192\" rel=\"noopener nofollow ugc\">this</a> line, could you please check? Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-26T13:42:32.815Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Logs disappeared from table",
		"Question_link": "https://community.wandb.ai/t/logs-disappeared-from-table/3732",
		"Question_created_time": "2023-01-21T23:31:18.113Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 175,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>The table section of a new project has changed. I usually run experiments where a log a lot of metrics at every epochs (a few hundreds). They still appear in workspace/chart. However the table only show the very very basic options of eachs runs ( State. Notes, User, Tags, Created, Runtime, Sweep). This is annoying given that:</p>\n<ul>\n<li>I don t see the configs of each run.</li>\n<li>I was used to export my final results to CSV from this table section.</li>\n</ul>\n<p>Is it a bug ? or an intentional change in the interface ? Or did I do something wrong ?</p>\n<p>best</p>\n<p>Barthelemy</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-24T21:00:46.627Z",
				"Answer_body": "<p>Hi Barthelemy,</p>\n<p>Could you send me a screenshot of what you are seeing on your side?</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-25T00:56:52.042Z",
				"Answer_body": "<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/8/8013083e2e5774b2c69d83e38212c16056f90391.png\" data-download-href=\"/uploads/short-url/igZTkPoUFCTt0qHYI80PxifIv8l.png?dl=1\" title=\"Screenshot 2023-01-24 9.53.11 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/8013083e2e5774b2c69d83e38212c16056f90391_2_690x392.png\" alt=\"Screenshot 2023-01-24 9.53.11 PM\" data-base62-sha1=\"igZTkPoUFCTt0qHYI80PxifIv8l\" width=\"690\" height=\"392\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/8013083e2e5774b2c69d83e38212c16056f90391_2_690x392.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/8013083e2e5774b2c69d83e38212c16056f90391_2_1035x588.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/8013083e2e5774b2c69d83e38212c16056f90391_2_1380x784.png 2x\" data-dominant-color=\"EBEBEB\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2023-01-24 9.53.11 PM</span><span class=\"informations\">1691\u00d7962 85.8 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nHere is screenshot of what I seeneither the config nor the losses I track appear here whereas they appear in the charts.</p>\n<p>Thank you <a class=\"mention\" href=\"/u/artsiom\">@artsiom</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-30T18:13:01.460Z",
				"Answer_body": "<p>Hi Barthelemy,<br>\nCould you check if all of the info you are looking for can be made visible again in the <code>columns</code> buttons shown in this video?</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-02T20:15:44.313Z",
				"Answer_body": "<p>Hi Barthelemy,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-06T21:51:40.010Z",
				"Answer_body": "<p>Hi Barthelemy, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-26T00:57:39.450Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Log custom metrics for a run outside of the training loop",
		"Question_link": "https://community.wandb.ai/t/log-custom-metrics-for-a-run-outside-of-the-training-loop/3696",
		"Question_created_time": "2023-01-13T12:46:10.984Z",
		"Question_answer_count": 10,
		"Question_score_count": 1,
		"Question_view_count": 230,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi,<br>\nI\u2019m currently working on a self-supervised representation learning project, and to evaluate the quality of my models I train a linear classifier on the outputs of my (frozen) trained encoder and look at the downstream classification accuracy.</p>\n<p>This evaluation procedure is done separately from the training of the encoder, however is there still a way to add the metrics computed during this evaluation phase to the standard metrics I log during the training phase, in the same run panel?</p>\n<p>More generally, can I add metrics to a run that is already finished?</p>\n<p>Thanks a lot!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-13T23:55:34.388Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ari0u\">@ari0u</a>, if I understood your question correctly, you are attempting to plot two separate metrics on a chart from two different runs?</p>\n<p>This can be done by adding a secondary Y metric key in the <code>Data</code>tab of a charts option panel.<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/9/938472e0466c758a383d8da8813a7023d682b9df.png\" alt=\"ChartsDualY\" data-base62-sha1=\"l2ZXpyuWhP3yvh2waBauTKf4eED\" width=\"246\" height=\"131\"></p>\n<p>Please let me know if you have additional questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-16T11:55:14.339Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a>, thanks a lot for your reply! In fact, my problem is a bit different, let me try to describe it better:</p>\n<p>First I have a training phase during which metrics are plot, e.g. loss, etc. Let\u2019s say I have three runs <code>version_0</code>, <code>version_1</code> and <code>version_2</code>. For each metric I therefore have one chart in which there is one curve for each run. For example, I have a panel <code>loss</code> containing 3 curves, one for each of the version</p>\n<p>Then, I have a second phase, during which new metrics are computed, e.g. downstream accuracy. What I\u2019d like to do is therefore to have a new panel in my project called <code>accuracy</code> also with 3 curves, one for <code>version_0</code>, <code>version_1</code> and <code>version_2</code>. Moreover, these metrics should really be added to the same run created during the training phase, so that e.g metrics computed during both phases are displayed together on the params tables, both curves should become invisible if I untick the run, etc.</p>\n<p>However the tricky part here is that I really cannot compute the <code>accuracy</code> on-the-fly during the training phase since it\u2019s self-supervised learning, and if I would just log accuracy afterwards it would create a new run instead of adding the metric to the existing one, which would make things quite unreadable.</p>\n<p>I was therefore wondering if there is a way to somehow \u201creload\u201d a wandb logger for a specific run so that I can add the new metrics to this run even if it\u2019s already finished.</p>\n<p>Hope it\u2019s a bit clearer, thanks a lot!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-19T00:18:59.911Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ari0u\">@ari0u</a> , appreciate your your additional feedback.</p>\n<p>This approach of first logging , <code>loss</code>, to a run, then revisiting/resuming a run to log different metric, <code>accuracy</code>, starting from <strong>step zero</strong> again is not supported. The wandb logging step must be monotonically increasing in each call, otherwise the <code>step</code> value is ignored during your call to <code>log()</code>. Now if you are not interested in logging accuracy at step 0, you <a href=\"https://docs.wandb.ai/guides/track/advanced/resuming#resuming-guidance\">could resume</a> the previously finished run using its un id and log additional metrics to the run. this however is problematic as the new metric is logged starting at the last known/registered step for the run.</p>\n<p>One approach to get around the issue you are running into  is to assign each of the runs to a <a href=\"https://docs.wandb.ai/guides/track/advanced/grouping\">specific group</a>. Example set <code>group = version_0</code> for any runs that logs metrics for this specific version of the model. You could then set grouping in the workspace to help with tracking  the different metrics for each experiment, <a href=\"https://wandb.ai/mohammadbakir/Group-Viz-Test/groups/L2/workspace?workspace=user-mohammadbakir\">see this example workspace</a>.</p>\n<p>Hope this helps and please let us know if you have additional questions.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-01-19T10:20:17.567Z",
				"Answer_body": "<p>Hi,<br>\nThanks again for your help, it\u2019s a bit sad that my issue cannot be solved as is but the workaround you suggested with the groups looks fine.<br>\nDo you have any idea why logging has to be monotonically increasing in W&amp;B? Is there fundamental implementation constraints making it impossible, or is it just not implemented for now and could eventually be supported one day? Should I consider sending a feature request?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-19T11:01:40.267Z",
				"Answer_body": "<p>You can also use the W&amp;B API to update or add metrics to a run after it is finished.</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/guides/track/public-api-guide#update-config-for-an-existing-run\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/c/c74534a2df0c93028c85f5aa85cbe3b185c39893.png\" class=\"site-icon\" width=\"132\" height=\"132\">\n\n      <a href=\"https://docs.wandb.ai/guides/track/public-api-guide#update-config-for-an-existing-run\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/b/bc8da779e3d547476a8cbe7e4bd3888df6f5ad36.png\" class=\"thumbnail onebox-avatar\" width=\"500\" height=\"500\" data-dominant-color=\"FFC924\">\n\n<h3><a href=\"https://docs.wandb.ai/guides/track/public-api-guide#update-config-for-an-existing-run\" target=\"_blank\" rel=\"noopener\">Import &amp; Export Data</a></h3>\n\n  <p>Best practices and common use cases for our public API to export data and update existing runs</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<pre><code class=\"lang-auto\">import wandb\napi = wandb.Api()\n\nrun = api.run(\"&lt;entity&gt;/&lt;project&gt;/&lt;run_id&gt;\")\nrun.config[\"key\"] = updated_value\nrun.update()\n</code></pre>\n<p>You could do this for each of versions you\u2019ve logged to attach your accuracy.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-24T13:03:02.048Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ari0u\">@ari0u</a>, I\u2019m jumping in here as Mohammad is out now. If you\u2019d like to log metrics to a previous step I can create a new feature request for this. Could you please share with me a little bit about your use-case? Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-24T13:31:59.985Z",
				"Answer_body": "<p>Hi,<br>\nThat would be great, yes! My use case is to log so-called \u201cdownstream accuracy\u201d when working on self-supervised representation learning methods. The point of those methods is basically to train a neural network to learn semantic representations of some input data, i.e. map each data sample from a dataset to a vector in a latent space, in an unsupervised way, so without using any labels. The output vector corresponding to an input data is called its representation.</p>\n<p>Then, a common practice to evaluate the quality of the produced representations is to train a linear classifier with these representations as inputs on a supervised classification task. The idea here is that if the original encoder is able to produce semantically relevant representations, then classes are likely to be linearly separable. For example, for images, that would mean that e.g. all dogs from the dataset are mapped to vectors that are close from each other in the latent space, but far from the vectors that represent planes.</p>\n<p>However, because of the self-supervised setting, training the encoder that produces the representations and the linear classifier that learns to separate the classes are two different phases that are run independently, it is really a posteriori evaluation. Therefore to log the values in wandb I would need to be able to add to wandb the <code>downstream accuracy</code> metric after the training and log the values for this metric on past steps.</p>\n<p>In terms of wandb features, what I would require is to be able to use <code>wandb.log(..., step=my_step)</code> even if <code>my_step</code> is a past step. Since I know when I have to log past values, there could be a kwarg in <code>wandb.init</code> like <code>enable_log_past_steps</code>, which can be set to <code>True</code> to enable what I want to do but defaults to <code>False</code> to keep the current behaviour unless stated otherwise.</p>\n<p>Since self-supervised learning is becoming a more and more active field of research, I\u2019m sure that such feature would benefit to many people. Please do not hesitate to tell me if something is unclear in my explanations or if you want more details about the usage.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-24T13:37:33.235Z",
				"Answer_body": "<p>That could be kind a solution, but if I update the config that would mean that downstream accuracy would be a parameter instead of a metric, right? Then I\u2019d lose cool features like logging it for different epochs, or use it for computing parameter importances, etc.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-24T13:55:19.283Z",
				"Answer_body": "<p>Thank you very much <a class=\"mention\" href=\"/u/ari0u\">@ari0u</a>, this is a great feedback and I\u2019ll submit internally. Regarding your last question, this is correct, the accuracy would then be a parameter under the config and not a metric.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-25T13:56:14.491Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Academic email not registered anymore?",
		"Question_link": "https://community.wandb.ai/t/academic-email-not-registered-anymore/3706",
		"Question_created_time": "2023-01-17T12:04:00.347Z",
		"Question_answer_count": 8,
		"Question_score_count": 0,
		"Question_view_count": 113,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey!</p>\n<p>I cannot create an academic team anymore (last year, it worked, but I just deleted the group). In my email settings, there is no academic tag. If I try to upgrade my plan to academic again, I\u2019m forwarded to my project page. Am I missing something here? Thanks <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-18T18:18:32.502Z",
				"Answer_body": "<p>Hey Lukas,</p>\n<p>Can you send me your username and your academic email?</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-19T16:00:57.777Z",
				"Answer_body": "<p>Hey Artsiom, thanks for your reply! I guess I cannot send you a PM? My username is lura and my academic mail lukas.rauch[at]<a href=\"http://uni-kassel.de\" rel=\"noopener nofollow ugc\">uni-kassel.de</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-19T21:56:41.492Z",
				"Answer_body": "<p>I readded your academic domain into our system. Could you check if it works for you now? <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-23T08:48:03.512Z",
				"Answer_body": "<p>Hey, thanks, but unfortunately, no. I still cannot create an academic team or verify my mail <img src=\"https://emoji.discourse-cdn.com/twitter/confused.png?v=12\" title=\":confused:\" class=\"emoji\" alt=\":confused:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-23T23:19:54.104Z",
				"Answer_body": "<p>Could you try one more time? I was told we just changed your status in our database directly <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-24T12:19:15.555Z",
				"Answer_body": "<p>Now it works. Thank you very much <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-29T06:27:11.275Z",
				"Answer_body": "<p>Hi Lukas!</p>\n<p>I\u2019m glad I could help!</p>\n<p>Cheers,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-25T12:19:56.344Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to override existing statistics in plot when resuming from a checkpoint?",
		"Question_link": "https://community.wandb.ai/t/how-to-override-existing-statistics-in-plot-when-resuming-from-a-checkpoint/3737",
		"Question_created_time": "2023-01-23T11:33:23.626Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 54,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello all! I\u2019m trying to set up proper training checkpointing and resuming for my code and thus far I\u2019ve gotten things to work but there is still one thing I am trying to figure out, which is how to get the logs in wandb to get overwritten/replaced after I load a checkpoint.</p>\n<p>For instance, right now in my code if I save a checkpoint at 5000 timesteps, let training run for a few more thousand timesteps, cancel it, and then load and resume training from that 5000 step checkpoint, a training plot will look like this:</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/0/0fd7c64199202e092516ae6671d3a7ffad419c7f.png\" alt=\"image\" data-base62-sha1=\"2g9sjoDhJ11TQUKPD8Ox6R0RONx\" width=\"481\" height=\"393\"></p>\n<p>This is because the built-in Wandb Step value didn\u2019t also reset back to 5k for when I restarted training from the 5k checkpoint, it just kept going. What I would instead like to have happen is that the Step value is synced with when I save the checkpoint so that when I resume, the existing plot is <strong>overridden</strong>, rather than continued. Is it possible to do this? Thanks in advance!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-24T10:59:31.329Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/chulabhaya\">@chulabhaya</a>, thanks for your question! If I\u2019m understanding you properly, you\u2019re resuming your run with <code>wandb.init(id='run_id', resume='allow')</code> and then trying to override <code>losses/alpha_loss</code> with <code>wandb.log({'losses/alpha_loss':value}, step=x)</code> where x is an already logged step? If this is the case this isn\u2019t possible now as when you resume a run you can only log from the latest step (or a higher one). I can create a new feature request for this if you want, just explain me your use-case to share the full context with our Product Team. Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-26T14:01:32.032Z",
				"Answer_body": "<p>Hi Chulabhaya,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-25T10:59:53.798Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Yolov5 creates wandb run with vscode jupyter notebook, but not with same nb in jupyterlab",
		"Question_link": "https://community.wandb.ai/t/yolov5-creates-wandb-run-with-vscode-jupyter-notebook-but-not-with-same-nb-in-jupyterlab/3716",
		"Question_created_time": "2023-01-19T02:28:37.761Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 272,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>When I run the same notebook with the same jupyter kernel (custom conda env) in vscode and in jupyterlab, it only creates a wandb run in vscode, but not in jupyterlab.</p>\n<p>Output in jupyterlab (no output from wandb):</p>\n<pre><code class=\"lang-auto\">Training with yolov5: yolov5_model_size: yolov5s batch size: 8 for 180 epochs\ntrain: weights=yolov5s.pt, cfg=, data=dataset/yolov5_config.yml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=180, batch_size=8, imgsz=1280, rect=True, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\ngithub: up to date with https://github.com/ultralytics/yolov5 \u2705\nYOLOv5 \ud83d\ude80 v7.0-71-gc442a2e Python-3.10.9 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1070 with Max-Q Design, 8120MiB)\n\nhyperparameters: lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\nClearML: run 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 \ud83d\ude80 in ClearML\nComet: run 'pip install comet_ml' to automatically track and visualize YOLOv5 \ud83d\ude80 runs in Comet\nTensorBoard: Start with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\nOverriding model.yaml nc=80 with nc=1\n\n                 from  n    params  module                                  arguments\n</code></pre>\n<p>Output in vscode jupyter notebook (shows output from wandb with link to run):</p>\n<pre><code class=\"lang-auto\">Output exceeds the size limit. Open the full output data in a text editor\nTraining with yolov5: yolov5_model_size: yolov5s batch size: 8 for 180 epochs\nwandb: Currently logged in as: tleyden (eyepi). Use `wandb login --relogin` to force relogin\ntrain: weights=yolov5s.pt, cfg=, data=dataset/yolov5_config.yml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=180, batch_size=8, imgsz=1280, rect=True, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\ngithub: up to date with https://github.com/ultralytics/yolov5 \u2705\nYOLOv5 \ud83d\ude80 v7.0-71-gc442a2e Python-3.10.9 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce GTX 1070 with Max-Q Design, 8120MiB)\n\nhyperparameters: lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\nClearML: run 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 \ud83d\ude80 in ClearML\nComet: run 'pip install comet_ml' to automatically track and visualize YOLOv5 \ud83d\ude80 runs in Comet\nTensorBoard: Start with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\nwandb: Tracking run with wandb version 0.13.9\nwandb: Run data is saved locally in /home/tleyden/Development/seal-face-detection/wandb/run-20230118_182447-02ee6gxj\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run kind-meadow-202\nwandb: \u2b50\ufe0f View project at https://wandb.ai/&lt;projectname&gt;/train\nwandb: \ud83d\ude80 View run at https://wandb.ai/&lt;projectname&gt;/train/runs/02ee6gxj\nOverriding model.yaml nc=80 with nc=1\n\n                 from  n    params  module                                  arguments         \n</code></pre>\n<p>Is there anything I can try in jupyterlab to get it to work?  If needed, I don\u2019t mind running it only in jupyterlab if it\u2019s not possible to switch back and forth between the two editing environments.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-23T17:57:12.358Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tleyden\">@tleyden</a> ! I can help look into this for you. Could you share what version of W&amp;B you are currently using and the <code>debug.log</code> and <code>debug-internal.log</code> files associated with  the runs you have linked here? They should be present in a folder called <code>wandb</code> in your working directory.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-26T21:07:05.198Z",
				"Answer_body": "<p>Hi <span class=\"mention\">@tleyen</span>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-28T11:43:10.013Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tleyden\">@tleyden</a>,</p>\n<p>We hope you were able to resolve your issue. If you have any further questions or concerns, please don\u2019t hesitate to reach out. Otherwise, we will be closing this support thread. Have a great day!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-24T17:57:51.335Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to log two variables at different increments of timesteps?",
		"Question_link": "https://community.wandb.ai/t/how-to-log-two-variables-at-different-increments-of-timesteps/3674",
		"Question_created_time": "2023-01-10T14:49:39.466Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 134,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi there! I was wondering, how do I deal with having multiple variables to log, but one of those variables I only want to log every 100 timesteps? The wandb docs seem to suggest that I need to collect all my metrics into one log function call, but in my scenario above where I want to track one variable every step and another variable every 100 steps, I would need multiple log calls. I saw the docs for the define metrics function, but I\u2019m not quite sure if that\u2019s the way to handle this. How do I approach this in PyTorch? Thanks!</p>\n<p>As an example, I currently have this Tensorboard logging that I\u2019m trying to convert to wandb:</p>\n<pre><code class=\"lang-auto\">print(f\"global_step={global_step}, episodic_return={info['episode']['r']}\")\nwriter.add_scalar(\"charts/episodic_return\", info[\"episode\"][\"r\"], global_step)\n\nif global_step % 100 == 0:\n    writer.add_scalar(\n        \"losses/qf1_values\", qf1_a_values.mean().item(), global_step\n    )\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-13T00:29:00.549Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/chulabhaya\">@chulabhaya</a> , happy to help. The approach you are considering is correct. You can set a check in place and log a dictionary with the values you want and set the step value.</p>\n<pre><code class=\"lang-auto\">for i in range (300):\n    if i%100==0:\n        wandb.log({\"value\": i, \"value\": 100}, step =i)\n    else:\n        wandb.log({\"value\": 100})\n</code></pre>\n<p>The <a href=\"https://docs.wandb.ai/guides/track/log#customize-axes-and-summaries-with-define_metric\">defined metric</a> function allows you to have more control over the representation of your x axis and also how that axes is incremented. There are a few examples listed in the linked doc on how it functions. Please let me know if you have any questions.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-01-23T11:22:11.010Z",
				"Answer_body": "<p>Thanks so much for confirming my approach! Much appreciated</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-24T11:22:25.678Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Artifact download link",
		"Question_link": "https://community.wandb.ai/t/artifact-download-link/3676",
		"Question_created_time": "2023-01-10T16:06:30.878Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 194,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello everyone,</p>\n<p>In <a href=\"http://wandb.ai\">wandb.ai</a> for every created project, there is an Artifacts page. There we have a toolbar with the options: \u201cOverview\u201d, \u201cMetadata\u201d, \u201cUsage\u201d, \u201cFiles\u201d and \u201cLineage\u201d. In the Files section, there are downloadable links for every file that make part of a given artifact.<br>\nIs it possible to get through wandb package this downloadable Artifact URL link?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-11T13:56:10.347Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/wnk\">@wnk</a>, thanks for your question! This is absolutely possible by using our Public API, check <a href=\"https://docs.wandb.ai/ref/python/public-api/artifact#get_path\">here</a> the method to get this link.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-11T14:28:03.615Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/luis_bergua1\">@luis_bergua1</a>, thanks for your reply.<br>\nInstead of using a method like \u201cpath.download()\u201d (as it\u2019s described in the link), I would like to have access to the S3 path where the artifact (or file from the artifact) is stored. With this link, I could share it and download the file directly.<br>\nDo you know if such is feasible?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-20T19:17:57.648Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/wnk\">@wnk</a>, sorry for the delay here! You should be able to get the link with <code>artifact.get_path(file).ref</code>. Could you please check if this works for you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-26T11:04:20.302Z",
				"Answer_body": "<p>Hi Wilson,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-21T19:18:13.451Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Changing files after starting a long sweep",
		"Question_link": "https://community.wandb.ai/t/changing-files-after-starting-a-long-sweep/3727",
		"Question_created_time": "2023-01-20T18:35:33.147Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 152,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey,</p>\n<p>I think it\u2019s okay, but I just want to make sure. Say that I start a long hyperparameter sweep with many options, is it okay to change the code files after the sweep has started? or it might break something?</p>\n<p>Thanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-21T00:44:37.447Z",
				"Answer_body": "<p>Hi Yonatan, are you trying to change the file names on your local machine? Can you tell me the use case of doing this?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-26T19:59:44.431Z",
				"Answer_body": "<p>Hi Yonatan, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-21T18:35:34.512Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Page scrolls when moving panels in the web UI",
		"Question_link": "https://community.wandb.ai/t/page-scrolls-when-moving-panels-in-the-web-ui/3672",
		"Question_created_time": "2023-01-10T14:45:04.230Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 128,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello !</p>\n<p>When dragging panels within sections or from one section to another, the webpage scrolls back to the top. This makes it impossible to move panels around.</p>\n<p>Can this bug be fixed?<br>\nThank you.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-11T13:38:00.099Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/bdevillers\">@bdevillers</a>, thanks for writing in! I just tried and it seems that I can move panels across sections without any issue, would you mind sharing a link to the Workspace where this is happening and also a video showing this? Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-11T14:48:02.894Z",
				"Answer_body": "<p>Hi and thank you for your reply!<br>\nThis is on a private project. But here is a GIF of this issue.<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/b/b6626daffe110a891586f561f1a0fab9e314ab7a.gif\" alt=\"scroll_when_moving_bug\" data-base62-sha1=\"q1rMsCsIXnpVJpCS5KsONT7JBmG\" width=\"640\" height=\"356\" class=\"animated\"></p>\n<p>However, I think this is a Firefox-related bug, as it seems that this does not happen in Chrome.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-20T18:13:31.498Z",
				"Answer_body": "<p>Thanks for sharing this <a class=\"mention\" href=\"/u/bdevillers\">@bdevillers</a>! I just checked and I\u2019m getting the same behaviour in Firefox so I\u2019ll report it as a bug!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-21T18:14:25.868Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to filter out sweep runs from UI",
		"Question_link": "https://community.wandb.ai/t/how-to-filter-out-sweep-runs-from-ui/3725",
		"Question_created_time": "2023-01-20T07:58:45.952Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 170,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I run several experiments, both singularly and using sweeps. Now I want to look at the results from the UI and I want to filter out runs that came from a sweep.</p>\n<p>I tried to filter out by name, but I can\u2019t get it to work. I manage to match all the sweep runs with the regex <code>.*sweep*</code>, but I don\u2019t know how to get the opposite. Any suggestion would be much appreciated, thanks! <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-20T11:28:55.865Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lclissa\">@lclissa</a> thanks for your question! You can go to the runs Table view and then perform the following actions: <code>Filter</code> &gt; <code>Add Filter</code> &gt; <code>Sweeps in \"&lt;null&gt;\"</code> as in the attached screenshot below.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/e/ef99184af5047a63dcc478a1480f31d9bcebc6ce.png\" data-download-href=\"/uploads/short-url/ybA7qg4vIknsHb3jlIldWMRDplY.png?dl=1\" title=\"Screenshot 2023-01-20 at 11.25.10\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ef99184af5047a63dcc478a1480f31d9bcebc6ce_2_690x244.png\" alt=\"Screenshot 2023-01-20 at 11.25.10\" data-base62-sha1=\"ybA7qg4vIknsHb3jlIldWMRDplY\" width=\"690\" height=\"244\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ef99184af5047a63dcc478a1480f31d9bcebc6ce_2_690x244.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ef99184af5047a63dcc478a1480f31d9bcebc6ce_2_1035x366.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ef99184af5047a63dcc478a1480f31d9bcebc6ce_2_1380x488.png 2x\" data-dominant-color=\"262728\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2023-01-20 at 11.25.10</span><span class=\"informations\">1836\u00d7651 72.5 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>In this way you will end up with the runs that weren\u2019t part of the Sweeps. Would this work for you?</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-01-20T11:43:54.817Z",
				"Answer_body": "<p>Great, in fact that\u2019s much easier than playing with regexps. Thanks a lot <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-20T11:55:52.990Z",
				"Answer_body": "<p>Glad to hear this worked for you <a class=\"mention\" href=\"/u/lclissa\">@lclissa</a> ! I will close this ticket for now, and please reach out to us again if you have any further questions. Have a great weekend!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-21T11:56:15.457Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Is it possible to continue training with additional epochs? Also where can I find logs in local?",
		"Question_link": "https://community.wandb.ai/t/is-it-possible-to-continue-training-with-additional-epochs-also-where-can-i-find-logs-in-local/3667",
		"Question_created_time": "2023-01-10T13:08:13.482Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 158,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Dear wandb team,</p>\n<p>I currently start using pytorch-lightning combining with wandb, so I will use WandbLogger. (Due to link limits, I didn\u2019t put url for the documentation.)</p>\n<p>Suppose I had trained a model, let\u2019s say for 10 epochs. The <em>project</em> is <strong>wandb_toy</strong>,  and the <em>name or ID</em> is <strong>toy</strong>. After training, it will automatically create two folders under <code>./</code>, i.e., <code>./wandb</code> and <code>./wandb_toy</code>. I know that the checkpoints will be saved in <code>wandb_toy/toy/checkpoints</code>. Also there will be a new run folder in <code>./wandb</code>, let\u2019s say <code>./wandb/run-20230101_102000</code>.</p>\n<p>Now if I want to continue the training from <em>epochs=10</em> to <em>epochs=20</em>, I know I can load the model state with adding <em>ckpt_path</em> during <em>trainer.fit()</em>, also update the config with <em>allow_val_change</em> setting to <em>True</em>. However, there is still a new additional run folder created, e.g., <code>./wandb/run-20230202_104000</code>.</p>\n<hr>\n<p><strong>My questions are:</strong></p>\n<ul>\n<li>I want to keep saving or update things in the original run folder <code>./wandb/run-20230101_102000</code>.</li>\n<li>Also is there any way to name the run folder, for example, change  <code>./wandb/run-20230101_102000</code> to  <code>./wandb/my_toy_run</code>. I have tried keywords like <em>dir</em> or <em>save_dir</em> already, but seems not right.</li>\n<li>If I delete the project in wandb ai (without delete folders in <code>./wandb</code>), then continue training from <em>epoch=10</em> to <em>epoch=20</em>, It will log only from epoch=10~20. Is there any way to still get the previous log from epoch=0~10? I have tried to look up <a href=\"https://docs.wandb.ai/guides/track/advanced/save-restore#examples-of-wandb.restore\"> Save &amp; Restore Files</a> or <a href=\"https://docs.wandb.ai/guides/track/advanced/resuming\">Resume Runs</a>, but unfortunately I couldn\u2019t figure it out.</li>\n<li>If I want to see each epochs log (e.g., accuracy and loss) in  my local, which file should I look for?</li>\n</ul>\n<p>Thanks for reading and I apologize if I couldn\u2019t make things clear.</p>\n<p>Best wishes,<br>\nYian</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-11T14:23:51.279Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ntuyianchen\">@ntuyianchen</a>, thanks for writing in and for sharing this detailed explanation of your use-case! Answering your questions:</p>\n<ul>\n<li>This is not possible at the moment as every time you resume a run a new folder is created <code>run-date_time</code> (this name is not mutable either other than manually) although the run is the same. This is useful to be able to track easily the different processes.</li>\n<li>You cannot resume a run at a previous step, it will only be resumed from the last step. The intention of this is to avoid overwritting previous logged data.</li>\n<li>Log metrics are not saved locally (other than the last epoch in <code>files/wandb-metadata.json</code>), but they are accesible through our public API by accesing <code>run.history()</code>. <a href=\"https://docs.wandb.ai/ref/python/public-api/run#history\">Here</a> you can have a look at the documentation on how to do this.</li>\n</ul>\n<p>Please let me know if these answers would be useful. Also, if you would like to have any of these features available, feel free to explain which ones and I will create a new request!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-11T17:18:22.250Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/luis_bergua1\">@luis_bergua1</a> , thanks for the concrete reply! It\u2019s really helpful and now I can understand why and how wandb designed this way. The <code>run.history()</code> is really the thing I was looking for, thank you very much!</p>\n<p>Thanks to wandb team for making this awesome package and documentations. I have one thing that\u2019s irrelevant to our discussion. I found that <strong>the text format seemed to be wrong</strong> at <a href=\"https://docs.wandb.ai/ref/python/public-api/run?_gl=1*1culllr*_ga*MTkwNzMzMTI4LjE2NzI0NzI2OTM.*_ga_JH1SJHJQXJ*MTY3MzQ1NTQ2OS40OC4xLjE2NzM0NTY1MTYuNDkuMC4w#history\">here</a> (the table for <code>Arguments</code> and <code>Returns</code> don\u2019t break new lines correctly in my Mac Safari, which makes it a little hard to read.) This  is not really an immediate big deal and I think it can be fixed in the future some day <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"> .</p>\n<p>Cheers!</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/5/56624e0424bcaa43a1d179393b9d14a71de4878f.png\" data-download-href=\"/uploads/short-url/ckbG7FMxBS7IwaZs55NAnQ9Y8PB.png?dl=1\" title=\"\u622a\u5716 2023-01-12 \u4e0a\u53481.15.42\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/56624e0424bcaa43a1d179393b9d14a71de4878f_2_581x499.png\" alt=\"\u622a\u5716 2023-01-12 \u4e0a\u53481.15.42\" data-base62-sha1=\"ckbG7FMxBS7IwaZs55NAnQ9Y8PB\" width=\"581\" height=\"499\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/56624e0424bcaa43a1d179393b9d14a71de4878f_2_581x499.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/56624e0424bcaa43a1d179393b9d14a71de4878f_2_871x748.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/56624e0424bcaa43a1d179393b9d14a71de4878f_2_1162x998.png 2x\" data-dominant-color=\"F7F8F9\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">\u622a\u5716 2023-01-12 \u4e0a\u53481.15.42</span><span class=\"informations\">1550\u00d71332 208 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-13T15:16:55.454Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ntuyianchen\">@ntuyianchen</a>, great to see that <code>run.history()</code> works for you! Thank you very much for the kind feedback, we really appreciate it! Regarding the table in the docs, I am not fully understanding you, would you like to have a different align foe the text/have it justified?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-15T15:16:44.781Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/luis_bergua1\">@luis_bergua1</a> , sorry for my ambiguous feedback. I was expecting that the argument should be something like</p>\n<blockquote>\n<p>samples (int, optional): The number \u2026<br>\npandas (bool, optional): Return \u2026<br>\nkeys (list optional): Only return \u2026</p>\n</blockquote>\n<p>Since without line-breaking, it\u2019s quite hard to find the argument at first sight.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-19T12:02:57.186Z",
				"Answer_body": "<p>Thanks a lot for clarifying <a class=\"mention\" href=\"/u/ntuyianchen\">@ntuyianchen</a>! I see the issue now, I\u2019ll report it!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-20T12:03:28.715Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Waiting for wandb.init",
		"Question_link": "https://community.wandb.ai/t/waiting-for-wandb-init/3658",
		"Question_created_time": "2023-01-09T18:43:24.453Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 649,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, the code ran 3 days agoand it worked, but after I changed some variables and it failed with: \u201cwandb: W&amp;B API key is configured. Use <code>wandb login --relogin</code> to force relogin wandb: - Waiting for wandb.init()\u2026wandb: \\ Waiting for wandb.init()\u2026wandb: | Waiting for wandb.init()\u2026wandb: / Waiting for wandb.init()\u2026wandb: - Waiting for wandb.init()\u2026Traceback (most recent call last):\u201d. Now after I changed it back the error persists.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-10T00:26:11.354Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/gammill-chance\">@gammill-chance</a> , happy to help. Could you  expand a bit on your experiment setup and which arguments are you setting in <code>wandb.init()</code>, additionally:</p>\n<ul>\n<li>Does the output of <code>wandb status</code> correspond correctly to the <code>entity</code>,<code> host_url</code>, and is the api key set there correctly?</li>\n<li>Try deleting the <code>~/.netrc</code>file that stored your wandb login info and api key and relogin</li>\n<li>Uninstall/reinstall wandb</li>\n</ul>\n<p>If the above doesn\u2019t work please provide the <code>debug.log</code> and <code>debug-internal.log</code> files for the failing runs located in the wandb folder of your project directory and we will take a closer look.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-10T16:09:54.716Z",
				"Answer_body": "<p>I am new to the Wandb coding, but for the init it is as follows,<br>\nwandb.init (project=\u2018U-Net\u2019,entity= \u2018gammill-chance\u2019, resume=\u2018allow\u2019,  anonymous=\u2018allow\u2019, name= \u2018check_8\u2019).<br>\nI will add that when logging in to wandb in the command console the command wandb login key, has not been working, so instead I used wandb.login(). Additionally I did not know about wandb status and I decided to run the neural network without wandb for the time being, so I can respond to that hopefully on Friday. After that I will try what you suggested and I will get back to you when I know if it works. Thank you!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-18T20:05:10.461Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/gammill-chance\">@gammill-chance</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-19T20:05:14.468Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Alpha channel of standard deviation",
		"Question_link": "https://community.wandb.ai/t/alpha-channel-of-standard-deviation/3681",
		"Question_created_time": "2023-01-11T14:04:08.149Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 138,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,<br>\ncan I change the alpha channel for an area of standard deviation around the line chart? Now it\u2019s not contrasting for me. I cannot recognise well the background and generated an area of stddev. Thanks a lot.<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/3/32a3a3152fa5af0639ab0307252f741fd6e98d66.jpeg\" alt=\"image\" data-base62-sha1=\"7dYsME5bMAybvxWbkjJ2F0gbUHQ\" width=\"482\" height=\"253\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-11T23:11:18.905Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/markub\">@markub</a> , happy to help. At this time you cannot directly change the color of just the alpha channel to different color. The option available to a user to to change the color of grouped line via legends which will also change the color of the alpha value to match.  Please let me know if you have any questions.</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/d19d32456f7af7168bd3dd4d6d4c70e0df06598f.png\" alt=\"Legend\" data-base62-sha1=\"tUkA92Eozfc53gRYCCn9ZTL77Vd\" width=\"335\" height=\"354\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-13T17:12:28.172Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> ,<br>\nThis is not solution for me. You change by this alpha value whole line. I need change only alpha channel of the area around line \u2026 This area represents a standard deviation. On the image you can see it hasn\u2019t desired effect\u2026</p>\n<p>Thanks for understanding my problem.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/9/92861a8493d08520e3ef1456f04e53fee06ce173.jpeg\" data-download-href=\"/uploads/short-url/kUd1D4cyp7KJZTF6mLrIVEZ9e1R.jpeg?dl=1\" title=\"Sni\u0301mka obrazovky 2023-01-13 o 18.11.51\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/9/92861a8493d08520e3ef1456f04e53fee06ce173_2_690x256.jpeg\" alt=\"Sni\u0301mka obrazovky 2023-01-13 o 18.11.51\" data-base62-sha1=\"kUd1D4cyp7KJZTF6mLrIVEZ9e1R\" width=\"690\" height=\"256\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/9/92861a8493d08520e3ef1456f04e53fee06ce173_2_690x256.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/9/92861a8493d08520e3ef1456f04e53fee06ce173_2_1035x384.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/9/92861a8493d08520e3ef1456f04e53fee06ce173_2_1380x512.jpeg 2x\" data-dominant-color=\"292A28\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Sni\u0301mka obrazovky 2023-01-13 o 18.11.51</span><span class=\"informations\">2746\u00d71020 158 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-18T00:46:54.608Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/markub\">@markub</a>, I completely understand how it is beneficial to modify the individual colors. I put in a feature request for this for our app team to review. Once a decision is made, I\u2019ll be sure to let you know. In the meantime, do let me know if there is anything else we could assist you with.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-19T00:47:50.644Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Resume run not working for sweep run",
		"Question_link": "https://community.wandb.ai/t/resume-run-not-working-for-sweep-run/3690",
		"Question_created_time": "2023-01-12T17:47:46.357Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 349,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am looking to resume some runs that crashed due to a timeout on a slurm cluster. I am doing this by supplying <code>wandb.init</code> with <code>id=run_id</code> and <code>resume=\"must\"</code>, however it is unable to resume as it seemingly is not finding the run or something like that.</p>\n<p>My resume code is as follows:</p>\n<pre data-code-wrap=\"py\"><code class=\"lang-plaintext\">            init_args = {}\n            if args.run_id is not None:\n                init_args['id'] = args.run_id\n                init_args['resume'] = 'must'\n                init_args['project'] = wandb_project\n            with wandb.init(**init_args):\n                # training code here (including loading the checkpoint in the case of resume)\n</code></pre>\n<p>When I run this it logs the following:</p>\n<pre><code class=\"lang-auto\">wandb: Sweep Agent: Waiting for job.\nwandb: Sweep Agent: Exiting.\n</code></pre>\n<p>and then sets the online Sweep State to finished. I am doing a grid search, and every parameter combination has a run associated with it, however some crashed due to the timeout. I am passing the IDs for these runs to my program (i.e. args.run_id contains the run ID of a crashed run), yet this happens.</p>\n<p>Is there anything I am missing?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-13T11:49:39.164Z",
				"Answer_body": "<p>To provide some more context, I am starting a wandb agent with the correct sweep_id and passing it the function that contains the code I put in my post above</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-15T16:37:57.508Z",
				"Answer_body": "<p>I just read this:</p>\n<blockquote>\n<p>Note that resuming a run which was executed as part of a Sweep is not supported.</p>\n</blockquote>\n<p>on this page <a href=\"https://docs.wandb.ai/guides/track/advanced/resuming\" class=\"inline-onebox\">Resume Runs - Documentation</a>.</p>\n<p>I suppose my issue is solved now, however  I would definitely like to see this added as this makes it difficult to run sweeps on slurm clusters where processes may time out</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-17T21:14:32.812Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/timvandamcs\">@timvandamcs</a></p>\n<p>Thank you for writing in with your question. The statement above is correct, you cannot resume runs that were part of a sweep. To re run a specific configuration of a sweep, wait till the sweep runs to completion. Then delete the runs that failed from the run tables. Resume the sweep and run a sweep agent with the existing sweep id. The failed runs will re-execute.</p>\n<p>I will add your notes on resuming runs of a sweep as a feature request with our product team.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-18T21:15:04.424Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Is it possible to log confidence intervals?",
		"Question_link": "https://community.wandb.ai/t/is-it-possible-to-log-confidence-intervals/3684",
		"Question_created_time": "2023-01-11T17:59:27.645Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 205,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I log model scores by steps and at every step I have metric value, confidence interval lower bound, confidence interval upper bound. Is it possible to log confidence intervals (on one graph) and show the confidence interval using different color?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-11T23:11:39.794Z",
				"Answer_body": "<p>Hi Denis, thank you for writing in! To make sure of what you are trying to do, are you trying to change the color of your lower bound and upper bound confidence intervals that are on the same chart with your metric value? Did you log these values in different runs? If so, you can do this by changing the color of the run itself, by clicking on the color of the circle next to the run name where a palette would appear to change the color. If there is something I\u2019m misunderstanding or that is different in your workflow, please let me know so I can help you further <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-17T15:26:59.646Z",
				"Answer_body": "<p>Sorry for a long response. I want something like this.<br>\nFor example, on every step (1, 2, 3\u2026) I log metric value, lower confidence bound and upper confidence bound. After that, I get the following chart. It is one run.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/5/565bc297d39dd0c1ec62c03fecc0df6d645cae69.jpeg\" data-download-href=\"/uploads/short-url/cjXELVkXqYKoiCoqlRxDvhL6qFP.jpeg?dl=1\" title=\"telegram-cloud-photo-size-2-5330127923157517744-y\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/565bc297d39dd0c1ec62c03fecc0df6d645cae69_2_690x463.jpeg\" alt=\"telegram-cloud-photo-size-2-5330127923157517744-y\" data-base62-sha1=\"cjXELVkXqYKoiCoqlRxDvhL6qFP\" width=\"690\" height=\"463\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/565bc297d39dd0c1ec62c03fecc0df6d645cae69_2_690x463.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/5/565bc297d39dd0c1ec62c03fecc0df6d645cae69.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/5/565bc297d39dd0c1ec62c03fecc0df6d645cae69.jpeg 2x\" data-dominant-color=\"F6F8FA\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">telegram-cloud-photo-size-2-5330127923157517744-y</span><span class=\"informations\">808\u00d7543 15.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-18T07:44:32.136Z",
				"Answer_body": "<p>Thank you so much for the example! This helps a whole lot. Currently this isn\u2019t a feature we have in our product, but I\u2019ll create a feature request for this and our team will reach out to you once there are any updates on this ticket.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2023-03-18T15:27:41.544Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Runs table expand view",
		"Question_link": "https://community.wandb.ai/t/runs-table-expand-view/3633",
		"Question_created_time": "2023-01-04T00:48:13.930Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 173,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>When I access to Runs Table, I found myself expanding the Runs table every single time.<br>\nIs there a way to set the expanded Runs table as default?</p>\n<p>Thank you.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-04T14:19:12.937Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lucaseo\">@lucaseo</a>, thanks for writing in! By default, when you access W&amp;B you\u2019ll go to yout Workspace. If you want to see the Runs Table, you have two options, expand it or click on the table icon:<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/5/5ca0ee1f678034a07b6c482fc51dfb45231563c4.png\" alt=\"Screenshot 2023-01-04 at 15.16.55\" data-base62-sha1=\"ddqIyc8ms5kfyToNUAXCkXGe7R2\" width=\"242\" height=\"447\"><br>\nIf I\u2019m understanding you properly, you\u2019d like to be able to select the default init page in the UI?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-09T16:05:04.851Z",
				"Answer_body": "<p>Hi lucaseo,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-12T10:37:20.790Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lucaseo\">@lucaseo</a>, could you please confirm me if the desired behaviour if being able to configure the default init page in the UI? If this is the case, would you mind sharing with me some more information on why you consider this useful?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-17T09:08:04.020Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/luis_bergua1\">@luis_bergua1</a> .</p>\n<p>I apologize for the late reply, and really appreciate commitment on improving W&amp;B.</p>\n<p>Yes, the desired behavior being able to set either Workspace or rRuns Table as default UI .<br>\nBoth shows Runs on the left, however I find it useful to keep track of my experiment by table and make decisions on the filtered columns that I prefer.<br>\nWhen I  click the project name, the default shows Workspace with charts. But if I can directly get access to Runs table (since I view the table much more frequently) that would be very neat.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-18T09:08:27.387Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Images are not saved/logged",
		"Question_link": "https://community.wandb.ai/t/images-are-not-saved-logged/3697",
		"Question_created_time": "2023-01-13T20:51:05.557Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 150,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi all,</p>\n<p>I am using pytorch_lightning.loggers.WandbLogger to log some intermediate results of my preprocessing but nothing (i.e. plots and images) are logged, except the key name.</p>\n<p>Below is what I did:</p>\n<pre><code class=\"lang-auto\">wandb_logger = WandbLogger(..)\nrunner = Trainer(logger=wandb_logger,..)\ndata = VAEDataset(.., logger=runner.logger,..) # LightningDataModule\ndata.setup()\n\n# in Dataset (in some preprocessing steps)\nplt.figure(figsize=(10, 30))\nplt.subplot(131), plt.imshow(orig_spec.detach(), cmap='gray')\nplt.title('Input'), plt.xticks([]), plt.yticks([])\nplt.subplot(132), plt.imshow(filtered_spec.squeeze().detach(), cmap='gray')\nplt.title('FilteredSpec'), plt.xticks([]), plt.yticks([])\nplt.subplot(133), plt.imshow(magnitude_spec.detach(), cmap='gray')\nplt.title('MagnitudeSpec'), plt.xticks([]), plt.yticks([])\nself.logger.experiment.log(\n        {\"HPFilter/Input_Filtered-_Magnitude-Spec\": plt}\n        )\n\n# alternatively, I used wandb directly\nwandb.log(\n            {\"HPFilter/FilteredSpec\": wandb.Image(torch.flipud(filtered_spec).detach(), caption=\"FilteredSpec.png\")}\n        )\n</code></pre>\n<p>Both gave such empty panels:.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/dd9cebdf46b068c21edbdbee92b5ec0fb5d8b9ac.png\" data-download-href=\"/uploads/short-url/vCtIR0dL0KQ5J70c9oMVxBaaXq4.png?dl=1\" title=\"wandb\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/dd9cebdf46b068c21edbdbee92b5ec0fb5d8b9ac_2_690x229.png\" alt=\"wandb\" data-base62-sha1=\"vCtIR0dL0KQ5J70c9oMVxBaaXq4\" width=\"690\" height=\"229\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/dd9cebdf46b068c21edbdbee92b5ec0fb5d8b9ac_2_690x229.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/dd9cebdf46b068c21edbdbee92b5ec0fb5d8b9ac_2_1035x343.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/dd9cebdf46b068c21edbdbee92b5ec0fb5d8b9ac.png 2x\" data-dominant-color=\"FDFDFD\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">wandb</span><span class=\"informations\">1171\u00d7389 13.8 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>There is no subdir called \u201cHPFilter\u201d under \u201cmedia\u201d but when I checked <code>wandb-summary.json</code>:</p>\n<pre><code class=\"lang-auto\">..., \"HPFilter/FilteredSpec\": {\"_type\": \"image-file\", \"sha256\": \"92bd05772ad44d6be9ef9fed80df00ff649e378abbcbb34f73d4082aceacedb0\", \"size\": 86404, \"path\": \"media/images/HPFilter/FilteredSpec_2_92bd05772ad44d6be9ef.png\", \"format\": \"png\", \"width\": 128, \"height\": 256, \"caption\": \"FilteredSpec_33150.png\"}, ...\n</code></pre>\n<p><strong>Added:</strong><br>\nTo eliminate that the problem lies in my actual data, I tried the below to replace my intended logging:</p>\n<pre><code class=\"lang-auto\">    arr = torch.rand(256, 128)\n    wandb.log(\n            {\"HPFilter/FilteredSpec\": wandb.Image(torch.flipud(arr).detach().cpu().numpy(), caption=f\"FilteredSpec.png\")}\n        )\n</code></pre>\n<p>It still behaved the same.</p>\n<p>Many thanks in advance for any hints!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-16T08:57:22.499Z",
				"Answer_body": "<p>Hi,</p>\n<p>I solved this problem over the weekend.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-17T08:57:38.382Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to stop weights & biases (wandb) from creating random tmp files?",
		"Question_link": "https://community.wandb.ai/t/how-to-stop-weights-biases-wandb-from-creating-random-tmp-files/3460",
		"Question_created_time": "2022-11-24T22:13:29.419Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 623,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have a million tmp files due to wandb on my home folder. I don\u2019t know why. Why are they being created &amp; how do I stop it?</p>\n<pre><code class=\"lang-auto\">anaconda\t\t\t\t\t   tmpa0wf77f_wandb-artifacts  tmpmv2ewoi1wandb-media\nanaconda.sh\t\t\t\t\t   tmpa3t655lewandb-media      tmpmvhp3i6ewandb-media\ndata\t\t\t\t\t\t   tmpa6roiz80wandb\t       tmpmwszwea4\ndebug-cli.brando9.log\t\t\t\t   tmpal7kticfwandb-artifacts  tmpn0p49w1hwandb-media\ndiversity-for-predictive-success-of-meta-learning  tmpalsnd4g1wandb-media      tmpnbxtnojbwandb-artifacts\ndiv_install_miniconda\t\t\t\t   tmpambb3rm9wandb-artifacts  tmpngpy96dawandb-artifacts\ndiv_install.out\t\t\t\t\t   tmpapco0xetwandb-media      tmpnqezeggnwandb-media\niit-term-synthesis\t\t\t\t   tmpaqf80v_hwandb-media      tmpo3cug5nzwandb-media\nmain.sh.e449240\t\t\t\t\t   tmpaqigpze6wandb-artifacts  tmpoc4x6l22wandb\nmain.sh.e457075\t\t\t\t\t   tmpaw1kvgtgwandb-media      tmpofql583uwandb-media\nmain.sh.e760266\t\t\t\t\t   tmpay63rbxgwandb-media      tmponqiggzswandb-artifacts\nmain.sh.err748250\t\t\t\t   tmpb2clycf5\t\t       tmpoqem6uclwandb-media\nmain.sh.err849450\t\t\t\t   tmpbbrfn_kmwandb-artifacts  tmpoqth0mgpwandb-media\nmain.sh.err923818\t\t\t\t   tmpbcxatqdiwandb-artifacts  tmppbd5bfm_wandb\nmain.sh.err962904\t\t\t\t   tmpbgewkz10wandb\t       tmppbnpm41gwandb-media\nmain.sh.o449240\t\t\t\t\t   tmpbsd96o99wandb-media      tmppwxmebn1\nmain.sh.o457075\t\t\t\t\t   tmpbtlp8zomwandb\t       tmpq396kfo1wandb-artifacts\nmain.sh.o748250\t\t\t\t\t   tmpby3a9u8ywandb\t       tmpq8jryat0wandb-media\nmain.sh.o760266\t\t\t\t\t   tmpc45e2nlxwandb-media      tmpqc65bfs0wandb\nmain.sh.o849450\t\t\t\t\t   tmpc4m5b21_\t\t       tmpqexdhp6gwandb-artifacts\nmain.sh.o923818\t\t\t\t\t   tmpcap20jmdwandb-media      tmpqh3uu7v2wandb-media\nmain.sh.o950686\t\t\t\t\t   tmpcl2sb6j_wandb\t       tmpqh99a72vwandb-media\nmain.sh.o962904\t\t\t\t\t   tmpcsncx8x4wandb-media      tmpqmim4sxywandb\nminiconda\t\t\t\t\t   tmpd7dhluxmwandb\t       tmpqpfcq9uwwandb\nminiconda.sh\t\t\t\t\t   tmpdbbb3hw_wandb-artifacts  tmpqtds4jdiwandb-artifacts\nnohup.out\t\t\t\t\t   tmpdfrjyk90wandb-media      tmp_qz8pu0xwandb-artifacts\nnohup.out449240\t\t\t\t\t   tmpdhqwaxygwandb\t       tmpr98qj7auwandb\nnohup.out457075\t\t\t\t\t   tmpdpj3bfz0wandb-artifacts  tmprfwooa22wandb-artifacts\nnohup.out760266\t\t\t\t\t   tmpdqzzy7v3\t\t       tmpri9xu8i_wandb-media\npycoq\t\t\t\t\t\t   tmpdr6fbpctwandb\t       tmprj4g0kkhwandb\ntest.py\t\t\t\t\t\t   tmpejwo7axlwandb\t       tmp_rla0cb9wandb-media\ntmp\t\t\t\t\t\t   tmpekqp7b2dwandb-media      tmprmrasn0fwandb-media\ntmp03kmjan0wandb\t\t\t\t   tmpf3pk0_3t\t\t       tmpr_yrhzj_wandb\ntmp07zhon11wandb-media\t\t\t\t   tmpf4w8yhsswandb-media      tmprzxltg0lwandb\ntmp0pkwjwg8wandb\t\t\t\t   tmpf_6vd6hkwandb-media      tmps0beul64wandb-media\ntmp0ypuhnktwandb-media\t\t\t\t   tmpf7vuwlipwandb\t       tmps5qf0_w0wandb\ntmp0zk3_ok1wandb\t\t\t\t   tmpfc8ltujrwandb-media      tmpsp2djjg6wandb-artifacts\ntmp14xa24j_wandb\t\t\t\t   tmpfmcmwgb8\t\t       tmpsqe0vylnwandb\ntmp1f3gqdq1wandb-media\t\t\t\t   tmpfqhl6c9vwandb\t       tmpstniop3twandb-media\ntmp1hmrx3xnwandb\t\t\t\t   tmpfvkvyklpwandb-media      tmpsv3n4fi7wandb-media\ntmp1nxq8dmowandb\t\t\t\t   tmpfxuc2zwjwandb-artifacts  tmp_t3mkuy4\ntmp1r2xah97wandb-media\t\t\t\t   tmpg051c49z\t\t       tmptb0urf26wandb\ntmp1sdb3vnqwandb-media\t\t\t\t   tmpg16e6zpxwandb-media      tmptgq1h308wandb-media\ntmp1wq9i7tmwandb-media\t\t\t\t   tmpg2qfjo5pwandb-artifacts  tmpthtghn1wwandb-media\ntmp27k3evykwandb-artifacts\t\t\t   tmpg34wt2g1wandb-media      tmptkp9qpgxwandb-media\ntmp2ncmg9jmwandb-media\t\t\t\t   tmpggaltim9wandb-media      tmptqn9w7rawandb-artifacts\ntmp2qxmugpjwandb-media\t\t\t\t   tmpgj6gyqw6wandb-media      tmptsqb0lwrwandb\ntmp2w92xlzowandb\t\t\t\t   tmpgpv_1hxk\t\t       tmptub9i1zzwandb-media\ntmp39lds7tywandb-media\t\t\t\t   tmpgswv7jpn\t\t       tmpu0k6cuycwandb-media\ntmp3ncj9tdewandb-artifacts\t\t\t   tmpgvz0_o1h\t\t       tmpu6uv_y0pwandb\ntmp3qlpfrylwandb-media\t\t\t\t   tmpgyarr2jxwandb\t       tmpumz7hmaiwandb-artifacts\ntmp3snbanfnwandb\t\t\t\t   tmph6m9dpa_wandb\t       tmpun08cdmwwandb-artifacts\ntmp3xrxd920wandb-artifacts\t\t\t   tmph8n3b36swandb-media      tmp_uqnbz5n\ntmp3zmnx6jxwandb-artifacts\t\t\t   tmphddkq3_3wandb\t       tmpurv7_fe2wandb\ntmp4103eum2wandb\t\t\t\t   tmphmva83y4wandb\t       tmpuwoxzzfvwandb-media\ntmp421qmhu3wandb\t\t\t\t   tmphs6erdxrwandb-media      tmpvb5bk2js\ntmp48khxd0nwandb-artifacts\t\t\t   tmphshrf9juwandb-artifacts  tmpvd_wklrtwandb\ntmp49fv73y2wandb-media\t\t\t\t   tmpi31q87a0wandb-artifacts  tmpvg_71vtdwandb-media\ntmp49sad_g1wandb-artifacts\t\t\t   tmpiu05wr2_wandb\t       tmpvlxyr3eawandb-media\ntmp4c4800_xwandb-media\t\t\t\t   tmpivnhmojfwandb\t       tmpvqmyjo4pwandb-media\ntmp4clbe6xvwandb-media\t\t\t\t   tmpj16iv0rbwandb-media      tmpw10pvrxxwandb-media\ntmp4nuizjduwandb-media\t\t\t\t   tmpj4nmef2_wandb-media      tmpw8eaus7xwandb-media\ntmp5aiik94rwandb-media\t\t\t\t   tmpj6k4pajlwandb-artifacts  tmpw97zp6pqwandb-media\ntmp5jusc1czwandb-media\t\t\t\t   tmpjetcrm92wandb-media      tmpwkzzglljwandb-media\ntmp5ks7vxpqwandb\t\t\t\t   tmp_jfnbfwcwandb-artifacts  tmpwlpoppuwwandb-media\ntmp5ss5gfoqwandb-media\t\t\t\t   tmpjhcfo3sjwandb-media      tmpwok9yxtqwandb-media\ntmp61l257guwandb-media\t\t\t\t   tmpjhkja0n4wandb-media      tmpwqbb7793wandb\ntmp66a_30crwandb\t\t\t\t   tmpjq3bc0iywandb-media      tmpwu7oid1swandb-media\ntmp6_95ss09\t\t\t\t\t   tmpjseq6pjrwandb\t       tmpwwmlqm3gwandb-artifacts\ntmp6eb3e1v_wandb-artifacts\t\t\t   tmpjywyihxswandb\t       tmpwys0txyz\ntmp6ev3bw0kwandb-media\t\t\t\t   tmpk7eb9cxxwandb-artifacts  tmpx0i8_uxdwandb-media\ntmp6j_pagmjwandb-media\t\t\t\t   tmpki8mvo7pwandb\t       tmpxby6g44swandb-media\ntmp6uz84wzpwandb\t\t\t\t   tmpkiqc2rxywandb-media      tmpxdsg3tk8wandb-artifacts\ntmp7dmpqrecwandb\t\t\t\t   tmpklsmildcwandb-media      tmpxm2j1915wandb\ntmp7fzpg3pjwandb-artifacts\t\t\t   tmpkvhsusnzwandb-artifacts  tmp_xmydpcnwandb-media\ntmp7iafm3cywandb-media\t\t\t\t   tmpkvt13pjiwandb\t       tmpxpj1qkhnwandb-media\ntmp7m0tkcx7wandb\t\t\t\t   tmpkxhoutmnwandb\t       tmpxqnwoio_wandb-media\ntmp7p7ko5c1\t\t\t\t\t   tmpl32i_q8cwandb-artifacts  tmpy3sbukw0wandb-artifacts\ntmp7xmnpnjxwandb-media\t\t\t\t   tmpldwit_dswandb-media      tmpy4tqgd9q\ntmp80lef2dvwandb\t\t\t\t   tmplf9oolt5wandb\t       tmpy5mlqvf2\ntmp89e0j4bjwandb-artifacts\t\t\t   tmplgmiofgnwandb-artifacts  tmpy5y0mxbrwandb\ntmp8h7rchd9wandb-artifacts\t\t\t   tmplw1n5b69wandb-media      tmpydoskv75wandb\ntmp8l4njuz2\t\t\t\t\t   tmplx9285iywandb\t       tmpyx791iakwandb-media\ntmp8lxb4u_0wandb\t\t\t\t   tmp_lzx3b9dwandb-media      tmpyy2hv95pwandb-artifacts\ntmp8lyo8smzwandb\t\t\t\t   tmpm1c4zy4twandb-artifacts  tmpz0gx4ikiwandb-media\ntmp8q4h8lu7wandb-artifacts\t\t\t   tmpm2755ginwandb-artifacts  tmpz26cajmh\ntmp_8uvnuf2wandb\t\t\t\t   tmpm56u1aa5wandb-media      tmpz5s198hnwandb-artifacts\ntmp96o0qfii\t\t\t\t\t   tmpm9gk_r6swandb-media      tmpz6oxqu4vwandb-media\ntmp974f9ciawandb-media\t\t\t\t   tmpm_9gv20owandb-media      tmpzgz2lbnmwandb\ntmp98ec7tz8wandb-media\t\t\t\t   tmpmdak3eqkwandb-media      tmpzyqel_hcwandb-artifacts\ntmp9i4bx28vwandb\t\t\t\t   tmpmekovp_5wandb-artifacts  tmpzzjlqqh8wandb-media\ntmp9l8xrnlqwandb-media\t\t\t\t   tmp_mpucxdiwandb-artifacts  ultimate-utils\ntmp9y_56adfwandb-media\t\t\t\t   tmpmsn3sy8mwandb-artifacts  wandb\n</code></pre>\n<h3>\n<a name=\"additional-files-1\" class=\"anchor\" href=\"#additional-files-1\"></a>Additional Files</h3>\n<p><em>No response</em></p>\n<h3>\n<a name=\"environment-2\" class=\"anchor\" href=\"#environment-2\"></a>Environment</h3>\n<p>WandB version:<br>\n(metalearning_gpu) brando9~ $ python<br>\nPython 3.9.13 (main, Oct 13 2022, 21:15:33)<br>\n[GCC 11.2.0] :: Anaconda, Inc. on linux<br>\nType \u201chelp\u201d, \u201ccopyright\u201d, \u201ccredits\u201d or \u201clicense\u201d for more information.</p>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>import wandb<br>\nwandb.<strong>version</strong><br>\n\u20180.13.5\u2019</p>\n</blockquote>\n</blockquote>\n</blockquote>\n<p>OS: ubuntu/linux</p>\n<p>(metalearning_gpu) brando9~ $ cat /etc/os-release<br>\nNAME=\u201cUbuntu\u201d<br>\nVERSION=\u201c16.04.7 LTS (Xenial Xerus)\u201d<br>\nID=ubuntu<br>\nID_LIKE=debian<br>\nPRETTY_NAME=\u201cUbuntu 16.04.7 LTS\u201d<br>\nVERSION_ID=\u201c16.04\u201d<br>\nHOME_URL=\u201c<a href=\"http://www.ubuntu.com/\" rel=\"noopener nofollow ugc\">http://www.ubuntu.com/</a>\u201d<br>\nSUPPORT_URL=\u201c<a href=\"http://help.ubuntu.com/\" rel=\"noopener nofollow ugc\">http://help.ubuntu.com/</a>\u201d<br>\nBUG_REPORT_URL=\u201c<a href=\"http://bugs.launchpad.net/ubuntu/\" rel=\"noopener nofollow ugc\">http://bugs.launchpad.net/ubuntu/</a>\u201d<br>\nVERSION_CODENAME=xenial<br>\nUBUNTU_CODENAME=xenial</p>\n<p>Python version: 3.9.13</p>\n<p>Versions of relevant libraries:</p>\n<hr>\n<p>related:</p>\n<ul>\n<li>cross: <a href=\"https://github.com/wandb/wandb/issues/4535\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">[CLI]: Random tmp files being made -- why? \u00b7 Issue #4535 \u00b7 wandb/wandb \u00b7 GitHub</a>\n</li>\n<li><a href=\"https://stackoverflow.com/questions/74566670/how-to-stop-weights-biases-wandb-from-creating-random-tmp-files\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">machine learning - How to stop weights &amp; biases (wandb) from creating random tmp files? - Stack Overflow</a></li>\n</ul>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-29T14:08:44.794Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/brando\">@brando</a> thank you for reporting this. Besides <a href=\"https://docs.wandb.ai/guides/artifacts/storage\">these directories</a> which are controlled by the environment variables <code>WANDB_DIR</code>, <code>WANDB_CACHE_DIR</code> and <code>WANDB_CONFIG_DIR</code>, the wandb SDK in some cases such as logging <code>wandb.Image</code> objects or Artifacts it will additionally write some temporary files in the <code>tmp</code> directory for code\u2019s efficiency reasons.</p>\n<p>It seems that in your system, these were created in your home directory. Could you please post here the output of <code>ls -lah /t*</code> to check the write permissions, and of <code>pwd</code> from within the directory where these files were generated? I have filed a feature request to our engineering team to expose an environment variable for this directory so that it can be controlled where to write the temp files. Please let me know if that would help. Also, in terms of logged data, has everything uploaded fine in W&amp;B, and in that case would you need any help to remove these temp files?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-30T10:27:41.843Z",
				"Answer_body": "<p>HI!</p>\n<p>I\u2019m encountering this logging thing in my /tmp folder when downloading artifacts. From your explanation, I guess it\u2019s the intended behaviour, but is there any way to just avoid wandb to produce these files?</p>\n<p>Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-04T10:33:07.848Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/jceamoran\">@jceamoran</a> indeed that\u2019s intended and it isn\u2019t currently possible to switch this off. You can however remove these files once your training has completed and everything has synced with W&amp;B App. May I please ask what\u2019s the reason that you wouldn\u2019t want to have some temporary files written in your disk? I can add this context to an existing feature request to allow users control the location of this directory, would this work for you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-05T09:17:13.110Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a> !</p>\n<p>I was just wondering how to make my deployments lighter. Nothing I cannot live with. However, being able to choose location of these files would be an interesting feature tho!</p>\n<p>Thanks for your answer <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-08T15:29:01.511Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/jceamoran\">@jceamoran</a> thanks for the context, good to hear it\u2019s not currently blocking you. You could in the meantime call a command as follows, to cleanup the /tmp folder after your training has finished and synced everything to W&amp;B App:<br>\n<code>os.system('find /tmp -type d -name \"*wandb*\" -exec rm -rf {} \\;')</code></p>\n<p>However, I understand that this might not be ideal to be done by you, so I have also increased the requests for this feature, and we will reach out to you here on any related updates!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-15T15:23:54.059Z",
				"Answer_body": "<p>Hi, I just noticed this behavior too.  We have literally millions of wandb directories in /tmp, so just listing the contents of the directory is slow, even though the total space they take up is only a few GB.  I guess it would be nice if wandb did not produce so much trash, and also if it does, maybe they could be stored in per-user subdirectories of /tmp instead of directly in /tmp</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-16T15:24:36.400Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Easy integration with yolov8?",
		"Question_link": "https://community.wandb.ai/t/easy-integration-with-yolov8/3694",
		"Question_created_time": "2023-01-13T10:50:17.251Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 99,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I tried the Pytorch integration and it doesn\u2019t work:</p>\n<pre><code class=\"lang-auto\">from ultralytics import YOLO\n\nimport wandb\nwandb.init()\n\n# Load a model\nmodel = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n\n# Magic\nwandb.watch(model, log_freq=100)\n\nmodel.train()\nfor batch_idx, (data, target) in enumerate(train_loader):\n    output = model(data)\n    loss = F.nll_loss(output, target)\n    loss.backward()\n    optimizer.step()\n    if batch_idx % args.log_interval == 0:\n        wandb.log({\"loss\": loss})\n\n\n# Use the model\nresults = model.train(data=\"coco128.yaml\", epochs=3, batch = 2)  # train the model\n</code></pre>\n<p>I get the following:</p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"train.py\", line 10, in &lt;module&gt;\n    wandb.watch(model, log_freq=100)\n  File \"/home/henry/.local/bin/.virtualenvs/ultralytics/lib/python3.8/site-packages/wandb/sdk/wandb_watch.py\", line 71, in watch\n    raise ValueError(\nValueError: Expected a pytorch model (torch.nn.Module). Received &lt;class 'ultralytics.yolo.engine.model.YOLO'&gt;\n\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-13T15:42:45.301Z",
				"Answer_body": "<p>Hi Danny!</p>\n<p>Are you currently following this Yolov5 and Wandb integration report?</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-19T16:03:46.922Z",
				"Answer_body": "<p>Hi Danny,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-24T18:10:55.064Z",
				"Answer_body": "<p>Hi danny, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-14T10:50:56.473Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "OSError: Input/output error",
		"Question_link": "https://community.wandb.ai/t/oserror-input-output-error/3693",
		"Question_created_time": "2023-01-13T10:47:31.697Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 220,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi everyone,<br>\nwhile using wandb to log the metrics of my model (written using PyTorch), I randomly get an exception during the training phase. It is still unclear to me why and when this happens, but it causes my runs to stop which is quite annoying.</p>\n<p>Any ideas? I really appreciate any help you can provide!</p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"/usr/local/anaconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n    self.flush()\n  File \"/usr/local/anaconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n    self.stream.flush()\nOSError: [Errno 5] Input/output error\nCall stack:\nException in thread OutRawRd-stderr:\nTraceback (most recent call last):\n  File \"/usr/local/anaconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n    self.run()\n  File \"/usr/local/anaconda3/lib/python3.8/threading.py\", line 870, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/homes/llumetti/alveolar_canal_base/venv/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 1027, in _output_raw_reader_thread\n  File \"/homes/llumetti/alveolar_canal_base/venv/lib/python3.8/site-packages/wandb/sdk/internal/sender.py\", line 1042, in _output_raw_flush\n    self._output_raw_file.write(data.encode(\"utf-8\"))\n  File \"/homes/llumetti/alveolar_canal_base/venv/lib/python3.8/site-packages/wandb/sdk/lib/filesystem.py\", line 64, in write\n  File \"/usr/local/anaconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n    self._bootstrap_inner()\n  File \"/usr/local/anaconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n    self.run()\n  File \"/homes/llumetti/alveolar_canal_base/venv/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/homes/llumetti/alveolar_canal_base/venv/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"/homes/llumetti/alveolar_canal_base/venv/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 264, in _process\n    self._hm.handle(record)\n  File \"/homes/llumetti/alveolar_canal_base/venv/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 131, in handle\n  File \"/homes/llumetti/alveolar_canal_base/venv/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 139, in handle_request\nMessage: 'handle_request: partial_history'\nArguments: ()\n    super().write(b\"\\n\".join(ret) + b\"\\n\")\n  File \"/homes/llumetti/alveolar_canal_base/venv/lib/python3.8/site-packages/wandb/sdk/lib/filesystem.py\", line 31, in write\n    self.f.flush()\nOSError: [Errno 5] Input/output error\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-13T16:14:34.574Z",
				"Answer_body": "<p>Hi Luca!</p>\n<p>Could you please disable WandB and see if you run into the same issue still?</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-19T17:11:13.570Z",
				"Answer_body": "<p>Hi Luca,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-24T19:06:19.470Z",
				"Answer_body": "<p>Hi Luca, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-14T10:47:57.109Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wrong result after wandb sync",
		"Question_link": "https://community.wandb.ai/t/wrong-result-after-wandb-sync/3570",
		"Question_created_time": "2022-12-19T10:50:43.749Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 304,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi everyone. I have a problem related to the sync of multiple offline runs: when syncing older runs are always overwritten with the latest run. The yellow and pink runs are represented only by the second run, while the first ones (from epoch 0 to nearly 100) have disappeared. Syncing only the first run makes the latter disappear. Runs were synced with the command</p>\n<pre><code class=\"lang-auto\">wandb sync --sync-all \"wandb\"\n</code></pre>\n<p>The blue run was an example of a complete online run on a different platform but with the same code.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/1/1459cc50f81ec38d21c64bc20597919c19713c54.png\" data-download-href=\"/uploads/short-url/2U1Wl6jhdLxDHIIQSfDpdpo7IA4.png?dl=1\" title=\"wandb-error\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/1/1459cc50f81ec38d21c64bc20597919c19713c54_2_690x260.png\" alt=\"wandb-error\" data-base62-sha1=\"2U1Wl6jhdLxDHIIQSfDpdpo7IA4\" width=\"690\" height=\"260\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/1/1459cc50f81ec38d21c64bc20597919c19713c54_2_690x260.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/1/1459cc50f81ec38d21c64bc20597919c19713c54_2_1035x390.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/1/1459cc50f81ec38d21c64bc20597919c19713c54_2_1380x520.png 2x\" data-dominant-color=\"FEFEFE\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">wandb-error</span><span class=\"informations\">1801\u00d7680 29.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Does someone know how to fix this?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-21T20:03:42.985Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lorenzo_b\">@lorenzo_b</a>, are these runs using the same run_id? If two runs have the same run_id then the second one will overwrite the first when it gets synced.</p>\n<p>One option is to specify a new run_id with <code>wandb sync &lt;run_folder&gt; --id &lt;new_run_id&gt;</code>. This won\u2019t work with <code>--sync-all</code> but you can write a quick for loop to iterate over each run folder and sync the runs individually.</p>\n<p>Let me know if this helps!<br>\n-Nate</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-12-28T15:10:06.084Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/lorenzo_b\">@lorenzo_b</a> I just want to follow up and see if you have had a chance to look into this any more and if the above solution was helpful?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-29T09:56:17.364Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nathank\">@nathank</a> and thank you for your answer. So it\u2019s not possible to resume offline runs and you are forced to create a new run to continue training?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-05T22:27:00.285Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/lorenzo_b\">@lorenzo_b</a> is the original run offline and the resume online? Or are both offline?</p>\n<p>When resuming, wandb must be in \u201conline\u201d mode. So for instance <code>wandb.init(mode=\"offline\", resume=\"must\", id=&lt;some_run_id&gt;)</code> will print this warning and it will start a new run: <code>wandb: WARNING  resume will be ignored since W&amp;B syncing is set to offline. Starting a new run with run id</code></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-09T08:22:25.051Z",
				"Answer_body": "<p>Thanks for the perfect explanation! The error I made was trying resuming offline runs</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-12T23:18:09.170Z",
				"Answer_body": "<p>Happy to help! Let us know if you have any other questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-13T23:18:23.631Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Multi-run confusion matrix is missing class",
		"Question_link": "https://community.wandb.ai/t/multi-run-confusion-matrix-is-missing-class/3691",
		"Question_created_time": "2023-01-12T20:27:54.420Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 71,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I  am working on a 3 classes classification problem and my confusion matrix is getting messed up. It does not show class 1.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/db00d90402775cbd38aa10db03d568c86fe1b6b1.png\" data-download-href=\"/uploads/short-url/vfonHnXSPR6s8bDCiSBgLDe4P17.png?dl=1\" title=\"multi-run_confusion_matrix\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/db00d90402775cbd38aa10db03d568c86fe1b6b1.png\" alt=\"multi-run_confusion_matrix\" data-base62-sha1=\"vfonHnXSPR6s8bDCiSBgLDe4P17\" width=\"690\" height=\"445\" data-dominant-color=\"F9F6F7\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">multi-run_confusion_matrix</span><span class=\"informations\">1016\u00d7656 12.6 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>The test accuracy for all three classes is 95% and all three classes are actually in the dataset.</p>\n<pre><code class=\"lang-auto\">        # log data for the confusion matrix\n        wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n                        y_true=y_test_true, preds=y_test_pred,\n                        class_names=labels)})\n</code></pre>\n<p>Any idea how to solve this issue?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-13T16:12:22.423Z",
				"Answer_body": "<p>Hi Susanne!</p>\n<p>Could I see a link to your workspace?</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-19T17:12:06.657Z",
				"Answer_body": "<p>Hi Susanne,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-24T19:10:29.188Z",
				"Answer_body": "<p>Hi Susanne, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-13T20:27:56.359Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Gradients Panel Management",
		"Question_link": "https://community.wandb.ai/t/gradients-panel-management/3688",
		"Question_created_time": "2023-01-12T11:45:04.026Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 71,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi there!<br>\nI ran a sweep logging the gradients and they showed up in the Dashboard, but they don\u2019t follow the graph model (also logged in the <code>Model</code> section of the dashboard), hence it is difficult to see the gradient evolution from \u201cinit to final\u201d.<br>\nAlso, I can\u2019t setup a custom layout since they\u2019re more than 50\u2026</p>\n<p>Thanks in advance for your help!</p>\n<p>Mattia</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-13T19:43:58.555Z",
				"Answer_body": "<p>Hi Mattia, thank you for writing in! Can you elaborate more on what you mean by <code>they don't follow the graph model</code> a bit more please? Can you also attach a link to your workspace? Regarding the custom layout, I\u2019m assuming this is with regards to the layout of your panels. If you would like, I could put in a feature request to increase the amount of panels you can have to use this feature.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-19T22:12:02.954Z",
				"Answer_body": "<p>Hi Mattia, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-13T11:45:21.457Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Join over different tables in a run",
		"Question_link": "https://community.wandb.ai/t/join-over-different-tables-in-a-run/3670",
		"Question_created_time": "2023-01-10T14:34:42.853Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 157,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>I am looking at <a href=\"https://wandb.ai/stacey/mnist-viz/reports/Visualize-Predictions-over-Time--Vmlldzo1OTQxMTk\">this example</a> where at each epoch a table is generated to represent a dataset (images, ground truth) along with the model prediction and is then logged to be able to visualize the model prediction at every epoch.</p>\n<p>It looks redundant and bandwidth-hungry to log the images at every epoch. I would like to have a way to log the dataset as a table only once with the columns (id, image, ground truth), then at every epoch log only a  table with the model predictions i.e. with columns (id, prediction), then on the UI join the two tables on the \u201cid\u201d key.</p>\n<p>This does not seem to be possible at the moment. Has anyone tried something similar? Is it really standard to log a whole dataset at every evaluation step?</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-11T15:53:33.620Z",
				"Answer_body": "<p>There is a way to log images just once. Basically, you log a table without the model predictions and then log a new table that references these images. Actually the integrations with lightning and keras do this.</p>\n<p>Basically, you do this in 3 steps.</p>\n<ul>\n<li>Log a Table into an Artifact</li>\n</ul>\n<pre><code class=\"lang-python\">at = wandb.Artifact(\"evaluation_data\", type=\"data\") \nds_table = wandb.Table(columns = [\"image\", \"label\"], data=data)\nds_at.add(ds_table,  \"dataset_table\")\nwandb.log_artifact(at)\n</code></pre>\n<ul>\n<li>then you grab this artifact and recover the table:</li>\n</ul>\n<pre><code class=\"lang-python\">at = wandb.use_artifact(\"evaluation_data\", type='data')\n\n# grab the ds table\nds_table = at.get(\"dataset_table\")\nindex = ds_table.get_index()\n</code></pre>\n<ul>\n<li>Finally, you create a new Table and reference (index) the values from the referenced table.</li>\n</ul>\n<pre><code class=\"lang-python\"># create a new predictions table\npreds_table = wandb.Table(columns=[\"image\",  \"label\", \"predictions\"])\n\n# then we fill the new table with the values from the `ds_table`\nfor idx in index:\n  pred = preds[idx]\n  row = [ds_table.data[idx][0], ds_table.data[idx][1], pred.argmax()]\n  self.preds_table.add_data(*row)\n\n# finally we log the new predictions table to a new Artifact\npred_artifact = wandb.Artifact(f\"run_{wandb.run.id}_preds\",  type=\"evaluation\")\npred_artifact.add(preds_table,  \"model_predictions\")\nwandb.log_artifact(pred_artifact)\n</code></pre>\n<p>It is pretty verbose, but it keeps track of the lineage.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-11T16:41:46.566Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/skandermoalla\">@skandermoalla</a>, it\u2019s possible to log the dataset only once, and for subsequent epochs, use referencing to access the logged dataset. Thus you need to upload the dataset only once.</p>\n<p>It\u2019s already used in MMDetection, MMSegmentation, MMClassification and new W&amp;B Keras Eval callback:</p>\n<ul>\n<li>MMDetection - <a href=\"https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/hook/wandblogger_hook.py\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">mmdetection/wandblogger_hook.py at master \u00b7 open-mmlab/mmdetection \u00b7 GitHub</a>\n</li>\n<li>For a simpler example check out Keras WandbEvalCallback: <a href=\"https://github.com/wandb/wandb/blob/0095a42b9a1ccf43c26ae09c2c7d52e727c9fd3d/wandb/integration/keras/callbacks/tables_builder.py#L10\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">wandb/tables_builder.py at 0095a42b9a1ccf43c26ae09c2c7d52e727c9fd3d \u00b7 wandb/wandb \u00b7 GitHub</a>\n</li>\n</ul>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-12T16:42:38.391Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Storing the files to AWS S3",
		"Question_link": "https://community.wandb.ai/t/storing-the-files-to-aws-s3/3679",
		"Question_created_time": "2023-01-11T12:41:11.244Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 87,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Is there a way we can save the tables to our own AWS S3 bucket ratherthan using W&amp;B storage.<br>\nCan we save all the .ckpt, .wand files that wandb logs to our AWS cloud storage.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-11T12:56:27.786Z",
				"Answer_body": "<p>Hi Sydney,</p>\n<p>Can you please help me understand how can it be done.\\</p>\n<p>Thanks &amp; Regards</p>\n<p>Prasanth Noel</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-11T14:02:26.002Z",
				"Answer_body": "<p>Hi Prasanth,</p>\n<p>Thanks for writing in! You can do that by using our reference artifacts, they allow you to track files saved outside the W&amp;B server. Also here you have a report showing an example on how to do this. Please let me know if this would be useful for you!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-13T10:20:34.305Z",
				"Answer_body": "<p>Hi Prasanth,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-12T12:42:08.479Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb does not log all .py files",
		"Question_link": "https://community.wandb.ai/t/wandb-does-not-log-all-py-files/3602",
		"Question_created_time": "2022-12-26T11:09:24.621Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 280,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi all,</p>\n<p>I\u2019m having an issue with logging code using wandb.run.log_code(\u201c.\u201d). While there are other .py files present in my directory, wandb only seems to log the script that called wandb.init(). This is frustrating, as I want to see all of the code that was used in my run. I\u2019ve even tried stepping through with a debugger, and it looks like wandb is looping over those .py files, but for some reason they aren\u2019t being logged on the run page in the code section.</p>\n<p>Has anyone else experienced this issue, or have any suggestions for how to resolve it?</p>\n<p>Thanks in advance for any help!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-28T01:53:34.290Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/miladink\">@miladink</a> , happy to help. When calling <code>wandb.run.log_code(\".\")</code>, wandb will capture all python source code files in the current and all sub directories as an <strong>artifact</strong>. Are you indicating that the generated artifact   is not saving all python files  when called for the run? Could you please provide a link to your workspace where you are encountering this behavior. Thank you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-28T01:53:43.296Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/miladink\">@miladink</a> , happy to help. When calling <code>wandb.run.log_code(\".\")</code>, wandb will capture all python source code files in the current and all sub directories as an <strong>artifact</strong>. Are you indicating that the generated artifact is not saving all python files for the run?</p>\n<p>[Discourse post]</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-30T11:33:34.744Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sydholl\">@sydholl</a> and <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> .  I don\u2019t know where to look for an artifact. I look at the \u201cfiles\u201d tab of a run and I guess all the logged files are there. However, in the code/ section on the files tab, I just see one of my python files which is just the python file that called wandb. However, the other python files that are present in that same directory are not logged. I should note I call <code>wandb.run.log_code(\".\")</code> from that script. Am I doing something wrong?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-05T22:07:22.862Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/miladink\">@miladink</a> , apologies for the delay. To access the artifacts page, select the DB icon as in this example <a href=\"https://docs.wandb.ai/ref/app/pages/project-page#artifacts-tab\">here</a>. Could you try the following:</p>\n<p><code>wandb.run.log_code(\".\", include_fn=lambda path: path.endswith(\".py\"))</code>.</p>\n<p>If it doesn\u2019t work, please provide:</p>\n<ul>\n<li>Screen shot of your working directory</li>\n<li>Link to your workspace</li>\n<li>Example code of how you are using <a href=\"https://docs.wandb.ai/ref/python/run#log_code\">log_code()</a>\n</li>\n</ul>\n<p>Thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-11T01:13:09.100Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/miladink\">@miladink</a>  since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-12T01:13:48.315Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Advanced legend doesn't display properly or displays [Object Object]",
		"Question_link": "https://community.wandb.ai/t/advanced-legend-doesnt-display-properly-or-displays-object-object/3638",
		"Question_created_time": "2023-01-04T16:20:20.018Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 146,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am trying to customize the legend on plots using the Advanced Legend syntax. But have a couple of problems there. Here is the workspace/plot: <a href=\"https://wandb.ai/gat/wandb-debug5?workspace=user-wjgat\" class=\"inline-onebox\">Weights &amp; Biases</a></p>\n<p>I am using the following string in the advanced legend: <code>A=(${config:spec.url}) B=(${config:url}) C=${config:spec_name}</code></p>\n<p>This should render as `A=(http:\\google.com/) B=(http:\\google.com/) C=(google) but:</p>\n<ol>\n<li>It renders as <code>A=( ) B=(http:\\\\google.com) C=google</code>\n</li>\n<li>The \u201con hover\u201d legend renders as <code>A=( ) B=([Object Object]) C=google</code>\n</li>\n</ol>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/3/339707641144d812c66bf80fbc18a6b6f79de511.png\" data-download-href=\"/uploads/short-url/7mnVAwnMPAidW9iqjOHkGnGgI6J.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/339707641144d812c66bf80fbc18a6b6f79de511_2_690x420.png\" alt=\"image\" data-base62-sha1=\"7mnVAwnMPAidW9iqjOHkGnGgI6J\" width=\"690\" height=\"420\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/339707641144d812c66bf80fbc18a6b6f79de511_2_690x420.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/339707641144d812c66bf80fbc18a6b6f79de511_2_1035x630.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/3/339707641144d812c66bf80fbc18a6b6f79de511.png 2x\" data-dominant-color=\"F4F6FB\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1190\u00d7726 100 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Are those bugs in wandb or I don\u2019t get sth?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-09T21:47:50.594Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/wjaskowski\">@wjaskowski</a> thanks for writing in and happy to help. I reviewed your workspace and your legend expression is correct. The legend label  does render correctly but as you mentioned the tooltip does not. This appears to be a bug on our end with how the tooltip handles URL visualization. I reported it to our eng team and will update you once I hear back on a fix. Thanks for reporting!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-09T22:16:16.109Z",
				"Answer_body": "<p>Thx for looking into <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a>! But why do you say that the legend renders correctly when it renders <code>A=( )</code> instead of <code>A=(https:\\\\google.com)</code>?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-09T22:48:29.272Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/wjaskowski\">@wjaskowski</a> , apologies. I made some test edits o a copy of your workspace and used <code>A=(${config:spec_url})</code> which renders correctly. Your exact example isn\u2019t rendering.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-10T08:20:42.741Z",
				"Answer_body": "<p>Which means that this is another bug, isn\u2019t it?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-10T20:52:32.776Z",
				"Answer_body": "<p>Correct, it is a bug.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-10T22:28:12.936Z",
				"Answer_body": "<p>Thank you <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> for confirming that. This drove me crazy for a while :/. Is there a place where I can track the status of this bug?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-11T22:28:21.371Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Matplotlib Plot throws an error",
		"Question_link": "https://community.wandb.ai/t/matplotlib-plot-throws-an-error/3654",
		"Question_created_time": "2023-01-09T11:59:32.634Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 219,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I\u2019m trying to log a matplotlib graph on Wandb and it throws the following error.</p>\n<pre><code class=\"lang-bash\">AttributeError: 'XAxis' object has no attribute '_gridOnMajor'\n</code></pre>\n<p>Steps to reproduce:<br>\nFollowing example: <a href=\"https://docs.wandb.ai/guides/track/log/plots#matplotlib-and-plotly-plots\" class=\"inline-onebox\">Log Plots - Documentation</a></p>\n<h2>\n<a name=\"exact-steps-1\" class=\"anchor\" href=\"#exact-steps-1\"></a>Exact steps:</h2>\n<h3>\n<a name=\"imports-2\" class=\"anchor\" href=\"#imports-2\"></a>imports</h3>\n<pre><code class=\"lang-python\">import wandb\nimport random\nimport math\n</code></pre>\n<h3>\n<a name=\"login-3\" class=\"anchor\" href=\"#login-3\"></a>Login:</h3>\n<pre><code class=\"lang-python\">wandb.login()\n</code></pre>\n<h3>\n<a name=\"create-and-upload-graph-4\" class=\"anchor\" href=\"#create-and-upload-graph-4\"></a>Create and upload graph</h3>\n<pre><code class=\"lang-auto\"># Start a new run\nrun = wandb.init(project='custom-charts')\noffset = random.random()\n\nimport matplotlib.pyplot as plt\n\nplt.plot([1, 2, 3, 4])\nplt.ylabel(\"some interesting numbers\")\nwandb.log({\"chart\": plt})\n\n# Finally, end the run. We only need this ine in Jupyter notebooks.\nrun.finish()\n</code></pre>\n<h3>\n<a name=\"summary-error-message-5\" class=\"anchor\" href=\"#summary-error-message-5\"></a>Summary error message:</h3>\n<pre><code class=\"lang-auto\">AttributeError                            Traceback (most recent call last)\n/home/ubuntu/src/workspace/py-vision/src/research/nbs/automated_inventory_analysis/aia_africaai_baseline/wanb_plot_test.ipynb Cell 4 in &lt;cell line: 9&gt;()\n      7 plt.plot([1, 2, 3, 4])\n      8 plt.ylabel(\"some interesting numbers\")\n----&gt; 9 wandb.log({\"chart\": plt})\n     11 # Finally, end the run. We only need this ine in Jupyter notebooks.\n     12 run.finish()\n\nFile ~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:256, in _run_decorator._noop.&lt;locals&gt;.wrapper(self, *args, **kwargs)\n    253         wandb.termwarn(message, repeat=False)\n    254         return cls.Dummy()\n--&gt; 256 return func(self, *args, **kwargs)\n\nFile ~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:222, in _run_decorator._attach.&lt;locals&gt;.wrapper(self, *args, **kwargs)\n    220         raise e\n    221     cls._is_attaching = \"\"\n--&gt; 222 return func(self, *args, **kwargs)\n\nFile ~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:1548, in Run.log(self, data, step, commit, sync)\n   1541 if sync is not None:\n   1542     deprecate.deprecate(\n   1543         field_name=deprecate.Deprecated.run__log_sync,\n   1544         warning_message=(\n   1545             \"`sync` argument is deprecated and does not affect the behaviour of `wandb.log`\"\n   1546         ),\n   1547     )\n-&gt; 1548 self._log(data=data, step=step, commit=commit)\n\nFile ~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:1339, in Run._log(self, data, step, commit)\n   1336 if any(not isinstance(key, str) for key in data.keys()):\n   1337     raise ValueError(\"Key values passed to `wandb.log` must be strings.\")\n-&gt; 1339 self._partial_history_callback(data, step, commit)\n   1341 if step is not None:\n   1342     if os.getpid() != self._init_pid or self._is_attached:\n\nFile ~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:1228, in Run._partial_history_callback(self, row, step, commit)\n   1225 if self._backend and self._backend.interface:\n   1226     not_using_tensorboard = len(wandb.patched[\"tensorboard\"]) == 0\n-&gt; 1228     self._backend.interface.publish_partial_history(\n   1229         row,\n   1230         user_step=self._step,\n   1231         step=step,\n   1232         flush=commit,\n   1233         publish_step=not_using_tensorboard,\n   1234     )\n\nFile ~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:541, in InterfaceBase.publish_partial_history(self, data, user_step, step, flush, publish_step, run)\n    530 def publish_partial_history(\n    531     self,\n    532     data: dict,\n   (...)\n    537     run: Optional[\"Run\"] = None,\n    538 ) -&gt; None:\n    539     run = run or self._run\n--&gt; 541     data = history_dict_to_json(run, data, step=user_step, ignore_copy_err=True)\n    542     data.pop(\"_step\", None)\n    544     partial_history = pb.PartialHistoryRequest()\n\nFile ~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/wandb/sdk/data_types/utils.py:54, in history_dict_to_json(run, payload, step, ignore_copy_err)\n     50         payload[key] = history_dict_to_json(\n     51             run, val, step=step, ignore_copy_err=ignore_copy_err\n     52         )\n     53     else:\n---&gt; 54         payload[key] = val_to_json(\n     55             run, key, val, namespace=step, ignore_copy_err=ignore_copy_err\n     56         )\n     58 return payload\n\nFile ~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/wandb/sdk/data_types/utils.py:82, in val_to_json(run, key, val, namespace, ignore_copy_err)\n     79     val = wandb.Table(dataframe=val)\n     81 elif util.is_matplotlib_typename(typename) or util.is_plotly_typename(typename):\n---&gt; 82     val = Plotly.make_plot_media(val)\n     83 elif isinstance(val, Sequence) and all(isinstance(v, WBValue) for v in val):\n     84     assert run\n\nFile ~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/wandb/sdk/data_types/plotly.py:48, in Plotly.make_plot_media(cls, val)\n     46     if util.matplotlib_contains_images(val):\n     47         return Image(val)\n---&gt; 48     val = util.matplotlib_to_plotly(val)\n     49 return cls(val)\n\nFile ~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/wandb/util.py:565, in matplotlib_to_plotly(obj)\n    557 obj = ensure_matplotlib_figure(obj)\n    558 tools = get_module(\n    559     \"plotly.tools\",\n    560     required=(\n   (...)\n    563     ),\n    564 )\n--&gt; 565 return tools.mpl_to_plotly(obj)\n\nFile ~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/plotly/tools.py:112, in mpl_to_plotly(fig, resize, strip_style, verbose)\n    110 if matplotlylib:\n    111     renderer = matplotlylib.PlotlyRenderer()\n...\n--&gt; 246     if axis._gridOnMajor and len(gridlines) &gt; 0:\n    247         color = export_color(gridlines[0].get_color())\n    248         alpha = gridlines[0].get_alpha()\n\nAttributeError: 'XAxis' object has no attribute '_gridOnMajor'\n</code></pre>\n<h3>\n<a name=\"full-error-message-6\" class=\"anchor\" href=\"#full-error-message-6\"></a>Full Error message:</h3>\n<pre><code class=\"lang-bash\">{\n\t\"name\": \"AttributeError\",\n\t\"message\": \"'XAxis' object has no attribute '_gridOnMajor'\",\n\t\"stack\": \"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\\n\\u001b[0;31mAttributeError\\u001b[0m                            Traceback (most recent call last)\\n\\u001b[1;32m/home/ubuntu/src/workspace/py-vision/src/research/nbs/automated_inventory_analysis/aia_africaai_baseline/wanb_plot_test.ipynb Cell 4\\u001b[0m in \\u001b[0;36m&lt;cell line: 9&gt;\\u001b[0;34m()\\u001b[0m\\n\\u001b[1;32m      &lt;a href='vscode-notebook-cell://ssh-remote%2Bai_training_g5/home/ubuntu/src/workspace/py-vision/src/research/nbs/automated_inventory_analysis/aia_africaai_baseline/wanb_plot_test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'&gt;7&lt;/a&gt;\\u001b[0m plt\\u001b[39m.\\u001b[39mplot([\\u001b[39m1\\u001b[39m, \\u001b[39m2\\u001b[39m, \\u001b[39m3\\u001b[39m, \\u001b[39m4\\u001b[39m])\\n\\u001b[1;32m      &lt;a href='vscode-notebook-cell://ssh-remote%2Bai_training_g5/home/ubuntu/src/workspace/py-vision/src/research/nbs/automated_inventory_analysis/aia_africaai_baseline/wanb_plot_test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'&gt;8&lt;/a&gt;\\u001b[0m plt\\u001b[39m.\\u001b[39mylabel(\\u001b[39m\\\"\\u001b[39m\\u001b[39msome interesting numbers\\u001b[39m\\u001b[39m\\\"\\u001b[39m)\\n\\u001b[0;32m----&gt; &lt;a href='vscode-notebook-cell://ssh-remote%2Bai_training_g5/home/ubuntu/src/workspace/py-vision/src/research/nbs/automated_inventory_analysis/aia_africaai_baseline/wanb_plot_test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'&gt;9&lt;/a&gt;\\u001b[0m wandb\\u001b[39m.\\u001b[39;49mlog({\\u001b[39m\\\"\\u001b[39;49m\\u001b[39mchart\\u001b[39;49m\\u001b[39m\\\"\\u001b[39;49m: plt})\\n\\u001b[1;32m     &lt;a href='vscode-notebook-cell://ssh-remote%2Bai_training_g5/home/ubuntu/src/workspace/py-vision/src/research/nbs/automated_inventory_analysis/aia_africaai_baseline/wanb_plot_test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'&gt;11&lt;/a&gt;\\u001b[0m \\u001b[39m# Finally, end the run. We only need this ine in Jupyter notebooks.\\u001b[39;00m\\n\\u001b[1;32m     &lt;a href='vscode-notebook-cell://ssh-remote%2Bai_training_g5/home/ubuntu/src/workspace/py-vision/src/research/nbs/automated_inventory_analysis/aia_africaai_baseline/wanb_plot_test.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'&gt;12&lt;/a&gt;\\u001b[0m run\\u001b[39m.\\u001b[39mfinish()\\n\\nFile \\u001b[0;32m~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:256\\u001b[0m, in \\u001b[0;36m_run_decorator._noop.&lt;locals&gt;.wrapper\\u001b[0;34m(self, *args, **kwargs)\\u001b[0m\\n\\u001b[1;32m    253\\u001b[0m         wandb\\u001b[39m.\\u001b[39mtermwarn(message, repeat\\u001b[39m=\\u001b[39m\\u001b[39mFalse\\u001b[39;00m)\\n\\u001b[1;32m    254\\u001b[0m         \\u001b[39mreturn\\u001b[39;00m \\u001b[39mcls\\u001b[39m\\u001b[39m.\\u001b[39mDummy()\\n\\u001b[0;32m--&gt; 256\\u001b[0m \\u001b[39mreturn\\u001b[39;00m func(\\u001b[39mself\\u001b[39;49m, \\u001b[39m*\\u001b[39;49margs, \\u001b[39m*\\u001b[39;49m\\u001b[39m*\\u001b[39;49mkwargs)\\n\\nFile \\u001b[0;32m~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:222\\u001b[0m, in \\u001b[0;36m_run_decorator._attach.&lt;locals&gt;.wrapper\\u001b[0;34m(self, *args, **kwargs)\\u001b[0m\\n\\u001b[1;32m    220\\u001b[0m         \\u001b[39mraise\\u001b[39;00m e\\n\\u001b[1;32m    221\\u001b[0m     \\u001b[39mcls\\u001b[39m\\u001b[39m.\\u001b[39m_is_attaching \\u001b[39m=\\u001b[39m \\u001b[39m\\\"\\u001b[39m\\u001b[39m\\\"\\u001b[39m\\n\\u001b[0;32m--&gt; 222\\u001b[0m \\u001b[39mreturn\\u001b[39;00m func(\\u001b[39mself\\u001b[39;49m, \\u001b[39m*\\u001b[39;49margs, \\u001b[39m*\\u001b[39;49m\\u001b[39m*\\u001b[39;49mkwargs)\\n\\nFile \\u001b[0;32m~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:1548\\u001b[0m, in \\u001b[0;36mRun.log\\u001b[0;34m(self, data, step, commit, sync)\\u001b[0m\\n\\u001b[1;32m   1541\\u001b[0m \\u001b[39mif\\u001b[39;00m sync \\u001b[39mis\\u001b[39;00m \\u001b[39mnot\\u001b[39;00m \\u001b[39mNone\\u001b[39;00m:\\n\\u001b[1;32m   1542\\u001b[0m     deprecate\\u001b[39m.\\u001b[39mdeprecate(\\n\\u001b[1;32m   1543\\u001b[0m         field_name\\u001b[39m=\\u001b[39mdeprecate\\u001b[39m.\\u001b[39mDeprecated\\u001b[39m.\\u001b[39mrun__log_sync,\\n\\u001b[1;32m   1544\\u001b[0m         warning_message\\u001b[39m=\\u001b[39m(\\n\\u001b[1;32m   1545\\u001b[0m             \\u001b[39m\\\"\\u001b[39m\\u001b[39m`sync` argument is deprecated and does not affect the behaviour of `wandb.log`\\u001b[39m\\u001b[39m\\\"\\u001b[39m\\n\\u001b[1;32m   1546\\u001b[0m         ),\\n\\u001b[1;32m   1547\\u001b[0m     )\\n\\u001b[0;32m-&gt; 1548\\u001b[0m \\u001b[39mself\\u001b[39;49m\\u001b[39m.\\u001b[39;49m_log(data\\u001b[39m=\\u001b[39;49mdata, step\\u001b[39m=\\u001b[39;49mstep, commit\\u001b[39m=\\u001b[39;49mcommit)\\n\\nFile \\u001b[0;32m~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:1339\\u001b[0m, in \\u001b[0;36mRun._log\\u001b[0;34m(self, data, step, commit)\\u001b[0m\\n\\u001b[1;32m   1336\\u001b[0m \\u001b[39mif\\u001b[39;00m \\u001b[39many\\u001b[39m(\\u001b[39mnot\\u001b[39;00m \\u001b[39misinstance\\u001b[39m(key, \\u001b[39mstr\\u001b[39m) \\u001b[39mfor\\u001b[39;00m key \\u001b[39min\\u001b[39;00m data\\u001b[39m.\\u001b[39mkeys()):\\n\\u001b[1;32m   1337\\u001b[0m     \\u001b[39mraise\\u001b[39;00m \\u001b[39mValueError\\u001b[39;00m(\\u001b[39m\\\"\\u001b[39m\\u001b[39mKey values passed to `wandb.log` must be strings.\\u001b[39m\\u001b[39m\\\"\\u001b[39m)\\n\\u001b[0;32m-&gt; 1339\\u001b[0m \\u001b[39mself\\u001b[39;49m\\u001b[39m.\\u001b[39;49m_partial_history_callback(data, step, commit)\\n\\u001b[1;32m   1341\\u001b[0m \\u001b[39mif\\u001b[39;00m step \\u001b[39mis\\u001b[39;00m \\u001b[39mnot\\u001b[39;00m \\u001b[39mNone\\u001b[39;00m:\\n\\u001b[1;32m   1342\\u001b[0m     \\u001b[39mif\\u001b[39;00m os\\u001b[39m.\\u001b[39mgetpid() \\u001b[39m!=\\u001b[39m \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39m_init_pid \\u001b[39mor\\u001b[39;00m \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39m_is_attached:\\n\\nFile \\u001b[0;32m~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/wandb/sdk/wandb_run.py:1228\\u001b[0m, in \\u001b[0;36mRun._partial_history_callback\\u001b[0;34m(self, row, step, commit)\\u001b[0m\\n\\u001b[1;32m   1225\\u001b[0m \\u001b[39mif\\u001b[39;00m \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39m_backend \\u001b[39mand\\u001b[39;00m \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39m_backend\\u001b[39m.\\u001b[39minterface:\\n\\u001b[1;32m   1226\\u001b[0m     not_using_tensorboard \\u001b[39m=\\u001b[39m \\u001b[39mlen\\u001b[39m(wandb\\u001b[39m.\\u001b[39mpatched[\\u001b[39m\\\"\\u001b[39m\\u001b[39mtensorboard\\u001b[39m\\u001b[39m\\\"\\u001b[39m]) \\u001b[39m==\\u001b[39m \\u001b[39m0\\u001b[39m\\n\\u001b[0;32m-&gt; 1228\\u001b[0m     \\u001b[39mself\\u001b[39;49m\\u001b[39m.\\u001b[39;49m_backend\\u001b[39m.\\u001b[39;49minterface\\u001b[39m.\\u001b[39;49mpublish_partial_history(\\n\\u001b[1;32m   1229\\u001b[0m         row,\\n\\u001b[1;32m   1230\\u001b[0m         user_step\\u001b[39m=\\u001b[39;49m\\u001b[39mself\\u001b[39;49m\\u001b[39m.\\u001b[39;49m_step,\\n\\u001b[1;32m   1231\\u001b[0m         step\\u001b[39m=\\u001b[39;49mstep,\\n\\u001b[1;32m   1232\\u001b[0m         flush\\u001b[39m=\\u001b[39;49mcommit,\\n\\u001b[1;32m   1233\\u001b[0m         publish_step\\u001b[39m=\\u001b[39;49mnot_using_tensorboard,\\n\\u001b[1;32m   1234\\u001b[0m     )\\n\\nFile \\u001b[0;32m~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:541\\u001b[0m, in \\u001b[0;36mInterfaceBase.publish_partial_history\\u001b[0;34m(self, data, user_step, step, flush, publish_step, run)\\u001b[0m\\n\\u001b[1;32m    530\\u001b[0m \\u001b[39mdef\\u001b[39;00m \\u001b[39mpublish_partial_history\\u001b[39m(\\n\\u001b[1;32m    531\\u001b[0m     \\u001b[39mself\\u001b[39m,\\n\\u001b[1;32m    532\\u001b[0m     data: \\u001b[39mdict\\u001b[39m,\\n\\u001b[0;32m   (...)\\u001b[0m\\n\\u001b[1;32m    537\\u001b[0m     run: Optional[\\u001b[39m\\\"\\u001b[39m\\u001b[39mRun\\u001b[39m\\u001b[39m\\\"\\u001b[39m] \\u001b[39m=\\u001b[39m \\u001b[39mNone\\u001b[39;00m,\\n\\u001b[1;32m    538\\u001b[0m ) \\u001b[39m-\\u001b[39m\\u001b[39m&gt;\\u001b[39m \\u001b[39mNone\\u001b[39;00m:\\n\\u001b[1;32m    539\\u001b[0m     run \\u001b[39m=\\u001b[39m run \\u001b[39mor\\u001b[39;00m \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39m_run\\n\\u001b[0;32m--&gt; 541\\u001b[0m     data \\u001b[39m=\\u001b[39m history_dict_to_json(run, data, step\\u001b[39m=\\u001b[39;49muser_step, ignore_copy_err\\u001b[39m=\\u001b[39;49m\\u001b[39mTrue\\u001b[39;49;00m)\\n\\u001b[1;32m    542\\u001b[0m     data\\u001b[39m.\\u001b[39mpop(\\u001b[39m\\\"\\u001b[39m\\u001b[39m_step\\u001b[39m\\u001b[39m\\\"\\u001b[39m, \\u001b[39mNone\\u001b[39;00m)\\n\\u001b[1;32m    544\\u001b[0m     partial_history \\u001b[39m=\\u001b[39m pb\\u001b[39m.\\u001b[39mPartialHistoryRequest()\\n\\nFile \\u001b[0;32m~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/wandb/sdk/data_types/utils.py:54\\u001b[0m, in \\u001b[0;36mhistory_dict_to_json\\u001b[0;34m(run, payload, step, ignore_copy_err)\\u001b[0m\\n\\u001b[1;32m     50\\u001b[0m         payload[key] \\u001b[39m=\\u001b[39m history_dict_to_json(\\n\\u001b[1;32m     51\\u001b[0m             run, val, step\\u001b[39m=\\u001b[39mstep, ignore_copy_err\\u001b[39m=\\u001b[39mignore_copy_err\\n\\u001b[1;32m     52\\u001b[0m         )\\n\\u001b[1;32m     53\\u001b[0m     \\u001b[39melse\\u001b[39;00m:\\n\\u001b[0;32m---&gt; 54\\u001b[0m         payload[key] \\u001b[39m=\\u001b[39m val_to_json(\\n\\u001b[1;32m     55\\u001b[0m             run, key, val, namespace\\u001b[39m=\\u001b[39;49mstep, ignore_copy_err\\u001b[39m=\\u001b[39;49mignore_copy_err\\n\\u001b[1;32m     56\\u001b[0m         )\\n\\u001b[1;32m     58\\u001b[0m \\u001b[39mreturn\\u001b[39;00m payload\\n\\nFile \\u001b[0;32m~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/wandb/sdk/data_types/utils.py:82\\u001b[0m, in \\u001b[0;36mval_to_json\\u001b[0;34m(run, key, val, namespace, ignore_copy_err)\\u001b[0m\\n\\u001b[1;32m     79\\u001b[0m     val \\u001b[39m=\\u001b[39m wandb\\u001b[39m.\\u001b[39mTable(dataframe\\u001b[39m=\\u001b[39mval)\\n\\u001b[1;32m     81\\u001b[0m \\u001b[39melif\\u001b[39;00m util\\u001b[39m.\\u001b[39mis_matplotlib_typename(typename) \\u001b[39mor\\u001b[39;00m util\\u001b[39m.\\u001b[39mis_plotly_typename(typename):\\n\\u001b[0;32m---&gt; 82\\u001b[0m     val \\u001b[39m=\\u001b[39m Plotly\\u001b[39m.\\u001b[39;49mmake_plot_media(val)\\n\\u001b[1;32m     83\\u001b[0m \\u001b[39melif\\u001b[39;00m \\u001b[39misinstance\\u001b[39m(val, Sequence) \\u001b[39mand\\u001b[39;00m \\u001b[39mall\\u001b[39m(\\u001b[39misinstance\\u001b[39m(v, WBValue) \\u001b[39mfor\\u001b[39;00m v \\u001b[39min\\u001b[39;00m val):\\n\\u001b[1;32m     84\\u001b[0m     \\u001b[39massert\\u001b[39;00m run\\n\\nFile \\u001b[0;32m~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/wandb/sdk/data_types/plotly.py:48\\u001b[0m, in \\u001b[0;36mPlotly.make_plot_media\\u001b[0;34m(cls, val)\\u001b[0m\\n\\u001b[1;32m     46\\u001b[0m     \\u001b[39mif\\u001b[39;00m util\\u001b[39m.\\u001b[39mmatplotlib_contains_images(val):\\n\\u001b[1;32m     47\\u001b[0m         \\u001b[39mreturn\\u001b[39;00m Image(val)\\n\\u001b[0;32m---&gt; 48\\u001b[0m     val \\u001b[39m=\\u001b[39m util\\u001b[39m.\\u001b[39;49mmatplotlib_to_plotly(val)\\n\\u001b[1;32m     49\\u001b[0m \\u001b[39mreturn\\u001b[39;00m \\u001b[39mcls\\u001b[39m(val)\\n\\nFile \\u001b[0;32m~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/wandb/util.py:565\\u001b[0m, in \\u001b[0;36mmatplotlib_to_plotly\\u001b[0;34m(obj)\\u001b[0m\\n\\u001b[1;32m    557\\u001b[0m obj \\u001b[39m=\\u001b[39m ensure_matplotlib_figure(obj)\\n\\u001b[1;32m    558\\u001b[0m tools \\u001b[39m=\\u001b[39m get_module(\\n\\u001b[1;32m    559\\u001b[0m     \\u001b[39m\\\"\\u001b[39m\\u001b[39mplotly.tools\\u001b[39m\\u001b[39m\\\"\\u001b[39m,\\n\\u001b[1;32m    560\\u001b[0m     required\\u001b[39m=\\u001b[39m(\\n\\u001b[0;32m   (...)\\u001b[0m\\n\\u001b[1;32m    563\\u001b[0m     ),\\n\\u001b[1;32m    564\\u001b[0m )\\n\\u001b[0;32m--&gt; 565\\u001b[0m \\u001b[39mreturn\\u001b[39;00m tools\\u001b[39m.\\u001b[39;49mmpl_to_plotly(obj)\\n\\nFile \\u001b[0;32m~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/plotly/tools.py:112\\u001b[0m, in \\u001b[0;36mmpl_to_plotly\\u001b[0;34m(fig, resize, strip_style, verbose)\\u001b[0m\\n\\u001b[1;32m    110\\u001b[0m \\u001b[39mif\\u001b[39;00m matplotlylib:\\n\\u001b[1;32m    111\\u001b[0m     renderer \\u001b[39m=\\u001b[39m matplotlylib\\u001b[39m.\\u001b[39mPlotlyRenderer()\\n\\u001b[0;32m--&gt; 112\\u001b[0m     matplotlylib\\u001b[39m.\\u001b[39;49mExporter(renderer)\\u001b[39m.\\u001b[39;49mrun(fig)\\n\\u001b[1;32m    113\\u001b[0m     \\u001b[39mif\\u001b[39;00m resize:\\n\\u001b[1;32m    114\\u001b[0m         renderer\\u001b[39m.\\u001b[39mresize()\\n\\nFile \\u001b[0;32m~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/plotly/matplotlylib/mplexporter/exporter.py:51\\u001b[0m, in \\u001b[0;36mExporter.run\\u001b[0;34m(self, fig)\\u001b[0m\\n\\u001b[1;32m     49\\u001b[0m     \\u001b[39mimport\\u001b[39;00m \\u001b[39mmatplotlib\\u001b[39;00m\\u001b[39m.\\u001b[39;00m\\u001b[39mpyplot\\u001b[39;00m \\u001b[39mas\\u001b[39;00m \\u001b[39mplt\\u001b[39;00m\\n\\u001b[1;32m     50\\u001b[0m     plt\\u001b[39m.\\u001b[39mclose(fig)\\n\\u001b[0;32m---&gt; 51\\u001b[0m \\u001b[39mself\\u001b[39;49m\\u001b[39m.\\u001b[39;49mcrawl_fig(fig)\\n\\nFile \\u001b[0;32m~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/plotly/matplotlylib/mplexporter/exporter.py:118\\u001b[0m, in \\u001b[0;36mExporter.crawl_fig\\u001b[0;34m(self, fig)\\u001b[0m\\n\\u001b[1;32m    115\\u001b[0m \\u001b[39mwith\\u001b[39;00m \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39mrenderer\\u001b[39m.\\u001b[39mdraw_figure(fig\\u001b[39m=\\u001b[39mfig,\\n\\u001b[1;32m    116\\u001b[0m                                props\\u001b[39m=\\u001b[39mutils\\u001b[39m.\\u001b[39mget_figure_properties(fig)):\\n\\u001b[1;32m    117\\u001b[0m     \\u001b[39mfor\\u001b[39;00m ax \\u001b[39min\\u001b[39;00m fig\\u001b[39m.\\u001b[39maxes:\\n\\u001b[0;32m--&gt; 118\\u001b[0m         \\u001b[39mself\\u001b[39;49m\\u001b[39m.\\u001b[39;49mcrawl_ax(ax)\\n\\nFile \\u001b[0;32m~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/plotly/matplotlylib/mplexporter/exporter.py:123\\u001b[0m, in \\u001b[0;36mExporter.crawl_ax\\u001b[0;34m(self, ax)\\u001b[0m\\n\\u001b[1;32m    120\\u001b[0m \\u001b[39mdef\\u001b[39;00m \\u001b[39mcrawl_ax\\u001b[39m(\\u001b[39mself\\u001b[39m, ax):\\n\\u001b[1;32m    121\\u001b[0m     \\u001b[39m\\\"\\\"\\\"Crawl the axes and process all elements within\\\"\\\"\\\"\\u001b[39;00m\\n\\u001b[1;32m    122\\u001b[0m     \\u001b[39mwith\\u001b[39;00m \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39mrenderer\\u001b[39m.\\u001b[39mdraw_axes(ax\\u001b[39m=\\u001b[39max,\\n\\u001b[0;32m--&gt; 123\\u001b[0m                                  props\\u001b[39m=\\u001b[39mutils\\u001b[39m.\\u001b[39;49mget_axes_properties(ax)):\\n\\u001b[1;32m    124\\u001b[0m         \\u001b[39mfor\\u001b[39;00m line \\u001b[39min\\u001b[39;00m ax\\u001b[39m.\\u001b[39mlines:\\n\\u001b[1;32m    125\\u001b[0m             \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39mdraw_line(ax, line)\\n\\nFile \\u001b[0;32m~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/plotly/matplotlylib/mplexporter/utils.py:272\\u001b[0m, in \\u001b[0;36mget_axes_properties\\u001b[0;34m(ax)\\u001b[0m\\n\\u001b[1;32m    264\\u001b[0m \\u001b[39mdef\\u001b[39;00m \\u001b[39mget_axes_properties\\u001b[39m(ax):\\n\\u001b[1;32m    265\\u001b[0m     props \\u001b[39m=\\u001b[39m {\\u001b[39m'\\u001b[39m\\u001b[39maxesbg\\u001b[39m\\u001b[39m'\\u001b[39m: export_color(ax\\u001b[39m.\\u001b[39mpatch\\u001b[39m.\\u001b[39mget_facecolor()),\\n\\u001b[1;32m    266\\u001b[0m              \\u001b[39m'\\u001b[39m\\u001b[39maxesbgalpha\\u001b[39m\\u001b[39m'\\u001b[39m: ax\\u001b[39m.\\u001b[39mpatch\\u001b[39m.\\u001b[39mget_alpha(),\\n\\u001b[1;32m    267\\u001b[0m              \\u001b[39m'\\u001b[39m\\u001b[39mbounds\\u001b[39m\\u001b[39m'\\u001b[39m: ax\\u001b[39m.\\u001b[39mget_position()\\u001b[39m.\\u001b[39mbounds,\\n\\u001b[1;32m    268\\u001b[0m              \\u001b[39m'\\u001b[39m\\u001b[39mdynamic\\u001b[39m\\u001b[39m'\\u001b[39m: ax\\u001b[39m.\\u001b[39mget_navigate(),\\n\\u001b[1;32m    269\\u001b[0m              \\u001b[39m'\\u001b[39m\\u001b[39maxison\\u001b[39m\\u001b[39m'\\u001b[39m: ax\\u001b[39m.\\u001b[39maxison,\\n\\u001b[1;32m    270\\u001b[0m              \\u001b[39m'\\u001b[39m\\u001b[39mframe_on\\u001b[39m\\u001b[39m'\\u001b[39m: ax\\u001b[39m.\\u001b[39mget_frame_on(),\\n\\u001b[1;32m    271\\u001b[0m              \\u001b[39m'\\u001b[39m\\u001b[39mpatch_visible\\u001b[39m\\u001b[39m'\\u001b[39m:ax\\u001b[39m.\\u001b[39mpatch\\u001b[39m.\\u001b[39mget_visible(),\\n\\u001b[0;32m--&gt; 272\\u001b[0m              \\u001b[39m'\\u001b[39m\\u001b[39maxes\\u001b[39m\\u001b[39m'\\u001b[39m: [get_axis_properties(ax\\u001b[39m.\\u001b[39;49mxaxis),\\n\\u001b[1;32m    273\\u001b[0m                       get_axis_properties(ax\\u001b[39m.\\u001b[39myaxis)]}\\n\\u001b[1;32m    275\\u001b[0m     \\u001b[39mfor\\u001b[39;00m axname \\u001b[39min\\u001b[39;00m [\\u001b[39m'\\u001b[39m\\u001b[39mx\\u001b[39m\\u001b[39m'\\u001b[39m, \\u001b[39m'\\u001b[39m\\u001b[39my\\u001b[39m\\u001b[39m'\\u001b[39m]:\\n\\u001b[1;32m    276\\u001b[0m         axis \\u001b[39m=\\u001b[39m \\u001b[39mgetattr\\u001b[39m(ax, axname \\u001b[39m+\\u001b[39m \\u001b[39m'\\u001b[39m\\u001b[39maxis\\u001b[39m\\u001b[39m'\\u001b[39m)\\n\\nFile \\u001b[0;32m~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/plotly/matplotlylib/mplexporter/utils.py:236\\u001b[0m, in \\u001b[0;36mget_axis_properties\\u001b[0;34m(axis)\\u001b[0m\\n\\u001b[1;32m    233\\u001b[0m     props[\\u001b[39m'\\u001b[39m\\u001b[39mfontsize\\u001b[39m\\u001b[39m'\\u001b[39m] \\u001b[39m=\\u001b[39m \\u001b[39mNone\\u001b[39;00m\\n\\u001b[1;32m    235\\u001b[0m \\u001b[39m# Get associated grid\\u001b[39;00m\\n\\u001b[0;32m--&gt; 236\\u001b[0m props[\\u001b[39m'\\u001b[39m\\u001b[39mgrid\\u001b[39m\\u001b[39m'\\u001b[39m] \\u001b[39m=\\u001b[39m get_grid_style(axis)\\n\\u001b[1;32m    238\\u001b[0m \\u001b[39m# get axis visibility\\u001b[39;00m\\n\\u001b[1;32m    239\\u001b[0m props[\\u001b[39m'\\u001b[39m\\u001b[39mvisible\\u001b[39m\\u001b[39m'\\u001b[39m] \\u001b[39m=\\u001b[39m axis\\u001b[39m.\\u001b[39mget_visible()\\n\\nFile \\u001b[0;32m~/anaconda3/envs/cyberhawk_ai/lib/python3.10/site-packages/plotly/matplotlylib/mplexporter/utils.py:246\\u001b[0m, in \\u001b[0;36mget_grid_style\\u001b[0;34m(axis)\\u001b[0m\\n\\u001b[1;32m    244\\u001b[0m \\u001b[39mdef\\u001b[39;00m \\u001b[39mget_grid_style\\u001b[39m(axis):\\n\\u001b[1;32m    245\\u001b[0m     gridlines \\u001b[39m=\\u001b[39m axis\\u001b[39m.\\u001b[39mget_gridlines()\\n\\u001b[0;32m--&gt; 246\\u001b[0m     \\u001b[39mif\\u001b[39;00m axis\\u001b[39m.\\u001b[39;49m_gridOnMajor \\u001b[39mand\\u001b[39;00m \\u001b[39mlen\\u001b[39m(gridlines) \\u001b[39m&gt;\\u001b[39m \\u001b[39m0\\u001b[39m:\\n\\u001b[1;32m    247\\u001b[0m         color \\u001b[39m=\\u001b[39m export_color(gridlines[\\u001b[39m0\\u001b[39m]\\u001b[39m.\\u001b[39mget_color())\\n\\u001b[1;32m    248\\u001b[0m         alpha \\u001b[39m=\\u001b[39m gridlines[\\u001b[39m0\\u001b[39m]\\u001b[39m.\\u001b[39mget_alpha()\\n\\n\\u001b[0;31mAttributeError\\u001b[0m: 'XAxis' object has no attribute '_gridOnMajor'\"\n}\n</code></pre>\n<p>Any suggestions are welcomed,<br>\nThanks <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-09T20:00:00.494Z",
				"Answer_body": "<p>Hi Kostas!</p>\n<p>Very Strange, using your code on my machine, I don\u2019t get the same error.</p>\n<p>Are you running this in google collab?<br>\nAlso just to double check is this the exact code you are using?<br>\nAlso, also, can you see if you are running into the exact same issue if wandb is disabled/commented out?</p>\n<p>Cheers,<br>\nArtsiom</p>\n<p><img src=\"https://weightsandbiases.zendesk.com/attachments/token/dZf5iFTNBqk15pt4FISNCaj9y/?name=image.png\" alt=\"\" role=\"presentation\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-10T16:35:48.881Z",
				"Answer_body": "<p>Hi Artsiom,<br>\nI\u2019m running on my local environment.<br>\nYes, that\u2019s the exact code that I\u2019m using.<br>\nI\u2019ve tried without Wandb and it works fine.</p>\n<p>I\u2019ve also tried today the same code with Wandb and works as expected :S , very weird \u2026</p>\n<p>Thanks,<br>\nKostas</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-12T21:21:17.641Z",
				"Answer_body": "<p>Hi Kostas,</p>\n<p>That is very strange :0<br>\nBut now that it works fine, you are not seeing any errors that are popping up anymore?</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-11T16:35:51.528Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb truncates stdout in run logs?",
		"Question_link": "https://community.wandb.ai/t/wandb-truncates-stdout-in-run-logs/3661",
		"Question_created_time": "2023-01-09T20:10:45.945Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 75,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m running a personal wandb server using Docker.  I have a script that prints to stdout:</p>\n<pre><code class=\"lang-auto\">Loaded 5000 training images.\nLoaded 1000 test images.\n59.3% of training images contain cats.\n57.7% of test images contain cats.\n***********************************************\nepoch: 0\n</code></pre>\n<p>\u2026 and-so-on.  However, when I view the run logs in wandb, I get the following:</p>\n<pre><code class=\"lang-auto\">5000 training images.\n1000 test images.\nof training images contain cats.\nof test images contain cats.\n***********************************************\n0\n</code></pre>\n<p>At first, I thought the output was being \u201ccovered\u201d by the sidebar, but a quick inspection of the page source shows that this is really what\u2019s being captured.  Any thoughts?  Is wandb looking for some kind of formatted log output?</p>\n<p>Thanks in advance,<br>\nTim</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-10T00:34:07.671Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tshead\">@tshead</a> , thank you for writing in and reporting this. This is a known bug that we are actively investigating where the logs first characters are \u201ccut off\u201d. Our apologies for the inconvenience this causes. I\u2019ve added your info  to our internal tracking tool and will update you once a fix is in place. Please let me know if there is anything else I could assist you with in the meantime.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-10T01:56:50.481Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> : Thanks for the quick response, good to hear it isn\u2019t just me.</p>\n<p>Cheers,<br>\nTim</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-11T01:57:05.230Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-04-28T18:56:53.600Z",
				"Answer_body": "<p>Hi Timothy,</p>\n<p>I wanted to let you know that the issue you were experience with local server logs first few characters being cut off has been fixed as our latest server release. Please do reach out again anytime we could be of help.</p>\n<p>Regards,<br>\nMohammad</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Line chart with config item on x-axis, multiple runs per line",
		"Question_link": "https://community.wandb.ai/t/line-chart-with-config-item-on-x-axis-multiple-runs-per-line/3548",
		"Question_created_time": "2022-12-14T16:50:43.610Z",
		"Question_answer_count": 11,
		"Question_score_count": 0,
		"Question_view_count": 288,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have several finetuning runs evaluating checkpoints of other pretraining runs. Pretraining run A creates checkpoints A-1 and A-2 in epochs 1 and 2. Now I have a finetuning run for each checkpoint of A. I would like to create a chart with on the X-axis the pretraining epoch (I can get this from a config file), not the finetuning epoch, and on the Y-axis a test metric I compute once at the end of every finetuning run. The above is easy to get with a scatter plot, but I would like to be able to group finetuning runs by the pretraining run (so A, that has a number of separate finetuning runs associated with it, not the pretraining checkpoint A-1 for which there is 1 finetuning run)(I have this info also in a config file), so that each line in the resulting line chart has points from different finetuning runs corresponding to different epochs of the same pretraining runs. Is that possible, to group runs in a line chart?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-19T20:24:21.851Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/rubencart\">@rubencart</a> thank you for writing in! In the project\u2019s workspace if you edit your line chart (<img src=\"https://emoji.discourse-cdn.com/twitter/pencil2.png?v=12\" title=\":pencil2:\" class=\"emoji\" alt=\":pencil2:\" loading=\"lazy\" width=\"20\" height=\"20\">  icon) there is a <code>Grouping</code> tab and once you toggle on the Runs option there you should be able to see the <code>Group by</code> drop-down menu with your parameters. Would this work for you? if that\u2019s not what you\u2019re looking for, would it be please possible to share a minimal code snippet that mimics such a workspace, or attach a screenshot of the current plot you have?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-20T08:54:08.151Z",
				"Answer_body": "<p>I don\u2019t immediately know how I would come up with a code snippet.<br>\nBut what you suggest does not work. I can add a scatter plot with the epoch of the pretraining checkpoint (stored in hyperparameter) on the x-axis, and my test metric on the y-axis, but there is no \u2018Grouping\u2019 tab (see screenshot 1).<br>\nAlternatively, I can start a line plot, which has a Grouping tab, but it does not allow to put my hyperparameter denoting the pretraining epoch on the x-axis (note, this are not the epoch values from finetuning runs in the current wandb project, they are epoch numbers from the pretraining (other project) checkpoints that runs in this project (finetuning) initialized their weights from). Additionally, when I select a test metric (instead of a val metric) for the y-axis, the web app automatically turns the chart into a bar chart since all runs only logged 1 value for that metric. See screenshot 2.<br>\nThanks for your help!<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/d920489f994b5f3ba1978996ffefe0fc6e9d7199.png\" data-download-href=\"/uploads/short-url/uYMMgNDLzcZQwa3pULu8oBqGiM1.png?dl=1\" title=\"Screenshot-1\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/d920489f994b5f3ba1978996ffefe0fc6e9d7199_2_690x186.png\" alt=\"Screenshot-1\" data-base62-sha1=\"uYMMgNDLzcZQwa3pULu8oBqGiM1\" width=\"690\" height=\"186\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/d920489f994b5f3ba1978996ffefe0fc6e9d7199_2_690x186.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/d920489f994b5f3ba1978996ffefe0fc6e9d7199_2_1035x279.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/d920489f994b5f3ba1978996ffefe0fc6e9d7199_2_1380x372.png 2x\" data-dominant-color=\"F9F9F9\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot-1</span><span class=\"informations\">1788\u00d7484 128 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-20T08:54:53.747Z",
				"Answer_body": "<p>And screenshot 2:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/9/9e222276c1263035c81df841e337014775b55a4e.png\" data-download-href=\"/uploads/short-url/myUzyfEvhOJdV5zS7gxOXBzqPcq.png?dl=1\" title=\"Screenshot-2\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/9/9e222276c1263035c81df841e337014775b55a4e_2_690x185.png\" alt=\"Screenshot-2\" data-base62-sha1=\"myUzyfEvhOJdV5zS7gxOXBzqPcq\" width=\"690\" height=\"185\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/9/9e222276c1263035c81df841e337014775b55a4e_2_690x185.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/9/9e222276c1263035c81df841e337014775b55a4e_2_1035x277.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/9/9e222276c1263035c81df841e337014775b55a4e_2_1380x370.png 2x\" data-dominant-color=\"F8F8F8\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot-2</span><span class=\"informations\">1783\u00d7480 154 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-23T16:40:24.395Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/rubencart\">@rubencart</a> thanks for the screenshots and the additional information. Just to confirm, to see if that\u2019s possible would it be correct that you want to plot on the x axis <code>finetune.pretrained_epoch</code> and on y axis the <code>test_id_maj_vote_f1_macro</code>? Do the test metrics have history values as the val metric? that might explain why you\u2019re seeing a bar instead of the values per step.</p>\n<p>Also regarding pretrained/finetuning projects, are these values you want to plot logged in this project? as it won\u2019t be possible in a project workspace to get the values from another project (pre-training). Unless you have logged these values in the finetuning project. The only area where you could have <a href=\"https://docs.wandb.ai/guides/reports/cross-project-reports\">multiple projects</a> would be in the Reports.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-27T09:59:13.360Z",
				"Answer_body": "<p>That\u2019s correct indeed. They don\u2019t have history values. In the plot that I want, one line would consist of points corresponding to different finetuning runs (different <code>finetune.pretrained_epoch</code>) starting from different checkpoints (<code>finetune.pretrained_epoch</code>) of the same pretraining run (the name of the pretraining run is also saved in a hyperparameter to which I have access). The y-values would indeed be <code>test_id_maj_vote_f1_macro</code> or a similar metric, of which I only have 1 value per finetuning run.</p>\n<p>All values I want to plot are logged or saved as hyperparameter in this current finetuning project.</p>\n<p>Just to be clear:</p>\n<ul>\n<li>I have some pretraining runs, e.g. A, B, with different checkpoints per pretraining run A.1, A.2, B.1, B.2</li>\n<li>I have, in the current wandb project, several finetuning runs, e.g. f, g, h, k.</li>\n<li>Each finetuning run starts from a pretraining checkpoint. The name of the pretraining run and the epoch number of the checkpoint are both saved in hyperparameters of the finetuning run: <code>finetune.all_backbone_ckpts_in_dir</code> and <code>finetune.pretrained_epoch</code> resp.</li>\n<li>All finetuning runs log a number of test metrics, a single time at the end of their training, e.g. <code>test_id_maj_vote_f1_macro</code> (these metrics don\u2019t have a history, I have val metrics with a history too but these I am not interested in for this plot).</li>\n<li>Let\u2019s say finetuning run f starts from checkpoint A.1 (so <code>finetune.all_backbone_ckpts_in_dir == A</code> and <code>finetune.pretrained_epoch == 1</code>), g from A.2, h from B.1 and k from B.2.</li>\n<li>Now what I want is a line plot where one line represents finetuning runs f and g, and hence pretraining run A, and connects the point (x: <code>finetune.pretrained_epoch == 1</code>, y: <code>test_id_maj_vote_f1_macro</code> (logged by f)) with (x: <code>finetune.pretrained_epoch == 2</code>, y: <code>test_id_maj_vote_f1_macro</code> (logged by g)). The second line connects (x: <code>finetune.pretrained_epoch == 1</code>, y: <code>test_id_maj_vote_f1_macro</code> (logged by h)) and (x: <code>finetune.pretrained_epoch == 2</code>, y: <code>test_id_maj_vote_f1_macro</code> (logged by k)).</li>\n<li>Just to repeat: finetuning run f has in its hyperparameters saved the name of its pretraining run A and the pretraining epoch 1, and it logged the test metric we want to plot.</li>\n<li>The finetuning epochs are irrelevant, what I want to plot is the evolution of the <code>test_id_maj_vote_f1_macro</code>, obtained by finetuning on a downstream task, over the course of pretraining (to see e.g. the optimal/minimal necessary number of pretraining epochs).</li>\n</ul>\n<p>If either the existing scatter plot interface would allow to group runs according to a hyperparameter (and connect the groups with a line), or if the existing line plot interface would allow to put a hyperparameter on the x-axis and would not automatically turn into a bar chart for metrics without a history, this would be very easy to achieve I guess? <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><br>\nLet me know if anything is unclear.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-27T15:11:39.960Z",
				"Answer_body": "<p>For the record, these are the types of plots I\u2019m interested in. The different dots on 1 line each correspond to an entire finetuning run.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/5/51f06ca51bf4562c22fa2a12ccf24cf22407c5da.png\" data-download-href=\"/uploads/short-url/bGRMtZsyN9LMOOkfHzJb4s40my6.png?dl=1\" title=\"test_id_bin_maj_vote_f1_macro_ft_2\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/51f06ca51bf4562c22fa2a12ccf24cf22407c5da_2_690x348.png\" alt=\"test_id_bin_maj_vote_f1_macro_ft_2\" data-base62-sha1=\"bGRMtZsyN9LMOOkfHzJb4s40my6\" width=\"690\" height=\"348\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/51f06ca51bf4562c22fa2a12ccf24cf22407c5da_2_690x348.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/51f06ca51bf4562c22fa2a12ccf24cf22407c5da_2_1035x522.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/5/51f06ca51bf4562c22fa2a12ccf24cf22407c5da.png 2x\" data-dominant-color=\"FBFBFB\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">test_id_bin_maj_vote_f1_macro_ft_2</span><span class=\"informations\">1187\u00d7600 52.3 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-27T15:13:04.477Z",
				"Answer_body": "<p>2nd example. Now the lines represent groups of pretraining runs and hence each dot represents a number of finetuning runs.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/b/be50ee7b0e22e2fed75b0ac57b3511652388d7a2.png\" data-download-href=\"/uploads/short-url/r9C75ZYKgOhHHv5wMYMRAYCEVvs.png?dl=1\" title=\"lt_test_id_maj_vote_f1_macro_frz\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/be50ee7b0e22e2fed75b0ac57b3511652388d7a2_2_690x295.png\" alt=\"lt_test_id_maj_vote_f1_macro_frz\" data-base62-sha1=\"r9C75ZYKgOhHHv5wMYMRAYCEVvs\" width=\"690\" height=\"295\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/be50ee7b0e22e2fed75b0ac57b3511652388d7a2_2_690x295.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/be50ee7b0e22e2fed75b0ac57b3511652388d7a2_2_1035x442.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/be50ee7b0e22e2fed75b0ac57b3511652388d7a2_2_1380x590.png 2x\" data-dominant-color=\"F9F9F3\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">lt_test_id_maj_vote_f1_macro_frz</span><span class=\"informations\">1400\u00d7600 69.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-03T08:49:55.779Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a> any thoughts?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-04T21:22:40.755Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/rubencart\">@rubencart</a> , following up on this for Thanos as he is out of office. I reviewed the thread, and at this time, it isn\u2019t currently doable for you to be that  selective with which data points and from which runs are plotted within a line. The following options are available to produce the desired plots.</p>\n<ul>\n<li>\n<p>After completing your  training runs, log specific data points of interest to a table and use a weave panel to plot the individual points as lines<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/1/1e6460ff5e4e4dd0cc0e1f66b712d3a744adb698.png\" alt=\"weave\" data-base62-sha1=\"4kRnRAge9HWnd4NgLHv8oPQnaOI\" width=\"285\" height=\"295\"></p>\n</li>\n<li>\n<p>Produce the line plot outside of wandb using matplot lib and log the graphs as images or charts, more on this <a href=\"https://docs.wandb.ai/guides/track/log/plots#matplotlib-and-plotly-plots\">here</a></p>\n</li>\n<li>\n<p>As wandb plots is built over Vega, you could attempt to produce a <a href=\"https://docs.wandb.ai/ref/app/features/custom-charts?q=vega\">custom chart</a> with the desired result.</p>\n</li>\n</ul>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-09T11:16:19.008Z",
				"Answer_body": "<p>Okay, thank you for the suggestions!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-10T11:17:10.456Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Tensorboard not logged correctly on wandb run",
		"Question_link": "https://community.wandb.ai/t/tensorboard-not-logged-correctly-on-wandb-run/3652",
		"Question_created_time": "2023-01-09T10:46:58.845Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 69,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,<br>\nI have been using wandb for a while now, but since last week  the training runs on W&amp;B  only show the validation losses and not the training losses. If I open tensorboard from the W&amp;B run page, I also can only see the validation stats, but if I open tensoboard from terminal independently from W&amp;B  the both training and validation stats are shown correctly.<br>\nI am not sure of what\u2019s going on, as I haven\u2019t changed my workflow at all, and since I don\u2019t get any error message I am not sure of how to debug the problem.<br>\nIf it helps, the folder structure of my project looks like this:</p>\n<pre><code class=\"lang-auto\">-main_folder\n    -training_notebook\n    -output     (folder)\n        -run_name_folder\n        -events.out.tfevents.1673259721.ip-.....   (tensorboard file for training)\n        -validation     (folder)\n            -events.out.tfevents.1673259726.ip-.... (tensorboard file for validation)\n</code></pre>\n<p>and I run the training with the following code:</p>\n<pre><code class=\"lang-auto\">with wandb.init(name=run_name,\n                project=project_name, \n                id=run_id,\n                job_type=\"training_job\",\n                sync_tensorboard=True) as run:\n</code></pre>\n<p>Any idea of why only the validation losses are logged on W&amp;B?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-11T20:57:57.677Z",
				"Answer_body": "<p>Hi Francesco, thank you for writing in! Can you tell me if you had done anything different between when it was showing the training losses where not appearing. For example, have you upgraded or changed your environment where you run your script?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-17T22:21:23.583Z",
				"Answer_body": "<p>Hi Francesco, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-10T10:47:08.648Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to get the sequential id for the experiment",
		"Question_link": "https://community.wandb.ai/t/how-to-get-the-sequential-id-for-the-experiment/3619",
		"Question_created_time": "2022-12-29T20:08:11.999Z",
		"Question_answer_count": 7,
		"Question_score_count": 1,
		"Question_view_count": 298,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi I am trying to name the experiment as per my project as well as a sequential id, for example my Project name is Semantic Segmentation and I have 3 runs, I want to name them something like SEM-1,SEM-2 and so on,<br>\nEssentially I need to log the new experiment by getting the previous experiment id and incrementing it by 1, if it is the first experiment then just start by first three letters of project and then append 1 and so on</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-29T20:48:38.359Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hafizprecisionai\">@hafizprecisionai</a> , thank you for writing in. <code>wandb.init()</code> allows you to assign unique names to your experiments via the <code>name</code> <a href=\"https://docs.wandb.ai/ref/python/init\">argument</a>. You can additionally assign unique run ids to an experiment run using the <code>id</code> argument. Hope this helps and please let me know if you have any questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-29T20:48:50.159Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hafizprecisionai\">@hafizprecisionai</a> , thank you for writing in. <code>wandb.init()</code> allows you to assign unique names to your experiments via the <code>name</code> argument. You can additionally assign unique run ids to an experiment run using the <code>id</code> argument. Hope this helps and please let me know if you have any questions.</p>\n<p>[Discourse post]</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-29T21:24:26.153Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> , Yes I know that, but what I want is to increment the ids based on what is already logged in wandb</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-30T00:16:43.533Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hafizprecisionai\">@hafizprecisionai</a> , thanks for clarifying. One way to accomplish this is to use our<a href=\"https://docs.wandb.ai/guides/track/public-api-guide#querying-multiple-runs\"> api</a>. You could for example verify the current run ids / names of runs to a project and implement your own logic from there for incrementing.</p>\n<pre><code class=\"lang-auto\">api = wandb.Api()\nentity, project = \"&lt;entity&gt;\", \"&lt;project&gt;\"  # set to your entity and project \nruns = api.runs(entity + \"/\" + project)\n.....\n#Check Run Ids/names `(run.id/run.name)` of fetched runs and increment accordingly\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-04T06:26:11.715Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hafizprecisionai\">@hafizprecisionai</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-06T17:33:06.432Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> Thank you Mohammad Bakir, I was able to solve with the given instruction. Really appreciate your help in this regard</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-07T17:34:02.418Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb sweeep training error",
		"Question_link": "https://community.wandb.ai/t/wandb-sweeep-training-error/3636",
		"Question_created_time": "2023-01-04T05:02:23.979Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 122,
		"Question_has_accepted_answer": false,
		"Question_body": "<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/b/b2b7478189f41aaca4f1c7ba31c9ab544d26e8e9.png\" data-download-href=\"/uploads/short-url/puZF9VtzGIPQ8W24OigDTk9RKiJ.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/b/b2b7478189f41aaca4f1c7ba31c9ab544d26e8e9.png\" alt=\"image\" data-base62-sha1=\"puZF9VtzGIPQ8W24OigDTk9RKiJ\" width=\"690\" height=\"413\" data-dominant-color=\"262727\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1010\u00d7605 29.4 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>this error happened while I was training and I know nothing about this. Help me on this :))</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-06T12:03:03.761Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sukhbatd2\">@sukhbatd2</a>,</p>\n<p>Looks like you are using HuggingFace\u2019s WandbCallback() API. A huggingface <code>Trainer</code> expects a <strong>list of Callbacks</strong>, not an individual callback.</p>\n<p>Seeing the error message, simply wrapping the <code>WandbCallback()</code> in brackets as <code>[WandbCallback()]</code> should fix the error.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-11T14:58:39.192Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sukhbatd2\">@sukhbatd2</a>,<br>\nI hope you were able to successfully resolve the issue. If you have any other questions, please do not hesitate to reach out.<br>\nWe are closing this thread now, but please feel free to contact us again if you run into any more issues.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-07T12:03:36.657Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb sweep & Hydra",
		"Question_link": "https://community.wandb.ai/t/wandb-sweep-hydra/3637",
		"Question_created_time": "2023-01-04T15:41:24.792Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 149,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi All,</p>\n<p>How are you?</p>\n<p>My colleague Soumik Rakshit directed me to you for help. I\u2019m trying to launch a sweep with hydra in which I would like to control two parameters which are already included in the yml file.</p>\n<p>I tried to follow <a href=\"https://wandb.ai/adrishd/hydra-example/reports/Configuring-W-B-Projects-with-Hydra--VmlldzoxNTA2MzQw\">this tutorial</a> but without success. What I\u2019m trying to do is to be able to both pass arg parse arguments using \u201c\u2013\u201d in addition to config parameters editing.</p>\n<p>Can we schedule a quick session for support?</p>\n<p>Cheers,</p>\n<p>Aviv</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-05T14:54:41.487Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/avivsham\">@avivsham</a>, thanks for writing in! I replied you in the chat and this seems to be solved so I\u2019ll close this for now. Feel free to ping me here if you have any other question related to this!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-05T14:56:36.737Z",
				"Answer_body": "<p>This request was closed and merged into request <span class=\"hashtag\">#38943</span> \u201cConversation with Aviv Navon\u201d.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-06T14:54:44.376Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Export grouped runs individually as CSV",
		"Question_link": "https://community.wandb.ai/t/export-grouped-runs-individually-as-csv/3571",
		"Question_created_time": "2022-12-19T14:21:28.409Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 328,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I am new to using wandb. I have a project that contain many groups, each group has multiple runs. I want to export the metrics of each single run in a group to a CSV file but it only allows me to export the statistics of  the group.</p>\n<p>How can export each run from a group to CSV?</p>\n<p>Thanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-19T18:41:50.161Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ahmedramly\">@ahmedramly</a>!</p>\n<p>Just to confirm your intent here - you would like each individual group as a new CSV file, correct?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-19T19:07:33.548Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a></p>\n<p>Not exactly, I would like to export a single group or multiple groups but instead of exporting a single metric \u201caccuracy for example\u201d for the group, I want to export the metrics of all the runs included in the group. For some further statistical analysis for instance.</p>\n<p>Thanks in advance</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-05T09:14:26.566Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ahmedramly\">@ahmedramly</a>,</p>\n<p>Got it. The best way to do this would be to use our API to import data: <a href=\"https://docs.wandb.ai/ref/python/public-api\" class=\"inline-onebox\">Import &amp; Export API - Documentation</a>.</p>\n<p>Specifically, the <a href=\"https://docs.wandb.ai/ref/python/public-api/api#runs\">runs</a> method of our API can be used to filter runs based on your requirements and then move that data to a  Pandas dataframe to export as a CSV</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-10T13:32:12.756Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ahmedramly\">@ahmedramly</a>,<br>\nJust wanted to check if you have had a chance to try out the API solution I suggested? If you have any further questions, please don\u2019t hesitate to reach out.<br>\nBest,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-11T15:00:39.619Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ahmedramly\">@ahmedramly</a>,<br>\nIt seems like you may have moved on from this issue, so I\u2019m going to go ahead and close this thread. If you have any further questions or run into any other issues, please don\u2019t hesitate to reach out.<br>\nThanks again for your time,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-06T09:14:35.466Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Account Storage and Artifacts not being freed",
		"Question_link": "https://community.wandb.ai/t/account-storage-and-artifacts-not-being-freed/3624",
		"Question_created_time": "2022-12-31T11:17:51.417Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 162,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi!</p>\n<p>I have the same issue - <a href=\"https://community.wandb.ai/t/account-storage-not-being-freed/1375\" class=\"inline-onebox\">Account storage not being freed?</a>.</p>\n<p>Is this bug still present?</p>\n<p>profile - <a href=\"https://wandb.ai/ramang\" class=\"inline-onebox\">Weights &amp; Biases</a></p>\n<p>Thanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-01-05T01:01:53.319Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ramang\">@ramang</a> , happy to help. I checked your usage page and the data has been cleared, see below.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/b/b9e7b07e91d6c3f440b5d88aba2f755a76fc932c.png\" data-download-href=\"/uploads/short-url/qwAIUoXogVZZuGKMRrc4GetHze4.png?dl=1\" title=\"Storage\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b9e7b07e91d6c3f440b5d88aba2f755a76fc932c_2_517x199.png\" alt=\"Storage\" data-base62-sha1=\"qwAIUoXogVZZuGKMRrc4GetHze4\" width=\"517\" height=\"199\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b9e7b07e91d6c3f440b5d88aba2f755a76fc932c_2_517x199.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b9e7b07e91d6c3f440b5d88aba2f755a76fc932c_2_775x298.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b9e7b07e91d6c3f440b5d88aba2f755a76fc932c_2_1034x398.png 2x\" data-dominant-color=\"F6F6F6\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Storage</span><span class=\"informations\">1167\u00d7450 28.4 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div>. It may take sometime for the deletion job to process. Please let me know if you encountering any issues on your end.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-06T01:02:51.405Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Failure to upload data after run",
		"Question_link": "https://community.wandb.ai/t/failure-to-upload-data-after-run/3612",
		"Question_created_time": "2022-12-28T11:16:48.345Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 263,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I have several runs that upon termination are getting stuck on the following error (unable to copy as text due to the rotating \u201c|\u201d sign):</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/ae27b992b80ee351ee93649b5d64e097b02af05a.png\" data-download-href=\"/uploads/short-url/oQEbMyZj2EOLrZlOJ30i5nPRdlE.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/ae27b992b80ee351ee93649b5d64e097b02af05a_2_690x53.png\" alt=\"image\" data-base62-sha1=\"oQEbMyZj2EOLrZlOJ30i5nPRdlE\" width=\"690\" height=\"53\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/ae27b992b80ee351ee93649b5d64e097b02af05a_2_690x53.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/ae27b992b80ee351ee93649b5d64e097b02af05a.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/ae27b992b80ee351ee93649b5d64e097b02af05a.png 2x\" data-dominant-color=\"1A2015\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">843\u00d765 14 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Any ideas on how to fix without stopping my run?</p>\n<p>Edit: I checked the <code>debug-internal.log</code> and it seems the below error message pops up.<br>\nAdditional details -<br>\n(1) The server uploading the data is in a private network (.technion.ac.il)<br>\n(2) Unlike other runs that do succeed in the meantime, here I upload a video using:</p>\n<pre><code class=\"lang-auto\">wandb.log({\"video\": wandb.Video(all_images, fps=4, format=\"mp4\")})\n</code></pre>\n<p>Error:</p>\n<p>2022-12-28 13:30:28,582 ERROR   Thread-17 :3928098 [internal_api.py:upload_file():1875] upload_file exception <a href=\"https://storage.googleapis.com/wandb-production.appspot.com/tomjur/\" rel=\"noopener nofollow ugc\">https://storage.googleapis.com/wandb-production.appspot.com/tomjur/</a>[my proj]/[current run]/wandb-metadata.json?Expires=1672313428&amp;GoogleAccessId=wandb-production%<a href=\"http://40appspot.gserviceaccount.com\" rel=\"noopener nofollow ugc\">40appspot.gserviceaccount.com</a>&amp;Signature=UKkwGiiPdbchVt3D9Np7HXU91ioIwnWZa5EqapeDR0UFZbjElm2TU5XOF93P2z7%2BnvCTcAEeSkV0tVg3ln0aMTUw%2BYTVSiyBBHncYCZkJcHWS2MDgcA5v9LzjnQ3c5kJoUA5dJwMWNVLebZ8LWkUDKdBSeafEfogP3xE%2FLIDdPtHolpISNJIvEY3JDPOrTJUh9Ge%2Bw3%2BgLgvep9LbG2qEtmj%2FIeeW%2FXqi9wIpfWdDjZ6ZlkGkohYjJPdSGA6GM9RLrglaDVnwmJQXTgyLEIpD9%2FsuKJeBN3U0v6qz1aE2OBoDCK%2Fs4lDEspXy%2FgOqVS6FEHrwQ813rkabFR6dvC1tA%3D%3D: HTTPSConnectionPool(host=\u2018<a href=\"http://storage.googleapis.com\" rel=\"noopener nofollow ugc\">storage.googleapis.com</a>\u2019, port=443): Max retries exceeded with url: /wandb-production.appspot.com/tomjur/[my proj]/[current run]/wandb-metadata.json?Expires=1672313428&amp;GoogleAccessId=wandb-production%<a href=\"http://40appspot.gserviceaccount.com\" rel=\"noopener nofollow ugc\">40appspot.gserviceaccount.com</a>&amp;Signature=UKkwGiiPdbchVt3D9Np7HXU91ioIwnWZa5EqapeDR0UFZbjElm2TU5XOF93P2z7%2BnvCTcAEeSkV0tVg3ln0aMTUw%2BYTVSiyBBHncYCZkJcHWS2MDgcA5v9LzjnQ3c5kJoUA5dJwMWNVLebZ8LWkUDKdBSeafEfogP3xE%2FLIDdPtHolpISNJIvEY3JDPOrTJUh9Ge%2Bw3%2BgLgvep9LbG2qEtmj%2FIeeW%2FXqi9wIpfWdDjZ6ZlkGkohYjJPdSGA6GM9RLrglaDVnwmJQXTgyLEIpD9%2FsuKJeBN3U0v6qz1aE2OBoDCK%2Fs4lDEspXy%2FgOqVS6FEHrwQ813rkabFR6dvC1tA%3D%3D (Caused by SSLError(CertificateError(\u201chostname \u2018<a href=\"http://storage.googleapis.com\" rel=\"noopener nofollow ugc\">storage.googleapis.com</a>\u2019 doesn\u2019t match either of \u2018*.technion.ac.il\u2019, \u2018technion.ac.il\u2019\u201d)))</p>\n<p>Thanks,<br>\nTom</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-28T23:31:11.886Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tomjur\">@tomjur</a> , happy to help. From the error message it appears you are encountering and SSL certification error, <code>SSLError(CertificateError(\u201c....\")</code>, most likely attributed to your private networks firewall. Please refer to our <a href=\"https://docs.wandb.ai/guides/technical-faq/troubleshooting#how-do-i-deal-with-network-issues\">guide here</a> on addressing network related issues. Do let me know if you still encounter issues after addressing the SSL error.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-03T18:44:25.426Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tomjur\">@tomjur</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-04T18:44:39.927Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Waiting for W&B process to finish... (success)",
		"Question_link": "https://community.wandb.ai/t/waiting-for-w-b-process-to-finish-success/3511",
		"Question_created_time": "2022-12-07T20:22:44.138Z",
		"Question_answer_count": 12,
		"Question_score_count": 1,
		"Question_view_count": 1840,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am using wandb to log Tensorflow model training. Unfortunately the runs keep on running forever even though the training has finished minutes before.</p>\n<p>I am receiving a lot of the following debug messages in debug-internals.log:</p>\n<pre><code class=\"lang-auto\">2022-12-07 21:19:47,595 DEBUG   HandlerThread:796 [handler.py:handle_request():139] handle_request: keepalive\n```\n\ndebug.log  is already finished with the following last messages:\n```\n2022-12-07 21:09:05,301 INFO    MainThread:12168 [wandb_run.py:_config_callback():1163] config_cb ('_wandb', 'session_history') code\\_session_history.ipynb None\n2022-12-07 21:09:05,323 INFO    MainThread:12168 [jupyter.py:_save_ipynb():389] looking for notebook: None\n2022-12-07 21:09:05,323 INFO    MainThread:12168 [wandb_init.py:_jupyter_teardown():408] cleaning up jupyter logic\n2022-12-07 21:09:05,323 INFO    MainThread:12168 [wandb_run.py:_atexit_cleanup():1955] got exitcode: 0\n2022-12-07 21:09:05,324 INFO    MainThread:12168 [wandb_run.py:_restore():1938] restore\n2022-12-07 21:09:05,325 INFO    MainThread:12168 [wandb_run.py:_restore():1944] restore done\n```\n\nI have already updated to wandb-013.6 but this did not solve the issues.</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-08T07:53:06.522Z",
				"Answer_body": "<p>I also encountered this problem, but it has not been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-08T08:00:52.144Z",
				"Answer_body": "<pre><code class=\"lang-auto\">object at 0x000001B3207410A0&gt;&gt;, args: ('https://api.wandb.ai/files/liuye/Image_Enhancement/1nykox3a/file_stream',), kwargs: {'json': {'complete': False, 'failed': False, 'dropped': 0, 'uploaded': []}}\n2022-12-08 15:56:47,968 WARNING FileStreamThread:7688 [file_stream.py:request_with_retry():667] requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/liuye/Image_Enhancement/1nykox3a/file_stream (Caused by ProxyError('Your proxy appears to only use HTTP and not HTTPS, try changing your proxy URL to be HTTP. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#https-proxy-error-http-proxy', SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1131)')))). func: &lt;bound method Session.post of &lt;requests.sessions.Session object at 0x000001B3207410A0&gt;&gt;, args: ('https://api.wandb.ai/files/liuye/Image_Enhancement/1nykox3a/file_stream',), kwargs: {'json': {'complete': False, 'failed': False, 'dropped': 0, 'uploaded': []}}\n</code></pre>\n<blockquote>\n<p>Blockquote</p>\n</blockquote>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-12T08:45:00.977Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/susbrock\">@susbrock</a> <a class=\"mention\" href=\"/u/liuyee\">@liuyee</a>, thanks for reporting this! I\u2019ll try to reproduce this issue and see what\u2019s happening here but, in the meantime, there are some points that will be helpful:</p>\n<ul>\n<li>Are you using Tensorboard in your experiment?</li>\n<li>Could you confirm me if your code is something like:</li>\n</ul>\n<pre><code class=\"lang-auto\">wandb.init()\n##Create and train tf model\nwandb.log({metrics})\n</code></pre>\n<ul>\n<li>If you aren\u2019t doing it yet, could you try to assign the run to a variable like <code>run = wandb.init()</code> and call <code>run.finish()</code> ate the end of your experiment?</li>\n</ul>\n<p>Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-12T08:45:09.905Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/susbrock\">@susbrock</a> <a class=\"mention\" href=\"/u/liuyee\">@liuyee</a>, thanks for reporting this! I\u2019ll try to reproduce this issue and see what\u2019s happening here but, in the meantime, there are some points that will be helpful:</p>\n<ul>\n<li>\n<p>Are you using Tensorboard in your experiment?</p>\n</li>\n<li>\n<p>Could you confirm me if your code is something like:</p>\n<p>wandb.init()<br>\n#<span class=\"hashtag\">#Create</span> and train tf model<br>\nwandb.log({metrics})</p>\n</li>\n<li>\n<p>If you aren\u2019t doing it yet, could you try to assign the run to a variable like <code>run = wandb.init()</code> and call <code>run.finish()</code> ate the end of your experiment?</p>\n</li>\n</ul>\n<p>Thanks!</p>\n<p>[Discourse post]</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-12T10:06:30.757Z",
				"Answer_body": "<ul>\n<li>Are you using Tensorboard in your experiment?  A: Yes.</li>\n<li>Could you confirm me if your code is something like that? A: i don\u2019t use <code>run.finish()</code>.</li>\n</ul>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-12T12:19:06.970Z",
				"Answer_body": "<p>Thanks for confirming this liuyee, could you try using <code>run.finish()</code> and see if the same issue appears?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-13T08:29:02.032Z",
				"Answer_body": "<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/8/8a1599054e9307738b048c59155a6c72639f71fb.png\" data-download-href=\"/uploads/short-url/jHya9SyQnTpU2wlc8ryfbf1tZXR.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/8a1599054e9307738b048c59155a6c72639f71fb_2_690x58.png\" alt=\"image\" data-base62-sha1=\"jHya9SyQnTpU2wlc8ryfbf1tZXR\" width=\"690\" height=\"58\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/8a1599054e9307738b048c59155a6c72639f71fb_2_690x58.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/8a1599054e9307738b048c59155a6c72639f71fb_2_1035x87.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/8/8a1599054e9307738b048c59155a6c72639f71fb.png 2x\" data-dominant-color=\"3A2D33\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1042\u00d789 7.99 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nIt still does not work.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-13T20:07:11.914Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/luis_bergua1\">@luis_bergua1</a>  I am using  Tensorboard.  I am using</p>\n<pre><code class=\"lang-auto\">wandb.init(....)\n...\n\nwandb.finish()\n</code></pre>\n<p>because I am running my code in jupyter notebook for VS code.</p>\n<p>Last week I was struggling with wandb  but currently it works fine.  I have add \u201crun = wandb.init(\u2026)\u201d sometime during the last days so that I cannot say if this is the important part. I am still finishing my code with \u201cwandb.finish()\u201d.  I had picked up the \u201crun = wand.init(\u2026)\u201d  implementation while I was looking for a solution to resume runs\u2026</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-15T17:02:45.804Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/susbrock\">@susbrock</a> <a class=\"mention\" href=\"/u/liuyee\">@liuyee</a>, thanks for your answers! I would highly recommend you to always assign <code>wandb.init()</code> to a variable since it can avoid errors when running multiple experiments. Have you experienced this issue again? If so, would you mind sharing with me the <code>debug.log</code> and <code>debug-internal.log</code> files under the local <code>wandb</code> folder? Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-25T10:12:28.471Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/luis_bergua1\">@luis_bergua1</a>  The problem is reappearing right now.  Therefore I am posting the debug files.</p>\n<p>debug.log</p>\n<pre><code class=\"lang-auto\">2022-12-25 10:24:34,055 INFO    MainThread:1764 [wandb_setup.py:_flush():68] Configure stats pid to 1764\n2022-12-25 10:24:34,055 INFO    MainThread:1764 [wandb_setup.py:_flush():68] Loading settings from C:\\Users\\Susanne\\.config\\wandb\\settings\n2022-12-25 10:24:34,055 INFO    MainThread:1764 [wandb_setup.py:_flush():68] Loading settings from i:\\tinyml\\tiny_cnn\\wandb\\settings\n2022-12-25 10:24:34,055 INFO    MainThread:1764 [wandb_setup.py:_flush():68] Loading settings from environment variables: {'_require_service': 'True', 'mode': 'online'}\n2022-12-25 10:24:34,055 INFO    MainThread:1764 [wandb_setup.py:_flush():68] Inferring run settings from compute environment: {'program': '&lt;python with no main file&gt;'}\n2022-12-25 10:24:34,056 INFO    MainThread:1764 [wandb_init.py:_log_setup():476] Logging user logs to i:\\tinyml\\tiny_cnn\\wandb\\run-20221225_102434-2dyabu0c\\logs\\debug.log\n2022-12-25 10:24:34,056 INFO    MainThread:1764 [wandb_init.py:_log_setup():477] Logging internal logs to i:\\tinyml\\tiny_cnn\\wandb\\run-20221225_102434-2dyabu0c\\logs\\debug-internal.log\n2022-12-25 10:24:34,056 INFO    MainThread:1764 [wandb_init.py:_jupyter_setup():426] configuring jupyter hooks &lt;wandb.sdk.wandb_init._WandbInit object at 0x000001FC77A5D900&gt;\n2022-12-25 10:24:34,057 INFO    MainThread:1764 [wandb_init.py:init():516] calling init triggers\n2022-12-25 10:24:34,057 INFO    MainThread:1764 [wandb_init.py:init():519] wandb.init called with sweep_config: {}\nconfig: {}\n2022-12-25 10:24:34,057 INFO    MainThread:1764 [wandb_init.py:init():569] starting backend\n2022-12-25 10:24:34,057 INFO    MainThread:1764 [wandb_init.py:init():573] setting up manager\n2022-12-25 10:24:34,060 INFO    MainThread:1764 [backend.py:_multiprocessing_setup():102] multiprocessing start_methods=spawn, using: spawn\n2022-12-25 10:24:34,065 INFO    MainThread:1764 [wandb_init.py:init():580] backend started and connected\n2022-12-25 10:24:34,080 INFO    MainThread:1764 [wandb_run.py:_label_probe_notebook():1116] probe notebook\n2022-12-25 10:24:34,083 INFO    MainThread:1764 [wandb_run.py:_label_probe_notebook():1126] Unable to probe notebook: 'NoneType' object has no attribute 'get'\n2022-12-25 10:24:34,083 INFO    MainThread:1764 [wandb_init.py:init():658] updated telemetry\n2022-12-25 10:24:34,183 INFO    MainThread:1764 [wandb_init.py:init():693] communicating run to backend with 60 second timeout\n2022-12-25 10:24:35,152 INFO    MainThread:1764 [wandb_run.py:_on_init():2006] communicating current version\n2022-12-25 10:24:35,417 INFO    MainThread:1764 [wandb_run.py:_on_init():2010] got version response \n2022-12-25 10:24:35,418 INFO    MainThread:1764 [wandb_init.py:init():728] starting run threads in backend\n2022-12-25 10:24:40,442 INFO    MainThread:1764 [wandb_run.py:_console_start():1986] atexit reg\n2022-12-25 10:24:40,443 INFO    MainThread:1764 [wandb_run.py:_redirect():1844] redirect: SettingsConsole.WRAP_RAW\n2022-12-25 10:24:40,443 INFO    MainThread:1764 [wandb_run.py:_redirect():1909] Wrapping output streams.\n2022-12-25 10:24:40,443 INFO    MainThread:1764 [wandb_run.py:_redirect():1931] Redirects installed.\n2022-12-25 10:24:40,443 INFO    MainThread:1764 [wandb_init.py:init():765] run started, returning control to user process\n2022-12-25 10:24:40,444 INFO    MainThread:1764 [wandb_config.py:__setitem__():155] config set batch_size = 32 - &lt;bound method Run._config_callback of &lt;wandb.sdk.wandb_run.Run object at 0x000001FC452EB040&gt;&gt;\n2022-12-25 10:24:40,444 INFO    MainThread:1764 [wandb_run.py:_config_callback():1163] config_cb batch_size 32 None\n2022-12-25 10:24:40,444 INFO    MainThread:1764 [wandb_config.py:__setitem__():155] config set learn_rate = 0.001 - &lt;bound method Run._config_callback of &lt;wandb.sdk.wandb_run.Run object at 0x000001FC452EB040&gt;&gt;\n2022-12-25 10:24:40,444 INFO    MainThread:1764 [wandb_run.py:_config_callback():1163] config_cb learn_rate 0.001 None\n2022-12-25 10:24:40,444 INFO    MainThread:1764 [wandb_config.py:__setitem__():155] config set momentum = 0.9 - &lt;bound method Run._config_callback of &lt;wandb.sdk.wandb_run.Run object at 0x000001FC452EB040&gt;&gt;\n2022-12-25 10:24:40,444 INFO    MainThread:1764 [wandb_run.py:_config_callback():1163] config_cb momentum 0.9 None\n2022-12-25 10:24:40,444 INFO    MainThread:1764 [wandb_config.py:__setitem__():155] config set epochs = 5 - &lt;bound method Run._config_callback of &lt;wandb.sdk.wandb_run.Run object at 0x000001FC452EB040&gt;&gt;\n2022-12-25 10:24:40,445 INFO    MainThread:1764 [wandb_run.py:_config_callback():1163] config_cb epochs 5 None\n2022-12-25 10:24:40,445 INFO    MainThread:1764 [wandb_config.py:__setitem__():155] config set classes = 3 - &lt;bound method Run._config_callback of &lt;wandb.sdk.wandb_run.Run object at 0x000001FC452EB040&gt;&gt;\n2022-12-25 10:24:40,445 INFO    MainThread:1764 [wandb_run.py:_config_callback():1163] config_cb classes 3 None\n2022-12-25 10:24:40,445 INFO    MainThread:1764 [wandb_config.py:__setitem__():155] config set id = 2dyabu0c - &lt;bound method Run._config_callback of &lt;wandb.sdk.wandb_run.Run object at 0x000001FC452EB040&gt;&gt;\n2022-12-25 10:24:40,445 INFO    MainThread:1764 [wandb_run.py:_config_callback():1163] config_cb id 2dyabu0c None\n2022-12-25 10:24:40,445 INFO    MainThread:1764 [wandb_config.py:__setitem__():155] config set architecture = efficientNetB0_0.1_96_c3_o3_keras - &lt;bound method Run._config_callback of &lt;wandb.sdk.wandb_run.Run object at 0x000001FC452EB040&gt;&gt;\n2022-12-25 10:24:40,446 INFO    MainThread:1764 [wandb_run.py:_config_callback():1163] config_cb architecture efficientNetB0_0.1_96_c3_o3_keras None\n2022-12-25 10:24:40,446 INFO    MainThread:1764 [wandb_config.py:__setitem__():155] config set optimizer = SGD - &lt;bound method Run._config_callback of &lt;wandb.sdk.wandb_run.Run object at 0x000001FC452EB040&gt;&gt;\n2022-12-25 10:24:40,446 INFO    MainThread:1764 [wandb_run.py:_config_callback():1163] config_cb optimizer SGD None\n2022-12-25 10:24:40,536 INFO    MainThread:1764 [wandb_run.py:_tensorboard_callback():1299] tensorboard callback: i:\\tinyml\\tiny_cnn\\wandb\\run-20221225_102434-2dyabu0c\\files\\train, True\n2022-12-25 10:25:31,797 INFO    MainThread:1764 [wandb_run.py:_tensorboard_callback():1299] tensorboard callback: i:\\tinyml\\tiny_cnn\\wandb\\run-20221225_102434-2dyabu0c\\files\\validation, True\n2022-12-25 10:28:02,476 INFO    MainThread:1764 [wandb_run.py:_config_callback():1163] config_cb ('_wandb', 'visualize', 'conf_mat') {'panel_type': 'Vega2', 'panel_config': {'panelDefId': 'wandb/confusion_matrix/v1', 'fieldSettings': {'Actual': 'Actual', 'Predicted': 'Predicted', 'nPredictions': 'nPredictions'}, 'stringSettings': {'title': ''}, 'transform': {'name': 'tableWithLeafColNames'}, 'userQuery': {'queryFields': [{'name': 'runSets', 'args': [{'name': 'runSets', 'value': '${runSets}'}], 'fields': [{'name': 'id', 'fields': []}, {'name': 'name', 'fields': []}, {'name': '_defaultColorIndex', 'fields': []}, {'name': 'summaryTable', 'args': [{'name': 'tableKey', 'value': 'conf_mat_table'}], 'fields': []}]}]}}} None\n2022-12-25 10:28:03,896 INFO    MainThread:1764 [wandb_run.py:_finish():1753] finishing run susbrock/efficientNetB0/2dyabu0c\n2022-12-25 10:28:03,980 INFO    MainThread:1764 [jupyter.py:save_history():477] saving 27 cells to _session_history.ipynb\n2022-12-25 10:28:03,980 INFO    MainThread:1764 [wandb_run.py:_config_callback():1163] config_cb ('_wandb', 'session_history') code\\_session_history.ipynb None\n2022-12-25 10:28:04,018 INFO    MainThread:1764 [jupyter.py:_save_ipynb():389] looking for notebook: None\n2022-12-25 10:28:04,018 INFO    MainThread:1764 [wandb_init.py:_jupyter_teardown():408] cleaning up jupyter logic\n2022-12-25 10:28:04,018 INFO    MainThread:1764 [wandb_run.py:_atexit_cleanup():1955] got exitcode: 0\n2022-12-25 10:28:04,018 INFO    MainThread:1764 [wandb_run.py:_restore():1938] restore\n2022-12-25 10:28:04,018 INFO    MainThread:1764 [wandb_run.py:_restore():1944] restore done\n</code></pre>\n<p>debug-internal.log will follow in separate message.<br>\nThanks for your support.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-02T17:39:05.286Z",
				"Answer_body": "<p>I do have a similar issue, Running the code from de MLOps course 01_EDA.ipynb</p>\n<p>The notebook basicaly does:<br>\nstart a run with run = wandb.init()<br>\ncreate an antifact and store a Table.<br>\nbut when I run run.finish(), it keeps going for ever and never finish running the cell<br>\n(I\u2019m using VS Code Jupyter notebook), running the same code as it is in the course Effective MLOps: Model Development, processing data for exploratory analysis.</p>\n<hr>\n<p>UPDATE:</p>\n<p>Running the code using Colab works just fine.<br>\nStill would like to work in my local PC<br>\nMy internet speed last test is 200/111 Mb download/upload so it\u2019s not a connection problem.</p>\n<hr>\n<p>this is the log I\u2019m having (debug-internal.log):</p>\n<blockquote>\n<p>2023-01-02 17:18:30,630 INFO    Thread-3998:6476 [upload_job.py:push():101] Uploaded file C:\\Users\\Vinc.cache\\wandb\\artifacts\\obj\\md5\\f4\\d1e18a269ee5ea2dfe1f31f62ace7e<br>\n2023-01-02 17:18:30,635 INFO    Thread-3975:6476 [upload_job.py:push():101] Uploaded file C:\\Users\\Vinc.cache\\wandb\\artifacts\\obj\\md5\\ef\\805451c61c3548e0b64d7cd43fb495<br>\n2023-01-02 17:18:30,637 INFO    Thread-3983:6476 [upload_job.py:push():101] Uploaded file C:\\Users\\Vinc.cache\\wandb\\artifacts\\obj\\md5\\f1\\159ed57aec7385894be1f50ff3db6b<br>\n2023-01-02 17:18:30,641 INFO    Thread-3974:6476 [upload_job.py:push():101] Uploaded file C:\\Users\\Vinc.cache\\wandb\\artifacts\\obj\\md5\\ef\\40545a3365286db74b9eec276aafe5<br>\n2023-01-02 17:18:30,662 INFO    Thread-3962:6476 [upload_job.py:push():101] Uploaded file C:\\Users\\Vinc.cache\\wandb\\artifacts\\obj\\md5\\ec\\5bb019ae113d7a08c9bb6eb9ac6fe8<br>\n2023-01-02 17:18:30,773 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:18:31,775 INFO    Thread-4012:6476 [upload_job.py:push():101] Uploaded file C:\\Users\\Vinc.cache\\wandb\\artifacts\\obj\\md5\\fa\\336027db262331cf3de1c2bc489161<br>\n2023-01-02 17:18:31,779 INFO    Thread-4023:6476 [upload_job.py:push():101] Uploaded file C:\\Users\\Vinc.cache\\wandb\\artifacts\\obj\\md5\\fd\\72fdd8e9b81196f34a27936872ec85<br>\n2023-01-02 17:18:31,802 INFO    Thread-4026:6476 [upload_job.py:push():101] Uploaded file C:\\Users\\Vinc.cache\\wandb\\artifacts\\obj\\md5\\fe\\23e9669b121a89dd294fbcd063240e<br>\n2023-01-02 17:18:35,832 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:18:40,870 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:18:45,886 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:18:50,958 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:18:55,987 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:19:01,020 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:19:06,043 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:19:11,062 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:19:16,108 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:19:21,124 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:19:26,138 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:19:31,175 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:19:36,203 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:19:41,221 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:19:46,246 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:19:51,287 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:19:56,303 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:20:01,336 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:20:06,359 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:20:11,360 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive<br>\n2023-01-02 17:20:16,378 DEBUG   HandlerThread:6476 [handler.py:handle_request():139] handle_request: keepalive</p>\n</blockquote>\n<p>This last line is still being printed\u2026</p>\n<br>\n<br>\n<p>Log (debug.log):</p>\n<blockquote>\n<p>2023-01-02 17:08:08,443 INFO    MainThread:15880 [wandb_setup.py:_flush():68] Configure stats pid to 15880<br>\n2023-01-02 17:08:08,443 INFO    MainThread:15880 [wandb_setup.py:_flush():68] Loading settings from C:\\Users\\Vinc.config\\wandb\\settings<br>\n2023-01-02 17:08:08,444 INFO    MainThread:15880 [wandb_setup.py:_flush():68] Loading settings from d:\\GitHub\\Repositories\\MLOps\\mlops-001\\lesson1\\wandb\\settings<br>\n2023-01-02 17:08:08,444 INFO    MainThread:15880 [wandb_setup.py:_flush():68] Loading settings from environment variables: {\u2018_require_service\u2019: \u2018True\u2019}<br>\n2023-01-02 17:08:08,444 INFO    MainThread:15880 [wandb_setup.py:_flush():68] Inferring run settings from compute environment: {\u2018program\u2019: \u2018\u2019}<br>\n2023-01-02 17:08:08,444 INFO    MainThread:15880 [wandb_init.py:_log_setup():476] Logging user logs to d:\\GitHub\\Repositories\\MLOps\\mlops-001\\lesson1\\wandb\\run-20230102_170808-2gezouc7\\logs\\debug.log<br>\n2023-01-02 17:08:08,445 INFO    MainThread:15880 [wandb_init.py:_log_setup():477] Logging internal logs to d:\\GitHub\\Repositories\\MLOps\\mlops-001\\lesson1\\wandb\\run-20230102_170808-2gezouc7\\logs\\debug-internal.log<br>\n2023-01-02 17:08:08,445 INFO    MainThread:15880 [wandb_init.py:_jupyter_setup():426] configuring jupyter hooks &lt;wandb.sdk.wandb_init._WandbInit object at 0x0000023EB863CAF0&gt;<br>\n2023-01-02 17:08:08,445 INFO    MainThread:15880 [wandb_init.py:init():516] calling init triggers<br>\n2023-01-02 17:08:08,445 INFO    MainThread:15880 [wandb_init.py:init():519] wandb.init called with sweep_config: {}<br>\nconfig: {}<br>\n2023-01-02 17:08:08,445 INFO    MainThread:15880 [wandb_init.py:init():569] starting backend<br>\n2023-01-02 17:08:08,446 INFO    MainThread:15880 [wandb_init.py:init():573] setting up manager<br>\n2023-01-02 17:08:08,449 INFO    MainThread:15880 [backend.py:_multiprocessing_setup():102] multiprocessing start_methods=spawn, using: spawn<br>\n2023-01-02 17:08:08,454 INFO    MainThread:15880 [wandb_init.py:init():580] backend started and connected<br>\n2023-01-02 17:08:08,468 INFO    MainThread:15880 [wandb_run.py:_label_probe_notebook():1116] probe notebook<br>\n2023-01-02 17:08:08,470 INFO    MainThread:15880 [wandb_run.py:_label_probe_notebook():1126] Unable to probe notebook: \u2018NoneType\u2019 object has no attribute \u2018get\u2019<br>\n2023-01-02 17:08:08,470 INFO    MainThread:15880 [wandb_init.py:init():658] updated telemetry<br>\n2023-01-02 17:08:08,513 INFO    MainThread:15880 [wandb_init.py:init():693] communicating run to backend with 60 second timeout<br>\n2023-01-02 17:08:09,065 INFO    MainThread:15880 [wandb_run.py:_on_init():2006] communicating current version<br>\n2023-01-02 17:08:09,380 INFO    MainThread:15880 [wandb_run.py:_on_init():2010] got version response<br>\n2023-01-02 17:08:09,380 INFO    MainThread:15880 [wandb_init.py:init():728] starting run threads in backend<br>\n2023-01-02 17:08:09,638 INFO    MainThread:15880 [wandb_run.py:_console_start():1986] atexit reg<br>\n2023-01-02 17:08:09,638 INFO    MainThread:15880 [wandb_run.py:_redirect():1844] redirect: SettingsConsole.WRAP_RAW<br>\n2023-01-02 17:08:09,638 INFO    MainThread:15880 [wandb_run.py:_redirect():1909] Wrapping output streams.<br>\n2023-01-02 17:08:09,638 INFO    MainThread:15880 [wandb_run.py:_redirect():1931] Redirects installed.<br>\n2023-01-02 17:08:09,640 INFO    MainThread:15880 [wandb_init.py:init():765] run started, returning control to user process<br>\n2023-01-02 17:08:09,640 INFO    MainThread:15880 [wandb_init.py:_pause_backend():389] pausing backend<br>\n2023-01-02 17:08:09,640 INFO    MainThread:15880 [jupyter.py:save_ipynb():378] not saving jupyter notebook<br>\n2023-01-02 17:08:20,386 INFO    MainThread:15880 [wandb_init.py:_resume_backend():398] resuming backend<br>\n2023-01-02 17:08:20,389 INFO    MainThread:15880 [wandb_init.py:_pause_backend():389] pausing backend<br>\n2023-01-02 17:08:20,389 INFO    MainThread:15880 [jupyter.py:save_ipynb():378] not saving jupyter notebook<br>\n2023-01-02 17:08:21,422 INFO    MainThread:15880 [wandb_init.py:_resume_backend():398] resuming backend<br>\n2023-01-02 17:08:21,446 INFO    MainThread:15880 [wandb_init.py:_pause_backend():389] pausing backend<br>\n2023-01-02 17:08:21,446 INFO    MainThread:15880 [jupyter.py:save_ipynb():378] not saving jupyter notebook<br>\n2023-01-02 17:08:22,609 INFO    MainThread:15880 [wandb_init.py:_resume_backend():398] resuming backend<br>\n2023-01-02 17:08:22,612 INFO    MainThread:15880 [wandb_init.py:_pause_backend():389] pausing backend<br>\n2023-01-02 17:08:22,612 INFO    MainThread:15880 [jupyter.py:save_ipynb():378] not saving jupyter notebook<br>\n2023-01-02 17:08:23,625 INFO    MainThread:15880 [wandb_init.py:_resume_backend():398] resuming backend<br>\n2023-01-02 17:08:28,241 INFO    MainThread:15880 [wandb_init.py:_pause_backend():389] pausing backend<br>\n2023-01-02 17:08:28,241 INFO    MainThread:15880 [jupyter.py:save_ipynb():378] not saving jupyter notebook<br>\n2023-01-02 17:08:28,349 INFO    MainThread:15880 [wandb_init.py:_resume_backend():398] resuming backend<br>\n2023-01-02 17:08:28,360 INFO    MainThread:15880 [wandb_init.py:_pause_backend():389] pausing backend<br>\n2023-01-02 17:08:28,360 INFO    MainThread:15880 [jupyter.py:save_ipynb():378] not saving jupyter notebook<br>\n2023-01-02 17:08:28,410 INFO    MainThread:15880 [wandb_init.py:_resume_backend():398] resuming backend<br>\n2023-01-02 17:08:28,413 INFO    MainThread:15880 [wandb_init.py:_pause_backend():389] pausing backend<br>\n2023-01-02 17:08:28,413 INFO    MainThread:15880 [jupyter.py:save_ipynb():378] not saving jupyter notebook<br>\n2023-01-02 17:08:29,158 INFO    MainThread:15880 [wandb_init.py:_resume_backend():398] resuming backend<br>\n2023-01-02 17:12:21,179 INFO    MainThread:15880 [wandb_init.py:_pause_backend():389] pausing backend<br>\n2023-01-02 17:12:21,179 INFO    MainThread:15880 [jupyter.py:save_ipynb():378] not saving jupyter notebook<br>\n2023-01-02 17:12:21,272 INFO    MainThread:15880 [wandb_init.py:_resume_backend():398] resuming backend<br>\n2023-01-02 17:12:31,453 INFO    MainThread:15880 [wandb_init.py:_pause_backend():389] pausing backend<br>\n2023-01-02 17:12:31,453 INFO    MainThread:15880 [jupyter.py:save_ipynb():378] not saving jupyter notebook<br>\n2023-01-02 17:12:31,531 INFO    MainThread:15880 [wandb_init.py:_resume_backend():398] resuming backend<br>\n2023-01-02 17:12:31,899 INFO    MainThread:15880 [wandb_init.py:_pause_backend():389] pausing backend<br>\n2023-01-02 17:12:31,899 INFO    MainThread:15880 [jupyter.py:save_ipynb():378] not saving jupyter notebook<br>\n2023-01-02 17:12:31,993 INFO    MainThread:15880 [wandb_init.py:_resume_backend():398] resuming backend<br>\n2023-01-02 17:12:31,993 INFO    MainThread:15880 [wandb_run.py:_finish():1753] finishing run vincpc/mlops-course-001/2gezouc7<br>\n2023-01-02 17:12:31,993 INFO    MainThread:15880 [jupyter.py:save_history():448] not saving jupyter history<br>\n2023-01-02 17:12:32,009 INFO    MainThread:15880 [jupyter.py:save_ipynb():378] not saving jupyter notebook<br>\n2023-01-02 17:12:32,009 INFO    MainThread:15880 [wandb_init.py:_jupyter_teardown():408] cleaning up jupyter logic<br>\n2023-01-02 17:12:32,009 INFO    MainThread:15880 [wandb_run.py:_atexit_cleanup():1955] got exitcode: 0<br>\n2023-01-02 17:12:32,009 INFO    MainThread:15880 [wandb_run.py:_restore():1938] restore<br>\n2023-01-02 17:12:32,009 INFO    MainThread:15880 [wandb_run.py:_restore():1944] restore done</p>\n</blockquote>\n<p>VS Code is not using any Network at all, so it\u2019s not Uploading anymore.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-03T17:39:05.453Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Boxplots do not show values if there is only a single point",
		"Question_link": "https://community.wandb.ai/t/boxplots-do-not-show-values-if-there-is-only-a-single-point/3528",
		"Question_created_time": "2022-12-10T21:34:45.943Z",
		"Question_answer_count": 10,
		"Question_score_count": 0,
		"Question_view_count": 230,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>E.g.,<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/1/1d2145c15eb2dcd404fc843e7cad5a4d3fb0a6b1.png\" data-download-href=\"/uploads/short-url/49H8dJRF7TWhHGd2OSIh5IiqgRb.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/1/1d2145c15eb2dcd404fc843e7cad5a4d3fb0a6b1_2_634x500.png\" alt=\"image\" data-base62-sha1=\"49H8dJRF7TWhHGd2OSIh5IiqgRb\" width=\"634\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/1/1d2145c15eb2dcd404fc843e7cad5a4d3fb0a6b1_2_634x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/1/1d2145c15eb2dcd404fc843e7cad5a4d3fb0a6b1.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/1/1d2145c15eb2dcd404fc843e7cad5a4d3fb0a6b1.png 2x\" data-dominant-color=\"FBFAFA\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">774\u00d7610 23 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>I would use barplot but I bar plot stacks the data over instead of computing means and do not see any possibility to compute means using weave.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-12T12:45:01.016Z",
				"Answer_body": "<p>Hi Wojciech,</p>\n<p>Thanks for writing in! Would you mind sharing a link to this chart and so I can have a look at it? If I use boxplot, when hovering over my mouse I can see max/min and median, the extra feature that you would like to have is being able to see also the mean, is it?</p>\n<p>Also, would you like to see data when there is only one point?</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-14T08:07:53.294Z",
				"Answer_body": "<p>Exactly, mean on box plots would be a plus. But median would be enough if it is also shown for a single point data.</p>\n<p>Box plots are the only way I found in wand to do something that I would do in Pandas using sth like:</p>\n<p>runs.summary.groupby(\u2018dataset_name\u2019).median(\u2018accuracy\u2019)</p>\n<p>Is there a way to do the above using weave? I cannot find anything like that in the documentation.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-15T16:50:40.805Z",
				"Answer_body": "<p>Hi Wojciech,</p>\n<p>Thanks for sharing this! I can create a new request for this feature, I would really appreciate if you could share with me your use-case and if this is blocking you in any way.</p>\n<p>In terms of finding a workaround for this, I am not sure if I fully understand what you are trying to do. If there is a single point, then the box-plot would not show the median since this has to be calculated with at least two points, so would you mind explaining me what would be your ideal behaviour? Also, it would be great if you could share a link to the Workspace where you have this data and so I can have a look at it.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-20T14:22:48.203Z",
				"Answer_body": "<p>Hi Wojciech,</p>\n<p>I just wanted to follow up here, could you share with the case in which you are finding this feature useful? Also, would you mind explaining a little bit more about your use-case and so I can help you finding a workaround for this?</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-20T16:01:09.131Z",
				"Answer_body": "<p>Use case: I test a number of algorithms on a set of datasets (or seeds). Thus, naturally, I\u2019d like to group by algorithms and see a distribution of performance for the algorithms. Some algorithms take a lot of time, so I cannot repeat them more than once thus, instead of having a distribution, I\u2019d like to have a single point shown on the plot.</p>\n<p>As to the groupby. Let me show you an exemplary board with a few runs: Weights &amp; Biases. There is a panel with summary table. I\u2019d like to do some groupby on the summary to calculate mean over the groups (algorithms). I am aware of Weights &amp; Biases but I don\u2019t get how to use the groupby on run.summary and run.history. Not enough examples and documentation.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-20T16:01:19.725Z",
				"Answer_body": "<p>Use case: I test a number of algorithms on a set of datasets (or seeds). Thus, naturally, I\u2019d like to group by algorithms and see a distribution of performance for the algorithms. Some algorithms take a lot of time, so I cannot repeat them more than once thus, instead of having a distribution, I\u2019d like to have a single point shown on the plot.</p>\n<p>As to the groupby. Let me show you an exemplary board with a few runs: Weights &amp; Biases. There is a panel with summary table. I\u2019d like to do some groupby on the summary to calculate mean over the groups (algorithms). I am aware of Weights &amp; Biases but I don\u2019t get how to use the groupby on run.summary and run.history. Not enough examples and documentation.</p>\n<p>[Discourse post]</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-21T21:09:31.078Z",
				"Answer_body": "<p>Oh. I c&amp;p and the link to the example did not get through. Let me share it again: <a href=\"https://wandb.ai/gat/alan-test?workspace=user-wjgat\" class=\"inline-onebox\">Weights &amp; Biases</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-22T16:39:53.259Z",
				"Answer_body": "<p>Hi Wojciech,</p>\n<p>Thanks a lot for sharing this! I have been able to explore this in depth. Weave gets the data from our Database meanwhile operations in the Workspace (like group your runs) are not affecting the database, that is why you cannot see your metrics grouped in the Weave expression even when there is some kind of group in the Workspace. There is not any groupby option in Weave. I have already reported your feedback about boxplots, would you like me to also file a request for having groupby as an option in Weave expressions?</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-02T09:35:53.342Z",
				"Answer_body": "<p>To me, weave without groupby is not useful.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-03-03T09:35:57.438Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "The debug-internal.log file is too large (>500MB)",
		"Question_link": "https://community.wandb.ai/t/the-debug-internal-log-file-is-too-large-500mb/3589",
		"Question_created_time": "2022-12-23T04:23:12.303Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 208,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Because of network problem. The local <code>debug-internal.log</code> files of some runs are too large (more than 500MB). To save the disk space, is there any way to avoid the generation of these log files?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-28T01:24:27.021Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/geyao\">@geyao</a> , thank you for writing in and happy to look into this for you.  <code>debug-internal.log</code> files are automatically generated and cannot be disabled by the user.  Please see this github issue thread that was raised about this issue were a user provided <a href=\"https://github.com/wandb/wandb/issues/4223#issuecomment-1236304565\" rel=\"noopener nofollow ugc\">workaround</a> solution to address this . Do let me know if this reference helps.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-12-30T07:26:10.062Z",
				"Answer_body": "<p>Thank you! It helps!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-28T07:26:40.660Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Cannot login after passing a wrong secret key",
		"Question_link": "https://community.wandb.ai/t/cannot-login-after-passing-a-wrong-secret-key/3546",
		"Question_created_time": "2022-12-14T15:22:27.089Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 221,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>After passing a wrong key value and initiating a run like below:</p>\n<blockquote>\n<p>wandb.login(key=&lt;wrong_key&gt; relogin=True)<br>\nrun = wandb.init(entity=&lt;entity_name&gt;, project=&lt;project_name&gt;)</p>\n</blockquote>\n<p>I can\u2019t use the same kernel session to initialize a new run even passing the right key value. I\u2019ve tried to remove all the wandb related lines of ~/.netrc (as subprocess) and even remove and reinstall wandb in the same kernel.</p>\n<p>Has someone faced the same issue and might know how to fix it during without restarting the kernel?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-19T21:24:44.073Z",
				"Answer_body": "<p>Hi Wilson, thank you for writing in! Have you tried deleting the whole .netrc file completely and using wandb login --relogin? Also, can you tell us more as to why you can\u2019t restart your kernel?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-23T04:47:48.229Z",
				"Answer_body": "<p>Hi Wilson,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-29T19:28:24.935Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/wnk\">@wnk</a>, since we haven\u2019t heard back we\u2019ll close this issue for now but feel free to respond here if this is still a problem and we can look into this more.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-27T19:28:29.708Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb: WARNING Invalid value for property root_dir",
		"Question_link": "https://community.wandb.ai/t/wandb-warning-invalid-value-for-property-root-dir/3505",
		"Question_created_time": "2022-12-06T20:36:23.881Z",
		"Question_answer_count": 8,
		"Question_score_count": 0,
		"Question_view_count": 247,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>I defined wandb_log_dir to be another directory than where my code resides and received the following warning: \u201cwandb: WARNING Invalid value for property root_dir: /home/xx/xxx/experiments. This will raise an error in the future.\u201d</p>\n<p>Normally I am not particularly concerned about warnings. But because it said \u201cThis will raise an error in the future\u201d, I would like to know what is considered a valid value for property root_dir (and why)? If defining it the way I did, why will it raise an error done the road?</p>\n<p>Many thanks in advance!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-09T10:57:17.734Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/rcheng\">@rcheng</a>  this means that unexpected settings will throw an error in next releases, while for now these <code>**kwarg</code> will be ignored in order to initialise the run with the default value instead. It\u2019s coming from <a href=\"https://github.com/wandb/wandb/blob/dea67a1038a1a539be46554cd83a1430a2267fb8/wandb/sdk/wandb_settings.py#L1069\" rel=\"noopener nofollow ugc\">this</a> line of our SDK code.</p>\n<p>Could you please provide a bit more information, where you set up this parameter, from the environment variables or from wandb.init() call? Would it be possible to share a code snippet of the line that gives this warning, and also what OS you\u2019re using?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-09T15:23:46.785Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a> , thanks for the info.</p>\n<p>I  am on 20.04.3 LTS and here is how I set up this parameter  :</p>\n<p>(from run.py)</p>\n<pre><code class=\"lang-auto\">from pytorch_lightning.loggers import WandbLogger\n\nwandb_log_dir = Path(config['logging_params']['save_dir']) / args.run_name\nwandb_logger = WandbLogger(save_dir=wandb_log_dir,\n                           name=args.run_name,\n                           project=\"beta-vae\"\n                           )\n</code></pre>\n<p>config.yaml file:</p>\n<pre><code class=\"lang-auto\">logging_params:\n  save_dir: \"logs/\" # or \"/home/xx/xxx/experiments\" (the same warning pops up)\n  manual_seed: 1265\n  name: 'BetaVAE'\n\n</code></pre>\n<p>Actually I realized that the warning pops up, regardless of the save_dir is under where the code resides or in a completely different directory. (I originally thought the warning showed up because it was expecting the log_dir to be at the same directory as the code.)</p>\n<p>Thanks in advance for further hints!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-22T14:49:44.030Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/rcheng\">@rcheng</a> thanks for the additional information, I have tried to reproduce the same issue using your code snippet but I didn\u2019t get the same warning. Could you please to explicitly set <code>save_dir='.'</code>or <code>save_dir=/home/dir1/dir2/experiments</code>? Would this work for you? also, is <code>Path</code> from the <code>pathlib</code> package and could you please <code>print(wandb_log_dir)</code> and post the output here as well?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-28T15:19:17.040Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/rcheng\">@rcheng</a> I wanted to follow up with you on this issue, and see if it still occurs for you? Would any of the above work for you? thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-29T16:29:13.461Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/rcheng\">@rcheng</a> since we haven\u2019t heard back from you in a while, I will go ahead and close this ticket for now. If this warning still occurs for you, please let us know and we will be happy to keep investigating!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-29T16:41:56.401Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a> ,</p>\n<p>Sorry for the delayed response.  Somehow the warning went away. I will report here if it shows up again in the coming days. Many thanks for the hints.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-29T17:06:23.238Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/rcheng\">@rcheng</a> glad to hear that, and thanks a lot for the update! Sure, please let us know if that pops up again and we can take it from there.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-27T17:06:39.048Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Is the wandb.ai server down?",
		"Question_link": "https://community.wandb.ai/t/is-the-wandb-ai-server-down/3611",
		"Question_created_time": "2022-12-28T05:54:47.228Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 217,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, it seems that the <a href=\"http://wandb.ai\">wandb.ai</a> server is currently down in my area.</p>\n<p>I live in Seoul, and can confirm access to <a href=\"http://wandb.ai\">wandb.ai</a> is down on my phone, computer, and server. All with different internet providers.</p>\n<p>I was wondering if this was a worldwide issue.</p>\n<p>Thanks in advance!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-28T05:57:43.068Z",
				"Answer_body": "<p>Actually, its back up again. It was down for 15 minutes or so\u2026</p>\n<p>I wonder what happened\u2026</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-28T22:01:27.211Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/joomyjoo\">@joomyjoo</a> , thank you for writing in and we apologies for the inconvenience. We did experience a brief blip on our backend that contributed to site not being active. The issue has been resolved and the underlying issue investigated. Thank you for being one of our valued users. Please do reach out again anytime we could be of help. Cheers!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-26T22:01:48.785Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb: Network error (ProxyError), entering retry loop",
		"Question_link": "https://community.wandb.ai/t/wandb-network-error-proxyerror-entering-retry-loop/3567",
		"Question_created_time": "2022-12-19T03:36:10.418Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 433,
		"Question_has_accepted_answer": false,
		"Question_body": "<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/c/c33f553564ce1498375ecc989c07f1d676c8d9be.png\" data-download-href=\"/uploads/short-url/rReNoE5gMy7hPVhQcXSs2fKrewu.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/c33f553564ce1498375ecc989c07f1d676c8d9be_2_690x191.png\" alt=\"image\" data-base62-sha1=\"rReNoE5gMy7hPVhQcXSs2fKrewu\" width=\"690\" height=\"191\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/c33f553564ce1498375ecc989c07f1d676c8d9be_2_690x191.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/c33f553564ce1498375ecc989c07f1d676c8d9be_2_1035x286.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/c33f553564ce1498375ecc989c07f1d676c8d9be_2_1380x382.png 2x\" data-dominant-color=\"152130\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1738\u00d7483 72.6 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>i run wandb in offline mode, and want to update to wandb server, it shows these error? i can ping to <a href=\"http://wandb.ai\">wandb.ai</a> but wandb sync is not ok, why?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-21T23:21:20.921Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/scottxu-wandb\">@scottxu-wandb</a>, is there indeed a Proxy between the machine and the server?</p>\n<p>If so, could you let me know what ports are open on the Proxy and any other relevant information about how this is ?</p>\n<p>Also, are you running a personal wandb server or do you access the UI at <a href=\"http://wandb.ai\">wandb.ai</a>?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-28T20:11:54.353Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/scottxu-wandb\">@scottxu-wandb</a>, I just wanted to check in and see if you are still seeing this issue?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-26T20:12:52.435Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Download logged table in run locally",
		"Question_link": "https://community.wandb.ai/t/download-logged-table-in-run-locally/3507",
		"Question_created_time": "2022-12-07T03:42:36.861Z",
		"Question_answer_count": 10,
		"Question_score_count": 4,
		"Question_view_count": 500,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi all,</p>\n<p>I have been trying to download and open Wandb table locally. I have managed to get the corresponding table and its id, however, I cannot find way to download the table and open it as CSV for example.</p>\n<pre><code class=\"lang-auto\">runs[0].summary['avg_results'].keys()\ndict_keys(['_type', 'ncols', 'nrows', 'sha256', 'artifact_path', '_latest_artifact_path', 'path', 'size'])```\n\nAbove is a snippet of what I have managed to reach, how can I go from this point to get the table file and read it as cdv</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-07T11:03:29.287Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohamedr002\">@mohamedr002</a> thank you for writing in! You could use the API to download the Table in json format which you could then easily convert to pandas dataframe. Please see below a code snippet, and feel free to ask more questions:</p>\n<pre><code class=\"lang-auto\">import wandb\napi = wandb.Api()\nrun = api.run(f\"ENTITY/PROJECT/{run_id}\")\ntable = run.logged_artifacts()[0]\ntable_dir = table.download()\ntable_name = \"my_table_name\"\ntable_path = f\"{table_dir}/{table_name}.table.json\"\nwith open(table_path) as file:\n    json_dict = json.load(file)\ndf = pd.DataFrame(json_dict[\"data\"], columns=json_dict[\"columns\"])\n</code></pre>\n<p>Please note that logged_artifacts() is an iterator, and for simplicity I added [0] to return only the first entry as an example. Would this work for you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-07T11:20:59.415Z",
				"Answer_body": "<p>Hi Thanos,</p>\n<p>Thank you so much for your clear response. But only one issue that when I logged the table I didn\u2019t log it as artifacts I have just used the workspace</p>\n<blockquote>\n<p>wandb.log(wandb.table)</p>\n</blockquote>\n<p>Will your provider solution still work? Or it requires logging the table as artifact?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-07T12:32:33.693Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"thanos-wandb\" data-post=\"2\" data-topic=\"3507\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/t/4af34b/40.png\" class=\"avatar\"> thanos-wandb:</div>\n<blockquote>\n<pre><code class=\"lang-auto\">df = pd.DataFrame(json_dict[\"data\"], columns=json_dict[\"columns\"])\n</code></pre>\n</blockquote>\n</aside>\n<p>Hi Thanos,</p>\n<p>I have tried your script it worked but not directly. The issue as I mentioned that I don\u2019t have the artifact name, so I managed to get the table path directly.</p>\n<pre><code class=\"lang-auto\">avg_table_path = best_run.summary['avg_results']['path']\navg_table = json.load(open(avg_table_path))\navg_df = pd.DataFrame(avg_table['data'], columns= avg_table['columns'])\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-07T12:33:21.640Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohamedr002\">@mohamedr002</a> that\u2019s automatically done when you\u2019re logging wandb.Table objects. You could click on the Artifacts icon (left panel) from your project\u2019s workspace. Another way to get directly <code>table</code> would be:</p>\n<p><code>table = run.use_artifact(\"run-&lt;run-id&gt;-&lt;table_name&gt;:&lt;tag&gt;\").get(\"&lt;table_name&gt;\")</code></p>\n<p>Please let me know if that works for you, or if you have any further questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-07T12:40:37.039Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohamedr002\">@mohamedr002</a> we both posted same time, is this issue now resolved for you by getting the <code>avg_table_path</code> first? May I also ask if these logged tables were wandb.Table objects? in that case it would also create an artifact.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-07T12:47:12.937Z",
				"Answer_body": "<p>Yes, you are right, I found the table as already been logged as artifiact, but rather than getting the name and directory separately, I used the \u2018path\u2019 element that exist in the table artifact dictionary.  I am really thankful for your prompt response. Really appreciated!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-07T13:01:52.708Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohamedr002\">@mohamedr002</a> glad to hear that, thanks a lot for posting your workaround for future reference! I am closing this ticket for now, but please feel free to reach out to us if you have any other questions!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-24T08:17:07.898Z",
				"Answer_body": "<p>Hey, I am trying to use, <code>table = run.use_artifact(\"run-&lt;run-id&gt;-&lt;table_name&gt;:&lt;tag&gt;\").get(\"&lt;table_name&gt;\")</code><br>\nCan you help how run should be initialised?</p>\n<p>What should I pass as arguments here?<br>\n<code>run = wandb.Api().artifact()</code></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-28T20:10:47.398Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/satpalsr\">@satpalsr</a> there are two ways to access this artifact, either by initialising a run such as <code>run = wandb.init()</code> and then you could use<code> run.use_artifact</code> method or by using our public API. In the latter case, you could do the following:</p>\n<pre><code class=\"lang-auto\">api = wandb.Api()\nartifact = api.artifact('entity/project/artifact-name:alias')\n</code></pre>\n<p>I hope this helps!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-26T20:10:52.431Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Trying to log wandb.Object3D object, getting exception \"unhashable type> 'Object3D'",
		"Question_link": "https://community.wandb.ai/t/trying-to-log-wandb-object3d-object-getting-exception-unhashable-type-object3d/3586",
		"Question_created_time": "2022-12-22T13:38:04.101Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 227,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey guys and gals,<br>\nI am currently trying to log an Object3D object but it wont let me stating that the object is unhashable\u2026</p>\n<p>minimal example:</p>\n<pre><code class=\"lang-auto\">import wandb\nimport numpy as np\n\nobj = wandb.Object3D(np.array([[0,1,2,100,200,50],[1,2,0,50,0,100]]))\nwandb.log({\"3dtest\",obj})\n\n</code></pre>\n<p>results in:</p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nTypeError: unhashable type: 'Object3D'\n\n</code></pre>\n<p>Any advice would be nice (:</p>\n<p>Ps: format r,g,b,c leads to the same outcome</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-22T15:52:59.595Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/michael_qapture\">@michael_qapture</a> thank you for writing in! You will need to change the log line as: <code>wandb.log({\"3dtest\": obj})</code>. Would this work for you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-22T17:09:16.087Z",
				"Answer_body": "<p>(I am the OP, I was logged into the wrong account)</p>\n<p>Oh how awkward, it needs a \u201e:\u201c<br>\nYeah that looks promising, in the console it obviously telly me i have to init a run first but thats promising. As soon as out current training run is done i will change that.<br>\nThanks for the quick response!!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-28T16:25:50.944Z",
				"Answer_body": "<p>Glad to be of help <a class=\"mention\" href=\"/u/marcelqapture\">@marcelqapture</a> <a class=\"mention\" href=\"/u/michael_qapture\">@michael_qapture</a>! I will close this ticket for now, as it seems resolved for you. But if you still experience any issue with this, please let us know and we will be happy to keep investigating.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-26T16:26:14.556Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Grouping runs decreases the granularity of the plots",
		"Question_link": "https://community.wandb.ai/t/grouping-runs-decreases-the-granularity-of-the-plots/3532",
		"Question_created_time": "2022-12-11T22:03:21.528Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 139,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>See the attached image with grouped runs and range set to samples. The actual plots (faint lines) have a much higher granularity then the grouped plot. This decrease in granularity is particularly visible when x-axis is set to log-scale.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/dd19adb3965d52d9a94a4031cb4cf30854dca58e.jpeg\" data-download-href=\"/uploads/short-url/vxWxi1IA9sZR2hhpUslBXc37Mxo.jpeg?dl=1\" title=\"Screenshot 2022-12-11 at 5.03.49 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/dd19adb3965d52d9a94a4031cb4cf30854dca58e_2_690x235.jpeg\" alt=\"Screenshot 2022-12-11 at 5.03.49 PM\" data-base62-sha1=\"vxWxi1IA9sZR2hhpUslBXc37Mxo\" width=\"690\" height=\"235\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/dd19adb3965d52d9a94a4031cb4cf30854dca58e_2_690x235.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/dd19adb3965d52d9a94a4031cb4cf30854dca58e_2_1035x352.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/dd19adb3965d52d9a94a4031cb4cf30854dca58e_2_1380x470.jpeg 2x\" data-dominant-color=\"FAFAFB\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2022-12-11 at 5.03.49 PM</span><span class=\"informations\">2801\u00d7957 152 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-14T21:35:58.235Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/vyasnikhil96\">@vyasnikhil96</a> thank you for writing in! The issue you\u2019re seeing is related to a combination of <a href=\"https://docs.wandb.ai/ref/app/features/panels/line-plot/sampling#bucketing\">bucketing</a> and sampling that takes place in order to improve the UI performance. Indeed the issue is even more obvious when working in log scale.</p>\n<p>Our engineers are actively working on this feature to allow users to dynamically adjust the total number of points. I have now increased the requests, and will keep you posted here once there are any updates regarding this!</p>\n<p>Would this work for you? alternatively, you could download the data using our API after the run is finished, in order to create the chart externally and log the generated plot or image.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-14T22:41:10.163Z",
				"Answer_body": "<p>Yes I think adjusting the number of points would be a great solution with the caveat that sampling is based on whether the plot is in log scale or not. If it is in log scale points should be weighted by 1/step.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-28T15:34:00.658Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/vyasnikhil96\">@vyasnikhil96</a> thanks for the additional information. I have already reported this UI behavior you\u2019re seeing to our engineers and we will reach out to you as soon as there are any updates.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-26T15:34:26.127Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "K-fold cross validation in one run?",
		"Question_link": "https://community.wandb.ai/t/k-fold-cross-validation-in-one-run/3560",
		"Question_created_time": "2022-12-16T14:14:26.196Z",
		"Question_answer_count": 7,
		"Question_score_count": 5,
		"Question_view_count": 322,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,<br>\nI have set a run with a model to execute k-fold  cross validation. When  the axis of the AUC or loss plot is steps , all the folds are shown but when I select the axis to be equal to epochs, then only one run is shown. Which is this run? The last one, the average of all the runs or the best one?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/5/5f9d03b825103840e76e8a66e4499ab603ea22e9.png\" data-download-href=\"/uploads/short-url/dDPLeeNKtZZqmBfzeeUj5hKYAMp.png?dl=1\" title=\"W&amp;amp;B Chart 12_16_2022, 3_12_11 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/5f9d03b825103840e76e8a66e4499ab603ea22e9_2_690x362.png\" alt=\"W&amp;B Chart 12_16_2022, 3_12_11 PM\" data-base62-sha1=\"dDPLeeNKtZZqmBfzeeUj5hKYAMp\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/5f9d03b825103840e76e8a66e4499ab603ea22e9_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/5f9d03b825103840e76e8a66e4499ab603ea22e9_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/5f9d03b825103840e76e8a66e4499ab603ea22e9_2_1380x724.png 2x\" data-dominant-color=\"FBFAFC\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">W&amp;amp;B Chart 12_16_2022, 3_12_11 PM</span><span class=\"informations\">2780\u00d71460 356 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nThanks in advance.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-16T14:16:05.548Z",
				"Answer_body": "<p>Because it did not let me post two images, I am posting here the initial graoh with all the folds.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/9/9a2a725f2461f1b385e18d9255d5ee960dcee3f1.jpeg\" data-download-href=\"/uploads/short-url/lZOthdL87QRSrrJ4wspHz5ydaTv.jpeg?dl=1\" title=\"W&amp;amp;B Chart 12_16_2022, 3_11_58 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/9/9a2a725f2461f1b385e18d9255d5ee960dcee3f1_2_690x362.jpeg\" alt=\"W&amp;B Chart 12_16_2022, 3_11_58 PM\" data-base62-sha1=\"lZOthdL87QRSrrJ4wspHz5ydaTv\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/9/9a2a725f2461f1b385e18d9255d5ee960dcee3f1_2_690x362.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/9/9a2a725f2461f1b385e18d9255d5ee960dcee3f1_2_1035x543.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/9/9a2a725f2461f1b385e18d9255d5ee960dcee3f1_2_1380x724.jpeg 2x\" data-dominant-color=\"FAF9FB\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">W&amp;amp;B Chart 12_16_2022, 3_11_58 PM</span><span class=\"informations\">1920\u00d71008 90.8 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-19T19:44:21.485Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/soulios\">@soulios</a>!</p>\n<p>So from your description of the issue, looks like the epochs are being overwritten as the folds progress, leading to this issue. Here are 2 solutions that would work here:</p>\n<ol>\n<li>Consider each fold as an individual run. You can use the <code>group</code> parameter to consolidate all your folds into individual experiments.</li>\n<li>Log a different key for each fold as:</li>\n</ol>\n<pre data-code-wrap=\"python3\"><code class=\"lang-plaintext\">wandb.log({\n  \"Metric\" : metric\n  f\"Fold {fold} Epoch\" : epoch\n})\n</code></pre>\n<p>or</p>\n<pre data-code-wrap=\"python3\"><code class=\"lang-plaintext\">wandb.log({\n  f\"Fold {fold} Metric\" : metric\n  f\"Fold {fold} Epoch\" : epoch\n})\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-20T07:52:31.459Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a> ! Thans for the reply. So the first plot refers to the last fold essentially?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-27T04:44:48.062Z",
				"Answer_body": "<p>Yup, that\u2019s correct.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-02T18:04:20.302Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-05T14:40:55.341Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/soulios\">@soulios</a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-25T04:45:40.363Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Unable to manage columns in project run table",
		"Question_link": "https://community.wandb.ai/t/unable-to-manage-columns-in-project-run-table/3551",
		"Question_created_time": "2022-12-14T19:24:08.938Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 423,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>I just started a new project and recorded my first runs. Unfortunately, I am unable to add the \u201caccuracy\u201d, \u201closs\u201d, \u201cval_accuracy\u201d and \u201cval_loss\u201d columns to the visible columns.  When I try to drag them to the visible columns they remain in the hidden columns.</p>\n<p>Thanks for your support.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-15T15:37:49.214Z",
				"Answer_body": "<p>Hi Susanne!</p>\n<p>Can you send me the workspace this is happening in?</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-20T18:09:52.626Z",
				"Answer_body": "<p>Hi Susanne,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-23T21:07:35.766Z",
				"Answer_body": "<p>Hi Susanne, since we have not heard back from you, we will close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-26T08:14:56.109Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/artsiom\">@artsiom</a>  This seems to be a \u201crefresh\u201d problem with Google Chrome. After organizing the columns\u2026 without seeing what is happening I have to resfresh the browser to see the results.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-24T08:15:05.297Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "All my plots start at epoch 2",
		"Question_link": "https://community.wandb.ai/t/all-my-plots-start-at-epoch-2/3593",
		"Question_created_time": "2022-12-23T21:50:17.765Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 328,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>See screenshots below. Each model has been trained for 3 epochs so far. They all started from 0, and the info panel shows that the most recent epoch was 2 and \u201cbest\u201d is 0. Looking at the plots though, it looks like all the plots cover epochs 2 through 4.</p>\n<p>I\u2019m calling keras <code>model.fit</code> with <code>from_epoch=0</code>. I\u2019m running inside a <code>ray</code> worker so maybe that\u2019s causing some problems?</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/6/674f340076209ecba401fa6747a6418e31e1f2fe.png\" data-download-href=\"/uploads/short-url/eJUS1BdlLEVdGhqEUtHrBXnO9Q2.png?dl=1\" title=\"Screenshot 2022-12-24 at 8.45.46 am\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/6/674f340076209ecba401fa6747a6418e31e1f2fe_2_690x288.png\" alt=\"Screenshot 2022-12-24 at 8.45.46 am\" data-base62-sha1=\"eJUS1BdlLEVdGhqEUtHrBXnO9Q2\" width=\"690\" height=\"288\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/6/674f340076209ecba401fa6747a6418e31e1f2fe_2_690x288.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/6/674f340076209ecba401fa6747a6418e31e1f2fe.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/6/674f340076209ecba401fa6747a6418e31e1f2fe.png 2x\" data-dominant-color=\"202121\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2022-12-24 at 8.45.46 am</span><span class=\"informations\">788\u00d7329 16.3 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/b/b82b054b707b56a829f444969855ec256c85aee5.png\" alt=\"Screenshot 2022-12-24 at 8.44.29 am\" data-base62-sha1=\"qhe1BKuwPFD8WbPpt39n8Mz0TKR\" width=\"456\" height=\"269\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-23T22:11:00.703Z",
				"Answer_body": "<p>Oh it seems the x-axis is \u201cStep\u201d, not epoch. How is this calculated?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-27T11:41:57.164Z",
				"Answer_body": "<p>Hi Tom,</p>\n<p>Thanks for writing in! So the step is calculated every time there is a call to <code>wandb.log(</code>, you can see more details in our docs. If you click on the Edit panel button (a pencil) in the top right corner of the chart, you can select the epoch as X axis. I just checked in your project and it starts in 0. Please let me know if I can help you in any other way!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-12-30T09:10:32.558Z",
				"Answer_body": "<p>Hi TomBirch,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-21T22:11:10.528Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Cache image in the wandb board?",
		"Question_link": "https://community.wandb.ai/t/cache-image-in-the-wandb-board/3510",
		"Question_created_time": "2022-12-07T16:18:22.330Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 340,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I\u2019m running a ML project where I need to log images every 10 epochs or so. Since I run for a large number of epochs, I often end up with a lot of images.</p>\n<p>I would like to get a sense of how the image quality improves overtime, however it is difficult to do so when the images have to load every time. Is there a way to cache the images in the board somehow?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-09T01:24:39.669Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lthiet\">@lthiet</a> , happy to look into this for you, are you logging experiments on a local private installation or to our cloud. If cloud please share a link to your workspace (will remain private, only support will have access to it). Thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-09T17:25:25.837Z",
				"Answer_body": "<p>I log all of my experiments locally</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-15T00:13:03.234Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lthiet\">@lthiet</a>, for local instance users with large projects we recommend they configure an external redis server for caching to improve load times, see <a href=\"https://docs.wandb.ai/guides/self-hosted/setup/configuration#advanced-reliability-settings\">here</a>. Is this an option that is available to you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-16T22:20:37.744Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lthiet\">@lthiet</a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-23T14:11:20.953Z",
				"Answer_body": "<p>Sorry for the late answer, I will try that, thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-21T14:11:43.402Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Error while using W&B on Vertex AI GCP",
		"Question_link": "https://community.wandb.ai/t/error-while-using-w-b-on-vertex-ai-gcp/3583",
		"Question_created_time": "2022-12-22T12:23:27.808Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 146,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\nRecently I switched from AWS to GCP, and when I try to run wandb.init() it keeps raising the following error</p>\n<pre><code class=\"lang-auto\">wandb: Network error (ConnectTimeout), entering retry loop.\nwandb: Network error (ConnectTimeout), entering retry loop.\nwandb: ERROR Error communicating with wandb process\nProblem at: /tmp/ipykernel_1/1411081884.py 2 &lt;module&gt;\nUsageError: Error communicating with wandb process\n</code></pre>\n<p>It seems that the notebook has some restrictions on connecting with the web, is there anything I can do to overcome this error?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-27T11:36:22.923Z",
				"Answer_body": "<p>Hi Ahmad,</p>\n<p>Thanks for writing in! I let you here a public report where it is explained how to integrate W&amp;B with Vertex AI. Please let me know if this is useful!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-30T09:14:09.560Z",
				"Answer_body": "<p>Hi Ahmad,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-20T12:23:35.365Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Team Permission Issues",
		"Question_link": "https://community.wandb.ai/t/team-permission-issues/3579",
		"Question_created_time": "2022-12-21T19:12:13.537Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 127,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m having issues with a team I created. Despite me creating the team I somehow am not the admin. In fact, nobody is an admin. I have been trying to delete some sweeps that I set up incorrectly and it\u2019s not letting me do this. If I go to organization settings I am the admin. I\u2019m not sure how to fix this and would appreciate some help</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-21T19:21:44.465Z",
				"Answer_body": "<p>I managed to solve the issue by adding myself to the organization again. I did not leave the team nor organization - simply adding myself to the organization and team as admin (despite already being in both) worked</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-22T14:38:01.747Z",
				"Answer_body": "<p>Hi Tim,</p>\n<p>Thanks for writing in! So if I am understanding you properly, this issue was resolved right? Please let me know if I can further assist you with anything else.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-19T19:22:05.731Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Retrieve all the sweeps in a team project",
		"Question_link": "https://community.wandb.ai/t/retrieve-all-the-sweeps-in-a-team-project/3534",
		"Question_created_time": "2022-12-12T08:49:21.489Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 134,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I was trying to retrieve all the sweeps in a project, I did the following:</p>\n<pre><code class=\"lang-auto\">sweeps = wandb.Api().project(&lt;project_name&gt;, entity=&lt;team_name&gt;).sweeps()\n</code></pre>\n<p>However, I got the error that Project object has no attribute sweeps.</p>\n<p>Can you please help with it?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-13T13:52:46.373Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohamedr002\">@mohamedr002</a> thank you for writing in! Can you please confirm you wandb version, and if you could try again by upgrading to our latest SDK version <code>0.13.6</code>? Your one line code is correct and works for me, so could you also check running the following:</p>\n<pre><code class=\"lang-auto\">api = wandb.Api()\np = api.project('PROJECT', entity='ENTITY')\nprint(p.url)\n</code></pre>\n<p>Would this return a URL to your project, and can you see if there are Sweeps in it?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-16T15:18:06.368Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohamedr002\">@mohamedr002</a> I wanted to follow up on this issue, does it still occur for you and could you provide a bit more details to assist you further? thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-21T17:45:23.949Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohamedr002\">@mohamedr002</a> since we haven\u2019t heard back from you, I will go ahead and close this ticket for now. If you\u2019re still experiencing any issue retrieving the sweeps please let us know and we will be happy to keep investigating!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-19T17:46:04.673Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Disable : \"Showing a bar chart instead of a line chart because all logged values are length one.\"",
		"Question_link": "https://community.wandb.ai/t/disable-showing-a-bar-chart-instead-of-a-line-chart-because-all-logged-values-are-length-one/3562",
		"Question_created_time": "2022-12-16T17:52:21.382Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 166,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>Is there a way to disable bar chart conversion of line charts that only have a single x value?<br>\nI have a chart that changed to a bar chart but no option to change it back to a line chart<br>\n<em>Showing a bar chart instead of a line chart because all logged values are length one.</em></p>\n<p>The issue is that the bar chart does not show a relation between the different runs.<br>\nMy variable logs the final accuracy but because it is bar chart that is simply ordered by experiment execution order it is very hard to assess the ranking of all runs.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/f/fe84452d092f2dc117b94f1a3a8bc9d34e01c9f9.png\" data-download-href=\"/uploads/short-url/AjyFeL7Tw01SYLTbfpy80ZtLF2x.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/f/fe84452d092f2dc117b94f1a3a8bc9d34e01c9f9.png\" alt=\"image\" data-base62-sha1=\"AjyFeL7Tw01SYLTbfpy80ZtLF2x\" width=\"690\" height=\"294\" data-dominant-color=\"DACFD5\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">700\u00d7299 2.39 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nI would rather see the a line chart with a single x step</p>\n<p>Kind regards,<br>\nMaxim</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-21T05:58:23.169Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mxbonn\">@mxbonn</a>,</p>\n<p>While there is no way to disable this currently, since the bar chart works better in most cases when comparing scalars, you could get a similar visualization to what you are looking for with our Custom Charts feature.</p>\n<p>You could set one up as the following screenshot  (replace <code>x</code> for the metric you would like to visualize):</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/c/cb461f520c806fb43b6bae785d100a1146538f97.png\" data-download-href=\"/uploads/short-url/t0fa6jJ6fYF7fuPvIVfrOOKlhCD.png?dl=1\" title=\"Screenshot from 2022-12-20 00-08-16\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/cb461f520c806fb43b6bae785d100a1146538f97_2_653x500.png\" alt=\"Screenshot from 2022-12-20 00-08-16\" data-base62-sha1=\"t0fa6jJ6fYF7fuPvIVfrOOKlhCD\" width=\"653\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/cb461f520c806fb43b6bae785d100a1146538f97_2_653x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/c/cb461f520c806fb43b6bae785d100a1146538f97.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/c/cb461f520c806fb43b6bae785d100a1146538f97.png 2x\" data-dominant-color=\"F7F8F8\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot from 2022-12-20 00-08-16</span><span class=\"informations\">925\u00d7708 33.2 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Please let me know if this helps!</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-26T20:55:05.954Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mxbonn\">@mxbonn</a>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-02T18:41:15.573Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mxbonn\">@mxbonn</a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-19T05:59:14.304Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Feature Request: Nested Tags",
		"Question_link": "https://community.wandb.ai/t/feature-request-nested-tags/3574",
		"Question_created_time": "2022-12-19T16:37:37.068Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 254,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Tags are a very powerful feature for organising experiment runs - it would be nice to have the ability to use nested tags as well, for instance:</p>\n<pre><code class=\"lang-auto\">#tag1\n#tag1/feature1\n#tag1/feature2\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-20T12:58:23.658Z",
				"Answer_body": "<p>Hi Daniel,</p>\n<p>Thank you for suggesting this! Would you mind explaining a little bit about your use-case, where do you find this useful?</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-23T10:12:29.768Z",
				"Answer_body": "<p>Hi Daniel,</p>\n<p>I wanted to follow up here! I can create a new request for this feature but could you please explain me a little bit about your use-case? Thanks!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-17T16:37:52.449Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Adding Image() to a Report programatically",
		"Question_link": "https://community.wandb.ai/t/adding-image-to-a-report-programatically/3266",
		"Question_created_time": "2022-10-17T06:03:20.457Z",
		"Question_answer_count": 14,
		"Question_score_count": 0,
		"Question_view_count": 352,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,<br>\nI am experimenting with programmatic report generation using Python.<br>\nI understand that reports are a beta feature.<br>\nI would like to add an Image object to a report.  The image was generated in MatPlotLib and rendered using PIL.  I\u2019ve read the documentation but there is little if any mention of how to handle <code>Image</code> objects, other than a brief mention that they are supported.</p>\n<p>I am getting the following error:</p>\n<pre><code class=\"lang-auto\">TypeError: url object must be of type (&lt;class 'str'&gt;,) (got &lt;class 'PIL.PngImagePlugin.PngImageFile'&gt;)\n</code></pre>\n<p>The generating code for the report looks like:</p>\n<pre><code class=\"lang-auto\">blocks  = []\nblocks += [wr.MarkdownBlock(text=\"Markdown cell with *italics* and **bold** and $e=mc^2$\")]\nfor result in results:\n    if result:\n        blocks += wr.PanelGrid(panels=[wr.Image(result['image'], caption=f\"Subject={result['subject']}\")])\nreport.blocks = blocks\nreport.save()</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-17T13:53:30.951Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> thanks for writing in, and glad to hear you are trying the Reports API. Currently, the Image object can\u2019t be inside the PanelGrid.  Could you please try the following code snippet and let me know if that worked for you?</p>\n<pre><code class=\"lang-auto\">blocks  = []\nblocks += [wr.MarkdownBlock(text=\"Markdown cell with *italics* and **bold** and $e=mc^2$\")]\nfor result in results:\n    if result:\n        blocks += [wr.Image(result['image'], caption=f\"Subject={result['subject']}\")]\nreport.blocks = blocks\nreport.save()\n</code></pre>\n<p>Please also have a look at <a href=\"https://colab.research.google.com/drive/1Fepp-JLFvK-wLL2BZ_BnkCG_fAC6HFbo#scrollTo=An_example_with_all_of_the_blocks_and_panels\" rel=\"noopener nofollow ugc\">this Colab</a> which you may find useful to find the currently supported features. The Python SDK view of our r<a href=\"https://docs.wandb.ai/guides/reports/edit-a-report#add-plots\">eference docs here</a> may help as well.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-17T20:00:12.129Z",
				"Answer_body": "<p>Hi thanos-wandb,<br>\nThat makes perfect sense.  I should have seen that.<br>\nI will implement it!<br>\nThanks!<br>\n-K</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-18T03:37:41.187Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a><br>\nI\u2019m getting the following error:</p>\n<pre><code class=\"lang-auto\">AttributeError: read\n</code></pre>\n<p>Here is the basic code:</p>\n<pre><code class=\"lang-auto\">import wandb.apis.reports as wr\nfrom PIL import Image\nbuf = io.BytesIO()\nplt.gcf().set_size_inches(PLOT_PICTURE_WIDTH, PLOT_PICTURE_HEIGHT)\nplt.savefig(buf, format='png', dpi=PLOT_DPI)\nblocks += [wr.Image(Image.open(buf))]</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-19T09:54:18.548Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> the wr.Image doesn\u2019t support the <code>PIL.PngImagePlugin.PngImageFile</code> type that you pass as input. If you change this argument to a <code>PNG</code> image it will work.</p>\n<p>For instance you may try the following:<br>\n<code>blocks += [wr.Image(url=\"https://assets.website-files.com/5ac6b7f2924c656f2b13a88c/5ecb633d54bd2fe1e0378852_logo%20white.png\",  caption=\"W&amp;B logo\")]</code></p>\n<p>I hope this helps, please let me know if you have any further questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-19T15:52:10.396Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a> ,<br>\nThank you for the help.<br>\nI will note that the above command parallels how I write to <code>wandb.log()</code>.  I avoid file-system writes and instead write to an in-memory file buffer and then hand <code>PIL.Image.open()</code> to the log method, since this saves time and avoids file-system hassles.  Its much faster and I have a lot of images that I need to upload.<br>\nAnd It would be very helpful in the different parts of WandB worked in similar ways.<br>\nIt would also be very helpful if there was documentation for this particular option.  The ability to add images is mentioned, but there is no example or explanation.<br>\nAnd yes, I understand that this is a beta feature.  Its just a really important feature for us!<br>\nThank you for your help!<br>\nKevin</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-24T12:47:45.417Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> thanks for the additional context! That\u2019s indeed more efficient way and there is a workaround that could help you do this.  It required though to first log these images in a dummy run. Please see below a code snippet:</p>\n<pre><code class=\"lang-auto\">wandb.init(entity=ENTITY, project=PROJECT)\nbuf = io.BytesIO()\nplt.gcf().set_size_inches(PLOT_PICTURE_WIDTH, PLOT_PICTURE_HEIGHT)\nplt.savefig(buf, format='png', dpi=PLOT_DPI)\nexample = wandb.Image(Image.open(buf))\nwandb.log({\"example\": example})\nwandb.finish()\n\nreport = wb.Report(\n    project=PROJECT,\n    title=\"Report Adding Images from runs media files\",\n    blocks=[wb.PanelGrid(panels=[wb.MediaBrowser(media_keys=\"example\")])]\n)\nreport.save()\n</code></pre>\n<p>Please let me know if there are any issues or further questions about this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-27T14:59:14.419Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> just checking in to see if the above code did the trick for you? thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-01T16:09:13.070Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> since we haven\u2019t heard back from you, I will close this ticket for now. If you still experience issues with this, please let us know to re-open the ticket and keep investigating.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-10T09:04:17.593Z",
				"Answer_body": "<p>Hi Thanos,<br>\nThank you for the help.<br>\nI implemented the code as you described:</p>\n<ol>\n<li>First log the image as a normal PNG bitmap.</li>\n<li>Connect the already existing image to the report using the <code>wr.MediaBrowser()</code> operation.</li>\n</ol>\n<p>Unfortunately, this does not actually display the image, but instead shows a browser panel.<br>\nSince this is a Report that needs to be exportable to a PDF document, the browser is not very useful.<br>\nInstead I need to be able to display the image itself, as one might in a typical PDF report.<br>\nSee example below of the actual \u201cimages\u201d in the report.  Do you have any recommendations?</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/c/c77857e7988a76fa160c111462d0dcbade450b9a.png\" data-download-href=\"/uploads/short-url/ssAQLGXM9IDJ1TMKUrVPgAoROky.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/c77857e7988a76fa160c111462d0dcbade450b9a_2_564x500.png\" alt=\"image\" data-base62-sha1=\"ssAQLGXM9IDJ1TMKUrVPgAoROky\" width=\"564\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/c77857e7988a76fa160c111462d0dcbade450b9a_2_564x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/c77857e7988a76fa160c111462d0dcbade450b9a_2_846x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/c77857e7988a76fa160c111462d0dcbade450b9a_2_1128x1000.png 2x\" data-dominant-color=\"222222\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1858\u00d71646 149 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-16T16:23:15.506Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a> Will you be able to reply to this?  Thank you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-16T20:42:36.159Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> apologies for the late response here. Since you logged the image, these images should be available in your Run/Files/media/image_key/ folder from the UI? If you click in one image there that would give a URL which you could use for the previous approach:<br>\n<code>wr.Image(url=\"https://wandb.ai/ENTITY/PROJECT/runs/RUN-ID/files/media/IMAGE_KEY/NAME.png\",   caption=\"Example\")</code><br>\nCan you please try this for one image and see if it works for you and displayed in report as needed? I could then provide you with a code snippet to get all the file names under the media folder.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-04T20:32:11.091Z",
				"Answer_body": "<p>Hi Thanos,<br>\nYes, any help would be appreciated. I really need to complete this project.<br>\nHere is an example URL for an image: (URL sent by email)<br>\nThere must be a simpler way to populate images in reports.  The whole point of programmatically generating reports is to be able to insert objects, charts, text and graphs into it.  Is there a plan to provide the ability to post images directly?<br>\nThanks,<br>\nKevin</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-18T20:22:53.480Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> I had followed up with you by email, but also posting here a snippet that may help you get the images logged in a run using the API, and then use these to programmatically populate a report:</p>\n<pre><code class=\"lang-auto\">import wandb\nimport wandb.apis.reports as wr\napi = wandb.Api()\nrun = api.run('ENTITY/PROJECT/run-id')\n\nurls=[]\nfor f in run.files(per_page=1000):\n    if f.name.endswith('png'):\n        print(f.name, f.url)\n        urls.append(f.url)\n\nwandb.require(\"report-editing\")\nreport = wr.Report(project='report-api-images', title='Report of media/images')\nreport.blocks = [\nwr.Image(im_url, caption='Image') for im_url in urls\n]\nreport.save()\n</code></pre>\n<p>I hope this helps, and please let me know if you have any further questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-16T20:23:09.503Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to customize Advanced Legend to display a string",
		"Question_link": "https://community.wandb.ai/t/how-to-customize-advanced-legend-to-display-a-string/3498",
		"Question_created_time": "2022-12-05T05:35:29.261Z",
		"Question_answer_count": 9,
		"Question_score_count": 0,
		"Question_view_count": 319,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello W&amp;B community!<br>\nFor a custom project within our company, we attempt to compare various models across a list of category.<br>\nWe therefore want to visualize, for each version of our model:</p>\n<ul>\n<li>for each category (a string)</li>\n<li>a score (float in 0,1).</li>\n</ul>\n<p>Here is how we log scores in W&amp;B (simplified for easy understanding):</p>\n<pre><code class=\"lang-auto\">    scores = [0.3, 0.5, 0.6, ...]\n    categories = ['dog', 'cat', 'fish', ...]\n    for k, (val, name) in enumerate(zip(scores, categories)):\n        wandb.log({\n                    f\"score\": val,\n                    f\"category\": name,\n                    f\"id\": k\n                })\n</code></pre>\n<p>Here is the graph associated with this code:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/e/ebc8c5a33c454d8dbd51c5ae856934adb624544d.jpeg\" data-download-href=\"/uploads/short-url/xDQmaIYqXkpCtcwGLMp3ch9QtmR.jpeg?dl=1\" title=\"Screenshot from 2022-12-05 14-29-41\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ebc8c5a33c454d8dbd51c5ae856934adb624544d_2_690x373.jpeg\" alt=\"Screenshot from 2022-12-05 14-29-41\" data-base62-sha1=\"xDQmaIYqXkpCtcwGLMp3ch9QtmR\" width=\"690\" height=\"373\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ebc8c5a33c454d8dbd51c5ae856934adb624544d_2_690x373.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ebc8c5a33c454d8dbd51c5ae856934adb624544d_2_1035x559.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ebc8c5a33c454d8dbd51c5ae856934adb624544d_2_1380x746.jpeg 2x\" data-dominant-color=\"F6F8F8\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot from 2022-12-05 14-29-41</span><span class=\"informations\">1389\u00d7751 103 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Now as you can see in the picture: For each version (td_ver), we display the \u201cscore\u201d (y) for each \u201cid\u201d (x). When we hover over the score itself, we do not want to show the \u201cid\u201d, but the \u201cname\u201d<br>\n(In the image, instead of displaying \u201c25\u201d highlighted in red, we want to display \u201cfish\u201d.</p>\n<p>I assume this change needs to happen in the \u201cAdvanced Legend\u201d section, but I could not find the correct spelling for that formula.</p>\n<pre><code class=\"lang-auto\">original:\n [[ ${x}: ${y} (${original})]] ${run:displayName}\n\nnew:\n???\n</code></pre>\n<p>Thanks a lot for your help!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-07T01:02:51.662Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/roland_roms\">@roland_roms</a> , happy to help. To update your legend to read \u201cfish\u201d instead of the \u201cid\u201d (x), use the following</p>\n<p><code> [[ fish: ${y} ]] ${run:displayName}</code></p>\n<p>Please let me know if you have any questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-07T01:58:12.803Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> , thank you for your answer!</p>\n<p>Sorry if my question wasn\u2019t asked properly:  I do not want the string \u201cfish\u201d to be displayed, but the name of the category.<br>\nAs you can see in the code I shared previously, each score is associated with a category: (scores[1] is for the categories[1], etc).<br>\nWith your solution, it would replace all occurrences of the ID ( ${x} ) by fish.<br>\nWhat I need is to have the first score with the first category (cat), the second score with the second category (dog), and so on\u2026</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-09T20:53:46.329Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/roland_roms\">@roland_roms</a> , appreciate the clarification. If you were to include your class categories in the run configuration, then you can reference that in your legend, see <a href=\"https://docs.wandb.ai/ref/app/features/panels/line-plot/reference#legend\">here</a>. This would look like</p>\n<p><code>[[ ${config:category}: ${y} ]] ${run:displayName}</code></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-12T03:08:21.753Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"mohammadbakir\" data-post=\"4\" data-topic=\"3498\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/m/a9a28c/40.png\" class=\"avatar\"> mohammadbakir:</div>\n<blockquote>\n<p>you were to include your class categories in the run configuration, then you can reference that in</p>\n</blockquote>\n</aside>\n<p>Thank you for your answer, but it does not work.<br>\nFollowing your advice, I added categories to the config, and tried to call it in various ways in Advanced legend:</p>\n<pre><code class=\"lang-python\">import wandb\n\nscores = [0.3, 0.5, 0.6]\ncategories = ['dog', 'cat', 'fish']\n\nconfig = {\"categories\": categories,\n            \"id_cat\": {0: \"dog\", 1:\"cat\", 2:\"fish\"}}\n\nwandb.init(project=\"dummy_test\", name=\"dummy_demo\", config=config)\nfor k, (val, name) in enumerate(zip(scores, categories)):\n    wandb.log({\n                \"score\": val,\n                \"category\": name,\n                \"categories\": name,\n                \"id_cat\": name,\n                \"id\": k\n            })\nwandb.finish()\n</code></pre>\n<p>As you can see, I tried to add it in various ways (categories or id_cat) and to call them in various ways inside the advanced legend. It never worked properly.</p>\n<p>Regarding the documentation you shared <a href=\"https://docs.wandb.ai/ref/app/features/panels/line-plot/reference#ignore-outliers\">here</a>, two points are to be highlighted:</p>\n<blockquote>\n<p>You can set value inside<code>[[ ]]</code> to display point specific values in the crosshair when hovering over a chart<br>\nAnd</p>\n</blockquote>\n<blockquote>\n<p>Supported values inside [<span class=\"chcklst-box fa fa-square-o fa-fw\"></span>] are as follows: \u2026<br>\n\u201cconfig\u201d is not part of these supported values. summary is also not supported. Therefore, I don\u2019t think it is possible to display it this way.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/e/ead33e06bdd6b38ebfc3bf256f570c7c02ddac64.jpeg\" data-download-href=\"/uploads/short-url/xvmjnEuXd20NUT3wOUv65YK0pi4.jpeg?dl=1\" title=\"Screenshot from 2022-12-12 12-07-53\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ead33e06bdd6b38ebfc3bf256f570c7c02ddac64_2_690x230.jpeg\" alt=\"Screenshot from 2022-12-12 12-07-53\" data-base62-sha1=\"xvmjnEuXd20NUT3wOUv65YK0pi4\" width=\"690\" height=\"230\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ead33e06bdd6b38ebfc3bf256f570c7c02ddac64_2_690x230.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ead33e06bdd6b38ebfc3bf256f570c7c02ddac64_2_1035x345.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ead33e06bdd6b38ebfc3bf256f570c7c02ddac64_2_1380x460.jpeg 2x\" data-dominant-color=\"FAFAF9\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot from 2022-12-12 12-07-53</span><span class=\"informations\">1833\u00d7612 84.3 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n</blockquote>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-12T03:34:37.674Z",
				"Answer_body": "<p>I have found a temporary solution, that gives a similar result (but not exactly the same).</p>\n<ol>\n<li>I run a first time, logging only categories:</li>\n</ol>\n<pre><code class=\"lang-python\">import wandb\n\nscores = [0.3, 0.5, 0.6]\ncategories = ['dog', 'cat', 'fish']\n\nwandb.init(project=\"dummy_test\", name=\"categories\")\nfor k, (val, name) in enumerate(zip(scores, categories)):\n    wandb.log({\n                # \"score\": val,\n                \"category\": name\n            })\nwandb.finish()\n</code></pre>\n<ol start=\"2\">\n<li>I can then run wandb logs without the categories, but with the scores (I run a first time with the version_1 scores, then a second time with version_2 scores, etc):</li>\n</ol>\n<pre><code class=\"lang-python\">import wandb\n\nscores = [0.3, 0.5, 0.6]\ncategories = ['dog', 'cat', 'fish']\n\nwandb.init(project=\"dummy_test\", name=\"version_1\")\nfor k, (val, name) in enumerate(zip(scores, categories)):\n    wandb.log({\n                \"score\": val,\n                # \"category\": name\n            })\nwandb.finish()\n</code></pre>\n<ol start=\"3\">\n<li>In wandb display pannel, I create a new line plot with the following Data as Y:</li>\n</ol>\n<ul>\n<li>\u201ccategory\u201d (Added manually via \u201cregular expression\u201d)</li>\n<li>score</li>\n</ul>\n<ol start=\"4\">\n<li>In Advanced Legend, I set up the formula as:</li>\n</ol>\n<blockquote>\n<p>[[ ${x}: ${y} ]] ${run:displayName}</p>\n</blockquote>\n<p>It gives me the following results:<br>\n(top: first point appearing as \u201cdog\u201d. bottom: second point appearing as \u201ccat\u201d)<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/5/5c2daa076374d2fba03b113aa392b82d794efd22.jpeg\" data-download-href=\"/uploads/short-url/d9rLgnww2wkjwIxLwLxWGS1x4SS.jpeg?dl=1\" title=\"Screenshot from 2022-12-12 12-33-48\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/5c2daa076374d2fba03b113aa392b82d794efd22_2_690x416.jpeg\" alt=\"Screenshot from 2022-12-12 12-33-48\" data-base62-sha1=\"d9rLgnww2wkjwIxLwLxWGS1x4SS\" width=\"690\" height=\"416\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/5c2daa076374d2fba03b113aa392b82d794efd22_2_690x416.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/5/5c2daa076374d2fba03b113aa392b82d794efd22_2_1035x624.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/5/5c2daa076374d2fba03b113aa392b82d794efd22.jpeg 2x\" data-dominant-color=\"FBFBF9\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot from 2022-12-12 12-33-48</span><span class=\"informations\">1302\u00d7785 107 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-13T01:48:44.904Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/roland_roms\">@roland_roms</a> , please see <a href=\"https://wandb.ai/mohammadbakir/Legend-Test?workspace=user-mohammadbakir\">this project example</a> that produces the following chart.  I used</p>\n<p><code>[[ ${x}: ${y} ]] ${run:displayName}:${config:animal}</code> to customize the legend and include animal types. Is this what you intend to accomplish?</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/c/c9e65e451857ca3dcc0ae8f53abd2820af307193.png\" data-download-href=\"/uploads/short-url/sO5x3MvHl2n7R0aeubOwsUZoBZF.png?dl=1\" title=\"CustomLegend\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/c9e65e451857ca3dcc0ae8f53abd2820af307193_2_690x227.png\" alt=\"CustomLegend\" data-base62-sha1=\"sO5x3MvHl2n7R0aeubOwsUZoBZF\" width=\"690\" height=\"227\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/c9e65e451857ca3dcc0ae8f53abd2820af307193_2_690x227.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/c9e65e451857ca3dcc0ae8f53abd2820af307193_2_1035x340.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/c/c9e65e451857ca3dcc0ae8f53abd2820af307193_2_1380x454.png 2x\" data-dominant-color=\"F7F8F8\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">CustomLegend</span><span class=\"informations\">1821\u00d7600 101 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<pre><code class=\"lang-auto\">import wandb\nimport random\n\ncategories = [\"cat\",\"dog\",\"frog\"]\n\nfor animal_type in categories:\n    config = {\"animal\": animal_type}\n\n    run1 = wandb.init(\n        project=\"Legend-Test\",\n        config=config,\n    )\n\n    epochs = 10\n    offset = random.random() / 5\n    for epoch in range(epochs):\n        acc = 1 - 2 ** -epoch - random.random()  - offset \n        run1.log({\"acc\": acc})\n\n    run1.finish()\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-13T02:15:47.560Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> . Thank you so much for your time and answer!<br>\nYour solution would be great in a different scenario, but it\u2019s not what I aim for.</p>\n<ul>\n<li>In your example, there is one line for each category (you have one run for \u201ccat\u201d, one for \u201cdog\u201d, etc). With multiple values for each one of them.</li>\n<li>What I have is one value per category. But multiple types of runs.</li>\n</ul>\n<p>Let\u2019s say that I want to compare two kinds of models (Yolov4 or Yolov5) for finding animals in images.<br>\nI train my model, then test yolov4 on 100 images of dogs, 100 images of cats, etc. Same for Yolov5.<br>\nI then get an average score for yolov4 on cats. then a score for yolov4 on dogs, etc. Same for yolov5.</p>\n<p>Now I want to compare both models: first line are the scores for yolov4 (score for cats, then for dogs, then for frog). Second line are the same scores, but for yolov5.</p>\n<p>Now each point of the line is for a category (cats, dogs, frogs). With the current system, I can see that \u201cfor the third point, yolov4 is better than yolov5\u201d. But I cannot say what the third point is (cats, dogs, frogs, or something else).</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-16T23:44:58.807Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/roland_roms\">@roland_roms</a> , thank you for the additional info and clarification. This is not doable natively via wandb and your proposed work around solution is the closest currently. As our charts use <a href=\"https://vega.github.io/vega/\" rel=\"noopener nofollow ugc\">Vega</a>, you may be able to accomplish this using <a href=\"https://docs.wandb.ai/ref/app/features/custom-charts\">custom charts</a>. Please do let me know if you have any other questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-14T23:45:45.542Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Run Time is inaccurate because of including upload time",
		"Question_link": "https://community.wandb.ai/t/run-time-is-inaccurate-because-of-including-upload-time/3499",
		"Question_created_time": "2022-12-05T14:04:58.960Z",
		"Question_answer_count": 8,
		"Question_score_count": 0,
		"Question_view_count": 145,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Some runs will spend minutes because of my terrible network:</p>\n<pre><code class=\"lang-shell\">wandb: Waiting for W&amp;B process to finish... (success).\n</code></pre>\n<p>I find the Run Time column in UI will also contain the uploading time (by comparing with other runs\u2019 Run Time).</p>\n<p>My script is organized as follow:</p>\n<pre><code class=\"lang-python\">def main(config):\n    ...\n    wandb.init(wandb_config)\n    ...\n\nif __name__ == '__main__':\n    config = blabla\n    for p in [p1, p2, p3]:  # for loop to tune hyperparameters\n        config.param = p\n        main(config)\n</code></pre>\n<p>To fix this issue, should I use <code>wandb.finish</code> in the end of the <code>main()</code> function? As the <a href=\"https://docs.wandb.ai/ref/python/finish\">doc</a> of <code>wandb.finish</code> lists:</p>\n<blockquote>\n<p>Marks a run as finished, and finishes uploading all data.</p>\n</blockquote>\n<p>I worry about whether this func will kill my slow data uploading worker.</p>\n<p>Or any other solutions?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-06T10:04:08.165Z",
				"Answer_body": "<p>I find the Run Time is also inaccurate when sync the offline-run instance. After sync, the Run-Time is about 1 min (seems to be the time spent on the sync command).</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-08T14:34:09.006Z",
				"Answer_body": "<p>Hi Yago!</p>\n<p>Looking into this.</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-14T22:12:44.048Z",
				"Answer_body": "<p>Hi Yao!</p>\n<p>Sorry for the late response. I have consulted with a few others on my team and this seems to be a bug, considering the fact that you still get the wrong time using the offline mode.</p>\n<p>Would you send us some info on how to reproduce this so we can fix it asap?</p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-16T10:05:55.002Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"artsiom\" data-post=\"4\" data-topic=\"3499\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://sea2.discourse-cdn.com/business7/user_avatar/community.wandb.ai/artsiom/40/1001_2.png\" class=\"avatar\"> artsiom:</div>\n<blockquote>\n<p>reproduce</p>\n</blockquote>\n</aside>\n<p>I think reproduce this issue is easy.</p>\n<ol>\n<li>Run wandb in offline mode.</li>\n<li>After the run is finish, use <code>wandb sync run_path</code> command to upload the run.</li>\n<li>The RunTime colum is several seconds (time the <code>sync</code> command spent) in the UI of uploaded run.</li>\n</ol>\n<p>My test code is like:</p>\n<pre><code class=\"lang-python\">os.environ['WANDB_MODE'] = 'offline'\nrun = wandb.init(...)\n...\nrun.finish()\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-21T20:48:23.323Z",
				"Answer_body": "<p>Hi Yao!</p>\n<p>Thank you for the directions. I was able to reproduce it and will send it over to the engineers!<br>\nThe only real workaround for this is recording the run-times yourself and then logging them to wandb.</p>\n<p>Artsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-27T21:36:19.734Z",
				"Answer_body": "<p>Hi Yao,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-03T15:30:48.984Z",
				"Answer_body": "<p>Hi Yao, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-14T10:06:10.411Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Every wandb command yields \"An error occured in MPI_Init_thread\"",
		"Question_link": "https://community.wandb.ai/t/every-wandb-command-yields-an-error-occured-in-mpi-init-thread/3422",
		"Question_created_time": "2022-11-15T23:40:42.183Z",
		"Question_answer_count": 10,
		"Question_score_count": 1,
		"Question_view_count": 542,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have a user on a multi-user server whose wandb installation appears to be broken. I have forced him to reinstall with</p>\n<pre><code class=\"lang-auto\">python3 -m pip install --upgrade pip\npython3 -m pip install --upgrade --force-reinstall wandb\n</code></pre>\n<p>after which he has wandb-0.13.5.</p>\n<p>But this error persists; even the simplest <code>wandb</code> command yields an <code>MPI_Init_thread</code> error:</p>\n<pre><code class=\"lang-auto\">$ wandb --version\n*** An error occurred in MPI_Init_thread\n*** on a NULL communicator\n*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,\n***    and potentially your MPI job)\n[xhostnamex:1359609] Local abort before MPI_INIT completed completed successfully, but am not able to aggregate error messages, and not able to guarantee that all other processes were killed!\n</code></pre>\n<p>On the same machine, my <code>wandb</code> installation works fine:</p>\n<pre><code class=\"lang-auto\">$ wandb --version\nwandb, version 0.13.5\n</code></pre>\n<p>Apologies if this is a duplicate, but I could not find this exact problem documented anywhere.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-16T06:01:02.815Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/andravin\">@andravin</a>,</p>\n<p>Is this the full stack trace for the error? If so, please run <code>wandb.init()</code> in a python file and share the full error trace from there along with the <code>debug.log</code> and <code>debug-internal.log</code> files from the <code>wandb</code> folder in the directory where you rant this process.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-18T01:37:52.221Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a> , I\u2019m the user who <a class=\"mention\" href=\"/u/andravin\">@andravin</a> mentioned.</p>\n<p>Here is what I did</p>\n<pre><code class=\"lang-auto\">moshin@pc$ python -V\nPython 3.8.10\nmoshin@pc$ ls\ntestwandb.py\nmoshin@pc$ cat testwandb.py \nimport wandb\n\nwandb.init()\nmoshin@pc$ python testwandb.py \n*** An error occurred in MPI_Init_thread\n*** on a NULL communicator\n*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,\n***    and potentially your MPI job)\n[pc:1623678] Local abort before MPI_INIT completed completed successfully, but am not able to aggregate error messages, and not able to guarantee that all other processes were killed!\nmoshin@pc$ ls\ntestwandb.py\n</code></pre>\n<p>It seems the process is broken before <code>wandb</code> folder is created.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-05T03:14:12.996Z",
				"Answer_body": "<p>We determined the error occurs on every node in the cluster, but only when the user session is created with <a href=\"https://slurm.schedmd.com/overview.html\" rel=\"noopener nofollow ugc\">SLURM</a>. A typical command-line to create the SLURM interactive session is <code>srun --pty bash</code>.</p>\n<p>The error is always reproducible simply by <code>import wandb</code>:</p>\n<pre><code class=\"lang-auto\">$ python3 -c 'import wandb'\n*** An error occurred in MPI_Init_thread\n*** on a NULL communicator\n*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,\n***    and potentially your MPI job)\n[node-name:1431860] Local abort before MPI_INIT completed completed successfully, but am not able to aggregate error messages, and not able to guarantee that all other processes were killed!\n</code></pre>\n<p>If the  user connects to the node with <code>ssh</code>, then <code>import wandb</code> works as expected.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-05T05:31:15.301Z",
				"Answer_body": "<p>Also, a different user with the same exact python packages installed via <code>pip</code> does not have this issue.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-06T04:49:56.242Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/andravin\">@andravin</a>!</p>\n<p>Any chance you can try <code>mpirun -np [NUM]</code> instead of <code>srun</code> here? This looks to be an issue with <code>srun</code> your slurm cluster specifically and not wandb, I would check your installation of <code>srun</code>/<code>mpirun</code> to make sure everything is running as expected over there.</p>\n<p>Have you tried importing any other libraries through which you also see the same error?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-13T13:59:30.201Z",
				"Answer_body": "<p>Hi!</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-14T16:05:05.079Z",
				"Answer_body": "<p>Hi Andrew,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-16T00:02:41.825Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a>  Thanks for the suggestion, our IT department will look into our SLURM and MPI configuration. It would appear that any issue is specific to the one particular user who sees the error, because WandB works fine for everyone else. So it would have to be a user-id inconsistency or permissions problem I would think.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-16T17:04:49.733Z",
				"Answer_body": "<p>Sounds good! Let us know if you guys have any more concerns related to wandb!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-14T00:03:19.395Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to make the Model Registry public?",
		"Question_link": "https://community.wandb.ai/t/how-to-make-the-model-registry-public/3489",
		"Question_created_time": "2022-12-02T15:08:26.271Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 632,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am currently trying to figure out how the Model Registry can be accessed by people not logged into WandB / not member of our developement team. Background is, that we link models that performed well in our private projects, to the Model Registry for reproducability, s.t. other researchers can access these models.</p>\n<p>Right now I managed to make the model-registry project public which enabled not logged in users to see the models in the model registry. However, I am still unable to download the visible modle version artifacts as the download buttons are not visible on the web UI.</p>\n<p>I am not sure if this is a bug or intendet behaviour as the entire experience of accessing a public model registry as a not logged in user is somehow very buggy with versions appearing and disappearing at random.</p>\n<p>Does anyone have any insights on this?</p>\n<p>Regards,<br>\nSnagnar</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-02T22:16:55.904Z",
				"Answer_body": "<p>Hi Snagnar,</p>\n<p>Happy to help. Could you please share an example link to a public project where users can download your models and specifically list the artifact you want them to download. Thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-08T17:11:11.100Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/snagnar\">@snagnar</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-15T11:16:18.159Z",
				"Answer_body": "<p>Yes, sorry I have been away the past few days. The public model registry repository I am currently trying to make publicly available is the following: <a href=\"https://wandb.ai/snagnar/model-registry/artifacts/model/bnnmodel\" class=\"inline-onebox\">Weights &amp; Biases</a></p>\n<p>There it is not possible to download the model files if I am not logged in or logged into an account without privileged access to the projects that these models were created in. Is this by design or is there a bug on the W&amp;B site?</p>\n<p>I can however download artifacts that are not models, i.e. in the linked model registry, everything in the tables section.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-13T11:17:16.475Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to jump the W&B upload process when the network is not so good?",
		"Question_link": "https://community.wandb.ai/t/how-to-jump-the-w-b-upload-process-when-the-network-is-not-so-good/3487",
		"Question_created_time": "2022-12-02T11:57:42.570Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 380,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>My training process unsuccessfully ended, because of the failure of the uploading process for W&amp;B.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/dbd70f7322f4960651abd3f6fae4f09d756e5380.png\" data-download-href=\"/uploads/short-url/vmNkve8jMTMA4YvuwSOc4NGUodW.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/dbd70f7322f4960651abd3f6fae4f09d756e5380_2_690x160.png\" alt=\"image\" data-base62-sha1=\"vmNkve8jMTMA4YvuwSOc4NGUodW\" width=\"690\" height=\"160\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/dbd70f7322f4960651abd3f6fae4f09d756e5380_2_690x160.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/dbd70f7322f4960651abd3f6fae4f09d756e5380_2_1035x240.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/dbd70f7322f4960651abd3f6fae4f09d756e5380_2_1380x320.png 2x\" data-dominant-color=\"F2EEDD\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1742\u00d7404 78.5 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nI often use a script file to run multiple experiments at once. When one of it is tucked, others cannot be run.<br>\nHow to jump this?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-02T22:55:15.381Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/yangze68\">@yangze68</a> , happy to help. From the image attached the <code>Network error (TransientError) points</code> to potential packet loss attributed to a network error on the users end. Event though a single experiment might fail, wandb would still execute subsequent runs, depending on how a user sets up their experiments.</p>\n<ul>\n<li>Could you please expand on how you are setting up your experiments and what additional errors you are seeing that stop subsequent runs</li>\n<li>Provide a <code>debug.log</code> and <code>debug-internal.log</code> file of the crashing run for us to get a better sense of anything else is happening with the run. These are located in the wandb/ folder of the working directory of the project.</li>\n</ul>\n<p>Thank you</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-03T03:41:43.670Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a>, thanks for your reply. If I set the wand mode to offline, I don\u2019t need to upload the file every time. But the new error accused. When I use the command <code>wandb sync --sync-all</code> to upload the offline file, the upload speed is very slow, I think this problem is related to the sync with tensorboad, which is mentioned in <a href=\"https://github.com/wandb/wandb/issues/1972\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">[CLI] Slow uploads of offline runs \u00b7 Issue #1972 \u00b7 wandb/wandb \u00b7 GitHub</a><br>\nHow can I share the debug.log file with you? By e-mail or here?<br>\nThanks again for your help</p>\n<p>When I copy the cached folder to another machine and upload it successfully.<br>\nAnd it throws a warning<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/7/786130bf568ecc3bfed9ba66b12e6dcb78f01713.png\" data-download-href=\"/uploads/short-url/haVwBOMDRDaRSKz5CZCbsuFD5N9.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/7/786130bf568ecc3bfed9ba66b12e6dcb78f01713.png\" alt=\"image\" data-base62-sha1=\"haVwBOMDRDaRSKz5CZCbsuFD5N9\" width=\"690\" height=\"31\" data-dominant-color=\"353836\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1016\u00d746 8.19 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nI think there\u2019s a bug with sync with tensorboad which slow the process.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-08T23:11:29.676Z",
				"Answer_body": "<p>Thank you for the update <a class=\"mention\" href=\"/u/yangze68\">@yangze68</a> . Please send them to <code>support@wandb.ai</code> and include my name in the subject line. I will perform some tests on the offline syncing of tensorboard output to wandb and get back to you with my findings.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-14T18:39:07.842Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/yangze68\">@yangze68</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-12T18:39:26.363Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Artefact upload very slow",
		"Question_link": "https://community.wandb.ai/t/artefact-upload-very-slow/3488",
		"Question_created_time": "2022-12-02T14:44:28.287Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 851,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m encountering a similar issue to the one reported here: <a href=\"https://community.wandb.ai/t/programmatically-accessing-artifact-object-very-slow-for-first-call-for-large-artifacts/1158\" class=\"inline-onebox\">Programmatically accessing artifact object very slow for first call for large artifacts</a></p>\n<p>I\u2019ve found artefacts to be an excellent way for storing the full outputs of my models for later debugging. However , as I\u2019m training information retrieval models my artefacts are rather large (~300MB). I\u2019m only storing titles of my documents but even with that each evaluation example has around 300 titles as an output.</p>\n<p>At the end of each WANDB run it takes a couple of hours for the run to sync. I\u2019m running the experiments on GCP VMs so internet speed should not be an issue.</p>\n<p>Do you have any ideas on how I could speed up the sync time?</p>\n<p>As I\u2019m running multiple experiments sequentially, atm the experiments are blocked by WANDB upload time. I\u2019m thinking as a quick workaround to disable automatic syncing from my scripts and run a <code>wandb sync; sleep</code> loop on a parallel process in the same directory. Does that sound like a reasonable way to go forward?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-02T22:46:29.626Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/boscience\">@boscience</a> , thank you for writing in and providing insight/feedback about artifact uploads. Our eng team is prioritizing improvements to artifacts usage and upload workflow that will significantly reduce upload times. These improvements will roll early next year.</p>\n<p>In regards to the problem you are facing, wandb writes artifacts through the cache.  As files are uploaded or downloaded, which happens asynchronously when you call <code>log_artifact</code>, the upload shouldn\u2019t be blocking your experiments.</p>\n<ul>\n<li>Are you using the latest wandb client version?</li>\n<li>Are you using <code>artifact.wait()</code> anywhere in your script?</li>\n<li>Which methods calls are you using to upload artifacts?</li>\n<li>Are the large artifacts single models or model checkpoint versions being constantly uploaded?</li>\n</ul>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-05T14:03:18.288Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a>,</p>\n<blockquote>\n<ul>\n<li>Are you using the latest wandb client version?</li>\n</ul>\n</blockquote>\n<p>Yes, I\u2019m using Python client, version <code>0.13.5</code>.</p>\n<blockquote>\n<p>Are you using <code>artifact.wait()</code> anywhere in your script?</p>\n</blockquote>\n<p>No</p>\n<blockquote>\n<p>Which methods calls are you using to upload artifacts?</p>\n</blockquote>\n<p>I\u2019m using only <code>wandb.log</code> statements, as the model only requires a single training step after setup. I make multiple calls to <code>wandb.log</code> with <code>commit=False</code>and then a single call with <code>commit=True</code>, that\u2019s the call where I log the artifact, which is a <code>wandb.Table</code>.</p>\n<blockquote>\n<p>Are the large artifacts single models or model checkpoint versions being constantly uploaded?</p>\n</blockquote>\n<p>The large artifact is a <code>wandb.Table</code>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-06T09:27:21.314Z",
				"Answer_body": "<p>At the end of my experiments, it hangs at the syncing step:</p>\n<pre><code class=\"lang-auto\">wandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run hopeful-firebrand-60\nwandb: \u2b50\ufe0f View project at https://wandb.ai/boclips/search-eval\nwandb: \ud83d\ude80 View run at https://wandb.ai/boclips/search-eval/runs/2iid9htu\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-08T23:06:47.918Z",
				"Answer_body": "<p>Thank you for the update <a class=\"mention\" href=\"/u/boscience\">@boscience</a> . Could you provide us the<code> debug.log</code> and <code>debug-internal.log</code> files for the runs that are hanging. They will provide additional clues to what is occurring. Please send them to <code>support@wandb.ai</code> and include my name in the subject line, thank you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-14T18:38:15.895Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/boscience\">@boscience</a> ,since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-12T18:38:26.701Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to check if a secret key corresponds to an entity?",
		"Question_link": "https://community.wandb.ai/t/how-to-check-if-a-secret-key-corresponds-to-an-entity/3541",
		"Question_created_time": "2022-12-13T20:28:48.878Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 124,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am trying to create a wandb run.</p>\n<pre><code class=\"lang-auto\">wandb.login(key=wandb_secret_key, relogin=True)\ntry:\n    run = wandb.init(\n        entity=wandb_entity_name,\n        project=wandb_project,\n        name=wandb_run_name,\n        notes=wandb_experiment_description,\n        config=wandb_configs,\n    )\nexcept Exception:\n    raise InvalidWanbInfoConfigurationsExeption(f\"wandb_secret_key({wandb_secret_key}) is not associated with wandb_entity_name ({wandb_entity_name})\")\n\n</code></pre>\n<p>I can exception handle like I did, but the subsequent runs are crashing even if wandb_secret_key and wandb_entity_name correspond.</p>\n<pre><code class=\"lang-auto\">---------------------------------------------------------------------------\nBrokenPipeError                           Traceback (most recent call last)\n~/.virtualenvs/tfpipeline/lib/python3.8/site-packages/wandb/sdk/wandb_init.py in init(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\n   1077         try:\n-&gt; 1078             run = wi.init()\n   1079             except_exit = wi.settings._except_exit\n\n~/.virtualenvs/tfpipeline/lib/python3.8/site-packages/wandb/sdk/wandb_init.py in init(self)\n    573             logger.info(\"setting up manager\")\n--&gt; 574             manager._inform_init(settings=self.settings, run_id=self.settings.run_id)\n    575 \n\n~/.virtualenvs/tfpipeline/lib/python3.8/site-packages/wandb/sdk/wandb_manager.py in _inform_init(self, settings, run_id)\n    169         svc_iface = self._get_service_interface()\n--&gt; 170         svc_iface._svc_inform_init(settings=settings, run_id=run_id)\n    171 \n\n~/.virtualenvs/tfpipeline/lib/python3.8/site-packages/wandb/sdk/service/service_sock.py in _svc_inform_init(self, settings, run_id)\n     37         assert self._sock_client\n---&gt; 38         self._sock_client.send(inform_init=inform_init)\n     39 \n\n~/.virtualenvs/tfpipeline/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py in send(self, inform_init, inform_start, inform_attach, inform_finish, inform_teardown)\n    210             raise Exception(\"unmatched\")\n--&gt; 211         self.send_server_request(server_req)\n...\n   1115                 os._exit(-1)\n-&gt; 1116             raise Exception(\"problem\") from error_seen\n   1117     return run\n</code></pre>\n<p>Is there a wat to check if they correspond without creating the run?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-14T18:33:45.276Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/aidev\">@aidev</a> , we appreciate your writing in and are happy to help. As this question was also raised in <a href=\"https://github.com/wandb/wandb/issues/4621\" rel=\"noopener nofollow ugc\">wandbs\u2019 github issues</a>, we will be tracking the discussion there for continuity.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-12T18:34:26.438Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Cannot access run data via run.history()",
		"Question_link": "https://community.wandb.ai/t/cannot-access-run-data-via-run-history/3530",
		"Question_created_time": "2022-12-11T19:02:41.235Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 125,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi,</p>\n<p>I am having trouble accessing run data keys in several of my runs. Specifically, I have logged a metric in my code, the metric is tracked in the online wandb UI, but when I try accessing the data using the following code</p>\n<pre><code class=\"lang-auto\">import wandb\napi = wandb.Api()\nrun = api.run(\"xxxxxx\")\nrun.history()[['_step', 'metric_name']]\n</code></pre>\n<p>It throws a <code>KeyError: \"['metric_name'] not in index\"</code>.</p>\n<p>When I print out <code>run.history()</code> in table format, it does show \u2018metric_name\u2019 as one of the columns; \u2018metric_name\u2019 also appears as a key in <code>run.summary</code>. I wonder what is the issue here?</p>\n<p>Would appreciate any help. Thank you!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-13T14:56:59.675Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/toruowo\">@toruowo</a> thank you for writing in! Can you please change your last line to:</p>\n<pre><code class=\"lang-auto\">run.history(keys=['_step', 'metric_name'])\n</code></pre>\n<p>Would this work for you?  Please let me know if you have any further issues or questions. You may also find some more <a href=\"https://docs.wandb.ai/guides/track/public-api-guide#public-api-examples\">API examples here</a> if that helps.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-12-13T18:40:32.125Z",
				"Answer_body": "<p>Thank you! Yes, this indeed resolves the problem!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-14T10:06:36.990Z",
				"Answer_body": "<p>Glad to hear that <a class=\"mention\" href=\"/u/toruowo\">@toruowo</a> thank you for confirming. I will close the ticket for now, and please reach out again if you have any further questions!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-12T10:07:24.405Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb Resume Logging",
		"Question_link": "https://community.wandb.ai/t/wandb-resume-logging/3543",
		"Question_created_time": "2022-12-14T01:34:28.598Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 572,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>I was trying to resume my run after a crash, but got confused about some points.<br>\nThe questions would mainly be about the <strong>resume</strong> and <strong>id</strong> argument in wandb.init().</p>\n<p>I have read the <strong>Resume Runs</strong> docs and followed thing mentioned in it.<br>\nPrecisely I have initialized my run as follows.</p>\n<pre><code class=\"lang-auto\">my_project_name = \"tmp\"\nmy_id = \"1r0f3yu4\"\nwandb.init(project=my_project_name, id=my_id, resume=\"must\") \n</code></pre>\n<p>where I have found <strong>my_id</strong> in  <strong>wandb/run-20221214_011018-1r0f3yu4</strong> which is a directory that was automatically generated from the crashed run. I have also double checked that <strong>my_project_name</strong> is also same as the crashed run.</p>\n<p>However,<br>\nProblem 1) I <strong>can</strong> see that the <strong>State</strong> in my Weight and Biases Workspace has change to \u201crunning\u201d again, but cannot see any plots or logging information updated in the dashboard (which worked fine for the crashed run).</p>\n<p>Problem 2) Instead of re-using the previous directory <strong>wandb/run-20221214_011018-1r0f3yu4</strong>, it generates a new directory <strong>wandb/run-anotherYYYYMMDD_anotherHHMMSS-1r0f3yu4</strong>. Is this the proper way it should work, or am I doing something wrong?<br>\n(Is it because of <strong><a href=\"https://github.com/wandb/wandb/blob/main/wandb/sdk/wandb_init.py/\" rel=\"noopener nofollow ugc\">https://github.com/wandb/wandb/blob/main/wandb/sdk/wandb_init.py/</a></strong> line299?)</p>\n<p>Finally, my questions would be<br>\nQuestion 1) How should I resume my run? I want to continue logging my training stats on the same dashboard. (I am already saving my checkpoint for training with torch.load/torch.save function. Thus, I just wand to know how to resume my \u201clogging\u201d in my Weight and Biases workspace  online.)</p>\n<p>Question 2) Is Problem2 the proper way it should work? or am I doing something wrong?</p>\n<p>I\u2019m not a very good English speaker, please let me know if anything sounds unclear.</p>\n<p>Thank you.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-16T14:59:20.595Z",
				"Answer_body": "<p>Hi MinKyu,</p>\n<p>Thanks for writing in! For your questions:</p>\n<ul>\n<li>\n<p>How should I resume my run? Here you have a code snippet where I am creating a run, finishing it and then resuming and logging data again. This new data appears in the UI properly. Could you try following the same flor in your process? If it still does not work, I can have a look at your code and see what is happening here.</p>\n<p>import wandbrun = wandb.init(project=\u2018resume_runs\u2019)id = run.idfor i in range(5): run.log({\u2018metric\u2019:i})run.finish()run_1 = wandb.init(project=\u2018resume_runs\u2019, id=id, resume=\u201cmust\u201d)for i in range(5): run_1.log({\u2018metric\u2019:5+i})run_1.finish()</p>\n</li>\n<li>\n<p>Is Problem2 the proper way it should work? This is the right way, as the folder contains the date of when the run is created, so a new folder will be created when resuming the run.</p>\n</li>\n</ul>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-20T14:23:39.836Z",
				"Answer_body": "<p>Hi MinKyu,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-12T01:34:38.997Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Logging volumetric data?",
		"Question_link": "https://community.wandb.ai/t/logging-volumetric-data/3476",
		"Question_created_time": "2022-11-28T15:15:25.050Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 202,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I was wondering if there was any tools that could be of use to log volumetric data? My data are essentially 3-d tensor where each values represent the density of a volume. Currently I use some third party tools to visualize them, but it would be nice to have everything in the wandb UI.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-29T18:17:19.276Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lthiet\">@lthiet</a> thank you for writing in. Could you please provide a bit more details on your use case? Which file formats do you generate and you would want to visualise with W&amp;B UI? Currently, we offer a  <code>wandb.Object3D</code> class that can be used to log file formats such as <code>obj</code>, <code>gltf</code>, <code>glb</code>, <code>babylon</code>, <code>stl</code>, <code>pts.json</code>. Our reference docs on this object can be found <a href=\"https://docs.wandb.ai/guides/track/log/media#3d-visualizations\">here</a>. Would this work for you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-05T11:31:02.811Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lthiet\">@lthiet</a> I wanted to check in here and see if you have any further questions or issues regarding this request? thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-05T11:57:39.745Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a></p>\n<p>Thank you a lot for your help. I haven\u2019t tried what you suggested yet, I will let you know what I find as soon as possible!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-08T14:59:29.625Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lthiet\">@lthiet</a> thanks for the update, glad to help you further with this if the above supported formats won\u2019t work for you. Let me know once you try these first, and we can take it from there.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-13T16:22:27.199Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lthiet\">@lthiet</a> I am closing this ticket for now, as we haven\u2019t heard back from you. Please let us know once you try the <code>wandb.Objectd3D</code>, and we will be glad to assist further if there are any issues or further questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-11T16:22:46.917Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Hp-sweep with function with arguments",
		"Question_link": "https://community.wandb.ai/t/hp-sweep-with-function-with-arguments/3539",
		"Question_created_time": "2022-12-13T12:26:40.394Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 401,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi</p>\n<p>Im wondering if its possible to have hp-sweep and instantiating wandb agent (using wandb.agent api) , such that the function will have arguments, in all of the example I\u2019ve seen that the passed functions to wandb.agent has no args at all.</p>\n<p>My training script looks as follows</p>\n<pre><code class=\"lang-auto\">\ndef trainer(input1, input2, input3):\n  # construct cfg file given the inputs\n  # passing the cfg file to wandb.init() \n  # receiving the returned config from wandb.config (with the decided params by the wandb Params controler)\n  # Continue training as usual, given the latest cfg.\n</code></pre>\n<p>I will be happy to get some inspiration about other ways to implement this<br>\nHope this is helpful</p>\n<p>Dor</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-14T12:46:58.632Z",
				"Answer_body": "<p>Hi Dor,</p>\n<p>Thanks for writing in! You can pass arguments to the function in the agent in the normal way <code>function=main(args)</code>, is this raising you any error?</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-19T15:21:42.859Z",
				"Answer_body": "<p>Hi Dor,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-11T12:26:56.570Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Calling run.history(samples=n_samples) returns a sample size different from n_samples",
		"Question_link": "https://community.wandb.ai/t/calling-run-history-samples-n-samples-returns-a-sample-size-different-from-n-samples/3414",
		"Question_created_time": "2022-11-14T14:27:22.567Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 193,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi everyone!</p>\n<p>I am experiencing weird behaviour of the run.history() function in Python:</p>\n<p>Calling <code>run.history(samples = 100)</code> gives me sample sizes different to 100 and the sample size varies for each call. E.g. executing it 5 times gave me sample sizes 98, 90, 88, 110, 104.<br>\nHowever, when I execute <code>run.history(keys=['my_key'], samples=100)</code>, I get a sample size of exactly 100 for every call. Why is this the case?</p>\n<p>After investigating this further, I found more strange behaviour: Calling <code>run.history(keys=['my_key'], samples=n_samples)</code> yields a sample size of exactly n_samples, as long as n_samples &lt;= 12493 (at least for my test run). If n_samples &gt; 12493, smaller sample sizes (varying roughly  between 12400 and 12490) are returned.</p>\n<p>Am I understanding something wrong or are these functions behaving in a way that they shouldn\u2019t?</p>\n<p>Thanks in advance!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-18T05:08:21.199Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kolja\">@kolja</a>,</p>\n<p>The function is probably not behaving as it is supposed to - I\u2019m going to have to investigate this on my end, but we should expect <code>run.history(samples = n)</code> to return <code>n</code> values (as long as they exist).</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-23T05:45:21.772Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kolja\">@kolja</a>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-23T14:32:21.476Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a> ,</p>\n<p>no unfortunately the issue is still not resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-30T06:08:44.193Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kolja\">@kolja</a>,</p>\n<p>I apologize about that - that was an automated message that was sent over. Could you try using <code>run.scan_history()</code> and let me know if you run into the same behaviour?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-30T16:24:20.601Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a> ,</p>\n<p><code>run.scan_history()</code> per definition returns the full history, not a sampled version. It behaves as expected, but my use case is that I want to downsample long runs to a specific number of samples, so this does not solve my issue.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-13T06:06:33.576Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/kolja\">@kolja</a>,</p>\n<p>Thanks for the explanation! <code>run.history()</code> is not behaving correctly here - I had already filed a bug report for this to be tracked internally. For now, I would suggest using <code>run.history(keys=['my_key'], samples=100)</code> in order to get all your metrics in that case.</p>\n<p>I will respond back here once this issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-11T06:06:37.366Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "CPU Temperature Metrics",
		"Question_link": "https://community.wandb.ai/t/cpu-temperature-metrics/3538",
		"Question_created_time": "2022-12-12T16:49:01.942Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 233,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Is there a way to measure CPU temperature? I am able to see GPU temps but it would be nice if there is a way to see CPU temps as well.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-12T20:36:35.380Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/cbisht\">@cbisht</a> , happy to help. There isn\u2019t a direct method of doing this directly via wandb. Wandb automatically logs the system metric listed <a href=\"https://docs.wandb.ai/ref/app/features/system-metrics\">here</a>. My recommendation is to track cpu temp via python package and log this data via <code>wandb.log(..)</code>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-10T20:37:09.509Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Rate Limit Exceeded wandb increase rate limit",
		"Question_link": "https://community.wandb.ai/t/rate-limit-exceeded-wandb-increase-rate-limit/3522",
		"Question_created_time": "2022-12-10T05:27:46.619Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 185,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi all, I get the following error in my logs:</p>\n<pre><code class=\"lang-auto\">^[[34m^[[1mwandb^[[0m: Network error (HTTPError), entering retry loop.^M                                                                                                                               \n306 ^[[34m^[[1mwandb^[[0m: 429 encountered (Filestream rate limit exceeded, retrying in 36.30758655296977 seconds), retrying request^M    \n</code></pre>\n<p>It appears i am sending too many requests. would it be possible to increase my rate limit?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2023-02-08T05:28:14.442Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Revert wandb server upgrade?",
		"Question_link": "https://community.wandb.ai/t/revert-wandb-server-upgrade/3518",
		"Question_created_time": "2022-12-09T17:38:12.654Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 248,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>When I start the wandb server locally, I got a notification to upgrade, so I upgraded the version. But now I couldn\u2019t access my runs and I run into this error whenever I run a training script:</p>\n<p><code>wandb: Network error (TransientError), entering retry loop.</code></p>\n<p>It also does not seem to log images anymore.</p>\n<p>I removed wandb from pip and reinstalled it at the version that still worked but the error still persists.</p>\n<p>Any ideas?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-10T01:04:29.803Z",
				"Answer_body": "<p>Problem solved: had to upgrade pip wandb!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-08T01:04:52.641Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Permanently delete Artifact Versions",
		"Question_link": "https://community.wandb.ai/t/permanently-delete-artifact-versions/3065",
		"Question_created_time": "2022-09-05T08:28:26.516Z",
		"Question_answer_count": 7,
		"Question_score_count": 2,
		"Question_view_count": 446,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I am trying to delete Artifact Versions using the API, for instance with something like this:</p>\n<pre><code class=\"lang-auto\">api = wandb.Api(overrides={\"entity\": entity, \"project\": project})\nartifact = api.artifact(name, type)\nartifact.delete()\n</code></pre>\n<p>The artifact is indeed deleted from the web UI, but then when I call <code>api.artifact_versions(type, name)</code> it is still present in the iterator.</p>\n<p>So, in order to get the list of all available artifacts, what I\u2019m currently doing is call the <code>api.artifact_versions()</code> method and then check if a specific version really exists by usiing <code>api.artifact</code> inside a try/except clause (if the artifact was deleted, it will raise a <code>wandb.CommError</code> exception), but of course this solution is more expensive.</p>\n<p>My question is: is there a way to permanently delete artifact versions so that they are not shown in <code>api.artifact_versions()</code> anymore? This would also help keep the version number from growing too high</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-07T23:31:59.086Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/andreapesare\">@andreapesare</a>, at this time although you can delete an artifact and all its sub versions via the API, an empty artifact remains in the project. The engineering team is considering automatically deleting this as well once a user has deleted all content within an artifact. After deleting all versions of the artifact, the empty artifact will be automatically deleted from the project.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-09T10:38:14.659Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> , thanks for your answer.<br>\nI am referring to a different (though probably linked) problem. I don\u2019t want to delete an empty artifact, but some artifact versions.</p>\n<p>Let me clarify it with an example:</p>\n<p>In my <code>example</code> project on W&amp;B I have a <code>SimpleNet</code> artifact collection of type <code>model</code> with versions <code>['v2', 'v3', 'v4', 'v5']</code> (see image below).</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/e133e393d5ad8572ba0f957a2c5bbb4cb960498d.png\" alt=\"image\" data-base62-sha1=\"w8eBlSzFHX4vcXgqUMUKnzes6S1\" width=\"342\" height=\"360\"></p>\n<p>Let\u2019s assume that when I run<br>\n<code>api.artifact_versions(name='SimpleNet', type='model')</code><br>\nI receive a list of ArtifactVersion, corresponding to the versions <code>['v2', 'v3', 'v4', 'v5']</code>.<br>\nNow I would like to delete some useless version, e.g. \u2018v2\u2019. I can do it either from the web UI or from the API itself.</p>\n<p>Then, if I ran again the command<br>\n<code>api.artifact_versions(name='SimpleNet', type='model')</code>,<br>\nI would expect the output to be a list with versions <code>['v3', 'v4', 'v5']</code>, but instead I get still <code>['v2', 'v3', 'v4', 'v5']</code>. However, when I try to access the ArtifactVersion <code>v2</code>, I get a <code>wandb.CommError</code> exception since that version has been deleted. It\u2019s like the W&amp;B server keeps a \u201cphantom\u201d view of all deleted artifact versions.<br>\nMy question is: is it possible to permanently delete them? Thanks for any help</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-14T22:52:16.854Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/andreapesare\">@andreapesare</a> , thank-you for the clarification. We tested this on our end and confirmed it\u2019s a bug. We are working on a fix, once implemented, I will provide you an update.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-04T18:09:17.007Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/andreapesare\">@andreapesare</a>,</p>\n<p>Following up on the recent issue you were facing with incorrect Artifact versions being fetched by our API after an artifact is deleted. Our eng team has released a <a href=\"https://github.com/wandb/wandb/pull/4221\" rel=\"noopener nofollow ugc\">fix</a> for this with our latest client release, <a href=\"https://github.com/wandb/wandb/releases/tag/v0.13.5\" rel=\"noopener nofollow ugc\">0.13.5</a>. Please let us know if there is anything else we could do for you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-07T12:31:30.288Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a>,</p>\n<p>I updated my <code>wandb</code> version to 0.13.5 but unfortunately this doesn\u2019t seem to fix the issue.<br>\nFor instance, in W&amp;B UI I have the following artifact versions (i.e. I deleted <code>v13</code>)<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/22d6117910e77523b0ca06d79bedea04eebd0ca5.png\" alt=\"image\" data-base62-sha1=\"4YaS8flP6T2uM2lKtImi1An5dPf\" width=\"243\" height=\"476\"><br>\nbut when I run</p>\n<pre><code class=\"lang-auto\">artifact_versions = api.artifact_versions(name='generator', type_name='model')\nfor v in artifact_versions:\n    print(v.name)\n</code></pre>\n<p>the output is the following, meaning that the version <code>v13</code> is still counted as available.<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/4/4555ed0487f1d0807fc749d15dea749f39f9229b.png\" alt=\"image\" data-base62-sha1=\"9Tn2wD0xmOZYcqmipZD3P8Wj9hh\" width=\"122\" height=\"315\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-08T11:09:41.919Z",
				"Answer_body": "<p>Hi,</p>\n<p>Just encountered a similar issue to the one you describe in your answer. I deleted all the artifact versions through the API but an empty artifact \u201cgroup\u201d remains. How do I delete it using the API?<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/4/4f6ba41d9190a802c83af016905ccbe9feb84539.png\" alt=\"image\" data-base62-sha1=\"bkAl5n9XGD9Nu2BLnmVNaVQV3fP\" width=\"441\" height=\"496\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-06T11:10:10.592Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Images logged using W&B logger bloats up /tmp",
		"Question_link": "https://community.wandb.ai/t/images-logged-using-w-b-logger-bloats-up-tmp/3450",
		"Question_created_time": "2022-11-23T02:06:16.532Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 610,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>In my code, I have the following  statement called at the end of every epoch as part of validation</p>\n<pre><code class=\"lang-auto\">wandb_logger.experiment.log({'test': wandb.Image(img)}, commit=commit)\n</code></pre>\n<p>where <code>img</code> is an image of type numpy array.</p>\n<p>I have noticed that  W&amp;B logger writes the image to a directory inside <code>/tmp</code>,  and this directory is only cleared at the  end of the run.</p>\n<p>I have limited space in <code>/tmp</code> and this leads to my training run crashing. I have tried saving the image to disk and then calling W&amp;B log on the path, this skips saving to <code>/tmp</code> but doesn\u2019t really work well with distributed training (deadlock issues).</p>\n<p>Expected behavior:<br>\nThe user should be able to configure the temporary directory where intermediary media is stored.</p>\n<p>Kindly let me know if there\u2019s any other workaround.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-28T20:35:52.539Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/suryatejrmatician\">@suryatejrmatician</a> , happy to help. Could you try changing g your cache directory by setting the <code>WANDB_CACHE_DIR</code> environment variable. As we write artifacts through the cache, after updating this directory, wandb will update where intermediary files are stored prior to logging them.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-01T22:22:37.293Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/suryatejrmatician\">@suryatejrmatician</a>  since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-04T07:24:06.347Z",
				"Answer_body": "<p>This sounds like a similar problem that my team was facing. My artifacts were being logged into the WandB account. I wrote a small gist which could tackle it. Its a kind of a workaround, let me know if it helps:</p>\n<aside class=\"onebox githubgist\" data-onebox-src=\"https://gist.github.com/skyprince999/621e9ba1bc9e7c665a5cc7f58442d7b3\">\n  <header class=\"source\">\n\n      <a href=\"https://gist.github.com/skyprince999/621e9ba1bc9e7c665a5cc7f58442d7b3\" target=\"_blank\" rel=\"noopener nofollow ugc\">gist.github.com</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <h4><a href=\"https://gist.github.com/skyprince999/621e9ba1bc9e7c665a5cc7f58442d7b3\" target=\"_blank\" rel=\"noopener nofollow ugc\">https://gist.github.com/skyprince999/621e9ba1bc9e7c665a5cc7f58442d7b3</a></h4>\n\n  <h5>Delete Artifacts.py</h5>\n  <pre><code class=\"Python\">########################################################################################\n# Loops through artifact files on Wandb server and deletes files with a given extension \n########################################################################################\n\nimport wandb\nfrom tqdm.notebook import tqdm\napi = wandb.Api()\n\nimport os\n</code></pre>\n    This file has been truncated. <a href=\"https://gist.github.com/skyprince999/621e9ba1bc9e7c665a5cc7f58442d7b3\" target=\"_blank\" rel=\"noopener nofollow ugc\">show original</a>\n\n<p>\n</p>\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-07T21:27:49.004Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"mohammadbakir\" data-post=\"2\" data-topic=\"3450\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/m/a9a28c/40.png\" class=\"avatar\"> mohammadbakir:</div>\n<blockquote>\n<p>WANDB_CACHE_DIR</p>\n</blockquote>\n</aside>\n<p>Hey <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a>, I have tried this and it doesn\u2019t seem to be working. The temporary files are still logged to <code>/tmp</code>, note that this is also for all logging that w&amp;b does, not necessaily the image logging example that I have given above.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-05T21:28:07.480Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "KeyError: 'fasterrcnn_resnet50'",
		"Question_link": "https://community.wandb.ai/t/keyerror-fasterrcnn-resnet50/3474",
		"Question_created_time": "2022-11-28T11:44:37.740Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 556,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am trying to run this GitHub repository <a href=\"https://github.com/sovit-123/fasterrcnn-pytorch-training-pipeline#Train-on-Custom-Dataset\" rel=\"noopener nofollow ugc\">faster rcnn-pytorch-custom-dataset</a> but I got this error.</p>\n<pre><code class=\"lang-auto\">Building model from scratch...\nTraceback (most recent call last):\n  File \"train.py\", line 491, in &lt;module&gt;\n    main(args)\n  File \"train.py\", line 248, in main\n    build_model = create_model[args['model']]\nKeyError: 'fasterrcnn_resnet50'\nwandb: Waiting for W&amp;B process to finish... (failed 1). Press Control-C to abort syncing.\nwandb: Synced smoke_training: https://wandb.ai/samahwa/fastercnn-pytorch-training-pipeline/runs/ejy5jyw8\nwandb: Synced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nwandb: Find logs at: ./wandb/run-20221128_113545-ejy5jyw8/logs\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-28T14:09:10.376Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/samahwa\">@samahwa</a> thank you for writing in. The KeyError seems to stem from the model\u2019s name you\u2019re passing in. In the GitHub repo you stored, there is a <code>models</code> directory where you could find the valid names. Could you please try if <code>fasterrcnn_resnet50_fpn</code> or <code>fasterrcnn_resnet50_fpn_v2</code> would work for you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-01T16:11:19.260Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/samahwa\">@samahwa</a> I wanted to follow up on this issue, does it still occur for you and are there any more questions to help with?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-07T09:32:25.474Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/samahwa\">@samahwa</a> since we haven\u2019t heard back from you, I will close this ticket for now. If you still experience any issue running your code, please let us know and we will keep investigating.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-05T09:32:58.443Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Resuming sweep runs on a cluster with job time limits",
		"Question_link": "https://community.wandb.ai/t/resuming-sweep-runs-on-a-cluster-with-job-time-limits/3333",
		"Question_created_time": "2022-10-27T18:44:38.337Z",
		"Question_answer_count": 8,
		"Question_score_count": 0,
		"Question_view_count": 461,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Many users (including myself) on our compute cluster use wandb Sweeps, but a current pain point is our cluster admins limit each job length to 6 hours. For some applications this is not enough time to train Sweep trial configs to convergence, so they get cut off. I see in the <a href=\"https://docs.wandb.ai/guides/track/advanced/resuming\">docs</a> we have \u201cresuming a run which was executed as part of a Sweep is not supported.\u201d <img src=\"https://emoji.discourse-cdn.com/twitter/frowning.png?v=12\" title=\":frowning:\" class=\"emoji\" alt=\":frowning:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<p>However the <a href=\"https://docs.wandb.ai/guides/track/advanced/resuming#preemptible-sweeps\">pre-emptible sweeps</a> section also mentions it can be possible to mark runs as being pre-empted, and \u201cresume logging at the step where it was interrupted\u201d. Sounds great, but there are a couple concerns:</p>\n<ol>\n<li>How can I ensure this resuming will actually resume properly, i.e. pick up model weights where they left off and so on? If I save model weights, optimizer state, etc with <code>wandb.save()</code>, will they be automatically pulled in when doing <code>wandb.init(resume=True)</code>? Or do I need to explicitly use <code>wandb.restore()</code>?</li>\n<li>More importantly, I\u2019m not sure how to actually implement this for our system. The current workflow is to generate the sweep config and sweep id, then submit a bunch of jobs (one job per trial) to the cluster with the appropriate sweep id. Each of these uses <code>wandb.agent</code> followed by <code>wandb.init</code> to get a sweep trial config and run it. However then presumably I\u2019d also have to launch some jobs with <code>wandb.init(resume=True)</code> to pick up the runs that don\u2019t finish in time (the number of which I won\u2019t know a priori), and these will clog up the queue. I guess this would all have to be manual \u2013 I\u2019d go and find all the runs which didn\u2019t finish and launch a corresponding number of jobs to complete them?</li>\n</ol>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-31T02:37:47.338Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/pzharrington\">@pzharrington</a>,</p>\n<p>For 1., You would need to call <code>restore()</code> if you called <code>save()</code>. In general, you would want to read and initialize your model using a checkpoint you have saved. The <code>resume</code> flag just sets up the W&amp;B run to where it was saved, we do not interface with your model. Each run has a <code>.resumed</code> property which holds a boolean value so that you can write a simple if-else statement for this.</p>\n<p>For 2., Could you share where you will be training your models? I\u2019ll have to look into this further and get back to you.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-31T21:11:36.384Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a>, thanks for the response. For (1) it sounds like <code>save()</code> and <code>restore()</code> would work well. Ideally our users wouldn\u2019t have to keep track of where checkpoints lived on the local filesystem, etc, if the resuming for a run could be based on some flag and pull the checkpoint from wandb  \u2013 I can describe more below.</p>\n<p>For (2), our system is <a href=\"https://docs.nersc.gov/systems/perlmutter/\" rel=\"noopener nofollow ugc\">Perlmutter</a>, a supercomputer where job submission/scheduling is handled by Slurm. We cannot change the job time limits for a number of reasons, so to get long-running jobs, users have to jump through extra hoops, e.g. schedule a reservation on the system, and this is not ideal. Thus for sweeps where each trial may take longer than 6 hours (our job time limit), there is a need for checkpoint/restart of individual sweep runs. I\u2019d assume there might be something you could do with <code>mark_preempting()</code> and the sweep controller/backend where a run could be marked as pre-empted and get re-queued with some flag like \u201cneeds resuming\u201d. Then whenever the next agent/job is launched, it gets assigned that run and can pull the checkpoint from wandb to resume training at the right point, by checking the same \u201cneeds resuming\u201d flag.</p>\n<p>This would also be great for fault tolerance/general pre-emptible instances (e.g. on a cloud provider) as well.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-30T18:11:12.815Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/pzharrington\">@pzharrington</a>,</p>\n<p>Apologies for the delay here - You are right, mark_preempting immediately communicates to the backend that the run is about to be preempted. In terms of resuming, is there a persistent storage on perlmutter (or maybe a network attached storage) to which you can communicate the active sweep ID? That should let you resume the process by storing the current run ID external to the process.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-30T19:30:25.263Z",
				"Answer_body": "<p>Yes, we do have persistent storage where run IDs could be stored. Based on our conversation so far I\u2019m confident I could  manually set something up myself to handle the checkpoint/restart case. Something like, at the start of each sweep job, manually check on the local filesystem for pre-empted sweep runs, and resume those if they exist, otherwise proceed with a new trial.</p>\n<p>I guess what I\u2019m seeking is a more general and user-friendly setup, incorporated into the wandb backend for sweep agents, that would lower the implementation burden for our users. We have many early career researchers who are newcomers to DL and implementing things like this would probably be a barrier to many. This is getting more into the realm of feature request now, and I do see a request on GitHub for essentially this exact functionality <a href=\"https://github.com/wandb/wandb/issues/2692\" rel=\"noopener nofollow ugc\">here</a>. In that issue there is talk of a new \u201crewind\u201d feature which seems to have been delayed multiple times now. Any idea if that is still undergoing development?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-30T19:50:15.473Z",
				"Answer_body": "<p>Understood - In all honesty the rewind feature was deprioritized in favour of other features being released at the moment. I can increase the priority on this feature for you and try to push for its development, but I\u2019m not sure if I can get you a timeline for its development at the moment.</p>\n<p>I\u2019ll have to have a chat with some folks internally and get back to you regarding the state of the rewind feature here.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-06T20:01:09.058Z",
				"Answer_body": "<p>Hey Peter,</p>\n<p>Just wanted to give an update over here. I checked in and this issue is not being actively worked upon at the moment, but I\u2019m pushing to get this prioritized. One of the members from our team will reach out on this thread once this feature request has been completed.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-06T20:19:01.432Z",
				"Answer_body": "<p>Hi Ramit,</p>\n<p>Okay, thanks for the reply and thanks for pushing for this feature. Do keep me posted on any changes.</p>\n<p>Peter</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-04T20:19:08.769Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Warning: \"Failed to detect the name of this notebook\"",
		"Question_link": "https://community.wandb.ai/t/warning-failed-to-detect-the-name-of-this-notebook/3491",
		"Question_created_time": "2022-12-03T09:45:31.457Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 749,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m not sure why this started happening, but WB is now giving us this error message:</p>\n<p><code>Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.</code></p>\n<p>We do not use notebooks and so there is no reason for us to set the above mentioned environment variable.  How can we make this stop?  And why is WB pushing us to set an optional parameter?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-06T05:24:21.482Z",
				"Answer_body": "<p>Hi Kevin!</p>\n<p>What environment are you running your code in? It sounds like wandb might be capturing an IPython kernel. You don\u2019t really need to worry about this warning, it does not affect your W&amp;B Run all too much.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-09T12:39:47.748Z",
				"Answer_body": "<p>Hi Kevin,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-13T15:42:05.856Z",
				"Answer_body": "<p>Hi Kevin, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-04T05:25:12.770Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Feature request: adding tags to a report",
		"Question_link": "https://community.wandb.ai/t/feature-request-adding-tags-to-a-report/3496",
		"Question_created_time": "2022-12-04T21:16:40.450Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 160,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>We\u2019ve generated a number of iterations of a report programmatically and it would be nice to be able to Tag the reports to indicate which is the best version.  We made use of the little heart icon to upvote a report, but it would also be nice to apply (and remove) a tag as new better versions of the report becomes available.  Thanks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-06T04:55:47.120Z",
				"Answer_body": "<p>Hi Kevin!</p>\n<p>Thank you for your feature request - I\u2019ll make an internal ticket to track this request and one of our team members will get back on this thread once this feature has been implemented!</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-02-04T04:56:12.728Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Get stuck at uploading at the end",
		"Question_link": "https://community.wandb.ai/t/get-stuck-at-uploading-at-the-end/3453",
		"Question_created_time": "2022-11-24T01:37:20.661Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 797,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>My program finished before a few hours, but wandb get stuck at uploading files until now. I asked my friend and he said he had the same problem. So there are any problem for wandb server in the past  few hours and how to fix it?</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/8/8fd37530d06301653d3129bbe42f02a5a1061cdf.jpeg\" data-download-href=\"/uploads/short-url/kwlk7giIWlj5N5PsCmnxPYQd8d1.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/8fd37530d06301653d3129bbe42f02a5a1061cdf_2_690x83.jpeg\" alt=\"image\" data-base62-sha1=\"kwlk7giIWlj5N5PsCmnxPYQd8d1\" width=\"690\" height=\"83\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/8fd37530d06301653d3129bbe42f02a5a1061cdf_2_690x83.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/8fd37530d06301653d3129bbe42f02a5a1061cdf_2_1035x124.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/8fd37530d06301653d3129bbe42f02a5a1061cdf_2_1380x166.jpeg 2x\" data-dominant-color=\"181717\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">2122\u00d7256 120 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-29T01:15:31.935Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/yueyang\">@yueyang</a> , happy to look into this for you. We did not have any network related issues last week that would have prevented users from logging experiments. Are you still experiencing this issue? If yes, could you please:</p>\n<ul>\n<li>Expand on the type of experiment you were running and approximately how many files and their size you were attempting to upload.</li>\n<li>Share the <code>debug.log</code> and <code>debug-internal.log</code> files of the hanging runs. These files are located in the working directory under<code> wandb/</code> folder</li>\n<li>Link to your private workspace for us to review</li>\n</ul>\n<p>Thank you</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-01T23:18:35.210Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/yueyang\">@yueyang</a>  since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-30T23:19:17.434Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Upload and Syncing of Artifacts are too slow using WSL - MainThread and HandlerThread hanging",
		"Question_link": "https://community.wandb.ai/t/upload-and-syncing-of-artifacts-are-too-slow-using-wsl-mainthread-and-handlerthread-hanging/3068",
		"Question_created_time": "2022-09-05T12:33:19.984Z",
		"Question_answer_count": 10,
		"Question_score_count": 0,
		"Question_view_count": 555,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello everyone, hope you can help me with this issue.</p>\n<p>I am very new to the W&amp;B interface and python library. I am tryingo to incorporate the dataset versioning and experiment tracking issues into my training procedure for now.</p>\n<p>In the dataset versioning section of my code, I am logging the raw dataset and the cleaned ones via wandb.Artifact \u2192 wandb.add_file \u2192 wandb.log_artifact workflow, as show in documentation.</p>\n<p>The problem is that a simple <strong>upload and syncing takes around 10 minutes to finish!</strong> The datasets sizes are small (approx. 2MB) and I don\u2019t have any connection constraints or issues that I\u2019m aware of.<br>\nI\u2019m using a JupyterNotebook in a WSL2 environment (distro Ubuntu 20.04)</p>\n<p>The output of code shows: <code>Wating for W&amp;B process to finish (sucess) ...</code> for the whole time, and the upload and syncing bar stucks during the whole time of waiting.</p>\n<p>The debug log for the <code>latest-run</code> show this over and over:</p>\n<pre><code class=\"lang-auto\">2022-09-05 01:29:54.344 INFO    MainThread:10293 [jupyter.py:save_history():447] not saving jupyter history\n2022-09-05 01:29:54.344 INFO    MainThread:10293 [jupyter.py:save_ipynb():377] not saving jupyter notebook\n2022-09-05 01:29:54.344 INFO    MainThread:10293 [wandb_init.py:_jupyter_teardown():393] cleaning up jupyter logic\n2022-09-05 01:29:54.344 INFO    MainThread:10293 [wandb_run.py:_atexit_cleanup():1931] got exitcode: 0\n2022-09-05 01:29:54.344 INFO    MainThread:10293 [wandb_run.py:_restore():1914] restore\n2022-09-05 01:29:54.345 INFO    MainThread:10293 [wandb_run.py:_restore():1920] restore done\n...\n2022-09-05 01:29:57.481 INFO    MainThread:10293 [wandb_run.py:_on_finish():2221] got exit ret: file_counts {\n  wandb_count: 5\n}\npusher_stats {\n  uploaded_bytes: 397\n  total_bytes: 4431\n}\n</code></pre>\n<p>And the <code>debug-intenal</code> log shows the following:</p>\n<pre><code class=\"lang-auto\">2022-09-05 01:29:57.789 DEBUG   SenderThread:10324 [sender.py:send_request():316] send_request: poll_exit\n2022-09-05 01:29:57.892 DEBUG   HandlerThread:10324 [handler.py:handle_request():141] handle_request: poll_exit\n2022-09-05 01:29:57.892 DEBUG   SenderThread:10324 [sender.py:send_request():316] send_request: poll_exit\n2022-09-05 01:29:57.993 DEBUG   HandlerThread:10324 [handler.py:handle_request():141] handle_request: poll_exit\n2022-09-05 01:29:57.994 DEBUG   SenderThread:10324 [sender.py:send_request():316] send_request: poll_exit\n</code></pre>\n<p>And in the end of the running cell, the <code>debug-internal</code> log shows (sensible info omitted):</p>\n<pre><code class=\"lang-auto\">2022-09-05 01:33:09,176 DEBUG   HandlerThread:10324 [handler.py:handle_request():141] handle_request: poll_exit\n2022-09-05 01:33:09,176 DEBUG   SenderThread:10324 [sender.py:send_request():316] send_request: poll_exit\n2022-09-05 01:33:10,268 INFO    WriterThread:10324 [datastore.py:close():279] close [...]\n2022-09-05 01:33:11,177 INFO    SenderThread:10324 [sender.py:finish():1312] shutting down sender\n2022-09-05 01:33:11,177 INFO    SenderThread:10324 [file_pusher.py:finish():171] shutting down file pusher\n2022-09-05 01:33:11,177 INFO    SenderThread:10324 [file_pusher.py:join():176] waiting for file pusher\n</code></pre>\n<p>I tried setting <code>WANDB_START_METHOD=thread</code> as mentioned in a Github issue, but didn\u2019t reduce overall time that the cell takes to finish. I have made the login through CLI and the cell recognizes my user.</p>\n<p>The raw data are in JSON format, and the cleaned data is a Pandas dataframe where of 30-60 rows, where each row contains an array of data (temporal analysis) around 2000 items.</p>\n<p><strong>Is there something I forgot  to setup? Is this the average time taken to upload files, even when they are small? I am missing something in the code workflow?</strong></p>\n<p>Any help would be much appreciated!</p>\n<p>Regards</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-08T18:22:21.028Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/shogunhirei\">@shogunhirei</a>, sorry you are running into this. Just to clarify, a single ~2MB dataset is taking 10 minutes to upload via Artifacts? Also, how many files are within the Artifact?</p>\n<p>We do perform a checksum of every file when uploading an Artifact which can take some time if an Artifact contains a large number of files.</p>\n<p>Can you also let me know what version of <code>wandb</code> you are running? <code>WANDB_START_METHOD=thread</code> is ignored in the latest version of <code>wandb</code> but I don\u2019t think that is the cause of this.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-08T21:36:36.720Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nathank\">@nathank</a>, thank you for the response.</p>\n<p>There are 7 files, they all together have size around 2MB, I added them to the same artifact. Is this not recommended?<br>\nMy version of wandb is 0.13.2.</p>\n<p>Looking at the logs that I have posted, it doesn\u2019t seems that the thread is stuck on some process\u2026<br>\nThe fact that I\u2019m using a WSL2 environment is a problem? Is there a network configuration that I should have done?</p>\n<p>I have also setted the <code>WANDB_START_METHOD</code> through <code>os.environ</code></p>\n<p>Thanks in advance</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-22T14:30:48.178Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/shogunhirei\">@shogunhirei</a> this is fine having the 7 files all together in a single Artifact. I was more concerned if this was a dataset with 100\u2019s of small files  but that doesn\u2019t look like the source of the problem.</p>\n<p>I think the most likely cause is the WSL2 environment. Could you possibly try uploading your files to a Colab and running this there to compare? This will also test if the issue is isolated to your network.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-27T17:10:16.470Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/shogunhirei\">@shogunhirei</a>, I wanted to follow up and see if you were still looking for help with this?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-27T17:35:03.389Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nathank\">@nathank</a> , sorry for not responding.</p>\n<p>I still haven\u2019t the time to check on this, but I\u2019ll do it soon enough. As soon as I can check in the Colab environment I\u2019ll post it here!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-27T17:38:52.283Z",
				"Answer_body": "<p>Ok, thank you for the update!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-02T20:47:50.106Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nathank\">@nathank</a>! Sorry for the late reply\u2026 (again <img src=\"https://emoji.discourse-cdn.com/twitter/sweat_smile.png?v=12\" title=\":sweat_smile:\" class=\"emoji\" alt=\":sweat_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"> )</p>\n<p>I have follow you advice and run the script in the Colab environment, it was way faster then in my WSL2 environment. Is there some thing I could do to fix this issue with WSL2?</p>\n<p>Is  this info enough to open a issue in the wandb repo?</p>\n<p>Kind regards,</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-31T03:53:11.080Z",
				"Answer_body": "<p>Hi everyone, does anyone know a solution for this?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-01T12:17:46.840Z",
				"Answer_body": "<p>Just want to add that I\u2019m running experiencing a similar problem</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-30T12:18:53.632Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Settings defined in wandb.config dictionary not shown at the Overview page",
		"Question_link": "https://community.wandb.ai/t/settings-defined-in-wandb-config-dictionary-not-shown-at-the-overview-page/3452",
		"Question_created_time": "2022-11-23T16:21:59.458Z",
		"Question_answer_count": 9,
		"Question_score_count": 1,
		"Question_view_count": 545,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Why settings specified in the wandb config dictionary (see the code below), are not shown in my W.&amp;B\u2019s Overview page?<br>\nWhen the init_wandb() method is called, all the parameter values are already known. I can see the logged information and charts in my W&amp;B\u2019s Workspace page but I can\u2019t see the settings in my Overview page.</p>\n<p>Any suggestions?<br>\nKind regards,<br>\nH.</p>\n<p>def init_wandb(self) \u2192 None:</p>\n<pre><code>    wandb.login(key=key_value)\n\n    my_params = {\n                 'architecture': self.model_name,\n                 'learning_rate': self.learning_rate,\n                 'epochs': self.epochs,\n                 'batch_size': self.batch_size,\n                 'dataset': self.dataset\n                 }\n\n    wandb.init(config=my_params,\n               project=self.project_name,\n               notes=self.dataset + '_' + self.date_now,\n               name=self.project_code\n               )\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-23T19:56:36.200Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hblanco2009\">@hblanco2009</a> thank you for writing in! You will have to select the specific Run from the project\u2019s workspace, and then go the run\u2019s Overview page. In the bottom left you should be able to see the config values. Does this work for you?</p>\n<p>Another way to get these values in the Project level would be to add a Weave panel and execute this expression: <code>runs.config</code>. Please let me know if you have any further questions or issues with this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-24T10:00:06.867Z",
				"Answer_body": "<p>I have the same problem, and this used to work fine. The behavior changed within the last month.</p>\n<p>Now, when i initialize a new project, I cannot see any of the configured parameters in the Runs table, only metrics. This holds true even when moving runs from an older project that behaves as it should into the new project.</p>\n<p>The configurations are indeed displayed when you open the individual run as <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a> says, but they do not show up in the Runs table any more (not under hidden columns either.)</p>\n<p>Would be great to get the configuration columns back into the Runs table.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-24T12:15:58.325Z",
				"Answer_body": "<p>Thank you very much for your soon reply. Now, I can see the settings specified in wandb.config dictionary at the  Overview page. In fact, I wasn\u2019t selecting the run. Nonetheless, I can also see these values in the Table page along with the performance metrics logged.</p>\n<p>Best regards<br>\nH.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-25T12:31:25.618Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hblanco2009\">@hblanco2009</a> thank you for confirming this, glad it\u2019s resolved for you!</p>\n<p><a class=\"mention\" href=\"/u/jugoetz\">@jugoetz</a> would it be possible to share a screenshot to investigate this further why it\u2019s still happening for you? thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-25T14:53:01.287Z",
				"Answer_body": "<p>Sure, let me supply some more info:<br>\nSo here is what I expect to see (the run is in a project created several weeks ago):<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/8/81c0be6ebee1eb6be2fc583e99859ad1a142b85e.png\" data-download-href=\"/uploads/short-url/ivQxP3Bzeu7rrZCifh46vC4nIBM.png?dl=1\" title=\"Screenshot 2022-11-25 at 15.42.41\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/81c0be6ebee1eb6be2fc583e99859ad1a142b85e_2_690x79.png\" alt=\"Screenshot 2022-11-25 at 15.42.41\" data-base62-sha1=\"ivQxP3Bzeu7rrZCifh46vC4nIBM\" width=\"690\" height=\"79\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/81c0be6ebee1eb6be2fc583e99859ad1a142b85e_2_690x79.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/81c0be6ebee1eb6be2fc583e99859ad1a142b85e_2_1035x118.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/81c0be6ebee1eb6be2fc583e99859ad1a142b85e_2_1380x158.png 2x\" data-dominant-color=\"222223\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2022-11-25 at 15.42.41</span><span class=\"informations\">1692\u00d7194 26.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nAs you can see, all of the configuration is conveniently shown in the Runs table.<br>\nNow, if I create a new project and move this run group to the new project, I get this:</p>\n<p>[see next post as the system lets me put only one embedded item per post]</p>\n<p>Now, I can still see some meta data and the metrics that I collect, but none of the configuration parameters show up anymore. They are also not available in the \u201cManage columns\u201d menu or in the filters.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-25T14:53:32.312Z",
				"Answer_body": "<p>[missing screenshot from last post]</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/4/45d6cac74469e1cdd448f1bab0deaf9c72130e09.png\" data-download-href=\"/uploads/short-url/9XP8oyfljDmuhRdZpQiSYXljIBb.png?dl=1\" title=\"Screenshot 2022-11-25 at 15.45.30\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/45d6cac74469e1cdd448f1bab0deaf9c72130e09_2_690x81.png\" alt=\"Screenshot 2022-11-25 at 15.45.30\" data-base62-sha1=\"9XP8oyfljDmuhRdZpQiSYXljIBb\" width=\"690\" height=\"81\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/45d6cac74469e1cdd448f1bab0deaf9c72130e09_2_690x81.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/45d6cac74469e1cdd448f1bab0deaf9c72130e09_2_1035x121.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/45d6cac74469e1cdd448f1bab0deaf9c72130e09_2_1380x162.png 2x\" data-dominant-color=\"222324\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2022-11-25 at 15.45.30</span><span class=\"informations\">1639\u00d7194 61 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-29T16:42:06.191Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/jugoetz\">@jugoetz</a> thanks a lot for the screenshots, that\u2019s really helpful. Could you please let me know the names of the <code>original</code> and <code>destination</code> projects, to investigate this issue further? Also, just to clarify are the values missing from certain config columns, or you can\u2019t even find the config parameters/columns? in the latter case, did you check if these appear under the <code>Hidden columns</code> section from the <code>Columns</code> button?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-30T10:15:49.250Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/jugoetz\">@jugoetz</a> I\u2019ve investigated this issue further, it\u2019s a bug which occurs when moving runs and the config returns null. The engineering team is working on a fix, and I will let you know here once this is released. Thanks so much for reporting this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-29T10:16:24.352Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Dataset selection for hyperparameter optimization and training",
		"Question_link": "https://community.wandb.ai/t/dataset-selection-for-hyperparameter-optimization-and-training/3455",
		"Question_created_time": "2022-11-24T07:50:35.658Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 99,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\ni want to make a multiclass classifier using a bert model. For this i would like to compare the performance of (at least) two domain specific bert models. But  before i compare the model performance i would like to find the best hyperparameters using wandb sweeps und the simpletransformers api (the simpletransformers api, has an easy integration with wandb).</p>\n<p>Currently i\u2019m a bit confused how to select a good dataset for</p>\n<ol>\n<li>the hyperparameter optimization</li>\n<li>the training with the best hyperparams.</li>\n</ol>\n<p>So for the hyperparams, should i create n cross-validation sets and then run a training cycle with the current selected hyperparams for every m in n dataset?<br>\nE.g. i created 2 train/test sets and i only want to find the best n of episodes out of [1,2]:<br>\nFor both train/test sets, the training is done for 1 episode and in the nex cycle for 2 episodes?</p>\n<p>And if i found the best hyperparameters, should i train the final model afterwards using my full dataset?</p>\n<p>Hope my questions are kind of clear</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-30T06:25:38.012Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/simonkleinfeld\">@simonkleinfeld</a>!</p>\n<p>Thank you for writing in!  The W&amp;B Help channel is usually meant for support with W&amp;B issues, you would probably get a better response on the community channel : <a href=\"https://community.wandb.ai/c/show-the-community/43\" class=\"inline-onebox\">Show the Community! - W&amp;B Community</a>.</p>\n<p>In any case, I\u2019ll take a stab at helping here : A good dataset for your model would be the same (or similar) to the dataset you plan to finally use for training and inference. Good hyperparameters are usually dataset dependent.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-29T06:26:30.474Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "About Network error (TransientError)",
		"Question_link": "https://community.wandb.ai/t/about-network-error-transienterror/3462",
		"Question_created_time": "2022-11-25T14:20:11.119Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 857,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I get below error message when starting a new run:</p>\n<pre><code class=\"lang-shell\">wandb: Network error (TransientError), entering retry loop.\n</code></pre>\n<p>Some metrics can be uploaded successfully, but some metrics are not (cannot be found in the UI).</p>\n<p>I have determined that it is an internet connection problem because this problem is solved when I change WIFI connection from A to B.</p>\n<p>I would like to know if there is any way to guide the network operator to fix the network A. Is <code>ping</code> command can help (should try to decrease the packet loss)?</p>\n<pre><code class=\"lang-shell\">PING www.wandb.ai (151.101.1.195): 56 data bytes\n64 bytes from 151.101.1.195: icmp_seq=0 ttl=42 time=258.594 ms\n64 bytes from 151.101.1.195: icmp_seq=1 ttl=42 time=188.247 ms\n64 bytes from 151.101.1.195: icmp_seq=2 ttl=42 time=186.654 ms\n64 bytes from 151.101.1.195: icmp_seq=3 ttl=42 time=189.388 ms\n64 bytes from 151.101.1.195: icmp_seq=4 ttl=42 time=228.432 ms\n64 bytes from 151.101.1.195: icmp_seq=5 ttl=42 time=280.176 ms\n64 bytes from 151.101.1.195: icmp_seq=6 ttl=42 time=324.054 ms\n64 bytes from 151.101.1.195: icmp_seq=7 ttl=42 time=215.211 ms\n64 bytes from 151.101.1.195: icmp_seq=8 ttl=42 time=224.348 ms\nRequest timeout for icmp_seq 9\n64 bytes from 151.101.1.195: icmp_seq=10 ttl=42 time=311.803 ms\n64 bytes from 151.101.1.195: icmp_seq=11 ttl=42 time=187.057 ms\n64 bytes from 151.101.1.195: icmp_seq=12 ttl=42 time=189.397 ms\n64 bytes from 151.101.1.195: icmp_seq=13 ttl=42 time=196.487 ms\n64 bytes from 151.101.1.195: icmp_seq=14 ttl=42 time=195.504 ms\n64 bytes from 151.101.1.195: icmp_seq=15 ttl=42 time=194.557 ms\n64 bytes from 151.101.1.195: icmp_seq=16 ttl=42 time=189.196 ms\n64 bytes from 151.101.1.195: icmp_seq=17 ttl=42 time=185.882 ms\n^C\n--- www.wandb.ai ping statistics ---\n19 packets transmitted, 17 packets received, 10.5% packet loss\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-29T21:13:03.223Z",
				"Answer_body": "<p>Hi Yao, is there a reason why you can\u2019t use network B to run your models? Trying to reduce the packet loss is always a great idea</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-30T05:42:06.078Z",
				"Answer_body": "<p>Thank you for the reply! I suppose many Chinese users have encountered this network error because of using the network provided by the same Network Operator (NO). Switching to another Network Operator is not very easy for everyone. I want to report this issue to the NO but I don\u2019t know how to describe it. Does there exist the testing address can be used for fixing this issue?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-12T22:53:33.467Z",
				"Answer_body": "<p>Hi Yao. By testing address do you mean the host address? If so, this should be <a href=\"http://wandb.ai\">wandb.ai</a>. If not, can you elaborate more on what you are asking for?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-16T21:37:48.892Z",
				"Answer_body": "<p>Hi Yao, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-29T05:42:15.398Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "ERROR: Project does not contain artifact",
		"Question_link": "https://community.wandb.ai/t/error-project-does-not-contain-artifact/3314",
		"Question_created_time": "2022-10-24T20:50:40.009Z",
		"Question_answer_count": 9,
		"Question_score_count": 0,
		"Question_view_count": 534,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m running the following code to initialize a run and use my dataset as an artifact:</p>\n<pre><code class=\"lang-auto\">    run = wandb.init(name=job_name, project=wandb_project_name, config=vars(args), save_code=True, job_type=\"training\")\n    wandb.run.log_code(\".\")\n    print(wandb_dataset_name)\n    dataset = run.use_artifact(wandb_dataset_name)\n</code></pre>\n<p>This code is in a Sagemaker script and when I run, everything works as expected. However, when I run the same exact script in a Sagemaker hyper parameter tuning job instead of a single training job, I get the following error:</p>\n<blockquote>\n<p>wandb: WARNING Calling wandb.login() after wandb.init() has no effect.<br>\ndistributedspectrum/RadioML-Experimentation/RadioML_tfrecords:v0<br>\nwandb: WARNING Calling wandb.login() after wandb.init() has no effect.<br>\nwandb: WARNING Calling wandb.login() after wandb.init() has no effect.<br>\nwandb: ERROR Project distributedspectrum/RadioML-Experimentation does not contain artifact: \u201cRadioML_tfrecords:v0\u201d<br>\nTraceback (most recent call last):<br>\nFile \u201c/usr/local/lib/python3.8/site-packages/wandb/apis/normalize.py\u201d, line 26, in wrapper<br>\nreturn func(*args, **kwargs)<br>\nFile \u201c/usr/local/lib/python3.8/site-packages/wandb/apis/public.py\u201d, line 937, in artifact<br>\nartifact = Artifact(self.client, entity, project, artifact_name)<br>\nFile \u201c/usr/local/lib/python3.8/site-packages/wandb/apis/public.py\u201d, line 4151, in <strong>init</strong><br>\nself._load()<br>\nFile \u201c/usr/local/lib/python3.8/site-packages/wandb/apis/public.py\u201d, line 4735, in _load<br>\nraise ValueError(<br>\nValueError: Project distributedspectrum/RadioML-Experimentation does not contain artifact: \u201cRadioML_tfrecords:v0\u201d<br>\nDuring handling of the above exception, another exception occurred:<br>\nTraceback (most recent call last):<br>\nFile \u201cradioml-training.py\u201d, line 306, in <br>\nmain(args)<br>\nFile \u201cradioml-training.py\u201d, line 175, in main<br>\ndataset = run.use_artifact(wandb_database_name)<br>\nFile \u201c/usr/local/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\u201d, line 255, in wrapper<br>\nreturn func(self, *args, **kwargs)<br>\nFile \u201c/usr/local/lib/python3.8/site-packages/wandb/sdk/wandb_run.py\u201d, line 2575, in use_artifact<br>\nartifact = public_api.artifact(type=type, name=name)<br>\nFile \u201c/usr/local/lib/python3.8/site-packages/wandb/apis/normalize.py\u201d, line 62, in wrapper<br>\nraise CommError(message, err).with_traceback(sys.exc_info()[2])<br>\nFile \u201c/usr/local/lib/python3.8/site-packages/wandb/apis/normalize.py\u201d, line 26, in wrapper<br>\nreturn func(*args, **kwargs)<br>\nFile \u201c/usr/local/lib/python3.8/site-packages/wandb/apis/public.py\u201d, line 937, in artifact<br>\nartifact = Artifact(self.client, entity, project, artifact_name)<br>\nFile \u201c/usr/local/lib/python3.8/site-packages/wandb/apis/public.py\u201d, line 4151, in <strong>init</strong><br>\nself._load()<br>\nFile \u201c/usr/local/lib/python3.8/site-packages/wandb/apis/public.py\u201d, line 4735, in _load<br>\nraise ValueError(<br>\nwandb.errors.CommError: Project distributedspectrum/RadioML-Experimentation does not contain artifact: \u201cRadioML_tfrecords:v0\u201d</p>\n</blockquote>\n<p>Literally everything is exactly the same but I suddenly get this error. I\u2019m also not sure why the warnings about wandb.login() appear as well. They don\u2019t appear in the single training job and I don\u2019t ever call wandb.login() in my code.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-25T21:30:18.456Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dspectrum\">@dspectrum</a> , happy to help with the issue you are facing.</p>\n<p>A few things come to mind.</p>\n<ul>\n<li>Do you see this artifact in the UI?</li>\n<li>Are you able to <strong>get</strong> the artifact via the command line? <code>wandb artifact get &lt;entity&gt;/&lt;project&gt;/&lt;artifact-name&gt;</code>\n</li>\n<li>Have you verified your sagemaker host environmental variable is referenced correctly prior to executing the training ? <code>wandb status</code> to check <strong>\u201cbase_url\u201d</strong>. To set, use <code>export WANDB_BASE_URL=&lt;HOST&gt;:&lt;PORT&gt;</code>\n</li>\n</ul>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-25T22:07:59.172Z",
				"Answer_body": "<p>Yes, the artifact is in the UI! I am able to get everything to work perfectly when I run in Sagemaker with one instance. It\u2019s just when I launch a hyperparameter tuning job that it doesn\u2019t work.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-09T20:54:43.947Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dspectrum\">@dspectrum</a>, following up on this. We ran some tests and were successful in utilizing artifacts within sagemaker. Are you still experiencing the same errors as before.</p>\n<p>One thing you can try is to include the full entity/project path to the artifact name. For example, instead of</p>\n<p><code>artifact_name = \u201cRadioML_tfrecords:v0\u201d</code><br>\nuse<br>\n<code>artifact_name = \u201c&lt;entity&gt;/&lt;project-name&gt;/RadioML_tfrecords:v0\u201d</code></p>\n<p>it might be that in SM, the entity and project it inherits from the run is different than where the artifact is.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-11T21:24:27.449Z",
				"Answer_body": "<p>Thanks for following up! To clarify, I have also been able to successfully use artifacts in sagemaker. It\u2019s only when I switch from a normal training job to a hyper parameter tuning job (<a href=\"https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">HyperparameterTuner \u2014 sagemaker 2.116.0 documentation</a>) that this error occurs.</p>\n<p>Also apologies if this was unclear but I am actually referring to the full path in my code.</p>\n<p>When I run <code>print(wandb_dataset_name)</code> you can see that I prints <code>distributedspectrum/RadioML-Experimentation/RadioML_tfrecords:v0</code></p>\n<p>Thanks for the help so far, let me know what you think!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-15T23:24:29.525Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dspectrum\">@dspectrum</a> , thank you for the clarifying remarks. I\u2019ll run some additional tests on our end as I was still unable to replicate. In the meantime could you try  <a href=\"https://docs.wandb.ai/ref/python/run#use_artifact\">use_artifact</a><code>use_artifact(\"&lt;entity&gt;/&lt;project&gt;/&lt;artifact&gt;:latest\")</code></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-21T19:50:14.785Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dspectrum\">@dspectrum</a> , following up on this. Are you still experiencing issues with using artifacts with your hyperparameter training runs with sagemaker?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-28T17:22:42.280Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dspectrum\">@dspectrum</a>  since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-30T03:21:13.777Z",
				"Answer_body": "<p>Hi,<br>\nVery sorry for the delay here. I tried again with :latest instead of :v0 but got the same result.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-29T03:21:57.487Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Digest mismatch error when trying to download model artifact from S3",
		"Question_link": "https://community.wandb.ai/t/digest-mismatch-error-when-trying-to-download-model-artifact-from-s3/3269",
		"Question_created_time": "2022-10-18T00:11:32.610Z",
		"Question_answer_count": 7,
		"Question_score_count": 2,
		"Question_view_count": 301,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I\u2019m using AWS Sagemaker to train a Keras model with the Wandb callback. In my Sagemaker script, I save checkpoints to <code>'/opt/ml/checkpoints/'</code> which it redirects to an s3 bucket continuously. After the model has finished training, I create my artifact and add a reference to that bucket.</p>\n<p>Later, if I try to download the model with:</p>\n<pre><code class=\"lang-auto\">model_path = run.use_artifact(...)\nmodel_path.download()\n</code></pre>\n<p>I get the following error:</p>\n<blockquote>\n<p>ValueError: Digest mismatch for object s3://\u2026/variables/variables.data-00000-of-00001: expected 4f8d37a52a3e87f1f0ee2d3101688848-3 but found 8ad5ef5242d547d7edaa76f620597b60-3</p>\n</blockquote>\n<p>My guess is that I\u2019ve added the reference to the artifact before Sagemaker has pushed the final model from the local directory to S3. I\u2019m not sure how to get around this, is there a better way to have my Artifacts be linked to an S3 bucket?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-20T22:18:32.157Z",
				"Answer_body": "<p>Hi Ben! Is this the whole error message received?</p>\n<p>If there is a stack trace associated to this error, it would be great to be able to have a look and also if it is possible, I would like to have a look at how you are uploading this artifact before I can give you a complete answer here.</p>\n<p>There could be multiple reasons for the digest to be mismatched, so I would need some more information to get a complete understanding of the issue to help you out here.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-20T22:40:48.757Z",
				"Answer_body": "<p>Thanks Ramit!</p>\n<p>Here\u2019s how everything currently works. In Sagemaker, I define my Tensorflow estimator as follows:</p>\n<pre><code class=\"lang-auto\">tf_estimator = TensorFlow(\n                          ...\n                          checkpoint_s3_uri    = f's3://ds-models-1/{model_name}/{run_name}',\n                          checkpoint_local_path= '/opt/ml/checkpoints/')\n</code></pre>\n<p>Then in my training script, I make the Checkpoint callback:</p>\n<pre><code class=\"lang-auto\">model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n        filepath='/opt/ml/checkpoints/',\n        save_weights_only=False,\n        monitor='val_accuracy',\n        mode='max',\n        save_best_only=True)\n</code></pre>\n<p>So the model checkpoints are saved to \u2018/opt/ml/checkpoints/\u2019 and Sagemaker monitors that folder and pushes to my S3 bucket.</p>\n<p>After training completes in the script, I create my Wandb artifact:</p>\n<pre><code class=\"lang-auto\">    art = wandb.Artifact(job_name, type=\"model\")\n    art.add_reference(f's3://ds-models-1/{model_name}/{run_name}')\n    wandb.log_artifact(art)\n</code></pre>\n<p>All of that works well and I can see my model uploaded to S3 as well as listed as an artifact in Wandb.<br>\nWhen I then go into my notebook to try to download the model, here\u2019s what I get:</p>\n<pre><code class=\"lang-auto\">run = wandb.init(name=\"download_model\", project=project, job_type=\"testing\")\nmodel_path = run.use_artifact(wandb_model_name, type='model')\nmodel_path.download()\n</code></pre>\n<blockquote>\n<p>ValueError                                Traceback (most recent call last)<br>\n/tmp/ipykernel_11366/3182984502.py in &lt;cell line: 4&gt;()<br>\n2<br>\n3 model_path = run.use_artifact(\u2018distributedspectrum/RadioML-Experimentation/RadioML-1d-conv-training-run-1:v0\u2019, type=\u2018model\u2019)<br>\n----&gt; 4 model_path.download()<br>\n~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/wandb/apis/public.py in download(self, root, recursive)<br>\n4521<br>\n4522         pool = multiprocessing.dummy.Pool(32)<br>\n \u2192 4523         pool.map(<br>\n4524             partial(self._download_file, root=dirpath, download_logger=download_logger),<br>\n4525             manifest.entries,<br>\n~/anaconda3/envs/tensorflow2_p38/lib/python3.8/multiprocessing/pool.py in map(self, func, iterable, chunksize)<br>\n362         in a list that is returned.<br>\n363         \u2018\u2019\u2019<br>\n \u2192 364         return self._map_async(func, iterable, mapstar, chunksize).get()<br>\n365<br>\n366     def starmap(self, func, iterable, chunksize=None):<br>\n~/anaconda3/envs/tensorflow2_p38/lib/python3.8/multiprocessing/pool.py in get(self, timeout)<br>\n769             return self._value<br>\n770         else:<br>\n \u2192 771             raise self._value<br>\n772<br>\n773     def _set(self, i, obj):<br>\n~/anaconda3/envs/tensorflow2_p38/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)<br>\n123         job, i, func, args, kwds = task<br>\n124         try:<br>\n \u2192 125             result = (True, func(*args, **kwds))<br>\n126         except Exception as e:<br>\n127             if wrap_exception and func is not _helper_reraises_exception:<br>\n~/anaconda3/envs/tensorflow2_p38/lib/python3.8/multiprocessing/pool.py in mapstar(args)<br>\n46<br>\n47 def mapstar(args):<br>\n\u2014&gt; 48     return list(map(*args))<br>\n49<br>\n50 def starmapstar(args):<br>\n~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/wandb/apis/public.py in _download_file(self, name, root, download_logger)<br>\n4620     ):<br>\n4621         # download file into cache and copy to target dir<br>\n \u2192 4622         downloaded_path = self.get_path(name).download(root)<br>\n4623         if download_logger is not None:<br>\n4624             download_logger.notify_downloaded()<br>\n~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/wandb/apis/public.py in download(self, root)<br>\n3943         manifest = self._parent_artifact._load_manifest()<br>\n3944         if self.entry.ref is not None:<br>\n \u2192 3945             cache_path = manifest.storage_policy.load_reference(<br>\n3946                 self._parent_artifact,<br>\n3947                 self.name,<br>\n~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/wandb/sdk/wandb_artifacts.py in load_reference(self, artifact, name, manifest_entry, local)<br>\n962         local: bool = False,<br>\n963     ) \u2192 str:<br>\n \u2192 964         return self._handler.load_path(artifact, manifest_entry, local)<br>\n965<br>\n966     def _file_url(<br>\n~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/wandb/sdk/wandb_artifacts.py in load_path(self, artifact, manifest_entry, local)<br>\n1120                 \u2018No storage handler registered for scheme \u201c%s\u201d\u2019 % str(url.scheme)<br>\n1121             )<br>\n \u2192 1122         return self._handlers[str(url.scheme)].load_path(<br>\n1123             artifact, manifest_entry, local=local<br>\n1124         )<br>\n~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/wandb/sdk/wandb_artifacts.py in load_path(self, artifact, manifest_entry, local)<br>\n1430                         )<br>\n1431                 else:<br>\n \u2192 1432                     raise ValueError(<br>\n1433                         \u201cDigest mismatch for object %s: expected %s but found %s\u201d<br>\n1434                         % (manifest_entry.ref, manifest_entry.digest, etag)<br>\nValueError: Digest mismatch for object s3://ds-models-1/RadioML-1d-conv/training-run-1/saved_model.pb: expected bd308623d5d8db45d883aa98e570147d but found 584fe63cdb5cff0663c058e57527dded</p>\n</blockquote>\n<p>Sometimes, it\u2019ll complain about the \u201csaved_model.pb\u201d file and sometimes it\u2019ll be one of the Keras variable files.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-27T17:31:38.081Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dspectrum\">@dspectrum</a>,</p>\n<p>Looking at your error and tracing back through our code - looks like versioning is not enabled on your S3 bucket, which means the artifact is changing the file itself, leading to different hashes. I would suggest turning on versioning on your S3 bucket and letting me know if you still run into the same error.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-10-31T03:22:37.179Z",
				"Answer_body": "<p>Hi Ben,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-01T16:11:07.629Z",
				"Answer_body": "<p>Hi Ben, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-30T01:49:03.762Z",
				"Answer_body": "<p>Apologies for the delay, this appears to have solved it! Thanks for the help</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-29T01:49:48.422Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Init and config in different files",
		"Question_link": "https://community.wandb.ai/t/init-and-config-in-different-files/3439",
		"Question_created_time": "2022-11-18T10:52:38.344Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 192,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi all,<br>\nI want to seperate the wandb.config from wandb.init in my training script. Howerever I cant seem to get around a circular import when trying to do this. I had a workaround where I use .init(mode=\u201coffline\u201d), so I can use wandb.config() afterwards and then call init() again in the training script. However this does not seem to work with sweeps.</p>\n<ol>\n<li>In settings.py: Run wandb.config()</li>\n<li>In training.py: From settings import config<br>\nRun wandb.init() in training.py</li>\n</ol>\n<p>I feel like there is an obvious solution, but I cant seem to find it.<br>\nThanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-21T17:17:35.046Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nime6\">@nime6</a>,<br>\nI may need to know a little bit more about the use case here. My initial thought is to save config as a .yaml and then read that into your <code>training.py</code> where you could pass it into <code>wandb.init(config=&lt;your_yaml_converted_to_a_dict&gt;)</code></p>\n<p>This also might be a use case for using a <a href=\"https://docs.wandb.ai/guides/track/config#file-based-configs\">file based config</a>.</p>\n<p>If that doesn\u2019t seem like what you are looking for could you elaborate more on why you are trying to set  <code>wandb.config()</code>outside of the training script?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-29T00:06:20.532Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nime6\">@nime6</a>, I just wanted to follow up on this and see if they above would work for you in this case?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-28T00:06:59.543Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Hypyerparameter optimization with k folds on each iteration",
		"Question_link": "https://community.wandb.ai/t/hypyerparameter-optimization-with-k-folds-on-each-iteration/3429",
		"Question_created_time": "2022-11-16T15:55:13.531Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 193,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am trying to perform hyperparameter optimization with wandb and for each iteration I would like to get the average performance across 3 different folds of my dataset.</p>\n<p>I have defined a function optimize that i pass to wandb.agent:</p>\n<pre><code class=\"lang-auto\">def optimize(config):\n    for fold in range(1, 4):    \n        dataset_artifact = f'fold-{fold}:latest'\n        config['dataset_artifact'] = dataset_artifact \n        with wandb.init(config=config, group=group_name, job_type=f'train-fold-{fold}', name=f'train-fold-{fold}', reinit=True) as run:   \n            train_and_log(config, run)  \n            run.finish()\n</code></pre>\n<p>I would expect this to creat a seperate run for each fold (since I have specified a different job type and run name as well as passing init=True) so that I would end up with:</p>\n<p>Group: param_combo_1</p>\n<p>\u00a0\u00a0\u00a0\u00a0&gt; Job Type: train-fold-1</p>\n<p>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&gt; train-fold-1</p>\n<p>\u00a0\u00a0\u00a0\u00a0&gt; Job Type: train-fold-2</p>\n<p>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&gt; train-fold-2</p>\n<p>\u00a0\u00a0\u00a0\u00a0&gt; Job Type: train-fold-3</p>\n<p>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&gt; train-fold-3</p>\n<p>However each run for a given hyperparameter iteration overwrites the previous fold so I in fact end up with</p>\n<p>Group: param_combo_1</p>\n<p>\u00a0\u00a0\u00a0\u00a0&gt; Job Type: train-fold-3</p>\n<p>\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&gt; train-fold-3</p>\n<p>How can I resolve this issue?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-17T15:09:37.838Z",
				"Answer_body": "<p>Hi Alexander, thanks for writing in!</p>\n<p>I can see the same behaviour as you do. After some investigation, I have realized that this is an intended one because of the fact that, with each combination of parameters it is created only one run (same run id), so it is only resuming the previous run although you use <code>reinit=True</code>. In terms of a workaround, I think there are two ways to solve this:</p>\n<ul>\n<li>Average your metrics inside the <code>optimize()</code>/<code>train_and_log()</code> function in the same run instead of creating different runs.</li>\n<li>Use the <code>grid</code> method instead of <code>random</code> and repeat some values (i.e. batch_size=[64,64,64,128,128,128]).<br>\nPlease let me know if any of these would work for you or if you would like me to create a request for this feature (I was thinking something like a new argument in the agent like <code>repeat=number_of_repetitions</code> and average the results). If this is the case, I would really appreciate if you could give me some more details about your use-case and why this new feature would be useful for you. Thanks!</li>\n</ul>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-22T10:28:46.330Z",
				"Answer_body": "<p>Hi Alexander,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-25T11:57:33.169Z",
				"Answer_body": "<p>Hi Luis,</p>\n<p>Those workarounds will probably be okay but I would very much like to see a feature allowing you to implement this behaviour with a parameter such as \u2018repeat\u2019 as you mentioned.</p>\n<p>Many thanks,<br>\nAlexander</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-28T10:49:07.561Z",
				"Answer_body": "<p>Hi Alexander,</p>\n<p>Thanks for confirming this! I have created a request for this feature, thanks for suggesting it. May I help you in any other way?</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-24T11:58:07.383Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Run to Run Logging",
		"Question_link": "https://community.wandb.ai/t/run-to-run-logging/3353",
		"Question_created_time": "2022-11-01T06:23:49.357Z",
		"Question_answer_count": 11,
		"Question_score_count": 0,
		"Question_view_count": 713,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>We are interested in using WandB to track monitoring statistics for a Model that is going into production.  We have a process that runs known data against the model and records results to confirm operation and timing.<br>\nWe would like to show the statistics in a lineplot over many iterations from these regular monitoring runs.  Its important to be able see a plot tracking the values over time.<br>\nWhat is the recommended way to log run-to-run values?<br>\nOptions:</p>\n<ol>\n<li>Use the <code>resume</code> command to continue a RunID repeatedly for every monitoring run.<br>\n<code>wand.init(project=\"name\",id=\"my_run_id\", resume=True)</code><br>\nThis seems to work, but I have found that I can\u2019t look at old values. Only the most recent values are shown under the <code>Summary</code> panel.  It would be helpful to see a Table of all recorded values over time.</li>\n<li>Somehow use a Table, but can\u2019t find a way to tack on data to a table from a previous run</li>\n<li>Use a separate Run for each test, but find some way to track statistics across runs.  I\u2019ve tried to search on this, but can\u2019t find a way to do this across dozens to hundreds of runs.<br>\nThanks for the help.</li>\n</ol>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-02T14:59:39.585Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> thank you for the question! These seem all valid options, and the decision depends on the specifics of your use case. Before diving into the implementation details, I wanted to confirm if this model is always the same, and the only change is the data that is fed into it? also could you please describe bit more the plotted data and what the x-axis would be, do the metrics change over time for each run, or each run provides a scalar and you want that value displayed on a different x-axis point?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-02T15:28:01.066Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a>,<br>\nThis is a production monitoring scenario where we are confirming operation of the model on a daily basis. The model does not change and the data does not change.  We want to confirm that none of the underlying systems have drifted, failed or become misconfigured. Think of it in terms of Statistical Process Control (SPC) where machinery is monitored to confirm operation.<br>\nPlotting should show (hopefully) a dead flat line, since nothing will be changing for the predicted values, but the inferencing time should wander a bit in a narrow span.<br>\nDoes this help?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-02T15:38:43.518Z",
				"Answer_body": "<p>The x-axis should be the iteration step or preferably the date, since the test will be run daily.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-04T10:16:58.172Z",
				"Answer_body": "<p>Thanks so much <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> for explaining the details of your use case, it\u2019s really helpful.  Production monitoring isn\u2019t available now but is a roadmap item for us and currently in the design phase.</p>\n<p>Regarding your issue though, there are couple workarounds to get this particular plot. Again here it seems you would be interested in the <a href=\"https://docs.wandb.ai/guides/artifacts/create-a-new-artifact-version\">patch mode</a> of artifacts which isn\u2019t yet available. However, you could create a new artifact table version for each new datapoints you would want to add to it, and that could be easily plotted. For the resuming run option, the previous points should be in the <code>history</code> field, the <code>summary</code> is updated to the latest value.  For both options, <code>Weave</code> could get the two fields (metric vs date) you want to plot. Would you be interested in a single line plot, or you want to overlay the band, error bars, etc?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-09T11:56:46.825Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> just checking in to see if the above information helped, or if you would prefer to provide you with a minimal example in case it hasn\u2019t been resolved for you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-10T08:11:59.670Z",
				"Answer_body": "<p>Hi Thanos,<br>\nThank you for checking in on this.<br>\nI have been using:</p>\n<ul>\n<li><code>wandb.log({\"ComputeTimeMean_msec\":123.4},)</code></li>\n</ul>\n<p>The suggestion to look into Weave is a good one.  It seems very powerful and I was able to get it to plot.<br>\nThough I must say the documentation is vague and seems to cover only a fraction of the features that are available.<br>\nThe <code>concat</code> operator, for example, seems to be critical but is not even mentioned in the docs. I only found it by trial-and-error.</p>\n<p>Here is a Table I was able to generate using Weave:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/8/84dacfb1a8d204f90d0f954f0cd4b5628eacdf1d.png\" data-download-href=\"/uploads/short-url/iXhPhAKF8M1gPi6SC87LDqkgV1X.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/84dacfb1a8d204f90d0f954f0cd4b5628eacdf1d_2_690x184.png\" alt=\"image\" data-base62-sha1=\"iXhPhAKF8M1gPi6SC87LDqkgV1X\" width=\"690\" height=\"184\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/84dacfb1a8d204f90d0f954f0cd4b5628eacdf1d_2_690x184.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/84dacfb1a8d204f90d0f954f0cd4b5628eacdf1d_2_1035x276.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/8/84dacfb1a8d204f90d0f954f0cd4b5628eacdf1d_2_1380x368.png 2x\" data-dominant-color=\"212121\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">3126\u00d7834 114 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Here is a plot for the same data.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/e/efca671a4d01cfb054c2ab49bd7c17df65eb93c2.png\" data-download-href=\"/uploads/short-url/ydhLcvyBWvdFLhZVeANV18CLU54.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/efca671a4d01cfb054c2ab49bd7c17df65eb93c2_2_690x207.png\" alt=\"image\" data-base62-sha1=\"ydhLcvyBWvdFLhZVeANV18CLU54\" width=\"690\" height=\"207\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/efca671a4d01cfb054c2ab49bd7c17df65eb93c2_2_690x207.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/efca671a4d01cfb054c2ab49bd7c17df65eb93c2_2_1035x310.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/efca671a4d01cfb054c2ab49bd7c17df65eb93c2_2_1380x414.png 2x\" data-dominant-color=\"232323\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">3138\u00d7944 258 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>And here is the default chart that was automatically added.  This almost seems easier to read, since the range-limits are auto-scaled \u2013 something that I was not able to do with Weave.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/e/ee0f824276730e3a7a1c53cd2677bd4162d8c996.png\" data-download-href=\"/uploads/short-url/xXYRESR4UKXRtrrElxVpJyc5Xr8.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ee0f824276730e3a7a1c53cd2677bd4162d8c996_2_690x343.png\" alt=\"image\" data-base62-sha1=\"xXYRESR4UKXRtrrElxVpJyc5Xr8\" width=\"690\" height=\"343\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ee0f824276730e3a7a1c53cd2677bd4162d8c996_2_690x343.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ee0f824276730e3a7a1c53cd2677bd4162d8c996_2_1035x514.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/ee0f824276730e3a7a1c53cd2677bd4162d8c996_2_1380x686.png 2x\" data-dominant-color=\"222223\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">2048\u00d71020 173 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-10T08:13:02.537Z",
				"Answer_body": "<p>With regard to the original question, it seems that using <code>wandb.log()</code> along with <code>weave</code> should be sufficient for my needs.  Is there anything else I should know about this?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-18T17:46:12.960Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> great to hear you enjoy <code>Weave</code> and that it solves the original issue. Thanks so much as well for posting detailed information on how this was achieved for future reference here in the forum. Indeed the reference docs for <code>Weave</code> won\u2019t cover all aspects yet, but Weave is actively developed with many new features coming in Q1 and the documentation is constantly updated. Would there be anything else to help with this issue?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-20T02:57:03.845Z",
				"Answer_body": "<p>Hi Thanos.<br>\nNo, I think we are good on this.<br>\nThank you!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-24T13:36:54.934Z",
				"Answer_body": "<p>Thanks <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> happy this is resolved for you, and thanks for posting the solution above. I am closing this ticket for now, and please let us know if you have any further questions that we can help you with.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-23T13:37:02.565Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Forcing Pre-emption in a sweep",
		"Question_link": "https://community.wandb.ai/t/forcing-pre-emption-in-a-sweep/3391",
		"Question_created_time": "2022-11-08T17:39:54.104Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 394,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>This is a bit of a weird one\u2026<br>\nMy lab has a cluster that usually runs using slurm, but slurm is down (and may be not up for a while). We would like to still use wandb and still maintain the priority levels that slurm gives (i.e. we want to make sure if there is some critical jobs that need to get run, we can easily pre-empt existing jobs that are running in sweeps and still get them to requeue later when the critical jobs are over (essentially we are trying to do manual pre-emption)</p>\n<p>I have been trying to set this up with a dummy sweep that just sends a single \u201cmagic number\u201d to each run, however no matter what I do I cannot seem to get the run to be pre-empted. If I try killing via <code>ctrl+C</code>, the wandb process shuts down normally and it marks the run as finished. Is there any way I can get around this to force the pre-emption? Thank you so much for your help!</p>\n<pre><code class=\"lang-auto\">import wandb\nimport time\nfrom random import randint\nimport os\nimport sys\nfrom tqdm.auto import tqdm\nwandb.init()\nmagic_number = wandb.config.magic_number\ntry:\n    print(f'Hello, world! Magic number is {magic_number}')\n    print('My PID is', os.getpid())\n    size = 1_000_000_000\n    for count in tqdm(range(size)):\n        if count % (size // 10) == 0:\n            print(f'On count {count}')\nexcept (Exception, KeyboardInterrupt, SystemExit) as e:\n    print('Keyboard interrupt!')\n    # I cannot reach this piece of code no matter when I do\n    # I have tried ctrl+c, killing the process corresponding to this python script, killing the wandb agent process\n    wandb.mark_preempting()\n    print('Preempted!')\n    sys.exit(999)\nprint('Done!')\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-11T01:16:46.971Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/evanv\">@evanv</a> , happy to help. As a point of clarification, are you wanting t to pre-empt a run called by a sweep?</p>\n<p>I\u2019m not quite sure what could be happening on your end. I ran your exact same code, made a minor tweak by passing  a config that includes a \u2018magic_number\u2019 to <code>wandb.init(). I successfully ran the code example, manually killed the run via </code>ctrl+c` and was able to place the run in a preempted state.</p>\n<pre><code class=\"lang-auto\">  config = {\"magic_number\":10}\n  wandb.init(config=config)\n  magic_number = wandb.config.magic_number\n  try:\n      print(f'Hello, world! Magic number is {magic_number}')\n      print('My PID is', os.getpid())\n      size = 1_000_000_000\n      for count in tqdm(range(size)):\n          if count % (size // 10) == 0:\n              print(f'On count {count}')\n  except (Exception, KeyboardInterrupt, SystemExit) as e:\n      #I was successful in triggering this except block with ctrl+c\n      print('Keyboard interrupt!')\n      wandb.mark_preempting()\n      print('Preempted!')\n      sys.exit(999)\n  print('Done!')\n</code></pre>\n<p>The produced ran can be viewed <a href=\"https://wandb.ai/mohammadbakir/uncategorized/runs/1nvrqaqq/overview?workspace=user-mohammadbakir\">here</a>. Could you provide me a link to your workspace where the runs are showing up as finished.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-12T02:22:57.742Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> ,</p>\n<p>Yes, I am trying to pre-empt a run which is called by a sweep. I may indeed have had some kind of strange issue on my end because your code also works for me. However one thing I noticed is that the runs which are pre-empted seem not to be immediately re-qued by a sweep. Interestingly it looks like you were able to use the <code>wand.mark_preempting</code> without a sweep in progress. Are you able to give a bit more insight into how this command works and what its implications are for the run queue? The <a href=\"https://docs.wandb.ai/guides/track/advanced/resuming#preemptible-sweeps\">documentation</a> seems to say they should be immediately re-queued, but I have not observed that to be the case. Is there any way I can check the queue to see what is happening?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-18T00:17:37.539Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/evanv\">@evanv</a> <code>wandb.mark_preempting()</code> will mark a run <code>preempting</code>, but the run is not requeued until the status is <code>preempted</code>. The status change <code>preempting</code> \u2192 <code>preempted</code> happens when the run exits with non zero status (maybe your signal handler is preventing this) or after the run spends 5 minutes in the preempting state and our backend receives no heartbeats from the run. If the run exits successfully (with zero status) after being put into the preempting state, we assume the run finished successfully before being preempted by the server and the run state is set to finished. In this case the run <strong>will not be requeued</strong>.</p>\n<p>There are likely two ways to have control over your exist status and force this <code>preempting</code> \u2192 <code>preempted</code></p>\n<ol>\n<li>call <code>wandb.finish(exit_code=1)</code> after you mark the run as prempting</li>\n<li>Make your process exit with a non-zero status, <code>exit(1)</code>\n</li>\n</ol>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-23T19:06:51.423Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/evanv\">@evanv</a>  since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-22T19:07:30.766Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "extraKeys don't show up in historyTable",
		"Question_link": "https://community.wandb.ai/t/extrakeys-dont-show-up-in-historytable/3416",
		"Question_created_time": "2022-11-14T15:29:54.076Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 557,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey everyone,</p>\n<p>I\u2019m trying to visualize some ROC curves for different epochs, and what I would like to do is add a slider with the epoch number to see how it evolves. I found this <a href=\"https://wandb.ai/stacey/presets/reports/PR-Curve-Slider-Example--Vmlldzo2NjE5ODk\">example</a>, but I am having an issue with the <code>extraKeys</code> parameter. No option shows up when I click on it\u2026 (I would like to use the <code>t_epoch</code> field that I correctly log (cf screenshots). Am I doing something wrong?</p>\n<p>Many thanks for considering my request.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/f/fcc44be61b70a4aae43f6fea3fa466fe0beaa409.png\" data-download-href=\"/uploads/short-url/A44SV67K2WiCfegtX5Wv8Yt9khj.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/f/fcc44be61b70a4aae43f6fea3fa466fe0beaa409_2_690x279.png\" alt=\"image\" data-base62-sha1=\"A44SV67K2WiCfegtX5Wv8Yt9khj\" width=\"690\" height=\"279\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/f/fcc44be61b70a4aae43f6fea3fa466fe0beaa409_2_690x279.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/f/fcc44be61b70a4aae43f6fea3fa466fe0beaa409_2_1035x418.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/f/fcc44be61b70a4aae43f6fea3fa466fe0beaa409_2_1380x558.png 2x\" data-dominant-color=\"F0F1F2\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1412\u00d7572 65.3 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-22T07:26:55.347Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/odietrich\">@odietrich</a>!</p>\n<p>Could you share a link to where you are trying to create this custom chart so that we can look into this?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-26T10:09:44.668Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/odietrich\">@odietrich</a>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-28T17:13:15.049Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/odietrich\">@odietrich</a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-21T07:27:09.339Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "ERROR Abnormal program exit",
		"Question_link": "https://community.wandb.ai/t/error-abnormal-program-exit/3448",
		"Question_created_time": "2022-11-22T04:32:51.015Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 951,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am using wandb version 0.13.5 on python 3.6.9 (Linux kernel version: 4.14.281-212.502.amzn2.x86_64). I have a problem running <code>wandb.init()</code> with the following error.</p>\n<blockquote>\n<p>Traceback (most recent call last):<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_init.py\u201d, line 1075, in init<br>\nwi.setup(kwargs)<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_init.py\u201d, line 165, in setup<br>\nself._wl = wandb_setup.setup()<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_setup.py\u201d, line 312, in setup<br>\nret = _setup(settings=settings)<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_setup.py\u201d, line 307, in _setup<br>\nwl = _WandbSetup(settings=settings)<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_setup.py\u201d, line 293, in <strong>init</strong><br>\n_WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_setup.py\u201d, line 106, in <strong>init</strong><br>\nself._setup()<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_setup.py\u201d, line 234, in _setup<br>\nself._setup_manager()<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_setup.py\u201d, line 266, in _setup_manager<br>\n_use_grpc=use_grpc, settings=self._settings<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_manager.py\u201d, line 108, in <strong>init</strong><br>\nself._service.start()<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/service/service.py\u201d, line 112, in start<br>\nself._launch_server()<br>\nFile \u201c/usr/local/lib/python3.6/dist-packages/wandb/sdk/service/service.py\u201d, line 108, in _launch_server<br>\nassert ports_found<br>\nAssertionError<br>\nwandb: ERROR Abnormal program exit<br>\nproc exited with 1</p>\n</blockquote>\n<blockquote>\n<hr>\n<p>AssertionError                            Traceback (most recent call last)<br>\n/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_init.py in init(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)<br>\n1074         wi = _WandbInit()<br>\n \u2192 1075         wi.setup(kwargs)<br>\n1076         except_exit = wi.settings._except_exit</p>\n<p>/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_init.py in setup(self, kwargs)<br>\n164<br>\n \u2192 165         self._wl = wandb_setup.setup()<br>\n166         # Make sure we have a logger setup (might be an early logger)</p>\n<p>/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_setup.py in setup(settings)<br>\n311 def setup(settings=None) \u2192 Optional[\u201c_WandbSetup\u201d]:<br>\n \u2192 312     ret = _setup(settings=settings)<br>\n313     return ret</p>\n<p>/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_setup.py in _setup(settings, _reset)<br>\n306         return<br>\n \u2192 307     wl = _WandbSetup(settings=settings)<br>\n308     return wl</p>\n<p>/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_setup.py in <strong>init</strong>(self, settings)<br>\n292             return<br>\n \u2192 293         _WandbSetup._instance = _WandbSetup__WandbSetup(settings=settings, pid=pid)<br>\n294</p>\n<p>/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_setup.py in <strong>init</strong>(self, pid, settings, environ)<br>\n105         self._check()<br>\n \u2192 106         self._setup()<br>\n107</p>\n<p>/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_setup.py in _setup(self)<br>\n233     def _setup(self):<br>\n \u2192 234         self._setup_manager()<br>\n235</p>\n<p>/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_setup.py in _setup_manager(self)<br>\n265         self._manager = wandb_manager._Manager(<br>\n \u2192 266             _use_grpc=use_grpc, settings=self._settings<br>\n267         )</p>\n<p>/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_manager.py in <strong>init</strong>(self, settings, _use_grpc)<br>\n107         if not token:<br>\n \u2192 108             self._service.start()<br>\n109             host = \u201clocalhost\u201d</p>\n<p>/usr/local/lib/python3.6/dist-packages/wandb/sdk/service/service.py in start(self)<br>\n111     def start(self) \u2192 None:<br>\n \u2192 112         self._launch_server()<br>\n113</p>\n<p>/usr/local/lib/python3.6/dist-packages/wandb/sdk/service/service.py in _launch_server(self)<br>\n107             ports_found = self._wait_for_ports(fname, proc=internal_proc)<br>\n \u2192 108             assert ports_found<br>\n109             self._internal_proc = internal_proc</p>\n<p>AssertionError:</p>\n<p>The above exception was the direct cause of the following exception:</p>\n<p>Exception                                 Traceback (most recent call last)<br>\n in <br>\n1 import wandb<br>\n----&gt; 2 wandb.init()</p>\n<p>/usr/local/lib/python3.6/dist-packages/wandb/sdk/wandb_init.py in init(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)<br>\n1114             if except_exit:<br>\n1115                 os._exit(-1)<br>\n \u2192 1116             raise Exception(\u201cproblem\u201d) from error_seen<br>\n1117     return run</p>\n<p>Exception: problem</p>\n</blockquote>\n<p>I tried downgrading the wandb version to 0.9.7 but the problem still the same. Could you please help me solve this error?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-24T18:03:29.592Z",
				"Answer_body": "<p>Hi Raveerat,</p>\n<p>Thanks for writing in and sorry that you are experiencing this! Could you try running <code>wandb login --relogin</code> and introducing you API key? Also, is this happening in colab and Jupiter notebook too?</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-29T09:05:07.995Z",
				"Answer_body": "<p>Hi Raveerat,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-21T04:33:16.803Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Select the metrics according to different step thresholds in the Runs Table",
		"Question_link": "https://community.wandb.ai/t/select-the-metrics-according-to-different-step-thresholds-in-the-runs-table/3403",
		"Question_created_time": "2022-11-10T08:26:29.469Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 88,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Take the following as an example. We train a model with different configurations  for 1000 steps. Then, the Runs Table only shows the final values of the logged metrics. In some cases, we might want to compare different runs within 500 steps. Can we add support for this functionality?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-14T21:56:18.409Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lanlin\">@lanlin</a> thank you for your question! This is indeed not feasible today, and I can make a feature request if you\u2019d like. You could get the intermediate values for all Runs using <code>Weave</code> in your Workspace instead. An alternative option would be to download the metrics you\u2019re interested at and log a <a href=\"https://docs.wandb.ai/guides/track/public-api-guide#update-metrics-for-a-run-after-the-run-has-finished\">new column using the API</a> for the specific step, then you could display this in the Runs Table section. Would any of these work for you? Let me know if you would like some example of these workarounds.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-15T02:13:10.866Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a> thanks for your reply. For now, I use the API to upload a new column to the Table. But it would be better to allow some operations directly in the web UI.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-21T22:02:49.855Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lanlin\">@lanlin</a> just an update on this, I have created a feature request for the engineering team as this would be indeed a very useful addition. Thanks for this suggestion, we will reach out to you here if there are any updates on this.</p>\n<p>In the meantime, another alternative would be to query these results from a Weave panel that you can add in your project\u2019s Workspace and provide an expression such as:<br>\n<code>runs.history.concat.filter((row) =&gt; row[\"epochs\"]==500)</code><br>\nI hope this helps, please let me know if you have any further questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-20T22:03:15.380Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "More on Bayes method",
		"Question_link": "https://community.wandb.ai/t/more-on-bayes-method/3355",
		"Question_created_time": "2022-11-01T10:36:20.752Z",
		"Question_answer_count": 5,
		"Question_score_count": 2,
		"Question_view_count": 174,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>is there a more detailed explanation on the use of bayes in hyperparameter search? For example, if it uses GP regression, what are the default kernel and parameters, and how to change them, etc.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-02T21:34:52.271Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/zyzhang\">@zyzhang</a> , could you expand on your question regarding Bayes. Are asking to have more hands on modification of our <a href=\"https://github.com/wandb/sweeps/blob/master/src/sweeps/bayes_search.py\" rel=\"noopener nofollow ugc\">implementation</a>? Unfortunately we don\u2019t support deeper control options at this time, but I am curious about your use case here.</p>\n<p>Please visit <a href=\"https://wandb.ai/site/articles/bayesian-hyperparameter-optimization-a-primer\">this detailed article</a> on the specifics of how Bayesian optimization works.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-06T09:55:49.960Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> I see. I was hoping to see at least something like, if GP is used, even if I can\u2019t change the kernel, I should be able to tell what kernel, scale length (and other parameters) are used, so the whole thing is not just a blackbox to me.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-08T02:12:27.793Z",
				"Answer_body": "<p>Thank you for the feedback <a class=\"mention\" href=\"/u/zyzhang\">@zyzhang</a>. We are working on expanding our sweeps features functionality. I will keep note of your comments and add them to our DB. Once there has been movement on this feature, I will update you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-20T18:04:48.824Z",
				"Answer_body": "<p>Sorry one more clarification. the \u2018bayes\u2019 search method apparently supports discrete search as well. May I know how is it done since by default GP shouldn\u2019t be able to do discrete search?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-19T18:05:16.590Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Unable to log each run when using pytorch lightning integration",
		"Question_link": "https://community.wandb.ai/t/unable-to-log-each-run-when-using-pytorch-lightning-integration/3443",
		"Question_created_time": "2022-11-18T22:42:35.261Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 415,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m able to log a training run with pytorch lightning + wandb based on <a href=\"https://docs.wandb.ai/guides/integrations/lightning\">these instructions</a> in google colab.  Here\u2019s a snippet of code I\u2019m running:</p>\n<pre><code class=\"lang-auto\">wandb_logger = WandbLogger(project=\"p\", entity=\"e\")\ntrainer = pl.Trainer(\n    logger=wandb_logger,    # W&amp;B integration\n    ..\n)\ntrainer.fit(model)\n</code></pre>\n<p>it outputs the link to the run and I can see all of the stats etc.</p>\n<p>However, how can I retrain?  If I try re-training with:</p>\n<pre><code class=\"lang-auto\">trainer = pl.Trainer(\n    logger=wandb_logger,    # W&amp;B integration\n    ..\n)\ntrainer.fit(model)\n</code></pre>\n<p>It doesn\u2019t seem to log a new run.  It looks like it doesn\u2019t even log the data to the existing run, it is just completely lost.</p>\n<p>If I try to create a new wandb logger before the re-training:</p>\n<pre><code class=\"lang-auto\">wandb_logger = WandbLogger(project=\"p\", entity=\"e\")\ntrainer = pl.Trainer(\n    logger=wandb_logger,    # W&amp;B integration\n    ..\n)\ntrainer.fit(model)\n</code></pre>\n<p>it times out after 1 minute with this error:</p>\n<pre><code class=\"lang-auto\">andb: ERROR Error communicating with wandb process\nwandb: ERROR For more info see: https://docs.wandb.ai/library/init#init-start-error\nProblem at: /usr/local/lib/python3.7/dist-packages/pytorch_lightning/loggers/wandb.py 406 experiment\n---------------------------------------------------------------------------\nUsageError                                Traceback (most recent call last)\n&lt;ipython-input-44-6016437e3426&gt; in &lt;module&gt;\n----&gt; 1 wandb_logger = WandbLogger(project=\"p\", entity=\"e\")\n\n6 frames\n/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py in init(self)\n    717                     backend.cleanup()\n    718                     self.teardown()\n--&gt; 719                 raise UsageError(error_message)\n    720             assert run_result and run_result.run\n    721             if run_result.run.resumed:\n\nUsageError: Error communicating with wandb process\nFor more info see: https://docs.wandb.ai/library/init#init-start-error```\n\nAm I using wandb + pytorch lightning the correct way?  What is the expected lifecycle of the wandb logger in relation to the pl training object?</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-19T00:32:56.410Z",
				"Answer_body": "<p>Actually nevermind, it\u2019s working now!  I don\u2019t know what I changed that fixed it while I was trying to debug, maybe I had forgotten to call .finish() on the first run.</p>\n<p>Here\u2019s the gist of the code I\u2019m running:</p>\n<pre><code class=\"lang-auto\">wandb_logger = WandbLogger(project=\"p\", entity=\"e\", log_model=True)\ntrainer = pl.Trainer(\n    logger=wandb_logger,    # W&amp;B integration\n    ..\n)\ntrainer.fit(model)\nwandb.finish()\n</code></pre>\n<p>I\u2019m able to run the above snippet repeatedly and it creates a new run each time.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-18T00:33:02.616Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to set the environment variable WANDB_IGNORE_GLOBS correctly?",
		"Question_link": "https://community.wandb.ai/t/how-to-set-the-environment-variable-wandb-ignore-globs-correctly/3423",
		"Question_created_time": "2022-11-16T07:04:43.551Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 135,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>The usage in the <a href=\"https://docs.wandb.ai/guides/track/advanced/environment-variables#optional-environment-variables\">Docs</a> is:</p>\n<blockquote>\n<p>Set this to a comma separated list of file globs to ignore. These files will not be synced to the cloud</p>\n</blockquote>\n<p>So, is the below code correct?</p>\n<pre><code class=\"lang-python\">os.environ['WANDB_IGNORE_GLOBS'] = '[*.pth, *.npy]'\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-17T13:08:01.706Z",
				"Answer_body": "<p>The code seems to be incorrect because the *.npy files still be uploaded (the *.pth files are ignored successfully).</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-17T15:17:40.971Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/geyao\">@geyao</a> thank you for writing in! Could you please check if the following would work for you?</p>\n<pre><code class=\"lang-auto\">os.environ['WANDB_IGNORE_GLOBS'] = '*.pth,*.npy'\n</code></pre>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-11-18T03:13:06.203Z",
				"Answer_body": "<p>Thanks for your reply, it works! I also find that it fails if there are spaces after the comma separator.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-18T15:51:35.267Z",
				"Answer_body": "<p>Great to hear <a class=\"mention\" href=\"/u/geyao\">@geyao</a> this now works - and thanks for adding the additional information, indeed I confirmed it won\u2019t work with spaces in between. Have a great weekend!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-17T15:51:37.426Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Manually ask sweep agents to start new run",
		"Question_link": "https://community.wandb.ai/t/manually-ask-sweep-agents-to-start-new-run/3441",
		"Question_created_time": "2022-11-18T14:53:29.156Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 241,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Sorry, it may be easy question or I was unable to find the answer \u2013 how do I manually ask one (or more) agents of a running sweep to stop the current run and move to a new one ?</p>\n<p>I am running a sweep with 48 possible configurations with 10 agents. I noticed (from sweep dashboard) some of configurations are poor from the very beginning. So I would like to terminate them and explore the unexplored configurations. The poor ones are just wasting my resources. I don\u2019t want to terminate all since some of them are doing quite good,</p>\n<p>How do we do this is wandb ?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-18T16:02:06.813Z",
				"Answer_body": "<p>Hi Ayan,</p>\n<p>Thanks for writing in! I think that early termination would be helpful for you. Also here is some more information. Let me know if this is useful.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-23T10:23:59.021Z",
				"Answer_body": "<p>Hi Ayan,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-17T14:54:27.528Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "(Windows 11) `wandb.sweep()` gives ConnectionResetError: [WinError 10054]",
		"Question_link": "https://community.wandb.ai/t/windows-11-wandb-sweep-gives-connectionreseterror-winerror-10054/3217",
		"Question_created_time": "2022-10-04T20:26:49.749Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 549,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello, sort of new to wandb. I\u2019m trying sweeps for the first time - I had no problem creating and running a sweep from the web UI, then copy-pasting the command to start an agent from bash. However, starting it using <code>wandb.agent()</code> keeps giving me problems. It starts training, but I keep running into two problems:</p>\n<ol>\n<li>I keep getting the error below each time a new run starts - it seems to be originating from another thread created by wandb, so I\u2019m not sure what to do about it. Also, the runs get logged in the sweep page, but none of them have the data I\u2019ve logged (and each run has the \u201cactive\u201d dot even once the script ends).</li>\n<li>I can\u2019t figure out what wandb calls to make, and in what order, to get the agent to populate its randomized values into <code>wandb.config</code>. I would like to set some default config values (which are not specified by my <code>sweep_config</code> dict), but have the sweep agent update <code>wandb.config</code> with the randomized values created from the <code>sweep_config</code> dict (it seems like this is what happens when I run from bash). In the traceback below, you can see I print <code>wandb.config</code> right before the model is trained, and it simply uses the <code>config</code> dict I specified when calling <code>wandb.init</code> (it is not updated/overwritten by the agent).</li>\n</ol>\n<p>Below is the full traceback. Thanks in advance for any ideas.</p>\n<pre><code class=\"lang-auto\">C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\python.exe C:\\Users\\jacks\\ml-project\\training_script.py \nUsing device: cuda\nwandb: Currently logged in as: jacksth22. Use `wandb login --relogin` to force relogin\nwandb: Tracking run with wandb version 0.13.3\nwandb: Run data is saved locally in C:\\Users\\jacks\\ml-project\\wandb\\run-20221004_162225-1aj4c6jt\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run restful-dew-107\nwandb:  View project at https://wandb.ai/jacksth22/&lt;project&gt;\nwandb:  View run at https://wandb.ai/jacksth22/&lt;project&gt;/runs/1aj4c6jt\nLoading data...done (elapsed=1.49s).\nConverting data to tensors: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 500/500 [00:03&lt;00:00, 164.20it/s]\ndone (elapsed=3.05s).\nCreate sweep with ID: plq6uobc\nSweep URL: https://wandb.ai/jacksth22/uncategorized/sweeps/plq6uobc\n=== Starting sweep agent ===\nwandb: WARNING Calling wandb.login() after wandb.init() has no effect.\nwandb: Waiting for W&amp;B process to finish... (success).\nwandb:                                                                                \nwandb: Synced restful-dew-107: https://wandb.ai/jacksth22/&lt;project&gt;/runs/1aj4c6jt\nwandb: Synced 6 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nwandb: Find logs at: .\\wandb\\run-20221004_162225-1aj4c6jt\\logs\nwandb: Agent Starting Run: 1bqu30r5 with config:\nwandb: \tbatch_size: 16\nwandb: \tdense_depth: 2\nwandb: \tdense_width: 64\nwandb: \tdepth: 6\nwandb: \tdropout: 0.25778082906860794\nwandb: \tepochs: 15\nwandb: \tgradient_clipping: 1\nwandb: \theads: 4\nwandb: \tlr: 0.0008418633888555167\nwandb: \tlr_warmup: 1960\nwandb: \tmax_seq_len: 64\nwandb: \toptimizer: AdamW\nwandb: \tuse_max_pool: False\nModel created with 90,714 parameters.\ntest: wandb.config: {'epochs': 3, 'batch_size': 16, 'test_size': 0.3, 'lr': 5, 'lr_warmup': 10000, 'optimizer': 'SGD', 'use_max_pool': True, 'embedding_dimension': 24, 'max_sequence_length': 512, 'heads': 8, 'depth': 10, 'rng_seed': 1, 'gradient_clipping': 1.0, 'dense_width': 64, 'dense_depth': 3, 'dropout': 0.2, 'log_dir': 'ml/logs/2022-10-04_16-22-22', 'using_small_dataset': True}\nTraining epoch 1/3:   0%|          | 0/22 [00:00&lt;?, ?it/s]Exception in thread ChkStopThr:\nTraceback (most recent call last):\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\threading.py\", line 980, in _bootstrap_inner\n    self.run()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\threading.py\", line 917, in run\n    self._target(*self._args, **self._kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 190, in check_status\n    status_response = self._interface.communicate_stop_status()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py\", line 128, in communicate_stop_status\n    resp = self._communicate_stop_status(status)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 69, in _communicate_stop_status\n    data = super()._communicate_stop_status(status)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 399, in _communicate_stop_status\n    resp = self._communicate(req, local=True)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 230, in _communicate\n    return self._communicate_async(rec, local=local).get(timeout=timeout)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 58, in _communicate_async\n    future = self._router.send_and_receive(rec, local=local)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\router.py\", line 94, in send_and_receive\n    self._send_message(rec)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\router_sock.py\", line 35, in _send_message\n    self._sock_client.send_record_communicate(record)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 216, in send_record_communicate\n    self.send_server_request(server_req)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\nException in thread NetStatThr:\nTraceback (most recent call last):\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\threading.py\", line 980, in _bootstrap_inner\n    self.run()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\threading.py\", line 917, in run\n    self._target(*self._args, **self._kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 172, in check_network_status\n    status_response = self._interface.communicate_network_status()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py\", line 139, in communicate_network_status\n    resp = self._communicate_network_status(status)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 82, in _communicate_network_status\n    data = super()._communicate_network_status(status)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 409, in _communicate_network_status\n    resp = self._communicate(req, local=True)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 230, in _communicate\n    return self._communicate_async(rec, local=local).get(timeout=timeout)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 58, in _communicate_async\n    future = self._router.send_and_receive(rec, local=local)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\router.py\", line 94, in send_and_receive\n    self._send_message(rec)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\router_sock.py\", line 35, in _send_message\n    self._sock_client.send_record_communicate(record)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 216, in send_record_communicate\n    self.send_server_request(server_req)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\nTraining epoch 1/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22/22 [00:06&lt;00:00,  3.32it/s]\nTesting epoch 1/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 20.42it/s]\nTraining epoch 2/3:   0%|          | 0/22 [00:00&lt;?, ?it/s]Train: acc =    9.43% | loss = 260.72%\nTest:  acc =   16.67% | loss = 225.52%\nTraining epoch 2/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22/22 [00:03&lt;00:00,  5.70it/s]\nTesting epoch 2/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 21.73it/s]\nTraining epoch 3/3:   0%|          | 0/22 [00:00&lt;?, ?it/s]Train: acc =   11.60% | loss = 221.38%\nTest:  acc =   13.33% | loss = 218.46%\nTraining epoch 3/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22/22 [00:03&lt;00:00,  5.84it/s]\nTesting epoch 3/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 21.05it/s]\nTrain: acc =   12.40% | loss = 218.99%\nTest:  acc =   13.33% | loss = 235.97%\nException in thread Thread-14:\nTraceback (most recent call last):\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 299, in _run_job\n    wandb.finish()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 3565, in finish\n    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 282, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 245, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1713, in finish\n    return self._finish(exit_code, quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1719, in _finish\n    tel.feature.finish = True\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\telemetry.py\", line 40, in __exit__\n    self._run._telemetry_callback(self._obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 593, in _telemetry_callback\n    self._telemetry_flush()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 604, in _telemetry_flush\n    self._backend.interface._publish_telemetry(self._telemetry_obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 78, in _publish_telemetry\n    self._publish(rec)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n    self.send_server_request(server_req)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\threading.py\", line 980, in _bootstrap_inner\n    self.run()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\threading.py\", line 917, in run\n    self._target(*self._args, **self._kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 303, in _run_job\n    wandb.finish(exit_code=1)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 3565, in finish\n    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 282, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 245, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1713, in finish\n    return self._finish(exit_code, quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1719, in _finish\n    tel.feature.finish = True\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\telemetry.py\", line 40, in __exit__\n    self._run._telemetry_callback(self._obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 593, in _telemetry_callback\n    self._telemetry_flush()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 604, in _telemetry_flush\n    self._backend.interface._publish_telemetry(self._telemetry_obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 78, in _publish_telemetry\n    self._publish(rec)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n    self.send_server_request(server_req)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\nwandb: Agent Starting Run: ly4ox06s with config:\nwandb: \tbatch_size: 16\nwandb: \tdense_depth: 4\nwandb: \tdense_width: 128\nwandb: \tdepth: 10\nwandb: \tdropout: 0.3449039365016265\nwandb: \tepochs: 15\nwandb: \tgradient_clipping: 1\nwandb: \theads: 6\nwandb: \tlr: 0.0007649760799562746\nwandb: \tlr_warmup: 1057\nwandb: \tmax_seq_len: 64\nwandb: \toptimizer: AdamW\nwandb: \tuse_max_pool: False\nModel created with 90,714 parameters.\ntest: wandb.config: {'epochs': 3, 'batch_size': 16, 'test_size': 0.3, 'lr': 5, 'lr_warmup': 10000, 'optimizer': 'SGD', 'use_max_pool': True, 'embedding_dimension': 24, 'max_sequence_length': 512, 'heads': 8, 'depth': 10, 'rng_seed': 1, 'gradient_clipping': 1.0, 'dense_width': 64, 'dense_depth': 3, 'dropout': 0.2, 'log_dir': 'ml/logs/2022-10-04_16-22-22', 'using_small_dataset': True}\nTraining epoch 1/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22/22 [00:03&lt;00:00,  5.86it/s]\nTesting epoch 1/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 21.62it/s]\nTrain: acc =   10.57% | loss = 247.77%\nTest:  acc =   10.00% | loss = 227.83%\nTraining epoch 2/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22/22 [00:03&lt;00:00,  5.84it/s]\nTesting epoch 2/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 21.09it/s]\nTraining epoch 3/3:   0%|          | 0/22 [00:00&lt;?, ?it/s]Train: acc =   10.60% | loss = 236.37%\nTest:  acc =   10.00% | loss = 231.93%\nTraining epoch 3/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22/22 [00:03&lt;00:00,  5.83it/s]\nTesting epoch 3/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 21.15it/s]\nException in thread Thread-15:\nTraceback (most recent call last):\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 299, in _run_job\n    wandb.finish()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 3565, in finish\nTrain: acc =   10.40% | loss = 233.15%\nTest:  acc =   13.33% | loss = 230.50%\n    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 282, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 245, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1713, in finish\n    return self._finish(exit_code, quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1719, in _finish\n    tel.feature.finish = True\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\telemetry.py\", line 40, in __exit__\n    self._run._telemetry_callback(self._obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 593, in _telemetry_callback\n    self._telemetry_flush()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 604, in _telemetry_flush\n    self._backend.interface._publish_telemetry(self._telemetry_obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 78, in _publish_telemetry\n    self._publish(rec)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n    self.send_server_request(server_req)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\threading.py\", line 980, in _bootstrap_inner\n    self.run()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\threading.py\", line 917, in run\n    self._target(*self._args, **self._kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 303, in _run_job\n    wandb.finish(exit_code=1)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 3565, in finish\n    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 282, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 245, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1713, in finish\n    return self._finish(exit_code, quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1719, in _finish\n    tel.feature.finish = True\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\telemetry.py\", line 40, in __exit__\n    self._run._telemetry_callback(self._obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 593, in _telemetry_callback\n    self._telemetry_flush()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 604, in _telemetry_flush\n    self._backend.interface._publish_telemetry(self._telemetry_obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 78, in _publish_telemetry\n    self._publish(rec)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n    self.send_server_request(server_req)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\nwandb: Agent Starting Run: viajyjrk with config:\nwandb: \tbatch_size: 16\nwandb: \tdense_depth: 4\nwandb: \tdense_width: 128\nwandb: \tdepth: 8\nwandb: \tdropout: 0.06200113164824134\nwandb: \tepochs: 15\nwandb: \tgradient_clipping: 1\nwandb: \theads: 6\nwandb: \tlr: 0.0006929869499125819\nwandb: \tlr_warmup: 2917\nwandb: \tmax_seq_len: 512\nwandb: \toptimizer: SGD\nwandb: \tuse_max_pool: False\nTraining epoch 1/3:   0%|          | 0/22 [00:00&lt;?, ?it/s]Model created with 90,714 parameters.\ntest: wandb.config: {'epochs': 3, 'batch_size': 16, 'test_size': 0.3, 'lr': 5, 'lr_warmup': 10000, 'optimizer': 'SGD', 'use_max_pool': True, 'embedding_dimension': 24, 'max_sequence_length': 512, 'heads': 8, 'depth': 10, 'rng_seed': 1, 'gradient_clipping': 1.0, 'dense_width': 64, 'dense_depth': 3, 'dropout': 0.2, 'log_dir': 'ml/logs/2022-10-04_16-22-22', 'using_small_dataset': True}\nTraining epoch 1/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22/22 [00:03&lt;00:00,  5.65it/s]\nTesting epoch 1/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 21.07it/s]\nTrain: acc =    9.43% | loss = 262.65%\nTest:  acc =   10.00% | loss = 221.72%\nTraining epoch 2/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22/22 [00:03&lt;00:00,  5.86it/s]\nTesting epoch 2/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 21.02it/s]\nTrain: acc =   11.60% | loss = 236.80%\nTest:  acc =   10.00% | loss = 234.05%\nTraining epoch 3/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 22/22 [00:03&lt;00:00,  5.81it/s]\nTesting epoch 3/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00&lt;00:00, 20.80it/s]\nException in thread Thread-16:\nTraceback (most recent call last):\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 299, in _run_job\n    wandb.finish()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 3565, in finish\n    wandb.run.finish(exit_code=exit_code, quiet=quiet)\nTrain: acc =   11.00% | loss = 226.62%\nTest:  acc =    9.33% | loss = 221.71%\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 282, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 245, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1713, in finish\n    return self._finish(exit_code, quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1719, in _finish\n    tel.feature.finish = True\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\telemetry.py\", line 40, in __exit__\n    self._run._telemetry_callback(self._obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 593, in _telemetry_callback\n    self._telemetry_flush()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 604, in _telemetry_flush\n    self._backend.interface._publish_telemetry(self._telemetry_obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 78, in _publish_telemetry\n    self._publish(rec)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n    self.send_server_request(server_req)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\threading.py\", line 980, in _bootstrap_inner\n    self.run()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\threading.py\", line 917, in run\n    self._target(*self._args, **self._kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 303, in _run_job\n    wandb.finish(exit_code=1)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 3565, in finish\n    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 282, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 245, in wrapper\n    return func(self, *args, **kwargs)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1713, in finish\n    return self._finish(exit_code, quiet)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1719, in _finish\n    tel.feature.finish = True\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\telemetry.py\", line 40, in __exit__\n    self._run._telemetry_callback(self._obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 593, in _telemetry_callback\n    self._telemetry_flush()\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 604, in _telemetry_flush\n    self._backend.interface._publish_telemetry(self._telemetry_obj)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 78, in _publish_telemetry\n    self._publish(rec)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n    self.send_server_request(server_req)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"C:\\Users\\jacks\\anaconda3\\envs\\ml-project\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n\nProcess finished with exit code 0\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-06T22:39:41.846Z",
				"Answer_body": "<p>Hi Jackson, this might also be a proxy configuration issue if you are trying this from inside a fire-walled corporate network or are you connected to a VPN?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-12T12:35:51.902Z",
				"Answer_body": "<p>This also happened to me now and I do not have VPN/firewall. It happened when I changed the project name, used wandb.init(project_name = \u201cnew_project_name\u201d) and since then every time I want to run wandb() I get the same error like above.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-12T16:03:00.848Z",
				"Answer_body": "<p>I see, can you give me the debug logs that are found in your wandb run directory when this occurs?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-17T19:08:23.678Z",
				"Answer_body": "<p>Hi Jackson, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-18T11:34:50.418Z",
				"Answer_body": "<p>I\u2019m receiving the same error repeatedly when I start a sweep.</p>\n<p>The log files: <a href=\"https://mega.nz/file/kfFH2Q7Y#I35dATozdctEoH_J4-DuLvCWSWVH1Tzy_iph6F5WW68\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">4.1 KB file on MEGA</a></p>\n<pre><code class=\"lang-auto\">Create sweep with ID: qs048o8w\nSweep URL: https://wandb.ai/maxw/lit-mnist/sweeps/qs048o8w\nwandb: WARNING Calling wandb.login() after wandb.init() has no effect.\nwandb: Waiting for W&amp;B process to finish... (success).\nwandb: Synced solar-yogurt-63: https://wandb.ai/maxw/lit-mnist/runs/vla9pdno\nwandb: Synced 6 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nwandb: Find logs at: .\\wandb\\run-20221118_121240-vla9pdno\\logs\nwandb: Agent Starting Run: 618an4iq with config:\nwandb: \tbatch_size: 16\nwandb: \tdropout: 0.5\nwandb: \tepochs: 5\nwandb: \tlr: 0.06530954613403434\nC:\\Users\\perry\\miniconda3\\envs\\PaperReplicas\\lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n  rank_zero_warn(\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n\n  | Name | Type       | Params\n------------------------------------\n0 | net  | Sequential | 1.4 M \n------------------------------------\n1.4 M     Trainable params\n0         Non-trainable params\n1.4 M     Total params\n5.518     Total estimated model params size (MB)\nSanity Checking: 0it [00:00, ?it/s]C:\\Users\\perry\\miniconda3\\envs\\PaperReplicas\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n  rank_zero_warn(\nSanity Checking DataLoader 0:   0%|          | 0/2 [00:00&lt;?, ?it/s]Exception in thread ChkStopThr:\nTraceback (most recent call last):\n  File \"C:\\Users\\perry\\miniconda3\\envs\\PaperReplicas\\lib\\threading.py\", line 980, in _bootstrap_inner\n    self.run()\n  File \"C:\\Users\\perry\\miniconda3\\envs\\PaperReplicas\\lib\\threading.py\", line 917, in run\n    self._target(*self._args, **self._kwargs)\n  File \"C:\\Users\\perry\\miniconda3\\envs\\PaperReplicas\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 200, in check_status\n    status_response = self._interface.communicate_stop_status()\n  File \"C:\\Users\\perry\\miniconda3\\envs\\PaperReplicas\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py\", line 128, in communicate_stop_status\n    resp = self._communicate_stop_status(status)\n  File \"C:\\Users\\perry\\miniconda3\\envs\\PaperReplicas\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 69, in _communicate_stop_status\n    data = super()._communicate_stop_status(status)\n  File \"C:\\Users\\perry\\miniconda3\\envs\\PaperReplicas\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 424, in _communicate_stop_status\n    resp = self._communicate(req, local=True)\n  File \"C:\\Users\\perry\\miniconda3\\envs\\PaperReplicas\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 255, in _communicate\n    return self._communicate_async(rec, local=local).get(timeout=timeout)\n  File \"C:\\Users\\perry\\miniconda3\\envs\\PaperReplicas\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 58, in _communicate_async\n    future = self._router.send_and_receive(rec, local=local)\n  File \"C:\\Users\\perry\\miniconda3\\envs\\PaperReplicas\\lib\\site-packages\\wandb\\sdk\\interface\\router.py\", line 94, in send_and_receive\n    self._send_message(rec)\n  File \"C:\\Users\\perry\\miniconda3\\envs\\PaperReplicas\\lib\\site-packages\\wandb\\sdk\\interface\\router_sock.py\", line 36, in _send_message\n    self._sock_client.send_record_communicate(record)\n  File \"C:\\Users\\perry\\miniconda3\\envs\\PaperReplicas\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 216, in send_record_communicate\nException in thread NetStatThr:\nTraceback (most recent call last):\n  File \"C:\\Users\\perry\\miniconda3\\envs\\PaperReplicas\\lib\\threading.py\", line 980, in _bootstrap_inner\n    self.send_server_request(server_req)\n  File \"C:\\Users\\perry\\miniconda3\\envs\\PaperReplicas\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n    self.run()\n  File \"C:\\Users\\perry\\miniconda3\\envs\\PaperReplicas\\lib\\threading.py\", line 917, in run\n    self._send_message(msg)\n  File \"C:\\Users\\perry\\miniconda3\\envs\\PaperReplicas\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n    self._target(*self._args, **self._kwargs)\n  File \"C:\\Users\\perry\\miniconda3\\envs\\PaperReplicas\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 182, in check_network_status\n    self._sendall_with_error_handle(header + data)\n  File \"C:\\Users\\perry\\miniconda3\\envs\\PaperReplicas\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n    status_response = self._interface.communicate_network_status()\n  File \"C:\\Users\\perry\\miniconda3\\envs\\PaperReplicas\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py\", line 139, in communicate_network_status\n    sent = self._sock.send(data)\nConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-17T11:35:16.621Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Training hangs with GPU Utilization 100% and wandb trying to sync",
		"Question_link": "https://community.wandb.ai/t/training-hangs-with-gpu-utilization-100-and-wandb-trying-to-sync/3376",
		"Question_created_time": "2022-11-03T23:12:28.231Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 221,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019ve been trying to get wandb to work with pytorch lightning on multiple gpus, it works fine, in the sense that the model is being trained, and metrics are being reported properly to the dashboard; however, only after a couple of hours and sometimes 20 mins, the system is maxed to use all the resources, causing the whole training process to freeze without any progress. I used <code>py-spy</code> to generate the following dumps</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/b/b7f9aeb6b00a64f0949160291dd29702c3f2a805.png\" data-download-href=\"/uploads/short-url/qfwjNuMRxJcCiiUOe6uuHTM1BLT.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b7f9aeb6b00a64f0949160291dd29702c3f2a805_2_690x260.png\" alt=\"image\" data-base62-sha1=\"qfwjNuMRxJcCiiUOe6uuHTM1BLT\" width=\"690\" height=\"260\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b7f9aeb6b00a64f0949160291dd29702c3f2a805_2_690x260.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b7f9aeb6b00a64f0949160291dd29702c3f2a805_2_1035x390.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/b/b7f9aeb6b00a64f0949160291dd29702c3f2a805.png 2x\" data-dominant-color=\"EAE7D7\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1282\u00d7484 70.8 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Hopefully, they\u2019d be helpful to figure out where is the issue.</p>\n<p>Thanks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-03T23:13:03.590Z",
				"Answer_body": "<p>Here is also the flamegraph,</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/a1ca2be3989e2908d9be36a70421b54199727142.png\" data-download-href=\"/uploads/short-url/n5g1qDqiUYdcVviVSw89l2m8Yb8.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/a1ca2be3989e2908d9be36a70421b54199727142_2_690x302.png\" alt=\"image\" data-base62-sha1=\"n5g1qDqiUYdcVviVSw89l2m8Yb8\" width=\"690\" height=\"302\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/a1ca2be3989e2908d9be36a70421b54199727142_2_690x302.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/a1ca2be3989e2908d9be36a70421b54199727142_2_1035x453.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/a1ca2be3989e2908d9be36a70421b54199727142_2_1380x604.png 2x\" data-dominant-color=\"E3BF91\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">2445\u00d71072 323 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-09T11:45:25.825Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ndrwnaguib\">@ndrwnaguib</a> thank you for reporting this. Can you please provide a bit more context on the training environment and resources, eg how many gpus, model size? Would it be possible to share your <code>debug.log</code> and <code>debug-internal.log</code> files of the run that\u2019s hanging? I also checked your W&amp;B account, and it seems you\u2019re part of a team where the rate limits are higher. Could you log your experiments in the team so as to rule out the possibility this being caused by rate limits? Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-14T14:01:26.986Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ndrwnaguib\">@ndrwnaguib</a> I wanted to follow up  with you regarding this issue, can you please provide some more information to help us debug this? thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-17T16:22:55.677Z",
				"Answer_body": "<p>Gi <a class=\"mention\" href=\"/u/ndrwnaguib\">@ndrwnaguib</a> since we haven\u2019t heard back from you in a while, I will go ahead and close this ticket for now. If the issue still persists, please provide us with some further information requested above, and we will be happy to reopen this and keep investigating!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-16T16:23:15.654Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Group by multiple variables in charts",
		"Question_link": "https://community.wandb.ai/t/group-by-multiple-variables-in-charts/3435",
		"Question_created_time": "2022-11-17T15:03:50.270Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 157,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I have some variables in my sweeps that i want to be able to group by at the same time in my charts.</p>\n<p>In this specific case it\u2019s 3 hyperparameters of the architecture: \u201clevels\u201d, \u201cconvolutions per level\u201d and \u201cstarting features\u201d.</p>\n<p>I can have multiple charts, grouping by one at a time, and see how each individual variable affects the runs, but it would be much more beneficial to see the effects of all three together.</p>\n<p>The \u201ccustom chart\u201d seemed the way to go, but i couldn\u2019t make it work so far. Any help would be really appreciated!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-17T15:30:23.534Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mateoballa\">@mateoballa</a> thank you for writing in! In the Project level, you can group your Runs by all these three hyperparameters from the Group button as in the attachment.<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/4/40fde472a1d51962372411528e99e65a7c90656d.png\" alt=\"Screenshot 2022-11-17 at 15.26.35\" data-base62-sha1=\"9gWweVkvwN7ym0GpqkZ8aunFcq9\" width=\"596\" height=\"303\"></p>\n<p>Then the Charts will adjust to this grouping. Would this help, or you wanted something different to achieve? Could you share a screenshot of your current custom chart?</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-11-17T15:38:57.531Z",
				"Answer_body": "<p>Oh i never saw that option!</p>\n<p>That\u2019s perfect, thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-17T15:48:23.453Z",
				"Answer_body": "<p>Glad to hear this works for you <a class=\"mention\" href=\"/u/mateoballa\">@mateoballa</a> ! I am closing the ticket for now, but please feel free to ask if you have further questions, and we will be happy to reopen this and keep investigating!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-16T15:49:22.534Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Set random seed for sweep initialization",
		"Question_link": "https://community.wandb.ai/t/set-random-seed-for-sweep-initialization/3418",
		"Question_created_time": "2022-11-15T19:43:01.663Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 189,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>is there a way to set the initial random seed for a random or bayesian hyperparameter sweep  so that  it goes through a reproducible  sequence of hyperparameter configurations?</p>\n<p>Thanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-16T23:42:01.266Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/rluethy\">@rluethy</a>,  currently there is no method to control the random seed <strong>of</strong> a sweep. Could you expand on the importance of this to your workflow.</p>\n<p>Please note there is an active feature request out for this and I have added your details to the ticket. Once there\u2019s been movement from the team I will update you. Cheers!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-15T23:42:12.638Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb: ERROR Failed to sample metric: psutil.NoSuchProcess process no longer exists (pid=453)",
		"Question_link": "https://community.wandb.ai/t/wandb-error-failed-to-sample-metric-psutil-nosuchprocess-process-no-longer-exists-pid-453/3393",
		"Question_created_time": "2022-11-08T21:06:52.934Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 559,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am running some NLP models and simply using wandb to log the errors during these modelings. I am receiving  the following error while logging:</p>\n<p><code>wandb: ERROR Failed to sample metric: psutil.NoSuchProcess process no longer exists (pid=453)</code></p>\n<p>I appreciate your help in fixing it.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-09T03:30:35.236Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/faizelkhan-umn\">@faizelkhan-umn</a>, happy to help you look into this but we will need additional info. Could you please provide the following:</p>\n<ul>\n<li>Brief description of your experiment setup and what integrations, if any, are you using? Expand on the structure of your runs including if you are running anything in parallel or if you are using multiple GPUs.</li>\n<li>Complete traceback of your error</li>\n<li>\n<code>Debug.log</code> and <code>Debug-internal.log</code> files for the crashing runs. These are found in the working directory of the project under <code>wandb</code> within the specific runs folder.</li>\n</ul>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-15T19:20:36.470Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/faizelkhan-umn\">@faizelkhan-umn</a>  since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-16T22:16:22.275Z",
				"Answer_body": "<p>I don\u2019t know if <a class=\"mention\" href=\"/u/faizelkhan-umn\">@faizelkhan-umn</a> fixed his issue or not, but I\u2019m also facing the same issue.</p>\n<p>I\u2019m not using any special integrations, or multiple GPUs.</p>\n<p>Here\u2019s the trace of my error:</p>\n<pre><code class=\"lang-auto\">WARNING:root:Failed to import geometry msgs in rigid_transformations.py.\nWARNING:root:Failed to import ros dependencies in rigid_transforms.py\nWARNING:root:autolab_core not installed as catkin package, RigidTransform ros me\nthods will be unavailable\nwandb: Currently logged in as: ******. Use `wandb log\nin --relogin` to force relogin\nwandb: Tracking run with wandb version 0.13.5\nwandb: Run data is saved locally in ./wandb/run-20221116_134736-3a4w8w3w\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run wandering-music-644\nAuto select gpus: [0]\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\nConditionalAE(\n  (encoder): Sequential(\n    (0): Linear(in_features=8, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=256, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=256, out_features=2, bias=True)\n  )\n  (decoder): Sequential(\n    (0): Linear(in_features=6, out_features=256, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=256, out_features=512, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=256, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=256, out_features=4, bias=True)\n  )\n  (dropout): Dropout(p=0.5, inplace=False)\n)\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\nLoading `train_dataloader` to estimate number of stepping batches.\n/home3/shivam/miniconda3/envs/l_a/lib/python3.10/site-packages/pytorch_lightning\n/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader,\ntrain_dataloader, does not have many workers which may be a bottleneck. Consider\n increasing the value of the `num_workers` argument` (try 48 which is the number\n of cpus on this machine) in the `DataLoader` init to improve performance.\n  rank_zero_warn(\n\n  | Name    | Type       | Params\n---------------------------------------\n0 | encoder | Sequential | 265 K\n1 | decoder | Sequential | 265 K\n2 | dropout | Dropout    | 0\n---------------------------------------\n531 K     Trainable params\n0         Non-trainable params\n531 K     Total params\n2.126     Total estimated model params size (MB)\nSanity Checking: 0it [00:00, ?it/s]/home3/shivam/miniconda3/envs/l_a/lib/python3\n.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: Po\nssibleUserWarning: The dataloader, val_dataloader 0, does not have many workers\nwhich may be a bottleneck. Consider increasing the value of the `num_workers` ar\ngument` (try 48 which is the number of cpus on this machine) in the `DataLoader`\n init to improve performance.\n  rank_zero_warn(\nSanity Checking DataLoader 0:   0%|                       | 0/2 [00:00&lt;?, ?it/s]\nKilled\nwandb: ERROR Failed to sample metric: p\nrocess no longer exists (pid=805480)\nException in thread MsgRouterThr:\nTraceback (most recent call last):\n  File \"/home3/shivam/miniconda3/envs/l_a/lib/python3.10/threading.py\", line 101\n6, in _bootstrap_inner\n</code></pre>\n<p>As for the debug outputs:<br>\ndebug.log</p>\n<pre><code class=\"lang-auto\">2022-11-16 13:47:36,086 INFO    MainThread:805480 [wandb_setup.py:_flush():68] Configure stats pid to 805480\n2022-11-16 13:47:36,087 INFO    MainThread:805480 [wandb_setup.py:_flush():68] Loading settings from /home3/shivam/.config/wandb/settings\n2022-11-16 13:47:36,087 INFO    MainThread:805480 [wandb_setup.py:_flush():68] Loading settings from /home3/shivam/latent-actions/wandb/settings\n2022-11-16 13:47:36,087 INFO    MainThread:805480 [wandb_setup.py:_flush():68] Loading settings from environment variables: {'_require_service': 'True'}\n2022-11-16 13:47:36,087 INFO    MainThread:805480 [wandb_setup.py:_flush():68] Inferring run settings from compute environment: {'program_relpath': 'train.py', 'program': '/home3/shivam/latent-actions/train.py'}\n2022-11-16 13:47:36,087 INFO    MainThread:805480 [wandb_init.py:_log_setup():476] Logging user logs to ./wandb/run-20221116_134736-3a4w8w3w/logs/debug.log\n2022-11-16 13:47:36,087 INFO    MainThread:805480 [wandb_init.py:_log_setup():477] Logging internal logs to ./wandb/run-20221116_134736-3a4w8w3w/logs/debug-internal.log\n2022-11-16 13:47:36,087 INFO    MainThread:805480 [wandb_init.py:init():516] calling init triggers\n2022-11-16 13:47:36,087 INFO    MainThread:805480 [wandb_init.py:init():519] wandb.init called with sweep_config: {}\nconfig: {}\n2022-11-16 13:47:36,088 INFO    MainThread:805480 [wandb_init.py:init():569] starting backend\n2022-11-16 13:47:36,088 INFO    MainThread:805480 [wandb_init.py:init():573] setting up manager\n2022-11-16 13:47:36,091 INFO    MainThread:805480 [backend.py:_multiprocessing_setup():102] multiprocessing start_methods=fork,spawn,forkserver, using: spawn\n2022-11-16 13:47:36,096 INFO    MainThread:805480 [wandb_init.py:init():580] backend started and connected\n2022-11-16 13:47:36,099 INFO    MainThread:805480 [wandb_init.py:init():658] updated telemetry\n2022-11-16 13:47:36,104 INFO    MainThread:805480 [wandb_init.py:init():693] communicating run to backend with 60 second timeout\n2022-11-16 13:47:36,367 INFO    MainThread:805480 [wandb_run.py:_on_init():2000] communicating current version\n2022-11-16 13:47:36,409 INFO    MainThread:805480 [wandb_run.py:_on_init():2004] got version response \n2022-11-16 13:47:36,409 INFO    MainThread:805480 [wandb_init.py:init():728] starting run threads in backend\n2022-11-16 13:47:38,000 INFO    MainThread:805480 [wandb_run.py:_console_start():1980] atexit reg\n2022-11-16 13:47:38,000 INFO    MainThread:805480 [wandb_run.py:_redirect():1838] redirect: SettingsConsole.WRAP_RAW\n2022-11-16 13:47:38,000 INFO    MainThread:805480 [wandb_run.py:_redirect():1903] Wrapping output streams.\n2022-11-16 13:47:38,000 INFO    MainThread:805480 [wandb_run.py:_redirect():1925] Redirects installed.\n2022-11-16 13:47:38,001 INFO    MainThread:805480 [wandb_init.py:init():765] run started, returning control to user process\n2022-11-16 13:47:42,335 INFO    MainThread:805480 [wandb_run.py:_config_callback():1160] config_cb None None {'total_parameters': 531462, 'trainable_parameters': 531462, 'dataset_size': 1976600}\n2022-11-16 13:47:42,731 INFO    MainThread:805480 [wandb_run.py:_config_callback():1160] config_cb None None {'latent_dim': 2, 'enc_dims': [256, 512, 256], 'dec_dims': [256, 512, 256], 'lr': 0.01, 'kl_coeff': 1.0, 'kl_schedule': 'cyclical', 'activation': 'relu', 'context_dim': 4, 'action_dim': 4, 'include_joint_angles': False, 'fixed_point_coeff': 0.001, 'dropout': 0.5, 'compute_divergence': False, 'div_coeff': 0, 'div_clip': inf, 'decode': True, 'align': False, 'model_class': 'cAE', 'batch_size': 64, 'max_epochs': 100, 'no_wandb': False, 'data_path': 'data/rpnp_traj_with_pose_and_noise.pkl', 'exclude_context_feature_joint_angles': True, 'exclude_context_feature_gripper_width': False, 'exclude_context_feature_pose': True, 'exclude_context_feature_ee_pos': False, 'exclude_context_feature_ee_rot': True, 'exclude_gripper': False, 'action_space': 'ee', 'size_limit': 'None'}\n</code></pre>\n<p>debug-internal.log</p>\n<pre><code class=\"lang-auto\">2022-11-16 13:47:36,096 INFO    StreamThr :824981 [internal.py:wandb_internal():88] W&amp;B internal server running at pid: 824981, started at: 2022-11-16 13:47:36.096186\n2022-11-16 13:47:36,105 DEBUG   HandlerThread:824981 [handler.py:handle_request():139] handle_request: status\n2022-11-16 13:47:36,105 DEBUG   SenderThread:824981 [sender.py:send_request():317] send_request: status\n2022-11-16 13:47:36,106 INFO    WriterThread:824981 [datastore.py:open_for_write():75] open: ./wandb/run-20221116_134736-3a4w8w3w/run-3a4w8w3w.wandb\n2022-11-16 13:47:36,106 DEBUG   SenderThread:824981 [sender.py:send():303] send: header\n2022-11-16 13:47:36,107 DEBUG   SenderThread:824981 [sender.py:send():303] send: run\n2022-11-16 13:47:36,108 INFO    SenderThread:824981 [sender.py:_maybe_setup_resume():593] checking resume status for ucla-ncel-robotics/latent-action/3a4w8w3w\n2022-11-16 13:47:36,368 DEBUG   HandlerThread:824981 [handler.py:handle_request():139] handle_request: check_version\n2022-11-16 13:47:36,374 INFO    SenderThread:824981 [dir_watcher.py:__init__():216] watching files in: ./wandb/run-20221116_134736-3a4w8w3w/files\n2022-11-16 13:47:36,375 INFO    SenderThread:824981 [sender.py:_start_run_threads():928] run started: 3a4w8w3w with start time 1668635256.096683\n2022-11-16 13:47:36,375 DEBUG   SenderThread:824981 [sender.py:send():303] send: summary\n2022-11-16 13:47:36,375 INFO    SenderThread:824981 [sender.py:_save_file():1171] saving file wandb-summary.json with policy end\n2022-11-16 13:47:36,375 DEBUG   SenderThread:824981 [sender.py:send_request():317] send_request: check_version\n2022-11-16 13:47:36,414 DEBUG   HandlerThread:824981 [handler.py:handle_request():139] handle_request: run_start\n2022-11-16 13:47:36,425 DEBUG   HandlerThread:824981 [system_info.py:__init__():31] System info init\n2022-11-16 13:47:36,425 DEBUG   HandlerThread:824981 [system_info.py:__init__():46] System info init done\n2022-11-16 13:47:36,425 INFO    HandlerThread:824981 [system_monitor.py:start():150] Starting system monitor\n2022-11-16 13:47:36,425 INFO    SystemMonitor:824981 [system_monitor.py:_start():116] Starting system asset monitoring threads\n2022-11-16 13:47:36,425 INFO    SystemMonitor:824981 [interfaces.py:start():168] Started cpu\n2022-11-16 13:47:36,425 INFO    HandlerThread:824981 [system_monitor.py:probe():168] Collecting system info\n2022-11-16 13:47:36,426 INFO    SystemMonitor:824981 [interfaces.py:start():168] Started disk\n2022-11-16 13:47:36,426 INFO    SystemMonitor:824981 [interfaces.py:start():168] Started gpu\n2022-11-16 13:47:36,427 INFO    SystemMonitor:824981 [interfaces.py:start():168] Started memory\n2022-11-16 13:47:36,427 INFO    SystemMonitor:824981 [interfaces.py:start():168] Started network\n2022-11-16 13:47:36,465 DEBUG   HandlerThread:824981 [system_info.py:probe():195] Probing system\n2022-11-16 13:47:36,467 DEBUG   HandlerThread:824981 [system_info.py:_probe_git():180] Probing git\n2022-11-16 13:47:36,471 DEBUG   HandlerThread:824981 [system_info.py:_probe_git():188] Probing git done\n2022-11-16 13:47:36,471 DEBUG   HandlerThread:824981 [system_info.py:probe():241] Probing system done\n2022-11-16 13:47:36,471 DEBUG   HandlerThread:824981 [system_monitor.py:probe():177] {'os': 'Linux-5.15.0-48-generic-x86_64-with-glibc2.31', 'python': '3.10.6', 'heartbeatAt': '2022-11-16T21:47:36.465175', 'startedAt': '2022-11-16T21:47:36.083219', 'docker': None, 'cuda': None, 'args': ('--decode', '--model_class', 'cAE', '--max_epochs', '100', '--data_path', 'data/rpnp_traj_with_pose_and_noise.pkl', '--action_space', 'ee', '--enc_dims', '256', '512', '256', '--dec_dims', '256', '512', '256', '--exclude_context_feature_pose', '--exclude_context_feature_joint_angles', '--exclude_context_feature_ee_rot', '--dropout', '0.5', '--fixed_point_coeff', '0.001', '--batch_size', '64'), 'state': 'running', 'program': '/home3/shivam/latent-actions/train.py', 'codePath': 'train.py', 'git': {'remote': 'https://github.com/shivampatel712/latent-actions', 'commit': '1d68621ead248ab96deb84c6420a39aca3d9081c'}, 'email': 'shivambpatel712@gmail.com', 'root': '/home3/shivam/latent-actions', 'host': 'obiwan', 'username': 'shivam', 'executable': '/home3/shivam/miniconda3/envs/l_a/bin/python', 'cpu_count': 24, 'cpu_count_logical': 48, 'cpu_freq': {'current': 4000.9778541666674, 'min': 2200.0, 'max': 3800.0}, 'cpu_freq_per_core': [{'current': 4006.182, 'min': 2200.0, 'max': 3800.0}, {'current': 4006.044, 'min': 2200.0, 'max': 3800.0}, {'current': 4005.846, 'min': 2200.0, 'max': 3800.0}, {'current': 4003.476, 'min': 2200.0, 'max': 3800.0}, {'current': 4003.603, 'min': 2200.0, 'max': 3800.0}, {'current': 4003.54, 'min': 2200.0, 'max': 3800.0}, {'current': 4007.326, 'min': 2200.0, 'max': 3800.0}, {'current': 3800.0, 'min': 2200.0, 'max': 3800.0}, {'current': 4007.215, 'min': 2200.0, 'max': 3800.0}, {'current': 4003.614, 'min': 2200.0, 'max': 3800.0}, {'current': 4004.054, 'min': 2200.0, 'max': 3800.0}, {'current': 4003.672, 'min': 2200.0, 'max': 3800.0}, {'current': 4005.822, 'min': 2200.0, 'max': 3800.0}, {'current': 4005.662, 'min': 2200.0, 'max': 3800.0}, {'current': 3996.473, 'min': 2200.0, 'max': 3800.0}, {'current': 4007.573, 'min': 2200.0, 'max': 3800.0}, {'current': 4007.093, 'min': 2200.0, 'max': 3800.0}, {'current': 4007.465, 'min': 2200.0, 'max': 3800.0}, {'current': 4007.39, 'min': 2200.0, 'max': 3800.0}, {'current': 4006.244, 'min': 2200.0, 'max': 3800.0}, {'current': 4006.625, 'min': 2200.0, 'max': 3800.0}, {'current': 4004.173, 'min': 2200.0, 'max': 3800.0}, {'current': 4004.033, 'min': 2200.0, 'max': 3800.0}, {'current': 4004.174, 'min': 2200.0, 'max': 3800.0}, {'current': 4006.828, 'min': 2200.0, 'max': 3800.0}, {'current': 4006.708, 'min': 2200.0, 'max': 3800.0}, {'current': 4006.514, 'min': 2200.0, 'max': 3800.0}, {'current': 4003.304, 'min': 2200.0, 'max': 3800.0}, {'current': 4003.476, 'min': 2200.0, 'max': 3800.0}, {'current': 4003.415, 'min': 2200.0, 'max': 3800.0}, {'current': 4007.905, 'min': 2200.0, 'max': 3800.0}, {'current': 4005.451, 'min': 2200.0, 'max': 3800.0}, {'current': 4007.746, 'min': 2200.0, 'max': 3800.0}, {'current': 4003.435, 'min': 2200.0, 'max': 3800.0}, {'current': 4003.914, 'min': 2200.0, 'max': 3800.0}, {'current': 4003.545, 'min': 2200.0, 'max': 3800.0}, {'current': 4006.094, 'min': 2200.0, 'max': 3800.0}, {'current': 4006.284, 'min': 2200.0, 'max': 3800.0}, {'current': 4006.247, 'min': 2200.0, 'max': 3800.0}, {'current': 4008.135, 'min': 2200.0, 'max': 3800.0}, {'current': 3996.988, 'min': 2200.0, 'max': 3800.0}, {'current': 4008.027, 'min': 2200.0, 'max': 3800.0}, {'current': 4007.263, 'min': 2200.0, 'max': 3800.0}, {'current': 4006.791, 'min': 2200.0, 'max': 3800.0}, {'current': 4007.211, 'min': 2200.0, 'max': 3800.0}, {'current': 4004.831, 'min': 2200.0, 'max': 3800.0}, {'current': 4004.694, 'min': 2200.0, 'max': 3800.0}, {'current': 4004.832, 'min': 2200.0, 'max': 3800.0}], 'disk': {'total': 915.3232879638672, 'used': 52.240882873535156}, 'gpu': 'NVIDIA GeForce RTX 3090', 'gpu_count': 3, 'gpu_devices': [{'name': 'NVIDIA GeForce RTX 3090', 'memory_total': 25447170048}, {'name': 'NVIDIA GeForce RTX 3090', 'memory_total': 25447170048}, {'name': 'NVIDIA GeForce RTX 3090', 'memory_total': 25438322688}], 'memory': {'total': 125.64818572998047}}\n2022-11-16 13:47:36,471 INFO    HandlerThread:824981 [system_monitor.py:probe():178] Finished collecting system info\n2022-11-16 13:47:36,471 INFO    HandlerThread:824981 [system_monitor.py:probe():181] Publishing system info\n2022-11-16 13:47:36,471 DEBUG   HandlerThread:824981 [system_info.py:_save_pip():51] Saving list of pip packages installed into the current environment\n2022-11-16 13:47:36,471 DEBUG   HandlerThread:824981 [system_info.py:_save_pip():67] Saving pip packages done\n2022-11-16 13:47:36,472 DEBUG   HandlerThread:824981 [system_info.py:_save_conda():74] Saving list of conda packages installed into the current environment\n2022-11-16 13:47:37,375 INFO    Thread-13 :824981 [dir_watcher.py:_on_file_created():275] file/dir created: ./wandb/run-20221116_134736-3a4w8w3w/files/wandb-summary.json\n2022-11-16 13:47:37,376 INFO    Thread-13 :824981 [dir_watcher.py:_on_file_created():275] file/dir created: ./wandb/run-20221116_134736-3a4w8w3w/files/requirements.txt\n2022-11-16 13:47:37,376 INFO    Thread-13 :824981 [dir_watcher.py:_on_file_created():275] file/dir created: ./wandb/run-20221116_134736-3a4w8w3w/files/conda-environment.yaml\n2022-11-16 13:47:37,926 DEBUG   HandlerThread:824981 [system_info.py:_save_conda():86] Saving conda packages done\n2022-11-16 13:47:37,926 INFO    HandlerThread:824981 [system_monitor.py:probe():183] Finished publishing system info\n2022-11-16 13:47:37,995 DEBUG   SenderThread:824981 [sender.py:send():303] send: files\n2022-11-16 13:47:37,996 INFO    SenderThread:824981 [sender.py:_save_file():1171] saving file wandb-metadata.json with policy now\n2022-11-16 13:47:38,000 DEBUG   HandlerThread:824981 [handler.py:handle_request():139] handle_request: stop_status\n2022-11-16 13:47:38,000 DEBUG   SenderThread:824981 [sender.py:send_request():317] send_request: stop_status\n2022-11-16 13:47:38,088 DEBUG   SenderThread:824981 [sender.py:send():303] send: telemetry\n2022-11-16 13:47:38,088 DEBUG   SenderThread:824981 [sender.py:send():303] send: metric\n2022-11-16 13:47:38,088 DEBUG   SenderThread:824981 [sender.py:send():303] send: telemetry\n2022-11-16 13:47:38,088 DEBUG   SenderThread:824981 [sender.py:send():303] send: metric\n2022-11-16 13:47:38,088 WARNING SenderThread:824981 [sender.py:send_metric():1127] Seen metric with glob (shouldn't happen)\n2022-11-16 13:47:38,346 INFO    Thread-16 :824981 [upload_job.py:push():143] Uploaded file /tmp/tmp10ff2xhawandb/byh38mac-wandb-metadata.json\n2022-11-16 13:47:38,375 INFO    Thread-13 :824981 [dir_watcher.py:_on_file_modified():292] file/dir modified: ./wandb/run-20221116_134736-3a4w8w3w/files/conda-environment.yaml\n2022-11-16 13:47:38,375 INFO    Thread-13 :824981 [dir_watcher.py:_on_file_created():275] file/dir created: ./wandb/run-20221116_134736-3a4w8w3w/files/wandb-metadata.json\n2022-11-16 13:47:41,387 INFO    Thread-13 :824981 [dir_watcher.py:_on_file_created():275] file/dir created: ./wandb/run-20221116_134736-3a4w8w3w/files/output.log\n2022-11-16 13:47:42,336 DEBUG   SenderThread:824981 [sender.py:send():303] send: config\n2022-11-16 13:47:42,732 DEBUG   SenderThread:824981 [sender.py:send():303] send: config\n2022-11-16 13:47:43,403 INFO    Thread-13 :824981 [dir_watcher.py:_on_file_modified():292] file/dir modified: ./wandb/run-20221116_134736-3a4w8w3w/files/output.log\n2022-11-16 13:48:53,773 INFO    Thread-13 :824981 [dir_watcher.py:_on_file_modified():292] file/dir modified: ./wandb/run-20221116_134736-3a4w8w3w/files/output.log\n2022-11-16 13:48:53,775 DEBUG   SystemMonitor:824981 [system_monitor.py:_start():130] Starting system metrics aggregation loop\n2022-11-16 13:48:54,755 WARNING StreamThr :824981 [internal.py:is_dead():385] Internal process exiting, parent pid 805480 disappeared\n2022-11-16 13:48:54,755 ERROR   StreamThr :824981 [internal.py:wandb_internal():147] Internal process shutdown.\n2022-11-16 13:48:54,773 INFO    Thread-13 :824981 [dir_watcher.py:_on_file_modified():292] file/dir modified: ./wandb/run-20221116_134736-3a4w8w3w/files/config.yaml\n2022-11-16 13:48:54,887 INFO    SenderThread:824981 [sender.py:finish():1331] shutting down sender\n2022-11-16 13:48:55,490 INFO    HandlerThread:824981 [handler.py:finish():814] shutting down handler\n2022-11-16 13:48:55,739 INFO    WriterThread:824981 [datastore.py:close():279] close: ./wandb/run-20221116_134736-3a4w8w3w/run-3a4w8w3w.wandb\n2022-11-16 13:48:56,227 INFO    SenderThread:824981 [dir_watcher.py:finish():362] shutting down directory watcher\n2022-11-16 13:48:56,769 INFO    MainThread:824981 [internal.py:handle_exit():78] Internal process exited\n</code></pre>\n<p>Thanks for your help.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-15T22:16:58.758Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Undelete runs no longer available?",
		"Question_link": "https://community.wandb.ai/t/undelete-runs-no-longer-available/3420",
		"Question_created_time": "2022-11-15T22:02:39.237Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 311,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi,<br>\nI deleted a run by accident and tried to recover it. However, I noticed there is undelete all runs option available from the dot menu on the overview page of the project.<br>\nIs there a way to recover a deleted run?<br>\nThank you.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-16T12:05:29.286Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/summer5e\">@summer5e</a> thank you for reporting this. The option to undelete runs should be available when you go to the Project\u2019s overview page, and not in the Runs overview level. I have attached a screenshot of an example, the option can be found when you click on the three vertical dots:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/b/b4766106065aa247f2d9930f131e3dab402136a6.png\" data-download-href=\"/uploads/short-url/pKrzn3Dflv0FWE8GGBfCE4JTMhM.png?dl=1\" title=\"Screenshot 2022-11-16 at 12.02.29\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b4766106065aa247f2d9930f131e3dab402136a6_2_690x174.png\" alt=\"Screenshot 2022-11-16 at 12.02.29\" data-base62-sha1=\"pKrzn3Dflv0FWE8GGBfCE4JTMhM\" width=\"690\" height=\"174\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b4766106065aa247f2d9930f131e3dab402136a6_2_690x174.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b4766106065aa247f2d9930f131e3dab402136a6_2_1035x261.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b4766106065aa247f2d9930f131e3dab402136a6_2_1380x348.png 2x\" data-dominant-color=\"212122\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2022-11-16 at 12.02.29</span><span class=\"informations\">2845\u00d7719 123 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Could you please let me know the name of your project to look further into this?</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-11-16T18:15:55.291Z",
				"Answer_body": "<p>Thank you! I was clicking on the overview in the runs panel not information panel.<br>\nThis solved my problem.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-16T19:13:36.556Z",
				"Answer_body": "<p>Glad to hear you got back your deleted run data <a class=\"mention\" href=\"/u/summer5e\">@summer5e</a>! I will close the ticket for now, and please reach out if you run into any other issue.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-15T19:13:48.578Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Nested Sweep Configuration",
		"Question_link": "https://community.wandb.ai/t/nested-sweep-configuration/3369",
		"Question_created_time": "2022-11-02T17:13:09.376Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 740,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have been attempting to use <a href=\"https://docs.wandb.ai/guides/integrations/other/hydra\">Hydra configuration</a> with a wandb sweeps. I have nested hierarchy of configuration. When defining the parameters I want to sweep over  I would like to something like the following:</p>\n<pre><code class=\"lang-auto\">optimizer:\n    parameters:\n        learning_rate:\n            values: [0.01, 0.001]\n        momentum:\n            value: 0.9\n</code></pre>\n<p>Source: <a href=\"https://docs.wandb.ai/guides/sweeps/define-sweep-configuration\">Sweep Configuration</a><br>\nWhen I attempt this, I get a <code>CommError</code> with a message that  <code>sweep config must have a parameters section </code>. I do not get this error if <code>parameters</code> is at the top level of the hierarchy, but then the configs are not read in properly.  If I were to modify the above example to the following (only swapped <code>parameters</code> with <code>optimizer</code>):</p>\n<pre><code class=\"lang-auto\">parameters:\n    optimizer:\n        learning_rate:\n            values: [0.01, 0.001]\n        momentum:\n            value: 0.9\n</code></pre>\n<p>I would get a <code>CommError</code> with message <code>Invalid sweep config: invalid hyperparameter configuration: optimizer</code>. I would like to keep the hierarchical structure of the YAML base config but add <code>parameters</code> which will indicate which parameters to sweep over. Any recommendation? or resources? A code example using a nested <code>sweep.yaml</code> would be ideal.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-03T05:18:55.590Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mjvolk3\">@mjvolk3</a>,</p>\n<p>This is currently not available with our sweep configurations. We have a more customizable nested sweep config as you describe planned as a feature for the future, I can go ahead and increase the priority on it for you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-06T16:10:26.175Z",
				"Answer_body": "<p>It looks like this is supported. It works if you put <code>parameters:</code> between every level. With the previous example it looks like the following:</p>\n<pre><code class=\"lang-auto\">parameters:\n    optimizer:\n        parameters:\n            learning_rate:\n                values: [0.01, 0.001]\n            momentum:\n                value: 0.9\n</code></pre>\n<p>The original source I referenced (wandb docs) must be indicating that the block below works if it is put under <code>parameters:</code></p>\n<pre><code class=\"lang-auto\">optimizer:\n    parameters:\n        learning_rate:\n            values: [0.01, 0.001]\n        momentum:\n            value: 0.9\n</code></pre>\n<p>I have tested this pattern with deeper hierarchies and it works.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-16T12:49:12.092Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/mjvolk3\">@mjvolk3</a>,</p>\n<p>You are right - I confirmed and this has been implemented recently, just skipped my radar. Is there anything else I can assist with here?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-15T12:49:26.426Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Filtering runs by job_type using API is not working",
		"Question_link": "https://community.wandb.ai/t/filtering-runs-by-job-type-using-api-is-not-working/3390",
		"Question_created_time": "2022-11-08T15:39:19.400Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 170,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi everyone!</p>\n<p>I am trying to retrieve  filtered runs from a project using the WandB API and a filter dictionary.</p>\n<p>I try to do the following:</p>\n<pre><code class=\"lang-auto\">api = wandb.Api()\nfilter_dict = {\"job_type\":  \"my_job_type\"}\nruns = api.runs(\"my_entity/my_project\", filters=filter_dict)\nfor run in runs:\n    print(run)\n</code></pre>\n<p>When I do this, I get the following error message:</p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"C:\\Users\\KoljaBauer\\anaconda3\\lib\\site-packages\\wandb\\apis\\public.py\", line 980, in __next__\n    if not self._load_page():\n  File \"C:\\Users\\KoljaBauer\\anaconda3\\lib\\site-packages\\wandb\\apis\\public.py\", line 965, in _load_page\n    self.last_response = self.client.execute(\n  File \"C:\\Users\\KoljaBauer\\anaconda3\\lib\\site-packages\\wandb\\sdk\\lib\\retry.py\", line 168, in wrapped_fn\n    return retrier(*args, **kargs)\n  File \"C:\\Users\\KoljaBauer\\anaconda3\\lib\\site-packages\\wandb\\sdk\\lib\\retry.py\", line 108, in __call__\n    result = self._call_fn(*args, **kwargs)\n  File \"C:\\Users\\KoljaBauer\\anaconda3\\lib\\site-packages\\wandb\\apis\\public.py\", line 207, in execute\n    return self._client.execute(*args, **kwargs)\n  File \"C:\\Users\\KoljaBauer\\anaconda3\\lib\\site-packages\\wandb\\vendor\\gql-0.2.0\\wandb_gql\\client.py\", line 52, in execute\n    result = self._get_result(document, *args, **kwargs)\n  File \"C:\\Users\\KoljaBauer\\anaconda3\\lib\\site-packages\\wandb\\vendor\\gql-0.2.0\\wandb_gql\\client.py\", line 60, in _get_result\n    return self.transport.execute(document, *args, **kwargs)\n  File \"C:\\Users\\KoljaBauer\\anaconda3\\lib\\site-packages\\wandb\\vendor\\gql-0.2.0\\wandb_gql\\transport\\requests.py\", line 39, in execute\n    request.raise_for_status()\n  File \"C:\\Users\\KoljaBauer\\anaconda3\\lib\\site-packages\\requests\\models.py\", line 1021, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.wandb.ai/graphql\n</code></pre>\n<p>However, other filters do work. For example I can do the above described procedure with</p>\n<pre><code class=\"lang-auto\">filter_dict = {\"group\":  \"my_group\"}\n</code></pre>\n<p>and it yields the correctly filtered jobs.</p>\n<p>What I am currently doing as a workaround is this:</p>\n<pre><code class=\"lang-auto\">api = wandb.Api()\nruns = api.runs(\"my_entity/my_project\")\nfor run in runs:\n    if run.job_type == \"my_job_type\":\n        print(run)\n</code></pre>\n<p>However, I would prefer to directly filter the runs with the API call. Any idea what I am doing wrong?</p>\n<p>Thanks in advance!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-08T16:25:24.247Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kolja\">@kolja</a> thank you for writing in! Could you please try if the following would work for you?</p>\n<pre><code class=\"lang-auto\">api = wandb.Api()\nfilter_dict = {\"jobType\":  \"my_job_type\"}\nruns = api.runs(\"my_entity/my_project\", filters=filter_dict)\nfor run in runs:\n    print(run)\n</code></pre>\n<p>The queries in <code>filters</code> are using the MongoDB query language. Hope this helps!</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-11-14T13:39:16.271Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a> thanks a lot for your reply!</p>\n<p>This solved my problem.</p>\n<p>Are those keys included in the documentation somewhere? I find it confusing that you can access them in Python via <code>my_job.job_type</code> and <code>my_job.name</code>, but in the query those parameters must be called <code>jobType</code> and <code>display_name</code>. I could not find any mention of <code>jobType</code> in the documentation and I only found <code>display_name</code> in some code example by coincidence.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-15T20:57:16.590Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kolja\">@kolja</a> glad to hear this is now fixed! Indeed this part is not <a href=\"https://docs.wandb.ai/ref/weave/run#run-jobtype\">well documented</a> but our docs are continuously updated. Another source to get these information would be our GitHub repository such as <a href=\"https://github.com/wandb/wandb/blob/main/wandb/apis/public.py#L84\" rel=\"noopener nofollow ugc\">here</a>. I hope this helps!</p>\n<p>I am closing the ticket for now as is resolved, but please feel free to reopen it if you have more questions related to this issue and I will be glad to assist further.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-14T20:58:11.378Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Cannot connect to Amazon S3 from self hosted wandb",
		"Question_link": "https://community.wandb.ai/t/cannot-connect-to-amazon-s3-from-self-hosted-wandb/3399",
		"Question_created_time": "2022-11-09T21:12:49.307Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 114,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I\u2019m trying to setup a self hosted wandb on k8s using helm charts. Unfortunately, I am not able to connect to my Amazon S3.</p>\n<p>I tried two ways:</p>\n<ol>\n<li>\n<p>Based on the example here <a href=\"https://docs.wandb.ai/guides/self-hosted/setup/on-premise-baremetal\" class=\"inline-onebox\">On Prem / Baremetal - Documentation</a>, I used the format:<br>\ns3://myaccess:myseceret@s3.amazonaws.com/ofer-bucket-1<br>\nHowever when the wandb pod starts, it says that the URL is not valid, as \u201c:mysecret\u201d is not a valid port.<br>\nFor some reason it considers the secret to indicate URL port and not secret</p>\n</li>\n<li>\n<p>I also tried changing my bucket to public,  but wandb pod failed to initialize again, this time with error 403 access denied.</p>\n</li>\n</ol>\n<p>Anyone has an example for the correct format of the BUCKET value or can explain how it should be structured? I prefer to have it with access/secret key. But I\u2019m ok with public as well.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-10T23:53:29.793Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/oferla\">@oferla</a> , happy to help you resolved this issue. We received your request to our support email and I followed up with request for additional information. I will continue our conversation but keep this discourse thread open for community members to contribute any additional feedback. Cheers!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-13T05:04:58.264Z",
				"Answer_body": "<p>I\u2019ll post the reply of Chris Van Pelt from WandB support, to assist anyone who encounters this:<br>\nThe correct format is indeed s3://access:secret@host/bucket<br>\nHowever, each component (access, secret, etc) needs to be url encoded as special characters within them can interfere with the parsing.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-11-14T18:46:53.443Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/oferla\">@oferla</a> thank you for updating the community with CVPs fix. Happy to hear you were able to successfully setup your instance.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-13T18:47:19.442Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Rename username",
		"Question_link": "https://community.wandb.ai/t/rename-username/3409",
		"Question_created_time": "2022-11-11T04:34:38.790Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 295,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello to all,</p>\n<p>I am new here. I thought I can change my username whenever I want when I signed up, so my username was informal. However, I couldn\u2019t find the place where I can change my username. I can only change my real name, institution, location, etc.</p>\n<p>Thank you very much<br>\nBest regards<br>\nJellerode</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-14T13:25:14.356Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/jellerode\">@jellerode</a>,</p>\n<p>We do not support changing usernames at the moment. In case you really need to change your username, I would suggest you delete your account and create a new account.</p>\n<p>I see your account does not have any runs yet, so there should be no lost data, but we can transfer your data over to the new account if you have logged any data.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-13T13:26:06.709Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Delete account?",
		"Question_link": "https://community.wandb.ai/t/delete-account/3412",
		"Question_created_time": "2022-11-12T00:00:11.695Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 402,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I want my account deleted as I want to be removed from all teams I am currently in (changed jobs). I cannot delete my account since I\u2019m a billing user for some reason (I don\u2019t get charged at all by wandb so not sure why?) My username is aharakeh. Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-14T15:37:29.257Z",
				"Answer_body": "<p>Hi Ali!</p>\n<p>Just to confirm,</p>\n<p>Are you sure you want to delete aharakeh? Deleting a user removes all user data permanently. This action cannot be undone.</p>\n<p>Cheers!</p>\n<p>Artsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-17T17:26:28.879Z",
				"Answer_body": "<p>Hi Ali,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-22T19:09:51.921Z",
				"Answer_body": "<p>Hi Ali, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>\n<p>You do have an option of deleting your account by going to <a href=\"http://wandb.ai/settings\" class=\"inline-onebox-loading\">wandb.ai/settings</a></p>\n<p>Cheers!<br>\nArtsiom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-11T00:00:47.621Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Detectron2 sweeps",
		"Question_link": "https://community.wandb.ai/t/detectron2-sweeps/3351",
		"Question_created_time": "2022-10-31T18:10:51.410Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 213,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello</p>\n<p>I\u2019m a CV engineer and I\u2019m trying to make sweeps using w&amp;b, the issue is that I use detectron2 framework, thus I use config files to build the model, solver, etc\u2026<br>\nThe config files are usually nested if its important<br>\nI\u2019m intrested to initialize the agent using SDK properly, but in contrast to the example in the documentation, I cant just assign all the parameters (like \u2018a\u2019 here) to wandb.config.a<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/0/0b77bb2ed35e6a9e13a69a44c28a0901046c6ea2.png\" alt=\"image\" data-base62-sha1=\"1DrM3iAAJsTbiAW3aq7KKi7FbFw\" width=\"620\" height=\"314\"><br>\nIs there a way to assign the determined parameters efficiently?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-02T15:42:53.121Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dorbitton\">@dorbitton</a> thank you for writing in! We support nested dictionaries or  <code>yaml</code> files, so this shouldn\u2019t be a problem. Could you please provide a code snippet in which circumstances you can\u2019t assign the parameters? do you use some extra arguments not specified in the sweep config file? Would <a href=\"https://docs.wandb.ai/guides/sweeps/define-sweep-configuration#examples-4\">this</a> example help?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-08T09:54:35.033Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dorbitton\">@dorbitton</a> just checking in with you to see if you still experience this issue, and if you could further elaborate on the reason that <code>a</code> won\u2019t be assigned in your code? thanks.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-11T15:17:18.866Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dorbitton\">@dorbitton</a> since we haven\u2019t heard back from you, I will go ahead and close this ticket for now. If you still experience this issue, feel free to re-open this and we will keep investigating!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-10T15:17:54.408Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "CI Credentials Not Tied to User",
		"Question_link": "https://community.wandb.ai/t/ci-credentials-not-tied-to-user/3388",
		"Question_created_time": "2022-11-08T14:37:29.037Z",
		"Question_answer_count": 4,
		"Question_score_count": 2,
		"Question_view_count": 235,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi there.</p>\n<p>We currently use wandb artifacts for model versioning during experiments. We\u2019d also like to integrate this into our production pipeline so that we can automatically pull specific model versions during builds.</p>\n<p>I am wondering if it\u2019s possible to get credentials that are not tied to a specific wandb user so that they don\u2019t expire if the team member that implements this happens to leave our company.</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-08T15:54:30.258Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/willjstone\">@willjstone</a> thank you for writing in! You can do this using a <code>service account</code>, the steps to add this account type to your team are explained in our documentation <a href=\"https://docs.wandb.ai/guides/technical-faq/general#what-is-a-service-account-and-why-is-it-useful\">here</a>. Would this work for your use case?</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-11-08T16:26:36.996Z",
				"Answer_body": "<p>Yep, that will do it. Thanks for the quick response.</p>\n<p>One more question; does this service account carry the same cost as a regular seat?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-08T16:57:30.653Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/willjstone\">@willjstone</a> the service account does not take up a seat, as it isn\u2019t associated with a user. For future reference, this account type is currently available on <a href=\"https://wandb.ai/site/pricing\">enterprise</a> plans.</p>\n<p>I will close the ticket for now as it seems resolved for you, but please let me know if you have any further questions related to this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-07T16:57:51.675Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Easiest way to load the best model checkpoint after training w/ pytorch lightning",
		"Question_link": "https://community.wandb.ai/t/easiest-way-to-load-the-best-model-checkpoint-after-training-w-pytorch-lightning/3365",
		"Question_created_time": "2022-11-02T00:15:43.889Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 1375,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I have a notebook based on <a href=\"http://wandb.me/lit-colab\" rel=\"noopener nofollow ugc\"> Supercharge your Training with PyTorch Lightning + Weights &amp; Biases</a> and I\u2019m wondering what the easiest approach to load a model with the best checkpoint after training finishes.</p>\n<p>I\u2019m assuming that after training the \u201cmodel\u201d instance will just have the weights of the most recent epoch, which might not be the most accurate model (in case it started overfitting etc).</p>\n<p>Specifically I was looking for an easy way to get the directory where the checkpoints artifacts are stored, which in my case look like this: <code>./MnistKaggle/1vzsgin6/checkpoints</code>, where <code>1vzsgin6</code> is the run id auto-generated by wandb.</p>\n<p>One (clunky) way to do it would be:</p>\n<pre><code class=\"lang-auto\">wandb_logger = WandbLogger(project=\"MnistKaggle\")\ncheckpoint_dir_path = None\n\ndef my_after_save_checkpoint(checkpoint):\n  checkpoint_dir_path = checkpoint.dirpath\n\nwandb_logger.after_save_checkpoint = my_after_save_checkpoint\n\n# Now find the checkpoint file in the checkpoint_dir_path directory and load the model from that.\n</code></pre>\n<p>Is there an easier way?  I was sorta expecting the <code>WandbLogger</code> object to have an easy method like <code>get_save_checkpoint_dirpath()</code>, but I\u2019m not seeing anything.</p>\n<p>Thanks in advance for any help!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-02T23:00:11.968Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tleyden\">@tleyden</a> , happy to help. Please review the following <a href=\"https://pytorch-lightning.readthedocs.io/en/stable/extensions/generated/pytorch_lightning.loggers.WandbLogger.html#:~:text=(model)-,Log%20model%20checkpoints,-Log%20model%20checkpoints\" rel=\"noopener nofollow ugc\">resource</a> on model checkpointing and retrieval.</p>\n<p>A common flow would be to log a model checkpoint as in the example then to also log a \u201cbest model\u201d artifact. Since artifacts are versioned you don\u2019t have to worry about renaming the new \u201cbest model\u201d artifact. Then at the end of your run you not only have an artifact history of your model at each of the checkpoints but also a versioned history of all the best models.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-11-07T18:37:27.390Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tleyden\">@tleyden</a>  since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-07T19:00:32.227Z",
				"Answer_body": "<p>Thanks for the tip about the \u201clatest/best\u201d aliases, I hadn\u2019t seen that.  So if I understand correctly, this would be downloading the model checkpoint locally via the API - which is somewhat redundant since I assume it\u2019s already saved locally, but it provides more control in terms of being able to specify those aliases.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-06T19:00:41.754Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Training crashes on 2nd epoch with ValueError: not enough image data",
		"Question_link": "https://community.wandb.ai/t/training-crashes-on-2nd-epoch-with-valueerror-not-enough-image-data/3341",
		"Question_created_time": "2022-10-28T19:46:50.551Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 193,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am trying to train a model but on the second epoch training crashes with the following error that is raised inside the wandb site-package:</p>\n<pre><code class=\"lang-auto\">----&gt; 1 history, model = train_model()\n\nCell In [11], line 54, in train_model()\n     51 early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=3)\n     53 checkpoint = ModelCheckpoint(\"my_tiny_model\", save_weights_only=True)\n---&gt; 54 history = model.fit(train_dataset,\n     55         epochs=config.epochs, \n     56         validation_data=val_dataset, \n     57         callbacks=[tensorboard_callback, wandb_callback, checkpoint, early_stopping])\n     59 wandb.finish()\n     60 return history, model\n\nFile d:\\Miniconda\\envs\\tiny_cnn\\lib\\site-packages\\wandb\\integration\\keras\\keras.py:174, in patch_tf_keras.&lt;locals&gt;.new_v2(*args, **kwargs)\n    172     for cbk in cbks:\n    173         set_wandb_attrs(cbk, val_data)\n--&gt; 174 return old_v2(*args, **kwargs)\n\nFile d:\\Miniconda\\envs\\tiny_cnn\\lib\\site-packages\\wandb\\integration\\keras\\keras.py:174, in patch_tf_keras.&lt;locals&gt;.new_v2(*args, **kwargs)\n    172     for cbk in cbks:\n    173         set_wandb_attrs(cbk, val_data)\n--&gt; 174 return old_v2(*args, **kwargs)\n...\n--&gt; 798     raise ValueError(\"not enough image data\")\n    799 if s[1] != 0:\n    800     raise ValueError(\"cannot decode image data\")\n\nValueError: not enough image data\n</code></pre>\n<p>Any idea on what needs to be fixed? Thanks for your support.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-31T11:43:50.844Z",
				"Answer_body": "<p>Hi Susanne,</p>\n<p>Thanks for writing in! Could you share a snippet of the code that you are using? Also, could you try running this code without the <code>wandb_callback</code> and check if the same error raises? Thanks!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-03T12:37:13.531Z",
				"Answer_body": "<p>Hi Susanne,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-06T19:42:33.884Z",
				"Answer_body": "<p>Due to several code fixes I am no longer able to reproduce the original error.  Right now my training crashes with an error:</p>\n<p>\u201c\u201d\"<br>\nwandb.termwarn(   \u201cNo validation_data set, pass a generator to the callback.\u201d<br>\n\u201c\u201d\"</p>\n<p>If I run the code without the wandb callback everything runs fine. My suspicion is that this is due to the fact that I use tf.data to stream my data and not an ImageGenerator.</p>\n<p>Code with disabled callback is available here: <a href=\"https://github.com/subrockmann/tiny_cnn/blob/master/Experiment%20Workbench.ipynb\" rel=\"noopener nofollow ugc\">https://github.com/subrockmann/tiny_cnn/blob/master/Experiment%20Workbench.ipynb</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-07T16:59:59.018Z",
				"Answer_body": "<p>Hi Susanne,</p>\n<p>Thanks for your answer! I cannot access the code since I am not able to find <code>tiny_cnn</code> in your profile, could you share if it is private or send me a code snippet please? Thanks!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-10T09:44:47.244Z",
				"Answer_body": "<p>Hi Susanne,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-05T19:42:54.343Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Uploadding seems never stop",
		"Question_link": "https://community.wandb.ai/t/uploadding-seems-never-stop/3379",
		"Question_created_time": "2022-11-04T10:50:12.707Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 171,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>When I finished my code or shut it by ctrl+c,The terminal will prompt that the upload is in progress, but it will last for a long time, as if it will not end.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/3/343b92e6ac8a17b1091ce6676845df22dffecfca.png\" data-download-href=\"/uploads/short-url/7s4sOJkQ3ydppUBxeHzteVX9AVA.png?dl=1\" title=\"1667558977574\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/3/343b92e6ac8a17b1091ce6676845df22dffecfca.png\" alt=\"1667558977574\" data-base62-sha1=\"7s4sOJkQ3ydppUBxeHzteVX9AVA\" width=\"690\" height=\"72\" data-dominant-color=\"E4DDCE\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">1667558977574</span><span class=\"informations\">1005\u00d7105 14.3 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-09T05:55:51.094Z",
				"Answer_body": "<p>Hi lhiker,</p>\n<p>Thank you for reaching out. Would it be possible for you to share the <code>debug.log</code> and <code>debug-internal.log</code> files associated to the run where you see this? They should be present in a folder of the format <code>wandb/run-DATETIME-RUN_ID/logs</code> relative to your working directory.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-14T13:20:17.201Z",
				"Answer_body": "<p>Hi lhiker,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-17T15:46:31.030Z",
				"Answer_body": "<p>Hi lhiker, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-03T10:51:17.897Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Log_code not working with hydra",
		"Question_link": "https://community.wandb.ai/t/log-code-not-working-with-hydra/3276",
		"Question_created_time": "2022-10-18T11:07:01.890Z",
		"Question_answer_count": 14,
		"Question_score_count": 0,
		"Question_view_count": 956,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello to all,</p>\n<p>I am new here.  I would like to  save my files to the wandb experiment .<br>\nThis was also working before I used hydra. Since Hydra is changing the run dir.<br>\nI also adapted the  wandb.run.log_code(root=) to the where files are.<br>\nStill not working.<br>\nHas someone an Idea How to fix it</p>\n<p>Thank you very much<br>\nBest regards<br>\nChris</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-18T12:20:30.169Z",
				"Answer_body": "<p>Hi Chris,</p>\n<p>Thanks for writing in! I was wondering if you could send me a code snippet and so I can see how are you trying to save your files. Also, here is our documentation on how to integrate Hydra with wandb, may it help you?</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-18T14:38:48.604Z",
				"Answer_body": "<blockquote>\n<p>Blockquote<br>\nrun_name = cfg.details.run_name + f\"{cfg.name}_{cfg.details.job_type}<em>seed</em>{cfg.seed}\"<br>\nimport wandb<br>\nwandb.init(<br>\nproject=\u201cmaster_lab_irl\u201d,<br>\nname=run_name,<br>\nsync_tensorboard=True,<br>\nmonitor_gym=True,<br>\nsave_code=True,<br>\nsettings=wandb.Settings(code_dir=\u201c/home/l-oktober/lab_master/src/inverse_rl/\u201d),<br>\njob_type=cfg.details.job_type,<br>\n)</p>\n</blockquote>\n<pre><code>    wandb.run.log_code(root= \"/home/l-/oktober/lab_master/src/inverse_rl/\")\n</code></pre>\n<p>Without Hydra I did  wandb.run.log_code((\u201c.\u201d)  and it worked<br>\nI had a look at the documentation but havent found something</p>\n<p>Thank you for your help</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-20T10:12:06.568Z",
				"Answer_body": "<p>Do you need more Information ?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-20T16:56:29.603Z",
				"Answer_body": "<p>Hi Chris,</p>\n<p>Sorry for my late response! I am having some troubles trying to reproduce this issue. I have found a more detail guide here and a complete hydra example here. Please let me know if this would be useful. I will keep trying to reproduce this issue. Thanks!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-20T18:58:38.395Z",
				"Answer_body": "<p>Hi Luis,</p>\n<p>where can I find this example ?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-20T19:36:52.970Z",
				"Answer_body": "<p>I found some but all are without saving the code (all .py files)</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-21T16:09:10.643Z",
				"Answer_body": "<p>Hi Chris,</p>\n<p>Thanks for your patience! I\u2019ve been able to investigate this in depth and reproduce the issue. Just to confirm that you are having the same behaviour:</p>\n<ul>\n<li>First I have run a simple code and <code>run.log_code()</code> is saving the <code>.py</code> file in the desired folder and uploading an artifact</li>\n<li>When I have integrated hydra, the <code>.py</code> file is not saved in the <code>root</code> argument directory and the artifact is not uploaded to W&amp;B.<br>\nCould you confirm me if you are experiencing the same issue and so I will report this?</li>\n</ul>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-23T15:53:41.997Z",
				"Answer_body": "<p>yes it seems that wandb save the files in the   wandb.root or similar<br>\nand this is by hydra a different dir then the  dir the .py is run .<br>\nif I do wandb.run.log_code(root= ) and change it to the orginal dir where the .py files are its still not working.<br>\nIt seems that is because wandb gets the wandb.root with os  current dir and this false.<br>\nAnd I tried to change it but its not working<br>\nMaybe you can help me ( and are able to follow me)<br>\nthanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-26T12:35:32.772Z",
				"Answer_body": "<p>yes so its not possible to make a quick  fix ?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-27T11:50:03.653Z",
				"Answer_body": "<p>Hi Chris,</p>\n<p>Thanks for answering back! I have gone through our entire conversation again and I think I have been able to solve this issue. I am running a code like this in <code>main.py</code> file:</p>\n<pre><code>import hydraimport omegaconfimport wandb@hydra.main(config_path=\"configs/\", config_name=\"defaults\")def run_experiment(cfg: omegaconf.DictConfig) -&gt; None: with wandb.init(entity=cfg.wandb.entity, project=cfg.wandb.project) as run: for i in range(5): run.log({'accuracy':i}) run.log_code(root=cfg.wandb.dir)run_experiment()\n</code></pre>\n<p>And my <code>defaults.yaml</code> config file is like:</p>\n<pre><code>---wandb: project: project_name entity: entity_name dir: &lt;folder where main.py is&gt;\n</code></pre>\n<p>And I can see inside my artifacts tab, in the files page, the <code>main.py</code> file. Could you share is there is something different in your workflow? Also, if this is still not working for you, a workaround may be creating a new artifact and adding your <code>.py</code> files with <code>add_file</code> (docs here). Please let me know if this would be useful. Thanks!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-02T09:25:02.096Z",
				"Answer_body": "<p>Hi Chris,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-04T10:10:19.112Z",
				"Answer_body": "<p>sorry I did somehow did not see that you answered me<br>\nThank you very much for your answer and yes it works<br>\nThe code its not where it was used to be but it a qiuck fix</p>\n<p>THank you very much and<br>\nPlease keep up your great work</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-04T10:19:27.773Z",
				"Answer_body": "<p>Hi Chris,</p>\n<p>No worries at all! Great to know that this code is working for you snd thank you very much for the kind words. May I help you in any other way?</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-03T10:11:08.380Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Experiment tracking for multiple ML models using mlflow in a single main evaluation",
		"Question_link": "https://community.wandb.ai/t/experiment-tracking-for-multiple-ml-models-using-mlflow-in-a-single-main-evaluation/3340",
		"Question_created_time": "2022-10-28T13:58:30.304Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 333,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Could you, in your experience, show an article or an experiment tracking example and only version \u201cMulti-independent models, but one input-&gt; multiple models-&gt; one output\u201d to get a single main score and conveniently compare sub-scores? see an example project in the diagram:</p>\n<p><strong><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/2d4287f78a095ed787cb30539b2a40edaf8c7aaa.png\" data-download-href=\"/uploads/short-url/6so1LjTa7qTKo5LoyNfMyNuc6vM.png?dl=1\" title=\"\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/2d4287f78a095ed787cb30539b2a40edaf8c7aaa_2_602x227.png\" alt=\"\" data-base62-sha1=\"6so1LjTa7qTKo5LoyNfMyNuc6vM\" width=\"602\" height=\"227\" role=\"presentation\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/2d4287f78a095ed787cb30539b2a40edaf8c7aaa_2_602x227.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/2d4287f78a095ed787cb30539b2a40edaf8c7aaa_2_903x340.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/2d4287f78a095ed787cb30539b2a40edaf8c7aaa_2_1204x454.png 2x\" data-dominant-color=\"EBD6DA\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\"></span><span class=\"informations\">1600\u00d7604 213 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></strong></p>\n<p>I understand and tried to use W&amp;B, MLFlow, DVC,  Neptune. ai, DagsHub for only one model, but I\u2019m not sure one is convenient to use for multi-independent models. I also did not find it in Google for the approximate phrase \u201cML tracking experiment and management for multi models\u201d</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-31T21:42:01.007Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/yayay\">@yayay</a> , thank you for the question. As you intend to train multiple models at once, our recommended approach to this is utilize multiple projects where for each, each models experimental is tracked. You could track the same model within the projects using artifacts. See our <a href=\"https://docs.wandb.ai/guides/data-and-model-versioning/model-versioning\">document</a> for model versioning tips.  Please let me know if you have any questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-03T17:52:01.867Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> , thanks for the answer. I will carefully read, do and still answer you:)</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-03T19:26:10.685Z",
				"Answer_body": "<p>Thank you for the update <a class=\"mention\" href=\"/u/yayay\">@yayay</a> , I will mark this resolved for now but please do re open the conversation if you need to.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-02T19:26:39.421Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Adding tags cause internal server error",
		"Question_link": "https://community.wandb.ai/t/adding-tags-cause-internal-server-error/3363",
		"Question_created_time": "2022-11-01T21:33:23.355Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 240,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Adding tags to any project in my account will cause an internal server error. Is there an outage or it\u2019s something specific to my account?</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://wandb.ai/cchi/tags_test_project\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/18b592222b97bc09df3743831bb4929dec23611c.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https://wandb.ai/cchi/tags_test_project\" target=\"_blank\" rel=\"noopener\">W&amp;B</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/7/7e3d01bfbb9f37b8c9af3076e9688c9bef1b6347.png\" class=\"thumbnail onebox-avatar\" width=\"120\" height=\"120\">\n\n<h3><a href=\"https://wandb.ai/cchi/tags_test_project\" target=\"_blank\" rel=\"noopener\">cchi</a></h3>\n\n  <p>Weights &amp; Biases, developer tools for machine learning</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/a924869568d0c7ad73ea9c46361492d6a4827051.png\" data-download-href=\"/uploads/short-url/o8iWO0KA8b01xdqNjqP8vCU1eUh.png?dl=1\" title=\"Screen Shot 2022-11-01 at 5.32.04 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/a924869568d0c7ad73ea9c46361492d6a4827051_2_690x258.png\" alt=\"Screen Shot 2022-11-01 at 5.32.04 PM\" data-base62-sha1=\"o8iWO0KA8b01xdqNjqP8vCU1eUh\" width=\"690\" height=\"258\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/a924869568d0c7ad73ea9c46361492d6a4827051_2_690x258.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/a924869568d0c7ad73ea9c46361492d6a4827051.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/a924869568d0c7ad73ea9c46361492d6a4827051.png 2x\" data-dominant-color=\"FBF3F4\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-11-01 at 5.32.04 PM</span><span class=\"informations\">789\u00d7296 13.7 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-02T04:20:49.066Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/cchi\">@cchi</a>,</p>\n<p>Could you try adding your tags once again? We were running into some site issues earlier today but they should be resolved now.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-11-02T15:09:59.413Z",
				"Answer_body": "<p>Thanks Ramit! Yes the problem has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-01T15:10:01.503Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "W&B Outage? 11/1/2022",
		"Question_link": "https://community.wandb.ai/t/w-b-outage-11-1-2022/3360",
		"Question_created_time": "2022-11-01T20:15:54.242Z",
		"Question_answer_count": 7,
		"Question_score_count": 3,
		"Question_view_count": 105,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hello,</p>\n<p>I was wondering if anybody from the W&amp;B team can confirm that there is an outage at the moment.</p>\n<p>I\u2019ve been having issues starting runs and it seems like other folks are having issues syncing runs with a network time out error (<a href=\"https://github.com/wandb/wandb/issues/4424\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">[CLI]: canno't sync my runs \u00b7 Issue #4424 \u00b7 wandb/wandb \u00b7 GitHub</a>). It\u2019s been ongoing for about 2 hours now.</p>\n<p>The status page is saying everything is fine - <a href=\"https://status.wandb.com\" rel=\"noopener nofollow ugc\">https://status.wandb.com</a></p>\n<p>All the best,<br>\nAlexey</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-01T20:26:23.885Z",
				"Answer_body": "<p>I had the same issue with sync and network communications at the moment.</p>\n<p>Best,<br>\nHang</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-01T20:48:07.453Z",
				"Answer_body": "<p>Hi, thank you for bringing this up! We are aware of this issue and our engineers are currently working on fixing this. I\u2019ll respond here once I receive an update from them</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-01T21:05:12.982Z",
				"Answer_body": "<p>Thanks for confirming!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-01T22:51:30.214Z",
				"Answer_body": "<p>Thank you for your patience! Our engineers were able to push a fix for this. There\u2019s still currently an issue regarding batch moving runs, but for the most part this issue has been resolved.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-11-02T14:42:36.452Z",
				"Answer_body": "<p>Thank you <a class=\"mention\" href=\"/u/lesliewandb\">@lesliewandb</a> - I can confirm everything is working properly on my end now.</p>\n<p>Best,<br>\nAlexey</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-07T19:28:02.033Z",
				"Answer_body": "<p>That\u2019s great! I\u2019ll close out this ticket now, and I hope you have a beautiful week <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2023-01-01T14:42:57.437Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "InitStartError: Error communicating with wandb process",
		"Question_link": "https://community.wandb.ai/t/initstarterror-error-communicating-with-wandb-process/3015",
		"Question_created_time": "2022-08-27T12:03:04.434Z",
		"Question_answer_count": 33,
		"Question_score_count": 0,
		"Question_view_count": 730,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>My code run well on wandb 0.12.21, but after I upgrade to the latest version, my code gave me this error <code>InitStartError: Error communicating with wandb process</code>. I tried the solution in the document but it doesn\u2019t work. Code is as shown below.</p>\n<pre><code class=\"lang-python\">def k_fold(config, log_folder=None, log_init_info=None):\n    \"\"\"\n    Performs a  k-fold cross validation.\n\n    Args:\n        config (Config): Parameters.\n        log_folder (None or str, optional): Folder to logs results to. Defaults to None.\n        log_init_info (None or dict, optional): Dictionary to init wandb logging.\n    \"\"\"\n    scores = []\n    nb_folds = 5\n\n    # Data preparation\n    print(\"Creating in-memory dataset ...\")\n\n    start_time = time.time()\n\n    in_mem_dataset = InMemoryTrainDataset(\n        train_tile_size=config.tile_size,\n        reduce_factor=config.reduce_factor,\n        train_transfo=HE_preprocess(size=config.tile_size),\n        valid_transfo=HE_preprocess(augment=False, size=config.tile_size),\n        train_path=config.train_path,\n        iter_per_epoch=config.iter_per_epoch,\n        on_spot_sampling=config.on_spot_sampling,\n        pl_path=config.pl_path,\n        use_pl=config.use_pl,\n        test_path=config.test_path,\n    )\n    print(f\"Done in {time.time() - start_time :.0f} seconds.\")\n\n    for i in config.selected_folds:\n        print(f\"\\n-------------   Fold {i + 1} / {nb_folds}  -------------\\n\")\n\n        # Init logging\n        if not DEBUG:\n            print(f\"    -&gt; Init wandb logging with name {log_init_info['name_head']}_fold{i + 1} ...\")\n            wandb.init(\n                project=PROJECT_NAME,\n                name=f\"{log_init_info['name_head']}_fold{i + 1}\",\n                config=log_init_info['config'],\n            )\n\n        meter, history, model = train(config, in_mem_dataset, i, log_folder=log_folder)\n\n        print(\"\\n    -&gt; Validating \\n\")\n\n        val_images = in_mem_dataset.valid_set\n        scores += validate(model, config, val_images)\n\n        if log_folder is not None:\n            history.to_csv(log_folder + f\"history_{i}.csv\", index=False)\n\n        if log_folder is None or len(config.selected_folds) == 1:\n            return meter\n\n        if not DEBUG:\n            wandb.finish()\n\n        # Garbage collect\n        del meter\n        del model\n        torch.cuda.empty_cache()\n        gc.collect()\n\n    print(f\"\\n\\n  -&gt;  Dice CV : {np.mean(scores) :.3f}  +/- {np.std(scores) :.3f}\")\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-31T09:35:40.781Z",
				"Answer_body": "<p>Hi Tiny, thanks for writing! Could you please confirm me if you are still having the same error? If so, are you using the 0.13.2 wandb version?</p>\n<p>Could you specify if you are having this error in Colab?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-31T09:49:16.732Z",
				"Answer_body": "<p>Yes, the issue remains. And yes I\u2019m having this trouble when using version 0.13.2. But, not in Colab, instead I encountered this on my local jupyter lab server.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-01T16:33:36.656Z",
				"Answer_body": "<p>Hi Tianyi, thanks for clarifying! Could you please send me the piece of code where you are using <code>wandb.login()</code>?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-02T02:33:17.562Z",
				"Answer_body": "<p>This successful running uses the same code that went wrong but with a lower version of wands as mentioned before. <a href=\"https://gist.github.com/NPU-Franklin/f17e1c1875a127df3e82313049e12d92\" rel=\"noopener nofollow ugc\">https://gist.github.com/NPU-Franklin/f17e1c1875a127df3e82313049e12d92</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-02T09:14:47.969Z",
				"Answer_body": "<p>Hi Tianyi, thanks for your answer! Could you please provide the debug logs files, <code>debug-internal.log</code> and <code>debug.log</code>? You can find them in <code>wandb/run-id/logs</code></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-02T10:53:16.712Z",
				"Answer_body": "<p>Currently, I\u2019ve downgraded my wandb and deleted all failed runs\u2019 logs. I will reproduce the error tomorrow. Thanks a lot.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-02T13:41:48.461Z",
				"Answer_body": "<p>run-20220902_211617-2saiqpw0/debug.log: <a href=\"https://pastebin.ubuntu.com/p/hTYgSXFpY8/\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Ubuntu Pastebin</a><br>\nrun-20220902_211617-2saiqpw0/debug-internal.log: <a href=\"https://pastebin.ubuntu.com/p/Z6DSsRsKvj/\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Ubuntu Pastebin</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-02T13:42:29.814Z",
				"Answer_body": "<p>run-20220902_212941-tt7k9b3u/debug.log: <a href=\"https://pastebin.ubuntu.com/p/NRD7xMbWdP/\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Ubuntu Pastebin</a><br>\nrun-20220902_212941-tt7k9b3u/debug-internal.log: <strong>haven\u2019t generated</strong></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-02T13:47:29.894Z",
				"Answer_body": "<p>The above are the two runs that triggered the error. The bug occurred in the second run(run-20220902_212941-tt7k9b3u) which was right after the first run(run-20220902_211617-2saiqpw0) finished.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-02T16:47:44.298Z",
				"Answer_body": "<p>Hi Tianyi! Thanks for the files! In the second run the <code>debug-internal.log</code> hasn\u2019t been generated, could you try sending it again please? Also, could you send me your python file and so I will try to reproduce this error on my end?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-03T01:57:56.152Z",
				"Answer_body": "<p>Thanks for the quick reply. The second run\u2019s <code>debug-internal.log</code> file literally hasn\u2019t been generated, wandb corrupted before it can generate this file. Sorry for the misleading words. And you can find my python file at <a href=\"https://drive.google.com/file/d/15sGc2Jg1pEu7Lilrq8J1L0w4Qa54ldN2/view?usp=sharing\" rel=\"noopener nofollow ugc\">google drive</a>. The main training notebook is at CSMMI/notebooks/Training.ipynb.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-06T15:52:18.203Z",
				"Answer_body": "<p>Hi Tianyi, thanks for the information and for your patience! I need to ask some internal questions and will get back to you then</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-07T14:18:53.952Z",
				"Answer_body": "<p>Thank you for all the help, no need to hurry.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-07T16:01:37.102Z",
				"Answer_body": "<p>Hi Tianyi, thanks for your patience!! I\u2019ve been revising your code and have some questions:</p>\n<ul>\n<li>Are you using wandb Local?</li>\n<li>I assume that the solution in the documentation you are using is this: <code>wandb.init(settings=wandb.Settings(start_method=\"fork\"))</code>. If so, have you tried both methods, fork and thread? Are they raising the same error message?</li>\n<li>You mentioned that you have downgraded wandb, was the error still occurring after this downgrade?</li>\n<li>I see that, in your notebook, you first run in a cell <code>wandb.login()</code>, which seems to be working fine and then in a following cell you call your <code>k_fold</code> function, where <code>wandb.init()</code> is used. Is the error raising in this cell? Could you send me a screenshot of this error? What happens if you don\u2019t run the <code>wandb.login()</code> cell?</li>\n</ul>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-08T04:06:28.433Z",
				"Answer_body": "<p>Thank you for your reply. For all the questions:</p>\n<ul>\n<li>No, I am using the online mode. But I also tried to run my code under the offline mode, and the error still existed.</li>\n<li>I tried both solutions and they didn\u2019t work.</li>\n<li>After being downgraded, my code worked fine. No error message.</li>\n<li>Yes, the error occurred in the cell where I called the <code>k_fold</code> function. The error message should be stored in the notebook I sent you. And I have already login to wandb through the console, so <code>wandb.login()</code> is used for making sure that I am still logging in. If you want me to try to run without the <code>wandb.login()</code> cell, please tell me and I will give it a try.</li>\n</ul>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-08T07:45:39.339Z",
				"Answer_body": "<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/e32a03c633cb4e45d0d96a1138224abd18ed5ff0.png\" data-download-href=\"/uploads/short-url/wpAoV9eAiP8dCIMq1wspMZohzaw.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e32a03c633cb4e45d0d96a1138224abd18ed5ff0_2_690x403.png\" alt=\"image\" data-base62-sha1=\"wpAoV9eAiP8dCIMq1wspMZohzaw\" width=\"690\" height=\"403\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e32a03c633cb4e45d0d96a1138224abd18ed5ff0_2_690x403.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e32a03c633cb4e45d0d96a1138224abd18ed5ff0_2_1035x604.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e32a03c633cb4e45d0d96a1138224abd18ed5ff0_2_1380x806.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e32a03c633cb4e45d0d96a1138224abd18ed5ff0_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1400\u00d7819 69.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-09T16:15:06.422Z",
				"Answer_body": "<p>Hi Tianyi, thanks for your patience! I\u2019ve escalated this issue to our Engineering Team, thanks for reporting it!<br>\nEven so, there are a few things that could solve it:</p>\n<pre><code>- Could you try setting `WANDB_DISABLE_SETTING=True`? This would disable \u2018service\u2019 which uses tcp sockets instead of grpc. This is usually desirable because grpc is not fork safe and introduces overhead in many same node cases.\n- Could you try to reset the environment and run the code again and see if the error is still occurring?\n- Could you try with a lower version than 0.13.2 (0.13.1 for example)?\n</code></pre>\n<p>Thanks for your help!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-10T01:27:14.881Z",
				"Answer_body": "<p>Happy to help! I will try these out and come back to you later.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-13T07:08:09.732Z",
				"Answer_body": "<ul>\n<li>First, after I set <code>os.environ[\"WANDB_DISABLE_SETTING\"] = 'True'</code> (Am I doing this right?), it didn\u2019t work.</li>\n<li>Second, I don\u2019t have enough space to create a new clean environment. Very sorry for that.</li>\n<li>Third, I tried versions <code>0.13.3</code>, <code>0.13.1</code> and <code>0.13.0</code>, and they all failed.</li>\n</ul>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "WandB and AWS Lambda",
		"Question_link": "https://community.wandb.ai/t/wandb-and-aws-lambda/3354",
		"Question_created_time": "2022-11-01T07:47:58.824Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 565,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>We\u2019re trying to run WandB (0.13.4) in an AWS Lambda with Python 3.9.  We have set an environment variable for our API Key.  But we are getting this error message from Lambda:</p>\n<pre><code class=\"lang-auto\">{\n  \"errorMessage\": \"Error communicating with wandb process\",\n  \"errorType\": \"UsageError\",\n  \"requestId\": \"0b6c4576-adbe-4182-826a-eca4dd06bc6f\",\n  \"stackTrace\": [\n    \"  File \\\"/var/task/lambda_monitor.py\\\", line 73, in test_harness\\n    run  = wandb.init(project= WB_PROJECT,\\n\",\n    \"  File \\\"/var/task/wandb/sdk/wandb_init.py\\\", line 1078, in init\\n    run = wi.init()\\n\",\n    \"  File \\\"/var/task/wandb/sdk/wandb_init.py\\\", line 719, in init\\n    raise UsageError(error_message)\\n\"\n  ]\n}\n</code></pre>\n<p>The calling code is this:</p>\n<pre><code class=\"lang-auto\">    run  = wandb.init(project= WB_PROJECT,\n                      id     = WB_RUN_ID,  # We force the run to continue with the specific monitoring Run ID\n                      resume = True,\n                      settings=wandb.Settings(start_method=\"fork\"))\n</code></pre>\n<p>And this error message from CloudWatch:</p>\n<pre><code class=\"lang-auto\">wandb: WARNING Path /var/task/wandb/ wasn't writable, using system temp directory.\nOpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k\nwandb: WARNING Path /var/task/wandb/ wasn't writable, using system temp directory\nwandb: W&amp;B API key is configured. Use `wandb login --relogin` to force relogin\nTraceback (most recent call last):\nFile \"/var/lang/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\nreturn _run_code(code, main_globals, None,\nFile \"/var/lang/lib/python3.9/runpy.py\", line 87, in _run_code\nexec(code, run_globals)\nFile \"/var/task/wandb/__main__.py\", line 3, in &lt;module&gt;\ncli.cli(prog_name=\"python -m wandb\")\nFile \"/var/task/click/core.py\", line 1130, in __call__\nreturn self.main(*args, **kwargs)\nFile \"/var/task/click/core.py\", line 1055, in main\nrv = self.invoke(ctx)\nFile \"/var/task/click/core.py\", line 1657, in invoke\nreturn _process_result(sub_ctx.command.invoke(sub_ctx))\nFile \"/var/task/click/core.py\", line 1404, in invoke\nreturn ctx.invoke(self.callback, **ctx.params)\nFile \"/var/task/click/core.py\", line 760, in invoke\nreturn __callback(*args, **kwargs)\nFile \"/var/task/wandb/cli/cli.py\", line 97, in wrapper\nreturn func(*args, **kwargs)\nFile \"/var/task/wandb/cli/cli.py\", line 282, in service\nserver.serve()\nFile \"/var/task/wandb/sdk/service/server.py\", line 142, in serve\nmux.loop()\nFile \"/var/task/wandb/sdk/service/streams.py\", line 394, in loop\nraise e\nFile \"/var/task/wandb/sdk/service/streams.py\", line 392, in loop\nself._loop()\nFile \"/var/task/wandb/sdk/service/streams.py\", line 385, in _loop\nself._process_action(action)\nFile \"/var/task/wandb/sdk/service/streams.py\", line 350, in _process_action\nself._process_add(action)\nFile \"/var/task/wandb/sdk/service/streams.py\", line 203, in _process_add\nstream = StreamRecord(action._data, mailbox=self._mailbox)\nFile \"/var/task/wandb/sdk/service/streams.py\", line 61, in __init__\nself._record_q = multiprocessing.Queue()\nFile \"/var/lang/lib/python3.9/multiprocessing/context.py\", line 103, in Queue\nreturn Queue(maxsize, ctx=self.get_context())\nFile \"/var/lang/lib/python3.9/multiprocessing/queues.py\", line 43, in __init__\nself._rlock = ctx.Lock()\nFile \"/var/lang/lib/python3.9/multiprocessing/context.py\", line 68, in Lock\nreturn Lock(ctx=self.get_context())\nFile \"/var/lang/lib/python3.9/multiprocessing/synchronize.py\", line 162, in __init__\nSemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx)\nFile \"/var/lang/lib/python3.9/multiprocessing/synchronize.py\", line 57, in __init__\nsl = self._semlock = _multiprocessing.SemLock(\nOSError: [Errno 38] Function not implemented\nwandb: - Waiting for wandb.init()...\nwandb: \\ Waiting for wandb.init()...\nwandb: | Waiting for wandb.init()...\nwandb: / Waiting for wandb.init()...\nwandb: - Waiting for wandb.init()...\nwandb: \\ Waiting for wandb.init()...\nwandb: | Waiting for wandb.init()...\nwandb: / Waiting for wandb.init()...\nwandb: - Waiting for wandb.init()...\nwandb: \\ Waiting for wandb.init()...\nwandb: | Waiting for wandb.init()...\nwandb: / Waiting for wandb.init()...\nwandb: - Waiting for wandb.init()...\nwandb: \\ Waiting for wandb.init()...\nwandb: | Waiting for wandb.init()...\nwandb: / Waiting for wandb.init()...\nwandb: - Waiting for wandb.init()...\nwandb: \\ Waiting for wandb.init()...\nwandb: | Waiting for wandb.init()...\nwandb: / Waiting for wandb.init()...\nwandb: - Waiting for wandb.init()...\nwandb: \\ Waiting for wandb.init()...\nwandb: | Waiting for wandb.init()...\nwandb: / Waiting for wandb.init()...\nwandb: - Waiting for wandb.init()...\nwandb: \\ Waiting for wandb.init()...\nwandb: | Waiting for wandb.init()...\nwandb: / Waiting for wandb.init()...\nwandb: - Waiting for wandb.init()...\nwandb: \\ Waiting for wandb.init()...\nwandb: | Waiting for wandb.init()...\nwandb: / Waiting for wandb.init()...\nwandb: - Waiting for wandb.init()...\nwandb: \\ Waiting for wandb.init()...\nwandb: | Waiting for wandb.init()...</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-01T07:53:50.760Z",
				"Answer_body": "<p>I added the additional Environment Variables as mentioned by <code>Akshey</code> (<a href=\"https://community.wandb.ai/t/integration-of-wandb-with-aws-lambda/2280\">here</a>):</p>\n<pre><code class=\"lang-auto\">WANDB_CACHE_DIR= /tmp/\nWANDB_CONFIG_DIR=/tmp/\nWANDB_DIR=/tmp/\nWANDB_SILENT=true\n</code></pre>\n<p>And the Cloudwatch log becomes:</p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\nFile \"/var/lang/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\nreturn _run_code(code, main_globals, None,\nFile \"/var/lang/lib/python3.9/runpy.py\", line 87, in _run_code\nexec(code, run_globals)\nFile \"/var/task/wandb/__main__.py\", line 3, in &lt;module&gt;\ncli.cli(prog_name=\"python -m wandb\")\nFile \"/var/task/click/core.py\", line 1130, in __call__\nreturn self.main(*args, **kwargs)\nFile \"/var/task/click/core.py\", line 1055, in main\nrv = self.invoke(ctx)\nFile \"/var/task/click/core.py\", line 1657, in invoke\nreturn _process_result(sub_ctx.command.invoke(sub_ctx))\nFile \"/var/task/click/core.py\", line 1404, in invoke\nreturn ctx.invoke(self.callback, **ctx.params)\nFile \"/var/task/click/core.py\", line 760, in invoke\nreturn __callback(*args, **kwargs)\nFile \"/var/task/wandb/cli/cli.py\", line 97, in wrapper\nreturn func(*args, **kwargs)\nFile \"/var/task/wandb/cli/cli.py\", line 282, in service\nserver.serve()\nFile \"/var/task/wandb/sdk/service/server.py\", line 142, in serve\nmux.loop()\nFile \"/var/task/wandb/sdk/service/streams.py\", line 394, in loop\nraise e\nFile \"/var/task/wandb/sdk/service/streams.py\", line 392, in loop\nself._loop()\nFile \"/var/task/wandb/sdk/service/streams.py\", line 385, in _loop\nself._process_action(action)\nFile \"/var/task/wandb/sdk/service/streams.py\", line 350, in _process_action\nself._process_add(action)\nFile \"/var/task/wandb/sdk/service/streams.py\", line 203, in _process_add\nstream = StreamRecord(action._data, mailbox=self._mailbox)\nFile \"/var/task/wandb/sdk/service/streams.py\", line 61, in __init__\nself._record_q = multiprocessing.Queue()\nFile \"/var/lang/lib/python3.9/multiprocessing/context.py\", line 103, in Queue\nreturn Queue(maxsize, ctx=self.get_context())\nFile \"/var/lang/lib/python3.9/multiprocessing/queues.py\", line 43, in __init__\nself._rlock = ctx.Lock()\nFile \"/var/lang/lib/python3.9/multiprocessing/context.py\", line 68, in Lock\nreturn Lock(ctx=self.get_context())\nFile \"/var/lang/lib/python3.9/multiprocessing/synchronize.py\", line 162, in __init__\nSemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx)\nFile \"/var/lang/lib/python3.9/multiprocessing/synchronize.py\", line 57, in __init__\nsl = self._semlock = _multiprocessing.SemLock(\nOSError: [Errno 38] Function not implemented\nProblem at: /var/task/lambda_monitor.py 73 test_harness[DEBUG]\t2022-11-01T07:51:38.952Z\tb1a9ad4c-e05a-40d4-b2cb-14eaa17be2c0\tStarting new HTTPS connection (1): o151352.ingest.sentry.io:443\n[ERROR] UsageError: Error communicating with wandb process\nTraceback (most recent call last):\n  File \"/var/task/lambda_monitor.py\", line 73, in test_harness\n    run  = wandb.init(project= WB_PROJECT,\n  File \"/var/task/wandb/sdk/wandb_init.py\", line 1078, in init\n    run = wi.init()\n  File \"/var/task/wandb/sdk/wandb_init.py\", line 719, in init\n    raise UsageError(error_message)</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-02T19:49:24.829Z",
				"Answer_body": "<p>Hi Leslie,<br>\nAny updates?</p>\n<p>Kevin A. Shaw, Ph.D.<br>\nCTO / CoFounder  |   Algorithmic Intuition Inc<br>\n<a href=\"http://www.algorithmicintuition.com\" class=\"onebox\" target=\"_blank\" rel=\"noopener nofollow ugc\">www.algorithmicintuition.com</a><br>\n<a href=\"mailto:kevin@algoint.com\">kevin@algoint.com</a>   |  Twitter: <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-03T18:23:55.391Z",
				"Answer_body": "<p>Hi Kevin, thank you for your patience! From your logs it looks like you are trying to use multiprocessing with AWS Lambda. AWS lambda doesn\u2019t have a shared memory folder hence why you\u2019re running into this issue. You can try to use <code>spawn</code> instead of <code>fork</code> in your wandb init function but since this is due to AWS Lambda, it might not be able to help here</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-31T07:54:12.561Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to log configs except for configs that need to be tuned in w&b when I use ray tune for tuning",
		"Question_link": "https://community.wandb.ai/t/how-to-log-configs-except-for-configs-that-need-to-be-tuned-in-w-b-when-i-use-ray-tune-for-tuning/3076",
		"Question_created_time": "2022-09-06T19:14:51.603Z",
		"Question_answer_count": 9,
		"Question_score_count": 0,
		"Question_view_count": 170,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hallo! I want to log some configs that are not for tuning, for example, the name for datasets, and the name for different losses. When I call WandbLoggerCallback in tune.Tuner,  it turns out that only the hyperparameters that it tuned are logged, other configs are not there, even though I have called wandb.config[\u201clossfn\u201d] = \"cross_entropy \" at the beginning.</p>\n<p>for example, as you see that there is nothing in the columns dataset and lossfn.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/1351feeae05de6ac2eac8a7aa62014b8d737b5b1.jpeg\" data-download-href=\"/uploads/short-url/2KUKjJmSyAImPaso4ffQ0ZnBcsh.jpeg?dl=1\" title=\"Screenshot 2022-09-06 at 21.14.38\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1351feeae05de6ac2eac8a7aa62014b8d737b5b1_2_690x336.jpeg\" alt=\"Screenshot 2022-09-06 at 21.14.38\" data-base62-sha1=\"2KUKjJmSyAImPaso4ffQ0ZnBcsh\" width=\"690\" height=\"336\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1351feeae05de6ac2eac8a7aa62014b8d737b5b1_2_690x336.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1351feeae05de6ac2eac8a7aa62014b8d737b5b1_2_1035x504.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1351feeae05de6ac2eac8a7aa62014b8d737b5b1_2_1380x672.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1351feeae05de6ac2eac8a7aa62014b8d737b5b1_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2022-09-06 at 21.14.38</span><span class=\"informations\">1920\u00d7936 85.2 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-12T16:30:43.219Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ziwencheng\">@ziwencheng</a>, you may just need to call <code>wandb.run.update()</code>  after you update the config to set the config for the run. If that doesn\u2019t work could you should me the order in which you are setting the config and initializing the WandbLoggerCallback object?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-13T16:58:24.399Z",
				"Answer_body": "<p>Hi Nate, thanks for your reply. wanb.run.update() doesn\u2019t work. I only initialize the WandbLoggerCallback object in the tune.Tuner. The setting config is before the WandbLoggerCallback. I can show you the whole function.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/3ffad77b104a7d39f0bc8f86e6fb4c8a66dbf2c2.png\" data-download-href=\"/uploads/short-url/97ZvpaBquUOOytSM5apu62oXsH0.png?dl=1\" title=\"Screenshot 2022-09-13 at 18.57.19\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3ffad77b104a7d39f0bc8f86e6fb4c8a66dbf2c2_2_548x500.png\" alt=\"Screenshot 2022-09-13 at 18.57.19\" data-base62-sha1=\"97ZvpaBquUOOytSM5apu62oXsH0\" width=\"548\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3ffad77b104a7d39f0bc8f86e6fb4c8a66dbf2c2_2_548x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3ffad77b104a7d39f0bc8f86e6fb4c8a66dbf2c2_2_822x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3ffad77b104a7d39f0bc8f86e6fb4c8a66dbf2c2_2_1096x1000.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3ffad77b104a7d39f0bc8f86e6fb4c8a66dbf2c2_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2022-09-13 at 18.57.19</span><span class=\"informations\">1914\u00d71744 318 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-13T16:59:19.850Z",
				"Answer_body": "<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/6b137998aa3161e7e777cd8252e85a02b0f38c52.png\" data-download-href=\"/uploads/short-url/fheOub5Y58zSSzKSoC92fLLzHVw.png?dl=1\" title=\"Screenshot 2022-09-13 at 18.59.05\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/6b137998aa3161e7e777cd8252e85a02b0f38c52_2_575x500.png\" alt=\"Screenshot 2022-09-13 at 18.59.05\" data-base62-sha1=\"fheOub5Y58zSSzKSoC92fLLzHVw\" width=\"575\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/6b137998aa3161e7e777cd8252e85a02b0f38c52_2_575x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/6b137998aa3161e7e777cd8252e85a02b0f38c52_2_862x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/6b137998aa3161e7e777cd8252e85a02b0f38c52_2_1150x1000.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/6b137998aa3161e7e777cd8252e85a02b0f38c52_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2022-09-13 at 18.59.05</span><span class=\"informations\">1760\u00d71528 272 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-03T15:29:52.377Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/ziwencheng\">@ziwencheng</a>, it looks like we don\u2019t have a way to do this currently with our Ray integration. Could you possibly add the parameters to your search space but only as single values? This wouldn\u2019t affect your search space since they are single values but would log the config values to W&amp;B.</p>\n<p>If you\u2019d like I can put in a feature request for a more official way of doing this?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-07T14:09:39.979Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/ziwencheng\">@ziwencheng</a> I wanted to follow up and see if this worked for you and if you\u2019d like us to make a feature request around this?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-11T19:10:55.641Z",
				"Answer_body": "<p>hi\uff01Sorry for the late response! It still doesn\u2019t work. It would be great if you make a feature request of course! Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-27T13:53:48.069Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ziwencheng\">@ziwencheng</a>, sorry for the delay! I was able to get this to work by using <code>wandb.config.update(&lt;dictionary of config I'd like to add&gt;)</code>. I know we tried <code>run.update</code> but could you possibly try using <code>wandb.config.update()</code> instead of simply assigning the values to the config object?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-01T16:19:06.140Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/ziwencheng\">@ziwencheng</a>, I just wanted to bump this and see if you got a chance to try the above method of updating the config?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-31T16:19:57.576Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Best practice to store data artifacts",
		"Question_link": "https://community.wandb.ai/t/best-practice-to-store-data-artifacts/3326",
		"Question_created_time": "2022-10-26T06:34:29.132Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 292,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>What\u2019s best practice for storing data artifacts? Currently we store them as csvs but I was wondering if pickling them makes more sense or if anyone has any experience with the pros and cons of doing that.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-26T21:33:23.569Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/davidclarance\">@davidclarance</a> , thank you for writing in with your question.</p>\n<p>Artifacts are a versatile and expansive feature of our platform for your data versioning needs. We don\u2019t have a  \u2018best practices\u2019 guide as artifact use cases is unique to a users workflow. Our documents are extensive and highlight various use cases and examples of artifacts creation/logging, see <a href=\"https://docs.wandb.ai/guides/artifacts\">here</a>. Do you have a specific use case for wanting to pickle your csv file first?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-01T16:19:04.557Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/davidclarance\">@davidclarance</a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-31T16:19:57.541Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Modeling stochastic dorminance",
		"Question_link": "https://community.wandb.ai/t/modeling-stochastic-dorminance/3324",
		"Question_created_time": "2022-10-26T04:38:29.539Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 75,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Modeling stochastic dorminance</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-26T09:27:18.349Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/johns-ke\">@johns-ke</a> thank you for writing in! Could you please elaborate on your question so that we can provide further assistance?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-31T11:20:41.870Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/johns-ke\">@johns-ke</a> since we haven\u2019t heard back from you, I will go ahead and close this ticket for now. Once you could provide us more information about this request, we will reopen this discussion and investigate it further!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-30T11:20:45.603Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Hyperparameter search for RL(stable baseline3)",
		"Question_link": "https://community.wandb.ai/t/hyperparameter-search-for-rl-stable-baseline3/3349",
		"Question_created_time": "2022-10-31T08:26:21.913Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 333,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>It seems the hyperparameter search guide in documentation is catered for supervised setting. Is there any guide on adapting it to reinforcement learning setting, specifically stable baseline3?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-11-02T13:58:39.731Z",
				"Answer_body": "<p>Hi Zeyu Xhang,</p>\n<p>Thanks for your question! Here you have an article about sweeps with RL. Also, I was wondering if you could explain me exactly in which step are you having issues to create the sweep and so I can help you better. Thanks!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-07T16:09:59.737Z",
				"Answer_body": "<p>Hi Zeyu,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-30T08:27:02.346Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "BUG: Parallel coordinates Panel in Sweep",
		"Question_link": "https://community.wandb.ai/t/bug-parallel-coordinates-panel-in-sweep/3318",
		"Question_created_time": "2022-10-25T01:37:25.342Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 289,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>My Sweep config looks like this:</p>\n<pre><code class=\"lang-yaml\">parameters:\n  pretraining_run_name:\n    values: [ns4bedao, 6cnr8gb9, lo4f6pma, qiha6oci]\n</code></pre>\n<p>As you can see, some of their names start with decimal.<br>\nThis makes the Parallel coordinates Panel broken.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/6/671538bef4b0651502815871345bf48d5af62323.png\" data-download-href=\"/uploads/short-url/eHUE5Lsun9I9dgN8ekmT7ipoEvN.png?dl=1\" title=\"\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2022-10-25 \u110b\u1169\u110c\u1165\u11ab 10.36.11\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/6/671538bef4b0651502815871345bf48d5af62323_2_176x500.png\" alt=\"\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2022-10-25 \u110b\u1169\u110c\u1165\u11ab 10.36.11\" data-base62-sha1=\"eHUE5Lsun9I9dgN8ekmT7ipoEvN\" width=\"176\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/6/671538bef4b0651502815871345bf48d5af62323_2_176x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/6/671538bef4b0651502815871345bf48d5af62323_2_264x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/6/671538bef4b0651502815871345bf48d5af62323.png 2x\" data-dominant-color=\"FAF9FB\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2022-10-25 \u110b\u1169\u110c\u1165\u11ab 10.36.11</span><span class=\"informations\">320\u00d7906 34.6 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Is there any workaround that I can do immediately?<br>\nOr not, I wish this would be fixed as soon as possible.</p>\n<p>Thanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-25T04:30:25.438Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/jnzaaesly8\">@jnzaaesly8</a>,</p>\n<p>While there is no immediate workaround for this, I\u2019ll report this to our engineering team to look into this as soon as possible.</p>\n<p>Could you share a link for this sweep so that I can share it with our team?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-25T04:49:19.002Z",
				"Answer_body": "<p>Thanks for quick response, <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a> !</p>\n<p>Here is my Sweep just made for this issue!</p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://wandb.ai/jnzaaesly8/Parallel-coordinates/sweeps/i01uhar5\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/18b592222b97bc09df3743831bb4929dec23611c.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https://wandb.ai/jnzaaesly8/Parallel-coordinates/sweeps/i01uhar5\" target=\"_blank\" rel=\"noopener\">W&amp;B</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/1/1bcee9ffa36d37b5c0edfa97b82b44d28229f6bc.png\" class=\"thumbnail onebox-avatar\" width=\"120\" height=\"120\">\n\n<h3><a href=\"https://wandb.ai/jnzaaesly8/Parallel-coordinates/sweeps/i01uhar5\" target=\"_blank\" rel=\"noopener\">jnzaaesly8</a></h3>\n\n  <p>Weights &amp; Biases, developer tools for machine learning</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-30T23:49:28.039Z",
				"Answer_body": "<p>Thanks for the reproduction!</p>\n<p>I\u2019m creating a ticket for our engineering team to look into this right now and we will let you know once this is resolved.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-29T23:50:08.503Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Pattern in semantic mask logging above size (100, 100)",
		"Question_link": "https://community.wandb.ai/t/pattern-in-semantic-mask-logging-above-size-100-100/3248",
		"Question_created_time": "2022-10-13T10:38:11.125Z",
		"Question_answer_count": 8,
		"Question_score_count": 0,
		"Question_view_count": 301,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>When attempting to log masks above size 100 x 100, the masks display a strange pattern. What is the cause of this and is there a way to ensure the pattern does not appear?</p>\n<p>Here is a toy example comparing two random images of size (100,100) and (200,200), each with two masks of all 0s and all 1s. This is logged as:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/3/3ff3a0c1c12a405fd7df79bc00d059c4b35cd142.jpeg\" data-download-href=\"/uploads/short-url/97K3axa7Ka7PdrF85pXm22No2rw.jpeg?dl=1\" title=\"Screenshot 2022-10-13 at 03.30.15\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/3ff3a0c1c12a405fd7df79bc00d059c4b35cd142_2_690x414.jpeg\" alt=\"Screenshot 2022-10-13 at 03.30.15\" data-base62-sha1=\"97K3axa7Ka7PdrF85pXm22No2rw\" width=\"690\" height=\"414\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/3ff3a0c1c12a405fd7df79bc00d059c4b35cd142_2_690x414.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/3ff3a0c1c12a405fd7df79bc00d059c4b35cd142_2_1035x621.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/3/3ff3a0c1c12a405fd7df79bc00d059c4b35cd142_2_1380x828.jpeg 2x\" data-dominant-color=\"DBD3DA\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2022-10-13 at 03.30.15</span><span class=\"informations\">1920\u00d71152 209 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>These images were generated by the following:</p>\n<pre><code class=\"lang-auto\">import numpy as np\nimport wandb\n\nwandb.init()\nsizes = [100,200]\n\nfor size in sizes:\n    name = str(size)\n    image = np.random.randint(low=0, high=256, size=(size, size, 3), dtype=np.uint8)\n    predicted_mask = np.ones((size, size), dtype=np.uint8)\n    ground_truth_mask = np.zeros((size, size), dtype=np.uint8)\n    class_labels = {\n        0: \"class 0\",\n        1: \"class 1\",\n    }\n\n    masked_image = wandb.Image(image, masks={\n        \"predictions\": {\n            \"mask_data\": predicted_mask,\n            \"class_labels\": class_labels\n        },\n        \"ground_truth\": {\n            \"mask_data\": ground_truth_mask,\n            \"class_labels\": class_labels\n        }\n    })\n\n    wandb.log({name : masked_image})\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-13T19:25:45.309Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/rdorfman\">@rdorfman</a>, happy to help with your question. The output of logging the images is expected behavior due to sampling. Our backend will sample in a non-deterministically sparse approach. Please let us know if you have any additional questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-14T08:53:47.070Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a>,  thanks very much for your response. Could you please clarify</p>\n<ol>\n<li>\n<p>Is there any way to prevent/correct the sampling so that the masks are logged correctly</p>\n</li>\n<li>\n<p>Why this sampling is occurring</p>\n</li>\n</ol>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-19T18:55:38.372Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/rdorfman\">@rdorfman</a> , apologies my comment caused confusion, I was addressing the incorrect thread.</p>\n<p>To clarify, segmentation masks and bounding boxes are not randomly sampled by W&amp;B when logged to the workspace. The predictions are user generated and the input of the user to wandb is directly being logged. From the code example you provided, you are generating prediction masks  and class labels for each of the pixels in the image.  Your comment on \" masks display a strange pattern\", are you referring to the rendering of bounding boxes being represented in the workspace? Would appreciate any additional clarifying remarks about your issue. Thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-20T09:36:42.263Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a>,</p>\n<p>No worries, thanks for you help. My comment on \u201cmasks display a strange pattern\u201d does refer to the rendering of the masks in the workspace. To try and clarify the issue, if you look at the center two masks in the screenshot (the middle column),  these are both generated by</p>\n<p><code>predicted_mask = np.ones((size, size), dtype=np.uint8)</code></p>\n<p>where size = 200 for the top image and size = 100 for the bottom image. However, you can see for the size = 200 mask (the top one), this is not displayed as a solid mask (as it should be since it is an array of only 1s), whereas the size = 100 mask below it is rendered correctly.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-28T19:53:29.459Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/rdorfman\">@rdorfman</a> , I ran some tests on my end with various array size and was unable to reproduce that rendering glitch you ran into. Please <a href=\"https://wandb.ai/mohammadbakir/image-seg-test?workspace=user-mohammadbakir\">see this project</a> where I have image/masks side by side displaying  solid masks. I will keep an eye out for other mentions of this behavior. At this time my recommendation is to delete the panels, clear your workspace ( From bottom left of screen, My Workspace &gt; Clear Workspace), re-run your code and see if this behavior persists. If it does, please send me a link to your workspace.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/e/e6a28ba14d3666d39d49665fd8f1635b2cd76345.png\" data-download-href=\"/uploads/short-url/wUi4lM5DMEazp36Al0A3XyS0hvv.png?dl=1\" title=\"Panels\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/e6a28ba14d3666d39d49665fd8f1635b2cd76345_2_690x296.png\" alt=\"Panels\" data-base62-sha1=\"wUi4lM5DMEazp36Al0A3XyS0hvv\" width=\"690\" height=\"296\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/e6a28ba14d3666d39d49665fd8f1635b2cd76345_2_690x296.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/e6a28ba14d3666d39d49665fd8f1635b2cd76345_2_1035x444.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/e/e6a28ba14d3666d39d49665fd8f1635b2cd76345_2_1380x592.png 2x\" data-dominant-color=\"E5E1E7\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Panels</span><span class=\"informations\">1577\u00d7678 11.7 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-29T14:53:06.826Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> , thanks for taking the time to test this. When I view the project you shared, all examples that do not show the rendering issue appear to have dimensions smaller than (100,100). However, the rendering issue shows up for me for the (200,200) masks. Could you please let me know if you can see this issue in your project for the (200,200) size mask?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-29T14:59:44.462Z",
				"Answer_body": "<p>Here is a screenshot from the project you shared:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/2bdcba98e4f591dc368932d77b9c08740adb3919.jpeg\" data-download-href=\"/uploads/short-url/6g1rk4Mrj9DgjHe2FBJK3ilWasF.jpeg?dl=1\" title=\"Screenshot 2022-10-29 at 07.58.58\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/2bdcba98e4f591dc368932d77b9c08740adb3919_2_690x237.jpeg\" alt=\"Screenshot 2022-10-29 at 07.58.58\" data-base62-sha1=\"6g1rk4Mrj9DgjHe2FBJK3ilWasF\" width=\"690\" height=\"237\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/2bdcba98e4f591dc368932d77b9c08740adb3919_2_690x237.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/2bdcba98e4f591dc368932d77b9c08740adb3919_2_1035x355.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/2bdcba98e4f591dc368932d77b9c08740adb3919_2_1380x474.jpeg 2x\" data-dominant-color=\"CFC9D5\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2022-10-29 at 07.58.58</span><span class=\"informations\">1754\u00d7604 145 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-28T15:00:03.376Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Logging with Tensorboard",
		"Question_link": "https://community.wandb.ai/t/logging-with-tensorboard/3265",
		"Question_created_time": "2022-10-16T18:59:17.447Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 199,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I am trying to run the demo code from <a href=\"https://colab.research.google.com/gist/sayakpaul/5b31ed03725cc6ae2af41848d4acee45/demo_tensorboard.ipynb\" rel=\"noopener nofollow ugc\">Demo_tensorboard.ipynb</a> so that I can learn more about the use of Tensorboard in combination with W&amp;B. Unfortunately this code throws this warning:</p>\n<p>WARNING When using several event log directories, please call <code>wandb.tensorboard.patch(root_logdir=\"...\")</code> before <code>wandb.init</code></p>\n<p>When I implement the suggested change with:</p>\n<p><code>wandb.tensorboard.patch(root_logdir=\"./logs/debug\")</code></p>\n<p>I get the following warning:<br>\nFound log directory outside of given root_logdir, dropping given root_logdir for event file in i:\\tinyml\\tiny_cnn\\wandb\\run-20221016_205607-22b9tlzf\\files\\train</p>\n<p>So my questions is: What is a suitable root_logdir for Tensorboard?</p>\n<p>Thanks for your support.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-17T13:16:21.990Z",
				"Answer_body": "<p>Hi Susanne,</p>\n<p>Thanks for writing in! The <code>root_logdir</code>argument is the path to the root of all tfevent files, so you can use the wandb project folder (in this case I think it is <code>I:/tinyml/tiny_cnn</code>). Could you try if setting this solves the issue?</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-10-20T08:48:45.986Z",
				"Answer_body": "<p>Hi Susanne,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-28T19:43:19.097Z",
				"Answer_body": "<p>Setting root_logdir = os.getcwd() actually solved the issue.</p>\n<p>Thanks for the support.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-27T19:43:39.383Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Workflow for running an ensemble of experiments with different initial conditions",
		"Question_link": "https://community.wandb.ai/t/workflow-for-running-an-ensemble-of-experiments-with-different-initial-conditions/3074",
		"Question_created_time": "2022-09-06T18:49:16.459Z",
		"Question_answer_count": 6,
		"Question_score_count": 1,
		"Question_view_count": 201,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Any ideas on the right workflow to run sweeps/groups with a whole bunch of different variations on initial conditions to see an ensemble of results?  I think that the  <a href=\"https://docs.wandb.ai/guides/track/advanced/grouping\" class=\"inline-onebox\">Group Runs - Documentation</a>  seems a natural candidate for this but I am not sure the right approach or how it overlays with sweeps in this sort of usecase.</p>\n<p>To setup the scenario I have in mind: I have a script  I want to run hundred times on my local machine with pretty much all parameters fixed except the neural network initial conditions.  I can control that by doing things like incrementing a <code>--seed</code> argument  or just not establishing a default seed.  After running those experiments, it is nice to see pretty pictures of distribtions in wandb but I also want to be able to later collect the results/assets as a group. and do things like plot a histogram of <code>val_loss</code> to put in a research paper.</p>\n<p>Is the way to do this with a combination of sweeps and run_groups?  Forr example, can I run a bunch of these in a sweep with after setting the <code>WANDB_RUN_GROUP</code> environment variable?  For example, maybe setup a sweep file like</p>\n<pre data-code-wrap=\"yaml\"><code class=\"lang-nohighlight\">program: train.py\nmethod: grid\nparameters:\n  seed:\n    min: 2\n    max: 102\n</code></pre>\n<p>Where <code>--seed</code> is used internally to set the seed for the experiment?  Any better approaches</p>\n<p>If that works, ,  then do I just need to set <code>WANDB_RUN_GROUP</code> environment variable on every machine that I will run an agent on and then it can be grouped?  Then I can pull down all of the assets for these with the <code>WAND_RUN_GROUP</code>?  I couldn\u2019t figure it out from the docs how to get all of the logged results (and the artifacts if there are any) for a group.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-12T08:42:48.877Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/jlperla\">@jlperla</a> thank you for writing in! It\u2019s indeed feasible to group the sweeps with various ways. If you name your Sweeps (by passing a distinct value to the <a href=\"https://docs.wandb.ai/guides/sweeps/configuration#structure-of-the-sweep-configuration\">name argument</a>) then in the UI you would be able to <code>Group by Sweeps</code>. Alternatively you can use the <code>group</code> argument in the wandb.init() call (or the <code>WANDB_RUN_GROUP</code> as you mentioned). Another workaround to group the Sweeps (and Runs in general) but not the most recommended for your case here would be to make use of Tags. Finally you can also make use of your <code>config</code> to group the Runs as in <a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-log/Configs_in_W%26B.ipynb\" rel=\"noopener nofollow ugc\">here</a>.</p>\n<p>Have you tried any of these solutions, and did you run into any issue? or what would be your preferred way and we can further look into this option? Would you prefer to have your Sweeps preconfigured from your script, or being able to do so afterwards in the UI by their <code>config</code> values?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-12T19:00:27.821Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"thanos-wandb\" data-post=\"2\" data-topic=\"3074\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/t/4af34b/40.png\" class=\"avatar\"> thanos-wandb:</div>\n<blockquote>\n<p>Have you tried any of these solutions, and did you run into any issue? or what would be your preferred way and we can further look into this option? Would you prefer to have your Sweeps preconfigured from your script, or being able to do so afterwards in the UI by their <code>config</code> values?</p>\n</blockquote>\n</aside>\n<p>Thanks.  That is very helpful.  What ended up working really well was a sweep file such as <code>sweep_ensemble.yaml</code></p>\n<pre data-code-wrap=\"yaml\"><code class=\"lang-nohighlight\">program: my_script.py\nproject: my_project\nmethod: grid\nparameters:\n  seed:\n    min: 10\n    max: 50\n</code></pre>\n<p>Called with <code>wandb sweep --name my_sweep_name sweep_ensemble.yaml</code></p>\n<p>Where I am using pytorch lightning\u2019s LightningCLI for running my experiments and <code>---seed=15</code> etc. will change the seed then run it.  I can then set the <code>tags</code> argument in in <a href=\"https://pytorch-lightning.readthedocs.io/en/stable/extensions/generated/pytorch_lightning.loggers.WandbLogger.html\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">WandbLogger \u2014 PyTorch Lightning 1.7.5 documentation</a> if it helps for searching.</p>\n<p>Different variations seem to work well for calling.  Where I am getting a little more stuck is the best way to programmatically get all of the details of the sweep with a query in the python interface.</p>\n<p>I can get the list of sweeps but I can\u2019t figure out how to do that by my chosen display name (i.e., <code>my_sweep_name</code> above) as opposed to the underlying sweep identifier.  Is there a way to use <code>runs = api.runs(\"myentity/my_project\", filters= ???)</code> or something like that which will get the list of runs given a display name which I can then query for summary, config, and artifacts</p>\n<p>Alternatively, if tags are easier and I set one up, is there an easy way to get all of the runs which have a particular tag?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-22T12:46:48.295Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/jlperla\">@jlperla</a> thank you for the detailed information, and great to hear that the grouping issue has been now resolved. Regarding your question using the API to filter runs, you could do that indeed with the following command:<br>\n<code>runs = api.runs(\"entity/project\", filters={\"sweep\": \"sweep_id\"})</code><br>\nAlternatively you can use <a href=\"https://docs.wandb.ai/ref/app/features/tags#how-to-add-tags\">API to tag all your runs</a> based on <code>my_sweep_name</code> identifier and then query runs as follows:<br>\n<code>runs = api.runs(\"entity/project\", filters={\"tags\": \"my_sweep_name\"})</code><br>\nIs my_sweep_name defined in your config? In that case you could do <code>filters={\"config.sweep_name\": \"my_sweep_name\"}</code>.</p>\n<p>Would any of these work for you? Please let me know if you have any further questions or issues with this!</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-09-27T16:08:13.684Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/jlperla\">@jlperla</a> I\u2019ve seen you accepted this as a solution, so I will close the ticket for now as it seems to have worked for you. Please feel free to message us here if you still experience any issues, or have any further questions and we will be happy to look into these!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-28T10:27:53.424Z",
				"Answer_body": "<p>I\u2019m interested in what you\u2019re saying regarding LightningCLI, could you explain a bit more what you have done?</p>\n<p>I have an experiment running using LightningCLI and I\u2019d like to know if I can instantiate agents using wandb agents where the agents are python experiments setup to make use of LightningCLI. Is that what you managed? If yes, would you please share a minimal example of how that was done? That would be very much appreciated.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-27T10:28:26.835Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sweep error - AttributeError: 'SettingsStatic' object has no attribute 'git_root'",
		"Question_link": "https://community.wandb.ai/t/sweep-error-attributeerror-settingsstatic-object-has-no-attribute-git-root/3335",
		"Question_created_time": "2022-10-27T21:19:53.478Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 153,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>When trying to make a new sweep I get the following error<br>\n<code>AttributeError: 'SettingsStatic' object has no attribute 'git_root'</code></p>\n<p>Seems to be repeated no matter what I try.<br>\nThe full log from <code>debug-internal.log</code></p>\n<pre><code class=\"lang-bash\">2022-10-27 21:15:00,236 INFO    StreamThr :3165542 [internal.py:wandb_internal():88] W&amp;B internal server running at pid: 3165542, started at: 2022-10-27 21:15:00.235637\n2022-10-27 21:15:00,237 DEBUG   HandlerThread:3165542 [handler.py:handle_request():138] handle_request: status\n2022-10-27 21:15:00,374 DEBUG   SenderThread:3165542 [sender.py:send_request():317] send_request: status\n2022-10-27 21:15:00,376 DEBUG   SenderThread:3165542 [sender.py:send():303] send: header\n2022-10-27 21:15:00,376 INFO    WriterThread:3165542 [datastore.py:open_for_write():75] open: /home/cin/Projects/MotionLatentSpace/wandb/run-20221027_211500-xj06c5a6/run-xj06c5a6.wandb\n2022-10-27 21:15:00,376 DEBUG   SenderThread:3165542 [sender.py:send():303] send: run\n2022-10-27 21:15:00,760 INFO    SenderThread:3165542 [dir_watcher.py:__init__():216] watching files in: /home/cin/Projects/MotionLatentSpace/wandb/run-20221027_211500-xj06c5a6/files\n2022-10-27 21:15:00,760 INFO    SenderThread:3165542 [sender.py:_start_run_threads():928] run started: xj06c5a6 with start time 1666905300.0\n2022-10-27 21:15:00,760 DEBUG   SenderThread:3165542 [sender.py:send():303] send: summary\n2022-10-27 21:15:00,760 INFO    SenderThread:3165542 [sender.py:_save_file():1171] saving file wandb-summary.json with policy end\n2022-10-27 21:15:00,761 DEBUG   HandlerThread:3165542 [handler.py:handle_request():138] handle_request: check_version\n2022-10-27 21:15:00,761 DEBUG   SenderThread:3165542 [sender.py:send_request():317] send_request: check_version\n2022-10-27 21:15:01,040 DEBUG   HandlerThread:3165542 [handler.py:handle_request():138] handle_request: run_start\n2022-10-27 21:15:01,044 DEBUG   HandlerThread:3165542 [meta.py:__init__():34] meta init\n2022-10-27 21:15:01,381 INFO    WriterThread:3165542 [datastore.py:close():279] close: /home/cin/Projects/MotionLatentSpace/wandb/run-20221027_211500-xj06c5a6/run-xj06c5a6.wandb\n2022-10-27 21:15:01,761 INFO    Thread-14 :3165542 [dir_watcher.py:_on_file_created():275] file/dir created: /home/cin/Projects/MotionLatentSpace/wandb/run-20221027_211500-xj06c5a6/files/wandb-summary.json\n2022-10-27 21:15:02,031 INFO    SenderThread:3165542 [sender.py:finish():1331] shutting down sender\n2022-10-27 21:15:02,031 INFO    SenderThread:3165542 [dir_watcher.py:finish():362] shutting down directory watcher\n2022-10-27 21:15:02,762 INFO    SenderThread:3165542 [dir_watcher.py:finish():392] scan: /home/cin/Projects/MotionLatentSpace/wandb/run-20221027_211500-xj06c5a6/files\n2022-10-27 21:15:02,762 INFO    SenderThread:3165542 [dir_watcher.py:finish():406] scan save: /home/cin/Projects/MotionLatentSpace/wandb/run-20221027_211500-xj06c5a6/files/wandb-summary.json wandb-summary.json\n2022-10-27 21:15:02,762 INFO    SenderThread:3165542 [dir_watcher.py:finish():406] scan save: /home/cin/Projects/MotionLatentSpace/wandb/run-20221027_211500-xj06c5a6/files/config.yaml config.yaml\n2022-10-27 21:15:02,762 INFO    SenderThread:3165542 [file_pusher.py:finish():168] shutting down file pusher\n2022-10-27 21:15:02,764 INFO    SenderThread:3165542 [file_pusher.py:join():173] waiting for file pusher\n2022-10-27 21:15:04,333 INFO    Thread-19 :3165542 [upload_job.py:push():143] Uploaded file /home/cin/Projects/MotionLatentSpace/wandb/run-20221027_211500-xj06c5a6/files/config.yaml\n2022-10-27 21:15:04,349 INFO    Thread-18 :3165542 [upload_job.py:push():143] Uploaded file /home/cin/Projects/MotionLatentSpace/wandb/run-20221027_211500-xj06c5a6/files/wandb-summary.json\n2022-10-27 21:15:04,954 ERROR   StreamThr :3165542 [internal.py:wandb_internal():163] Thread HandlerThread:\nTraceback (most recent call last):\n  File \"/home/cin/.local/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 50, in run\n    self._run()\n  File \"/home/cin/.local/lib/python3.8/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n    self._process(record)\n  File \"/home/cin/.local/lib/python3.8/site-packages/wandb/sdk/internal/internal.py\", line 263, in _process\n    self._hm.handle(record)\n  File \"/home/cin/.local/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 130, in handle\n    handler(record)\n  File \"/home/cin/.local/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 140, in handle_request\n    handler(record)\n  File \"/home/cin/.local/lib/python3.8/site-packages/wandb/sdk/internal/handler.py\", line 672, in handle_request_run_start\n    run_meta = meta.Meta(settings=self._settings, interface=self._interface)\n  File \"/home/cin/.local/lib/python3.8/site-packages/wandb/sdk/internal/meta.py\", line 40, in __init__\n    root=self._settings.git_root,\nAttributeError: 'SettingsStatic' object has no attribute 'git_root'\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-27T21:53:42.374Z",
				"Answer_body": "<p>Hi Christian, thank you for writing in! Based on your post, it seems that you had run sweeps before without this problem. Can you tell me if there was anything that had changed between the last time you ran sweeps to when you ran into this error? For example, did you connect your project to GitHub? Also, can you send me a link to your sweep runs where you are running into this?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-28T07:32:33.022Z",
				"Answer_body": "<p>Hi Leslie,</p>\n<p>Found the issue! I was even though I had the correct conda env activated running the <code>wandb sweep</code> command with my local new version of wandb while the python code and env where running with and old 12.XX version.</p>\n<p>I changed it to use the same install for both and now it works.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-11-01T22:53:09.243Z",
				"Answer_body": "<p>Hi Christian! I\u2019m glad you were able to find a fix for this <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"> I\u2019m going to close this ticket out now, but I hope you have a beautiful rest of the week</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-27T07:33:22.376Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Image resolution with log()",
		"Question_link": "https://community.wandb.ai/t/image-resolution-with-log/3289",
		"Question_created_time": "2022-10-19T17:35:22.619Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 475,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>We are generating some intricate images and using log() to store those with the run (not to mention trying to add them to a Report).  It has recently become apparent that WandB is downscaling the images when they are logged.  For example, our images are 200DPI, but on viewing them after logging they are 72DPI.<br>\nIs there a way to override this?  I have checked the source for <code>wandb.Image()</code> but there is no mention of DPI or resolution.  Its not clear if this is being done by <code>log()</code> or by <code>Image()</code>.<br>\nThank you.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-20T17:57:11.297Z",
				"Answer_body": "<p>HI <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> , thanks for writing in. I checked and we don\u2019t interfere with an image resolution. Please:</p>\n<ul>\n<li>Provide a description of how this was verified on your end</li>\n<li>If possible a reproducible example of your verification process</li>\n</ul>\n<p>Thank you</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-27T17:09:00.771Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> ,  since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-26T17:09:30.323Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Exporting graphs gives different graph datapoints",
		"Question_link": "https://community.wandb.ai/t/exporting-graphs-gives-different-graph-datapoints/3294",
		"Question_created_time": "2022-10-20T13:16:56.925Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 113,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>When exporting a line graph to png or svg gives a figure that is different than the actual graph. The final points of each graph should be located at the end of the line of that graph. However, the final points are placed much farther to the right.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-20T13:45:17.701Z",
				"Answer_body": "<p>Hi daankrol,</p>\n<p>Thanks for writing in! I have checked this but it seems to be working properly for me. Would you mind sending me a screenshot of both charts and a link to the Workspace and so I can try to reproduce this issue?</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-20T14:47:37.492Z",
				"Answer_body": "<p>Hi,</p>\n<p>Here an example:</p>\n<p><img src=\"https://weightsandbiases.zendesk.com/attachments/token/rP5OBhMoXk1mzFtUJ8LSaNoKq/?name=W%26B+Chart+20_10_2022%2C+14_03_10-3.png\" alt=\"\" role=\"presentation\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-20T15:42:43.362Z",
				"Answer_body": "<p>Hi Daan,</p>\n<p>Thanks for sharing this! I was wondering if you could send me a link to the chart where you are facing this issue. Also, I would like to know if you are experiencing this in all the charts. Thanks!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-25T09:27:11.969Z",
				"Answer_body": "<p>Hi daankrol,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-27T14:32:24.862Z",
				"Answer_body": "<p>Hi Luis,</p>\n<p>Unfortunately I did not receive a notification of your reply. It seems that the issue has been resolved. The graph ends are now positioned correctly when exporting to PNG. However, when I export a chart to SVG a scrollbar will be added to the legend. For example, try to export <a href=\"https://wandb.ai/daankrol/Dataset%20Reduction%20for%20IL/reports/Papilion-test-F1-Transfer-learning-22-10-27-16-31-53---VmlldzoyODY0MDkw?accessToken=upr3q00htnwp0bmk0ucaxhvmfyuxq5adqwy7g9xh2tf34cwy2syv0zdh26bl5pas\">this graph</a> to SVG. A scrollbar will appear in the top right. This can also be observed in the image supplied earlier in this post.</p>\n<p>I hope that this information helps you to resolve this issue.</p>\n<p>Kind regards,<br>\nDaan</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-26T14:32:38.594Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "The wandb.log function does not treat nested dict as it describes in the document",
		"Question_link": "https://community.wandb.ai/t/the-wandb-log-function-does-not-treat-nested-dict-as-it-describes-in-the-document/3330",
		"Question_created_time": "2022-10-27T00:42:51.509Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 89,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I find that using the <code>wandb.log()</code> does not work like it describe in the document that</p>\n<blockquote>\n<p>Logging nested metrics is encouraged and is supported in the W&amp;B UI. If you log with a nested dictionary like <code>wandb.log({\"train\": {\"acc\": 0.9}, \"val\": {\"acc\": 0.8}})</code> , the metrics will be organized into <code>train</code> and <code>val</code> sections in the W&amp;B UI.</p>\n</blockquote>\n<p>Instead, it seems like it will create separate plots with a dot to make different names. In the above sample, it would show me<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/7/77fb781483d08f4abf148a2abd22caa5c42a5d2b.png\" data-download-href=\"/uploads/short-url/h7pAvZ8ws18O7lJwodYZ0CdnF6X.png?dl=1\" title=\"img1\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/7/77fb781483d08f4abf148a2abd22caa5c42a5d2b_2_690x237.png\" alt=\"img1\" data-base62-sha1=\"h7pAvZ8ws18O7lJwodYZ0CdnF6X\" width=\"690\" height=\"237\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/7/77fb781483d08f4abf148a2abd22caa5c42a5d2b_2_690x237.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/7/77fb781483d08f4abf148a2abd22caa5c42a5d2b_2_1035x355.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/7/77fb781483d08f4abf148a2abd22caa5c42a5d2b_2_1380x474.png 2x\" data-dominant-color=\"FDFCFC\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">img1</span><span class=\"informations\">2136\u00d7736 31.2 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nHowever, what I expect is the UI should show me two sections (train and val) and separate \u201cacc\u201d named plots inside. BTW, I know if I use <code>wandb.log({\"train/acc\": 0.9, \"val/acc\": 0.9})</code> can achieve this functionality.</p>\n<p>Any helps would be appreciated!<br>\nThank you!<br>\nDylan</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-27T03:37:25.749Z",
				"Answer_body": "<p>Hi Dylan!</p>\n<p>Thank you for bringing this up with us! I\u2019ll let our engineering team know there is an issue here. For now, you should also be able to log nested groups as the following:</p>\n<pre><code class=\"lang-python\">wandb.log({\n    'train/acc' : 0.9,\n    'val/acc' : 0.8\n})\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-26T03:38:24.895Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Stored artifact is not h5 file",
		"Question_link": "https://community.wandb.ai/t/stored-artifact-is-not-h5-file/3322",
		"Question_created_time": "2022-10-25T14:07:27.698Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 552,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I\u2019m using tensorflow with the python callback. The callback stores several files automatically for each run:</p>\n<ul>\n<li>saved_model.pb</li>\n<li>keras_metadata.pb</li>\n</ul>\n<p>I would like to automatically store the weights h5 file as well. Is there an option for this? Do I have to do it manually?<br>\nNote that I can find best-model.h5 in the wand folder of each run, but for some reason it is not uploaded to the server.</p>\n<p>Thank you,<br>\nArnaud</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-25T18:52:07.474Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/secondlayer\">@secondlayer</a>,</p>\n<p>Conversion to <code>.h5</code> files will have to be done in your python process and then uploaded to Weights and Biases.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-30T23:50:50.145Z",
				"Answer_body": "<p>Hi Arnaud,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-02T03:54:30.532Z",
				"Answer_body": "<p>Hi Arnaud, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-24T18:52:07.569Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to stop logging locally but only save to wandb's servers and have wandb work using soft links?",
		"Question_link": "https://community.wandb.ai/t/how-to-stop-logging-locally-but-only-save-to-wandbs-servers-and-have-wandb-work-using-soft-links/3305",
		"Question_created_time": "2022-10-23T23:03:31.012Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 379,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am having a weird issue where I change the location of all my code &amp; data to a different location with more disk space, then I soft link my projects &amp; data to those locations with more space. I assume there must be some file handle issue because wandb\u2019s logger is throwing me issues. So my questions:</p>\n<ol>\n<li>how do I have wandb only log  online and not locally? (e.g. stop trying to log anything to <code>./wandb</code>[or any secret place it might be logging to]  since it\u2019s creating issues). Note my code was running fine after I  stopped logging to wandb so I assume that was the issue. note that the <code>dir=None</code> is the default to wandb\u2019s param.</li>\n<li>how do I resolve this issue entirely so that it works seemlessly with all my projects softlinked somewhere else?</li>\n</ol>\n<hr>\n<h1>\n<a name=\"more-details-on-the-error-1\" class=\"anchor\" href=\"#more-details-on-the-error-1\"></a>More details on the error</h1>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/logging/__init__.py\", line 1087, in emit\n    self.flush()\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/logging/__init__.py\", line 1067, in flush\n    self.stream.flush()\nOSError: [Errno 116] Stale file handle\nCall stack:\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py\", line 930, in _bootstrap\n    self._bootstrap_inner()\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n    self.run()\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/vendor/watchdog/observers/api.py\", line 199, in run\n    self.dispatch_events(self.event_queue, self.timeout)\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/vendor/watchdog/observers/api.py\", line 368, in dispatch_events\n    handler.dispatch(event)\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/vendor/watchdog/events.py\", line 454, in dispatch\n    _method_map[event_type](event)\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/filesync/dir_watcher.py\", line 275, in _on_file_created\n    logger.info(\"file/dir created: %s\", event.src_path)\nMessage: 'file/dir created: %s'\nArguments: ('/shared/rsaas/miranda9/diversity-for-predictive-success-of-meta-learning/wandb/run-20221023_170722-1tfzh49r/files/output.log',)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/logging/__init__.py\", line 1087, in emit\n    self.flush()\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/logging/__init__.py\", line 1067, in flush\n    self.stream.flush()\nOSError: [Errno 116] Stale file handle\nCall stack:\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py\", line 930, in _bootstrap\n    self._bootstrap_inner()\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n    self.run()\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 50, in run\n    self._run()\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n    self._process(record)\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/internal/internal.py\", line 263, in _process\n    self._hm.handle(record)\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/internal/handler.py\", line 130, in handle\n    handler(record)\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/internal/handler.py\", line 138, in handle_request\n    logger.debug(f\"handle_request: {request_type}\")\nMessage: 'handle_request: stop_status'\nArguments: ()\nN/A% (0 of 100000) |      | Elapsed Time: 0:00:00 | ETA:  --:--:-- |   0.0 s/it\n\nTraceback (most recent call last):\n  File \"/home/miranda9/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/experiment_mains/main_dist_maml_l2l.py\", line 1814, in &lt;module&gt;\n    main()\n  File \"/home/miranda9/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/experiment_mains/main_dist_maml_l2l.py\", line 1747, in main\n    train(args=args)\n  File \"/home/miranda9/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/experiment_mains/main_dist_maml_l2l.py\", line 1794, in train\n    meta_train_iterations_ala_l2l(args, args.agent, args.opt, args.scheduler)\n  File \"/home/miranda9/ultimate-utils/ultimate-utils-proj-src/uutils/torch_uu/training/meta_training.py\", line 167, in meta_train_iterations_ala_l2l\n    log_zeroth_step(args, meta_learner)\n  File \"/home/miranda9/ultimate-utils/ultimate-utils-proj-src/uutils/logging_uu/wandb_logging/meta_learning.py\", line 92, in log_zeroth_step\n    log_train_val_stats(args, args.it, step_name, train_loss, train_acc, training=True)\n  File \"/home/miranda9/ultimate-utils/ultimate-utils-proj-src/uutils/logging_uu/wandb_logging/supervised_learning.py\", line 55, in log_train_val_stats\n    _log_train_val_stats(args=args,\n  File \"/home/miranda9/ultimate-utils/ultimate-utils-proj-src/uutils/logging_uu/wandb_logging/supervised_learning.py\", line 116, in _log_train_val_stats\n    args.logger.log('\\n')\n  File \"/home/miranda9/ultimate-utils/ultimate-utils-proj-src/uutils/logger.py\", line 89, in log\n    print(msg, flush=flush)\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/lib/redirect.py\", line 640, in write\n    self._old_write(data)\nOSError: [Errno 116] Stale file handle\nwandb: Waiting for W&amp;B process to finish... (failed 1). Press Control-C to abort syncing.\nwandb: Synced vit_mi Adam_rfs_cifarfs Adam_cosine_scheduler_rfs_cifarfs 0.001: args.jobid=101161: https://wandb.ai/brando/entire-diversity-spectrum/runs/1tfzh49r\nwandb: Synced 6 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nwandb: Find logs at: ./wandb/run-20221023_170722-1tfzh49r/logs\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/interface/router_sock.py\", line 27, in _read_message\n    resp = self._sock_client.read_server_response(timeout=1)\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 283, in read_server_response\n    data = self._read_packet_bytes(timeout=timeout)\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 269, in _read_packet_bytes\n    raise SockClientClosedError()\nwandb.sdk.lib.sock_client.SockClientClosedError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/interface/router.py\", line 70, in message_loop\n    msg = self._read_message()\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/interface/router_sock.py\", line 29, in _read_message\n    raise MessageRouterClosedError\nwandb.sdk.interface.router.MessageRouterClosedError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/logging/__init__.py\", line 1087, in emit\n    self.flush()\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/logging/__init__.py\", line 1067, in flush\n    self.stream.flush()\nOSError: [Errno 116] Stale file handle\nCall stack:\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py\", line 930, in _bootstrap\n    self._bootstrap_inner()\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n    self.run()\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/threading.py\", line 910, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/site-packages/wandb/sdk/interface/router.py\", line 77, in message_loop\n    logger.warning(\"message_loop has been closed\")\nMessage: 'message_loop has been closed'\nArguments: ()\n/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/tempfile.py:817: ResourceWarning: Implicitly cleaning up &lt;TemporaryDirectory '/srv/condor/execute/dir_27749/tmpmvf78q6owandb'&gt;\n  _warnings.warn(warn_message, ResourceWarning)\n/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/tempfile.py:817: ResourceWarning: Implicitly cleaning up &lt;TemporaryDirectory '/srv/condor/execute/dir_27749/tmpt5etqpw_wandb-artifacts'&gt;\n  _warnings.warn(warn_message, ResourceWarning)\n/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/tempfile.py:817: ResourceWarning: Implicitly cleaning up &lt;TemporaryDirectory '/srv/condor/execute/dir_27749/tmp55lzwviywandb-media'&gt;\n  _warnings.warn(warn_message, ResourceWarning)\n/home/miranda9/miniconda3/envs/metalearning_gpu/lib/python3.9/tempfile.py:817: ResourceWarning: Implicitly cleaning up &lt;TemporaryDirectory '/srv/condor/execute/dir_27749/tmprmk7lnx4wandb-media'&gt;\n  _warnings.warn(warn_message, ResourceWarning)\n</code></pre>\n<p>cross: <a href=\"https://stackoverflow.com/questions/74175401/how-to-stop-logging-locally-but-only-save-to-wandbs-servers-and-have-wandb-work\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">python - How to stop logging locally but only save to wandb's servers and have wandb work using soft links? - Stack Overflow</a></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-24T16:50:03.404Z",
				"Answer_body": "<p>to document what I\u2019ve tried so far.</p>\n<ul>\n<li>I tried removing the old .wandb logs that are saved locally automatically and symlinked everything else (e.g. the data folder and where the models are checkpointing). But it still failed. I am surprised because I don\u2019t understand what could be so large in wandb that it make me have disk quota error. The main solution is that the wandb team should make wandb work regardless where my data, project, etc folders are or if I use symlinks. Any advice <a class=\"mention\" href=\"/u/_scott\">@_scott</a> ?</li>\n</ul>\n<hr>\n<p>gitissue: <a href=\"https://github.com/wandb/wandb/issues/4409\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">[CLI]: wandb saving to local does not work when soft links to the current project are used \u00b7 Issue #4409 \u00b7 wandb/wandb \u00b7 GitHub</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-25T03:56:22.967Z",
				"Answer_body": "<p>Hey Brando,</p>\n<p>I have responded to your GitHub post, lets keep the conversation there for greater visibility for other folks  in the future.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-25T04:42:19.258Z",
				"Answer_body": "<p><a href=\"https://github.com/wandb/wandb/issues/4409\" rel=\"noopener nofollow ugc\">[CLI]: wandb saving to local does not work when soft links to the current project are used \u00b7 Issue #4409 \u00b7 wandb/wandb \u00b7 GitHub</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-24T04:42:28.497Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "[Q] Pyinstaller not fetching wandb_gql",
		"Question_link": "https://community.wandb.ai/t/q-pyinstaller-not-fetching-wandb-gql/3309",
		"Question_created_time": "2022-10-24T05:03:03.585Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 430,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m checking if pyinstaller package works to binarize a project and to test it, and I\u2019m currently using pieces of code that contain the main functionality and package dependencies to the main project.</p>\n<p>To decode into binary through pyinstaller I\u2019m running:</p>\n<pre><code class=\"lang-bash\">pyinstaller pyinst_test.py\n</code></pre>\n<p>And to execute the generated binary:</p>\n<pre><code class=\"lang-bash\">$ ./dist/pyinst_test/pyinst_test \n</code></pre>\n<p>The output of the binary is the following execution error:</p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"pyinst_test.py\", line 3, in &lt;module&gt;\n    import wandb\n  File \"PyInstaller/loader/pyimod02_importers.py\", line 499, in exec_module\n  File \"wandb/__init__.py\", line 26, in &lt;module&gt;\n  File \"PyInstaller/loader/pyimod02_importers.py\", line 499, in exec_module\n  File \"wandb/sdk/__init__.py\", line 7, in &lt;module&gt;\n  File \"PyInstaller/loader/pyimod02_importers.py\", line 499, in exec_module\n  File \"wandb/sdk/wandb_artifacts.py\", line 30, in &lt;module&gt;\n  File \"PyInstaller/loader/pyimod02_importers.py\", line 499, in exec_module\n  File \"wandb/apis/__init__.py\", line 31, in &lt;module&gt;\n  File \"PyInstaller/loader/pyimod02_importers.py\", line 499, in exec_module\n  File \"wandb/apis/internal.py\", line 1, in &lt;module&gt;\n  File \"PyInstaller/loader/pyimod02_importers.py\", line 499, in exec_module\n  File \"wandb/sdk/internal/internal_api.py\", line 1, in &lt;module&gt;\nModuleNotFoundError: No module named 'wandb_gql'\n</code></pre>\n<p>Is there anyway to use pyinstaller and wandb? Or is recommended another solution to encode wandb code dependencies as binary?</p>\n<hr>\n<p><strong>Issue description and steps:</strong></p>\n<p>tensorflow==2.10.0<br>\nwandb==0.12.20</p>\n<p>The baseline code (pyinst_test.py):</p>\n<pre><code class=\"lang-python\">import os\nfrom tempfile import mkdtemp\nimport wandb\nimport tensorflow as tf\n\nclass Test:\n    def __init__(self) -&gt; None:\n        wandb_secret_key = \"&lt;wandb_secret_key&gt;\"\n        wandb_entity = \"&lt;wandb_entity&gt;\"\n        wandb_project = \"&lt;wandb_project&gt;\"\n        artifact_name = \"&lt;artifact_name&gt;\"\n        artifact_version = \"&lt;artifact_version&gt;\"\n\n        model_full_path = self._download_artifact(\n            wandb_secret_key = wandb_secret_key,\n            wandb_entity = wandb_entity,\n            wandb_project = wandb_project,\n            artifact_name = artifact_name,\n            artifact_version = artifact_version    \n        )\n        print(f\"[INFO] Model Artifact Directory: {model_full_path}\")\n        model = self._load_tf_model(model_full_path)\n        self._print_model_summary(model)\n\n    def _download_artifact(\n        self,\n        wandb_entity: str,\n        wandb_project: str,\n        artifact_name: str,\n        artifact_version: str):\n\n        api = wandb.Api()\n        artifact = api.artifact(f\"{wandb_entity}/{wandb_project}/{artifact_name}:{artifact_version}\")\n        local_download_folder = mkdtemp()\n\n        artifact_dir = artifact.download(local_download_folder)\n        model_full_path = os.path.join(local_download_folder, artifact_dir)\n        return model_full_path\n\n    \n    def _load_tf_model(self, model_path: str):\n        model = tf.keras.models.load_model(model_path)\n        return model\n\n    def _print_model_summary(self, model: tf.keras.models.Model):\n        model.summary()\n\nif __name__ == \"__main__\":\n    test = Test()\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-25T04:00:54.339Z",
				"Answer_body": "<p>Hey Wilson,</p>\n<p>Using pip is the recommended way to install <code>wandb</code>. Is there anything that is blocking you from using pip in this situation?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-28T16:00:56.514Z",
				"Answer_body": "<p>Hi Wilson,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights and Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-31T03:22:54.679Z",
				"Answer_body": "<p>Hi Wilson, Since we have not heard back from you, we are closing this support request. If you would like to re-open this request, please reply to this thread!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-24T04:01:21.508Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Add alias to artifacts linked to a registered model/collection",
		"Question_link": "https://community.wandb.ai/t/add-alias-to-artifacts-linked-to-a-registered-model-collection/3237",
		"Question_created_time": "2022-10-11T02:16:27.885Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 132,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I can update the aliases of an artifact that is not linked to a registered model in the following manner:</p>\n<pre><code class=\"lang-auto\">    api = wandb.Api()\n    artifact = api.artifact('entity/project/artifact:v1')\n\n    # Add an alias\n    artifact.aliases.append('test')\n\n    # Persist all artifact modifications\n    artifact.save()\n</code></pre>\n<p>However, I  cannot update an artifact linked to a registered model/collection.</p>\n<pre><code class=\"lang-auto\">    api = wandb.Api()\n    artifact = api.artifact('entity/project/collection:v1')\n\n    # Add an alias\n    artifact.aliases.append('test')\n\n    # Persist all artifact modifications\n    artifact.save()\n</code></pre>\n<p>Error:</p>\n<pre><code class=\"lang-auto\">File \"/usr/local/lib/python3.8/dist-packages/requests/models.py\", line 1021, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://api.wandb.ai/graphql\n</code></pre>\n<p>The only way to do it is by using the UI and manually adding an alias.<br>\nIs there a way to programmatically update the alias of an artifact in a collection/registered model?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-13T23:25:30.281Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ahmeds\">@ahmeds</a> thank you for writing in, great to hear you\u2019re using the model registry! The API to interact with the registered models is still in progress, and more features will be available in future releases. The current supported commands can be found in <a href=\"https://docs.wandb.ai/guides/models/walkthrough\">this</a> reference doc and the companion Colab.</p>\n<p>However, updating the aliases may be done by using the artifact and linking it back to the same. Please see below a code snippet:</p>\n<pre><code class=\"lang-auto\">import wandb\napi = wandb.Api()\nart = api.artifact('entity/project/artifact:v1', type='model')\nart.link('entity/project/artifact', aliases=['test'])\n</code></pre>\n<p>Would this work for you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-19T10:25:50.738Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ahmeds\">@ahmeds</a> just checking in with you to see if you tried the above code and if it worked for you? thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-24T13:01:11.986Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ahmeds\">@ahmeds</a> since we haven\u2019t heard back from you, I will close this ticket for now. If you still experience this issue, please let us know and we will keep investigating!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-23T13:01:17.470Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Adding Confusion Matrix to report programatically",
		"Question_link": "https://community.wandb.ai/t/adding-confusion-matrix-to-report-programatically/3267",
		"Question_created_time": "2022-10-17T06:22:44.533Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 131,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>We are experimenting with programmatic report generation with WandB.<br>\nI would like to be able to add a Confusion Matrix to a report, but this is not one of the base types (as far as I can tell). Is there a good way to do this?<br>\nI could generate a PNG/Image and insert it, but I can\u2019t figure out how to add an Image to a report yet (see recent question).  Are there other ways?<br>\nThanks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-17T14:06:09.169Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> I am also posting here <a href=\"https://colab.research.google.com/drive/1Fepp-JLFvK-wLL2BZ_BnkCG_fAC6HFbo#scrollTo=An_example_with_all_of_the_blocks_and_panels\" rel=\"noopener nofollow ugc\">this Colab</a> and the Python SDK commands of our <a href=\"https://docs.wandb.ai/guides/reports/edit-a-report#add-plots\">Reports reference docs</a> which may be helpful.</p>\n<p>The confusion matrix isn\u2019t <a href=\"https://github.com/wandb/wandb/blob/main/wandb/apis/reports/panels.py\" rel=\"noopener nofollow ugc\">currently exposed</a> but I have increased this feature requests for our engineering team. We will reach out to you once this is implemented. I hope this helps, please let me know if you have any further questions or issues with the Reports API.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-10-24T12:58:47.288Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> since the above was accepted as a solution, I will close this ticket and let you know once the confusion matrix is implemented to be directly used with the Reports API. In the meantime, only a static version of it can be used programmatically in the reports, provided you have downloaded the chart as PNG.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-23T12:59:20.816Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sweep agents sometimes become extremely slow",
		"Question_link": "https://community.wandb.ai/t/sweep-agents-sometimes-become-extremely-slow/3171",
		"Question_created_time": "2022-09-22T08:07:59.543Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 532,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>I am running a hyperparameter grid search using sweeps. I launched 4 agents on the same machine but I noticed that after completing one run, one of the agents is struggling with the next run.</p>\n<p>This agent seems to be still communicating with <a href=\"http://wandb.ai\">wandb.ai</a>, the updated variable is regularly updated to the current time on the active run, and the agent itself has the same heartbeat as the others.</p>\n<p>The agent should be in its 8th run by now, but is only at the second one and only computed two epochs. All runs should take the same amount of time as they have the same number of epochs and model architecture.</p>\n<p>The \u201cLogs\u201d panel is also completely blank for this agent. And now that I\u2019m writing this, it seems another agent is starting to slow down.</p>\n<p>Also, I had the same issue in the previous sweep, this is the second time I run it with the same configuration. Previously, the issue appeared in the first few runs so I quickly stopped it and ran everything again.</p>\n<p>Is it most likely an issue with the CPU resources being not well distributed (all threads are at 100% usage), or could it be a network issue? How can I investigate what\u2019s happening?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-22T16:14:06.352Z",
				"Answer_body": "<p>I will add that the process seems to continue while using very little CPU, and it continues to log epochs. It has reached epoch 64 but only it is only logged up to epoch 4 on <a href=\"http://wandb.ai\">wandb.ai</a>.</p>\n<p>Perhaps this is a network issue that randomly target some processes?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-27T16:07:56.297Z",
				"Answer_body": "<p>Hi Ben, thank you for writing in! This shouldn\u2019t be happening intermittently. Can you double check that you have a good internet connection? If your internet is good, can you send me the link to your sweep page and send me your debug logs found in your wandb run directory please?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-30T18:53:15.387Z",
				"Answer_body": "<p>Hi Ben! Do you still need help here?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-05T22:12:43.184Z",
				"Answer_body": "<p>Hi again Ben! Since we haven\u2019t heard from you, I\u2019m going to close out this ticket. But please write back in if you\u2019re still running into this issue</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-22T09:56:28.877Z",
				"Answer_body": "<p>Hello again,</p>\n<p>Sorry for not replying the other time, I don\u2019t know why the notifications didn\u2019t get to me.<br>\nAnyways, I have the issue again, this time not in sweeps but in regular runs too.</p>\n<p>See this project: <a href=\"https://wandb.ai/bencrulis/continual_learning?workspace=user-bencrulis\" class=\"inline-onebox\">Weights &amp; Biases</a><br>\nglorious-armadillo-18 and dauntless-deluge-17 were launched at the same time and crunched through the iteration at the same speed initially, but then the second one slow down significantly.</p>\n<p>They don\u2019t have exactly the same computational cost, but it is glorious-armadillo-18 that should be a bit slower. Despite this, it is the one of the two that finished all 390 training experiences.</p>\n<p>The internet connection is apparently all good, this time it isn\u2019t even the same computing server as in my first post.<br>\nBy the way, the logs are sometimes a bit mangled even though in the server log file it is all good.</p>\n<p>Thanks for your insight</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-21T09:56:58.431Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Confusion matrix not generating \"Custom chart\" entry",
		"Question_link": "https://community.wandb.ai/t/confusion-matrix-not-generating-custom-chart-entry/3181",
		"Question_created_time": "2022-09-25T06:38:12.866Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 430,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m using the following code (based on <code>wandb.plot.confusion_matrix</code> because I accumulate my own confusion matrix per step using <code>tf.math.confusion_matrix</code>) to log a confusion matrix:</p>\n<pre><code class=\"lang-auto\"> data = []\n for i in range(n_classes):\n     for j in range(n_classes):\n         data.append([class_names[i], class_names[j], value[i, j]])\n\n fields = {\n     \"Actual\": \"Actual\",\n     \"Predicted\": \"Predicted\",\n     \"nPredictions\": \"nPredictions\",\n }\n return wandb.plot_table(\n     \"wandb/confusion_matrix/v1\",\n     wandb.Table(columns=[\"Actual\", \"Predicted\", \"nPredictions\"], data=data),\n     fields,\n     {\"title\": title},\n )\n</code></pre>\n<p>On one run I did get the custom chart, but the \u201cActual\u201d labels (on the Y-axis) were horribly laid out so I tweaked the code to generate different labels and now I don\u2019t see the custom chart. I tried to create my own custom chart cloning the settings from the other confusion matrix, but the \u201cOK\u201d button is grayed out.</p>\n<p>Are there some extra checks somewhere that decide whether or not to generate a confusion matrix report?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/d5db4d0f7e4bcecf7a79828175f915f107ddd53b.png\" data-download-href=\"/uploads/short-url/uvRybQw5OBb0uSf32Wb66ffRbFV.png?dl=1\" title=\"Screen Shot 2022-09-25 at 4.30.45 pm\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/d5db4d0f7e4bcecf7a79828175f915f107ddd53b.png\" alt=\"Screen Shot 2022-09-25 at 4.30.45 pm\" data-base62-sha1=\"uvRybQw5OBb0uSf32Wb66ffRbFV\" width=\"183\" height=\"500\" data-dominant-color=\"272727\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-09-25 at 4.30.45 pm</span><span class=\"informations\">268\u00d7732 9.57 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/0/074387bfc030623568325ce892dc4c2921eb1d2d.jpeg\" data-download-href=\"/uploads/short-url/12g1yYFJCC60Ln7oWdZARFbh57v.jpeg?dl=1\" title=\"Screen Shot 2022-09-25 at 4.34.29 pm\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/0/074387bfc030623568325ce892dc4c2921eb1d2d_2_690x333.jpeg\" alt=\"Screen Shot 2022-09-25 at 4.34.29 pm\" data-base62-sha1=\"12g1yYFJCC60Ln7oWdZARFbh57v\" width=\"690\" height=\"333\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/0/074387bfc030623568325ce892dc4c2921eb1d2d_2_690x333.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/0/074387bfc030623568325ce892dc4c2921eb1d2d_2_1035x499.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/0/074387bfc030623568325ce892dc4c2921eb1d2d_2_1380x666.jpeg 2x\" data-dominant-color=\"252525\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-09-25 at 4.34.29 pm</span><span class=\"informations\">2934\u00d71418 140 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-29T09:24:10.923Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tbirch\">@tbirch</a>, thank you for reporting this, and sorry for the delay in this response. I am following up with you here after our discussion in the Support chat.</p>\n<p>I have looked into the wandb-summary.json and the summary metrics between the two Runs. It appears that the variables conf_mat_table and conf_mat_norm_table were not logged in the case where the confusion matrix isn\u2019t generated. The Vega spec and the code snippet above are correct, but the button is greyed out because it can\u2019t query the data. I am wondering if you had overwritten the Run, or did this experiment run a single time?</p>\n<p>The artifacts seem to be properly logged in both cases and you can get them to your Workspace using a Weave expression such as:<br>\nproject(\u201centity\u201d, \u201cproject-name_\u201d).artifact(\u201crun-runid-conf_mat_norm_table\u201d).membershipForAlias(\u201cv19\u201d).artifactVersion.file(\u201cconf_mat_norm_table.table.json\u201d)</p>\n<p>Would you be interested in the option to download the data, generate the chart externally and then log it to this Run?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-29T10:25:10.202Z",
				"Answer_body": "<p>I\u2019d like to just know the correct code to log a \u201cwandb/confusion_matrix/v1\u201d given a NxN matrix of values and N labels. I don\u2019t care about the data for these runs, I was just doing them to test confusion matrix.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-11T22:09:47.739Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tbirch\">@tbirch</a> apologies for the late reply here, <a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-log/Log_a_Confusion_Matrix_with_W%26B.ipynb#scrollTo=6NZJwm8OE7Qw\" rel=\"noopener nofollow ugc\">this</a> is a working Colab that demonstrates how to log confusion matrices from your code. A minimal code example would be something like the following:</p>\n<pre><code class=\"lang-auto\">        vals = np.random.uniform(size=(10, 5))\n        probs = np.exp(vals)/np.sum(np.exp(vals), keepdims=True, axis=1)\n        y_true = np.random.randint(0, 5, size=(10))\n        labels = [\"Cat\", \"Dog\", \"Bird\", \"Fish\", \"Horse\"]\n        wandb.log({'confusion_matrix': wandb.plot.confusion_matrix(probs, y_true=y_true, class_names=labels)})\n</code></pre>\n<p>Please let me know if that would help, or if you still have issues or further questions about this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-17T10:35:14.328Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tbirch\">@tbirch</a> I wanted to follow up on this request, did the above Colab solve this? and would there be any further questions to help you with? thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-20T12:53:03.724Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tbirch\">@tbirch</a> since we haven\u2019t heard back from you, I am going to close this ticket for now. If you still experience any issues, please let us know and we will keep investigating.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-19T12:53:36.613Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Pulling artifact metadata into report",
		"Question_link": "https://community.wandb.ai/t/pulling-artifact-metadata-into-report/3201",
		"Question_created_time": "2022-09-29T19:01:58.863Z",
		"Question_answer_count": 5,
		"Question_score_count": 1,
		"Question_view_count": 610,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Is there a way to pull artifact metadata into reports? Here is my use case:</p>\n<p>I have several datasets that I use for evaluation of my model. They are stored as input artifacts and have metadata associated with them for example data type, source, and size. I would like to put a table in my report which outlines the size and type of each dataset, and ideally, could perform excel-like operations on the table (e.g. to sum the sizes of each dataset to create a total, or to get a label distribution).</p>\n<p>Right now I build these tables manually but it is error prone and time consuming. Here is an example:</p>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th>Dataset</th>\n<th>Size</th>\n<th>Sources</th>\n<th>% Positive Class</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>A</td>\n<td>1333</td>\n<td>[\u2018type-1\u2019 \u2018type-2\u2019]</td>\n<td>0.63</td>\n</tr>\n<tr>\n<td>B</td>\n<td>13308</td>\n<td>[\u2018type-1\u2019 \u2018type-2\u2019 \u2018type-3\u2019]</td>\n<td>0.63</td>\n</tr>\n<tr>\n<td>C</td>\n<td>1153</td>\n<td>[\u2018type-2\u2019 \u2018type-3\u2019]</td>\n<td>0.61</td>\n</tr>\n<tr>\n<td>D</td>\n<td>273</td>\n<td>[\u2018type-1\u2019]</td>\n<td>0.66</td>\n</tr>\n</tbody>\n</table>\n</div><p>Is there any existing way to do this? Or a hack to get something like it?</p>\n<p>Thanks in advance!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-30T14:05:13.152Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/elhutton\">@elhutton</a> thank you for writing in! You can do this using <a href=\"https://docs.wandb.ai/ref/app/features/panels/weave\">Weave</a> with a couple of options:</p>\n<p>i) get the metadata for a single artifact you have created with the following Weave expression (in your Report press \u201c/\u201d and add Weave)<br>\n<code>project(\"entity-name\", \"project-name\").artifact(\"artifact-name\").versions(\"v0\").metadata</code></p>\n<p>ii) get a table of artifacts for a specific artifact type in a Weave again expression such as:<br>\nproject(\u201centity-name\u201d, \u201cproject-name\u201d).artifactType(\u201cdataset\u201d).artifactVersions.metadata</p>\n<p>iii) render directly the artifacts metadata based on a specific artifact type as follows:<br>\nproject(\u201centity-name\u201d, \u201cproject-name\u201d).artifactType(\u201cdataset\u201d).artifacts</p>\n<p>Would any of these work for you? Please let me know if you have any further questions or issues with this!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-30T18:34:06.142Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a>,</p>\n<p>Thanks so much for your reply!</p>\n<p><code>project(\u201centity-name\u201d, \u201cproject-name\u201d).artifactType(\u201cdataset\u201d).artifactVersions.metadata</code> is getting me close to what I want. How would I then filter the table to only show the latest version of each artifact? Right now this view shows a different row for each version of each artifact, but I would like to show only the latest version of each artifact.</p>\n<p>Also, is there a way to perform operations on the values within the columns of such a table? For example, if I have a field called \u201cn_examples\u201d in the metadata for each artifact of a certain type, could I then get the sum of the n_examples over all the artifacts?</p>\n<p>Thanks a lot!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-14T18:55:46.937Z",
				"Answer_body": "<p>Hi <span class=\"mention\">@elhutt</span> apologies for the late response to this one. Showing only the latest version of each artifact should be possible by the following expression:<br>\n<code>project(\"entity\", \"project\").artifactType(\"dataset\").artifacts.membershipForAlias(\"latest\").artifactVersion.metadata</code></p>\n<p>You can indeed add columns and perform operations or group by the table. Each column has a cell expression that allows you to do some operations. You can find some examples in <a href=\"https://wandb.ai/stacey/xtable/reports/How-to-Compare-Tables-in-Workspaces--Vmlldzo4MTc0MTA\">this Report</a>.</p>\n<p>To get the sum of all rows you will need a new Weave expression as follows:<br>\n<code>project(\"entity\", \"project\").artifactType(\"dataset\").artifacts.membershipForAlias(\"latest\").artifactVersion.metadata[\"n_examples\"].sum</code></p>\n<p>Hope this helps, please let me know if you have any further questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-20T12:23:48.709Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/elhutton\">@elhutton</a> as this seems to be resolved for you, I will close the ticket for now. Please let me know in case the above solution didn\u2019t work for you and we will be happy to keep investigating!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-19T12:24:40.691Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Problem of not seeing all the images in media,",
		"Question_link": "https://community.wandb.ai/t/problem-of-not-seeing-all-the-images-in-media/3292",
		"Question_created_time": "2022-10-20T12:02:26.925Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 576,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>In the workspace/images, i am only seeing 30 images, when with oldest images getting deleted every time. Is there any limits that this images slot can show? If yes, is there any way that i can see more images that is saved on locally saved log folder??</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-20T13:10:32.472Z",
				"Answer_body": "<p>Hi ilhoon,</p>\n<p>Thanks for writing in! I was wondering if you could explain me how are you logging these images and if you could send me a link to the Workspace and so I can see the error. Thanks!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-25T09:27:47.101Z",
				"Answer_body": "<p>Hi ilhoon,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-19T12:02:46.431Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb.Html() not displaying",
		"Question_link": "https://community.wandb.ai/t/wandb-html-not-displaying/3271",
		"Question_created_time": "2022-10-18T04:55:19.749Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 302,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m trying to display a block of text (a confusion matrix actually, since they do not display in WB) using HTML.<br>\nThe code runs but it will not show up on run panel.  How can i see it?  It seems only images will display.</p>\n<pre><code class=\"lang-auto\">wandb.log({f\"ConfMatrix\" : wandb.Html(\"&lt;tt&gt;\"+my_confusion_matrix.ai2_confusion_matrix(y_true, y_pred...).replace(\"\\n\", \"&lt;P&gt;\").replace(\" \", \"&amp;nbsp;\"))})\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-19T20:07:40.484Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a>!</p>\n<p>Could you share a sample output of <code>my_confusion_matrix.ai2_confusion_matrix(y_true, y_pred, ...)</code>? I\u2019ll try to reproduce this on my end and look into how we can get this working for you.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-25T03:15:31.526Z",
				"Answer_body": "<p>Hi Kevin,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-27T03:32:51.935Z",
				"Answer_body": "<p>Hi Kevin, Since we have not heard back from you, we are closing this support request. If you would like to re-open this request, please reply to this thread!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-18T20:08:34.020Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Support for ComplexFloat",
		"Question_link": "https://community.wandb.ai/t/support-for-complexfloat/3279",
		"Question_created_time": "2022-10-18T17:44:07.645Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 128,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Python 3.9.7<br>\nWandb 0.13.4<br>\nPytorch 1.12.0+cu116</p>\n<p>I am running a neural network over complex valued data and getting the following error:</p>\n<pre><code class=\"lang-python\">Traceback (most recent call last):\n  File \"/home/aclifton/rf_fp/run_training_w_evaluate.py\", line 523, in &lt;module&gt;\n    run_training_pipeline(tmp_dict)\n  File \"/home/aclifton/rf_fp/run_training_w_evaluate.py\", line 229, in run_training_pipeline\n    outputs = rffp_model(**batch)\n  File \"/home/aclifton/anaconda3/envs/rffp/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1151, in _call_impl\n    hook_result = hook(self, input, result)\n  File \"/home/aclifton/anaconda3/envs/rffp/lib/python3.9/site-packages/wandb/wandb_torch.py\", line 110, in &lt;lambda&gt;\n    lambda mod, inp, outp: parameter_log_hook(\n  File \"/home/aclifton/anaconda3/envs/rffp/lib/python3.9/site-packages/wandb/wandb_torch.py\", line 105, in parameter_log_hook\n    self.log_tensor_stats(data.cpu(), \"parameters/\" + prefix + name)\n  File \"/home/aclifton/anaconda3/envs/rffp/lib/python3.9/site-packages/wandb/wandb_torch.py\", line 221, in log_tensor_stats\n    tmin = flat.min().item()\nRuntimeError: \"min_all\" not implemented for 'ComplexFloat'\n</code></pre>\n<p>I\u2019m not quite sure what to make of it and was wondering if anyone could offer some advice? Thanks in advance for your help!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-19T18:27:56.838Z",
				"Answer_body": "<p>For those interested, I have opened a github question here:</p><aside class=\"onebox githubissue\" data-onebox-src=\"https://github.com/wandb/wandb/issues/4382\">\n  <header class=\"source\">\n\n      <a href=\"https://github.com/wandb/wandb/issues/4382\" target=\"_blank\" rel=\"noopener nofollow ugc\">github.com/wandb/wandb</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"github-row\">\n  <div class=\"github-icon-container\" title=\"Issue\">\n\t  <svg width=\"60\" height=\"60\" class=\"github-icon\" viewbox=\"0 0 14 16\" aria-hidden=\"true\"><path fill-rule=\"evenodd\" d=\"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z\"></path></svg>\n  </div>\n\n  <div class=\"github-info-container\">\n    <h4>\n      <a href=\"https://github.com/wandb/wandb/issues/4382\" target=\"_blank\" rel=\"noopener nofollow ugc\">[Q] Support for ComplexFloat</a>\n    </h4>\n\n    <div class=\"github-info\">\n      <div class=\"date\">\n        opened <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2022-10-18\" data-time=\"20:41:46\" data-timezone=\"UTC\">08:41PM - 18 Oct 22 UTC</span>\n      </div>\n\n\n      <div class=\"user\">\n        <a href=\"https://github.com/aclifton314\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n          <img alt=\"aclifton314\" src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/9/9e486f3ce56550ea3b5fe50d71d6b5e893b410a3.jpeg\" class=\"onebox-avatar-inline\" width=\"20\" height=\"20\">\n          aclifton314\n        </a>\n      </div>\n    </div>\n\n    <div class=\"labels\">\n    </div>\n  </div>\n</div>\n\n  <div class=\"github-row\">\n    <p class=\"github-body-container\">I posted this in the wandb forum, but also wanted to post it here to just in cas<span class=\"show-more-container\"><a href=\"\" rel=\"noopener\" class=\"show-more\">\u2026</a></span><span class=\"excerpt hidden\">e it's more appropriate. If it's best to leave it in the forum, please let me know and I'll close this question.\n\nPython 3.9.7\nWandb 0.13.4\nPytorch 1.12.0+cu116\n\nI am running a neural network over complex valued data and getting the following error:\n```python\nTraceback (most recent call last):\n  File \"/home/aclifton/rf_fp/run_training_w_evaluate.py\", line 523, in &lt;module&gt;\n    run_training_pipeline(tmp_dict)\n  File \"/home/aclifton/rf_fp/run_training_w_evaluate.py\", line 229, in run_training_pipeline\n    outputs = rffp_model(**batch)\n  File \"/home/aclifton/anaconda3/envs/rffp/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1151, in _call_impl\n    hook_result = hook(self, input, result)\n  File \"/home/aclifton/anaconda3/envs/rffp/lib/python3.9/site-packages/wandb/wandb_torch.py\", line 110, in &lt;lambda&gt;\n    lambda mod, inp, outp: parameter_log_hook(\n  File \"/home/aclifton/anaconda3/envs/rffp/lib/python3.9/site-packages/wandb/wandb_torch.py\", line 105, in parameter_log_hook\n    self.log_tensor_stats(data.cpu(), \"parameters/\" + prefix + name)\n  File \"/home/aclifton/anaconda3/envs/rffp/lib/python3.9/site-packages/wandb/wandb_torch.py\", line 221, in log_tensor_stats\n    tmin = flat.min().item()\nRuntimeError: \"min_all\" not implemented for 'ComplexFloat'\n```\nI\u2019m not quite sure what to make of it and was wondering if anyone could offer some advice? Thanks in advance for your help!</span></p>\n  </div>\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-18T18:28:08.451Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Confusion Matrix generates report not plot",
		"Question_link": "https://community.wandb.ai/t/confusion-matrix-generates-report-not-plot/3270",
		"Question_created_time": "2022-10-18T03:50:14.660Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 434,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019ve recently attempted to build a Confusion Matrix using the <code>wandb.plot.confusion_matrix()</code> command.<br>\nMuch to my surprise, I get a Table object, not a plot.<br>\nImagine my surprise when I discovered a comment (<a href=\"https://community.wandb.ai/t/wandb-plot-confusion-matrix-just-show-a-table/1744\">here</a>) saying \u201cLogging the Table also is expected behaviour\u201d.<br>\nReally?  If I wanted a Table, i would call <code>wand.table.confusion_matrix()</code>, not the <code>plot</code> command.<br>\nI really do want a plot and and do NOT want to \u201cinteractively explore\u201d it.  I want to see it along with the twenty other plots that I generate with this run.  Clicking each and every CM to view it kinda defeats the purpose.<br>\nI would like to recommend that this choice be rethought, or at least put in the <code>table</code> namespace.<br>\nIs there a way to generate a real CM plot?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-18T11:45:14.064Z",
				"Answer_body": "<p>Hi Kevin, thanks for writing in! I\u2019ve investigated this issue and as you mentioned it seems that when you log the <code>wandb.plot.confusion_matrix()</code> it is logged as a tablet but, once the run is finished, the plot is created in the \u201cCustom Charts\u201d section. Could you please check if this is also the behaviour on your end? Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-19T01:09:00.583Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/system\">@system</a> Thank you for the response.<br>\nI can confirm that the CM tables does NOT show up in a plot.  Only the table is shown.<br>\nSee attached.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/a87d008da1038c99c53d5b2dc3c3ff9e4e7a0cf4.png\" data-download-href=\"/uploads/short-url/o2w1UTAcBwTJzflLCaGxc3kvjWQ.png?dl=1\" title=\"Untitled 3\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/a87d008da1038c99c53d5b2dc3c3ff9e4e7a0cf4_2_690x351.png\" alt=\"Untitled 3\" data-base62-sha1=\"o2w1UTAcBwTJzflLCaGxc3kvjWQ\" width=\"690\" height=\"351\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/a87d008da1038c99c53d5b2dc3c3ff9e4e7a0cf4_2_690x351.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/a87d008da1038c99c53d5b2dc3c3ff9e4e7a0cf4_2_1035x526.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/a/a87d008da1038c99c53d5b2dc3c3ff9e4e7a0cf4_2_1380x702.png 2x\" data-dominant-color=\"202020\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Untitled 3</span><span class=\"informations\">2526\u00d71288 142 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-19T09:01:19.123Z",
				"Answer_body": "<p>Hi Kevin,</p>\n<p>Thanks for your answer! I\u2019ve explored this and by running the following code I can see both the table (Tables section) and the plot (Custom Charts section) once the run is finished. Could you try running it and see if you get the plots and the tables? Also, it would be really useful if you could send me a code snippet and a link to the Workspace where you are logging this.</p>\n<pre><code>import wandbimport numpy as npwandb.init(project='Confusion_Matrix')cm = wandb.plot.confusion_matrix( probs=None, y_true=np.random.randint(3, size=5), preds=np.random.randint(3, size=5), class_names=['cat', 'dog', 'human'], title=f'Confusion Matrix')wandb.log({f'Confusion Matrix': cm})wandb.finish()\n</code></pre>\n<p><img src=\"https://weightsandbiases.zendesk.com/attachments/token/rysRbFROcW12KqEAu3yYtA03p/?name=image.png\" alt=\"\" role=\"presentation\"><br>\nBest,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-21T08:55:44.525Z",
				"Answer_body": "<p>Hi Kevin,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-25T09:34:31.620Z",
				"Answer_body": "<p>Hi Kevin,</p>\n<p>Since we have not heard back, I will go ahead and close this ticket for now. If you are having any issues again with this, feel free to message us here and we will be happy to re-open the ticket and keep investigating. Thank you!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-18T01:09:39.388Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "There is not history when logging wandb.plot.bar?",
		"Question_link": "https://community.wandb.ai/t/there-is-not-history-when-logging-wandb-plot-bar/3203",
		"Question_created_time": "2022-09-30T05:19:45.654Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 212,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\nI want to use wandb.plot.bar to log a bar chart, with below code</p>\n<pre><code class=\"lang-auto\">    table_data = some_function_to_get_data()\n    table = wandb.Table([\"label\", \"value\"], table_data)\n    wandb.log(\n        {\"a_bar_chart\": wandb.plot.bar(table, \"label\", \"value\")}, step=global_step,\n    )\n</code></pre>\n<p>There are two problems:</p>\n<ol>\n<li>there is no bar plot shown in browser, I need to create the a chart and custom it to bar, this is a little weird in the sense that I already told wandb to log a bar, but it does not do it by default</li>\n<li>there is no history of the bar chart, only the current bar chart, as we are <strong>logging</strong> the bar chart, I suppose I can see the history of bar chart, that\u2019s how we call it a log right?  So we should able to see the history of both table and bar chart during training.</li>\n</ol>\n<p>Maybe I did something wrong?<br>\nBTW, I know I can achieve what I want by using matplotlib and log the figure, but I prefer using wandb.pot, as this allows to free of worrying about create and delete the figure object.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-30T19:05:22.682Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/wztdream\">@wztdream</a>,</p>\n<p>Are you calling these lines of code in a loop? <code>log</code> for <code>Table</code>s are not designed to be called repeatedly right now, but we plan to change this in the future.</p>\n<p>I would definitely need some more context into what exactly you are looking to do to help you out best, and a link to your workspace would be great too.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-01T11:15:42.187Z",
				"Answer_body": "<p>thank you for your reply, yes I call these code repeatedly, every training step in my case, and I want to see how the bar chart change over training. So I suppose currently this is not supported, and have to wait until this feature is available <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-03T17:20:12.086Z",
				"Answer_body": "<p>Got it, what you would like to do instead in this case for now is log all your data under one table, log it when you are done with your table and then use the <code>wandb.plot.bar</code> function.</p>\n<p>An alternative (and admittedly not very efficient) hack would be to instantiate a new table object in each loop, copy data from your old table to your new table and then append more data to your new table. This has the potential for having a quadratic memory cost, so I would recommend against it, but if you really need real time logging on tables and have the RAM to support  it, this might be an option to consider.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-04T01:24:03.771Z",
				"Answer_body": "<p>let me make it clear, I did not mean log all data in <strong>one</strong> table.  I suppose it should be similar with logging an <code>pyplot.plot</code> figure. In that case there is one plot figure for each step, and there is a nice control bar to review the history figure. It will be nice there is similar control bar for <code> wandb.plot.bar</code> and even for <code>wandb.Table</code></p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/a/aeabd9c7b49dc0ed077c098cbafd99628756d8bb.png\" alt=\"image\" data-base62-sha1=\"oVdgDjzSUNRvPLtNDQZvXsNKdSj\" width=\"616\" height=\"88\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-18T18:30:14.006Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/wztdream\">@wztdream</a>,</p>\n<p>Apologies for the delay,  just wanted to provide an update here - I looked into this and we do not support the step slider on <code>wandb.plot.bar</code> as we do on images, since they work on different underlying mechanisms. That does sound like a great feature request though, and I am creating a feature request to enable this.</p>\n<p>For now, I would suggest using <code>wandb.Image</code> to get a step slider based bar graph.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-17T18:30:33.449Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Scaling in the parelles coordinates plot",
		"Question_link": "https://community.wandb.ai/t/scaling-in-the-parelles-coordinates-plot/3274",
		"Question_created_time": "2022-10-18T08:54:08.386Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 324,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I want to have custom value ranges for my hyperparameters, for example, for all GCN layers, I want it to range from 0 to 500.  I also want accuracy to range from 0-100. Would this be possible in the plot?</p>\n<p>Thanks.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/2fa3a6c300fee74cd3820b8960ba4c2c662641ce.jpeg\" data-download-href=\"/uploads/short-url/6Nr3SOp7uDdsYf6W6V2DDTkiMsS.jpeg?dl=1\" title=\"Screen Shot 2022-10-18 at 7.52.00 pm\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/2fa3a6c300fee74cd3820b8960ba4c2c662641ce_2_690x224.jpeg\" alt=\"Screen Shot 2022-10-18 at 7.52.00 pm\" data-base62-sha1=\"6Nr3SOp7uDdsYf6W6V2DDTkiMsS\" width=\"690\" height=\"224\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/2fa3a6c300fee74cd3820b8960ba4c2c662641ce_2_690x224.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/2fa3a6c300fee74cd3820b8960ba4c2c662641ce_2_1035x336.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/2fa3a6c300fee74cd3820b8960ba4c2c662641ce_2_1380x448.jpeg 2x\" data-dominant-color=\"EABFC3\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-10-18 at 7.52.00 pm</span><span class=\"informations\">1574\u00d7512 141 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-18T12:11:34.895Z",
				"Answer_body": "<p>Hi sepetab, thanks for writing in! I\u2019ve explored this and it seems that it\u2019s not an available feature now, would you like me to create a request for it? If so, it would be great if you could explain me why you consider that this would be useful and if it\u2019s blocking you in any way. In the meantime, you can create two new runs with the limits for each axis (for example 0 and 500 for all the GCN layers) and so you will have these new value ranges. Please let me know if this would be useful. Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-21T08:55:28.404Z",
				"Answer_body": "<p>Hi sepetab,</p>\n<p>I just wanted to follow up with you regarding your support request as we have not heard back from you. Please let me know if you would like me to create a request for this feature. Thanks!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-25T09:32:41.412Z",
				"Answer_body": "<p>Hi sepetab,</p>\n<p>Since we have not heard back from you, I will close this ticket but please feel free to re-open it in case you want me to create a request for this feature and, if so, could you explain me a bit more about why is it useful in your workflow and if it is blocking you in any way? Thanks!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-17T08:54:26.457Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Problem with Sweep; how to use run.finish() and log without error + Question about defined metric",
		"Question_link": "https://community.wandb.ai/t/problem-with-sweep-how-to-use-run-finish-and-log-without-error-question-about-defined-metric/3260",
		"Question_created_time": "2022-10-16T05:44:58.604Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 487,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi all,</p>\n<p>Nice to meet you!</p>\n<p>Currently I\u2019m not understanding how to use run.finish() and wandb.init for logging correctly. I\u2019m constantly getting an error when the wandb.agent sweeps to another model configuration. It\u2019s successfully doing the K-fold split, I dont see any errors. But it\u2019s right after the K-fold split  when the now model configuration is applied by the sweep.</p>\n<p><strong>Information about my code:</strong><br>\nMy code is a bit messy. I think there is no way to use K cross validation from scikitlearn. I\u2019ve tried it many times, but my input and output are (with N = number of datasets):</p>\n<p>Input 1: N datasets of 1000 numbers (x-axis)<br>\nInput2 : N datasets of 1000 numbers (y-axis)<br>\nOutput1: 1 number for each N\u2019th dataset<br>\nOutput2: 1 number for each N\u2019th dataset</p>\n<p>Input 1 and 2 are concatenated to produce 2 outputs. Lets say N is 300 and split is 0.2 then:<br>\nOutput1.shape, Output2.shape, Output1_test.shape, Output2_test.shape, X.shape, Y.shape, X_test.shape, Y_test.shape</p>\n<p>In the same order, their shapes: ((240,), (240,), (60,), (60,), (240, 1000), (240, 1000), (60, 1000), (60, 1000))<br>\nI think there is just no way I can define the cross validation with sklearn with this type of data I think\u2026</p>\n<p><strong>Error</strong><br>\nI\u2019ve introduced to save to model each time it\u2019s configured. Then load the model in each for loop with zero weigths. This way may cross validation succeeds. However, I\u2019m not sure how to correctly log my files. This code is doing bad at producing the groups I want them to be in; it\u2019s just overwriting them. Also, and as I mentioned; every time when a new model is initiated by the sweep, I get and error:</p>\n<p><strong>display</strong></p>\n<pre><code class=\"lang-auto\">wandb: Sweep Agent: Waiting for job.\nwandb: Job received.\nwandb: While tearing down the service manager. The following error has occured: [WinError 10054] De externe host heeft een verbinding verbroken\nwandb: Agent Starting Run: ekc1s4gm with config:\nwandb: \tbatch_size: 6\nwandb: \tdense_units: 63.48472025895866\nwandb: \tdense_units2: 81.47931201263756\nwandb: \tlearning_rate: 0.0007466619646085462\nwandb: \tnum_layers: 10\nwandb: \toptimizer: Adam\nwandb: WARNING Ignored wandb.init() arg project when running a sweep.\n\nException in thread ChkStopThr: \n.....\nSome file information\n.....\n\nException in thread NetStatThr::\n.....\nSome file information\n.....\n\nEnding in: \n\nConnectionResetError: [WinError 10054] De externe host heeft een verbinding verbroken\n    sent = self._sock.send(data)\nConnectionResetError: [WinError 10054] De externe host heeft een verbinding verbroken\n</code></pre>\n<p>So when this error occurs, it just continues right after  it created the new model configuration. The last time this error occurs is when the last loop and last model gets evaluated.  Also this error occurs every loop</p>\n<blockquote>\n<p>wandb: WARNING Ignored wandb.init() arg project when running a sweep.</p>\n</blockquote>\n<p>I think it definitely has to do something with the Groups I want certain logs to be in and therefore also my run.finish() command (<strong>The error does not error without any wandb.init()!!! The error also occurs with just the wandb.init() in the for loop, also if I add this, each sweep is overwritten by the other sweep so it\u2019s not creating groups aswell!!</strong>.  I\u2019m unsure if I placed them correctly.  it sounded logical to me to define run just once and to have to others as just wandb.init()\u2026  (see me code). I just don\u2019t understand how to use it in this case\u2026  I hope you do ? <strong>How can I group my folds and my validation seperately without  using wandb.init()</strong> ? Any recommendations on this would be very welcome!</p>\n<p><strong>My code</strong><br>\nHere is my code\u2026 A little messy, sorry.</p>\n<pre><code class=\"lang-auto\">def seed_all(seed):\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n</code></pre>\n<pre><code class=\"lang-auto\">def build_model(config):\n  \n    activ = config.activation   \n    dense_units = config.dense_units  \n    dense_units2 = config.dense_units2\n    num_layers = config.num_layers\n    batch_size = config.batch_size\n    batch_norm = False\n    optimizer = config.optimizer\n    learning_rate = config.learning_rate\n    \n    x = tf.keras.layers.Concatenate()([input1, input2])\n                   \n        #input_layer = Input(shape=(len(norm_train_X .columns), len(norm_train_X.iloc[0][0]))\n    x = Dense(units=dense_units, activation=activ)(x)\n        \n    for _ in range(num_layers):\n        x = Dense(units=dense_units, activation=activ)(x)\n        \n        \n    x1 = Dense(units=dense_units2, activation=activ)(x)\n    \n        # Y1 output will be fed directly from the second dense\n    \n    y1_output = Dense(units='1', name='y1_output')(x1)\n\n    third_dense = Dense(units=dense_units2, activation=activ)(x1)\n\n         # Y2 output will come via the third dense\n    y2_output = Dense(units='1', name='y2_output')(third_dense)\n        \n    model = Model(inputs=[input1, input2], outputs=[y1_output, y2_output])\n    print(model.summary())   \n    model.save_weights('model.h5', overwrite = True)\n    return model\n</code></pre>\n<pre><code class=\"lang-auto\">def train():\n    test_loss_sum =np.array([0])\n    Hp_loss_sum = np.array([0])\n    MDp_loss_sum = np.array([0])\n    Hp_rmse_sum = np.array([0])\n    MDp_rmse_sum = np.array([0])\n    loss_sum = np.array([0])\n    loss_sum_tot =0 \n    Hp_R2_append = []\n    test_loss_sum_tot =0\n    hp_append = []\n    MDp_append = []\n    hp_pred_append = []\n    MDp_R2_append = []\n    MDp_sum = 0\n    Hp_sum = 0\n    test_loss_mean = 0 \n    hp_pred_append = []\n    MDp_pred_append = []\n    Hp_loss_sum_tot = 0\n    MDp_loss_sum_tot =0\n    Hp_rmse_sum_tot =0\n    MDp_rmse_sum_tot=0\n    \n    X = np.vstack(np.asarray(norm1.numpy()[:]))\n    Y = np.vstack(np.asarray(norm2.numpy()[:]))\n    max_trials = 2\n    epochs = 100\n    test_loss_sum = np.array([0])\n    Hp = train_Y_1_t\n    MDp = train_Y_2_t\n    Hp_test = test_Y_1_t\n    MDp_test = test_Y_2_t\n    hyperparams = dict(\n        lr = 0.0001,\n        optimizer = 'Adam',\n        dense_units = 256,\n        batch_size = 64,\n        epochs = 1,        \n        ense_units2 = 64,\n        activation = 'relu',)\n    \n    cb_reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor = \"val_loss\",\n        mode = 'auto',\n        factor = 0.1,\n        patience = 20,\n        min_delta = 1e-04, #default\n        min_lr = 1e-07,\n        verbose = 1)\n\n    cb_earlystop= tf.keras.callbacks.EarlyStopping(\n        monitor=\"val_loss\",\n        mode=\"auto\",\n        min_delta = 0,\n        patience=25,\n        verbose=1)\n    \n    run = wandb.init(project=\"custom-charts\", config=hyperparams, reinit = True) #Note the Reinit here!\n    config = wandb.config\n    \n    Wandcalback = WandbCallback(monitor='val_loss')\n    \n    model =  build_model(config=config)\n    \n    LR = config.learning_rate     # 0.001\n    \n    if config.optimizer=='Adam':\n        optimizer = tf.keras.optimizers.Adam(lr = LR)\n    elif config.optimizer=='RMSprop':\n        optimizer = tf.keras.optimizers.RMSprop(lr=LR, rho=0.9, epsilon=1e-08, decay=0.0)\n    else: \n        raise\n    \n    # Compile the model\n    model.compile(optimizer=optimizer,\n    loss={'y1_output': 'mse', 'y2_output': 'mse'},\n    metrics={'y1_output': tf.keras.metrics.RootMeanSquaredError(),'y2_output': tf.keras.metrics.RootMeanSquaredError()})\n   \n    n_splits = 4\n    skf = KFold(n_splits, shuffle = True)\n    skf.get_n_splits(X, Y)\n    i=0\n    vall_loss = []\n    for train_index, test_index in skf.split(X, Y):\n        \n        wandb.init(project=\"custom-charts\", group = \"folds_experiment\", job_type = \"fold{}\".format(i)) \n        model.load_weights('model.h5')\n        \n        train_index = train_index.astype(int)\n        test_index = test_index.astype(int)\n        X = np.array(X)\n        Y = np.array(Y)\n        Hp = np.array(Hp)\n        MDp = np.array(MDp)\n        X_train, X_test = X[train_index], X[test_index]\n        Y_train, Y_test = Y[train_index], Y[test_index]\n        Hp_train, Hp_test = Hp[train_index], Hp[test_index]\n        MDp_train, MDp_test = MDp[train_index],MDp[test_index]      \n        \n        history = model.fit([tf.convert_to_tensor(X), tf.convert_to_tensor(Y)], [Hp, MDp], validation_data = ([tf.convert_to_tensor(X_test), tf.convert_to_tensor(Y_test)], [Hp_test, MDp_test]), \n                     batch_size=config.batch_size,    \n                     epochs=2,             \n                     callbacks=[Wandcalback,cb_earlystop,cb_reducelr],\n                     verbose=1)\n        \n        loss_sum = pd.DataFrame(history.history)['loss'].iloc[-1]  + loss_sum\n        test_loss_sum = pd.DataFrame(history.history)['val_loss'].iloc[-1]  + test_loss_sum\n        Hp_loss_sum = pd.DataFrame(history.history)['val_y1_output_loss'].iloc[-1]  + Hp_loss_sum\n        MDp_loss_sum = pd.DataFrame(history.history)['val_y2_output_loss'].iloc[-1]  + MDp_loss_sum\n        Hp_rmse_sum = pd.DataFrame(history.history)['val_y1_output_root_mean_squared_error'].iloc[-1]  + Hp_rmse_sum\n        MDp_rmse_sum = pd.DataFrame(history.history)['val_y2_output_root_mean_squared_error'].iloc[-1]  + MDp_rmse_sum\n            \n        loss_sum_tot = pd.DataFrame(history.history)['loss']  + loss_sum_tot\n        test_loss_sum_tot = pd.DataFrame(history.history)['val_loss']  + test_loss_sum_tot\n        Hp_loss_sum_tot = pd.DataFrame(history.history)['val_y1_output_loss'] +  Hp_loss_sum_tot\n        MDp_loss_sum_tot = pd.DataFrame(history.history)['val_y2_output_loss']  + MDp_loss_sum_tot\n        Hp_rmse_sum_tot = pd.DataFrame(history.history)['val_y1_output_root_mean_squared_error']  +  Hp_rmse_sum_tot\n        MDp_rmse_sum_tot = pd.DataFrame(history.history)['val_y2_output_root_mean_squared_error']  +  MDp_rmse_sum_tot   \n\n        Y_pred = model.predict([tf.convert_to_tensor(X_test), tf.convert_to_tensor(Y_test)])\n        metric = tfa.metrics.r_square.RSquare()\n            \n        metric.update_state(Hp_test, Y_pred[0].flatten())\n        result = metric.result()\n        R_2_Hp = result.numpy()\n        Hp_R2_append.append(R_2_Hp)\n           \n        metric.update_state(MDp_test, Y_pred[1].flatten())\n        result = metric.result()\n        R_2_MDp = result.numpy()\n        MDp_R2_append.append(R_2_MDp)\n        \n        hp_append.append(Hp_test)\n        MDp_append.append(MDp_test)\n        hp_pred_append.append(Y_pred[0])\n        MDp_pred_append.append(Y_pred[1])\n        MDp_sum = MDp_sum + Y_pred[1]\n        Hp_sum = Hp_sum + Y_pred[0]\n        i = i + 1 \n    \n    test_loss_mean = test_loss_sum/n_splits\n    loss_sum_mean = loss_sum/n_splits\n    test_loss_sum_mean =  test_loss_sum/n_splits\n    Hp_loss_sum_mean = Hp_loss_sum/n_splits\n    MDp_loss_sum_mean = MDp_loss_sum/n_splits\n    Hp_rmse_sum_mean = Hp_rmse_sum/n_splits\n    MDp_rmse_sum_mean = MDp_rmse_sum/n_splits\n         \n    test_MDp_R2 = np.mean(MDp_R2_append)\n    test_Hp_R2 = np.mean(Hp_R2_append)\n                \n        \n    Hp_mean = Hp_sum/n_splits\n    MDp_mean = MDp_sum/n_splits    \n        # wandb.init(project= \"sweep &amp; optimalisation RandomSearch\", group=\"experimentfold{}\".format(i), job_type=\"validation\")\n    wandb.init(project=\"custom-charts\", group =\"folds_experiment\", job_type = \"validation\")\n    for val_los in range(len(test_loss_sum_tot)):\n        wandb.log({\"val_loss_mean\" : test_loss_sum_tot[val_los]/n_splits})\n    for loss in range(len(loss_sum_tot)):\n        wandb.log({\"loss_mean\": loss_sum_tot[loss]/n_splits})\n    for val_MDp_los in range(len(test_loss_sum_tot)):\n        wandb.log({\"val_MDp_loss_mean\" : test_loss_sum_tot[val_MDp_los]/n_splits})\n    for val_hp_los in range(len( Hp_loss_sum_tot)):\n        wandb.log({\"val_hp_loss_mean\": Hp_loss_sum_tot[val_hp_los]/n_splits})\n    for val_MDp_rmse in range(len(MDp_rmse_sum_tot)):\n        wandb.log({\"val_MDp_rmse_mean\" : MDp_loss_sum_tot[val_MDp_rmse]/n_splits})\n    for val_hp_rmse in range(len(Hp_rmse_sum_tot)):\n        wandb.log({\"val_MDp_rmse_mean\": Hp_rmse_sum_tot[val_hp_rmse]/n_splits})\n       \n    hp_append = np.concatenate(hp_append)\n    MDp_append = np.concatenate(MDp_append)\n    hp_pred_append = np.concatenate(hp_pred_append)\n    MDp_pred_append = np.concatenate(MDp_pred_append)\n            \n    Hp_score = np.sqrt(mean_squared_error(hp_pred_append,hp_append))\n    MDp_score = np.sqrt(mean_squared_error(MDp_pred_append,MDp_append))  \n    test_MDp_R2 = np.mean(MDp_R2_append)\n    test_Hp_R2 = np.mean(Hp_R2_append)\n        \n    wandb.log({\"R2_score_hp\":Hp_score, \"R2_score_MDp\":MDp_score, \"R2_hp\":test_Hp_R2, \"R2_MDp\":test_MDp_R2})\n    Hp = np.asarray(Hp_mean.flatten())\n    MDp = np.asarray(MDp_mean.flatten())\n    Hp_testt = np.asarray(Hp_test.flatten())\n    MDp_testt = np.asarray(MDp_test.flatten())\n        \n        \n    fd = pd.DataFrame({\"pred\": Hp,\"actual\":Hp_testt})\n    print(fd)\n    table = wandb.Table(dataframe=fd)\n    wandb.log({'scatter-plot1': wandb.plot.scatter(table, \"pred\", \"actual\")})\n        \n    fd2 = pd.DataFrame({\"pred\": MDp,\"actual\":MDp_testt})\n    print(fd2)\n    table2 = wandb.Table(dataframe=fd2)\n    wandb.log({'scatter-plot2': wandb.plot.scatter(table2, \"pred\", \"actual\")})\n        \n    predictions_h = [s for s in Hp_mean]\n    predictions_h\n    table2 = wandb.Table(data=predictions_h, columns=[\"h_predictions\"])\n    wandb.log({'my_histogramM': wandb.plot.histogram(table2, \"h_predictions\",\n    title=\"Prediction Score Distribution Hubble Parameter\")})\n        # hist = np.histogram(predictions_h)\n        # wandb.log({'Hubble parameter': wandb.plot.histogram(hist)})\n        \n        \n    predictions_hh = [ s for s in MDp_mean]\n    predictions_hh\n    table3 = wandb.Table(data=predictions_hh, columns=[\"h_predictions\"])\n    wandb.log({'my_histogram': wandb.plot.histogram(table3, \"h_predictions\",\n    title=\"Prediction Score Distribution Mass Density\")})\n        # hist = np.histogram(predictions_hh)\n        # wandb.log({'Mass Density parameter': wandb.plot.histogram(hist)})\n    run.finish()\n</code></pre>\n<pre><code class=\"lang-auto\">sweep_config = {\n    'method': 'random',         \n    'metric': {\n        'name': 'test_loss_mean',     \n        'goal': 'minimize'      \n    },\n    'parameters': {\n        'dense_units': {\n            'distribution': 'log_uniform_values',\n            'min': 32,\n            'max': 256\n        },\n        'learning_rate': {\n            'distribution': 'log_uniform_values',\n            'min': 0.0000001,\n            'max': 0.1\n        },\n        'dense_units2': {\n            'distribution': 'log_uniform_values',\n            'min': 32,\n            'max': 256\n        },\n        'batch_size': {\n            #Integers between 32 and 256 \n            # with evenly distributed logarithms\n            'values': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\n               \n        },\n        'optimizer': {\n            'values': ['Adam', 'RMSprop']\n        },\n        'num_layers': {\n            'values': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n        }\n\n    }\n}\n</code></pre>\n<pre><code class=\"lang-auto\">sweep_id = wandb.sweep(sweep_config, entity=\"stijnvdbosch\", project=\"custom-charts\")\nwandb.agent(sweep_id, function=train, count=2, project=\"custom-charts\")\n</code></pre>\n<p>You can also see i\u2019m updating my own <strong>defined metric</strong> (not from model.fit) called <strong>test_loss_mean</strong>. I suppose I did that correct?<br>\nIf there is any more information you need to help me, then, please, send  me a message and I will reply in a blink. <img src=\"https://emoji.discourse-cdn.com/twitter/blush.png?v=12\" title=\":blush:\" class=\"emoji\" alt=\":blush:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-12-15T05:45:13.425Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Very Slow UI - How to bulk delete charts?",
		"Question_link": "https://community.wandb.ai/t/very-slow-ui-how-to-bulk-delete-charts/3183",
		"Question_created_time": "2022-09-25T22:14:37.344Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 994,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019ve been using W&amp;B for 1.5 years and this is the first time I am running into a problem. This problem is very serious and I can\u2019t access any of my runs.</p>\n<p>The UI is very slow because there are 129 charts that were created automatically in my charts section of my project.</p>\n<p>I am confused because I did not manually create these 129 charts, they were automatically created when I completed my run.</p>\n<p>It takes over 5 minutes to open a run from the table, then when I go to the charts section, it takes almost 10 minutes to delete 1 of the 129 charts.</p>\n<p>The whole entire UI is completely freezing and slow because of this. When I delete the charts section, all 129 charts go to the Hidden Charts section, and I cant delete that section at all.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-27T20:08:00.253Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/japi\">@japi</a> , thank you for writing in. This is currently the intended behavior for after deleting charts. The charts when deleted from your workspace will populate in the hidden panels section of the UI. This is being looked at by our team and I will provide an update once I hear back. In the meantime, I have asked the backend team to review your workspace to see what can be done to assist you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-04T00:25:20.546Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/japi\">@japi</a></p>\n<p>I appreciate your patience on this while I verified with App team the functionality of deleted graphs. The behavior your are seeing is as designed. When a user \u201cdeletes\u201d a panel, it simply gets moved to the \u201cHidden Panels\u201d section. You should keep this section closed so that those panels don\u2019t affect workspace performance. That hidden panel section functions as a sort of trash can, but you can\u2019t delete charts from that section entirely.</p>\n<p>In terms of your new project, how are you logging your data? Can you please provide a brief code example for us to review. We might be able to reduce the number of charts logged based on how you are setting up your experiments.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-04T04:14:10.000Z",
				"Answer_body": "<p>Hi Mohammad, the new project is actually running fine.</p>\n<p>I am logging the metrics from the sci-kit learn classification_report for my testSets</p>\n<p>classification_report1 = classification_report(allLabels,allPredixs, output_dict=True)</p>\n<p>prediction_time = time.perf_counter()</p>\n<p>accuracy = accuracy_score(allLabels,allPredixs)</p>\n<p>if(self.wandbSwitch):</p>\n<p>api = wandb.Api()</p>\n<p>run = api.run(self.wandbApiUUID)</p>\n<p>print(\u201cALL KEYS\u201d,run.summary.keys())</p>\n<p>for key in classification_report1[\u2018non_shaky\u2019]:</p>\n<p>run.summary[f\u2019testSet_{testSetName[testSetIndex]}.classification_report.non_shaky.{key}'] = classification_report1[\u2018non_shaky\u2019][key]</p>\n<p>print(f\u2019testSet_{testSetName[testSetIndex]}.classification_report.non_shaky.{key}: ',classification_report1[\u2018non_shaky\u2019][key])</p>\n<p>for key in classification_report1[\u2018shaky\u2019]:</p>\n<p>run.summary[f\u2019testSet_{testSetName[testSetIndex]}.classification_report.shaky.{key}'] = classification_report1[\u2018shaky\u2019][key]</p>\n<p>print(f\u2019testSet_{testSetName[testSetIndex]}.classification_report.shaky.{key}: ',classification_report1[\u2018shaky\u2019][key])</p>\n<p>run.summary[f\"testSet_{testSetName[testSetIndex]}.Prediction\"] = prediction_time-start_time</p>\n<p>run.summary[f\"testSet_{testSetName[testSetIndex]}.Test Error Rate\"] = round((1-accuracy)*100, 2)</p>\n<p>run.update()</p>\n<p>run.summary.update()</p>\n<p>I created a new project under the name \u201cjapi-tuc\u201d however I ran into the same problem, there are only 44 runs however almost 130 charts were created.</p>\n<p>I understand that when deleting charts they are sent to the hidden_charts section.</p>\n<p>However even when I delete the chart and they are in the hidden_charts section, it seems almost impossible to load the project table still.</p>\n<p>It is taking over 6 minutes to load the project table with just 40 runs.</p>\n<p>Please let me know if there is a way around this !</p>\n<p>Kind regards,</p>\n<p>Japinder</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-05T06:45:18.967Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/japi\">@japi</a> , that number of charts shouldn\u2019t  impact your workspace performance, especially as most are in the hidden panels section.  Try to:</p>\n<ul>\n<li>Clear browser history and cache</li>\n<li>Access the project in a different web browser</li>\n</ul>\n<p>Does the issue persist?</p>\n<p>Please watch the screen recording I sent to your email where I successfully accessed/browsed your new project without running into the behavior you are experiencing. When time permits, provide a screen recording of the behavior your are experiencing while displaying the browser console tab (this may provide us additional clues into what may be occurring). I appreciate your patience as we continue to look into this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-10T19:16:40.735Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/japi\">@japi</a>  since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-09T19:17:29.585Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Some clarification about W&B starter-plan pricing",
		"Question_link": "https://community.wandb.ai/t/some-clarification-about-w-b-starter-plan-pricing/3227",
		"Question_created_time": "2022-10-07T16:51:21.915Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 174,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello everyone! I\u2019m currently evaluating W&amp;B as experiment tracking solution for the company I\u2019m currently working. So far, we found that W&amp;B cover all our basic needs so we would like to buy a starter plan. However before to move on,  I need some clarifications about the pricing that are not so clear from the info available on the website:</p>\n<ul>\n<li>\n<p>Tracked Hours:  for tier 1 plan there are 250 to 5000 cumulative tracked hours. These are counted per-user or shared by all the user of the team? In other words, can each user track up to 5000 hours of experiments each month? It seems to be a little bit confusing since the the bill is specified per user.</p>\n</li>\n<li>\n<p><a href=\"https://wandb.ai/site/pricing#lineage-tracking\">Storage/Artifacts</a>: these 100GB of storage should be intended as shared between Storage &amp; Artifacts or there are a total of 200gb (100+100) of storage for each objects category. By the way, what is considered \u201cfiles saved to W&amp;B\u201d? Tracked metrics/distributions/parameters are included in this category?</p>\n</li>\n</ul>\n<p>Sorry for the silly questions but we want to be extra sure before to buy a license <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-07T22:13:52.278Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/prfina\">@prfina</a> !</p>\n<p>Thank you for reaching out! Here are the answers to your questions:</p>\n<ol>\n<li>\n<p>How our subscriptions operate is that each subscription is associated to what we call an \u201corganization\u201d - which is a collection of all your teams under your account. So, if your company buys a subscription, you will create an \u201corganization\u201d which can be further divided into teams and each team can hold individual users. The \u201ctracked hours\u201d are tracked over the whole organization - as in the number of cumulative logged hours tracked by your users.</p>\n</li>\n<li>\n<p>There is a total of only 100GB of total storage provided for free for both files and Artifacts combined. Any file saved through <code>wandb.save</code> or <code>wandb.log_artifact</code> is included here.</p>\n</li>\n</ol>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-10T08:22:58.398Z",
				"Answer_body": "<p>Everything is clear now, thanks a lot <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a> !</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-10T09:04:26.095Z",
				"Answer_body": "<p>Glad to hear! I\u2019ll close this support request for now, but if any other issues seem to pop up here, feel free to reply to this thread!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-09T08:23:11.393Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "AttributeError with sweep",
		"Question_link": "https://community.wandb.ai/t/attributeerror-with-sweep/3221",
		"Question_created_time": "2022-10-05T11:21:21.823Z",
		"Question_answer_count": 6,
		"Question_score_count": 1,
		"Question_view_count": 299,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>When I activated my sweep agent, I got AttributeError as following:</p>\n<p>Thread HandlerThread:<br>\nTraceback (most recent call last):<br>\nFile \u201c/home1/prof/jeon/anaconda3/envs/deep/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\u201d, line 50, in run<br>\nself._run()<br>\nFile \u201c/home1/prof/jeon/anaconda3/envs/deep/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\u201d, line 101, in _run<br>\nself._process(record)<br>\nFile \u201c/home1/prof/jeon/anaconda3/envs/deep/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\u201d, line 263, in _process<br>\nself._hm.handle(record)<br>\nFile \u201c/home1/prof/jeon/anaconda3/envs/deep/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\u201d, line 130, in handle<br>\nhandler(record)<br>\nFile \u201c/home1/prof/jeon/anaconda3/envs/deep/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\u201d, line 140, in handle_request<br>\nhandler(record)<br>\nFile \u201c/home1/prof/jeon/anaconda3/envs/deep/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\u201d, line 666, in handle_request_run_start<br>\nself._system_stats = stats.SystemStats(<br>\nFile \u201c/home1/prof/jeon/anaconda3/envs/deep/lib/python3.10/site-packages/wandb/sdk/internal/stats.py\u201d, line 76, in <strong>init</strong><br>\nself._pid = settings._stats_pid<br>\nAttributeError: \u2018SettingsStatic\u2019 object has no attribute \u2018_stats_pid\u2019</p>\n<p>However, the code \u2018main.py\u2019 is ran correctly without sweep\u2026<br>\nHow can I fix this issue so I can use sweep agent?<br>\nI do really appreciate your help.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-07T01:31:31.466Z",
				"Answer_body": "<p>Hi SeungHwan! This issue could be probably related to <code>wandb.init().</code> Using i<code>f __name__ == __main__</code> or setting <code>start_method='thread'</code> should help out here. If you\u2019re still running into issues after trying this, can you send me your debug logs found in your wandb run directory please?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-10T01:55:59.321Z",
				"Answer_body": "<p>Thank you for your prompt response and your suggestion.</p>\n<p>I already used if <strong>name</strong> == <strong>main</strong>, so I tried to set <code>settings=dict(start_method=\"thread\")</code> in wandb.init(). However, the same issue happens to me\u2026</p>\n<p>Debug log is:</p>\n<pre><code class=\"lang-auto\">2022-10-10 10:51:21,749 INFO    StreamThr :85970 [internal.py:wandb_internal():88] W&amp;B internal server running at pid: 85970, started at: 2022-10-10 10:51:21.715580\n2022-10-10 10:51:21,750 DEBUG   HandlerThread:85970 [handler.py:handle_request():138] handle_request: status\n2022-10-10 10:51:21,751 DEBUG   SenderThread:85970 [sender.py:send_request():315] send_request: status\n2022-10-10 10:51:21,752 DEBUG   SenderThread:85970 [sender.py:send():301] send: header\n2022-10-10 10:51:21,752 DEBUG   SenderThread:85970 [sender.py:send():301] send: run\n2022-10-10 10:51:21,753 INFO    WriterThread:85970 [datastore.py:open_for_write():75] open: /home1/prof/jeon/an/causal_vae/wandb/run-20221010_105121-ear9tkf4/run-ear9tkf4.wandb\n2022-10-10 10:51:22,310 DEBUG   HandlerThread:85970 [handler.py:handle_request():138] handle_request: check_version\n2022-10-10 10:51:22,313 INFO    SenderThread:85970 [dir_watcher.py:__init__():216] watching files in: /home1/prof/jeon/an/causal_vae/wandb/run-20221010_105121-ear9tkf4/files\n2022-10-10 10:51:22,313 INFO    SenderThread:85970 [sender.py:_start_run_threads():912] run started: ear9tkf4 with start time 1665366681.0\n2022-10-10 10:51:22,313 DEBUG   SenderThread:85970 [sender.py:send():301] send: summary\n2022-10-10 10:51:22,354 INFO    SenderThread:85970 [sender.py:_save_file():1155] saving file wandb-summary.json with policy end\n2022-10-10 10:51:22,355 DEBUG   SenderThread:85970 [sender.py:send_request():315] send_request: check_version\n2022-10-10 10:51:22,455 DEBUG   HandlerThread:85970 [handler.py:handle_request():138] handle_request: run_start\n2022-10-10 10:51:22,756 INFO    WriterThread:85970 [datastore.py:close():279] close: /home1/prof/jeon/an/causal_vae/wandb/run-20221010_105121-ear9tkf4/run-ear9tkf4.wandb\n2022-10-10 10:51:23,314 INFO    Thread-14 :85970 [dir_watcher.py:_on_file_created():275] file/dir created: /home1/prof/jeon/an/causal_vae/wandb/run-20221010_105121-ear9tkf4/files/wandb-summary.json\n2022-10-10 10:51:23,445 INFO    SenderThread:85970 [sender.py:finish():1315] shutting down sender\n2022-10-10 10:51:23,445 INFO    SenderThread:85970 [dir_watcher.py:finish():362] shutting down directory watcher\n2022-10-10 10:51:24,315 INFO    SenderThread:85970 [dir_watcher.py:finish():392] scan: /home1/prof/jeon/an/causal_vae/wandb/run-20221010_105121-ear9tkf4/files\n2022-10-10 10:51:24,315 INFO    SenderThread:85970 [dir_watcher.py:finish():406] scan save: /home1/prof/jeon/an/causal_vae/wandb/run-20221010_105121-ear9tkf4/files/config.yaml config.yaml\n2022-10-10 10:51:24,316 INFO    SenderThread:85970 [dir_watcher.py:finish():406] scan save: /home1/prof/jeon/an/causal_vae/wandb/run-20221010_105121-ear9tkf4/files/wandb-summary.json wandb-summary.json\n2022-10-10 10:51:24,316 INFO    SenderThread:85970 [file_pusher.py:finish():168] shutting down file pusher\n2022-10-10 10:51:24,316 INFO    SenderThread:85970 [file_pusher.py:join():173] waiting for file pusher\n2022-10-10 10:51:25,062 INFO    Thread-17 :85970 [upload_job.py:push():139] Uploaded file /home1/prof/jeon/an/causal_vae/wandb/run-20221010_105121-ear9tkf4/files/config.yaml\n2022-10-10 10:51:25,069 INFO    Thread-18 :85970 [upload_job.py:push():139] Uploaded file /home1/prof/jeon/an/causal_vae/wandb/run-20221010_105121-ear9tkf4/files/wandb-summary.json\n2022-10-10 10:51:25,519 ERROR   StreamThr :85970 [internal.py:wandb_internal():163] Thread HandlerThread:\nTraceback (most recent call last):\n  File \"/home1/prof/jeon/anaconda3/envs/deep/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 50, in run\n    self._run()\n  File \"/home1/prof/jeon/anaconda3/envs/deep/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n    self._process(record)\n  File \"/home1/prof/jeon/anaconda3/envs/deep/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 263, in _process\n    self._hm.handle(record)\n  File \"/home1/prof/jeon/anaconda3/envs/deep/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 130, in handle\n    handler(record)\n  File \"/home1/prof/jeon/anaconda3/envs/deep/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 140, in handle_request\n    handler(record)\n  File \"/home1/prof/jeon/anaconda3/envs/deep/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 666, in handle_request_run_start\n    self._system_stats = stats.SystemStats(\n  File \"/home1/prof/jeon/anaconda3/envs/deep/lib/python3.10/site-packages/wandb/sdk/internal/stats.py\", line 76, in __init__\n    self._pid = settings._stats_pid\nAttributeError: 'SettingsStatic' object has no attribute '_stats_pid'\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-20T03:39:42.069Z",
				"Answer_body": "<p>Thank you for the debug log! Can you also send me the link to your workspace so I can see if I can find anything there since the error is still the same as in the previous message? Also, for good measure, if you\u2019re not using our most recent version, can you upgrade to it and see if that\u2019s able to help?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-25T16:32:23.753Z",
				"Answer_body": "<p>Hi Seunghwan, do you still need help here?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-28T18:31:31.229Z",
				"Answer_body": "<p>Hi Seunghwan, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-09T01:56:22.420Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "ConnectionResetError appearing while i am training due to wandb run",
		"Question_link": "https://community.wandb.ai/t/connectionreseterror-appearing-while-i-am-training-due-to-wandb-run/3210",
		"Question_created_time": "2022-10-01T22:14:58.353Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 159,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi all,<br>\nI am facing a problem while I am training my model.<br>\nthe training crashed due to wandb run.<br>\ncould anyone explain why this error happened and how can I avoid it.<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/0/0169513adb7250af5ca174ac97243b8fdc0e5c6a.jpeg\" alt=\"Capture.PNG\" data-base62-sha1=\"cu7muubyTNVdJjnHUpHxiUChdM\" width=\"690\" height=\"360\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-01T22:18:53.675Z",
				"Answer_body": "<pre><code class=\"lang-auto\">ConnectionreSerror: [Winerror 10054] An existing connection had to be closed by the remote host\nException in Thread Netstatatthr:\nTradeback (Most recent Call Last):\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-03T23:12:09.544Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/asekhri\">@asekhri</a> , happy to help. We\u2019ve seen this issue and it could be directly attributed to proxy configuration when users attempt to log to wandb from inside a fire-walled corporate network or they might be connected to a VPN. Are any of those cases applicable to you?</p>\n<p>Please provide the <code>debug.log</code> and <code>debug-internal.log</code> files for the crashed run, as the files may provide additional clues. Additionally, are you using wandb cloud or local? and which version are you using. Thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-06T22:54:39.810Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/asekhri\">@asekhri</a> since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-05T22:54:52.631Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Deleting data from self-hosted server",
		"Question_link": "https://community.wandb.ai/t/deleting-data-from-self-hosted-server/2613",
		"Question_created_time": "2022-06-15T14:29:55.067Z",
		"Question_answer_count": 13,
		"Question_score_count": 3,
		"Question_view_count": 1238,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I saw <a href=\"https://community.wandb.ai/t/delete-files-from-a-run/1031\">this</a> post, but it doesn\u2019t answer my question. We are running a self-hosted wandb instance. We have somewhat limited space, though we\u2019ve been good about deleting old runs through the interface.</p>\n<p>We thought deleting from the interface would also delete the physical files from the hard disk, but that doesn\u2019t appear to be the case. For example, going into the minio folder on the server shows a particular project taking up 130 GB of space, while wandb reports 30 GB. That\u2019s a big difference!</p>\n<p>How do we really really delete files from minio that wandb no longer knows anything about?</p>\n<p>Suggestion: please have a central <code>/usage/</code> URL for admins to look through usage from all teams and users rather than having to go through each one individually!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-17T18:27:10.321Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/tkott\">@tkott</a>, I\u2019m looking into this but I believe there isn\u2019t a way through the UI to physically delete the files from your hard drive. I\u2019ll look into this more to confirm this and if this is indeed the case, I can put in a feature request for you to make this possible through the UI.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-17T18:43:33.000Z",
				"Answer_body": "<p>Hi Nate \u2013 so how do you suggest that we free up space generally then? Do we have to note the hash / digest of files and look for them on the minio server by hand?</p>\n<p>I would expect that if you \u201cdelete\u201d from the server with a big scary \u201cthis is a permanent operation\u201d type warning, that the server will, in fact, remove the files. If it doesn\u2019t remove the files, it isn\u2019t actually a permanent operation since the files can be salvaged (albeit with some work).</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/c068a531a4cb060559186c287c0508c8c7321469.jpeg\" alt=\"image001.jpg\" data-base62-sha1=\"rs7SiFek7tnQtx4wt2yshERms0p\" width=\"79\" height=\"79\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-22T15:10:19.015Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/nathank\">@nathank</a> any suggestions for how do it programmatically through wandb in the meantime?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-12T20:09:02.108Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tkott\">@tkott</a>,<br>\nSorry for the delay here.  A member of our team put together a script to do this for you <a href=\"https://gist.github.com/venky-wandb/b95542f107b377fb9e1ad2c811201bbe\" rel=\"noopener nofollow ugc\">here</a>.</p>\n<p>You can use this by running <code>python file_cleanup.py -d 10</code> where the <code>-d</code> tag can specify how many days ago a run has to have been deleted from the UI in order for the script to delete it from Minio storage.</p>\n<p>Please note that this will only work if you are using our bare-metal Docker container setup. If you have connected an external database this will not work.</p>\n<p>Also, we are working towards making this a default part of our local deployment where you can set a retention policy for deleted runs and the server will automatically clean up deleted runs after a certain amount of time .</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-12T20:57:53.000Z",
				"Answer_body": "<p>Thanks! If I understand that gist right, I first need to use the UI to delete the run. At that point, the run files are still on the server. At that point, I can run this script (or maybe set to run weekly). When the script finds run that were deleted more than 10 days ago (via <code>-d 10</code> option), it will look for their references and delete files that live in the parent folder found ( <code> \"/vol/minio/local-files/{}/{}/{}\".format(entity_name, project_name, run_id)</code>).</p>\n<p>So a couple of questions:</p>\n<ol>\n<li>\n<p>What happens to the artifacts associated with runs?</p>\n</li>\n<li>\n<p>What happens with child folders? (And why isn\u2019t it all files and folders within the parent folder?)</p>\n</li>\n<li>\n<p>If child directories are present, are they now orphaned with no pointer from the database?</p>\n</li>\n</ol>\n<p>Thanks!</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/c068a531a4cb060559186c287c0508c8c7321469.jpeg\" alt=\"image001.jpg\" data-base62-sha1=\"rs7SiFek7tnQtx4wt2yshERms0p\" width=\"79\" height=\"79\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-21T18:12:48.826Z",
				"Answer_body": "<ol>\n<li>The artifacts are not deleted, if there is an artifacts directory in the object storage we still keep it and delete all the rest of the files.</li>\n<li>All child folders are also deleted in the object storage. We don\u2019t delete Artifacts folder because artifacts are not just used by runs but also by other parts of the product so we keep them to avoid breaking things in other parts of the app.</li>\n<li>There is no connection with the runs table in the database once the deletion happens but there might be other tables that are still referring to these artifacts.</li>\n</ol>\n<p>This can be run from outside the container or inside the container. But in either case it expects to have the <code>mysql-connector-python</code> python package installed on the container. You can login to the container using <code>docker exec -it wandb-local bash</code> and run pip install <a href=\"https://gist.github.com/venky-wandb/b95542f107b377fb9e1ad2c811201bbe#file-file_cleanup-py-L2\">like this</a> to install the dependency.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-21T18:37:24.000Z",
				"Answer_body": "<p>Thanks for confirming those questions!</p>\n<p>Can you also then recommend a way of deleting older versions of artifacts? (which you can do from the UI as well, but presumably this doesn\u2019t affect the underlying store in the same way that deleting runs doesn\u2019t remove them from the store.)</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/c068a531a4cb060559186c287c0508c8c7321469.jpeg\" alt=\"image001.jpg\" data-base62-sha1=\"rs7SiFek7tnQtx4wt2yshERms0p\" width=\"79\" height=\"79\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-04T14:36:12.617Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/a-sh0ts\">@a-sh0ts</a>  or <a class=\"mention\" href=\"/u/nathank\">@nathank</a> \u2013 any suggestions on dealing with artifacts in a similar way?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-12T18:00:13.295Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/tkott\">@tkott</a> , apologies for the delay here.<br>\nYou can delete artifact versions programmatically via our <a href=\"https://docs.wandb.ai/ref/python/public-api/artifact#delete\">public API</a>. Here\u2019s a sample script doing the same:</p>\n<pre><code class=\"lang-auto\">api = wandb.Api()\nproject = api.project('project_name')\n\nfor artifact_type in project.artifacts_types():\n    for artifact_collection in artifact_type.collections():        \n        for version in artifact_collection.versions():\n            if artifact_type.type == 'dataset':\n                if len(version.aliases) &gt; 0:\n                    # print out the name of the one we are keeping\n                    print(f'KEEPING {version.name}')\n                else:\n                    print(f'DELETING {version.name}')\n                    if not dry_run:\n                        print('')\n                        version.delete()\n</code></pre>\n<p>Please let me if this helps.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-12T18:18:15.511Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/anmolmann\">@anmolmann</a> thanks and I think that\u2019s fine for deleting it from the UI, but my understanding is that this would not delete it from the actual physical drive through the minio interface. How do I do <em>that</em>?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-06T17:33:10.485Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/tkott\">@tkott</a> , we identified this as a bug where deleting the artifact versions via API or UI wouldn\u2019t actually delete them from the object storage as well. Our team is working on a fox for this and I\u2019ll keep you posted as soon as i\u2019ve an update on this issue.<br>\nMeanwhile, you can delete these artifact versions via a script similar <a href=\"https://gist.github.com/venky-wandb/b95542f107b377fb9e1ad2c811201bbe\" rel=\"noopener nofollow ugc\">to this one</a>. You should remove lines 44 and 45, and update the <code>elif</code> in line 41 to <code>elif os.path.isdir(f)</code> so that if the folder contains any artifacts then that folder is deleted as well. Also, you should add one more dir path, maybe have a list of dir_paths in line 31 as artifacts are also stored in <code>wandb_artifacts</code> in <code>local-files</code>. So, your additional dir_path would be <code>dir_path_2 = \"/vol/minio/local-files/wandb_artifacts/{}/{}\".format( idx_1, idx_2)</code>, where idx_1 is the artifact index and idx_2 is the artifact version index.<br>\nApologies for the inconvenience caused here as I do acknowledge this workaround would be a hacky way to get around this issue.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/0/0f65f09b2d5d85af038107eae357ec7bd8e1e33e.png\" data-download-href=\"/uploads/short-url/2cdzanw1auqQjNmN2MsHLYoMSUm.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/0/0f65f09b2d5d85af038107eae357ec7bd8e1e33e_2_690x365.png\" alt=\"image\" data-base62-sha1=\"2cdzanw1auqQjNmN2MsHLYoMSUm\" width=\"690\" height=\"365\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/0/0f65f09b2d5d85af038107eae357ec7bd8e1e33e_2_690x365.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/0/0f65f09b2d5d85af038107eae357ec7bd8e1e33e_2_1035x547.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/0/0f65f09b2d5d85af038107eae357ec7bd8e1e33e.png 2x\" data-dominant-color=\"F3F3F5\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1174\u00d7622 35.5 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-06T18:12:51.000Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/anmolmann\">@anmolmann</a> Thanks for the suggestion. I\u2019m a little confused because while we\u2019ve used the gist you point out to remove old runs (yay!), if I understand it the artifacts are a separate thing. I don\u2019t know which run to delete that would also (when the changes to the gist are made as you suggest) delete a specific artifact version, and only that specific artifact version. I\u2019m also not sure that we necessarily want to delete the run at the same time as the artifact. Can you elaborate a bit more about the relationship between artifacts and runs and how the gist would handle that?</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/5/52d5f1c08649212fe6768d2cacdcf8df711810d9.jpeg\" alt=\"~WRD000.jpg\" data-base62-sha1=\"bONwCMToQaefS5MCaw6ckHjvG5z\" width=\"100\" height=\"100\"></p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/c068a531a4cb060559186c287c0508c8c7321469.jpeg\" alt=\"image001.jpg\" data-base62-sha1=\"rs7SiFek7tnQtx4wt2yshERms0p\" width=\"79\" height=\"79\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-05T18:13:10.590Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Continuing an artifact",
		"Question_link": "https://community.wandb.ai/t/continuing-an-artifact/3198",
		"Question_created_time": "2022-09-29T04:28:27.593Z",
		"Question_answer_count": 5,
		"Question_score_count": 1,
		"Question_view_count": 784,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>We are running long data preparation run (30+ hours) to pre-build source files for training.  However, part of the dataset was not ready and was excluding from the current run (which is 20+ hours into the run).  I would like to process the remaining data and ADD it to this current artifact.<br>\nI note that whenever I run this code is creates a new version of the artifact.<br>\nHow can I append new data to an existing artifact?</p>\n<p>Second question: Can I add new data in-parallel with the original job.  That is, can two different processes add data to the same artifact at the same time?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-29T23:56:05.719Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> , thank-you for writing in, we will be happy to help here. As per my response to your email inquiry, I am discussing this with the team as to how best to approach the above. Once I hear back,  I will provide you an update. Thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-30T19:32:06.301Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a></p>\n<p>After speaking with the the team, you have options via our wandb artifact upsert calls to append to a non-finalized artifact as output of a run, see <a href=\"https://docs.wandb.ai/ref/python/run#upsert_artifact\">here</a>.However, we highly recommend you utilize S3 URI reference instead as it would be the more straightforward approach. Add all data to the S3 bucket <a href=\"https://docs.wandb.ai/guides/track/track-external-files#amazon-s3-gcs-references\">then setup reference URI</a> to generate the new artifact with all your processed data. If you run into any issues, please let me know.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-10-04T20:13:50.353Z",
				"Answer_body": "<p>Thank you.  I think that I am starting understand that Artifact are intended as locked or frozen containers of objects.  And this since projects and experiments will reference them historically, they cant be changed once finalized, since that would mess with the historical references.<br>\nWe are already using s3 references for all our files in the datasets.<br>\nThank you, Kevin</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-05T23:08:16.163Z",
				"Answer_body": "<p>Thank you <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> for confirming  you are using S3 references for all your files.</p>\n<p>In regards to Artifacts, your understanding is correct in that Artifacts are containers of objects to track history of changes and can be thought of as a versioned directory. This makes it easy to get a complete and auditable history of changes to your files. Anytime you change the contents of an Artifact, W&amp;B will create a new version of your artifact instead overwriting the previous contents (maintaining the historical reference you mentioned). Please do reach out again anytime you have additional questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-04T23:08:54.825Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Histogram across steps with in a run",
		"Question_link": "https://community.wandb.ai/t/histogram-across-steps-with-in-a-run/3219",
		"Question_created_time": "2022-10-05T05:03:14.952Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 210,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>As we prepare our datasets we are using WandB to track results of different runs.  These data-prep runs last several days across 10M+ frames and we would like to log the ongoing results to histograms.  For example, we want to generate histograms of statistics metrics across all data frames.<br>\nThe simplest technique would seem to be to log each parameter step-by-step for each frame using <code>wandb.log()</code>.  But the workspace Panel (\u201cAdd Panel\u201d) does not not support histograms.<br>\nI\u2019ve read the <a href=\"https://docs.wandb.ai/guides/track/log/media#histograms\">section on histograms</a> repeatedly and I can\u2019t help but conclude that continuous tracking of histograms is not supported.  Which seems odd.<br>\nThe documentation suggests that I should accumulate the elements in a local list, generate a histogram with each frame (locally) and to then log the histogram to WandB. Basically we are just plotting the histogram locally and pushing a figure. This seems inefficient for large data sets.<br>\nWandB would seem to be well suited for tracking statistics across steps and runs using histograms.<br>\nBut perhaps I have not yet found it in the documentation.  Can you provide some guidance?</p>\n<p>To reiterate, I want to log a several statistics every step across many (millions) of steps.  I wish to plot a histogram of these values across all steps.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-05T22:19:52.985Z",
				"Answer_body": "<p>Hi Kevin!</p>\n<p>The docs you found using <code>wandb.log({'Hist' : wandb.Histogram(...)})</code> would be the best way to log your histograms, even across multiple steps.</p>\n<p>One potential path for you might also be to use <a href=\"https://docs.wandb.ai/ref/app/features/custom-charts\">Custom Charts</a> - a chart format which uses <a href=\"https://vega.github.io/vega/\" rel=\"noopener nofollow ugc\">Vega</a> to build charts.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-11T17:53:05.819Z",
				"Answer_body": "<p>Hi Kevin,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-15T10:32:49.309Z",
				"Answer_body": "<p>Hi Kevin, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-04T22:20:48.539Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Strategy for adding referenced files to an artifact",
		"Question_link": "https://community.wandb.ai/t/strategy-for-adding-referenced-files-to-an-artifact/3094",
		"Question_created_time": "2022-09-11T05:29:45.197Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 224,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>We are new to WandB and working out best-practices for using referenced-artifacts.<br>\nWe have an S3 bucket were we keep our data corpus, so that it can be shared between machines.<br>\nWe want to use WandB to track these files and to use it to download/synchronize copies of the datasets to local machines.<br>\nThere seem to be two ways to add files to an artifact:</p>\n<ol>\n<li>By-Group: Create the file locally and put it to S3. Repeat with all other data files until done.  Then use the <code>artifact.add_reference()</code> command and point it to the S3 prefix/directory for the files.  This will add the directory and its files to the artifact.  The artifact will report that only a single \u201cfile\u201d exists (since we only added the directory) \u2013 which I think is weird, by the way \u2013 but all the files seem to be there.</li>\n<li>One-by-one: create the file locally, put it to S3 and immediately add the S3 file to the artifact.  Repeat until all files are done and then close the artifact and the run.  The artifact will now properly note that n-files have been added.</li>\n</ol>\n<p>The real question is, when I later execute a <code>download(root=my-local-path)</code> operation, will I be able to cleanly load the files from the artifact to my local directory.  That is, without having to fight a path mismatch between the S3 paths and my local paths.<br>\nThat is, if the S3 path is: /really/deep/s3/path/to/my/dataset/files<br>\nAnd my local path is: /Users/user/<br>\nCan the files end up here: /Users/user/dataset/files</p>\n<p>Thank you,<br>\nKevin</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-14T18:15:56.567Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> , when <a href=\"https://docs.wandb.ai/ref/python/artifact#download\">downloading</a> the Artifact, set the argument <code>recursive= True</code>and define your <code>root</code> directory to download Artifacts to. The artifacts will download cleanly.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-20T18:17:33.822Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-20T18:40:26.157Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> Thank you for the response.  However my core question still stands.  What sets the base path or root path for a given file.  If I add the files one by one how does it know the root path of the file?<br>\nFor example:<br>\nIf the S3 path for a file is: /really/deep/s3/path/to/my/dataset/files/my_file<br>\nAnd my local path is: /Users/user/<br>\nDo the files end up here: /Users/user/dataset/files/my_file<br>\nOr do I get: /Users/user/really/deep/s3/path/to/my/dataset/files/my_file</p>\n<p>How do I control this?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-05T04:28:17.503Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> Do you have any thoughts on this?  Thank you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-04T04:28:55.592Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "MatPlotLib into WandB",
		"Question_link": "https://community.wandb.ai/t/matplotlib-into-wandb/3212",
		"Question_created_time": "2022-10-03T04:23:09.932Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 784,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I need to import MatPlotLib images into WandB.  On the surface, this seems simple, since the documentation clearly shows how to ingest a <code>plt</code> or <code>fig</code> object.  However, WandB is making a mess of the plots and I don\u2019t want to recode them in plotly.<br>\nSo I next want to use MatPlotLib to save a PNG and ingest that.  Again seems easy, but I would prefer to do it using an in-memory buffer object (this avoids messing with local paths and temp directories on various instances).  Apparently I\u2019m not the first one to do this either (<a href=\"https://stackoverflow.com/questions/35999020/convert-pyplot-figure-into-wand-image-image\" rel=\"noopener nofollow ugc\">link</a>). The instructions are clear and show someone has already done this.  But it fails when I try it:</p>\n<pre><code class=\"lang-auto\">fig, (ax1, ax2) = plt.subplots(2, 1, dpi=300, figsize=(10, 5))\n...\nbuf = io.BytesIO()\nplt.savefig(buf, format='png')\nbuf.seek(0)\nwandb.log(({\"chart\": wandb.Image(file=buf)}))\n</code></pre>\n<p>The error seems to be with <code>wandb.Image()</code>.  It returns:<br>\n<code>{TypeError}__init__() got an unexpected keyword argument 'file'</code></p>\n<p>I can remove the <code>file=</code> parameter so that the command is:</p>\n<pre><code class=\"lang-auto\">wandb.Image(buf)\n</code></pre>\n<p>And I get: <code>{AttributeError}'_io.BytesIO' object has no attribute 'ndim'</code></p>\n<p>Any recommendations?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-03T17:26:35.860Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a>!</p>\n<p>The <code>BytesIO</code> type is not supported by <code>wandb.Image</code> which is why you are running into this issue. Here are a few options that would work instead:</p>\n<ul>\n<li><code>wandb.log({ 'chart' : wandb.Image(Image.open(buf)) })</code></li>\n<li><code>wandb.log({ 'chart' : wandb.Image(fig) })</code></li>\n<li>\n<code>wandb.log({ 'chart' : fig })</code> (Please note that this does not actually save an image but an interactable Plotly chart on your workspace</li>\n</ul>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-10-05T04:18:50.434Z",
				"Answer_body": "<p>Thank you, <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a>!<br>\nThe first line you provided worked perfectly!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-05T20:49:59.222Z",
				"Answer_body": "<p>Glad to hear! I\u2019ll close this request for now, but if any other issues seem to pop up here, feel free to reply to this thread!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-04T04:18:55.558Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Report page often crashes when I collapse a section of the report",
		"Question_link": "https://community.wandb.ai/t/report-page-often-crashes-when-i-collapse-a-section-of-the-report/3115",
		"Question_created_time": "2022-09-14T12:29:47.156Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 92,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>report page often crashes when I collapse a section of the report.<br>\nHere is one of the reports that crash: <a href=\"https://wandb.ai/dc914337/nri/reports/Generalizing-movement--VmlldzoyNjMyMTUx\" class=\"inline-onebox\">Weights &amp; Biases</a></p>\n<p>How to reproduce:</p>\n<ol>\n<li>click \u201cedit\u201d report</li>\n<li>collapse and open different sections until you see</li>\n</ol>\n<blockquote>\n<p>Oops, something went wrong.</p>\n<p>If this keeps happening, email us at <a href=\"mailto:support@wandb.com\">support@wandb.com</a> with this page link.</p>\n</blockquote>\n<p>Emailing the address doesn\u2019t work as well. Google says group doesn\u2019t exist</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-15T21:01:43.660Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dc914337\">@dc914337</a>, I was unable to reproduce the page crash within any of the reports for that project. Can you please clear your browser cache and try reproducing again. Does this crash occur with other browsers? Additionally, I verified <code>support@wandb.com</code>  does receive emails. Can you share a screenshot of the message you received from google.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-16T16:24:07.873Z",
				"Answer_body": "<p>shared the screenshot in the related group. I suggest to keep them separate as they are probably unrelated (one is mailing system, another is your website).</p>\n<p>For me the page crashes both in Firefox and Chrome. Happens on my macbook and on windows. I have 32gb of ram on both.<br>\nOk, apparently just closing and opening is not enough. You need to edit something inside the section and then close it. Then it immediately shows you this:<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/5438141342f87906ca06707734bd1db500b7e50b.png\" alt=\"image\" data-base62-sha1=\"c12fO7WNm9qY5iZAQ10hpQeCICT\" width=\"665\" height=\"349\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-21T05:56:43.567Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dc914337\">@dc914337</a>, I was able to reproduce this behavior on my end. I flagged this as a bug report for the app team to review. I will update you once a fix is in place. Thanks again for surfacing this issue.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-04T22:22:24.289Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dc914337\">@dc914337</a> , the issue with crashing reports when collapsing a section has been fixed by our team. Thanks again for bringing it to our attention. Please let me know if there is anything else I can  assist you with.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-03T22:23:04.288Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Storage limit under free plan: How long until freed space is recognised?",
		"Question_link": "https://community.wandb.ai/t/storage-limit-under-free-plan-how-long-until-freed-space-is-recognised/3179",
		"Question_created_time": "2022-09-23T09:26:47.434Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 185,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I had exceeded the 100GB storage limit available for the free plan yesterday and accordingly deleted a lot of sweeps and artifacts right away. In the usage dashboard, it says that I\u2019m taking up 104GB. However, when I click the project to see a more detailed view, I only see artfiacts/ with 20GB and runs/ with 16GB. It seems that the 104GB are not updated to the current state.</p>\n<p>Is this a caching issue? Are my runs in danger of not being able to save their data?</p>\n<p>My user name is sgerard, in case you want to look into this more closely.</p>\n<p>Best regards</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-28T18:52:31.939Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sgerard\">@sgerard</a>, we\u2019re looking into your account now. I see the same error in your usage. We\u2019ll try to get this fixed ASAP as the storage usage should update as soon as you delete Artifacts/files that are using data.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-04T14:59:08.050Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/sgerard\">@sgerard</a> we\u2019ve identified the bug and are working on a fix. In the meantime it looks like if you delete the entire Artifact collection rather than just versions this will clear this up. I understand if that isn\u2019t an option though. I can follow up as soon as we have a fix on this and let you know.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-03T14:59:14.546Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Labels of x and y axis is not clearly seen?",
		"Question_link": "https://community.wandb.ai/t/labels-of-x-and-y-axis-is-not-clearly-seen/3177",
		"Question_created_time": "2022-09-23T00:50:31.656Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 231,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Dears, I am new to use wandb. Currently when I plot a curve by creating a link between my experiment and wandb, the labels of x and y axis is inside of the graph grid itself making it invisible as you see in the picture below. How can I fix this issue so I can make labels out of the grid of the graph?<br>\nI do really appreciate your help.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/2/22b56b8efcd793ac0d3b4c589d74684bbe7ca3da.jpeg\" data-download-href=\"/uploads/short-url/4X2VldFgZ2NNZmAaZXvucjxWrTY.jpeg?dl=1\" title=\"convergence curve11\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/22b56b8efcd793ac0d3b4c589d74684bbe7ca3da_2_690x362.jpeg\" alt=\"convergence curve11\" data-base62-sha1=\"4X2VldFgZ2NNZmAaZXvucjxWrTY\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/22b56b8efcd793ac0d3b4c589d74684bbe7ca3da_2_690x362.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/22b56b8efcd793ac0d3b4c589d74684bbe7ca3da_2_1035x543.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/2/22b56b8efcd793ac0d3b4c589d74684bbe7ca3da_2_1380x724.jpeg 2x\" data-dominant-color=\"F8F9FA\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">convergence curve11</span><span class=\"informations\">2528\u00d71328 179 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\n.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-23T22:55:19.842Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/getutadesse\">@getutadesse</a> thank you for reporting this! May I ask how you created this plot, was it logged from API as plot or data? In case you added this panel from the UI was it in the Workspace or Report section? For extra charts\u2019 customisation, I would recommend that you log plots in one of the following ways:</p>\n<ol>\n<li><a href=\"https://docs.wandb.ai/ref/app/features/custom-charts/walkthrough\">as a Custom chart using Vega spec</a></li>\n<li><a href=\"https://docs.wandb.ai/guides/track/log/plots#matplotlib-and-plotly-plots\">as matplotlib or Plotly</a></li>\n<li><a href=\"https://docs.wandb.ai/ref/app/features/panels/weave\">Weave</a></li>\n</ol>\n<p>Would any of these work for you? Please let me know if you need further assistance on how to use the above options, glad to help!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-29T11:47:08.020Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/getutadesse\">@getutadesse</a> just checking in to see if any of the above options work for you, and if you need any further help here. Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-04T13:14:14.598Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/getutadesse\">@getutadesse</a> since we haven\u2019t heard back from you, I will go ahead and close this ticket for now. Please let us know if you still have any issues or questions, and we will be happy to assist you further!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-03T13:14:25.315Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to save/log PipFile",
		"Question_link": "https://community.wandb.ai/t/how-to-save-log-pipfile/3150",
		"Question_created_time": "2022-09-19T04:33:50.701Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 171,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I understand that WandB stores the <code>requirements.txt</code> as part of its logging for every experiment.<br>\nSince i use <code>pipenv</code> I would also like to log the <code>PipFile</code>.  However this file is at the path-level as <code>requirements.txt</code> and I am prohibited from saving this file.  I get the error message: <code>globs can't walk above base_path</code>.  Is there a way to log this file?</p>\n<p>Edit: I\u2019ve discovered that I can use <code>wandb.init(dir=\"my/project/root/dir\")</code> and can then use <code>wandb.save(\"Pipfile\")</code>.  Now I dont have an error, but the file also is NOT being added to the files logged by the experiment.  I\u2019m guessing that I instead need to copy the <code>Pipfile</code> into the local wandb temp directory.  Perhaps that is enough.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-22T08:34:22.405Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> thank you for writing in! Copying <code>Pipfile</code> into the wandb run directory may do the trick here, did you try this? Another option would be to provide the <code>base_path</code> argument to your <code>wandb.save</code> call as following <code>wandb.save(\"PipFile\", base_path=\"my/project/root/dir\")</code>. Would this work for you? if not, can you please send a screenshot of the <code>tree</code> command output?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-27T18:54:27.232Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> I wanted to follow up on this issue, did you try any of the suggested workarounds? Is the file still not logged? thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-03T10:26:45.344Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevinashaw\">@kevinashaw</a> since we haven\u2019t heard back from you, I will go ahead and close this ticket for now. Please let us know if this issue still occurs for you, and we will be happy to reopen this and keep investigating!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-12-02T10:27:14.510Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Add row to table replaces existing rows",
		"Question_link": "https://community.wandb.ai/t/add-row-to-table-replaces-existing-rows/3205",
		"Question_created_time": "2022-09-30T12:00:24.075Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 1692,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I want to add a row to a table in each epoch.  But it overrides existing data each time a new row is added (or at least there is always only 1 row shown in the dashboard. Ive tried different options when to create the table using <em>wandb.Table</em>, use <em>table.add_row</em> and when to use <em>run.log</em>.  The problem is always the same.</p>\n<p>In the dashboard <em>runs.summary[\u201cimage_table\u201d]</em> is used to show the table.</p>\n<p>What might be the problem here? Shouldnt I create the wandb.Table once and then  add_row and log for each epoch? Is there an option to show the full table in dashboard correctly?</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-30T18:10:08.452Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/nime6\">@nime6</a>,</p>\n<p>We are still building a streaming API for tables, so logging on every epoch is not currently supported. I would suggest you to call <code>add_row</code> per epoch and call <code>log</code> once per training run.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-29T18:10:34.579Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Training yoloX",
		"Question_link": "https://community.wandb.ai/t/training-yolox/2825",
		"Question_created_time": "2022-07-29T10:14:10.950Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 145,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>hi,<br>\ni am trying to enable logging for yolox nano, but when i start training i get this error :</p>\n<p>File \u201c/content/YOLOX/yolox/utils/logger.py\u201d, line 206, in <strong>init</strong><br>\nself.cats = val_dataset.cats<br>\n\u2502           \u2514 &lt;yolox.data.datasets.voc.VOCDetection object at 0x7f6f1d379e10&gt;<br>\n\u2514 &lt;yolox.utils.logger.WandbLogger object at 0x7f6f1e77ed10&gt;</p>\n<p>AttributeError: \u2018VOCDetection\u2019 object has no attribute \u2018cats\u2019</p>\n<p>also this is my colab code:<br>\n!python tools/train.py -f exps/example/yolox_voc/yolox_voc_nano.py -d 1 -b 16 --fp16 -o --logger wandb wandb-project object-detectiontemp -c weights/yolox_nano.pth</p>\n<p>could you please guide me or give me some hints on what should i do ?<br>\nbecause as i see there is a val_dataset variable, but i have no idea how do you fill that .</p>\n<p>thanks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-29T10:43:00.877Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/phoenix64\">@phoenix64</a> ! Engineer from W&amp;B here. The reason for this issue is that currently we support only COCO style datasets in YOLOX. We are working on creating it for VOC as well</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-30T00:07:20.741Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/phoenix64\">@phoenix64</a> , please see <a class=\"mention\" href=\"/u/manan-goel\">@manan-goel</a> response above and please let us know if you have any additional questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-30T01:01:08.480Z",
				"Answer_body": "<p>thank you so much,<br>\nis it determined approximately when would the new version for this out?<br>\ni am saying that cause i was following this <a href=\"https://www.youtube.com/watch?v=be_D3V9Pxlg&amp;ab_channel=Neuralearn\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Training your own YoloX Object Detection Model on Colab - YoloX Object Detection Model Deployment - YouTube</a> and they did no further configuration and get the result.<br>\nis there any older version of that for example that work and i can use it for now?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-05T00:08:26.772Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/phoenix64\">@phoenix64</a> , we cannot give an exact timeline on when this will be released. Please <a href=\"https://wandb.ai/manan-goel/yolox-nano/reports/Tracking-your-YOLOX-Runs-with-Weights-Biases---VmlldzoxNzc0NjA0\">see this wandb report</a> on YoloX.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-30T13:12:53.558Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/phoenix64\">@phoenix64</a> ! A <a href=\"https://github.com/Megvii-BaseDetection/YOLOX/pull/1525\" rel=\"noopener nofollow ugc\">PR</a> for this is up now</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-29T13:13:34.560Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "ConnectionRefusedError",
		"Question_link": "https://community.wandb.ai/t/connectionrefusederror/3200",
		"Question_created_time": "2022-09-29T14:10:02.042Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 385,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\nI used colab to run the code,  it succeeded the first time, but failed the third time, why did it like this? what should I do? Thanks!<br>\nException has occurred: ConnectionRefusedError<br>\n[Errno 111] Connection refused<br>\nFile \u201c/content/OPTIM/0_template_graph_node_classify copy/agent_sweep.py\u201d, line 75, in <br>\nsweep_id = wandb.sweep(sweep_config, project=\u201cvscode_debug\u201d)</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-30T09:47:49.122Z",
				"Answer_body": "<p>Hi yan,</p>\n<p>Thanks for writing in! Have you tried \u201cRestart runtime\u201d and run the collar again? It would be also very useful if you could send a snippet of your code and so I could better understand what is happening here.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-05T10:43:57.230Z",
				"Answer_body": "<p>Hi yan,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-28T14:10:32.485Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Can a same combinasion happened twice with bayesian optimisation?",
		"Question_link": "https://community.wandb.ai/t/can-a-same-combinasion-happened-twice-with-bayesian-optimisation/3172",
		"Question_created_time": "2022-09-22T08:54:57.751Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 141,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I\u2019m using sweeps with bayesian optimisation, and i have a limited number of possible combinations between the hyperparameters I\u2019m trying to optimise (16 possible combinations) .</p>\n<p>In a test, I tried to run 16 runs with bayesian optimisation in the same sweep expecting to have all 16 possible hyperparameter combinations, but only 12 of the possible combinations were selected.</p>\n<p>Is this behavior normal?</p>\n<p>In an other test a same combination appeared 4 times.</p>\n<p>Thank you</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-22T23:35:53.544Z",
				"Answer_body": "<p>Hi Felix,</p>\n<p>Yes, this is quite possible. A bayesian search does not provide any guarantees over not repeating combinations, it tries to learn an optimal distribution of hyperparameters and given what I am assuming in your case is a discrete search space, this combination might have been optimal according to the bayesian search.</p>\n<p>If you are looking to perform an exhaustive search over all hyperparameter combinations, I would suggest running a grid search.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-28T18:12:59.519Z",
				"Answer_body": "<p>Hi F\u00e9lix, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-27T18:13:59.387Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Barchart Grouping by Time/Step/Count",
		"Question_link": "https://community.wandb.ai/t/barchart-grouping-by-time-step-count/3157",
		"Question_created_time": "2022-09-19T16:32:16.917Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 794,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Dear W&amp;B Community,</p>\n<p>I have system metrics logged like the \u201c<em>time per step</em>\u201d or \u201c<em>time per backward pass</em>\u201d for a model.<br>\nWhen doing this on different hardware, I would like to compare the effect this has on these metrics.<br>\nIn the following examples, I profile the basic Torch CIFAR10 model on a 1,2,4,8,16 and 32 CPU VM.</p>\n<p>When looking at a <code>Linechart</code>, the full history of these metrics is visible, however, it is very hard to compare them due to the overlapping and oscillation:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/fc4a70f56ac98f28ece07b404e7c5e734d81d351.png\" data-download-href=\"/uploads/short-url/zZROm2jlGDN4WUrxx2lQXAA8jYZ.png?dl=1\" title=\"W&amp;amp;B Chart 9_19_2022, 6_22_16 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/fc4a70f56ac98f28ece07b404e7c5e734d81d351_2_690x362.png\" alt=\"W&amp;B Chart 9_19_2022, 6_22_16 PM\" data-base62-sha1=\"zZROm2jlGDN4WUrxx2lQXAA8jYZ\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/fc4a70f56ac98f28ece07b404e7c5e734d81d351_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/fc4a70f56ac98f28ece07b404e7c5e734d81d351_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/fc4a70f56ac98f28ece07b404e7c5e734d81d351_2_1380x724.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/fc4a70f56ac98f28ece07b404e7c5e734d81d351_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">W&amp;amp;B Chart 9_19_2022, 6_22_16 PM</span><span class=\"informations\">3539\u00d71859 509 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>When using a <code>Barchart</code>, only the last value is visualized:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/48a4597177e867b3eb511112ad23b561f18f1137.png\" data-download-href=\"/uploads/short-url/amCuG3pzRgnimYoyoJeru5muDMH.png?dl=1\" title=\"W&amp;amp;B Chart 9_19_2022, 6_20_31 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/48a4597177e867b3eb511112ad23b561f18f1137_2_690x362.png\" alt=\"W&amp;B Chart 9_19_2022, 6_20_31 PM\" data-base62-sha1=\"amCuG3pzRgnimYoyoJeru5muDMH\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/48a4597177e867b3eb511112ad23b561f18f1137_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/48a4597177e867b3eb511112ad23b561f18f1137_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/48a4597177e867b3eb511112ad23b561f18f1137_2_1380x724.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/48a4597177e867b3eb511112ad23b561f18f1137_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">W&amp;amp;B Chart 9_19_2022, 6_20_31 PM</span><span class=\"informations\">3539\u00d71859 251 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>The functionality that would be nice is to group values based on their count or occurrence, as grouping by runs already works perfectly. Here\u2019s the same data but run through <code>seaborn.barplot</code>:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/379ac43b0eee017cfc2884cd7a3635262eb5d479.png\" data-download-href=\"/uploads/short-url/7VTQur5SLq8cPHTQtTqGrDuwPRn.png?dl=1\" title=\"download\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/379ac43b0eee017cfc2884cd7a3635262eb5d479_2_690x427.png\" alt=\"download\" data-base62-sha1=\"7VTQur5SLq8cPHTQtTqGrDuwPRn\" width=\"690\" height=\"427\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/379ac43b0eee017cfc2884cd7a3635262eb5d479_2_690x427.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/379ac43b0eee017cfc2884cd7a3635262eb5d479_2_1035x640.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/379ac43b0eee017cfc2884cd7a3635262eb5d479_2_1380x854.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/379ac43b0eee017cfc2884cd7a3635262eb5d479_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">download</span><span class=\"informations\">3777\u00d72341 159 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Would this be possible to implement? Or does anybody know a way to get that functionality?</p>\n<p>My current workaround is to download the data manually and run it through seaborn. Unfortunately, I did not understand the errors I\u2019ve gotten with the <code>Custom Chart</code> functionality when trying to port Vega examples to use wandb as a data basis.</p>\n<p>I\u2019d be very glad if anybody can point me to a tutorial on how to migrate existing Vega examples to be used with wandb (and the common problems, like differences between v3/v4/v5, as these seemed to be an issue for me).</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-20T12:12:42.794Z",
				"Answer_body": "<p>After fiddling a bit more with the <code>Custom Chart</code> functionality, I got a half-baked solution.</p>\n<p>The biggest issue when trying to implement a Custom Chart is to watch out for the difference between <strong>vega</strong> and <strong>vega-lite</strong>.</p>\n<p>Examples from the <a href=\"https://vega.github.io/vega-lite/examples/\" rel=\"noopener nofollow ugc\"><strong>vega-lite</strong> documentation</a> are mostly easily adaptable while the ones from <a href=\"https://vega.github.io/vega/examples/\" rel=\"noopener nofollow ugc\"><strong>vega</strong> DO NOT WORK</a>.</p>\n<p>I didn\u2019t dig quite deep enough to understand why, but it seems to have something to do with the way wandb provides its data.</p>\n<p>However, here\u2019s the code for anybody interested in the following boxplot. It has basic tooltips and a configurable range. If you want the 1.5 IQR boxplot instead of the min-max one, simply remove this line <code>\"extent\": \"min-max\"</code>.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/4/4b33102390240fc3ead10aa67730e22279dd88a7.png\" data-download-href=\"/uploads/short-url/aJfdagtmw8Kj0H1fWsrb3f3rPFR.png?dl=1\" title=\"Screenshot_20220920_135209\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/4b33102390240fc3ead10aa67730e22279dd88a7_2_690x359.png\" alt=\"Screenshot_20220920_135209\" data-base62-sha1=\"aJfdagtmw8Kj0H1fWsrb3f3rPFR\" width=\"690\" height=\"359\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/4b33102390240fc3ead10aa67730e22279dd88a7_2_690x359.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/4/4b33102390240fc3ead10aa67730e22279dd88a7.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/4/4b33102390240fc3ead10aa67730e22279dd88a7.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/4/4b33102390240fc3ead10aa67730e22279dd88a7_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot_20220920_135209</span><span class=\"informations\">842\u00d7439 47 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Configuration:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/b/b47f70df94a57ed34a6be3c54eaecb246f326804.png\" data-download-href=\"/uploads/short-url/pKKZ6y1H7u2Njkrjn4zwMX2CnWc.png?dl=1\" title=\"Screenshot_20220920_135547\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b47f70df94a57ed34a6be3c54eaecb246f326804_2_313x500.png\" alt=\"Screenshot_20220920_135547\" data-base62-sha1=\"pKKZ6y1H7u2Njkrjn4zwMX2CnWc\" width=\"313\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b47f70df94a57ed34a6be3c54eaecb246f326804_2_313x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b47f70df94a57ed34a6be3c54eaecb246f326804_2_469x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/b/b47f70df94a57ed34a6be3c54eaecb246f326804.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/b/b47f70df94a57ed34a6be3c54eaecb246f326804_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot_20220920_135547</span><span class=\"informations\">492\u00d7784 27.4 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<pre><code class=\"lang-json\">{\n  \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.json\",\n  \"description\": \"A simple box plot from https://vega.github.io/vega-lite/examples/boxplot_2D_vertical.html, refer to the full documentation here https://vega.github.io/vega-lite/docs/boxplot.html\",\n  \"title\": \"${field:y}\",\n  \"data\": {\n    \"name\": \"wandb\"\n  },\n  \"layer\":[\n  { \n    \"mark\": {\n      \"type\": \"boxplot\",\n      \"extent\": \"min-max\",\n      \"clip\": true,\n      \"median\": { \"color\": \"black\" },\n      \"ticks\": true\n    },\n    \"encoding\": {\n      \"size\":{ \"value\": 25},\n      \"x\": {\n        \"field\": \"${field:group_by}\",\n        \"type\": \"nominal\",\n        \"axis\": {\"labelAngle\": -25}\n      },\n      \"y\": {\n        \"field\": \"${field:y}\",\n        \"type\": \"quantitative\",\n        \"sort\": \"-y\",\n        \"scale\": {\"domain\": [\"${string:min_domain}\", \"${string:max_domain}\"]},\n        \"title\": null\n      },\n      \"color\": {\n        \"field\": \"${field:group_by}\",\n        \"type\": \"nominal\"\n\n      },\n      \"tooltip\": [\n        { \"field\": \"${field:y}\", \"type\":\"quantitative\" }\n      ]\n    }\n  }\n  ],\n  \"config\": {\n    \"axis\": { \"grid\": true },\n    \"view\": {\n      \"stroke\": \"transparent\"\n    }    \n  }\n}\n</code></pre>\n<p>Some things to watch out for:</p>\n<ul>\n<li>vega-lite seems to be a wrapper around vega, and the boxplot primitive creates a lot of layers that are not modifiable by default (as do other primitives)</li>\n<li>I presume that this is the reason I did not get any transforms working that are in the default <code>Line plot</code>\n</li>\n<li>the GraphQL input in the second image is sometimes buggy and does not allow you to select the correct field but you can work around that by typing something in the first field, then &lt;Tab&gt; and selecting the second field, then deleting the first one (Brave Build: Version 1.42.97 Chromium: 104.0.5112.102)</li>\n<li>When in the \u201cChart Definition\u201d view (<code>Custom Chart -&gt; Edit</code>), data recomputation is delayed/buggy. If you change the chart code, you might need to re-select the fields to see the changes (e.g., <code>group_by</code> for me)</li>\n<li>When in the \u201cChart Definition\u201d view, just below the chart is a dropdown list of the generated/imported data. Use that extensively to make sure that your transforms do what you want them to do!</li>\n</ul>\n<p>A nice improvement from this boxplot would be to have violin plots, but these still seem to be in active development, see this <a href=\"https://github.com/vega/vega-lite/issues/3442\" rel=\"noopener nofollow ugc\">issue</a>.</p>\n<p>\u2013</p>\n<p>Final thoughts: I would still love to have a group-by time/count in the default <code>Bar chat</code> as it would integrate much more tightly with the remaining look of the dashboard and would provide violin plots by default.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-22T11:18:52.059Z",
				"Answer_body": "<p>Hi Alexander,</p>\n<p>Thank you very much for sharing this, it is really useful! It seems that you have solved your issue but let me know if I can help you in any way! Also, I was wondering if you could send me an example of a Vega example that is not working and so I can check what is happening there! Thanks!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-23T08:16:42.318Z",
				"Answer_body": "<p>Hi Luis,</p>\n<p>thanks for taking the time! I think the best solution would be to allow grouping over time in the W&amp;B GUI for your integrated bar charts, but for now, a big help for the community would be an example of making a <code>vega</code> example run with wandb.</p>\n<p>Here\u2019s the basic bar chart example from <a href=\"https://vega.github.io/vega/examples/bar-chart/\" rel=\"noopener nofollow ugc\">the official page</a>, adapted to use with wandb by including the <code>${field:x}</code> and <code>${field:y}</code>.</p>\n<pre><code class=\"lang-auto\">{\n  \"$schema\": \"https://vega.github.io/schema/vega/v5.json\",\n  \"description\": \"A simple line plot\",\n  \"data\": {\n    \"name\": \"wandb\"\n  },\n  \"signals\": [\n    {\n      \"name\": \"tooltip\",\n      \"value\": {},\n      \"on\": [\n        {\"events\": \"rect:mouseover\", \"update\": \"datum\"},\n        {\"events\": \"rect:mouseout\",  \"update\": \"{}\"}\n      ]\n    }\n  ],\n\n  \"scales\": [\n    {\n      \"name\": \"xscale\",\n      \"type\": \"band\",\n      \"domain\": {\"data\": \"table\", \"field\": \"${field:x}\"},\n      \"range\": \"width\",\n      \"padding\": 0.05,\n      \"round\": true\n    },\n    {\n      \"name\": \"yscale\",\n      \"domain\": {\"data\": \"table\", \"field\": \"${field:y}\"},\n      \"nice\": true,\n      \"range\": \"height\"\n    }\n  ],\n\n  \"axes\": [\n    { \"orient\": \"bottom\", \"scale\": \"xscale\" },\n    { \"orient\": \"left\", \"scale\": \"yscale\" }\n  ],\n\n  \"marks\": [\n    {\n      \"type\": \"rect\",\n      \"from\": {\"data\":\"table\"},\n      \"encode\": {\n        \"enter\": {\n          \"x\": {\"scale\": \"xscale\", \"field\": \"${field:x}\"},\n          \"width\": {\"scale\": \"xscale\", \"band\": 1},\n          \"y\": {\"scale\": \"yscale\", \"field\": \"${field:y}\"},\n          \"y2\": {\"scale\": \"yscale\", \"value\": 0}\n        },\n        \"update\": {\n          \"fill\": {\"value\": \"steelblue\"}\n        },\n        \"hover\": {\n          \"fill\": {\"value\": \"red\"}\n        }\n      }\n    },\n    {\n      \"type\": \"text\",\n      \"encode\": {\n        \"enter\": {\n          \"align\": {\"value\": \"center\"},\n          \"baseline\": {\"value\": \"bottom\"},\n          \"fill\": {\"value\": \"#333\"}\n        },\n        \"update\": {\n          \"x\": {\"scale\": \"xscale\", \"signal\": \"tooltip.${field:x}\", \"band\": 0.5},\n          \"y\": {\"scale\": \"yscale\", \"signal\": \"tooltip.${field:y}\", \"offset\": -2},\n          \"text\": {\"signal\": \"tooltip.${field:y}\"},\n          \"fillOpacity\": [\n            {\"test\": \"datum === tooltip\", \"value\": 0},\n            {\"value\": 1}\n          ]\n        }\n      }\n    }\n  ]\n}\n</code></pre>\n<p>The error happens between line 4 and 6:<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/6/66528b2dfb927997137472fb4de0879851457f43.png\" alt=\"image\" data-base62-sha1=\"eBby9YUEAUyx3HxcaRvmQ4WK2r1\" width=\"684\" height=\"183\"></p>\n<p>I haven\u2019t been able to modify the code in any way to make this example work.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-27T10:20:24.356Z",
				"Answer_body": "<p>Hi Alexander,</p>\n<p>Thanks for sending this detailed explanation! I have been exploring it and I think that the issue here is that, in lines 22, 29 and 43 you have \u201cdata\u201d: \u201ctable\u201d but as the name has been changed to \u201cwandb\u201d, then you should have \u201cdata\u201d: \u201cwandb\u201d. To solve the error between lines 4 and 6, you can use <span class=\"chcklst-box fa fa-square-o fa-fw\"></span> and it is solved, but it seems that it is not affecting to the chart.</p>\n<pre><code>\"data\": [{ \"name\": \"wandb\" }]\n</code></pre>\n<p>Please let me know if this would be useful for you!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-09-28T11:10:21.945Z",
				"Answer_body": "<p>Thanks for the help Luis, it worked out perfectly!</p>\n<p>Just for completion\u2019s sake if somebody else is looking for the full code for the <a href=\"https://vega.github.io/vega/examples/bar-chart/\" rel=\"noopener nofollow ugc\">vega bar chart example</a> adapted to work with W&amp;B:</p>\n<pre><code class=\"lang-auto\">{\n  \"$schema\": \"https://vega.github.io/schema/vega/v5.json\",\n  \"description\": \"A simple line plot\",\n  \"data\": [{ \"name\": \"wandb\" }],\n  \"signals\": [\n    {\n      \"name\": \"tooltip\",\n      \"value\": {},\n      \"on\": [\n        {\"events\": \"rect:mouseover\", \"update\": \"datum\"},\n        {\"events\": \"rect:mouseout\",  \"update\": \"{}\"}\n      ]\n    }\n  ],\n  \"scales\": [\n    {\n      \"name\": \"xscale\",\n      \"type\": \"band\",\n      \"domain\": {\"data\": \"wandb\", \"field\": \"${field:x}\"},\n      \"range\": \"width\",\n      \"padding\": 0.05,\n      \"round\": true\n    },\n    {\n      \"name\": \"yscale\",\n      \"domain\": {\"data\": \"wandb\", \"field\": \"${field:y}\"},\n      \"nice\": true,\n      \"range\": \"height\"\n    }\n  ],\n\n  \"axes\": [\n    { \"orient\": \"bottom\", \"scale\": \"xscale\" },\n    { \"orient\": \"left\", \"scale\": \"yscale\" }\n  ],\n\n  \"marks\": [\n    {\n      \"type\": \"rect\",\n      \"from\": {\"data\":\"wandb\"},\n      \"encode\": {\n        \"enter\": {\n          \"x\": {\"scale\": \"xscale\", \"field\": \"${field:x}\"},\n          \"width\": {\"scale\": \"xscale\", \"band\": 1},\n          \"y\": {\"scale\": \"yscale\", \"field\": \"${field:y}\"},\n          \"y2\": {\"scale\": \"yscale\", \"value\": 0}\n        },\n        \"update\": {\n          \"fill\": {\"value\": \"steelblue\"}\n        },\n        \"hover\": {\n          \"fill\": {\"value\": \"red\"}\n        }\n      }\n    },\n    {\n      \"type\": \"text\",\n      \"encode\": {\n        \"enter\": {\n          \"align\": {\"value\": \"center\"},\n          \"baseline\": {\"value\": \"bottom\"},\n          \"fill\": {\"value\": \"#333\"}\n        },\n        \"update\": {\n          \"x\": {\"scale\": \"xscale\", \"signal\": \"tooltip.${field:x}\", \"band\": 0.5},\n          \"y\": {\"scale\": \"yscale\", \"signal\": \"tooltip.${field:y}\", \"offset\": -2},\n          \"text\": {\"signal\": \"tooltip.${field:y}\"},\n          \"fillOpacity\": [\n            {\"test\": \"datum === tooltip\", \"value\": 0},\n            {\"value\": 1}\n          ]\n        }\n      }\n    }\n  ]\n}\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-29T15:37:22.482Z",
				"Answer_body": "<p>Hi Alexander,</p>\n<p>Thanks for sharing this! I will close this ticket as it seems to be solved but please feel free to re-open it if you have any other issues with it!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-27T11:10:39.019Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Upload a series of time sequence (ecg curve) with each corresponding heart rate into a table",
		"Question_link": "https://community.wandb.ai/t/upload-a-series-of-time-sequence-ecg-curve-with-each-corresponding-heart-rate-into-a-table/3072",
		"Question_created_time": "2022-09-06T12:16:11.195Z",
		"Question_answer_count": 9,
		"Question_score_count": 0,
		"Question_view_count": 144,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Dear friends,<br>\nI\u2019m a new wandb. My task is to predict a time sequence and its heart rate. Therefore, I want to visualize each result by uploading it to a table. Is there any data format similar to the image? I want to achieve a table like below:<br>\npredicted time sequence(1D point), heart rate(single value), the ground truth time sequence (also a 1D point)<br>\nEach column represents a different data type.<br>\nHow to achieve it?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-08T12:58:18.198Z",
				"Answer_body": "<p>Hi yang, thanks for your question! Here you can see our Documentation on how to log data into tables. As you can see, you can log different data types on each columns. Also, here you can see all the data types that can be logged and how to create each type. Please let me know if this would solve your question!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-13T14:29:46.277Z",
				"Answer_body": "<p>Hi Yang,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-15T12:57:45.409Z",
				"Answer_body": "<p>Hi:<br>\nSince I want to upload the 1D points to the table and visualize them.<br>\nI have already checked the type in your API. There is no type suitable for my situation.<br>\nDo you have any ideas?<br>\nI want to visualize it like a curve, which is shown in a table.<br>\nTherefore, I can check whether the model generates an accurate curve.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-16T13:26:22.567Z",
				"Answer_body": "<p>Hi Yang,</p>\n<p>Thanks for your answer! Since you want to visualise a curve, would Plotly be useful for your case? I was thinking that another way could be logging it as an image, would it work?<br>\nAlso, could you send me a screenshot of the 1D points that you want to upload and so I can have a better idea of your use-case?</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-19T07:57:24.739Z",
				"Answer_body": "<p>Hi,<br>\nMy curve looks like this<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/2283ce6d7ad7c0b6cdfca0a7aa33fb9b8e899bc5.png\" data-download-href=\"/uploads/short-url/4VkCVjSNYVD0GNq7qjdPl9aFORL.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2283ce6d7ad7c0b6cdfca0a7aa33fb9b8e899bc5_2_690x251.png\" alt=\"image\" data-base62-sha1=\"4VkCVjSNYVD0GNq7qjdPl9aFORL\" width=\"690\" height=\"251\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2283ce6d7ad7c0b6cdfca0a7aa33fb9b8e899bc5_2_690x251.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2283ce6d7ad7c0b6cdfca0a7aa33fb9b8e899bc5_2_1035x376.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2283ce6d7ad7c0b6cdfca0a7aa33fb9b8e899bc5_2_1380x502.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2283ce6d7ad7c0b6cdfca0a7aa33fb9b8e899bc5_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">2094\u00d7764 221 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nThis curve represents the cardiac activity, which can be used to calculate the heart rate.<br>\nI want to not only see the shape of the curve but also need to know whether it is the correct heart rate.<br>\nTherefore, I need to upload the curve and the single value of heart rate into different columns in one Table.<br>\nDo you have any idea? I think your visualization of a Table for the MNIST dataset is awesome. Could I realize the similar Table?<br>\nBest,<br>\nZe Yang</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-22T17:20:31.069Z",
				"Answer_body": "<p>Hi yangze,</p>\n<p>Sorry for the delay here! I think a code like this could be useful for you:</p>\n<pre><code>columns=[\"curve\", \"predicted_heart_rate\", \"true_heart_rate\"]table = wandb.Table(columns=columns)for epoch in range(n_epochs): table.add_data(curve, predicted, true) wandb.log({\"table\" : table})\n</code></pre>\n<p>Then you can set the variable <code>curve</code> as the chart that you want and the predicted heart rate and the true heart rate and so you can check whether it is correct or not. Please let me know if this would help you!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-28T00:19:32.610Z",
				"Answer_body": "<p>Hi Yangze, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-28T10:39:32.281Z",
				"Answer_body": "<p>Hi,<br>\nThanks for your help. But I cannot set the curve as chart type in table.add_data().<br>\nDo you know which API I can use?<br>\nBy the way, I find I can use Plotly and save the plot as HTML to visualize the curve. The shortage is I need to save the plot as  \u2018.html\u2019.</p>\n<p>Best,<br>\nZe Yang</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-27T10:39:46.561Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Metric data exceeds maximum size",
		"Question_link": "https://community.wandb.ai/t/metric-data-exceeds-maximum-size/3082",
		"Question_created_time": "2022-09-08T07:30:16.472Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 657,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>When I use wandb.log online, the following error will be reported: \u201cMetric data exceeds maximum size of 10.4MB\u201d. Now if I don\u2019t want to run again, how can I fix this mistake?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-09T12:47:28.382Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/eatonlee\">@eatonlee</a> thank you for reporting this issue. May I please ask if you\u2019re making any wandb.watch() calls? Could you try to remove or reduce the number of watch calls and see if that helps?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-14T21:02:11.985Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/eatonlee\">@eatonlee</a> I wanted to follow up on this issue, is it still happening? did you try the above suggestion regarding wandb.watch() calls? thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-16T07:21:06.210Z",
				"Answer_body": "<p>Sorry it has taken so long to get back to you. I tried your method, but I still wanted to watch the change in every epoch , so I deleted the wandb folder and solved the problem.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-16T09:45:43.301Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/eatonlee\">@eatonlee</a> thank you for posting the solution to this issue, glad this now works for you. I will close the ticket for now, but please feel free to re-open it by posting here if you have any further questions or issues with this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-28T07:32:22.026Z",
				"Answer_body": "<p>Can this restriction be removed? If not, will it be considered for subsequent development? I\u2019d like to be able to observe the changes in each epoch before running each experiment, but I can\u2019t tell in advance if the limit will be exceeded.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-27T07:32:47.396Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Remove from a team",
		"Question_link": "https://community.wandb.ai/t/remove-from-a-team/3193",
		"Question_created_time": "2022-09-27T08:25:18.870Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 433,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I would like to remove myself from a tesm. How can I do it?</p>\n<p>Thanks,<br>\nP</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-27T16:28:26.197Z",
				"Answer_body": "<p>Hi Paolo,</p>\n<p>Right now you can\u2019t remove yourself from a team. An admin on your instance would have to do that. This is a current bug we are aware of and are working on fixing. If you want, I can remove you from the team. Can you tell me the team name you are part of that you want to be removed from?</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-26T08:25:22.533Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb generates all the files in the root path of my project",
		"Question_link": "https://community.wandb.ai/t/wandb-generates-all-the-files-in-the-root-path-of-my-project/3132",
		"Question_created_time": "2022-09-17T09:05:12.983Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 122,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi there. I am faced with a issue here. You see when my experiments begin wandb creates all the files right in my project root path, just like below<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/93a1fd2da61f793bf82efd3c3e9dc2aaabb2f2cc.png\" data-download-href=\"/uploads/short-url/l41fn57sn746ESH9dhIVvNNmgt6.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/93a1fd2da61f793bf82efd3c3e9dc2aaabb2f2cc.png\" alt=\"image\" data-base62-sha1=\"l41fn57sn746ESH9dhIVvNNmgt6\" width=\"525\" height=\"500\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/93a1fd2da61f793bf82efd3c3e9dc2aaabb2f2cc_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">708\u00d7674 13.6 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-17T09:05:43.583Z",
				"Answer_body": "<p>When the training finishes and the program quits, most of them disappear but several json files remain:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/751911a4c94468416d07f620f4711456ac7bb80b.png\" data-download-href=\"/uploads/short-url/gHTzAi7tjVRdg4vMDoEdoIMlBSb.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/751911a4c94468416d07f620f4711456ac7bb80b.png\" alt=\"image\" data-base62-sha1=\"gHTzAi7tjVRdg4vMDoEdoIMlBSb\" width=\"690\" height=\"223\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/751911a4c94468416d07f620f4711456ac7bb80b_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">703\u00d7228 5.39 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nSo is there any way to solve this issue?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-19T21:43:09.906Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/xiangyu-zhao\">@xiangyu-zhao</a> , can you please expand on this, not sure I quite understand. All files associated with your project runs are placed into the <code>wandb</code> folder of your working directory.  Please check there and inform me of your findings.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-26T16:42:46.724Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/xiangyu-zhao\">@xiangyu-zhao</a>  since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-25T16:43:28.381Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Filter GPU curves in the system panel",
		"Question_link": "https://community.wandb.ai/t/filter-gpu-curves-in-the-system-panel/3152",
		"Question_created_time": "2022-09-19T05:45:41.242Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 192,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi,<br>\nMe and a colleague are sharing a remote server with 8 GPUs. We split them, 4 GPUs each. In the system panel at the WANDB page I currently see data of all 8 GPUs. Is it possible to filter some of those curves, so I\u2019ll only see the GPUs I\u2019m using?</p>\n<p>Many thanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-20T15:55:12.779Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/yonatan-shimoni\">@yonatan-shimoni</a> thank you for writing in! Just to clarify here, is this for the System view that you can access from the left panel of an individual Run, or is it at the System panels section in your Project\u2019s Workspace? You can select which GPUs to visualise there by editing the Chart (pencil icon) as in the attached screenshot. Would this help?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/d/d6fae44c542194daa3cd8f4afb453e59ecbdc818.png\" data-download-href=\"/uploads/short-url/uFNI8njAc6A8srPIjwcR86x4AZi.png?dl=1\" title=\"Screenshot 2022-09-20 at 16.50.40\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/d6fae44c542194daa3cd8f4afb453e59ecbdc818_2_476x500.png\" alt=\"Screenshot 2022-09-20 at 16.50.40\" data-base62-sha1=\"uFNI8njAc6A8srPIjwcR86x4AZi\" width=\"476\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/d6fae44c542194daa3cd8f4afb453e59ecbdc818_2_476x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/d6fae44c542194daa3cd8f4afb453e59ecbdc818_2_714x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/d6fae44c542194daa3cd8f4afb453e59ecbdc818_2_952x1000.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/2X/d/d6fae44c542194daa3cd8f4afb453e59ecbdc818_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2022-09-20 at 16.50.40</span><span class=\"informations\">1098\u00d71153 76.4 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-09-21T05:45:08.649Z",
				"Answer_body": "<p>Yes, that is what I was looking for. Thanks.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-23T13:40:23.104Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/yonatan-shimoni\">@yonatan-shimoni</a> thank you for confirming this, and glad this is now resolved for you! I will close the ticket for now, but please feel free to message us here if you have any further questions or issues with this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-22T13:40:47.310Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Rate Limit Exceeded",
		"Question_link": "https://community.wandb.ai/t/rate-limit-exceeded/753",
		"Question_created_time": "2021-09-23T13:29:47.148Z",
		"Question_answer_count": 12,
		"Question_score_count": 4,
		"Question_view_count": 1947,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>Since recently, I have been getting this error when browsing the runs/workspace of my latest project.</p>\n<p>For info, it is a segmentation tasks trained in pytorch using fastai callback.</p>\n<p>My log looks like this:</p>\n<pre><code class=\"lang-auto\">\n0: *Quadro RTX 8000,         48.6GB, tensor_cores=72\n1: GeForce RTX 2070 SUPER,   8.0GB, tensor_cores=40\n Selecting GPU : Quadro RTX 8000\nException ignored in: &lt;function _releaseLock at 0x7f3232131ee0&gt;\nTraceback (most recent call last):\n  File \"/home/tcapelle/miniconda3/envs/pytorch_18/lib/python3.8/logging/__init__.py\", line 227, in _releaseLock\n    def _releaseLock():\nKeyboardInterrupt:\nWandbCallback requires use of \"SaveModelCallback\" to log best model\nwandb: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\nwandb: Network error resolved after 0:00:08.499452, resuming normal operation.\nwandb: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\nwandb: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\nwandb: Network error resolved after 0:00:09.337473, resuming normal operation.\nwandb: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\nwandb: Network error resolved after 0:00:08.679539, resuming normal operation.\n</code></pre>\n<p>this happens in the training notebooks and in the wandb page afterwards.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-23T16:45:57.220Z",
				"Answer_body": "<p>Thanks for flagging! We\u2019re looking into it <img src=\"https://emoji.discourse-cdn.com/twitter/tea.png?v=10\" title=\":tea:\" class=\"emoji\" alt=\":tea:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-23T16:57:54.071Z",
				"Answer_body": "<p>It appears the issue is due to logging either too frequently from one run, from too many runs in parallel, or loading too much data in the UI. If we can track down which one it is, that will help debug. -Is it possible for you to share the run page/link? That might help debug the same.</p>\n<p>The team had also deployed a fix related to the same today, could you please confirm if you\u2019re facing the issue today as well?</p>\n<p>TIA! <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-24T08:09:20.982Z",
				"Answer_body": "<p>Thanks, Thomas. Since the link is visible to everyone, I deleted your comment to keep it private. I hope that\u2019s okay.</p>\n<p>I\u2019ll get back once the team takes a look <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-27T09:17:29.016Z",
				"Answer_body": "<p>It appears to be working fine now.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-27T09:32:20.989Z",
				"Answer_body": "<p>Thank you, please let me know incase this/any other issues reappear <img src=\"https://emoji.discourse-cdn.com/twitter/smiley.png?v=10\" title=\":smiley:\" class=\"emoji\" alt=\":smiley:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-24T13:54:46.264Z",
				"Answer_body": "<p>Same problem here. It appears to be some IP based restriction on WandB\u2019s side. Not very happy with this <img src=\"https://emoji.discourse-cdn.com/twitter/frowning.png?v=12\" title=\":frowning:\" class=\"emoji\" alt=\":frowning:\" loading=\"lazy\" width=\"20\" height=\"20\"> especially since It\u2019s blocking training which hasn\u2019t even been started - so I\u2019ve no idea why its reaching arbitrary ratelimits</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-24T15:42:35.325Z",
				"Answer_body": "<p>Hi Neel! It\u2019s nice to meet you, I\u2019m Leslie from the support team. I have increased your rate limits for your account.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-13T08:55:29.081Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lesliewandb\">@lesliewandb</a> , I am encountering the same issue. Can you please help me fix it?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-13T17:38:23.542Z",
				"Answer_body": "<p>Hi, I\u2019m getting the same issue here.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-22T16:18:41.624Z",
				"Answer_body": "<p>Pretty sure in my case it\u2019s logging from too many runs in parallel (200). How do I decrease the logging frequency?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-22T16:23:25.264Z",
				"Answer_body": "<p>This seems relevant:</p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/guides/track/limits#rate-limits\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/63fbdc722981d8c123c2cc529ad1317258d52c56.png\" class=\"site-icon\" width=\"132\" height=\"132\">\n\n      <a href=\"https://docs.wandb.ai/guides/track/limits#rate-limits\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d964bbbc3da358de18b80af06dd499d89199a157_2_500x500.png\" class=\"thumbnail onebox-avatar\" width=\"500\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d964bbbc3da358de18b80af06dd499d89199a157_2_500x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d964bbbc3da358de18b80af06dd499d89199a157.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d964bbbc3da358de18b80af06dd499d89199a157.png 2x\" data-dominant-color=\"FFC924\">\n\n<h3><a href=\"https://docs.wandb.ai/guides/track/limits#rate-limits\" target=\"_blank\" rel=\"noopener\">Limits &amp; Performance</a></h3>\n\n  <p>Appropriate limits and guidelines for logging data to Weights &amp; Biases</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<blockquote>\n<p>The W&amp;B API is rate limited by IP and API key. New accounts are restricted to 200 requests per minute. This rate allows you to run approximately 15 processes in parallel and have them report without being throttled. If the <strong>wandb</strong> client detects it\u2019s being limited, it will backoff and retry sending the data in the future. If you need to run more than 15 processes in parallel send an email to <a href=\"mailto:contact@wandb.com\">contact@wandb.com</a>.</p>\n</blockquote>\n<p>I don\u2019t mind the client sending less frequently but I\u2019d like to get rid of the warnings clogging up my log files:</p>\n<pre><code class=\"lang-auto\">1/1 [==============================] - ETA: 0s\n1/1 [==============================] - 2s 2s/step\nwandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.440871229689856 seconds), retrying request\nwandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.7759137728990915 seconds), retrying request\nwandb: 429 encountered (Filestream rate limit exceeded, retrying in 9.637983936851159 seconds), retrying request\n\n1/1 [==============================] - ETA: 0s\n1/1 [==============================] - 0s 23ms/step\nwandb: 429 encountered (Filestream rate limit exceeded, retrying in 17.76077947047857 seconds), retrying request\nwandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.2036541589775873 seconds), retrying request\nwandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.225510290209322 seconds), retrying request\n\n1/1 [==============================] - ETA: 0s\n1/1 [==============================] - 0s 25ms/step\nwandb: 429 encountered (Filestream rate limit exceeded, retrying in 9.133716207985449 seconds), retrying request\nwandb: 429 encountered (Filestream rate limit exceeded, retrying in 18.076738516025497 seconds), retrying request\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-22T16:27:10.880Z",
				"Answer_body": "<p>Looks like this is where the logging happens</p>\n<aside class=\"onebox githubblob\" data-onebox-src=\"https://github.com/wandb/wandb/blob/06c6e6d10/wandb/sdk/wandb_run.py#L183-L189\">\n  <header class=\"source\">\n\n      <a href=\"https://github.com/wandb/wandb/blob/06c6e6d10/wandb/sdk/wandb_run.py#L183-L189\" target=\"_blank\" rel=\"noopener nofollow ugc\">github.com</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <h4><a href=\"https://github.com/wandb/wandb/blob/06c6e6d10/wandb/sdk/wandb_run.py#L183-L189\" target=\"_blank\" rel=\"noopener nofollow ugc\">wandb/wandb/blob/06c6e6d10/wandb/sdk/wandb_run.py#L183-L189</a></h4>\n\n\n\n    <pre class=\"onebox\"><code class=\"lang-py\">\n      <ol class=\"start lines\" start=\"183\" style=\"counter-reset: li-counter 182 ;\">\n          <li>        else:</li>\n          <li>            wandb.termlog(</li>\n          <li>                \"{} encountered ({}), retrying request\".format(</li>\n          <li>                    hr.http_status_code, hr.http_response_text.rstrip()</li>\n          <li>                )</li>\n          <li>            )</li>\n          <li>join_requested = self._join_event.wait(self._retry_polling_interval)</li>\n      </ol>\n    </code></pre>\n\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>Maybe need to set a larger <code>retry_polling_interval</code> on <code>RunStatusChecker</code>?</p>\n<aside class=\"onebox githubblob\" data-onebox-src=\"https://github.com/wandb/wandb/blob/06c6e6d1/wandb/sdk/wandb_run.py#L145-L156\">\n  <header class=\"source\">\n\n      <a href=\"https://github.com/wandb/wandb/blob/06c6e6d1/wandb/sdk/wandb_run.py#L145-L156\" target=\"_blank\" rel=\"noopener nofollow ugc\">github.com</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <h4><a href=\"https://github.com/wandb/wandb/blob/06c6e6d1/wandb/sdk/wandb_run.py#L145-L156\" target=\"_blank\" rel=\"noopener nofollow ugc\">wandb/wandb/blob/06c6e6d1/wandb/sdk/wandb_run.py#L145-L156</a></h4>\n\n\n\n    <pre class=\"onebox\"><code class=\"lang-py\">\n      <ol class=\"start lines\" start=\"145\" style=\"counter-reset: li-counter 144 ;\">\n          <li>class RunStatusChecker:</li>\n          <li>    \"\"\"Periodically polls the background process for relevant updates.</li>\n          <li>\n          </li>\n<li>    For now, we just use this to figure out if the user has requested a stop.</li>\n          <li>    \"\"\"</li>\n          <li>\n          </li>\n<li>    def __init__(</li>\n          <li>        self,</li>\n          <li>        interface: InterfaceBase,</li>\n          <li>        stop_polling_interval: int = 15,</li>\n          <li>        retry_polling_interval: int = 5,</li>\n          <li>    ) -&gt; None:</li>\n      </ol>\n    </code></pre>\n\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>Edit:</p>\n<p>Doesn\u2019t appear to help. I tried</p>\n<pre data-code-wrap=\"py\"><code class=\"lang-nohighlight\"># put this line after wandb.init()\n# https://community.wandb.ai/t/753/14\nwandb.run._run_status_checker._retry_polling_interval = 50  # type: ignore\n</code></pre>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Limiting the number of runs for a sweep of method 'bayes'",
		"Question_link": "https://community.wandb.ai/t/limiting-the-number-of-runs-for-a-sweep-of-method-bayes/3137",
		"Question_created_time": "2022-09-18T07:52:40.972Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 156,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>Is there a way to limit in advance the number of configs a sweep is going to use?<br>\nCurrently, I need to follow the progress and stop the sweep manually.</p>\n<p>Moreover, if there is such a setting, could it also be configured dynamically on-the-fly?</p>\n<p>Thanks,<br>\nTom</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-18T15:48:20.055Z",
				"Answer_body": "<p><a href=\"https://docs.wandb.ai/ref/python/agent\">wandb agent</a> has a parameter count with which you can set the number of trials to run.</p>\n<p>You can use wandb python agent to dynamically set it.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-18T16:48:59.043Z",
				"Answer_body": "<p>Thank you, but I was asking if the sweep has a count (for instance if I have several agents and don\u2019t know in advance which agent will finish first)</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-22T14:16:17.954Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tomjur\">@tomjur</a>, there isn\u2019t really a way to set this explicitly. As <a class=\"mention\" href=\"/u/udaylunawat\">@udaylunawat</a> pointed out you could make the sum of the agent counts equal the number of runs you would like but this wouldn\u2019t allow you to dynamically change this as you mentioned.</p>\n<p>Probably the closest thing you could do is access the sweep via the API and introduce some logic to shut the sweep if it reaches the number of runs you are looking for. For example:</p>\n<pre><code class=\"lang-auto\">import wandb\nimport os\napi = wandb.Api()\nsweep = api.sweep(path/to/sweep)\nif len(sweep.runs) &gt;=  max_runs:\n    command = f'wandb sweep --stop {sweep_id}'\n    os.system(command)\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-22T14:37:55.249Z",
				"Answer_body": "<p>Thanks, that could work for now.<br>\nIt would be great if the web UI \\ config were able to control this behaviour.</p>\n<p>Thanks!<br>\nTom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-21T14:38:51.773Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sweep, how is the optimisation metric selected in bayesian optimisation",
		"Question_link": "https://community.wandb.ai/t/sweep-how-is-the-optimisation-metric-selected-in-bayesian-optimisation/3126",
		"Question_created_time": "2022-09-16T13:48:14.344Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 105,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi every one,</p>\n<p>When using a sweep, the selection of a metric that need to beoptimized is required when using bayesian optimisation.</p>\n<p>I wanted to know if for the selection of the next critierion for the next runs, the bayesian optimisation is based on the value of that metric at the end of the run (last epoch) or on the highest value reached by the metric during the run ?</p>\n<p>Because in the first case, if I choose a metric calculated over my validation dataset, it performance may decrease during the training because of overfitting, then the value of my metric at the end would not reflect the best performance of my model.</p>\n<p>Thanks for your help</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-19T22:16:04.437Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/felix_quinton\">@felix_quinton</a> ,  please visit <a href=\"https://wandb.ai/site/articles/bayesian-hyperparameter-optimization-a-primer\">this detailed article</a> on the specifics of how Bayesian optimization works. If you still have any questions please let us know.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-21T15:30:31.835Z",
				"Answer_body": "<p>Hi,</p>\n<p>Thanks for your time, i read this article but it doesn\u2019t seems to answer my question, I might have been unclear.</p>\n<p>Lets take an example, :</p>\n<p>I want to found the best hyperparameter configuration for my model over 10 runs with bayesian search.<br>\nI choose the accuracy over my validation dataset as a metric to maximise.  I train all my runs over 1000 epochs.</p>\n<p>For the run 1:</p>\n<ul>\n<li>The  run achieve it\u2019s best value of accuracy over validation dataset at the epoch 700, with a value  of 0.60</li>\n<li>After that the run start to overfit and the value of accuracy over validation decrease to 0.40 at epoch 1000</li>\n</ul>\n<p>For the run 2:</p>\n<ul>\n<li>The  run achieve it\u2019s best value of accuracy over validation dataset at the epoch 700, with a value  of 0.50</li>\n<li>After that the run start to overfit and the value of accuracy over validation decrease to 0.45 at epoch 1000</li>\n</ul>\n<p>In my eyes, I would considered the run 1 as a better run since this configuration as reached the highest results with a maximum score of 0.60 compare to 0.50 for the run 2.</p>\n<p>But the process seems to only care of the value reached at the end of the training to consider the quality of the run. Meaning that, in this case, the run 2 would appears as a better run with a score of 0.45 compared to 0.40 for the run 1. And so the hyperparameter combination of run 2 would be  have more influence than the one of run 1 in the bayesian optimisation process.</p>\n<p>Am I right ?</p>\n<p>Thanks.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-20T15:30:36.454Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Recording videos of custom gym environments",
		"Question_link": "https://community.wandb.ai/t/recording-videos-of-custom-gym-environments/3110",
		"Question_created_time": "2022-09-13T21:49:41.075Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 1019,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I am try to use VecVideoRecorder to log videos of my custom environment. The observation come from a camera, though I don\u2019t think that is the issue.  The error is:</p>\n<p>AttributeError(\u201c\u2018VideoRecorder\u2019 object has no attribute \u2018path\u2019\u201d)</p>\n<p>I\u2019m not directly setting nor accessing an attribute \u2018path\u2019 so I\u2019m having identifying where this is coming from. My code looks like this:</p>\n<pre><code>def make_env():\n    env = DummyVecEnv([lambda:    Monitor(ReacherFiveJointsImageSpace(random_start=wandb.config.random_start,\n                                                        log_state_actions=True,\n                                                        shape_reward=wandb.config.shape_reward,\n                                                        file_name_prefix=wandb.config.rl_name,\n                                                        env_type=wandb.config.env_type,\n                                                        seed=(wandb.config.seed+wandb.config.run)),\n                                       log_dir)])\n    env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=5.)\n    env = VecVideoRecorder(env, video_folder=log_dir,\n                           record_video_trigger=lambda x: x % 100 == 0, video_length=10)  # record videos\n    stats_path = os.path.join(log_dir,\n                              \"run\" + str(wandb.config.run) + \"_vec_normalize_\" + run.id + \".pkl\")\n    env.save(stats_path)\n    return env\n</code></pre>\n<p>Can anyone point me in the right direction?</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-15T21:51:44.445Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/cbellinger\">@cbellinger</a> , this doesn\u2019t appear to be directly tied to W&amp;B.  Can you please revisit source code for the <a href=\"https://stable-baselines.readthedocs.io/en/master/_modules/stable_baselines/common/vec_env/vec_video_recorder.html\" rel=\"noopener nofollow ugc\">videorecorder</a> to identify if your setup is correct. Thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-21T06:14:12.613Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/cbellinger\">@cbellinger</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-20T06:14:50.416Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Traceback error",
		"Question_link": "https://community.wandb.ai/t/traceback-error/3008",
		"Question_created_time": "2022-08-25T22:14:17.943Z",
		"Question_answer_count": 7,
		"Question_score_count": 1,
		"Question_view_count": 2068,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey guys,</p>\n<p>I am totally new to W&amp;B. I am getting a Traceback error when I want to run \u201cwandb.init(project=\u201d\u2026\u201c)\u201d. Last week it still did work. Any tips what to do?? Thank you so much.</p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"/home/p/pthielge/.local/lib/python3.6/site-packages/wandb/sdk/wandb_init.py\", line 999, in init\n    run = wi.init()\n  File \"/home/p/pthielge/.local/lib/python3.6/site-packages/wandb/sdk/wandb_init.py\", line 651, in init\n    backend.cleanup()\n  File \"/home/p/pthielge/.local/lib/python3.6/site-packages/wandb/sdk/backend/backend.py\", line 246, in cleanup\n    self.interface.join()\n  File \"/home/p/pthielge/.local/lib/python3.6/site-packages/wandb/sdk/interface/interface_shared.py\", line 475, in join\n    super().join()\n  File \"/home/p/pthielge/.local/lib/python3.6/site-packages/wandb/sdk/interface/interface.py\", line 666, in join\n    _ = self._communicate_shutdown()\n  File \"/home/p/pthielge/.local/lib/python3.6/site-packages/wandb/sdk/interface/interface_shared.py\", line 472, in _communicate_shutdown\n    _ = self._communicate(record)\n  File \"/home/p/pthielge/.local/lib/python3.6/site-packages/wandb/sdk/interface/interface_shared.py\", line 226, in _communicate\n    return self._communicate_async(rec, local=local).get(timeout=timeout)\n  File \"/home/p/pthielge/.local/lib/python3.6/site-packages/wandb/sdk/interface/interface_shared.py\", line 231, in _communicate_async\n    raise Exception(\"The wandb backend process has shutdown\")\nException: The wandb backend process has shutdown\nwandb: ERROR Abnormal program exit\n---------------------------------------------------------------------------\nException                                 Traceback (most recent call last)\n~/.local/lib/python3.6/site-packages/wandb/sdk/wandb_init.py in init(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\n    998         try:\n--&gt; 999             run = wi.init()\n   1000             except_exit = wi.settings._except_exit\n\n~/.local/lib/python3.6/site-packages/wandb/sdk/wandb_init.py in init(self)\n    650                     # we don't need to do console cleanup at this point\n--&gt; 651                     backend.cleanup()\n    652                     self.teardown()\n\n~/.local/lib/python3.6/site-packages/wandb/sdk/backend/backend.py in cleanup(self)\n    245         if self.interface:\n--&gt; 246             self.interface.join()\n    247         if self.wandb_process:\n\n~/.local/lib/python3.6/site-packages/wandb/sdk/interface/interface_shared.py in join(self)\n    474     def join(self) -&gt; None:\n--&gt; 475         super().join()\n    476 \n\n~/.local/lib/python3.6/site-packages/wandb/sdk/interface/interface.py in join(self)\n    665             return\n--&gt; 666         _ = self._communicate_shutdown()\n    667 \n\n~/.local/lib/python3.6/site-packages/wandb/sdk/interface/interface_shared.py in _communicate_shutdown(self)\n    471         record = self._make_record(request=request)\n--&gt; 472         _ = self._communicate(record)\n    473 \n\n~/.local/lib/python3.6/site-packages/wandb/sdk/interface/interface_shared.py in _communicate(self, rec, timeout, local)\n    225     ) -&gt; Optional[pb.Result]:\n--&gt; 226         return self._communicate_async(rec, local=local).get(timeout=timeout)\n    227 \n\n~/.local/lib/python3.6/site-packages/wandb/sdk/interface/interface_shared.py in _communicate_async(self, rec, local)\n    230         if self._process_check and self._process and not self._process.is_alive():\n--&gt; 231             raise Exception(\"The wandb backend process has shutdown\")\n    232         future = self._router.send_and_receive(rec, local=local)\n\nException: The wandb backend process has shutdown\n\nThe above exception was the direct cause of the following exception:\n\nException                                 Traceback (most recent call last)\n&lt;ipython-input-49-e3734aa09c65&gt; in &lt;module&gt;\n      1 #Login to wandb\n      2 # #! wandb login config_dict[\"wandb_key\"]\n----&gt; 3 wandb.init()\n      4 #run_name = wandb.run.name\n\n~/.local/lib/python3.6/site-packages/wandb/sdk/wandb_init.py in init(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\n   1035             if except_exit:\n   1036                 os._exit(-1)\n-&gt; 1037             raise Exception(\"problem\") from error_seen\n   1038     return run\n\nException: problem\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-29T23:11:28.940Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/pthielge\">@pthielge</a>!</p>\n<p>Thanks for writing in, and I am sorry you are facing issues over here. There could be a few issues that could cause this error to show up in your program. Could you share some more information with me so that we could narrow down the scope of this error?</p>\n<ul>\n<li>What version of <code>wandb</code> are you using?</li>\n<li>What operating system are you running this script on?</li>\n<li>There should be a folder called <code>wandb</code> in your working directory with multiple sub-folders of the format <code>run-&lt;DATETIME&gt;-&lt;ID&gt;</code>, could you share the <code>debug.log</code> and <code>debug-internal.log</code> files from the folder corresponding to this run ID?</li>\n</ul>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-30T08:53:15.297Z",
				"Answer_body": "<p>Hi Ramit,</p>\n<p>thanks for your reply.  I\u2019m using version \u20180.13.2\u2019 in JupyterLab in Windows 11. Somehow, there is only a debug.log and no debug-internal.log file, so I will append it here.</p>\n<p>Thanks,</p>\n<p>Philip</p>\n<pre><code class=\"lang-auto\">2022-08-30 10:44:49,612 INFO    MainThread:420 [wandb_setup.py:_flush():76] Configure stats pid to 420\n2022-08-30 10:44:49,612 INFO    MainThread:420 [wandb_setup.py:_flush():76] Loading settings from /home/p/pthielge/.config/wandb/settings\n2022-08-30 10:44:49,612 INFO    MainThread:420 [wandb_setup.py:_flush():76] Loading settings from /home/p/pthielge/3D/S2_Top/wandb/settings\n2022-08-30 10:44:49,612 INFO    MainThread:420 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'_require_service': 'True'}\n2022-08-30 10:44:49,612 INFO    MainThread:420 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program': '&lt;python with no main file&gt;'}\n2022-08-30 10:44:49,612 INFO    MainThread:420 [wandb_init.py:_log_setup():461] Logging user logs to /home/p/pthielge/3D/S2_Top/wandb/run-20220830_104449-5v6f9ano/logs/debug.log\n2022-08-30 10:44:49,613 INFO    MainThread:420 [wandb_init.py:_log_setup():462] Logging internal logs to /home/p/pthielge/3D/S2_Top/wandb/run-20220830_104449-5v6f9ano/logs/debug-internal.log\n2022-08-30 10:44:49,613 INFO    MainThread:420 [wandb_init.py:init():495] calling init triggers\n2022-08-30 10:44:49,613 INFO    MainThread:420 [wandb_init.py:init():499] wandb.init called with sweep_config: {}\nconfig: {}\n2022-08-30 10:44:49,613 INFO    MainThread:420 [wandb_init.py:init():548] starting backend\n2022-08-30 10:44:49,613 INFO    MainThread:420 [wandb_init.py:init():552] setting up manager\n2022-08-30 10:44:49,631 ERROR   MainThread:420 [wandb_init.py:init():1070] error\nTraceback (most recent call last):\n  File \"/home/p/pthielge/.local/lib/python3.6/site-packages/wandb/sdk/wandb_init.py\", line 1043, in init\n    run = wi.init()\n  File \"/home/p/pthielge/.local/lib/python3.6/site-packages/wandb/sdk/wandb_init.py\", line 553, in init\n    manager._inform_init(settings=self.settings, run_id=self.settings.run_id)\n  File \"/home/p/pthielge/.local/lib/python3.6/site-packages/wandb/sdk/wandb_manager.py\", line 161, in _inform_init\n    svc_iface._svc_inform_init(settings=settings, run_id=run_id)\n  File \"/home/p/pthielge/.local/lib/python3.6/site-packages/wandb/sdk/service/service_sock.py\", line 39, in _svc_inform_init\n    self._sock_client.send(inform_init=inform_init)\n  File \"/home/p/pthielge/.local/lib/python3.6/site-packages/wandb/sdk/lib/sock_client.py\", line 140, in send\n    self.send_server_request(server_req)\n  File \"/home/p/pthielge/.local/lib/python3.6/site-packages/wandb/sdk/lib/sock_client.py\", line 84, in send_server_request\n    self._send_message(msg)\n  File \"/home/p/pthielge/.local/lib/python3.6/site-packages/wandb/sdk/lib/sock_client.py\", line 81, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"/home/p/pthielge/.local/lib/python3.6/site-packages/wandb/sdk/lib/sock_client.py\", line 61, in _sendall_with_error_handle\n    sent = self._sock.send(data[total_sent:])\nBrokenPipeError: [Errno 32] Broken pipe\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-14T16:28:02.005Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/pthielge\">@pthielge</a>,</p>\n<p>Thanks for the logs! Is this an error that you see consistently across the runs or is this just a one-off event? Looks like the communication we set up between your program and our server was dropped, so I don\u2019t expect this to happen consistently.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-20T17:07:33.911Z",
				"Answer_body": "<p>\u200bHi <a class=\"mention\" href=\"/u/pthielge\">@pthielge</a>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-20T17:23:57.681Z",
				"Answer_body": "<p>Hi,</p>\n<p>thanks for your reply <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a>. It seems you\u2019re right, some temporary connection problem. I had this issue for 2 days, and then suddenly it was no longer there, without changing the code.</p>\n<p>Thank you so much. Best regards!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-20T17:28:03.479Z",
				"Answer_body": "<p>Got it! In that case, I\u2019ll go ahead and close out this support request. In case this issue shows up again, please let us know!</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-19T17:28:32.595Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to ignore NaNs in x-axis scaling?",
		"Question_link": "https://community.wandb.ai/t/how-to-ignore-nans-in-x-axis-scaling/3021",
		"Question_created_time": "2022-08-29T11:37:10.331Z",
		"Question_answer_count": 17,
		"Question_score_count": 0,
		"Question_view_count": 206,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi!</p>\n<p>I\u2019m trying to plot some results from Ray, but due to the presence of NaNs, my X axis is scaled very weirdly. Is there any way to ignore NaNs?</p>\n<p>My issue is very similar to this one: <a href=\"https://community.wandb.ai/t/nan-loss-causes-incorrect-x-axis-time-scale/2410\" class=\"inline-onebox\">NaN loss causes incorrect X axis time scale</a></p>\n<p>This is the way it looks now:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/a9a2403dfe2030c681662aac536bfb6938af619a.png\" data-download-href=\"/uploads/short-url/ocEjriMibztw54CCD86LMzxWCaS.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a9a2403dfe2030c681662aac536bfb6938af619a_2_690x248.png\" alt=\"image\" data-base62-sha1=\"ocEjriMibztw54CCD86LMzxWCaS\" width=\"690\" height=\"248\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a9a2403dfe2030c681662aac536bfb6938af619a_2_690x248.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a9a2403dfe2030c681662aac536bfb6938af619a_2_1035x372.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a9a2403dfe2030c681662aac536bfb6938af619a_2_1380x496.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a9a2403dfe2030c681662aac536bfb6938af619a_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1501\u00d7540 35.8 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-31T09:55:53.953Z",
				"Answer_body": "<p>Hi Olaf, thanks for writing! Could you please send me a link to the chart? When trying ti reproduce it, I obtain a normal chart:</p>\n<p><img src=\"https://weightsandbiases.zendesk.com/attachments/token/HRNMs6PtaUCwLu9699jYBmxku/?name=image.png\" alt=\"\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-01T08:32:44.069Z",
				"Answer_body": "<p>Thanks for looking into my issue!</p>\n<p>Since you can get a normal chart, it may be a Ray/WandB integration issue.</p>\n<p>Here\u2019s my chart: <a href=\"https://wandb.ai/olipinski/TRG/reports/episode_reward_mean-22-09-01-08-09-93---VmlldzoyNTYwNTI5?accessToken=1pyjegpzhduteztkhmj61xr0trqaeufheud6dcjhpaa521b7ksdfjgrnwj1a92f0\" class=\"inline-onebox\">Weights &amp; Biases</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-01T16:41:45.311Z",
				"Answer_body": "<p>Hi Olaf! Thanks for your answer! You have sent me a link to a report, so I can\u2019t see what data has the graph, could you please send me a link to the chart or try to load the chart in the report again?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-05T13:48:13.164Z",
				"Answer_body": "<p>Hi! Do I need to share the chart in some way as to share the data too? I have not used WandB much before.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-06T15:46:40.259Z",
				"Answer_body": "<p>Hi Olaf! You can send me a link to your Workspace and tell me what chart is causing the issue , would it be okay?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-07T08:35:42.455Z",
				"Answer_body": "<p>Hi!</p>\n<p>The workspace is <a href=\"https://wandb.ai/olipinski/TRG?workspace=user-olipinski\" class=\"inline-onebox\">Weights &amp; Biases</a> and the chart that is currently broken is <code>episode_reward_mean</code>.</p>\n<p>Thanks in advance!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-09T11:58:31.517Z",
				"Answer_body": "<p>Hi Olaf! Thanks for the link! When I find this chart, it doesn\u2019t seem to have any NaN values and is shown right, have you been able to solve the issue?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-12T08:42:51.136Z",
				"Answer_body": "<p>Nope, when the chart is set to X axis being Wall time, I still get NaNs, and incorrect scaling. This happens only for some groups of my runs, though.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-12T16:30:37.016Z",
				"Answer_body": "<p>Hi Olaf! Thanks for clarifying, I\u2019ve been able to find the chart that you mention. Could you please explain me what would be the right behaviour of the chart and what would you like to represent? From my understanding, it\u2019s working properly. I you click in More actions \u2192 Export Panel \u2192 CSV Export, in the preview you can see that all the values are NaN. Also, as the Wall Time is a number and not a Series, wouldn\u2019t it be useful to create a bar plot with Weave?</p>\n<p>Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-13T08:24:28.350Z",
				"Answer_body": "<p>Hi!</p>\n<p>Ideally, the behaviour would be that the NaNs are ignored in the chart scaling, so instead of the previous behaviour (I can only post one image per post), I would see this, but with the Wall Time as X axis.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/7caf98a8c306df13aa3bb51c0fb8989153ea1f93.png\" data-download-href=\"/uploads/short-url/hN1q1qJ9Z9R8s8Yw8cCxQvCmU1B.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7caf98a8c306df13aa3bb51c0fb8989153ea1f93_2_690x344.png\" alt=\"image\" data-base62-sha1=\"hN1q1qJ9Z9R8s8Yw8cCxQvCmU1B\" width=\"690\" height=\"344\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7caf98a8c306df13aa3bb51c0fb8989153ea1f93_2_690x344.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7caf98a8c306df13aa3bb51c0fb8989153ea1f93_2_1035x516.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/7caf98a8c306df13aa3bb51c0fb8989153ea1f93.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7caf98a8c306df13aa3bb51c0fb8989153ea1f93_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1039\u00d7519 101 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>In terms of all values being NaNs - at least to me it looks like there is only a couple of NaNs per run, and then the runs continue fine. So that breaks the scaling, I think.</p>\n<p>As for the bar plot - I\u2019m not sure what I could do there. My aim is to plot the reward over run time.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-16T15:51:10.709Z",
				"Answer_body": "<p>Hi Olaf,</p>\n<p>Thanks for the explanation! I can see the issue here, I will create a request for this feature! Please let me know if I can be of further assistance.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-20T08:33:52.143Z",
				"Answer_body": "<p>Hi Luis!</p>\n<p>I\u2019m glad to hear this may be a feature in the future! Thanks for all your help!</p>\n<p>Thanks,<br>\nOlaf</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-22T09:01:07.079Z",
				"Answer_body": "<p>Hi Olaf,</p>\n<p>Thanks you for suggesting this feature, it is really useful! Have a great day!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-27T15:58:23.489Z",
				"Answer_body": "<p>Hi Olaf,</p>\n<p>I have just checked this issue and it seems that it is working properly now. I have set the X axis to Wall Time in the <code>episode_reward_mean</code> chart and it working right. Could you check if this is working properly also for you?</p>\n<p>Best,<br>\nLuis</p>\n<p><img src=\"https://weightsandbiases.zendesk.com/attachments/token/77s1SQiyf7ADvbTecrERvagMI/?name=image.png\" alt=\"\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-03T09:10:53.585Z",
				"Answer_body": "<p>Hi Olaf,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-05T10:43:21.137Z",
				"Answer_body": "<p>Hi Olaf,</p>\n<p>Since we have not heard back, I will go ahead and close this ticket for now. If you are having any issues again with this, feel free to message us here and we would be happy to re-open the ticket and keep investigating. Thank you!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-19T08:34:39.421Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Runs in parrallel with bayesian optimisation",
		"Question_link": "https://community.wandb.ai/t/runs-in-parrallel-with-bayesian-optimisation/3127",
		"Question_created_time": "2022-09-16T14:00:06.094Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 107,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi everyone,</p>\n<p>I started to use sweeps with bayesian optimisation. The idea is that the selected criterion in the futur runs will be impacted by the past runs.</p>\n<p>But if a run starts when the last run isn\u2019t over yet, will the last run results (which is not completed yet) have an impact over the selected criterion on the run which is up to start  or will the selection of the parameters for the new run be only based on the runs that are  already over  ?</p>\n<p>Thanks for your time.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-19T22:49:59.173Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/felix_quinton\">@felix_quinton</a>, when running a parallel sweeps, we use both intermediate results in addition to results from jobs that have finished for selection of the new parameters. Our implementation is based on, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.Matern.html\" rel=\"noopener nofollow ugc\">reference1</a>, and <a href=\"http://gaussianprocess.org/gpml/chapters/RW4.pdf\" rel=\"noopener nofollow ugc\">reference2</a>, <a href=\"https://arxiv.org/pdf/1206.2944.pdf\" rel=\"noopener nofollow ugc\">reference3</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-18T22:50:41.691Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to download the learning curves of grouped runs",
		"Question_link": "https://community.wandb.ai/t/how-to-download-the-learning-curves-of-grouped-runs/3010",
		"Question_created_time": "2022-08-26T16:25:47.920Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 131,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>Is there a way to download the learning curves of grouped runs? For grouped runs, the learning curves have shaded area. Does that represent the standard deviation or the 95% confidence interval? And can we download them (the grouped curve, not the individual ones) in a python script so that we can customize the plot with matplotlib or seaborn? Thanks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-31T20:25:32.905Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/taochen\">@taochen</a>, currently it isn\u2019t possible to download these curves but you could recreate them by downloading all of the run data. The shaded area represents the variance by default but this can be changed in the graph settings. Could you let me know what you are looking to customize in Matplotlib and perhaps we could make a feature request to make this available in the UI?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-01T02:45:44.934Z",
				"Answer_body": "<p>Thanks, Nate. That makes sense. I am trying to redraw the figure in matplotlib so that the figure is better suited for paper publications. For example, customize title, font, x/y title, etc.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-14T14:09:49.068Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/taochen\">@taochen</a>, I wanted to check back and see if you were able to recreate these with the downloaded metrics or if you would like for me to submit a feature request around this?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-14T15:11:00.184Z",
				"Answer_body": "<p>Yes, I figured out a way for this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-19T21:08:53.111Z",
				"Answer_body": "<p>Great, glad to hear it!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-18T21:09:37.447Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Cannot add new members to a team I created",
		"Question_link": "https://community.wandb.ai/t/cannot-add-new-members-to-a-team-i-created/3156",
		"Question_created_time": "2022-09-19T09:42:08.669Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 131,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi there,<br>\nI created a team, but apparently I\u2019m not an admin (and neither is anyone else for that matter).<br>\nSo we\u2019re all simple members and cannot add new ppl to our team.</p>\n<p>Any solutions?<br>\nThanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-19T20:08:57.167Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/talreis\">@talreis</a>, I changed your account type to admin on team new-relic-air. Please let me know if you require additional assistance.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-19T20:44:46.000Z",
				"Answer_body": "<p>Hi Mohammad,<br>\nThat\u2019s perfect, thank you very much.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-18T20:45:31.460Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb has no attribute login error",
		"Question_link": "https://community.wandb.ai/t/wandb-has-no-attribute-login-error/3146",
		"Question_created_time": "2022-09-19T00:40:44.682Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 383,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>For some reason, I\u2019m getting an error when I run wandb in a notebook that used to run fine. My error is:</p>\n<p>AttributeError                            Traceback (most recent call last)<br>\nInput In [11], in &lt;cell line: 1&gt;()<br>\n----&gt; 1 wandb.login(key=\u2018xxx\u2019)</p>\n<p>AttributeError: module \u2018wandb\u2019 has no attribute \u2018login\u2019</p>\n<p>Has anyone else encountered this?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-19T01:04:58.020Z",
				"Answer_body": "<p>I was able to resolve this by uninstalling wandb and reinstalling the latest package. I\u2019m still not sure what caused it to begin with.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-19T20:36:51.987Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/havocy28\">@havocy28</a> , thank-you for letting us know your issue resolved with a reinstall. It\u2019s difficult to say why that error occurred, however, if it does repeat, please reach out again and we\u2019ll take a closer look.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-18T20:37:31.865Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Add_reference() with nested folders",
		"Question_link": "https://community.wandb.ai/t/add-reference-with-nested-folders/3092",
		"Question_created_time": "2022-09-10T16:36:30.113Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 441,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>We need to set a dataset folder in S3 as an artifact.  The folder has many sub-directories (only one layer though).<br>\nWhen I use the a <code>add_reference()</code> command it only stores the directory names of the top-level.<br>\nOf course, I could loop across it, but I\u2019m wondering if there is a command option to make the operation recursive?</p>\n<pre><code class=\"lang-auto\">run  = wandb.init(project=WB_PROJECT)\nart = wandb.Artifact(WB_ENTITY, type=WB_DATASET)\nart.add_reference(s3_full, max_objects=WB_MAX_OBJECTS_TO_UPLOAD)\nrun.log_artifact(art)\nwandb.finish()\n</code></pre>\n<p>EDIT 1: I conclude that the all files are not being added because the <code>Num Files</code> in the Artifact Overview shows only <code>5</code>.  If I click on the directories, it seems I can see the files, but I assume they are not actually there because of the <code>5</code> being reported for the number of files.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-14T13:35:14.013Z",
				"Answer_body": "<p>Hi Kevin,</p>\n<p>Thanks for your question! I think that the only thing that may work for you would be adding an S3 prefix without an explicit name (documentation here), the other way could be using a loop. Please let me know if this would be helpful</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-19T04:29:06.402Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/system\">@system</a> (luis) Thank you for the reply.  I think the core question is: why does \u201cNum Files\u201d (In the Artifact view) incorrectly list only the top-level files?  I may have 200K files in the artifact, but the \u201cNum Files\u201d only says \u201c5\u201d.  See example below.  Perhaps this could be fixed?  It is somewhat distressing for this parameter to be so wrong.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b49b825923f1f84758e445e5fe3ff1c2f4fd209e.png\" data-download-href=\"/uploads/short-url/pLJ7xdYJeVEm5H2IwETfNri6E2O.png?dl=1\" title=\"Artifact\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b49b825923f1f84758e445e5fe3ff1c2f4fd209e_2_690x150.png\" alt=\"Artifact\" data-base62-sha1=\"pLJ7xdYJeVEm5H2IwETfNri6E2O\" width=\"690\" height=\"150\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b49b825923f1f84758e445e5fe3ff1c2f4fd209e_2_690x150.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b49b825923f1f84758e445e5fe3ff1c2f4fd209e_2_1035x225.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b49b825923f1f84758e445e5fe3ff1c2f4fd209e_2_1380x300.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b49b825923f1f84758e445e5fe3ff1c2f4fd209e_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Artifact</span><span class=\"informations\">2228\u00d7486 49.3 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-21T11:32:02.548Z",
				"Answer_body": "<p>Hi Kevin,</p>\n<p>Thanks for the detailed explanation! I see your issue, I will create a request for this feature, thanks for reporting it! May I help you with any other issue?</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-11-18T04:29:28.422Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Multi-level nesting in yaml for sweeps",
		"Question_link": "https://community.wandb.ai/t/multi-level-nesting-in-yaml-for-sweeps/3108",
		"Question_created_time": "2022-09-13T19:43:49.093Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 1059,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I am trying to start a sweep using this yaml file.</p>\n<p>sweep.yaml</p>\n<pre><code class=\"lang-auto\">method: bayes\nmetric:\n  goal: maximize\n  name: val_f1_score\nparameters:\n  notes:\n    value: \"\"\n  seed:\n    value: 42\n  lr:\n    values: [1e-3, 5e-4, 1e-4, 5e-5, 1e-5]\n  epochs:\n    value: 30\n  augmentation:\n    value: True\n  class_weights:\n    value: True\n  optimizer:\n    value: adam\n  loss:\n    value: categorical_crossentropy\n  metrics:\n    value: [\"accuracy\"]\n  batch_size:\n    value: 64\n  num_classes:\n    value: 7\n  paths:\n    - \n      data:\n        value: ${hydra:runtime.cwd}/data/4_tfds_dataset/\n\nwandb:\n  -\n    use:\n      value: True\n    project:\n      value: Whats-this-rock\n\ndataset:\n  -\n    id:\n      value: [1, 2, 3, 4]\n    dir:\n      value: data/3_consume/\n    image:\n      size:\n        value: 124\n      channels:\n        value: 3\n    classes:\n      value: 10\n    sampling:\n      value: None\n\nmodel:\n  -\n    backbone:\n      value: efficientnetv2m\n    use_pretrained_weights:\n      value: True\n    trainable:\n      value: True\n    preprocess:\n      value: True\n    dropout_rate:\n      value: 0.3\n\ncallback:\n  -\n    monitor:\n      value: \"val_f1_score\"\n    earlystopping:\n      patience:\n        value: 10\n    reduce_lr:\n      factor:\n        values: [.9, .7, .5]\n      min_lr: 0.00001\n      patience:\n        values: [1, 2, 3, 4]\n    save_model:\n      status:\n        value: True\n      best_only:\n        value: True\n\nprogram: src/models/train.py\n\n</code></pre>\n<pre><code class=\"lang-auto\">Error: Invalid sweep config: invalid hyperparameter configuration: paths\n</code></pre>\n<p>Here\u2019s the full traceback of the error:-</p>\n<pre><code class=\"lang-auto\">During handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/wandb/cli/cli.py\", line 97, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/wandb/cli/cli.py\", line 942, in sweep\n    launch_scheduler=_launch_scheduler_spec,\n  File \"/usr/local/lib/python3.7/dist-packages/wandb/apis/internal.py\", line 102, in upsert_sweep\n    return self.api.upsert_sweep(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/wandb/apis/normalize.py\", line 62, in wrapper\n    raise CommError(message, err).with_traceback(sys.exc_info()[2])\n  File \"/usr/local/lib/python3.7/dist-packages/wandb/apis/normalize.py\", line 26, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/internal/internal_api.py\", line 2178, in upsert_sweep\n    raise e\n  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/internal/internal_api.py\", line 2175, in upsert_sweep\n    check_retry_fn=no_retry_4xx,\n  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/lib/retry.py\", line 129, in __call__\n    retry_timedelta_triggered = check_retry_fn(e)\n  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/internal/internal_api.py\", line 2153, in no_retry_4xx\n    raise UsageError(body[\"errors\"][0][\"message\"])\nwandb.errors.CommError: Invalid sweep config: invalid hyperparameter configuration: paths\n</code></pre>\n<p>I am using hydra and trying to replicate a config.yaml for wandb sweeps</p>\n<p>config.yaml</p>\n<pre><code class=\"lang-auto\">notes: \"\"\nseed: 42\nlr: 0.001\nepochs: 30\naugmentation: True\nclass_weights: True\noptimizer: adam\nloss: categorical_crossentropy\nmetrics: [\"accuracy\"]\nbatch_size: 64\nnum_classes: 7\n\npaths:\n  data: ${hydra:runtime.cwd}/data/4_tfds_dataset/\n\nwandb:\n  use: True\n  project: Whats-this-rock\n\ndataset:\n  id: [1, 2, 3, 4]\n  dir: data/3_consume/\n  image:\n    size: 124\n    channels: 3\n  classes: 10\n  sampling: None\n\nmodel:\n  backbone: efficientnetv2m\n  use_pretrained_weights: True\n  trainable: True\n  preprocess: True\n  dropout_rate: 0.3\n\ncallback:\n  monitor: \"val_f1_score\"\n  earlystopping:\n    patience: 10\n  reduce_lr:\n    factor: 0.4\n    min_lr: 0.00001\n    patience: 2\n  save_model:\n    status: True\n    best_only: True\n\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-15T23:14:14.029Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/udaylunawat\">@udaylunawat</a>!</p>\n<p>Thanks for your request! This is already a planned feature which has recieved quite a few requests, I\u2019ll go ahead and increase the priority of this feature request for you.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-16T21:11:01.193Z",
				"Answer_body": "<p>Nesting other parameters inside a root level parameter might do the trick, I\u2019ll try it and let you know.</p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/guides/sweeps/configuration#examples-1\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/63fbdc722981d8c123c2cc529ad1317258d52c56.png\" class=\"site-icon\" width=\"132\" height=\"132\">\n\n      <a href=\"https://docs.wandb.ai/guides/sweeps/configuration#examples-1\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d964bbbc3da358de18b80af06dd499d89199a157_2_500x500.png\" class=\"thumbnail onebox-avatar\" width=\"500\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d964bbbc3da358de18b80af06dd499d89199a157_2_500x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d964bbbc3da358de18b80af06dd499d89199a157.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d964bbbc3da358de18b80af06dd499d89199a157.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d964bbbc3da358de18b80af06dd499d89199a157_2_10x10.png\">\n\n<h3><a href=\"https://docs.wandb.ai/guides/sweeps/configuration#examples-1\" target=\"_blank\" rel=\"noopener\">Sweep Configuration</a></h3>\n\n  <p>Syntax to set the hyperparameter ranges, search strategy, and other aspects of your sweeps</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/2fba82a63a6feedfc9a6d30d581b78d3f6f7f12a.jpeg\" data-download-href=\"/uploads/short-url/6Oe2kSLQ8DRWbLozx0x5seRVve2.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2fba82a63a6feedfc9a6d30d581b78d3f6f7f12a_2_690x272.jpeg\" alt=\"image\" data-base62-sha1=\"6Oe2kSLQ8DRWbLozx0x5seRVve2\" width=\"690\" height=\"272\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2fba82a63a6feedfc9a6d30d581b78d3f6f7f12a_2_690x272.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2fba82a63a6feedfc9a6d30d581b78d3f6f7f12a_2_1035x408.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2fba82a63a6feedfc9a6d30d581b78d3f6f7f12a_2_1380x544.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2fba82a63a6feedfc9a6d30d581b78d3f6f7f12a_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1556\u00d7614 56 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<pre data-code-wrap=\"yaml\"><code class=\"lang-nohighlight\">method: bayes\nmetric:\n  goal: maximize\n  name: val_f1_score\nparameters:\n  notes:\n    value: \"\"\n  seed:\n    value: 42\n  lr:\n    values: [1e-3, 5e-4, 1e-4, 5e-5, 1e-5]\n  epochs:\n    value: 30\n  augmentation:\n    value: True\n  class_weights:\n    value: True\n  optimizer:\n    value: adam\n  loss:\n    value: categorical_crossentropy\n  metrics:\n    value: [\"accuracy\"]\n  batch_size:\n    value: 64\n  num_classes:\n    value: 7\n  paths:\n    parameters:\n      data:\n        value: data/4_tfds_dataset/\n  wandb:\n    parameters:\n      use:\n        value: True\n      project:\n        value: Whats-this-rock\n  dataset:\n    parameters:\n      id:\n        value: [1, 2, 3, 4]\n      dir:\n        value: data/3_consume/\n      image:\n        parameters:\n          size:\n            value: 124\n          channels:\n            value: 3\n      classes:\n        value: 10\n      sampling:\n        value: None\n  model:\n    parameters:\n      backbone:\n        value: efficientnetv2m\n      use_pretrained_weights:\n        value: True\n      trainable:\n        value: True\n      preprocess:\n        value: True\n      dropout_rate:\n        value: 0.3\n  callback:\n    parameters:\n      monitor:\n        value: \"val_f1_score\"\n      earlystopping:\n        parameters:\n          patience:\n            value: 10\n      reduce_lr:\n        parameters:\n          factor:\n            values: [.9, .7, .5]\n          patience:\n            values: [1, 2, 3, 4]\n          min_lr:\n            value: 0.00001\n      save_model:\n        parameters:\n          status:\n            value: True\n          best_only:\n            value: True\nprogram: src/models/train.py\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-16T21:32:54.210Z",
				"Answer_body": "<pre><code class=\"lang-auto\">2022-09-16 21:28:51,236 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python src/models/train.py augmentation=True batch_size=64 \"callback={'earlystopping': {'patience': 10}, 'monitor': 'val_f1_score', 'reduce_lr': {'factor': 0.7, 'min_lr': 1e-05, 'patience': 2}, 'save_model': {'best_only': True, 'status': True}}\" class_weights=True \"dataset={'classes': 7, 'dir': 'data/4_tfds_dataset/', 'id': [1, 2, 3, 4], 'image': {'channels': 3, 'size': 224}, 'sampling': 'oversampling'}\" epochs=30 loss=categorical_crossentropy lr=0.0001 metrics=['accuracy'] \"model={'backbone': 'resnet', 'dropout_rate': 0.3, 'preprocess': True, 'trainable': True, 'use_pretrained_weights': False}\" notes= num_classes=7 optimizer=adamax \"paths={'data': 'data/4_tfds_dataset/'}\" seed=42 \"wandb={'project': 'Whats-this-rock', 'use': True}\"\nno viable alternative at input '{'earlystopping''\nSee https://hydra.cc/docs/next/advanced/override_grammar/basic for details\n</code></pre>\n<p>Looks like hydra doesn\u2019t supports nesting other parameters.<br>\nIs there someway I can fix this?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-18T15:44:40.848Z",
				"Answer_body": "<p>The solution is to use dot notation instead of nested parameters as wandb (v0.13.3) sweeps doesn\u2019t support nested parameters.</p>\n<pre><code class=\"lang-auto\">sweep.yaml\n\nmethod: bayes\nmetric:\n  goal: maximize\n  name: val_accuracy\nparameters:\n  notes:\n    value: \"\"\n  seed:\n    values: [1, 42, 100]\n  lr:\n    values: [1e-3, 5e-4, 1e-4, 5e-5, 1e-5]\n  epochs:\n    value: 100\n  augmentation:\n    value: True\n  class_weights:\n    value: True\n  optimizer:\n    values: [adam, adamax]\n  loss:\n    value: categorical_crossentropy\n  metrics:\n    value: [\"accuracy\"]\n  batch_size:\n    value: 64\n  num_classes:\n    value: 7\n  train_split:\n    values:\n      - 0.70\n      - 0.75\n      - 0.80\n  data_path:\n    value: data/4_tfds_dataset/\n  wandb.use:\n    value: True\n  wandb.mode:\n    value: online\n  wandb.project:\n    value: Whats-this-rockv3\n  dataset_id:\n    values:\n      - [1]\n  image_size:\n    value: 224\n  image_channels:\n    value: 3\n  sampling:\n    values: [None, oversampling, undersampling]\n  backbone:\n    values:\n      [\n        efficientnetv2m,\n        efficientnetv2,\n        resnet,\n        mobilenetv2,\n        inceptionresnetv2,\n        xception,\n      ]\n  use_pretrained_weights:\n    values: [True]\n  trainable:\n    values: [True, False]\n  preprocess:\n    value: True\n  dropout_rate:\n    values: [0.3]\n  monitor:\n    value: \"val_accuracy\"\n  earlystopping.use:\n    value: True\n  earlystopping.patience:\n    values: [10]\n  reduce_lr.use:\n    values: [True]\n  reduce_lr.factor:\n    values: [.9, .7, .5, .3]\n  reduce_lr.patience:\n    values: [1, 3, 5, 7, 13]\n  reduce_lr.min_lr:\n    value: 1e-5\n  save_model:\n    value: False\n\nprogram: src/models/train.py\ncommand:\n  - ${env}\n  - python\n  - ${program}\n  - ${args_no_hyphens}\n\n</code></pre>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-11-17T15:44:42.439Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb automatically logeed into the wrong user -- why?",
		"Question_link": "https://community.wandb.ai/t/wandb-automatically-logeed-into-the-wrong-user-why/2916",
		"Question_created_time": "2022-08-12T14:33:18.111Z",
		"Question_answer_count": 14,
		"Question_score_count": 2,
		"Question_view_count": 1693,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I followed the usual instructions:</p>\n<pre><code class=\"lang-auto\">pip install wandb\nwandb login\n</code></pre>\n<p>but then it never asked me for the user and thus when I pasted my key into the terminal when asked it was there in the <code>.netrc</code> file but it was all wrong:</p>\n<pre><code class=\"lang-auto\">(iit_term_synthesis) brandomiranda~ \u276f\n(iit_term_synthesis) brandomiranda~ \u276f wandb login\nwandb: W&amp;B API key is configured. Use `wandb login --relogin` to force relogin\n(iit_term_synthesis) brandomiranda~ \u276f wandb login --relogin\nwandb: Logging into wandb.ai. (Learn how to deploy a W&amp;B server locally: https://wandb.me/wandb-server)\nwandb: You can find your API key in your browser here: https://wandb.ai/authorize\nwandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\nwandb: Appending key for api.wandb.ai to your netrc file: /Users/brandomiranda/.netrc\n(iit_term_synthesis) brandomiranda~ \u276f cat /Users/brandomiranda/.netrc\nmachine api.wandb.ai\n  login user\n  password djkfhkjsdhfkjshdkfj...SECRET...sdhjfjhsdjkfhsdjf\n</code></pre>\n<p>how to fix this?</p>\n<aside class=\"onebox stackexchange\" data-onebox-src=\"https://stackoverflow.com/questions/73335735/wandb-automatically-logeed-into-the-wrong-user-why\">\n  <header class=\"source\">\n\n      <a href=\"https://stackoverflow.com/questions/73335735/wandb-automatically-logeed-into-the-wrong-user-why\" target=\"_blank\" rel=\"noopener nofollow ugc\">stackoverflow.com</a>\n  </header>\n\n  <article class=\"onebox-body\">\n      <a href=\"https://stackoverflow.com/users/1601580/charlie-parker\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n    <img alt=\"Charlie Parker\" src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/5e9c0a0caedbda92f5ad9bc087e52e143936f9f5.png\" class=\"thumbnail onebox-avatar\" width=\"256\" height=\"256\">\n  </a>\n\n<h4>\n  <a href=\"https://stackoverflow.com/questions/73335735/wandb-automatically-logeed-into-the-wrong-user-why\" target=\"_blank\" rel=\"noopener nofollow ugc\">Wandb automatically logeed into the wrong user -- why?</a>\n</h4>\n\n<div class=\"tags\">\n  <strong>wand</strong>\n</div>\n\n<div class=\"date\">\n  asked by\n  \n  <a href=\"https://stackoverflow.com/users/1601580/charlie-parker\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n    Charlie Parker\n  </a>\n  on <a href=\"https://stackoverflow.com/questions/73335735/wandb-automatically-logeed-into-the-wrong-user-why\" target=\"_blank\" rel=\"noopener nofollow ugc\">02:32PM - 12 Aug 22 UTC</a>\n</div>\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-12T14:48:34.706Z",
				"Answer_body": "<p>not sure what happened, but I would suggest <a href=\"https://docs.wandb.ai/ref/cli/wandb-login\">forcing a relogin</a></p>\n<pre><code class=\"lang-auto\">wandb login --relogin\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-12T14:55:39.606Z",
				"Answer_body": "<p>yes I tried forcing a relogin, and it changes my username in the <code>.netrc</code> file to <code>user</code> <img src=\"https://emoji.discourse-cdn.com/twitter/confused.png?v=12\" title=\":confused:\" class=\"emoji\" alt=\":confused:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-12T14:56:34.143Z",
				"Answer_body": "<p>why does the relogin change my username as followins in the <code>.netrc</code> file:</p>\n<pre><code class=\"lang-auto\">machine api.wandb.ai\n  login user\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-12T15:02:37.217Z",
				"Answer_body": "<p>seems to have the right version?</p>\n<pre><code class=\"lang-auto\">(iit_term_synthesis) brandomiranda~ \u276f pip install wandb --upgrade\nRequirement already satisfied: wandb in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (0.13.1)\nRequirement already satisfied: setproctitle in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (from wandb) (1.2.3)\nRequirement already satisfied: docker-pycreds&gt;=0.4.0 in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: setuptools in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (from wandb) (61.2.0)\nRequirement already satisfied: Click!=8.0.0,&gt;=7.0 in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (from wandb) (8.1.3)\nRequirement already satisfied: protobuf&lt;4.0dev,&gt;=3.12.0 in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (from wandb) (3.19.4)\nRequirement already satisfied: requests&lt;3,&gt;=2.0.0 in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (from wandb) (2.28.1)\nRequirement already satisfied: psutil&gt;=5.0.0 in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (from wandb) (5.9.1)\nRequirement already satisfied: six&gt;=1.13.0 in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (from wandb) (1.16.0)\nRequirement already satisfied: PyYAML in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (from wandb) (6.0)\nRequirement already satisfied: pathtools in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: GitPython&gt;=1.0.0 in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (from wandb) (3.1.27)\nRequirement already satisfied: shortuuid&gt;=0.5.0 in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (from wandb) (1.0.9)\nRequirement already satisfied: sentry-sdk&gt;=1.0.0 in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (from wandb) (1.6.0)\nRequirement already satisfied: promise&lt;3,&gt;=2.0 in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (from wandb) (2.3)\nRequirement already satisfied: gitdb&lt;5,&gt;=4.0.1 in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (from GitPython&gt;=1.0.0-&gt;wandb) (4.0.9)\nRequirement already satisfied: smmap&lt;6,&gt;=3.0.1 in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (from gitdb&lt;5,&gt;=4.0.1-&gt;GitPython&gt;=1.0.0-&gt;wandb) (5.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (1.26.9)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (3.3)\nRequirement already satisfied: certifi&gt;=2017.4.17 in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (2022.6.15)\nRequirement already satisfied: charset-normalizer&lt;3,&gt;=2 in ./miniconda/envs/iit_term_synthesis/lib/python3.9/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (2.0.12)\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-12T15:08:10.652Z",
				"Answer_body": "<p>is there a terminal command to test I logged into wandb?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-12T15:09:54.535Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/morgan\">@morgan</a> can you show me the output of your command:</p>\n<pre><code class=\"lang-auto\">cat ~/.netrc\n</code></pre>\n<p>of course you should remove the key value with something else like <code>SECRET</code> when pasting it here.</p>\n<p>Mine looks as follows:</p>\n<pre><code class=\"lang-auto\">(iit_term_synthesis) brandomiranda~ \u276f cat /Users/brandomiranda/.netrc\nmachine api.wandb.ai\n  login brando\n  password SECRET\n</code></pre>\n<p>but relogin changes it to:</p>\n<pre><code class=\"lang-auto\">machine api.wandb.ai\n  login user\n  password SECRET\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-12T15:14:11.763Z",
				"Answer_body": "<p>note I do have this env variable set to see if it forced things:</p>\n<pre><code class=\"lang-auto\">echo $WANDB_API_KEY\n</code></pre>\n<p>it\u2019s output does look like my key.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-12T15:22:04.480Z",
				"Answer_body": "<p>actually just discovered that it doesn\u2019t work in the pycharm debugger. Thats the issue.</p>\n<p>But that is weird, I\u2019ve ran it from pycharm debugger before\u2026<img src=\"https://emoji.discourse-cdn.com/twitter/confused.png?v=12\" title=\":confused:\" class=\"emoji\" alt=\":confused:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-12T15:49:49.713Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"brando\" data-post=\"9\" data-topic=\"2916\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://sea2.discourse-cdn.com/business7/user_avatar/community.wandb.ai/brando/40/199_2.png\" class=\"avatar\"> brando:</div>\n<blockquote>\n<p>But that is weird, I\u2019ve ran it from pycharm debugger before\u2026<img src=\"https://emoji.discourse-cdn.com/twitter/confused.png?v=12\" title=\":confused:\" class=\"emoji\" alt=\":confused:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n</blockquote>\n</aside>\n<p>First make sure your <code>.netrc</code> file looks right. Login in as instructed in wandb and its fine to relogin. Make sure it still looks fine. Make sure you update wandb with pip. You can set the env variable with your key too. Update pycharm. Remove all the .idea folders in your projects and start from scratch. Make sure your pycharm projs have the right path to the python interpreter form pycharm. Thats I think what worked\u2026</p>\n<pre><code class=\"lang-auto\">(iit_term_synthesis) brandomiranda~/iit-term-synthesis \u276f rm -rf ../ultimate-utils/.idea\n(iit_term_synthesis) brandomiranda~/iit-term-synthesis \u276f rm -rf ../iit-term-synthesis/.idea\n(iit_term_synthesis) brandomiranda~/iit-term-synthesis \u276f rm -rf ../pycoq/.idea\n(iit_term_synthesis) brandomiranda~/iit-term-synthesis \u276f rm -rf ../data/.idea\n(iit_term_synthesis) brandomiranda~/iit-term-synthesis \u276f rm -rf ../proverbot/.idea\n</code></pre>\n<p>this was useful:</p>\n<pre><code class=\"lang-auto\">run_bash_command('pip install wandb --upgrade')\ncat_file('~/.zshrc')\ncat_file('~/.netrc')\n\nwandb.init(project=\"proof-term-synthesis\", entity=\"brando\", name='run_name', group='expt_name')\n\nprint('success!\\a')\n\n</code></pre>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-08-16T16:14:48.293Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/morgan\">@morgan</a> is it really correct behaviour that a forcing in login changes my login field in the netrc to user? see:</p>\n<pre><code class=\"lang-auto\">(iit_synthesis) [miranda9@cccxc518 pycoq]$ cat ~/.netrc\nmachine api.wandb.ai\n  login user\n  password fdlhsljkhsdflhjkfsdlhjk...SECRET...iputriuyohjsdbkljfdslhkj\n</code></pre>\n<p>also, is it normal that despite my <code>~/.netrc</code> files looks fine that my bash script still needs this env variable?:</p>\n<pre><code class=\"lang-auto\">WANDB_API_KEY=jhkjlljhkhjklhjkl....secret....skdfjdsfjlhjkfsd\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-24T15:18:38.917Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/brando\">@brando</a> I do see that it changes my login field in netrc to \u201cuser\u201d also, and I haven\u2019t had any issues with logging in before\u2026</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-15T23:47:38.359Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/morgan\">@morgan</a> do you have an example of a <code>.netrc</code> that is \u201ccorrect\u201d/works</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-16T17:47:10.605Z",
				"Answer_body": "<p>some answers that don\u2019t work here: <a href=\"https://stackoverflow.com/questions/73335735/wandb-automatically-logged-into-the-wrong-user-why\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">pycharm - Wandb automatically logged into the wrong user -- why? - Stack Overflow</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-15T17:48:01.758Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "The group you tried to contact (support) may not exist",
		"Question_link": "https://community.wandb.ai/t/the-group-you-tried-to-contact-support-may-not-exist/3114",
		"Question_created_time": "2022-09-14T12:24:07.836Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 100,
		"Question_has_accepted_answer": false,
		"Question_body": "<blockquote>\n<p>We\u2019re writing to let you know that the group you tried to contact (support) may not exist, or you may not have permission to post messages to the group. A few more details on why you weren\u2019t able to post:</p>\n<ul>\n<li>You might have spelled or formatted the group name incorrectly.</li>\n<li>The owner of the group may have removed this group.</li>\n<li>You may need to join the group before receiving permission to post.</li>\n<li>This group may not be open to posting.</li>\n</ul>\n</blockquote>\n<p>The email I was using is: <a href=\"mailto:support@wandb.com\">support@wandb.com</a><br>\nIt is displayed when my page crashes and I just wanted to report it.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-15T20:33:44.082Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dc914337\">@dc914337</a>, can you please expand on what you mean by the page crashing. Are you on a specific page when this occurs?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-15T20:43:57.318Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dc914337\">@dc914337</a> , we will continue the conversation in <a href=\"https://community.wandb.ai/t/report-page-often-crashes-when-i-collapse-a-section-of-the-report/3115\">the other thread you posted</a> as it seems the issue is tied to your reports.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-16T05:36:01.768Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> I\u2019m facing the same issue emailing <a href=\"mailto:support@wandb.com\">support@wandb.com</a> following instructions from <a href=\"https://docs.wandb.ai/company/getting-help\" class=\"inline-onebox\">Support - Documentation</a></p>\n<blockquote>\n<p>We\u2019re writing to let you know that the group you tried to contact (support) may not exist, or you may not have permission to post messages to the group. A few more details on why you weren\u2019t able to post:</p>\n<ul>\n<li>You might have spelled or formatted the group name incorrectly.</li>\n<li>The owner of the group may have removed this group.</li>\n<li>You may need to join the group before receiving permission to post.</li>\n<li>This group may not be open to posting.</li>\n</ul>\n</blockquote>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-16T16:18:04.295Z",
				"Answer_body": "<p>it\u2019s probably not. One is mail, second is your frontend.<br>\nHere is the screenshot of the undelivered message.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/7340186597f35272af96614c058f92d16b1fd286.png\" data-download-href=\"/uploads/short-url/gryeqiLtJdcWfcbZeJ34ZHNnmNo.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/7340186597f35272af96614c058f92d16b1fd286.png\" alt=\"image\" data-base62-sha1=\"gryeqiLtJdcWfcbZeJ34ZHNnmNo\" width=\"690\" height=\"443\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7340186597f35272af96614c058f92d16b1fd286_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">736\u00d7473 14.7 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-15T16:18:10.511Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to retrieve the `group` and `job_type` of a resumed run?",
		"Question_link": "https://community.wandb.ai/t/how-to-retrieve-the-group-and-job-type-of-a-resumed-run/3031",
		"Question_created_time": "2022-08-30T15:53:04.218Z",
		"Question_answer_count": 6,
		"Question_score_count": 1,
		"Question_view_count": 109,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I am inspecting and analysing my best runs. I expected that <code>group</code> and <code>job_type</code> would be populated with the resumed run\u2019s values after running the code below.</p>\n<pre><code class=\"lang-python\">run_id = input(\"id=\")\nwith wandb.init(entity=wandb_entity, project=wandb_project, id=run_id, resume=\"must\") as wandb_r:\n    config = wandb_r.config\n    group = wandb_r.group\n    job_type = wandb_r.job_type\n</code></pre>\n<p>Even though <code>config</code> is successfully recovered, <code>group</code> and <code>job_type</code> are just empty strings. How do I retrieve group and job_type values from WandB? Thanks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-02T14:18:38.611Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/avm21\">@avm21</a>, it looks like we don\u2019t download these on resumed runs but rather we don\u2019t update them unless you explicitly change them on a resumed run. If you need to get group/job_type you can use the public API like this to access anything you may need:</p>\n<pre><code class=\"lang-auto\">import wandb\nfrom wandb import Api\n\napi = Api()\n\nwith wandb.init(entity=wandb_entity, project=wandb_project, id=run_id, resume=\"must\") as wandb_r:\n    config = wandb_r.config\n\n    # A resumed run will still have the path attribute which can be used to access the run via the API\n    api_run = api.run(wandb_r.path)\n\n    # This will correctly print the group of the run\n    print(api_run.group)\n</code></pre>\n<p>Let me know if you have any questions around this.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-09-02T14:48:41.545Z",
				"Answer_body": "<p>Hi Nate,</p>\n<p>Thank you for the snippet, it will do! The only question that remains is \u201cwhy not?\u201d, but I guess it is more of a rhetorical kind and does not necessitate an answer.</p>\n<p>Regards,</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-09T16:54:52.780Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/avm21\">@avm21</a>,<br>\nGlad this got you unblocked! I\u2019m not sure the reasoning behind not downloading all metadata associated with the run when it is resumed but if you would like to see a change in this behavior I\u2019d be happy to put a feature request around this?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-09T22:28:55.308Z",
				"Answer_body": "<p>Yes, I would like to see a change in this behaviour, even though I can live without it. I expected the fields of <code>wandb_r</code> to be repopulated on resume, and I guess other reasonable users would find this expectation reasonable. First, it is only logical that since <code>wandb_r</code> represents a run, the run\u2019s properties are reflected in <code>wandb_r</code>\u2019s properties. Second, it allows me to re-use code, for as far as I remember, <code>wandb_r.group</code> is set when I initiate a new run. Third, I\u2019ve been always confused as to the purpose and difference between <code>wandb.public.Api.Run</code> and <code>wandb.Run</code> objects, and the fewer differences there are, the better I like it.</p>\n<p>Kind regards,</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-16T15:33:44.840Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/avm21\">@avm21</a>, I\u2019ve submitted your feedback to our engineering team. Thank you for the details as to why you feel this is important. I agree that it is counter-intuitive that some attributes are filled when resuming but some are not.</p>\n<p>I\u2019ll follow up with you here once the engineering team has a chance to take a look at this.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-15T15:34:04.342Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Lighting: Checkpoints silently fail to save",
		"Question_link": "https://community.wandb.ai/t/lighting-checkpoints-silently-fail-to-save/3048",
		"Question_created_time": "2022-09-01T23:10:02.656Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 111,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Every couple of hours I silently get this error during training then checkpoints silently fail to save from then on. I\u2019ve now lost &gt;30 hrs of training because of this weird issue. Does anyone know what\u2019s causing this and how to fix it?</p>\n<p>for future searchers:<br>\n<code>NVMLError_OperatingSystem: The operating system has blocked the request.</code></p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/40594953988cd414c66052042a88418ba4eda5a4.jpeg\" data-download-href=\"/uploads/short-url/9bfQUuHL4Ek3Qjo5EjzA1z8ucRK.jpeg?dl=1\" title=\"IMG_0367\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/40594953988cd414c66052042a88418ba4eda5a4_2_690x497.jpeg\" alt=\"IMG_0367\" data-base62-sha1=\"9bfQUuHL4Ek3Qjo5EjzA1z8ucRK\" width=\"690\" height=\"497\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/40594953988cd414c66052042a88418ba4eda5a4_2_690x497.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/40594953988cd414c66052042a88418ba4eda5a4_2_1035x745.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/40594953988cd414c66052042a88418ba4eda5a4.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/40594953988cd414c66052042a88418ba4eda5a4_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">IMG_0367</span><span class=\"informations\">1284\u00d7925 205 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-07T15:25:10.995Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/zaptrem\">@zaptrem</a> thank you for reporting this. We will need a bit more context here on your setup both hardware and environments. Is this a WSL terminal? there might be some issues with NVML and WSL.<br>\nAlso wanted to clarify, did it not log anything from epoch 1876 to 2392? would you be interested in running the experiments in offline mode and write the data to your disk and sync to W&amp;B afterwards?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-12T17:36:47.447Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/zaptrem\">@zaptrem</a> I wanted to follow up with you regarding this issue, could you provide some more information asked above to help debug this? Please let me know if I can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-16T11:39:46.460Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/zaptrem\">@zaptrem</a> as we haven\u2019t heard back from you, we are going to close the ticket for now. Please feel free to message us here if the issue hasn\u2019t been resolved for you, and we will be happy to keep investigating!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-15T11:40:13.660Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Support@wandb.com doesn't work",
		"Question_link": "https://community.wandb.ai/t/support-wandb-com-doesnt-work/3122",
		"Question_created_time": "2022-09-16T05:37:48.094Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 91,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I emailed <a href=\"mailto:support@wandb.com\">support@wandb.com</a> following instructions from <a href=\"https://docs.wandb.ai/company/getting-help\">Support - Documentation</a></p>\n<p>However, my email doesn\u2019t go through and I get the following automated reply:</p>\n<blockquote>\n<p>We\u2019re writing to let you know that the group you tried to contact (support) may not exist, or you may not have permission to post messages to the group. A few more details on why you weren\u2019t able to post:</p>\n<ul>\n<li>You might have spelled or formatted the group name incorrectly.</li>\n<li>The owner of the group may have removed this group.</li>\n<li>You may need to join the group before receiving permission to post.</li>\n<li>This group may not be open to posting.</li>\n</ul>\n</blockquote>\n<p>I also can\u2019t seem to access the Zendesk chat widget, even with ad blockers and all extensions removed.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-16T19:40:48.486Z",
				"Answer_body": "<p>Hi Yulong,</p>\n<p>Thanks for reporting this! We have fixed and this should be working again.</p>\n<p>Thanks,<br>\nSydney</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-15T05:38:21.933Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to install wandb on a docker image for arm?",
		"Question_link": "https://community.wandb.ai/t/how-to-install-wandb-on-a-docker-image-for-arm/3080",
		"Question_created_time": "2022-09-08T00:09:22.611Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 937,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>My docker building failed at the <code>RUN </code></p>\n<p>with:</p>\n<pre><code class=\"lang-auto\">(meta_learning) brandomiranda~ \u276f docker build -f ~/iit-term-synthesis/Dockerfile_arm -t brandojazz/iit-term-synthesis:test_arm ~/iit-term-synthesis/\n\n[+] Building 184.7s (20/28)\n =&gt; [internal] load build definition from Dockerfile_arm                                                                                           0.0s\n =&gt; =&gt; transferring dockerfile: 41B                                                                                                                0.0s\n =&gt; [internal] load .dockerignore                                                                                                                  0.0s\n =&gt; =&gt; transferring context: 2B                                                                                                                    0.0s\n =&gt; [internal] load metadata for docker.io/continuumio/miniconda3:latest                                                                           0.0s\n =&gt; [ 1/24] FROM docker.io/continuumio/miniconda3                                                                                                  0.0s\n =&gt; https://api.github.com/repos/IBM/pycoq/git/refs/heads/main                                                                                     0.3s\n =&gt; CACHED [ 2/24] RUN apt-get update   &amp;&amp; apt-get install -y --no-install-recommends     ssh     git     m4     libgmp-dev     opam     wget      0.0s\n =&gt; CACHED [ 3/24] RUN useradd -m bot                                                                                                              0.0s\n =&gt; CACHED [ 4/24] WORKDIR /home/bot                                                                                                               0.0s\n =&gt; CACHED [ 5/24] ADD https://api.github.com/repos/IBM/pycoq/git/refs/heads/main version.json                                                     0.0s\n =&gt; CACHED [ 6/24] RUN opam init --disable-sandboxing                                                                                              0.0s\n =&gt; CACHED [ 7/24] RUN opam switch create ocaml-variants.4.07.1+flambda_coq-serapi.8.11.0+0.11.1 ocaml-variants.4.07.1+flambda                     0.0s\n =&gt; CACHED [ 8/24] RUN opam switch ocaml-variants.4.07.1+flambda_coq-serapi.8.11.0+0.11.1                                                          0.0s\n =&gt; CACHED [ 9/24] RUN eval $(opam env)                                                                                                            0.0s\n =&gt; CACHED [10/24] RUN opam repo add coq-released https://coq.inria.fr/opam/released                                                               0.0s\n =&gt; CACHED [11/24] RUN opam repo --all-switches add --set-default coq-released https://coq.inria.fr/opam/released                                  0.0s\n =&gt; CACHED [12/24] RUN opam update --all                                                                                                           0.0s\n =&gt; CACHED [13/24] RUN opam pin add -y coq 8.11.0                                                                                                  0.0s\n =&gt; [14/24] RUN opam install -y coq-serapi                                                                                                       176.3s\n =&gt; [15/24] RUN eval $(opam env)                                                                                                                   0.2s\n =&gt; ERROR [16/24] RUN pip install wandb --upgrade                                                                                                  8.0s\n------\n &gt; [16/24] RUN pip install wandb --upgrade:\n#20 0.351 Defaulting to user installation because normal site-packages is not writeable\n#20 0.637 Collecting wandb\n#20 0.986   Downloading wandb-0.13.2-py2.py3-none-any.whl (1.8 MB)\n#20 1.365 Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from wandb) (61.2.0)\n#20 1.366 Requirement already satisfied: six&gt;=1.13.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (1.16.0)\n#20 1.409 Collecting promise&lt;3,&gt;=2.0\n#20 1.472   Downloading promise-2.3.tar.gz (19 kB)\n#20 2.087 Collecting PyYAML\n#20 2.154   Downloading PyYAML-6.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (731 kB)\n#20 2.431 Collecting protobuf&lt;4.0dev,&gt;=3.12.0\n#20 2.492   Downloading protobuf-3.20.1-cp39-cp39-manylinux2014_aarch64.whl (917 kB)\n#20 2.648 Collecting setproctitle\n#20 2.706   Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (30 kB)\n#20 2.763 Collecting Click!=8.0.0,&gt;=7.0\n#20 2.818   Downloading click-8.1.3-py3-none-any.whl (96 kB)\n#20 2.902 Collecting sentry-sdk&gt;=1.0.0\n#20 2.962   Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n#20 3.112 Collecting psutil&gt;=5.0.0\n#20 3.172   Downloading psutil-5.9.2.tar.gz (479 kB)\n#20 3.871 Collecting pathtools\n#20 3.937   Downloading pathtools-0.1.2.tar.gz (11 kB)\n#20 4.431 Collecting shortuuid&gt;=0.5.0\n#20 4.509   Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n#20 4.512 Requirement already satisfied: requests&lt;3,&gt;=2.0.0 in /opt/conda/lib/python3.9/site-packages (from wandb) (2.27.1)\n#20 4.568 Collecting docker-pycreds&gt;=0.4.0\n#20 4.636   Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n#20 4.695 Collecting GitPython&gt;=1.0.0\n#20 4.781   Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n#20 4.834 Collecting gitdb&lt;5,&gt;=4.0.1\n#20 4.892   Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n#20 4.934 Collecting smmap&lt;6,&gt;=3.0.1\n#20 4.992   Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n#20 5.005 Requirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (1.26.8)\n#20 5.005 Requirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (2021.10.8)\n#20 5.006 Requirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/conda/lib/python3.9/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (3.3)\n#20 5.006 Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests&lt;3,&gt;=2.0.0-&gt;wandb) (2.0.4)\n#20 5.075 Collecting urllib3&lt;1.27,&gt;=1.21.1\n#20 5.135   Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n#20 5.172 Building wheels for collected packages: promise, psutil, pathtools\n#20 5.172   Building wheel for promise (setup.py): started\n#20 5.851   Building wheel for promise (setup.py): finished with status 'done'\n#20 5.852   Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21503 sha256=6de0373376d2a8e995959e6173507e13cba502c79b648b5884b1eac45d1ec9ae\n#20 5.852   Stored in directory: /home/bot/.cache/pip/wheels/e1/e8/83/ddea66100678d139b14bc87692ece57c6a2a937956d2532608\n#20 5.854   Building wheel for psutil (setup.py): started\n#20 6.226   Building wheel for psutil (setup.py): finished with status 'error'\n#20 6.226   ERROR: Command errored out with exit status 1:\n#20 6.226    command: /opt/conda/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-vgietl2j/psutil_c905945489d349018aaad0a17600df0b/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-vgietl2j/psutil_c905945489d349018aaad0a17600df0b/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-4y62c4eb\n#20 6.226        cwd: /tmp/pip-install-vgietl2j/psutil_c905945489d349018aaad0a17600df0b/\n#20 6.226   Complete output (45 lines):\n#20 6.226   running bdist_wheel\n#20 6.226   running build\n#20 6.226   running build_py\n#20 6.226   creating build\n#20 6.226   creating build/lib.linux-aarch64-3.9\n#20 6.226   creating build/lib.linux-aarch64-3.9/psutil\n#20 6.226   copying psutil/_psosx.py -&gt; build/lib.linux-aarch64-3.9/psutil\n#20 6.226   copying psutil/_psbsd.py -&gt; build/lib.linux-aarch64-3.9/psutil\n#20 6.226   copying psutil/_common.py -&gt; build/lib.linux-aarch64-3.9/psutil\n#20 6.226   copying psutil/_pswindows.py -&gt; build/lib.linux-aarch64-3.9/psutil\n#20 6.226   copying psutil/_psposix.py -&gt; build/lib.linux-aarch64-3.9/psutil\n#20 6.226   copying psutil/__init__.py -&gt; build/lib.linux-aarch64-3.9/psutil\n#20 6.226   copying psutil/_compat.py -&gt; build/lib.linux-aarch64-3.9/psutil\n#20 6.226   copying psutil/_pslinux.py -&gt; build/lib.linux-aarch64-3.9/psutil\n#20 6.226   copying psutil/_pssunos.py -&gt; build/lib.linux-aarch64-3.9/psutil\n#20 6.226   copying psutil/_psaix.py -&gt; build/lib.linux-aarch64-3.9/psutil\n#20 6.226   creating build/lib.linux-aarch64-3.9/psutil/tests\n#20 6.226   copying psutil/tests/__main__.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 6.226   copying psutil/tests/test_process.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 6.226   copying psutil/tests/test_aix.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 6.226   copying psutil/tests/test_misc.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 6.226   copying psutil/tests/test_bsd.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 6.226   copying psutil/tests/test_linux.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 6.226   copying psutil/tests/runner.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 6.226   copying psutil/tests/__init__.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 6.226   copying psutil/tests/test_connections.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 6.226   copying psutil/tests/test_unicode.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 6.226   copying psutil/tests/test_windows.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 6.226   copying psutil/tests/test_contracts.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 6.226   copying psutil/tests/test_sunos.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 6.226   copying psutil/tests/test_testutils.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 6.226   copying psutil/tests/test_osx.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 6.226   copying psutil/tests/test_memleaks.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 6.226   copying psutil/tests/test_posix.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 6.226   copying psutil/tests/test_system.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 6.226   running build_ext\n#20 6.226   building 'psutil._psutil_linux' extension\n#20 6.226   creating build/temp.linux-aarch64-3.9\n#20 6.226   creating build/temp.linux-aarch64-3.9/psutil\n#20 6.226   gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -n1 .2-a+fp16+rcpc+dotprod+crypto -isystem /opt/conda/include -I/opt/conda/include -fPIC -O2 -n1 .2-a+fp16+rcpc+dotprod+crypto -isystem /opt/conda/include -fPIC -DPSUTIL_POSIX=1 -DPSUTIL_SIZEOF_PID_T=4 -DPSUTIL_VERSION=592 -DPSUTIL_LINUX=1 -I/opt/conda/include/python3.9 -c psutil/_psutil_common.c -o build/temp.linux-aarch64-3.9/psutil/_psutil_common.o\n#20 6.226   gcc: error: .2-a+fp16+rcpc+dotprod+crypto: No such file or directory\n#20 6.226   gcc: error: .2-a+fp16+rcpc+dotprod+crypto: No such file or directory\n#20 6.226   gcc: error: unrecognized command-line option \u2018-n1\u2019; did you mean \u2018-n\u2019?\n#20 6.226   gcc: error: unrecognized command-line option \u2018-n1\u2019; did you mean \u2018-n\u2019?\n#20 6.226   error: command '/usr/bin/gcc' failed with exit code 1\n#20 6.226   ----------------------------------------\n#20 6.226   ERROR: Failed building wheel for psutil\n#20 6.226   Running setup.py clean for psutil\n#20 6.550   Building wheel for pathtools (setup.py): started\n#20 7.135   Building wheel for pathtools (setup.py): finished with status 'done'\n#20 7.135   Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=8e205a0f68c9c7a3c0107d1cc40d94f1d2843c78270217378dcbe98212958b82\n#20 7.135   Stored in directory: /home/bot/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n#20 7.136 Successfully built promise pathtools\n#20 7.136 Failed to build psutil\n#20 7.195 Installing collected packages: smmap, urllib3, gitdb, shortuuid, setproctitle, sentry-sdk, PyYAML, psutil, protobuf, promise, pathtools, GitPython, docker-pycreds, Click, wandb\n#20 7.262   WARNING: The script shortuuid is installed in '/home/bot/.local/bin' which is not on PATH.\n#20 7.262   Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n#20 7.345     Running setup.py install for psutil: started\n#20 7.727     Running setup.py install for psutil: finished with status 'error'\n#20 7.727     ERROR: Command errored out with exit status 1:\n#20 7.727      command: /opt/conda/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-vgietl2j/psutil_c905945489d349018aaad0a17600df0b/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-vgietl2j/psutil_c905945489d349018aaad0a17600df0b/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-gb2y421d/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/bot/.local/include/python3.9/psutil\n#20 7.727          cwd: /tmp/pip-install-vgietl2j/psutil_c905945489d349018aaad0a17600df0b/\n#20 7.727     Complete output (47 lines):\n#20 7.727     running install\n#20 7.727     /opt/conda/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n#20 7.727       warnings.warn(\n#20 7.727     running build\n#20 7.727     running build_py\n#20 7.727     creating build\n#20 7.727     creating build/lib.linux-aarch64-3.9\n#20 7.727     creating build/lib.linux-aarch64-3.9/psutil\n#20 7.727     copying psutil/_psosx.py -&gt; build/lib.linux-aarch64-3.9/psutil\n#20 7.727     copying psutil/_psbsd.py -&gt; build/lib.linux-aarch64-3.9/psutil\n#20 7.727     copying psutil/_common.py -&gt; build/lib.linux-aarch64-3.9/psutil\n#20 7.727     copying psutil/_pswindows.py -&gt; build/lib.linux-aarch64-3.9/psutil\n#20 7.727     copying psutil/_psposix.py -&gt; build/lib.linux-aarch64-3.9/psutil\n#20 7.727     copying psutil/__init__.py -&gt; build/lib.linux-aarch64-3.9/psutil\n#20 7.727     copying psutil/_compat.py -&gt; build/lib.linux-aarch64-3.9/psutil\n#20 7.727     copying psutil/_pslinux.py -&gt; build/lib.linux-aarch64-3.9/psutil\n#20 7.727     copying psutil/_pssunos.py -&gt; build/lib.linux-aarch64-3.9/psutil\n#20 7.727     copying psutil/_psaix.py -&gt; build/lib.linux-aarch64-3.9/psutil\n#20 7.727     creating build/lib.linux-aarch64-3.9/psutil/tests\n#20 7.727     copying psutil/tests/__main__.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 7.727     copying psutil/tests/test_process.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 7.727     copying psutil/tests/test_aix.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 7.727     copying psutil/tests/test_misc.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 7.727     copying psutil/tests/test_bsd.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 7.727     copying psutil/tests/test_linux.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 7.727     copying psutil/tests/runner.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 7.727     copying psutil/tests/__init__.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 7.727     copying psutil/tests/test_connections.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 7.727     copying psutil/tests/test_unicode.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 7.727     copying psutil/tests/test_windows.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 7.727     copying psutil/tests/test_contracts.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 7.727     copying psutil/tests/test_sunos.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 7.727     copying psutil/tests/test_testutils.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 7.727     copying psutil/tests/test_osx.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 7.727     copying psutil/tests/test_memleaks.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 7.727     copying psutil/tests/test_posix.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 7.727     copying psutil/tests/test_system.py -&gt; build/lib.linux-aarch64-3.9/psutil/tests\n#20 7.727     running build_ext\n#20 7.727     building 'psutil._psutil_linux' extension\n#20 7.727     creating build/temp.linux-aarch64-3.9\n#20 7.727     creating build/temp.linux-aarch64-3.9/psutil\n#20 7.727     gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -n1 .2-a+fp16+rcpc+dotprod+crypto -isystem /opt/conda/include -I/opt/conda/include -fPIC -O2 -n1 .2-a+fp16+rcpc+dotprod+crypto -isystem /opt/conda/include -fPIC -DPSUTIL_POSIX=1 -DPSUTIL_SIZEOF_PID_T=4 -DPSUTIL_VERSION=592 -DPSUTIL_LINUX=1 -I/opt/conda/include/python3.9 -c psutil/_psutil_common.c -o build/temp.linux-aarch64-3.9/psutil/_psutil_common.o\n#20 7.727     gcc: error: .2-a+fp16+rcpc+dotprod+crypto: No such file or directory\n#20 7.727     gcc: error: .2-a+fp16+rcpc+dotprod+crypto: No such file or directory\n#20 7.727     gcc: error: unrecognized command-line option \u2018-n1\u2019; did you mean \u2018-n\u2019?\n#20 7.727     gcc: error: unrecognized command-line option \u2018-n1\u2019; did you mean \u2018-n\u2019?\n#20 7.727     error: command '/usr/bin/gcc' failed with exit code 1\n#20 7.727     ----------------------------------------\n#20 7.728 ERROR: Command errored out with exit status 1: /opt/conda/bin/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-vgietl2j/psutil_c905945489d349018aaad0a17600df0b/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-vgietl2j/psutil_c905945489d349018aaad0a17600df0b/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-gb2y421d/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/bot/.local/include/python3.9/psutil Check the logs for full command output.\n------\nexecutor failed running [/bin/sh -c pip install wandb --upgrade]: exit code: 1\n</code></pre>\n<p>why?</p>\n<p>Docker file so far:</p>\n<pre><code class=\"lang-auto\">FROM continuumio/miniconda3\n\nRUN apt-get update \\\n  &amp;&amp; apt-get install -y --no-install-recommends \\\n    ssh \\\n    git \\\n    m4 \\\n    libgmp-dev \\\n    opam \\\n    wget \\\n    ca-certificates \\\n    rsync \\\n    strace\n\nRUN useradd -m bot\nWORKDIR /home/bot\nUSER bot\n\n## https://stackoverflow.com/questions/73642349/how-to-have-miniconda-work-properly-with-docker-especially-naming-my-conda-en\n#RUN wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh  \\\n#    &amp;&amp; bash Miniconda3-latest-Linux-x86_64.sh -b -f\n#ENV PATH=\"/home/bot/miniconda3/bin:${PATH}\"\n#RUN conda create -n pycoq python=3.9 -y\n## somehow this \"works\" but conda isn't fully aware of this. Fix later?\n#ENV PATH=\"/home/bot/miniconda3/envs/pycoq/bin:${PATH}\"\n\nADD https://api.github.com/repos/IBM/pycoq/git/refs/heads/main version.json\n\n# -- setup opam like VP's PyCoq\nRUN opam init --disable-sandboxing\n# compiler + '_' + coq_serapi + '.' + coq_serapi_pin\nRUN opam switch create ocaml-variants.4.07.1+flambda_coq-serapi.8.11.0+0.11.1 ocaml-variants.4.07.1+flambda\nRUN opam switch ocaml-variants.4.07.1+flambda_coq-serapi.8.11.0+0.11.1\nRUN eval $(opam env)\n\nRUN opam repo add coq-released https://coq.inria.fr/opam/released\n# RUN opam pin add -y coq 8.11.0\n# ['opam', 'repo', '--all-switches', 'add', '--set-default', 'coq-released', 'https://coq.inria.fr/opam/released']\nRUN opam repo --all-switches add --set-default coq-released https://coq.inria.fr/opam/released\nRUN opam update --all\nRUN opam pin add -y coq 8.11.0\n\n#RUN opam install -y --switch ocaml-variants.4.07.1+flambda_coq-serapi_coq-serapi_8.11.0+0.11.1 coq-serapi 8.11.0+0.11.1\nRUN opam install -y coq-serapi\n\nRUN eval $(opam env)\n\n# makes sure depedencies for pycoq are installed once already in the docker image\nENV WANDB_API_KEY=\"SECRET\"\nRUN pip install wandb --upgrade\n</code></pre>\n<aside class=\"onebox stackexchange\" data-onebox-src=\"https://stackoverflow.com/questions/73642527/how-to-install-wandb-on-a-docker-image-for-arm\">\n  <header class=\"source\">\n\n      <a href=\"https://stackoverflow.com/questions/73642527/how-to-install-wandb-on-a-docker-image-for-arm\" target=\"_blank\" rel=\"noopener nofollow ugc\">stackoverflow.com</a>\n  </header>\n\n  <article class=\"onebox-body\">\n      <a href=\"https://stackoverflow.com/users/1601580/charlie-parker\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n    <img alt=\"Charlie Parker\" src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/5e9c0a0caedbda92f5ad9bc087e52e143936f9f5.png\" class=\"thumbnail onebox-avatar\" width=\"256\" height=\"256\">\n  </a>\n\n<h4>\n  <a href=\"https://stackoverflow.com/questions/73642527/how-to-install-wandb-on-a-docker-image-for-arm\" target=\"_blank\" rel=\"noopener nofollow ugc\">How to install wandb on a docker image for arm?</a>\n</h4>\n\n<div class=\"tags\">\n  <strong>python, linux, docker, anaconda</strong>\n</div>\n\n<div class=\"date\">\n  asked by\n  \n  <a href=\"https://stackoverflow.com/users/1601580/charlie-parker\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n    Charlie Parker\n  </a>\n  on <a href=\"https://stackoverflow.com/questions/73642527/how-to-install-wandb-on-a-docker-image-for-arm\" target=\"_blank\" rel=\"noopener nofollow ugc\">12:07AM - 08 Sep 22 UTC</a>\n</div>\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-09T21:12:35.448Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/brando\">@brando</a> , thank-you for writing in. There are several errors that appear, but primarily the <code>exit code 1</code> could be attributed to you building the container using the base image cached layers. As a preliminary step, can you please try to build the container again and use the command <code>--no-cache</code> when doing so. Please let me know what results from this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-16T05:19:31.238Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/brando\">@brando</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-15T05:20:19.823Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Running wandb server behind a jupyterhub proxy",
		"Question_link": "https://community.wandb.ai/t/running-wandb-server-behind-a-jupyterhub-proxy/2930",
		"Question_created_time": "2022-08-15T00:54:18.007Z",
		"Question_answer_count": 13,
		"Question_score_count": 0,
		"Question_view_count": 240,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>i\u2019m trying to proxy the wandb \u201clocal\u201d server that runs under docker behind jupyterhub. (Playing with an on-prem install to do labs in the new full stack-dl course). Jupyterhub has a proxy server which lets one obtain an app at an arbitrary port show up at a given url.  The wandb server wants a particular url, but to be behind jupyterhub i need the base url for the wandb server to be something like <a href=\"http://hostname/hub/user-redirect/proxy/8080\" rel=\"noopener nofollow ugc\">http://hostname/hub/user-redirect/proxy/8080</a>. Is it possible to set a base url as an option in the docker container/arguments to the local web server in the container there?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-17T19:38:35.091Z",
				"Answer_body": "<p>Hi Rahul!</p>\n<p>You can set a port on wandb local as <code>wandb local start --port PORT</code> in order to set a port for your local instance. Does that fulfill your usecase?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-23T04:56:48.724Z",
				"Answer_body": "<p>Hi Rahul,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-26T18:10:34.242Z",
				"Answer_body": "<p>Hi Rahul, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-30T13:06:16.160Z",
				"Answer_body": "<p>I actually do this\u2026the problem is not in the port. I can even get to the port but the html wont form. This is because the wandb server hardcodes (i think) the URLS in the docker server. So I was wondering if there was a variable such as <code>baseurl</code> that i can supply to the container (possibly rebuilding it) which will let me provide a prefix-url to the wandb server.  Now whatever leading string the jupyterhub proxy provides in the URL can be incorporated</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-01T17:00:22.700Z",
				"Answer_body": "<p>Hi Ramit,</p>\n<p>Any thoughts? Where I am trying to get this to work (a healthcare company) has strict data egress restrictions, and proxying through jupyterhub rather than exposing the port is what we need. Basically i need a way to change the base URL on the wandb server of this is at all possible\u2026</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-01T21:27:22.416Z",
				"Answer_body": "<p>Not sure exactly what your issue is, but I had a similar issue when I was testing out self-hosting. I was using a SOCKS proxy and while I could connect to the server I couldn\u2019t login as I kept getting stuck in a retry loop. What did work for me was using SSH port forwarding, but I ended up not self hosting in the end, so I never found a proper solution.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-02T14:54:23.565Z",
				"Answer_body": "<p>Its worse for me, the CSS and JS wont load. The wandb server is expecting a particular URL, but because jupyter-server-proxy adds a <a href=\"https://jupyterhubhost/user/proxy/PORTNUM/\" rel=\"noopener nofollow ugc\">https://jupyterhubhost/user/proxy/PORTNUM/</a> to the beginning of the URLS, and wandb server expects an absolute url (i think) nothing is properly visible\u2026</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-02T17:57:24.239Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/rahuldave\">@rahuldave</a>,</p>\n<p>Apologies about the delay here, you would want to start your server like this in that case:</p>\n<pre><code class=\"lang-auto\">wandb server start --env HOST=&lt;HOST&gt;:&lt;PORT&gt;\n</code></pre>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-06T00:25:01.695Z",
				"Answer_body": "<p>Not sure I made my use case clear: i am not trying to start wandb server at a particular port. That proxying is taken care of by jupyterhub. What i am trying to do iis to have the base URL of the server something like: \u201c<a href=\"https://jupyterhubhost/user/proxy/PORTNUM/\" rel=\"noopener nofollow ugc\">https://jupyterhubhost/user/proxy/PORTNUM/</a>\u201d because thats what jupyter gives me. The internal linlks in wandb server are expecting the top level to be \u201c/js\u201d or \u201c/css\u201d for example, but i am stuck with the base url of the form \u201c/user/proxy/PORTNUM/\u201d so that the css url for example is \u201c/user/proxy/PORTNUM/css\u201d</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-15T20:54:26.454Z",
				"Answer_body": "<p>Hey Rahul,</p>\n<p>The HOST I specified on the previous comment is the base URL for the server. Is there any errors/odd behaviour you see in particular when running this command? It would be great if you could share a few screenshots / a screen recording so that we can understand what\u2019s happening on your machine.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-21T09:34:31.493Z",
				"Answer_body": "<p>Hi Rahul,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-26T19:43:43.145Z",
				"Answer_body": "<p>Hi Rahul, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-14T20:55:14.384Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Force Bayesian sweep to run certain variable tests",
		"Question_link": "https://community.wandb.ai/t/force-bayesian-sweep-to-run-certain-variable-tests/3098",
		"Question_created_time": "2022-09-12T08:09:38.525Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 130,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi!<br>\nI want to run a bayesian HP sweep with 5-fold CV. In other words I want the bayesian sweep to decide upon a configuration, run 5 runs with that configuration and log each run. The easiest way to do this would be to have a variable in the sweep, called e.g. fold_id which simply can take the values 1,2,3,4,5 and force the agent to always test all the fold_ids per configuration.</p>\n<p>Is there any way to make this possible? I.e force the sweep agent to always test a variable, even though running a bayesian sweep. In a way it would be like running a grid sweep over a bayesian sweep.</p>\n<p>One way I\u2019ve thought of is by making all parameters nested inside the fold_id variable but it still won\u2019t probably do what I\u2019m after.</p>\n<p>I\u2019ve seen the k-fold CV example code, but it\u2019s quite advanced and does not seem to work when running on CUDA and my understanding of multiprocessing is limited.</p>\n<p>Thank you!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-12T08:13:20.687Z",
				"Answer_body": "<p>Another way I\u2019ve though of is the following:</p>\n<p>Use this pseudo trainer function (called by wandb.agent):</p>\n<pre><code class=\"lang-auto\">def trainer(config=None):\n    # Initialize a new run with the sweep configuration\n    wandb.init(config=config)\n\n# Store the config parameters\n    sweepconfig = wandb.config\n\n# Load the raw data and split into k-folds\n    data = pd.read_csv(...)\n    folds = Make_KFolds().Split(...)\n\n# Store the sweep run's name\n    name = wandb.run.name\n    \n    sweep_metric = []\n    for fold_id in range(1,  k_folds+1, 1):\n        # init new run to store performance of this fold\n        wandb.init(config=sweepconfig, name=f\"{name+'-'+str(fold_id)}\", group=name)\n        wandb.config.update({'fold_id': fold_id})\n        # Run the training function which logs metrics to the fold's run\n        metric = RunTrainingEpochs(...)\n        sweep_metric.append(metric)\n\n\n# Exit loop, resume the sweep run and log the avg sweep metric as the average performance\n    wandb.init(config=sweepconfig, name = name, resume=True)\n    wandb.log({'Avg metric': sum(sweep_metric)/ k_folds})\n</code></pre>\n<p>But this does not work. In my opinion this should basically do the same as the kfold-CV example code. The sweep agent seems to be limited to one run per trainer call. Even though it initializes new runs, the previous run is continuously overwritten by the next wandb.init call.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-15T16:51:08.921Z",
				"Answer_body": "<p>You can create a nested sweep where each fold could be a list and then you can then iterate over those values.  Make sure that the run name changes per run so that way the runs don\u2019t overwrite one another.</p>\n<p>Here\u2019s an example config of a nested sweep:</p>\n<pre><code class=\"lang-auto\">command:\n  - ${env}\n  - python3\n  - ${program}\n  - ${args}\nmethod: random\nparameters:\n  MULTI_STAGE_TRAINING:\n    value:\n      DEPTH_SCALE:\n        - 100\n        - 100\n      HEAD:\n        - OBJECT_DETECTION\n      NETWORK:\n        - net_a\n        - net_b\n        - net_c\n      NUM_EPOCHS_IN_EACH_STAGE:\n        - 0\n        - 1\n        - 2\n        - 3\n      NUM_STAGES:\n        - 0\n        - 1\n        - 2\n        - 3\n        - 4\n        - 5\n        - 6\n        - 7\n        - 8\n        - 9\n      OPTIMIZER_PARAMS_PER_STAGE:\n        lr:\n          - 0\n          - 1\n          - 2\n          - 3\n          - 4\n          - 5\n          - 6\n          - 7\n          - 8\n          - 9\n        momentum:\n          - 0\n          - 1\n          - 2\n          - 3\n          - 4\n          - 5\n          - 6\n          - 7\n          - 8\n          - 9\n        weight_decay:\n          - 0\n          - 1\n          - 2\n          - 3\n          - 4\n          - 5\n          - 6\n          - 7\n          - 8\n          - 9\n  epochs:\n    value: 10\nprogram: script.py\n</code></pre>\n<p>And here\u2019s a script that is able to run it:</p>\n<pre><code class=\"lang-auto\">import wandb\n\u200b\ndef create_sweep(\n    sweep_config:dict,\n    update:bool,\n    project:str,\n    entity:str):\n    \n    parameters_dict = {'MULTI_STAGE_TRAINING':\n                   {'value':\n                    {'NUM_STAGES':list(range(10)),\n                     'OPTIMIZER_PARAMS_PER_STAGE':\n                     {'lr':list(range(10)),'momentum': list(range(10)),'weight_decay':list(range(10))},\n                     'NUM_EPOCHS_IN_EACH_STAGE':list(range(4)),\n                     'NETWORK':['net_a','net_b','net_c'],\n                     'HEAD':['OBJECT_DETECTION'],\n                     'DEPTH_SCALE': [100,100]\n                     }\n                    }\n                   }\n    sweep_config['parameters'] = parameters_dict\n    \n    parameters_dict.update({\n    'epochs': {\n        'value': 10}\n    })\n    return wandb.sweep(sweep_config,entity=entity,project=project)\n\u200b\nif __name__ == '__main__':\n\u200b\n    SWEEP_CONFIG = {\n    'method': 'random',\n    'program':'script.py',\n    'command':['${env}', 'python3', '${program}','${args}']\n    }\n    ENTITY = 'demonstrations'\n    PROJECT = 'sweep_gm'\n    UPDATE = True\n\u200b\n    sweep = create_sweep(\n        sweep_config=SWEEP_CONFIG,\n        entity=ENTITY,\n        project=PROJECT,\n        update=UPDATE)\n</code></pre>\n<p>Let me know if you need any further help with this!</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-09-20T19:28:47.638Z",
				"Answer_body": "<p>Do you need any help here still?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-26T15:11:44.764Z",
				"Answer_body": "<p>Hi Styrbj\u00f6rn, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-14T16:52:02.624Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Parallel coordinate plot doesn't work with nested groupings",
		"Question_link": "https://community.wandb.ai/t/parallel-coordinate-plot-doesnt-work-with-nested-groupings/3102",
		"Question_created_time": "2022-09-13T08:51:19.631Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 123,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi!</p>\n<p>I have tried to use a parallel coordinate plot with a nested group, and it only shows the top-level group, whereas line plots correctly show multiple level groups. See screenshot below for example\u2014there are 3 lines on the parallel coordinates, but 6 on the line plot. Is this correct behaviour?</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/ae3ada7ecf86fcbad869ea1404ea0ac792733cda.png\" data-download-href=\"/uploads/short-url/oRjaIBHNsSCjMDTUurlQOHfluci.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ae3ada7ecf86fcbad869ea1404ea0ac792733cda_2_503x500.png\" alt=\"image\" data-base62-sha1=\"oRjaIBHNsSCjMDTUurlQOHfluci\" width=\"503\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ae3ada7ecf86fcbad869ea1404ea0ac792733cda_2_503x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ae3ada7ecf86fcbad869ea1404ea0ac792733cda_2_754x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ae3ada7ecf86fcbad869ea1404ea0ac792733cda_2_1006x1000.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ae3ada7ecf86fcbad869ea1404ea0ac792733cda_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1042\u00d71034 127 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-14T20:39:57.043Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/olipinski\">@olipinski</a>!</p>\n<p>Thank you for reaching out to us. This is a known issue which is planned to be resolved in the future, I\u2019ll keep you posted with updates on this as movement is made!</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-15T10:18:45.814Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a> !</p>\n<p>Thanks for your quick reply! I will keep a lookout for when it\u2019s fixed.</p>\n<p>Thanks,<br>\nOlaf</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-14T10:19:22.767Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to do \"Pnael Export\", I found no button of it",
		"Question_link": "https://community.wandb.ai/t/how-to-do-pnael-export-i-found-no-button-of-it/2991",
		"Question_created_time": "2022-08-25T04:13:05.513Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 190,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I want to export all log from cloud like this \" <a href=\"https://wandb.ai/site/articles/export-data-from-wb\">Export Your Data from W&amp;B on Weights &amp; Biases (wandb.ai)</a>\". However, there  is no option for \u201cPanel Export\u201d now. How should I do?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-26T23:51:13.905Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/wu-dongdong\">@wu-dongdong</a> , the export panel option is still present for all panels in the UI, see below image. Can you provide a screen shot from your end of what you are seeing?</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/78a5f63d64761a0cac73d40531e5aaf007535fd4.png\" alt=\"ExportPanel\" data-base62-sha1=\"hdiRP5BfhYQDZvOBDSBtYOJ3Ehu\" width=\"545\" height=\"359\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-01T22:30:13.448Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/wu-dongdong\">@wu-dongdong</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-09T16:31:07.224Z",
				"Answer_body": "<p>Oh Thanks for you!@ mohammadbakir.  My question is how to export data of multi runs in a table. Like the second picture of that link. However, in my test, it only export the mean,  maximum and minimum value of all runs(refer the last three columns of the following picture)<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d1696624d41951b1cb8f06734e58ae4a8c90a4c1.png\" data-download-href=\"/uploads/short-url/tSxBFLka2X67A5GGYFdA5rgFQGJ.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d1696624d41951b1cb8f06734e58ae4a8c90a4c1_2_690x487.png\" alt=\"image\" data-base62-sha1=\"tSxBFLka2X67A5GGYFdA5rgFQGJ\" width=\"690\" height=\"487\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d1696624d41951b1cb8f06734e58ae4a8c90a4c1_2_690x487.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d1696624d41951b1cb8f06734e58ae4a8c90a4c1_2_1035x730.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d1696624d41951b1cb8f06734e58ae4a8c90a4c1_2_1380x974.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d1696624d41951b1cb8f06734e58ae4a8c90a4c1_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1467\u00d71036 94.5 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-09T16:34:07.771Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a>  Hi, I want to export the data of all runs (not mean value\u2026), then how should I do? thanks for your reply.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d03535d9d7e5b47c0e85b664b677484545d5c453.png\" data-download-href=\"/uploads/short-url/tHTjCG6lYP5XAgqlUl9ytWDPaX9.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d03535d9d7e5b47c0e85b664b677484545d5c453_2_690x211.png\" alt=\"image\" data-base62-sha1=\"tHTjCG6lYP5XAgqlUl9ytWDPaX9\" width=\"690\" height=\"211\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d03535d9d7e5b47c0e85b664b677484545d5c453_2_690x211.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d03535d9d7e5b47c0e85b664b677484545d5c453_2_1035x316.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d03535d9d7e5b47c0e85b664b677484545d5c453_2_1380x422.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d03535d9d7e5b47c0e85b664b677484545d5c453_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">2477\u00d7758 126 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-14T23:19:10.908Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/wu-dongdong\">@wu-dongdong</a> , one way to do this is by hiding all the columns you don\u2019t want to export to a CSV. To hide the columns select the <code>Columns</code> option menu in the top right of the screen. Once ready, select the <code>bottom arrow</code> option, also in the top right of the screen, and select <code>CSV Export</code>. Alternatively you can also do this via the API, see more <a href=\"https://docs.wandb.ai/guides/track/public-api-guide\">here</a> for exporting data.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-13T23:20:01.530Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Getting `AttributeError : 'NoneType' object has no attribute '_log' `when trying to run test set",
		"Question_link": "https://community.wandb.ai/t/getting-attributeerror-nonetype-object-has-no-attribute-log-when-trying-to-run-test-set/3090",
		"Question_created_time": "2022-09-09T17:52:20.278Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 1170,
		"Question_has_accepted_answer": true,
		"Question_body": "<p><strong>Framework: Pytorch</strong><br>\n<strong>wandb version : 0.13.3</strong><br>\n<strong>workspace: Google colab</strong></p>\n<pre><code class=\"lang-python\">config = dict(\n    dropout = 0.4,\n    train_batch = 3,\n    val_batch = 1,\n    test_batch = 1,\n    learning_rate = 0.001,\n    epochs = 5,\n    architecture = \"CNN\",\n    model_name = \"efficientnet-b0\",\n    infra = \"Colab\",\n    dataset=\"dysphagia_dataset2\"\n    )\n\n</code></pre>\n<p>My test function</p>\n<pre><code class=\"lang-auto\">def test_model():\n    running_correct = 0.0\n    running_total = 0.0\n    true_labels = []\n    pred_labels = []\n    with torch.no_grad():\n        for data in dataloaders[TEST]:\n            inputs, labels = data\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            true_labels.append(labels.item())\n            outputs = model_ft(inputs)\n            _, preds = torch.max(outputs.data, 1)\n            pred_labels.append(preds.item())\n            running_total += labels.size(0)\n            running_correct += (preds == labels).sum().item()\n        acc = running_correct/running_total\n    return (true_labels, pred_labels, running_correct, running_total, acc)\n\n\ntrue_labels, pred_labels, running_correct, running_total, acc = test_model()\n\n</code></pre>\n<p><strong>Error</strong></p>\n<pre><code class=\"lang-bash\">AttributeError                            Traceback (most recent call last)\n\n&lt;ipython-input-26-b7dbeaddcbbb&gt; in &lt;module&gt;\n----&gt; 1 true_labels, pred_labels, running_correct, running_total, acc = test_model()\n      2 \n\n4 frames\n\n/usr/local/lib/python3.7/dist-packages/wandb/wandb_torch.py in log_tensor_stats(self, tensor, name)\n    254             bins = torch.Tensor(bins_np)\n    255 \n--&gt; 256         wandb.run._log(\n    257             {name: wandb.Histogram(np_histogram=(tensor.tolist(), bins.tolist()))},\n    258             commit=False,\n\nAttributeError: 'NoneType' object has no attribute '_log'\n</code></pre>\n<p>This is how i initialize training:</p>\n<pre><code class=\"lang-python\">model_ft = train_model(model_ft, \n                       criterion, \n                       optimizer_ft,\n                       config\n                       )\n</code></pre>\n<p>my wandb init:</p>\n<pre><code class=\"lang-python\">wandb.init(config=config,\n           name='efficientnet0+albumentions',\n           group='pytorch-efficientnet-baseline', \n           project='dysphagia_image_classification',\n           job_type='train')\nconfig = wandb.config\n\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-09T19:44:50.228Z",
				"Answer_body": "<p>Finally caught my mistake <img src=\"https://emoji.discourse-cdn.com/twitter/slightly_smiling_face.png?v=12\" title=\":slightly_smiling_face:\" class=\"emoji\" alt=\":slightly_smiling_face:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<pre><code class=\"lang-auto\">model_ft._fc = nn.Sequential(\n    nn.BatchNorm1d(num_features=num_ftrs),    \n    nn.Linear(num_ftrs, 512),\n    nn.ReLU(),\n    nn.BatchNorm1d(512),\n    nn.Linear(512, 128),\n    nn.ReLU(),\n    nn.BatchNorm1d(num_features=128),\n    nn.Dropout(p=config.dropout), # Error due to this\n    nn.Linear(128, 2),\n    )\n\nmodel_ft = model_ft.to(device)\n\n</code></pre>\n<p>I was calling my test function outside of  wandb(only used wandb for training)and wandb must have call <code>.finish</code> so, it must have set the my config dict:-&gt; None  as I was passing it to wandb.config.</p>\n<p>Now , my model class use one of the config (dropout) but I passed my config file into wandb config so, it set it to None after my model finish training. So, when my def test function use my model, the dropout hyparameter value is None now!</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-09-13T20:32:39.410Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/vishu\">@vishu</a> , thank-you for letting us know that you successfully resolved your issue.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-12T20:32:50.429Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Invited to org, the login is broken",
		"Question_link": "https://community.wandb.ai/t/invited-to-org-the-login-is-broken/3070",
		"Question_created_time": "2022-09-05T13:43:12.872Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 74,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I was invited to an org, logged in and when I try to accept the invite I receive a page saying:</p>\n<p>\"XXX is an invite-only team.</p>\n<p>Received an invite but still can\u2019t see the team? Make sure you are logged in with the email where you received the invite.\"</p>\n<p>the thing is I am logged in with the mail I was invited by, suggestions?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-08T00:04:30.384Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/orian\">@orian</a> , it shows on my end you are currently a member of the harmonai team. Have you been able to successfully access the team?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-13T20:08:04.557Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/orian\">@orian</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-12T20:08:42.591Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Interprete gradient graphs",
		"Question_link": "https://community.wandb.ai/t/interprete-gradient-graphs/3052",
		"Question_created_time": "2022-09-02T13:25:01.171Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 305,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi everyone,<br>\nAttached is the gradient histograms of my training. It seems that the gradient for lin1.weight and line2.weight are mostly zero everywhere.  Does it mean that the model doesn\u2019t learn anything from these parameters and should I exclude them my optimizer?</p>\n<p>Thank you very much<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d4407acdc05fd1bbf26d360e1cc8c98ee256e367.png\" data-download-href=\"/uploads/short-url/uhFmZAeJe0w8aS6Cbez7CQKl5j1.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d4407acdc05fd1bbf26d360e1cc8c98ee256e367_2_690x238.png\" alt=\"image\" data-base62-sha1=\"uhFmZAeJe0w8aS6Cbez7CQKl5j1\" width=\"690\" height=\"238\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d4407acdc05fd1bbf26d360e1cc8c98ee256e367_2_690x238.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d4407acdc05fd1bbf26d360e1cc8c98ee256e367_2_1035x357.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d4407acdc05fd1bbf26d360e1cc8c98ee256e367_2_1380x476.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d4407acdc05fd1bbf26d360e1cc8c98ee256e367_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1808\u00d7624 111 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-07T20:41:05.455Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thongnt\">@thongnt</a> , it\u2019s difficult to say why your gradients are zeroed out. Assuming it\u2019s not an error in your code, you may be encountering a vanishing gradient which could be leading to overflow / underflow issues. Here are some debugging steps I can suggest. 1) ensure the that you\u2019re calling <code>optimizer.zero_grad()</code> before each batch 2). try normalizing the weights and inputs 3). Try implementing gradient clipping. Please let me know if any of these work for you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-12T23:12:34.255Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thongnt\">@thongnt</a> ,  since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-11T23:12:37.911Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to reenable automatic synchronisation",
		"Question_link": "https://community.wandb.ai/t/how-to-reenable-automatic-synchronisation/3061",
		"Question_created_time": "2022-09-04T01:29:31.968Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 155,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I made a change to my script and now I have to manually synchronise my runs, my script contains</p>\n<pre><code>if args.dry_run:\n    os.environ['WANDB_MODE'] = 'dryrun'\n\nwandb.init(project=args.project_name, notes=args.notes)\n\n# log all experimental args to wandb\nwandb.config.update(args)\n</code></pre>\n<p>The change I made was the first line, setting <code>WANDB_MODE=dryrun</code>. From that point on I cannot re-enable automatic synchronisation.</p>\n<p>I\u2019ve run <code>wandb online</code> and run my script with <code>dryrun=False</code>. I also realised that this doesn\u2019t unset WANDB_MODE so I tried setting it to \u2018online\u2019 when <code>dryrun==False</code>. But it always ends up logging to <code>wandb/offline-run-*</code> and I have to manually sync it.</p>\n<p>Is there another step to re-enable sync\u2019ing?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-05T04:26:38.381Z",
				"Answer_body": "<p>I fixed the original problem, I had a bug in my argument parser that meant that dry_run was always true.</p>\n<p>However I still cannot get all my metrics synchronised. I\u2019m using the Huggingface trainer, the trainer first trains the models and logs the training metrics, then performed a separate evaluation step.</p>\n<p>When I look at the local <code>wandb-summary.json</code> it contains all the metrics, including <code>eval/loss</code> but none of the evaluation metrics are available on the cloud.</p>\n<p>Also if I look at <code>files/output.log</code> it\u2019s different to the cloud version - it\u2019s complete and the cloud version is truncated part way through the evaluation.</p>\n<p>But if I run <code>wandb sync --sync-all</code> it says \u201cnothing to sync\u201d, despite there being a clear difference - it seems to think the run has already ended too early. Perhaps there\u2019s a bug in the Huggingface integration that causes it to mark the run complete after training but before evaluation?</p>\n<p>For example this is the log on the cloud</p>\n<pre><code class=\"lang-auto\">09/05/2022 14:01:29 - INFO - __main__ -   *** Evaluate ***\n***** Running Evaluation *****\n  Num examples = 3820356\n  Batch size = 1024\n\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 3665/3731 [11:10&lt;00:13,  4.92it/s]\n</code></pre>\n<p>Compared to the local version</p>\n<pre><code class=\"lang-auto\">100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 3728/3731 [11:23&lt;00:00,  5.47it/s]\n***** eval metrics *****\n  epoch                   =        1.0\n  eval_loss               =     4.4664\n  eval_runtime            = 0:11:23.99\n  eval_samples            =    3820356\n  eval_samples_per_second =   5585.376\n  eval_steps_per_second   =      5.455\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3731/3731 [11:23&lt;00:00,  5.46it/s]\n09/05/2022 14:12:54 - INFO - __main__ -   *** Train Finished ***\n</code></pre>\n<p>Yet</p>\n<pre><code class=\"lang-auto\">$ wandb sync --sync-all\nwandb: ERROR Nothing to sync.\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-05T05:21:29.729Z",
				"Answer_body": "<p>I\u2019ve found a way around this - I\u2019m not really sure why it\u2019s happening but I noticed that the huggingface trainer logs the metrics at the end of training as follows:</p>\n<pre><code>                if not args.load_best_model_at_end\n                else {\n                    f\"eval/{args.metric_for_best_model}\": state.best_metric,\n                    \"train/total_floss\": state.total_flos,\n                }\n</code></pre>\n<p>Meaning it logs the validation loss, but only if you train with <code>load_best_model_at_end=True</code> and set <code>save_strategy==evaluation_strategy</code> (epoch or steps) and <code>save_steps=eval_steps</code>.</p>\n<p>Doing this means I didn\u2019t need to perform the separate eval step since it\u2019s already logged the evaluation loss from the best model during training.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-09-09T08:57:04.890Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/david-waterworth\">@david-waterworth</a> thank you for reporting this. Has this been now resolved for you with the arguments you mentioned at your last message? Regarding the initial post, it seems that the <code>dryrun</code> mode was due to your argument parser. Does this mean you are now running in <code>online</code> mode? that would explain why the syncing with <code>--sync-all</code> would output the message <code>nothing to sync</code>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-09T23:27:01.416Z",
				"Answer_body": "<p>Hi, yes it\u2019s working now thanks.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-12T08:49:27.147Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/david-waterworth\">@david-waterworth</a> thank you for confirming this, and glad the issue is now resolved for you! I will close the ticket for now, but please feel free to re-open the ticket by posting here any further questions related to this issue and we will be happy to keep investigating.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-11T08:49:36.762Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to keep only last checkpoint artifact?",
		"Question_link": "https://community.wandb.ai/t/how-to-keep-only-last-checkpoint-artifact/3014",
		"Question_created_time": "2022-08-27T08:35:42.720Z",
		"Question_answer_count": 6,
		"Question_score_count": 1,
		"Question_view_count": 691,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>How do I keep only the last checkpoint artifact in wandb?</p>\n<p>I am using lightning\u2019s ModelCheckpoint to periodically save my checkpoint artifact to wandb. However, these artifacts are really large. If I keep multiple checkpoint artifact versions on wandb, they get big really quickly.</p>\n<p>However, I can\u2019t just checkpoint at the end of training. My GPUs occasionally terminate, so I need to checkpoint periodically.</p>\n<p>How do I make sure that only the last checkpoint artifact is kept on wandb?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-28T12:52:44.241Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/turian\">@turian</a>,<br>\nYou need to define a custom checkpoint callback which is straightforward:</p>\n<pre><code class=\"lang-auto\">from pytorch_lightning.loggers import WandbLogger\nfrom pytorch_lightning.callbacks import ModelCheckpoint\n\n# define WANDB logger\nwandb_logger = WandbLogger(log_model=\"all\")\n\n# define pytorch lightning checkpoint callback\ncheckpoint_callback = ModelCheckpoint(every_n_epochs=1)\n\n# define trainer\ntrainer = Trainer(logger=wandb_logger, callbacks=[checkpoint_callback])\n</code></pre>\n<p>In this example, the checkpoint will be saved at the end of each epoch, but you can set whatever value you want. And if you want to save the checkpoints based on steps or time, you just need to set <code>every_n_train_steps</code> or <code>train_time_interval</code>, respectively.</p>\n<p>If you\u2019re looking for more specific information, I highly recommend you to check out the official docs:</p>\n<ul>\n<li><a href=\"https://pytorch-lightning.readthedocs.io/en/stable/extensions/generated/pytorch_lightning.loggers.WandbLogger.html\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">WandbLogger \u2014 PyTorch Lightning 1.7.3 documentation</a></li>\n<li><a href=\"https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.callbacks.ModelCheckpoint.html#pytorch_lightning.callbacks.ModelCheckpoint\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">ModelCheckpoint \u2014 PyTorch Lightning 1.7.3 documentation</a></li>\n</ul>\n<p>Hope it does help you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-29T09:17:06.588Z",
				"Answer_body": "<p>Also, if you want to delete artifacts after training, you can use the <code>wandb.Api</code>.</p>\n<pre><code class=\"lang-auto\">import wandb\n\n\"\"\"\ndeletes all models that do not have a tag attached\n\nby default this means wandb will delete all but the \"latest\" or \"best\" models\n\nset dry_run == False to delete...\n\"\"\"\nproject_name='demo-project'\nentity='_scott'\ndry_run = True\napi = wandb.Api(overrides={\"project\": project_name, \"entity\": entity})\nproject = api.project(project_name)\nfor artifact_type in project.artifacts_types():\n    for artifact_collection in artifact_type.collections():\n        for version in api.artifact_versions(artifact_type.type, artifact_collection.name):\n            if artifact_type.type == 'model':\n                if len(version.aliases) &gt; 0:\n                    # print out the name of the one we are keeping\n                    print(f'KEEPING {version.name}')\n                else:\n                    print(f'DELETING {version.name}')\n                    if not dry_run:\n                        version.delete()\n</code></pre>\n<p>Source for this snippet:</p><aside class=\"quote quote-modified\" data-post=\"1\" data-topic=\"1498\">\n  <div class=\"title\">\n    <div class=\"quote-controls\"></div>\n    <img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/d/d2c977/40.png\" class=\"avatar\">\n    <a href=\"https://community.wandb.ai/t/using-the-python-api-to-delete-models-with-no-tag-minimal/1498\">Using the python API to delete models with no tag (minimal)</a> <a class=\"badge-wrapper  bullet\" href=\"/c/show-the-community/43\"><span class=\"badge-category-bg\" style=\"background-color: #92278F;\"></span><span style=\"\" data-drop-close=\"true\" class=\"badge-category clear-badge\" title=\"Share what you\u2019ve built on top of W&amp;B! This is the place to share your latest open source project, blog post/public W&amp;B Report, research paper, wandb code snippet, tutorial or any other project that uses W&amp;B.\">Show the Community!</span></a>\n  </div>\n  <blockquote>\n    Hey all, \nHere\u2019s a minimal example of how to delete models that have no tag. \nThis is useful when you blow your data limit by saving too many intermediate checkpoints during training. \nIf you improve this script, post your improvements to this thread for the benefit of all. \nPeace \nDuane \nimport wandb\n\n\"\"\"\ndeletes all models that do not have a tag attached\n\nby default this means wandb will delete all but the \"latest\" or \"best\" models\n\nset dry_run == False to delete...\n\"\"\"\n\ndry_run = True\napi = w\u2026\n  </blockquote>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-31T09:15:10.969Z",
				"Answer_body": "<p>Hi Joseph, thanks for your question! Would the solutions proposed by Matteo and Scott work for you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-06T10:27:00.716Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-10T09:12:07.264Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/_scott\">@_scott</a> thanks for the code. As I mentioned <a href=\"https://community.wandb.ai/t/using-the-python-api-to-delete-models-with-no-tag-minimal/1498\">here</a>, this doesn\u2019t appear to delete the artifacts any more, even with dry run disabled.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-09T09:12:59.790Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Showing total loss in distributed computing",
		"Question_link": "https://community.wandb.ai/t/showing-total-loss-in-distributed-computing/2923",
		"Question_created_time": "2022-08-13T22:40:05.468Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 411,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>I am trying to use wandb to monitor my loss functions and I am running my code on multiple GPU nodes. When logging my loss function I can see 4 different links for each node. However, I would like to see the total loss and have one process reporting that through wandb. How should I take care of this?</p>\n<p>I would appreciate any feedback as I am totally new to this community,<br>\nThanks,</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-17T20:14:15.297Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mkhoshle\">@mkhoshle</a> welcome to W&amp;B community!</p>\n<p>Is it one experiment distributed in 4 GPUs or are you running 4 different experiments? Which framework are you using? Any code snippet or link to the workspace would help to further investigate this issue.</p>\n<p>Would <a href=\"https://github.com/wandb/examples/tree/master/examples/pytorch/pytorch-ddp#method-1-log-from-a-single-process\" rel=\"noopener nofollow ugc\">this</a> example with PyTorch DDP fit your case?  You may also find useful our reference docs <a href=\"https://docs.wandb.ai/guides/track/advanced/distributed-training\">here</a> about distributed training.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-17T20:48:32.726Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thanos-wandb\">@thanos-wandb</a> ,</p>\n<p>Yes, I am running my experiment using multiple GPUs (e.g. 4 GPUs) and yes PyTorch DistributedDataParallel is my case. I just need some information regarding when I should log on all processes and when I should log using only one process.  Which would be more useful and provide more insight?</p>\n<p>Thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-29T19:04:56.686Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mkhoshle\">@mkhoshle</a> , this <a href=\"https://docs.wandb.ai/guides/track/advanced/distributed-training#logging-distributed-training-experiments-with-w-and-b\">document</a> may be helpful, listing two methods recommend by W&amp;B for multiprocessing logging. Method 1, logging through the <code>rank0</code> process would work for you case of only wanting to log a single value from a single process.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-01T22:12:25.083Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mkhoshle\">@mkhoshle</a> , do you still need assistance with W&amp;B multiprocessing?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-09T23:55:16.466Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mkhoshle\">@mkhoshle</a> ,  since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-08T23:55:19.392Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Plot overlay obscures most of plot",
		"Question_link": "https://community.wandb.ai/t/plot-overlay-obscures-most-of-plot/3044",
		"Question_created_time": "2022-09-01T04:34:45.138Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 79,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>See screenshot, when I mouse over the plot showing the value of a metric across multiple runs, the acutal shape of the plot is obscured by the detail view almost all of the time. This makes it almost impossible to visually compare runs while also seeing precise values at certain points.</p>\n<p>Additionally, assuming this gets fixed by moving the detail view to the lower-right portion of the plot (or even outside the bounds of the plot entirely), it would be really nice to see a horizontal guide in addition to a vertical guide, so I can visually tell  how the peaks of a given run compare to the peaks of other runs a different points in time (I\u2019m using <code>tfa.optimizers.CyclicalLearningRate</code> so my metrics have a rather spiky nature).</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/2590f8667fb82a696da92b44e20ea000587efde7.png\" alt=\"Screen Shot 2022-09-01 at 2.24.01 pm\" data-base62-sha1=\"5mkgmk48PEjHXdWpVtiAwgVAwZN\" width=\"477\" height=\"277\"></p>\n<p>Screenshot showing spiky nature of metric plot:<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/f72adaf4477903b571813ced8457fdf9cdab5c34.png\" alt=\"Screen Shot 2022-09-01 at 2.31.11 pm\" data-base62-sha1=\"zgxKDAV5kmh1mT2P88Unv5CvThO\" width=\"422\" height=\"151\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-06T19:31:45.772Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tbirch\">@tbirch</a><br>\nThank-you for writing in with your observation. I understand how this leads to an obstruct run view on the individual charts. I passed along this feedback to our App team to review. In the meantime please view the chart in full screen mode which will grant visual access to your run results. Additionally, I have passed long the note on  adding a horizontal guide to make it easier to visually tell how the peaks of a given run compare to the peaks of other runs. Once an update is provided by the team I will let you know here.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-08T02:06:56.024Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a>, full screen mode helps but doesn\u2019t completely solve the problem, especially on mobile. The floating panel with the y-axis values still typically appears at the top of the screen, and with enough simultaneous runs showing, the overlay box will occlude a significant portion of the graph.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-07T02:07:39.458Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb login issue",
		"Question_link": "https://community.wandb.ai/t/wandb-login-issue/3023",
		"Question_created_time": "2022-08-29T11:52:50.926Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 1251,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, everytime I run my experiment in kubernetes, wandb is asking for options wandb:<br>\n(1) Create a W&amp;B account<br>\nwandb: (2) Use an existing W&amp;B account<br>\nwandb: (3) Don\u2019t visualize my results</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-29T15:32:38.978Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/vijaya\">@vijaya</a>, you should be able to <a href=\"https://docs.wandb.ai/guides/track/advanced/environment-variables\">environment</a> to set your API Key and host url when setting up your Kubernetes environment which will allow you to not have to login every time you start an experiment. Setting <code>WANDB_API_KEY</code> and <code>WANDB_BASE_URL</code> should help you get past this.</p>\n<p>Let me know if you have any other questions around this.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-29T15:33:06.855Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/vijaya\">@vijaya</a>, you should be able to environment to set your API Key and host url when setting up your Kubernetes environment which will allow you to not have to login every time you start an experiment. Setting <code>WANDB_API_KEY</code> and <code>WANDB_BASE_URL</code> should help you get past this.</p>\n<p>Let me know if you have any other questions around this.</p>\n<p>Thank you,<br>\nNate</p>\n<p>[Discourse post]</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-31T07:28:32.891Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sydholl\">@sydholl</a>,<br>\nThank you for your reply. Now I am getting a new error saying  \" mkdir(name, mode)<br>\nPermissionError: [Errno 13] Permission denied: \u2018/.config\u2019\" while I try to run wandb in a docker environment. Can you please help me resolve this issue.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-01T19:26:18.889Z",
				"Answer_body": "<p>HI <a class=\"mention\" href=\"/u/vijaya\">@vijaya</a>, this looks like your script does not have write access to \u2018/config\u2019. You can either resolve this by giving your script root access or you can change the folder that W&amp;B is trying to write to.</p>\n<p>The env variables WANDB_DIR, WANDB_CACHE_DIR, and WANDB_CONFIG_DIR should all be set to folders that you have permissions to write to.</p>\n<p>Let me know if this resolves the issue for you</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-06T19:41:42.433Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/vijaya\">@vijaya</a> I wanted to follow up and see if you were able to get this to work or if you still needed any help with this?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-05T19:42:25.311Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Code Comparer can only show the difference of main training file",
		"Question_link": "https://community.wandb.ai/t/code-comparer-can-only-show-the-difference-of-main-training-file/3020",
		"Question_created_time": "2022-08-29T11:36:01.165Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 153,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>If I call <code>wandb.run.log_code(\".\")</code>, all python source code files in the current directory are saved in W&amp;B cloud. That\u2019s what I want.</p>\n<p>However, only changes in main training file where I call <code>wandb.init()</code> can be shown in <a href=\"https://docs.wandb.ai/ref/app/features/panels/code#code-comparer\">Code Comparer</a>. The change in other file (like <code>helper_funcs.py</code>) will not appear in code panel. Do you have any suggestions about it?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-31T14:14:44.028Z",
				"Answer_body": "<p>Hi Yao, thanks for writing in! As you have said, you can\u2019t compare in the panel other files than the one where you call <code>wandb.init()</code>, but you can compare them in the artefacts tab. I send you a video on how to do this. Please let me know if this would work for you.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-09-01T01:50:19.127Z",
				"Answer_body": "<p>Thanks for your help. But I can\u2019t find the video in my email. Maybe it was blocked by the email system. Can you send it to my google email: <a href=\"mailto:tulifang1995@gmail.com\">tulifang1995@gmail.com</a>?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-01T16:21:40.994Z",
				"Answer_body": "<p>Hi Yao! I have already sent the video to your google email. Please let me know if you have received it and if this would work for you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-03T14:15:02.560Z",
				"Answer_body": "<p>Thanks! The video is really helpful! To make it easier for people with the same problem to find the answer, I\u2019ll briefly describe the method in the video:</p>\n<ol>\n<li>Open Artifacts page.</li>\n<li>Click files.</li>\n<li>Click \u2018compare\u2019 button here:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/872c08e8148763b60d65ddd40545095a3dfb6931.png\" data-download-href=\"/uploads/short-url/jhMNLfOCBCruw4no4loaD0uloVb.png?dl=1\" title=\"compare_code\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/872c08e8148763b60d65ddd40545095a3dfb6931_2_229x250.png\" alt=\"compare_code\" data-base62-sha1=\"jhMNLfOCBCruw4no4loaD0uloVb\" width=\"229\" height=\"250\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/872c08e8148763b60d65ddd40545095a3dfb6931_2_229x250.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/872c08e8148763b60d65ddd40545095a3dfb6931_2_343x375.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/872c08e8148763b60d65ddd40545095a3dfb6931_2_458x500.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/872c08e8148763b60d65ddd40545095a3dfb6931_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">compare_code</span><span class=\"informations\">746\u00d7812 50.5 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div>\n</li>\n</ol>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-06T15:17:24.192Z",
				"Answer_body": "<p>Hi Yao, thanks for your suggestion! Is there anything else I can help you with?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-11-02T14:15:53.356Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Feature Request: Embed only a table/report",
		"Question_link": "https://community.wandb.ai/t/feature-request-embed-only-a-table-report/3037",
		"Question_created_time": "2022-08-30T23:42:17.612Z",
		"Question_answer_count": 7,
		"Question_score_count": 1,
		"Question_view_count": 238,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I intend to do a series of blog posts which use W&amp;B reports like this one:</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://write.farook.org/stable-diffusion-parameter-variations/\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/31da22c8b3786e20cdf0326872a564cdf70efa6d.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https://write.farook.org/stable-diffusion-parameter-variations/\" target=\"_blank\" rel=\"noopener nofollow ugc\">write.farook.org</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/199;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e5563ba054b6d9637277a5f0369fed9909c580da_2_690x199.jpeg\" class=\"thumbnail\" width=\"690\" height=\"199\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e5563ba054b6d9637277a5f0369fed9909c580da_2_690x199.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e5563ba054b6d9637277a5f0369fed9909c580da_2_1035x298.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e5563ba054b6d9637277a5f0369fed9909c580da_2_1380x398.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e5563ba054b6d9637277a5f0369fed9909c580da_2_10x10.png\"></div>\n\n<h3><a href=\"https://write.farook.org/stable-diffusion-parameter-variations/\" target=\"_blank\" rel=\"noopener nofollow ugc\">Stable Diffusion Parameter Variations \u2013 Meandering Musings</a></h3>\n\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>As you\u2019ll notice, I have multiple reports in the blog post. The current embed with an IFRAME takes up way too much space because of the header and the footer where you can comment etc. I\u2019d prefer to have the ability to just embed a table (or preferably) the content section of a report.</p>\n<p>Does this ability currently exist? I checked the documentation but couldn\u2019t find anything like that.</p>\n<p>If the functionality does not exist, being able to do so in future would be a great help for me and probably for others too.</p>\n<p>I currently take screenshots of the relevant part of the report and then link to the full report on W&amp;B. But I hope you\u2019d agree that having the interactivity of the W&amp;B report in the post itself would be much more preferable <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-31T14:03:22.644Z",
				"Answer_body": "<p>Hi there,</p>\n<p>Thanks for wanting to share W&amp;B within your blog.<br>\nHere is how you can embed W&amp;B Reports as iFrames:</p>\n<blockquote>\n<p>Select the <strong>Share</strong> button on the upper right hand corner within a report. A modal window will appear. Within the modal window, select <strong>Copy embed code</strong> . The copied code will render within an Inline Frame (IFrame) HTML element. Paste the copied code into an iframe HTML element of your choice.</p>\n</blockquote>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/guides/reports/embed-reports\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/fc4afdec4db041ed1f06c087657ff8ae1e6b8d7c.png\" class=\"site-icon\" width=\"256\" height=\"256\">\n\n      <a href=\"https://docs.wandb.ai/guides/reports/embed-reports\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d964bbbc3da358de18b80af06dd499d89199a157_2_500x500.png\" class=\"thumbnail onebox-avatar\" width=\"500\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d964bbbc3da358de18b80af06dd499d89199a157_2_500x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d964bbbc3da358de18b80af06dd499d89199a157.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d964bbbc3da358de18b80af06dd499d89199a157.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d964bbbc3da358de18b80af06dd499d89199a157_2_10x10.png\">\n\n<h3><a href=\"https://docs.wandb.ai/guides/reports/embed-reports\" target=\"_blank\" rel=\"noopener\">Embed reports</a></h3>\n\n  <p>Embed Weights &amp; Biases reports directly into Notion or with an HTML IFrame element.</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-31T14:16:44.091Z",
				"Answer_body": "<p>Hi Scott,</p>\n<p>Thank you for the reply <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"> But you might have missed the relevant part in my question \u2026 namely, \u201cThe current embed with an IFRAME takes up way too much space because of the header and the footer where you can comment etc. I\u2019d prefer to have the ability to just embed a table (or preferably) the content section of a report.\u201d</p>\n<p>I have already looked at your documentation, searched the forums etc. I don\u2019t believe what I want is supported at the moment. Just checking in case I missed something obvious.</p>\n<p>Again, I do know I can use the \u201cShare\u201d feature but that embeds everything including the report title and the comment area. I do not want that. I\u2019m looking to embed just the table/content area.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-31T14:35:37.766Z",
				"Answer_body": "<p>oh, sorry I about that. I reread it and I don\u2019t know how I missed that <img src=\"https://emoji.discourse-cdn.com/twitter/man_facepalming.png?v=12\" title=\":man_facepalming:\" class=\"emoji\" alt=\":man_facepalming:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<p>No, it\u2019s not currently possible to just embed the W&amp;B Table. This is a good feature request, I\u2019ll follow up with the team. Thank you</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-31T15:02:02.546Z",
				"Answer_body": "<p>Not at all, Scott <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"> I\u2019m sure you have lots of people who don\u2019t bother to read the docs and ask about embedding stuff. So no worries.</p>\n<p>Thank you for passing on the request to the team. Much appreciated!</p>\n<p>I\u2019ve done at least 10 screenshots of data grids since yesterday for two separate blog posts. So I know that this would be something that would be useful to others too <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<p>Incidentally, I\u2019ve found W&amp;B to be really, really useful. And if you guys want more feature requests, I do have some!</p>\n<p>Also have a few other questions but will create posts for those later on \u2026 Thanks again!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-01T21:30:12.113Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/fahimf\">@fahimf</a> , thank-you for the feature request. There is currently an open request for this and it is under consideration. Once the team makes a decision, I will provide an update in this thread.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-01T22:39:47.224Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> , thank you for the update. Will wait for your update!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-31T22:40:16.364Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "NotFoundError()",
		"Question_link": "https://community.wandb.ai/t/notfounderror/3006",
		"Question_created_time": "2022-08-25T16:42:15.566Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 305,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I was wondering if you have any suggestions on what could be causing the following error:</p>\n<p>wandb: Synced 6 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)<br>\nwandb: Find logs at: ./wandb/run-20220825_163228-73lfow6y/logs<br>\nRun 73lfow6y errored: NotFoundError()<br>\nwandb: ERROR Run 73lfow6y errored: NotFoundError()</p>\n<p>Please note, I am using:<br>\nPython 3.7.12<br>\nwandb, version 0.13.2</p>\n<p>Thank you!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-25T18:34:14.111Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dfrances\">@dfrances</a>,<br>\nCould you possibly share a minimal replication of your code? Also, if you are using our public cloud service would you mind sending a link to your workspace and I can take a look?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-01T22:07:42.973Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dfrances\">@dfrances</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-31T22:08:12.417Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Local controller seems block",
		"Question_link": "https://community.wandb.ai/t/local-controller-seems-block/2955",
		"Question_created_time": "2022-08-18T06:17:13.186Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 339,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I make the following sweep (yaml) file:</p>\n<pre><code class=\"lang-auto\">program: train_mnist.py\nmethod: grid\nparameters:\n  lr_schedule:\n    values: [ step, cyclic ]\n  epoch_total:\n    values: [ 2, 4 ]\nmetric:\n  goal: maximize\n  name: test-result/accuracy\nproject: my-mnist-test-project\nname: MNIST-Sweep-Test\ndescription: test sweep demo\n</code></pre>\n<p>and I use <a href=\"https://docs.wandb.ai/guides/sweeps/advanced-sweeps/local-controller#running-the-local-controller-from-the-command-line\">local controller</a> to perform sweep locally. However, it seems block here:</p>\n<pre><code class=\"lang-auto\">(pytorch) geyao@geyaodeMacBook-Air wandb_test % wandb sweep --controller sweep_config.yaml\nwandb: Creating sweep from: sweep_config.yaml\nwandb: Created sweep with ID: o2mzl569\nwandb: View sweep at: https://wandb.ai/geyao/my-mnist-test-project/sweeps/o2mzl569\nwandb: Run sweep agent with: wandb agent geyao/my-mnist-test-project/o2mzl569\nwandb: Starting wandb controller...\nSweep: o2mzl569 (grid) | Runs: 0\n\n# ------blocked here!------\n</code></pre>\n<p>When I turn off the network, it will be:</p>\n<pre data-code-wrap=\"shell\"><code class=\"lang-nohighlight\">(pytorch) geyao@geyaodeMacBook-Air wandb_test % wandb sweep --controller sweep_config.yaml\nwandb: Creating sweep from: sweep_config.yaml\nwandb: Network error (ConnectionError), entering retry loop.\n</code></pre>\n<p>Why local controller tries to connect the network? How can I perform local sweep with/without network in the right way?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-22T18:17:18.238Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/geyao\">@geyao</a> , we will attempt to reproduce on our end and reply soon.  When the sweep hangs, do any errors eventually print to terminal? Or do any debug logs for the run get generated under wandb//logs you can share with us?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-23T02:49:54.223Z",
				"Answer_body": "<p>Thanks for your reply! Unfortunately, I don\u2019t have any log information in my local wandb directory. But I find the below log in wandb cloud:</p>\n<pre><code class=\"lang-auto\">2022-08-23T02:43:06.098679 Created sweep z9kz3pzk\nUsing local controller...\n \n2022-08-23T02:43:08.554205 Sweep configuration updated to: {\"description\":\"test sweep demo\",\"method\":\"grid\",\"metric\":{\"goal\":\"maximize\",\"name\":\"test-result/accuracy\"},\"name\":\"MNIST-Sweep-Test\",\"parameters\":{\"epoch_total\":{\"values\":[2,4]},\"lr_schedule\":{\"values\":[\"step\",\"cyclic\"]}},\"program\":\"train_mnist.py\",\"project\":\"my-mnist-test-project\",\"controller\":{\"type\":\"local\"}}\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-25T21:50:53.697Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/geyao\">@geyao</a> , you aren\u2019t blocked,</p>\n<p><code>Sweep: o2mzl569 (grid) | Runs: 0</code> is expected behavior as your sweep will be in a \u2018Pending\u2019 state once you initiate the Local Controller.  Once you begin running your sweep,<code> wandb agent o2mzl569</code>, your sweep will now execute and you can step through the sweep controller using your python script.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-26T13:22:54.726Z",
				"Answer_body": "<p>Thanks for your answer! It works when I start a new terminal to run the agent. But I still want to know: is it necessary for local controller to connect to W&amp;B cloud service?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-01T00:39:13.334Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/geyao\">@geyao</a> , the local controller doesn\u2019t have the full functionality of W&amp;B cloud, and is not intended for actual hyperparameter optimization workloads. It\u2019s intended for development and debugging of new algorithms for the Sweeps tool. You don\u2019t need to connect to W&amp;B cloud service to use the controller.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-10-31T00:39:34.501Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Legend ordering",
		"Question_link": "https://community.wandb.ai/t/legend-ordering/3041",
		"Question_created_time": "2022-08-31T23:35:30.181Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 163,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey all,<br>\nI was just wondering if its possible to rearrange/order elements in the legend of a chart? I have different data series that each go by a number and right now, the legend displays these numbers in random order\u2026</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-02T13:05:44.621Z",
				"Answer_body": "<p>Hi Christopher,</p>\n<p>Thanks for your question! Currently this is not possible, but I can create a request for this feature. The order in which the legend is shown is by the time each run has been logged. Please let me know if I can help you in any other way!</p>\n<p>Best,<br>\nLuis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-30T23:36:22.374Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Rate limit exceeded wandb website",
		"Question_link": "https://community.wandb.ai/t/rate-limit-exceeded-wandb-website/3001",
		"Question_created_time": "2022-08-25T06:55:37.930Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 142,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Help! I can\u2019t log in to my wandb on the web. It returns Rate limit exceed error. It\u2019s been like this for hours @@.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-25T21:30:39.929Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/_giaabaoo\">@_giaabaoo</a>,</p>\n<p>I\u2019m sorry you are facing issues here - could you share if you see any console errors in your browser when trying to log in?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-31T07:29:52.811Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/_giaabaoo\">@_giaabaoo</a>,</p>\n<p>This should be resolved for you now. I\u2019ll close out this support request, but feel free to reply to this thread / reach out in case you encounter any other issues.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-30T07:29:56.452Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb docker-run fails to detect image argument",
		"Question_link": "https://community.wandb.ai/t/wandb-docker-run-fails-to-detect-image-argument/3033",
		"Question_created_time": "2022-08-30T18:09:27.257Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 76,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Trying to set up wandb, I get the following error when running</p>\n<pre><code class=\"lang-auto\">wandb docker-run [docker run options] [IMAGE] bash\n</code></pre>\n<p>wandb: Couldn\u2019t detect image argument, running command without the WANDB_DOCKER env variable</p>\n<p>The image loads as usual but I cannot access wandb.</p>\n<p>Error presents even after deleting all docker run options.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-02T16:01:02.245Z",
				"Answer_body": "<p>Hi Camden, Just to confirm, did you use the WANDB_DOCKER environment variable? In order to properly incorporate wandb to docker, this has to be set up properly.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-08T17:19:54.018Z",
				"Answer_body": "<p>Hi Camden,</p>\n<p>Do you still need help here?</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-13T20:17:50.154Z",
				"Answer_body": "<p>Hi Camden, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-29T18:09:33.735Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Getting KeyError: tensor([0]) while plotting wandb's confusion matrix",
		"Question_link": "https://community.wandb.ai/t/getting-keyerror-tensor-0-while-plotting-wandbs-confusion-matrix/2974",
		"Question_created_time": "2022-08-22T16:46:51.132Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 320,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\nI am trying to plot confusion matrix using wandb\u2019s API.<br>\nBut I am getting</p>\n<pre><code class=\"lang-auto\">  File \"/home/ubuntu/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/wandb/plot/confusion_matrix.py\", line 72, in confusion_matrix\n    counts[class_mapping[y_true[i]], class_mapping[preds[i]]] += 1\nKeyError: tensor([0])\n</code></pre>\n<p>My validation loops like below -</p>\n<pre><code class=\"lang-auto\">for batch_idx, (data, target) in enumerate(loader['valid']):\n     output = model(data)\n     preds = torch.max(output, dim=1, keepdim=True)[1]\n     wandb.log({\"conf_mat\": wandb.plot.confusion_matrix(y_true=target, preds=preds, # noqa\n                       class_names=class_names)})\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-24T23:57:37.580Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/rishav\">@rishav</a> , this  happens when your prediction array values don\u2019t  index the correct class name.  Example:</p>\n<p>The below would produce a <code>KeyError: 5</code> as there isn\u2019t a 5th index in class_names</p>\n<pre><code class=\"lang-auto\">preds   = [1,2,3,4,5]\nclass_names = [\"one\",\"two\",\"three\",\"four\",\"five\"]\n</code></pre>\n<p>The above should instead be</p>\n<pre><code class=\"lang-auto\">preds   = [0,1,2,3,4]\nclass_names = [\"one\",\"two\",\"three\",\"four\",\"five\"]\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-30T18:08:13.219Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/rishav\">@rishav</a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-29T18:08:31.457Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Parameter importance for categorical variables",
		"Question_link": "https://community.wandb.ai/t/parameter-importance-for-categorical-variables/2966",
		"Question_created_time": "2022-08-22T07:13:28.896Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 214,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi!</p>\n<p>I have a conditional variable (True/False) in my sweep for freezing a layer or not. It gets quite high importance and a high positive correlation. How do I know if the \u201cTrue\u201d or the \u201cFalse\u201d is the \u201chigher\u201d value? In other words, how do I know which to set it to? Is it based on the order specified in the sweep-config? Unfortunately I cannot see any clear pattern in the runs due to a lot of other parameters also being varied at the time in my Bayesian sweep.</p>\n<p>Thank you!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-24T21:05:59.111Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/styrbjornkall\">@styrbjornkall</a> , I did a brief review of the sweep parallel coordinates chart in your <code>freezing_sweep</code> project, and based on the results, both <code>True</code> and <code>False</code> appear to have equitable influence on your results. It is difficult to interpret boolean results, yes, and our parameter importance panel won\u2019t tell you which value is the \u201chigher\u201d value, just that relative importance of the hyperparameter in respect to the chosen metric.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-30T00:29:22.842Z",
				"Answer_body": "<p>HI <a class=\"mention\" href=\"/u/styrbjornkall\">@styrbjornkall</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-29T00:29:38.517Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Login error! init error + broken pipeline",
		"Question_link": "https://community.wandb.ai/t/login-error-init-error-broken-pipeline/2926",
		"Question_created_time": "2022-08-14T16:35:44.419Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 177,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi there, I am facing this issue while using wandb.init().</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/4de690d919b9d13b072bd6968c7c5a6d8c4061af.png\" data-download-href=\"/uploads/short-url/b78KvLFKhAaWKkyNhJ2WPEjnkBN.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/4de690d919b9d13b072bd6968c7c5a6d8c4061af.png\" alt=\"image\" data-base62-sha1=\"b78KvLFKhAaWKkyNhJ2WPEjnkBN\" width=\"690\" height=\"364\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/4de690d919b9d13b072bd6968c7c5a6d8c4061af_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1211\u00d7640 24.3 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>I tried running following instructions:</p>\n<pre><code class=\"lang-auto\">wandb.init(settings=wandb.Settings(start_method='fork'))\nor\nwandb.init(settings=wandb.Settings(start_method='thread'))\n</code></pre>\n<p>is not working.</p>\n<p>Help would be appreciated, thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-17T21:21:19.698Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/prj\">@prj</a> ,</p>\n<p>We recently set our client (<a href=\"https://github.com/wandb/wandb/blob/master/CHANGELOG.md#0130-august-4-2022\" rel=\"noopener nofollow ugc\">v 0.13.0</a>) to use <a href=\"https://docs.wandb.ai/guides/track/advanced/distributed-training#wandb-service\">wandb service</a> by default for distributed training. The service  addresses the <a href=\"/guides/track/advanced/distributed-training#common-issues\">Common Issues</a> users run into.  Please update your cli or follow instructions in docs in how to use.  Let us know if this resolves your issues.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-24T06:21:54.320Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/prj\">@prj</a> , Following up on this post. Do you still require support assistance on multiprocessing?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-29T22:51:25.518Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/prj\">@prj</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-29T22:51:43.126Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/prj\">@prj</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>\n<p>[Discourse post]</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-28T22:51:28.653Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "xAxis settings for line plot over different runs",
		"Question_link": "https://community.wandb.ai/t/xaxis-settings-for-line-plot-over-different-runs/2894",
		"Question_created_time": "2022-08-10T19:48:28.832Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 77,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have developed a script to estimate some hardware evaluations for running my neural network. As parameter for this script the number of layers can be defined. This parameter is also passed to Wand.config.<br>\nThen the network trains over several epochs and evaluates the hardware. The results are all logged. At the end I would like to have a line chart with the number of layers as xaxis and for example the energy consumption on the yaxis. However, it is not possible to select the num_layers parameter in the menu.<br>\nMy guess is that line charts can only be plotted across a run and not as in my case where per value of the xaxis (num_layers) a different run specifies the value.</p>\n<p>Is there any way to implement my plan in Wandb in an automated way? Otherwise I would have to export the data and plot it with matplotlib etc.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-15T21:06:21.541Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/chwolters\">@chwolters</a> , can you please provide a link to your workspace for us to review. Thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-16T19:31:56.771Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a>! You can have a look here: <a href=\"https://wandb.ai/duke-tum/example?workspace=user-chwolters\" class=\"inline-onebox\">Weights &amp; Biases</a><br>\nIn this workspace there are 6 runs; 3 for each learning rule which I want to compare. These two sets of runs have an increasing network depth (2, 3, 4). Now I\u2019d like to plot different metrics such as accuracy over the different network depts. So, on the x-axis there would be the depth with values 2, 3, 4; while measuring accuracy on the y-axis.<br>\nAll this should be plotted as a line chart with one line for each learning rule, i.e. comparing \u201cBP\u201d with \u201cDFA\u201d.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-24T07:32:00.510Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/chwolters\">@chwolters</a> , this is definitely doable with <a href=\"https://docs.wandb.ai/ref/app/features/custom-charts\">custom charts</a>. Specifically a chart with a custom x axis of 2,3,4, and three y fields values to referencing the runs accuracy. Alternatively yes, using Matplotlib is an option, however, with custom charts, you can save the preset for future use.</p>\n<p>If you decide for a custom chart, some of your Vega code may  appear as follows</p>\n<p>Define Multiple Y fields</p>\n<pre><code class=\"lang-auto\">\"transform\": [\n  {\"filter\": {\"field\": \"${field:yfield1}\", \"valid\": true}},\n  {\"filter\": {\"field\": \"${field:yfield2}\", \"valid\": true}},\n  {\"filter\": {\"field\": \"${field:yfield3}\", \"valid\": true}}\n],\n</code></pre>\n<p>Define custom x axis</p>\n<pre><code class=\"lang-auto\">\"x\":{\n  \"type\": \"quantitative\",\n  \"axis\": {\n    \"values\": [2, 3, 4]\n  }\n},\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-29T19:55:08.679Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/chwolters\">@chwolters</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-28T19:55:26.820Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Logging multiline plots",
		"Question_link": "https://community.wandb.ai/t/logging-multiline-plots/3025",
		"Question_created_time": "2022-08-29T15:12:03.618Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 83,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m looking for an elegant way to log multiline plots (e.g. showing AUROC and AUPRC on one plot) whilst training, and using the wandb.log() function. As far as I can tell, the only way is to keep track of the values from the start of training up until the current iteration, then log a wandb.plot.line (according to <a href=\"https://wandb.ai/wandb/plots/reports/Custom-Line-Plots--VmlldzoyNjk5NTA\" class=\"inline-onebox\">Weights &amp; Biases</a>), however this is a different interface from the standard use of wandb.log(), wherein you only give the latest value.</p>\n<p>Is there some way to do what I\u2019m looking for (multiline plots that update each iteration of training, and only need to be given the latest value for each variable)?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-01T18:27:58.797Z",
				"Answer_body": "<p>Hi Addison,</p>\n<p>I would recommend logging each line into a new run. From there you can create a new line plot via \u2018+ Add Panel\u2019 on the top right of your workspace and have all of your lines on the same plot. Let me know if you need any help regarding this!</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-07T20:13:13.878Z",
				"Answer_body": "<p>Hi Addison, were you able to create a multiline plot with the directions I gave in my previous response?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-13T13:09:32.704Z",
				"Answer_body": "<p>Hi Addison, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-28T15:12:20.535Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb takes too much time after each run ends",
		"Question_link": "https://community.wandb.ai/t/wandb-takes-too-much-time-after-each-run-ends/2947",
		"Question_created_time": "2022-08-16T21:43:49.100Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 270,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019ve been using wandb sweeps and I found that after each run is finished, the following message shows up</p>\n<blockquote>\n<p>wandb: Waiting for W&amp;B process to finish\u2026 (success)</p>\n</blockquote>\n<p>but then 10 minutes pass with nothing happening.<br>\nOnly after this long time wandb shows the run history and summary and starts a new run.<br>\nI\u2019m using wandb in a Gradient Paperspace notebook, running it from the terminal.</p>\n<p>I\u2019ve found anyone else with this issue, so it may be something wrong at my side.<br>\nDo you have any idea of what the problem might be?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-18T00:58:42.683Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ogait\">@ogait</a> , in your project workspace, under the overview page for the sweep/runs associated with the sweep, what is the status of those sweeps/runs? Additionally, we can take a look at your debug bundles to verify if there is anything that is causing issues. They are the <code>debug.log</code> and <code>debug-internal.log</code> files located in the working directory of the project inside the <code>wandb</code> folder of the runs. Please provide logs for the runs where you are seeing issues.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-18T01:28:26.916Z",
				"Answer_body": "<p>Hello Mohammad thanks for the response.<br>\nWhen this happens, both the sweep and the run status is \u201crunning\u201d.<br>\nHere is an example of <code>debug.log</code> and <code>debug-internal.log</code> (unfortunately the files are too big to be included in this message): <a href=\"https://easyupload.io/m/oa3r5t\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Easyupload.io - Upload files for free and transfer big files easily.</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-26T02:00:05.608Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ogait\">@ogait</a> , thank-you for providing the files. After review it appears this is due to a performance related bug on our end where the run exit response hangs until all the run data syncs, example. <code>[wandb_run.py:_on_finish():2221] got exit ret: None</code>.  This bugs shows up in runs with a lot of .log calls. The bug is currently in <strong>Selected For Development</strong>.  I will update you here when there has been movement.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-26T09:25:06.742Z",
				"Answer_body": "<p>Thanks for the update Mohammad!<br>\nCan I do something to reduce the number of log calls?<br>\nI am using fastai with the following callback <code>WandbCallback(log_model=False, log_preds=False)</code> and at the end of training I use <code>wandb.summary</code> to save six simple variables.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-25T09:25:34.408Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Plotting confusion matrix",
		"Question_link": "https://community.wandb.ai/t/plotting-confusion-matrix/2902",
		"Question_created_time": "2022-08-11T12:31:44.757Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 166,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m training a model and I\u2019m trying to add a confusion matrix, which would be displayed in my wandb, but got lost a bit. Basically, the matrix works, I can print it, but it\u2019s not loaded into wandb. Everything should be ok, except it\u2019s not. Can you please help me? I\u2019m new to all this. Thanks a lot!</p>\n<pre><code class=\"lang-auto\">                nb_classes = 7\n\n                confusion_matrix = torch.zeros(nb_classes, nb_classes)\n                with torch.no_grad():\n                    for i, (inputs, classes) in enumerate(dataloaders['val']):\n                        inputs = inputs.to(device)\n                        classes = classes.to(device)\n                        outputs = model_ft(inputs)\n                        _, preds = torch.max(outputs, 1)\n                    \n                    for t, p in zip(classes.view(-1), preds.view(-1)):\n                        confusion_matrix[t.long(), p.long()] += 1\n              wandb.log({'matrix' : confusion_matrix})\n                           \n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-15T21:11:37.533Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/diakonua\">@diakonua</a> , please provide a link to your space for us to investigate the not loading concern you have. Thank-you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-17T12:42:24.845Z",
				"Answer_body": "<p>Hi, wandb is not to blame, it\u2019s definitely my fault.  At my wandb workspace I don\u2019t see the plot at all, yet the code prints matrix. I then thought to use the wandb\u2019s confusion matrix, but I cannot define it properly. Could you please help with that? Sorry, for a really primitive problem and not trying to figure the code on my own, but I\u2019m really lost here and new to all of this.</p>\n<p><strong>wandb\u2019s code</strong></p>\n<pre><code class=\"lang-auto\">confusion_matrix = wandb.plot.confusion_matrix(\n    y_true=ground_truth,\n    preds=predictions,\n    class_names=class_names)\n    \nwandb.log({\"confusion_matrix\": confusion_matrix })\n</code></pre>\n<p><strong>my piece of code</strong></p>\n<pre><code class=\"lang-auto\">def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs))\n        print('-' * 10)\n\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  \n            else:\n                model.eval()   \n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n                from sklearn.metrics import f1_score\n                f1_score = f1_score(labels.cpu().data, preds.cpu(), average=None)\n                       \n                wandb.log({'F1 score' : f1_score})\n\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n            wandb.log({'epoch loss': epoch_loss,\n                    'epoch acc': epoch_acc})\n            \n            data = [[i, random.random() + math.sin(i / 10)] for i in range(100)]\n            table = wandb.Table(data=data, columns=[\"step\", \"height\"])\n            wandb.log({'line-plot1': wandb.plot.line(table, \"step\", \"height\")})\n\n        \n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc, f1_score))\n\n            if phase == 'val' and epoch_acc &gt; best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n                \n        print()\n    \n    nb_classes = 2\n\n    confusion_matrix = torch.zeros(nb_classes, nb_classes)\n    with torch.no_grad():\n          for i, (inputs, classes) in enumerate(dataloaders['val']):\n              inputs = inputs.to(device)\n              classes = classes.to(device)\n              outputs = model_ft(inputs)\n              _, preds = torch.max(outputs, 1)\n                    \n          for t, p in zip(classes.view(-1), preds.view(-1)):\n              confusion_matrix[t.long(), p.long()] += 1\n                        \n    sns.heatmap(confusion_matrix, annot=True)\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n    print('f1_score: {}'.format(f1_score))\n   \n    model.load_state_dict(best_model_wts)\n    return model\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-26T00:31:47.620Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/diakonua\">@diakonua</a> , from your code block above, it\u2019s not clear where you log your confusion matrix to wandb. I see that you\u2019ve logged the F1 score, epoch loss, and line-plot1. Below are three example of logging confusion matrix to wandb.</p>\n<pre><code class=\"lang-auto\">from sklearn.metrics import confusion_matrix\nimport plotly.express as px\nimport seaborn as sns\nimport wandb\n\n#Seaborn\ny_true = [2, 0, 2, 2, 0, 1]\ny_pred = [0, 0, 2, 2, 0, 2]\ncfm = confusion_matrix(y_true, y_pred)\ncfm1 = sns.heatmap(cfm, annot=True)\n\n#Plotly\nz = [[.1, .3, .5, .7, .9],\n     [1, .8, .6, .4, .2],\n     [.2, 0, .5, .7, .9],\n     [.9, .8, .4, .2, 0],\n     [.3, .4, .5, .7, 1]]\n\ncfm2 = px.imshow(z, text_auto=True)\n\n#Wandb Matrix\nclass_names = [\"zero\",\"one\",\"two\"]\ncfm3 = wandb.plot.confusion_matrix(\n    y_true=y_true,\n    preds=y_pred,\n    class_names=class_names)\n\nwandb.init(entity=\"&lt;entity&gt;\", project=\"&lt;project-name&gt;\")\nwandb.log({\"cfm1\": cfm1})\nwandb.log({\"cfm2\": cfm2})\nwandb.log({\"cfm3\": cfm3})\nwandb.finish()\n</code></pre>\n<p>There are additional examples in our <a href=\"https://docs.wandb.ai/\">documents</a>. Hope this helps and please let us know if you have additional questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-25T00:32:17.628Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "All records are lost in a project without any action",
		"Question_link": "https://community.wandb.ai/t/all-records-are-lost-in-a-project-without-any-action/2993",
		"Question_created_time": "2022-08-25T04:55:18.517Z",
		"Question_answer_count": 13,
		"Question_score_count": 5,
		"Question_view_count": 269,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Dear Sir or Madam,</p>\n<p>Sorry for bothering you, I think there is an error in one of my wandb projects and the records of all runs were lost. The account is nbower0707, email 1155156871@link.cuhk.edu.hk, and the project name is ocp22.</p>\n<p>Everything worked fine before today, and I did a lot of experiments on this project. I\u2019m uploading records of my metric around every 5000 steps, and the result validation metric plot should be something like  figure 1 shows(continuous lines of records, with multiple data points) I\u2019m uploading the corresponding metrics every 2500 steps, and wandb displayed all results fine yesterday (either undergoing or finished runs)</p>\n<p>However, when I check the plot today, the record of metric in all runs were (completely or partly) lost, except for some small isolated data points left (as figure 2 and 3 shows).</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/a14c097f39437a5f49c44e628d5d3e3d92490c4d.jpeg\" data-download-href=\"/uploads/short-url/n0TMrYL9SyvpaH1YKsBmceDhhRb.jpeg?dl=1\" title=\"Picture 1\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a14c097f39437a5f49c44e628d5d3e3d92490c4d_2_414x500.jpeg\" alt=\"Picture 1\" data-base62-sha1=\"n0TMrYL9SyvpaH1YKsBmceDhhRb\" width=\"414\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a14c097f39437a5f49c44e628d5d3e3d92490c4d_2_414x500.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a14c097f39437a5f49c44e628d5d3e3d92490c4d_2_621x750.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a14c097f39437a5f49c44e628d5d3e3d92490c4d_2_828x1000.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a14c097f39437a5f49c44e628d5d3e3d92490c4d_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Picture 1</span><span class=\"informations\">2337\u00d72818 348 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>I tried to use <strong>wandb sync</strong> from the local file, and upload the runs to a new project, the result is still the same.</p>\n<p>I didn\u2019t do any specific operations regarding wandb logging process or on the website. The project consist of runs uploaded from different machines, therefore it wouldn\u2019t be mistakenly deletion/ false operation offline. And the phenomenon of lost of data also occurs on old runs that finished weeks ago.</p>\n<p>Please let me know if you have any suggestions on this error, and if the records could be recovered.</p>\n<p>Your time and patience are sincerely appreciated.</p>\n<p>Bowen Wang</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-25T05:10:38.981Z",
				"Answer_body": "<p>I have the same problem\u2026</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-25T06:26:28.134Z",
				"Answer_body": "<p>Me too. From night to morning the runs graphs miss a lot of data points in the validation section and I also noted that the resize of the panels in that section doesn\u2019t work properly</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-25T06:27:35.035Z",
				"Answer_body": "<p>Same problem here, the plots are weird and loses a lot of data points</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-25T06:44:26.346Z",
				"Answer_body": "<p>Me too\u2026 It seem to be  same problem</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-25T07:43:03.396Z",
				"Answer_body": "<p>Hi Everyone,</p>\n<p>Apologies for the inconvenience here. We are looking into the issue - any links to workspaces where you see this currently would be greatly appreciated.</p>\n<p>Thanks,<br>\nRamit<br>\nW&amp;B Support</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-25T08:19:07.481Z",
				"Answer_body": "<p>Mine is <a href=\"https://wandb.ai/niansong1996/cot-codegen?workspace=user-niansong1996\" class=\"inline-onebox\">Weights &amp; Biases</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-25T08:20:00.625Z",
				"Answer_body": "<p>Same problem here, plots look similar to the ones shown</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-25T08:45:43.885Z",
				"Answer_body": "<p>Here\u2019s <a href=\"https://wandb.ai/johnminelli/TwoWaySinth\">mine</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-25T09:41:56.499Z",
				"Answer_body": "<p>The same issue\u2026<br>\nYesterday  they were fine\u2026</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-25T09:46:40.765Z",
				"Answer_body": "<p>Same issue  <a href=\"https://wandb.ai/ecotoxformer/fish-EC50-MOR?workspace=user-styrbjornkall\">here</a>. Though the charts look fine when opened in their respective run, just not in the combined workspace\u2026</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-25T16:49:12.578Z",
				"Answer_body": "<p>Now it\u2019s fine for me, thank you for the support</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-25T21:07:26.293Z",
				"Answer_body": "<p>Hey all,</p>\n<p>Our engineering team looked into this and rolled back some changes, everything should be working fine now.</p>\n<p>Please let us know if this issue persists.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-10-24T21:08:14.661Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Can I resume the sweep using python code instead of command?",
		"Question_link": "https://community.wandb.ai/t/can-i-resume-the-sweep-using-python-code-instead-of-command/2976",
		"Question_created_time": "2022-08-23T04:25:44.841Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 115,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I meet the <a href=\"https://github.com/wandb/wandb/issues/3344\" rel=\"noopener nofollow ugc\">bug</a> when I try to resume the sweep through command. I want to know if there exists the way to resume the sweep using python code.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-25T00:08:27.202Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/geyao\">@geyao</a> , there isn\u2019t an API method currently to resume a sweep. There is an active feature request for this. I can provide an update once a decision has been made by the team. In the meantime can you send us your debug logs, <code>debug.log</code> and <code>debug-internal.log</code> for review. I will gather notes on the issue to pass along to the team.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-25T08:09:06.523Z",
				"Answer_body": "<p>Thanks for your contribution to the wonderful tool W&amp;B. I think my debug logs is same as listed in the <a href=\"https://github.com/wandb/wandb/issues/3344\" rel=\"noopener nofollow ugc\">issue</a>. Please let me know if I can provide other useful information for solving this problem.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-24T08:10:05.512Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Please delete my account",
		"Question_link": "https://community.wandb.ai/t/please-delete-my-account/2978",
		"Question_created_time": "2022-08-23T10:37:26.876Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 111,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Can you please delete this account (gws-flux). Thank you!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-23T14:18:28.828Z",
				"Answer_body": "<p>Hi Felix, I can delete that account for you, but before I do can you confirm:</p>\n<p>Are you sure you want to delete this user? Deleting a user removes all user data permanently. This action cannot be undone.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-25T06:44:49.557Z",
				"Answer_body": "<p>I am sure, thank you for deleting it.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-02T01:26:39.975Z",
				"Answer_body": "<p>You\u2019re welcome! I\u2019m going to close this ticket out now, but I hope you have a great rest of the day <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-24T06:45:03.543Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Cannot find a specific column in sweep -> sweep table",
		"Question_link": "https://community.wandb.ai/t/cannot-find-a-specific-column-in-sweep-sweep-table/2925",
		"Question_created_time": "2022-08-14T04:00:40.995Z",
		"Question_answer_count": 8,
		"Question_score_count": 0,
		"Question_view_count": 141,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>When searching, I first hide all the columns (because in total there are more than 500 entries, which cannot be fully visible), and then I search for my intended column, but I find that I cannot find it. What\u2019s weird is that I didn\u2019t change my code and i am pretty sure I can see them before. Also, I can see that entry (i.e., a bleu result) in the charts. What\u2019s happening?</p>\n<p>Actually, I can see that entry appears for a millisecond, and then disappears. So, I guess that the table can only show arguments instead of result from now on?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-17T19:38:06.169Z",
				"Answer_body": "<p>Hi Oliver, can you tell me which column you are trying to search for and a link to this project so I can reproduce this on my side?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-18T11:25:26.495Z",
				"Answer_body": "<p>Hi leslie, it was <a href=\"https://wandb.ai/olivernova/HeadCollaboration/sweeps/1ss2kz1u/table?workspace=user-olivernova\">this</a> sweep project (for example). The metric I was searching for in the table is eval/bleu. It first appears for a half second, and then disappears.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/463fa3980aec636818545db2e86032b1b9517b62.png\" data-download-href=\"/uploads/short-url/a1rLFOFI00b0jH8CF5L99AZqYKe.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/463fa3980aec636818545db2e86032b1b9517b62_2_497x500.png\" alt=\"image\" data-base62-sha1=\"a1rLFOFI00b0jH8CF5L99AZqYKe\" width=\"497\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/463fa3980aec636818545db2e86032b1b9517b62_2_497x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/463fa3980aec636818545db2e86032b1b9517b62_2_745x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/463fa3980aec636818545db2e86032b1b9517b62_2_994x1000.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/463fa3980aec636818545db2e86032b1b9517b62_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1458\u00d71466 138 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-23T17:21:26.311Z",
				"Answer_body": "<p>Thank you for the link Oliver, it helps a whole lot. Just to make sure I\u2019m looking for the correct metric, it will be under eval/bleu which is not the same as eval_bleu, is this correct?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-25T02:46:40.120Z",
				"Answer_body": "<p>yes, it\u2019s eval/bleu.</p>\n<p>By the way, now I cannot see the whole table of this project (the same one). It\u2019s all blank, and I am not sure what is happening (maybe too many entries? I have 3000+entries)</p>\n<p>Thank you~</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-25T02:48:56.960Z",
				"Answer_body": "<p>pps, you can see the eval/bleu metric under the \u201csweep work space \u2192 eval\u201d, it shows as a chart.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9f6965fad9a62bdd5de855ccfe77c8affcff7145.png\" data-download-href=\"/uploads/short-url/mKdJqFoDwteoO8rC3inVqrUP2rH.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9f6965fad9a62bdd5de855ccfe77c8affcff7145_2_690x393.png\" alt=\"image\" data-base62-sha1=\"mKdJqFoDwteoO8rC3inVqrUP2rH\" width=\"690\" height=\"393\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9f6965fad9a62bdd5de855ccfe77c8affcff7145_2_690x393.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9f6965fad9a62bdd5de855ccfe77c8affcff7145.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9f6965fad9a62bdd5de855ccfe77c8affcff7145.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9f6965fad9a62bdd5de855ccfe77c8affcff7145_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">839\u00d7478 17.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-06T17:29:52.582Z",
				"Answer_body": "<p>Hi Oliver! Can you try clearing your workspace on the bottom left of your page? I\u2019m able to see all the runs on my end from the link you sent me. Regarding the columns, it looks like this is a bug on our end. I have reported it to our eng team and I\u2019ll let you know if there are any updates on it</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-16T15:48:29.437Z",
				"Answer_body": "<p>Hi again Oliver!</p>\n<p>Our engineers have fixed this issue! Please let me know if you are still experiencing it on your end.</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-24T02:49:29.386Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Use GPU with Keras - Colab File Missing",
		"Question_link": "https://community.wandb.ai/t/use-gpu-with-keras-colab-file-missing/2879",
		"Question_created_time": "2022-08-09T23:00:55.369Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 85,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Link: <a href=\"https://wandb.ai/authors/ayusht/reports/Use-GPUs-with-Keras--VmlldzoxNjEyNjE?_gl=1%2A1uwdrw1%2A_ga%2AMTA2NjE2OTcwOC4xNjYwMDgxMDY1%2A_ga_JH1SJHJQXJ%2AMTY2MDA4MTA2NC4xLjEuMTY2MDA4NTg2MC41Mg\" class=\"inline-onebox\">Weights &amp; Biases</a>\u2026</p>\n<h1>\n<a name=\"using-gpus-with-keras-a-tutorial-with-code-1\" class=\"anchor\" href=\"#using-gpus-with-keras-a-tutorial-with-code-1\"></a>Using GPUs With Keras: A Tutorial With Code</h1>\n<p>I am following this article to Monitor GPU and CPU performances but Colab file is missing. I wish to see this tutorial Can you help in this regard</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-12T16:42:51.213Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/alishafique\">@alishafique</a> thank you for reporting this broken link! Please find the Colab notebook of this article <a href=\"https://colab.research.google.com/github/ayulockin/DLshots/blob/master/Keras_GPU_Growth.ipynb\" rel=\"noopener nofollow ugc\">here</a>. Would this open for you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-19T13:28:20.719Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/alishafique\">@alishafique</a> were you able to open the Colab notebook from the link above? Let me know if I can help further with this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-25T00:53:20.012Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/alishafique\">@alishafique</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-24T00:53:35.643Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Show only columns with different values in experiments table",
		"Question_link": "https://community.wandb.ai/t/show-only-columns-with-different-values-in-experiments-table/2972",
		"Question_created_time": "2022-08-22T15:58:05.637Z",
		"Question_answer_count": 2,
		"Question_score_count": 1,
		"Question_view_count": 104,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>In the table view of a project, is it possible to show only the columns that have different values among runs? This would be very useful to quickly explore how changing parameters affect the model.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-24T23:22:17.881Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/enajx\">@enajx</a> , would the run comparer table work for your use case, see <a href=\"https://docs.wandb.ai/ref/app/features/panels/run-comparer\">here</a>.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-10-23T23:22:53.787Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Is parameter importance affected by the number of runs in bayesian sweep?",
		"Question_link": "https://community.wandb.ai/t/is-parameter-importance-affected-by-the-number-of-runs-in-bayesian-sweep/2965",
		"Question_created_time": "2022-08-22T06:57:27.397Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 127,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi!</p>\n<p>I have used wandb for a while now and since this is my first post here I must begin by extending my thanks to the team for making a great product! To my question:</p>\n<p>I have just started using Bayesian sweeps instead of grid based. I have a question about the parameter importance chart that you may add. If I understand it correctly, the bayesian sweep runs a couple of runs to build a probability model for e.g. the validation loss based on tweeking the given parameters inside their span. So in other words if permitted to run for say 100 runs, there will be many more runs inside the parameter-span where the probability of getting a low validation loss is highest than the opposite. This also means that some parameter configurations will be vastly overrepresented.</p>\n<p>Does it matter that there is a big inbalance in the tested parameter configurations when making the \u201cParameter Importance\u201d chart/panel? I don\u2019t know much about how the RF importance parameter is achieved, but for the Correlation it seems to me that this would be affected. Now I don\u2019t if that would be a bad thing, since I guess it should reflect the probability model but I would just like to hear someone else\u2019s opinion on the matter <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<p>Thank you!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-24T21:57:03.936Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/styrbjornkall\">@styrbjornkall</a>!</p>\n<p>Thanks for your question. The Parameter Importance plot essentially predicts how \u201creliably\u201d we can predict the output metric given the hyperparameters.</p>\n<p>Essentially, the <code>importance</code> metric represents how cleanly a given input hyperparameter was able to split a tree to produce 2 output classes, and as a result, how much information was gained due to that one hyperparameter. The more information gained, the more higher the <code>importance</code> of that one input parameter is.</p>\n<p>I would recommend looking up \u201cGini importance\u201d and \u201cGini impurity\u201d if you are interested in diving deeper into this.</p>\n<p>Coming back to your question about the relation between number of runs and importance, importance is a statistical measure. The more runs you create, the less variance you will see with importance and the closer they will be to the true importance of the metric.</p>\n<p>If there is a large imbalance in the input hyperparameters, this could definitely skew the importance plot. There should not be a large difference, however since the Bayes\u2019 search establishes a good balance between exploring new combinations / using past combinations.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-30T04:34:43.793Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/styrbjornkall\">@styrbjornkall</a>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-02T17:34:25.162Z",
				"Answer_body": "<p>Hi Styrbj\u00f6rn, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-23T21:57:55.692Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Embed Plotly Graphs in HTML",
		"Question_link": "https://community.wandb.ai/t/embed-plotly-graphs-in-html/2986",
		"Question_created_time": "2022-08-24T15:07:20.713Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 197,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I would like to use some of my wandb plots to <a href=\"https://plotly.com/python/embedding-plotly-graphs-in-HTML/\" rel=\"noopener nofollow ugc\">Embed Plotly Graphs in HTML</a>. Is there anyway to get similar functionality? If it cannot be done directly on wandb I see the other option as downloading the graphs, and uploading them to Plotly Chart Studio where they can then be embedded in HTML.</p>\n<p>I do like reports, but this would allow for the inclusion of plots in a wider scope of documents. For example, papers for publication, books, or even a dissertation.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-29T15:35:37.353Z",
				"Answer_body": "<p>Hi Michael,</p>\n<p>Thank you for this feature request! At this moment we don\u2019t have this functionality. At the moment you can share wandb charts by exporting them by clicking on the top right of the chart and clicking on the three dots. From there, you can navigate to \u2018Export panel\u2019 to get a variety of ways to share it. We do have a ticket out to allow for this functionality though and I\u2019ll let you know if we have any updates on it.</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-23T15:08:20.359Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Scores of BoundingBoxes2D object now showing in workspace",
		"Question_link": "https://community.wandb.ai/t/scores-of-boundingboxes2d-object-now-showing-in-workspace/2891",
		"Question_created_time": "2022-08-10T16:21:23.491Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 77,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey, I\u2019m using <a href=\"https://docs.wandb.ai/ref/python/data-types/boundingboxes2d\">boundingboxes2d</a> to save my detection predictions, which include keys like <code>position</code> and <code>scores</code>.</p>\n<p>The <code>media/metadata/boxes2D/*.json</code> files show that I successfully logged what I want. However, in the workspace, where can I get a visual of the scores?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/6d76fa5ed37cae06c917319fe332817dfc5dd251.jpeg\" data-download-href=\"/uploads/short-url/fCmX7d0Pk78vObXQyale8gQ6yQx.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/6d76fa5ed37cae06c917319fe332817dfc5dd251_2_690x457.jpeg\" alt=\"image\" data-base62-sha1=\"fCmX7d0Pk78vObXQyale8gQ6yQx\" width=\"690\" height=\"457\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/6d76fa5ed37cae06c917319fe332817dfc5dd251_2_690x457.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/6d76fa5ed37cae06c917319fe332817dfc5dd251_2_1035x685.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/6d76fa5ed37cae06c917319fe332817dfc5dd251_2_1380x914.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/6d76fa5ed37cae06c917319fe332817dfc5dd251_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1920\u00d71272 120 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Besides, can I sort the results based on scores?</p>\n<p>Thanks for your time!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-12T21:08:26.583Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sybil\">@sybil</a> , please provide a code example of how you are passing scores to the predictions dictionary of the boxes. Additionally, provide a copy of the json for review. Thank-yo.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-18T21:57:53.289Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sybil\">@sybil</a> , following back on this. Do you still need assistance with the issue you faced with bounding boxes?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-24T06:23:47.480Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sybil\">@sybil</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-23T06:24:17.488Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Rate limited exceeded",
		"Question_link": "https://community.wandb.ai/t/rate-limited-exceeded/2981",
		"Question_created_time": "2022-08-24T04:37:38.978Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 508,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I ran a few distributed training runs with 12 parallel processes. I now have problems accessing the web interface, with the error message \u201crate limit exceeded\u201d showing. Please help!</p>\n<p>Thank you.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-24T15:38:44.446Z",
				"Answer_body": "<p>Hi Calvin,</p>\n<p>I have increased the rate limit on your account. Please let me know if you have any other issues!</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-29T18:02:16.625Z",
				"Answer_body": "<p>Hi Calvin, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-23T04:38:25.518Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Plotly aspect ratio",
		"Question_link": "https://community.wandb.ai/t/plotly-aspect-ratio/2848",
		"Question_created_time": "2022-08-03T19:43:18.584Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 147,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am creating plots on my mac notebook and logging them to wandb, and this works. However, wandb displays these plots in a fixed aspect ratio, which only includes a subset of the axis range. I must scroll to see the entire plot, which is inconvenient. The default aspect ratio seems to be chosen to display a nice layout together with other logged items. My question is whether it is possible to specify the aspect ratio for specific logged variables and plotly plots. Thank you. Gordon.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-03T20:54:25.140Z",
				"Answer_body": "<p>I do not know the answer to my question. However, if I increase the size of the panel, I find that the panel of subsequent runs keeps its shape, even if the run id changes. That is good.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-08T17:23:55.934Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/erlebacher\">@erlebacher</a>, could you possibly send me a link to your workspace so I can take a look? Also, are the plots originally created in Plotly or are they created in Matplotlib first?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-09T15:42:30.614Z",
				"Answer_body": "<p>Thank you, Nate. The plots are created in matplotlib first. I no longer have the workspace. But I found that if I scaled the plot manually in the panel, this scaling was maintained. I\u2019d have to create another example to demonstrate this, but won\u2019t have time until Thursday.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-12T19:39:38.849Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/erlebacher\">@erlebacher</a>, I wanted to check back and see if you had a chance to recreate this in another workspace?</p>\n<p>I also wanted to ask if you were looking to specify this in code? One option might be to convert the Matplotlib plot to Plotly in your code first (Plotly has a function to do this) and then adjust the axis before logging to W&amp;B.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-18T05:56:41.249Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/erlebacher\">@erlebacher</a>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-23T18:22:40.342Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/erlebacher\">@erlebacher</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-22T18:22:56.841Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to export data from local run files?",
		"Question_link": "https://community.wandb.ai/t/how-to-export-data-from-local-run-files/2959",
		"Question_created_time": "2022-08-19T03:24:43.281Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 218,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>The doc <a href=\"https://docs.wandb.ai/guides/track/public-api-guide\">Import &amp; Export Data</a> gives the way how to export data from cloud. Can I use api to export data from local run files? I tried use path to local run directory instread of <code>&lt;entity&gt;/&lt;project&gt;/&lt;run_id&gt;</code>, but it doesn\u2019t work.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-22T23:35:26.167Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/geyao\">@geyao</a> , this is currently not an available option. This functionality will be revisited in the future for consideration. Our API only works with runs logged to the cloud.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-08-23T02:53:18.156Z",
				"Answer_body": "<p>Thanks for your reply! Hope W&amp;B will support more features in the future. I really like this tool.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-22T02:53:55.506Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Description field",
		"Question_link": "https://community.wandb.ai/t/description-field/2881",
		"Question_created_time": "2022-08-10T00:50:58.434Z",
		"Question_answer_count": 9,
		"Question_score_count": 0,
		"Question_view_count": 126,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I am loving <a href=\"http://wandb.ai\">wandb.ai</a> and all it can do for me. I have a question whose answer I cannot find anywhere.<br>\nAmong the various fields in the wandb.config file are a few that wandb generates automatically. One of them is <code>Description</code>. I tried setting it from a Python program via my configuration file, but to no avail. So I am wondering how to set the Description field programmatically. This will allow me to \u201cdescribe\u201d several hundred simulations for easy retrieval. Thanks,</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-10T07:34:48.127Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/erlebacher\">@erlebacher</a> ,</p>\n<p>You can pass a notes string to initialization, like: <code>wanbd.init(notes='my special run')</code> or modify it on the run through <code>run.notes</code>(eg. <code>r=wandb.run; r.notes='xx'</code>).</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-10T09:16:37.688Z",
				"Answer_body": "<p>Thanks! This makes sense.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-10T16:33:31.383Z",
				"Answer_body": "<p>As a continuation of my question: When looking at a series of runs on wandb, I can filter by Description, by cannot filter by Notes. My current Notes field is empty, but why this restriction? Thanks.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-12T19:44:51.443Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/erlebacher\">@erlebacher</a> , descriptions are associated with Artifacts. Artifacts have a natural hierarchy where the latest Artifact <code>**latest**</code> alias to the logged version. Are you asking if you can sort Artifacts?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-15T18:39:39.973Z",
				"Answer_body": "<p>Thanks. I have not gotten to artifacts as yet, so no, I am not asking about sorting artifacts. When looking at Runs on <a href=\"http://wandb.ai\">wandb.ai</a>, two of the columns are labeled Description and Note. I was enquiring about those two fields only and whether can select subsets of records based on specific words in either Note or Description.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-15T19:28:23.622Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/erlebacher\">@erlebacher</a>, thank-you for clarifying. The runs table can\u2019t be sorted by Notes/Descriptions. There are other fields you can filter by including <code>Tags</code>, <code>Group</code>, <code>Type</code> , ect.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/1f6b66fa455e95a685431ee8f404448929daab0d.png\" data-download-href=\"/uploads/short-url/4tWUpumJwXuLezTxR4hYtJNXhkp.png?dl=1\" title=\"Filters\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1f6b66fa455e95a685431ee8f404448929daab0d_2_517x500.png\" alt=\"Filters\" data-base62-sha1=\"4tWUpumJwXuLezTxR4hYtJNXhkp\" width=\"517\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1f6b66fa455e95a685431ee8f404448929daab0d_2_517x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/1f6b66fa455e95a685431ee8f404448929daab0d.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/1f6b66fa455e95a685431ee8f404448929daab0d.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1f6b66fa455e95a685431ee8f404448929daab0d_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Filters</span><span class=\"informations\">552\u00d7533 21.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-16T13:57:35.742Z",
				"Answer_body": "<p>Thank you, <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> . I am wondering why did the W&amp;B developers decide not to include Notes and Descriptions in the list of items that can be filtered? Is it a lack of implemented string functions? I am surprised given that W&amp;B is already full-featured.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-18T22:05:26.461Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/erlebacher\">@erlebacher</a> , It\u2019s pretty expensive to do pattern filtering in MySQL, especially on a large column like <code>notes</code> . The engineering team decided this feature will not be implemented. I will mark this resolved but please let me know if there is anything else I can answer for you.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-10-17T22:06:27.457Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Access sweep_id and run_id within train() function for local weight storage",
		"Question_link": "https://community.wandb.ai/t/access-sweep-id-and-run-id-within-train-function-for-local-weight-storage/2948",
		"Question_created_time": "2022-08-17T07:01:45.149Z",
		"Question_answer_count": 2,
		"Question_score_count": 2,
		"Question_view_count": 142,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hello,</p>\n<p>As I cannot simply upload infinitely many weights using artifacts, I also want to store some locally.<br>\nFor naming, I would like to use the sweep id and/or the run id.</p>\n<p>Can I access that somehow in the train function I hand over to the agent?</p>\n<p>Thanks</p>\n<p>Markus</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-18T22:04:29.034Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/markuskarner\">@markuskarner</a>!</p>\n<p>The <code>wandb.Run</code> object that is returned from <code>wandb.init</code> contains this information as properties. You should be able to access <code>run.id</code> and <code>run.sweep_id</code> in the train function after calling <code>run = wandb.init(...)</code>.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-10-17T22:05:26.069Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb dashboard/report table - rotate column names",
		"Question_link": "https://community.wandb.ai/t/wandb-dashboard-report-table-rotate-column-names/2889",
		"Question_created_time": "2022-08-10T14:09:19.235Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 104,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi wandb Team,</p>\n<p>I just recently started to use your tool and I already really like it! It\u2019s integration is very easy and helps to decouple the monitoring of my experiments from my own computer.</p>\n<p>I have a question regarding the table visualizations in the dashboard or as part of a report. I am wondering whether it is possible to rotate the column names by 90\u00b0 so that I can use the available space more efficiently because I am tracking a lot of metrics, which I would like to compare.</p>\n<p>If this is not possible at the moment, I would really appreciate such a feature!<br>\nMy workaround will be now to use abbreviations for the metrics.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-12T20:50:34.342Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/bigdatalex\">@bigdatalex</a> ,</p>\n<p>This feature is currently unavailable. Please provide a few sentence summary of how this assists/is important to your workflow and I will put in a feature request to the engineering team for review.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-18T21:59:03.327Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/bigdatalex\">@bigdatalex</a>  since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-17T21:59:30.377Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Retrieving sweep id when starting sweep from CL",
		"Question_link": "https://community.wandb.ai/t/retrieving-sweep-id-when-starting-sweep-from-cl/2921",
		"Question_created_time": "2022-08-13T13:58:59.209Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 217,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I start a sweep from the command line (<code>wandb sweep config.yaml</code>). The sweep ID is now displayed (<code>wandb: Created sweep with ID: 6bb3459a</code>), but I would like to get it programatically, such that I can later start agents automatically without copy-pasting the ID.</p>\n<p>Is there a way to achieve this?</p>\n<p>Thanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-17T20:52:11.114Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/bask0\">@bask0</a> ,  we currently do not have the equivalent of <code>api.sweeps()</code> built into our API. This is being integrated for future releases. At this time, specific sweeps functionality via the API can be found <a href=\"https://docs.wandb.ai/guides/track/public-api-guide#get-runs-from-a-specific-sweep\">here</a>. I attached your inquiry to our feature request system. Once it\u2019s been implemented we will let you know.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-18T09:00:14.054Z",
				"Answer_body": "<p>Thanks <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> ! For those looking for a temporary solution: for now, I direct the output to a file and grab the ID from there.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-17T09:00:32.721Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Subset of list of values as hyperparameters",
		"Question_link": "https://community.wandb.ai/t/subset-of-list-of-values-as-hyperparameters/2934",
		"Question_created_time": "2022-08-15T13:46:08.207Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 400,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I\u2019m currently training a object detection model and wanted to use sweeps to do some hyperparameter optimization. A few of the hyperparameters are in the form of lists. E.g: data_preprocessors: [\u201crandom-flip\u201d, \u201crandom-crop\u201d, \u201crandom-expand\u201d, etc.]</p>\n<p>I would like sweep to take a subset from these values and pass them to my training script. However I could not find how to do this easily without a lot of custom wrapping code.<br>\nMy current solution would be to have each value as a boolean and add some custom logic to convert that to the list I want, however this is not easily expandable/reusable. Is there something I am missing?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-17T19:46:23.110Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dikvangenuchten\">@dikvangenuchten</a>,</p>\n<p>You seem to have a good idea for this. Assuming you set up your sweep with these parameters like this:</p>\n<pre data-code-wrap=\"yaml\"><code class=\"lang-nohighlight\">random_flip:\n    values:\n        - True\n        - False\nrandom_crop:\n    values:\n        - True\n        - False\nrandom_expand:\n    values:\n        - True\n        - False\n</code></pre>\n<p>A sample config would look as follows:</p>\n<pre><code class=\"lang-python\">{\n    \"random_flip\" : True,\n    \"random_crop\" : False,\n    \"random_expand\" : True\n}\n</code></pre>\n<p>You should be use these boolean values as <code>wandb.config['random_crop']</code> in order to get your desired output.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-23T04:57:22.636Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dikvangenuchten\">@dikvangenuchten</a>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-26T18:09:25.188Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dikvangenuchten\">@dikvangenuchten</a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-16T19:46:28.463Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Multiple tables",
		"Question_link": "https://community.wandb.ai/t/multiple-tables/2856",
		"Question_created_time": "2022-08-06T00:09:11.959Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 227,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I know how to create a table with a data frame programmatically. However, I have two data frames, and they have different number of rows, so I cannot combine them into a single data frame. How do I upload two different tables to a Weights&amp;Biases project? Somehow, I suspect that the following is not the correct approach:</p>\n<pre><code class=\"lang-python\">    train_df = pd.DataFrame({\n        'tx':train_x,\n        'ty':train_y,\n    })\n    valid_df = pd.DataFrame({\n        'vx':valid_x,\n        'vy':valid_y\n    })\n\n    # How to add multiple tables\n\n    wandb.log({\"table\": train_df}, commit=False)\n    wandb.log({\"table\": valid_df}, commit=False)\n</code></pre>\n<p>Any help is greatly appreciated.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-10T21:27:09.977Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/erlebacher\">@erlebacher</a> , see <a href=\"https://docs.wandb.ai/guides/data-vis/log-tables#create-tables\">this document</a> on how to create tables from dataframes and please let me know if you have any questions.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-08-17T08:38:02.302Z",
				"Answer_body": "<p>HI <a class=\"mention\" href=\"/u/erlebacher\">@erlebacher</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-16T08:38:25.554Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Graphs out of sync with each other",
		"Question_link": "https://community.wandb.ai/t/graphs-out-of-sync-with-each-other/2803",
		"Question_created_time": "2022-07-26T19:42:09.811Z",
		"Question_answer_count": 9,
		"Question_score_count": 0,
		"Question_view_count": 208,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>This happens to multiple users on other projects as well, not just me. If you look at the graphs here, as an example (<a href=\"https://wandb.ai/kaiyotech/KaiBumBot?workspace=user-kaiyotech\" class=\"inline-onebox\">Weights &amp; Biases</a>) you can see that if you move your mouse to the right side of the graph, they show different steps, so they\u2019re not in sync with each other. This makes it really complicated to actually nicely figure out what\u2019s happening with a run, and makes some graphs out of date with others. Occasionally the screen will refresh and some graphs will change to be more in date and others will move out of date, it seems random.</p>\n<p>Is there something I can do about this?</p>\n<p>Thanks,<br>\nKai</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-28T21:55:19.784Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kaiyotech\">@kaiyotech</a> ,</p>\n<p>I\u2019m not sure I completely understand the issue here, could you help me understand a little bit further? A screen recording might be a little more helpful to understand this.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-01T14:16:57.137Z",
				"Answer_body": "<p>Do you, by any chance,  log all this metrics in different <code>wandb.log(...)</code> calls?</p>\n<p>Everytime you call this function the step counter is updated, If you were to call a single <code>wandb.log(...)</code> with all your metrics it would solve your issue.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-02T13:20:59.441Z",
				"Answer_body": "<p>Here\u2019s a screenshot that shows it. The only thing a video would show is that sometimes the screen refreshes and these numbers change, but they\u2019re often not all in sync (sometimes they are though, especially early on in a run when steps is lower). You can see that 9790 is my actual latest step, but all my graphs are various amounts behind that.</p>\n<p>The code is done with multiple logger.log() calls but all with commit=False until the last one so it commits all at once.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/3e655b4fbfd518ee71a71cfa68f5c1c749ffeabc.png\" data-download-href=\"/uploads/short-url/8TYL34QucP5iOAcPdL9aUWIZTyc.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3e655b4fbfd518ee71a71cfa68f5c1c749ffeabc_2_690x280.png\" alt=\"image\" data-base62-sha1=\"8TYL34QucP5iOAcPdL9aUWIZTyc\" width=\"690\" height=\"280\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3e655b4fbfd518ee71a71cfa68f5c1c749ffeabc_2_690x280.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3e655b4fbfd518ee71a71cfa68f5c1c749ffeabc_2_1035x420.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3e655b4fbfd518ee71a71cfa68f5c1c749ffeabc_2_1380x560.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3e655b4fbfd518ee71a71cfa68f5c1c749ffeabc_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1582\u00d7642 77.7 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-10T17:29:03.546Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kaiyotech\">@Kaiyotech</a>!</p>\n<p>Am I correct in assuming that these charts do update eventually to the correct step? There is a few things that can cause an error here:</p>\n<ul>\n<li>Each call to <code>wandb.log</code> counts as one step, so the graphs will not be the exact same step value unless logged together as:</li>\n</ul>\n<pre data-code-wrap=\"python3\"><code class=\"lang-nohighlight\">wandb.log({\n    stat/average_boost : &lt;VALUE&gt;,\n    stat/distance_to_bal: &lt;VALUE&gt;,\n    stat/average_demos: &lt;VALUE&gt;,\n    ...\n})\n</code></pre>\n<ul>\n<li>Additionally, I see that you are using <code>commit = False</code>. <code>commit = False</code> makes it such that the step value is not incremented when <code>log</code> is called, so the <code>step</code> counter has to be managed manually, otherwise there is a chance that some of your data is being overwritten. This also might be making your graphs look like they are out of sync.</li>\n</ul>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-10T19:29:37.776Z",
				"Answer_body": "<p>I think eventually they\u2019ll sync up maybe? I\u2019m honestly not sure. I just went and looked and they\u2019re still out of sync by about 10 steps or so. They do all keep moving, even if some are behind, if that makes sense.</p>\n<p>All calls that have <code>commit=False</code> has the step <code>step=iteration</code> and then the final one without commit doesn\u2019t have the step either, so it\u2019s automatic.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-16T23:26:44.604Z",
				"Answer_body": "<p>There is a good chance that your code is working correctly then, and just has some lag. This could be for multiple reasons:</p>\n<ul>\n<li>If you are logging a lot of metrics in quick succession, we usually store them in a queue and bundle them up before sending them over to our servers, this is reduce the number of inbound network requests to the server and ensure server health.</li>\n<li>Network lag usually plays a role in how metrics are shown.</li>\n<li>Since you are using <code>commit=False</code>, this would also add some delay to your metrics.</li>\n</ul>\n<p>I would suggest ensuring that all your metrics are being logged by printing them to the console as well, since there is a good chance there is no bug here.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-22T19:54:57.439Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kaiyotech\">@kaiyotech</a>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-25T21:05:46.205Z",
				"Answer_body": "<p>Hi Kaiyotech, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-15T23:27:29.735Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb Sweep running bash scripts",
		"Question_link": "https://community.wandb.ai/t/wandb-sweep-running-bash-scripts/2895",
		"Question_created_time": "2022-08-10T21:12:38.652Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 89,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I\u2019d like to use Wandb sweep but running different parameter settings with bash. Is it possible?<br>\nOr I have to have a python file as entry point to parse the parameters and execute bash from python.</p>\n<p>Thanks,</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-11T19:18:02.209Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevindong\">@kevindong</a>,</p>\n<p>This should be possible, I was able to set up a sweep config which can run a bash shell:</p>\n<pre><code class=\"lang-auto\">program: main.sh\nmethod: random\nmetric:\n  name: validation_loss\n  goal: minimize\nparameters:\n  learning_rate:\n    min: 0.0001\n    max: 0.1\n  optimizer:\n    values: [\"adam\", \"sgd\"]\ncommand:\n  - ${env}\n  - bash\n  - ${program}\n  - ${args}\n</code></pre>\n<p>However, there is no equivalent of  <code>wandb.log</code> for bash, so there is no way to communicate any data back to W&amp;B.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-12T23:26:08.418Z",
				"Answer_body": "<p>Thanks Ramit. your code above works.</p>\n<p>However, if I use bash script as the ${program}, it seems the wandb server can\u2019t know if the run is successful or not. All runs started in such a way will end up as \u201cCrashed\u201d state in the sweep table on the webapp</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-12T23:28:25.171Z",
				"Answer_body": "<p>How does Wandb determine the status code?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-16T23:20:20.207Z",
				"Answer_body": "<p>Hey Kevin,</p>\n<p>W&amp;B will not be able to send off a status code if you are operating directly through bash - the exit code is communicated to our servers through <code>wandb.finish</code>, which is written for python.</p>\n<p>You might want to set up an entrypoint through python and run your bash script through there if you are looking to interact with W&amp;B more.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-22T20:38:41.673Z",
				"Answer_body": "<p>Hi Kevin,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-25T22:11:09.231Z",
				"Answer_body": "<p>Hi Kevin, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-15T23:20:34.801Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Save multiindex dataframes",
		"Question_link": "https://community.wandb.ai/t/save-multiindex-dataframes/2913",
		"Question_created_time": "2022-08-12T09:22:03.520Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 265,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Is it possible to log a multiindex pandas dataframe?</p>\n<p>In addition, is it possible to save a pandas dataframe with the names of the rows? Even though my dataframe has names in the rows, in the UI I see a linear index.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-16T00:16:40.732Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/george-ai2c\">@george-ai2c</a>,</p>\n<p>Unfortuately not at the moment. Tables, as they are implemented right now only support sequential integer indexes.</p>\n<p>We have plans to implement more complex indexing in the future, such as objects as indices and multi-indices, but these features are not available right now.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-15T00:17:40.327Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Taking a long time to download artifact of only 300mb",
		"Question_link": "https://community.wandb.ai/t/taking-a-long-time-to-download-artifact-of-only-300mb/2909",
		"Question_created_time": "2022-08-11T15:18:52.264Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 60,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Its taking ages to download an artifact of only 300mb. Its there anyway to enable parallel download ? add multiprocessing ?</p>\n<p>wandb: Downloading large artifact Data-Split-802020:v0, 303.21MB. 148470 files\u2026</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-15T22:34:21.610Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/usman94\">@usman94</a> , we are actively focusing/working on improving the performance of Artifact uploads/downloads. There isn\u2019t an ability to split up and artifact when downloading it. This is under consideration for implementation. Once the engineering team has provided an update, I will let you know.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-14T22:34:53.434Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Is it possible to invert the logged images?",
		"Question_link": "https://community.wandb.ai/t/is-it-possible-to-invert-the-logged-images/2907",
		"Question_created_time": "2022-08-11T13:18:47.393Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 130,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>is it possible to invert my logged images ? Or is there maybe a way to do that in pytorch ?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-15T21:10:22.932Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sophie_jo\">@sophie_jo</a> ,</p>\n<p>There isn\u2019t an ability to invert images directly from the UI. You are correct that this can be done in <a href=\"https://pytorch.org/vision/stable/generated/torchvision.transforms.functional.invert.html\" rel=\"noopener nofollow ugc\">pytorch</a>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-14T21:10:34.462Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Unable to login using wandb local",
		"Question_link": "https://community.wandb.ai/t/unable-to-login-using-wandb-local/2868",
		"Question_created_time": "2022-08-09T15:41:53.918Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 185,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Python: 3.9.7<br>\nwandb: 0.12.17<br>\nOS: Ubuntu 20.04.4 LTS</p>\n<p>Yesterday (08 Aug) I was able to login and view my training artifacts using <code>wandb local</code>. However, today I am unable to do so. Here are the commands I run:</p>\n<pre><code class=\"lang-auto\">conda activate my_env\nwandb local\n</code></pre>\n<p>I then navigate in my browser to <code>localhost:8080</code>. I\u2019m taken to a page that says \u201cDeveloper Tools for Deep Learning\u201d and click the Login button in the upper right corner. The url is redirected to <code>http://localhost:8080/login?local=true</code> and I am presented with the login fields. I login using the same credentials I used yesterday (and the same ones that gave me access to the wandb forum and the ability to make this post), but  get an error saying \u201cInvalid password\u201d.</p>\n<p>I tried resetting the password but I get another error that says \u201cError while trying to reset password\u201d.</p>\n<p>Any thoughts about what might be going on? If need be, I\u2019m fine with completely wiping the user account and starting over as I don\u2019t have anything of real value uploaded. Thanks in advance for your help!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-11T23:49:48.239Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/aclifton314\">@aclifton314</a> .  Perform the following  from your terminal to reset your local instance password and attempt to login again.</p>\n<pre><code class=\"lang-auto\">docker exec -ti wandb-local bash\n/usr/local/bin/local password &lt;admin_email@domain.com&gt;\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-15T17:22:01.556Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a>  Thank you for your response! I posted this same issue on the wandb github. Here is the link: <a href=\"https://github.com/wandb/wandb/issues/4080\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">[App]: Credentials rejected when signing into localhost:8080 for wandb local \u00b7 Issue #4080 \u00b7 wandb/wandb \u00b7 GitHub</a>. I\u2019ll continue to post on the github as they recommend a similar potential solution.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-15T19:10:27.948Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/aclifton314\">@aclifton314</a> , great, thank-you for the update. I will mark this resolved on my end. The steps Frida recommended are exactly what you should do. Cheers!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-14T19:11:01.496Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How can I move a run from one project to another?",
		"Question_link": "https://community.wandb.ai/t/how-can-i-move-a-run-from-one-project-to-another/2900",
		"Question_created_time": "2022-08-11T07:15:21.472Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 118,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>The runs on two projects share all the same parameters, I maybe accidently create two projects, now I want to aggregate the two projects to one, is there any way I can do this?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-15T02:35:37.867Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/junyi42\">@junyi42</a>,</p>\n<p>Yup! You can move runs to another project through the runs table. <a href=\"https://docs.wandb.ai/ref/app/features/teams#move-runs-to-a-team\">Here</a> is a quick tutorial on how to do this.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-14T02:36:07.554Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Axis scales",
		"Question_link": "https://community.wandb.ai/t/axis-scales/2892",
		"Question_created_time": "2022-08-10T17:44:01.068Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 62,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I have created 100 runs, and would like to make two scatter plots. The first scatter plot involves the first 50 simulations, with axis limits [0,10] in both directions. The second scatter plot uses simulations 51 to 100, with different axis limits, say [10,20]. So far, I created a new panel, for both these plots. But wandb does not like that. Whatever I set the axis limits will be the same for both subsets (1-50, and 51-100). What is the recommended approach to have a plot for each of the data subsets? Must I create two different panels? If so, that means that one panel 2 might have to be turned off for the first batch of data experiments, and panel 1 would be turned off for the second batch of experiments. Is this the recommended approach? Thanks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-12T22:11:24.524Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/erlebacher\">@erlebacher</a>,</p>\n<p>Have you tried creating reports with different panel plots? They should work here.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-10-11T22:12:16.871Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb sweep project always getting created in a specific team",
		"Question_link": "https://community.wandb.ai/t/wandb-sweep-project-always-getting-created-in-a-specific-team/2887",
		"Question_created_time": "2022-08-10T12:26:32.672Z",
		"Question_answer_count": 2,
		"Question_score_count": 1,
		"Question_view_count": 143,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Following is my simple Python code along with the sweep.yaml file I am using:</p>\n<pre><code class=\"lang-auto\">import wandb\nwandb.init(\n    entity=\"kanishkanarch\", \n    project=\"wandb-sweep-testing\", \n    name=\"my_first_sweep\"\n)\nconfig = wandb.config\nseed = config.seed\nsum = 0 \nsum += seed\n</code></pre>\n<pre><code class=\"lang-auto\">program: testing.py\nmethod: random\nmetric:\n  name: sum \n  goal: maximize\nparameters:\n  seed:\n    min: 1\n    max: 10\n</code></pre>\n<p>I created a public project on my personal wandb page by the name <code>wandb-sweep-testing</code> but whenever I run <code>wandb sweep sweep.yaml</code> file it shows that the project is getting created in another team that I am part of.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/ffd3fc04357ae6289f8d318afb8f06375cc7e20b.png\" data-download-href=\"/uploads/short-url/Av9VD7f5wslMTylimEN27Ms3Qsb.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ffd3fc04357ae6289f8d318afb8f06375cc7e20b_2_690x74.png\" alt=\"image\" data-base62-sha1=\"Av9VD7f5wslMTylimEN27Ms3Qsb\" width=\"690\" height=\"74\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ffd3fc04357ae6289f8d318afb8f06375cc7e20b_2_690x74.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ffd3fc04357ae6289f8d318afb8f06375cc7e20b_2_1035x111.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/ffd3fc04357ae6289f8d318afb8f06375cc7e20b.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ffd3fc04357ae6289f8d318afb8f06375cc7e20b_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1115\u00d7120 62.7 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>How can I make a project on my personal profile not on my team\u2019s profile?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-12T19:34:48.815Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kanishkanarch\">@kanishkanarch</a>,</p>\n<p>You should be able to set all runs to log to your personal account through the settings page here : <a href=\"http://wandb.ai/settings\" class=\"inline-onebox\">Weights &amp; Biases</a> under Project Defaults &gt; Default Location to create new projects.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-11T19:34:58.348Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Key Error in wandb.config when using wandb.sweep in pytorch",
		"Question_link": "https://community.wandb.ai/t/key-error-in-wandb-config-when-using-wandb-sweep-in-pytorch/2898",
		"Question_created_time": "2022-08-11T05:43:04.671Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 156,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am trying to run this codebase <a href=\"https://github.com/devzhk/LMCTS\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">GitHub - devzhk/LMCTS</a>. To run hyperparameter sweep, I ran the following:</p>\n<pre><code class=\"lang-auto\">wandb sweep sweep/simulation/linear-lmcts.yaml\nwandb agent [agent id]\n</code></pre>\n<p><a href=\"https://github.com/devzhk/LMCTS/blob/master/sweep/simulation/linear-lmcts.yaml\" rel=\"noopener nofollow ugc\">The config file</a> seems to have the same style as the sweep tutorial in W&amp;B website has. However, when I run sweep command as above, I get the following error</p>\n<pre><code class=\"lang-auto\">2022-08-10 02:12:55,113 - wandb.wandb_agent - INFO - Running runs: []\n2022-08-10 02:12:55,352 - wandb.wandb_agent - INFO - Agent received command: run\n2022-08-10 02:12:55,362 - wandb.wandb_agent - INFO - Agent starting run with config:\n\tT: 10000\n\talgo: LMCTS\n\tbeta_inv: 0.0001\n\tdatapath: data/gaussian50-20-1-1.pt\n\tdim_context: 20\n\tfunc: linear\n\tlr: 0.1\n\tmodel: linear\n\tnum_arm: 50\n\tnum_iter: 70\n\tsigma: 0.5\n2022-08-10 02:12:55,372 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python3 run_simulation.py\n2022-08-10 02:13:00,385 - wandb.wandb_agent - INFO - Running runs: ['ngxmksza']\n/home/mila/i/ishfaqha/code/LMCTS/LCMTS/lib/python3.7/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  dtype=np.int):\nRandom seed: 720\nTraceback (most recent call last):\n  File \"run_simulation.py\", line 107, in &lt;module&gt;\n    run(config, args)\n  File \"run_simulation.py\", line 41, in run\n    data = torch.load(config['datapath'])\nKeyError: 'datapath'\n\n</code></pre>\n<p>Shouldn\u2019t it automatically parse the config?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-11T16:36:38.330Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hmishfaq\">@hmishfaq</a> , followed up on this in the git thread as well. You are correct that wandb will automatically parse the config. In line <a href=\"https://github.com/devzhk/LMCTS/blob/97114fc7a2160ba5d45c9ef483d2284497f81be6/run_simulation.py#L27\" rel=\"noopener nofollow ugc\">27</a> of <code>run_simulation.py</code>  ,the condition <code>if args.log and wandb</code> isn\u2019t satisfied as the default <code>fixed-linear-lmcts.yaml</code> <a href=\"https://github.com/devzhk/LMCTS/blob/master/sweep/simulation/linear-lmcts.yaml\" rel=\"noopener nofollow ugc\">file</a> doesn\u2019t include the command <code>- log</code> , thus wandb init is never called. See the <a href=\"https://github.com/devzhk/LMCTS/blob/master/README.md\" rel=\"noopener nofollow ugc\">LMCTS README.md</a> for more info</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-10T16:37:09.636Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Cannot join team via invite",
		"Question_link": "https://community.wandb.ai/t/cannot-join-team-via-invite/2905",
		"Question_created_time": "2022-08-11T13:10:58.030Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 61,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi!</p>\n<p>I can\u2019t join team after accepting the invite, only receive message \u201cReceived an invite but still can\u2019t see the team? Make sure you are logged in with the email where you received the invite.\u201d, but I already logged with that email.</p>\n<p>Best regards,<br>\nBohdan</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-15T14:52:04.330Z",
				"Answer_body": "<p>Hi Bohdan, can you tell me the team name you are trying to join? I see that your account is already associated with a team.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-18T16:59:28.610Z",
				"Answer_body": "<p>Hi Bohdan, I\u2019m just checking in to see if you still need help here?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-23T22:50:56.989Z",
				"Answer_body": "<p>Hi Bohdan, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-10T13:11:13.562Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Multiple teams",
		"Question_link": "https://community.wandb.ai/t/multiple-teams/2903",
		"Question_created_time": "2022-08-11T13:00:38.615Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 70,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I could not find the answer to the following question. I work in an academic environment and have a single use free W&amp;B account. I would like to create multiple teams. Is this possible? Thanks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-15T14:40:33.342Z",
				"Answer_body": "<p>Hi Gordon,</p>\n<p>Academics are only allowed limited to have one team. Let me know if you have any other questions.</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-18T17:00:04.972Z",
				"Answer_body": "<p>Hi Gordon, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-10T13:01:11.336Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Duplicating a project?",
		"Question_link": "https://community.wandb.ai/t/duplicating-a-project/2866",
		"Question_created_time": "2022-08-09T11:23:56.077Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 62,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>It would be super useful to be able to  duplicate a project, in order to have a \u2018benchmark/control project\u2019 on top of which I can do experiments.</p>\n<p>Is this possible?</p>\n<p>Many thanks<br>\nHarry</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-11T07:44:13.449Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/idk\">@idk</a>  cloning a project and using it as a template is not possible today. There is a feature request out for this that team is considering.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-10T07:44:41.541Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb.log inconsistent behavior with step parameter",
		"Question_link": "https://community.wandb.ai/t/wandb-log-inconsistent-behavior-with-step-parameter/2771",
		"Question_created_time": "2022-07-19T02:13:54.539Z",
		"Question_answer_count": 7,
		"Question_score_count": 1,
		"Question_view_count": 183,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Why does these code snippets produce different results?</p>\n<pre><code class=\"lang-auto\">for i in range(100):\n    wandb.log({\"train/loss\": i}, step=i)\n    \nfor i in range(100):\n    wandb.log({\"val/loss\": i**2}, step=i)\n</code></pre>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://wandb.ai/dminn/WandbHelp/runs/ioofli05?workspace=user-dminn\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/18b592222b97bc09df3743831bb4929dec23611c.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https://wandb.ai/dminn/WandbHelp/runs/ioofli05?workspace=user-dminn\" target=\"_blank\" rel=\"noopener\">W&amp;B</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/626b9c1d1ceb6cb5d3bb90cf6ab8d2894a6b8b14.png\" class=\"thumbnail onebox-avatar\" width=\"128\" height=\"128\">\n\n<h3><a href=\"https://wandb.ai/dminn/WandbHelp/runs/ioofli05?workspace=user-dminn\" target=\"_blank\" rel=\"noopener\">dminn</a></h3>\n\n  <p>Weights &amp; Biases, developer tools for machine learning</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<pre><code class=\"lang-auto\">for i in range(100):\n    wandb.log({\"train/loss\": i}, step=i)\n    wandb.log({\"val/loss\": i**2}, step=i)\n</code></pre>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://wandb.ai/dminn/WandbHelp/runs/146hdnar?workspace=user-dminn\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/18b592222b97bc09df3743831bb4929dec23611c.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https://wandb.ai/dminn/WandbHelp/runs/146hdnar?workspace=user-dminn\" target=\"_blank\" rel=\"noopener\">W&amp;B</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/626b9c1d1ceb6cb5d3bb90cf6ab8d2894a6b8b14.png\" class=\"thumbnail onebox-avatar\" width=\"128\" height=\"128\">\n\n<h3><a href=\"https://wandb.ai/dminn/WandbHelp/runs/146hdnar?workspace=user-dminn\" target=\"_blank\" rel=\"noopener\">dminn</a></h3>\n\n  <p>Weights &amp; Biases, developer tools for machine learning</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-20T19:14:35.236Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/dminn\">@dminn</a>, thanks for flagging this. I\u2019ll check internally on what\u2019s causing this issue and get back to you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-21T13:55:33.624Z",
				"Answer_body": "<p>As far as I understand the step variable, once the step is incremented, the value is stored immutably. So, if chronologically, you execute:</p>\n<pre><code class=\"lang-python\">\nwandb.log({'potato': 1}, step=0}\nwandb.log({'tomato': 1}, step=0}\nwandb.log({'potato': 2}, step=1}\nwandb.log({'tomato': 2}, step=1}\n\n</code></pre>\n<p>It\u2019ll be fine but instead if you execute:</p>\n<pre><code class=\"lang-python\">\nwandb.log({'potato': 1}, step=0}\nwandb.log({'potato': 2}, step=1}\nwandb.log({'tomato': 1}, step=0}\nwandb.log({'tomato': 2}, step=1}\n\n</code></pre>\n<p>the third command (tomato = 1, step 0) will not be executed since the logger has already moved past step 0.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-07-27T01:07:39.894Z",
				"Answer_body": "<p>Thanks that makes sense, I like to keep my training/validation steps separate. Are there any solutions/plans to accommodate  metrics with different steps aside from storing the different steps as a dictionary.</p>\n<p>e.g.</p>\n<pre><code class=\"lang-auto\">for i in range(100):\n    wandb.log({\"potato\": i, \"step\": i})\n    \nfor i in range(100):\n    wandb.log({\"tomato\": i**2, \"step\": i})\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-01T20:45:49.418Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/dminn\">@dminn</a>, correctly pointed out by <a class=\"mention\" href=\"/u/geraltofrivia783\">@geraltofrivia783</a> , as soon you call <code>wandb.log()</code> with a different value for step than the previous one, W&amp;B will write all the collected keys and values to the history, and start collection over again. Therefore, <code>wandb.log</code> doesn\u2019t let you write to any history step that you\u2019d like, only the \u201ccurrent\u201d one and the \u201cnext\u201d one.<br>\nAs a potential workaround/solution, you can <a href=\"https://docs.wandb.ai/guides/track/log#customize-axes\">make use of <code>define_metric</code></a> which will meet your needs for this use-case.</p>\n<p>For example, you can update your script to</p>\n<pre><code class=\"lang-auto\"># define your custom x axis metric\nwandb.define_metric(\"custom_step\")\n\n# define which metrics will be plotted against it\nwandb.define_metric(\"potato\", step_metric=\"custom_step\")\nwandb.define_metric(\"tomato\", step_metric=\"custom_step\")\n\n...\n\nfor i in range(100):\n  log_dict = {\n      \"custom_step\": i,\n      \"potato\": i,\n  }\n  wandb.log(log_dict)\n\n...\n\nfor i in range(100):\n  log_dict = {\n      \"custom_step\": i,\n      \"tomato\": i**2,\n  }\n  wandb.log(log_dict)\n</code></pre>\n<p>Hope this helps.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-05T05:25:05.941Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dminn\">@dminn</a> , I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-10T17:11:54.127Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dminn\">@dminn</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-09T17:12:21.438Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to start? No knowledge no skill in AI or ML",
		"Question_link": "https://community.wandb.ai/t/how-to-start-no-knowledge-no-skill-in-ai-or-ml/2876",
		"Question_created_time": "2022-08-09T21:27:28.945Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 249,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi every one, i am a pure pure beginner in AI  and this forum can you tell me where should i go to learn basics of ML?<br>\nBecause i saw 2min Paper  telling the audience that People like me are welcomed!<br>\nThank you very much!<br>\nEro</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-08T21:27:45.576Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Boolean variables",
		"Question_link": "https://community.wandb.ai/t/boolean-variables/2874",
		"Question_created_time": "2022-08-09T20:25:47.423Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 72,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am performing a hyperparameter sweep, and all is going well, except for an issue involving Boolean variables.<br>\nVariables that are True or False, do not appear as such in the run tables. Here are some images to demonstrate.<br>\nInstead, there are little horizontal dashes. So my question is whether one can include \u201cTrue/False\u201d values for variables in configurations, and if so, how do they appear in the run tables displayed on <a href=\"http://wandb.ai\">wandb.ai</a>?  Thanks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-12T15:28:25.344Z",
				"Answer_body": "<p>Hi Gordon, thank you for writing in! Can you attach the images so I can see what the issue you are running into is? Also, can you add a link to your project page, please?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-17T23:32:09.886Z",
				"Answer_body": "<p>Hi again Gordon! Do you still need help here?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-23T14:19:17.766Z",
				"Answer_body": "<p>Hi Gordon, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-08T20:26:15.576Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Reverse deleted projects",
		"Question_link": "https://community.wandb.ai/t/reverse-deleted-projects/2872",
		"Question_created_time": "2022-08-09T18:27:47.533Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 289,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey,<br>\nWondering is there anyway to restore deleted projects with artifacts ?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-10-08T18:28:07.634Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "White screen crash",
		"Question_link": "https://community.wandb.ai/t/white-screen-crash/2862",
		"Question_created_time": "2022-08-09T04:48:35.949Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 63,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>If I login <a href=\"http://wandb.ai\">wandb.ai</a>, the website does not respond and just show white screen\u2026</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/0fd3ec49a644267b723ce3a0df7d09acd227e45f.png\" data-download-href=\"/uploads/short-url/2g1cHYijVLuymAZWY8CC8f6Kqon.png?dl=1\" title=\"\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2022-08-09 \u110b\u1169\u1112\u116e 1.46.50\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0fd3ec49a644267b723ce3a0df7d09acd227e45f_2_690x388.png\" alt=\"\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2022-08-09 \u110b\u1169\u1112\u116e 1.46.50\" data-base62-sha1=\"2g1cHYijVLuymAZWY8CC8f6Kqon\" width=\"690\" height=\"388\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0fd3ec49a644267b723ce3a0df7d09acd227e45f_2_690x388.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0fd3ec49a644267b723ce3a0df7d09acd227e45f_2_1035x582.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0fd3ec49a644267b723ce3a0df7d09acd227e45f_2_1380x776.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0fd3ec49a644267b723ce3a0df7d09acd227e45f_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2022-08-09 \u110b\u1169\u1112\u116e 1.46.50</span><span class=\"informations\">5120\u00d72880 363 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Any help is greatly appreciated.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-09T04:49:46.770Z",
				"Answer_body": "<p>Hi Seunghwan,</p>\n<p>I\u2019m sorry about that, we are currently fixing a frontend issue and it should be fixed within the next hour.</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-09T05:11:08.891Z",
				"Answer_body": "<p>Thank you for your prompt response!!!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-09T05:24:54.925Z",
				"Answer_body": "<p>You\u2019re welcome! And thank you for being patient with us <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"> Everything should be up and running now, but please let me know if you\u2019re still experiencing this</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-08T05:11:35.309Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Add a default sweep plot?",
		"Question_link": "https://community.wandb.ai/t/add-a-default-sweep-plot/2854",
		"Question_created_time": "2022-08-05T00:22:26.380Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 239,
		"Question_has_accepted_answer": false,
		"Question_body": "<p><strong>Context</strong>: In my project, I am performing benchmarking on a lot of datasets and therefore need to perform a lot of sweeps.</p>\n<p><strong>Problem</strong>:  I have some custom metrics that I wish to plot together to quickly review the performance of the different runs in the sweep in a specific way. This means for each sweep I need to recreate the plot which is frustrating.</p>\n<p><strong>Question</strong>: Is there a way of adding a custom default plot setup in the sweep workspace?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-08T23:57:39.642Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/jahanpd\">@jahanpd</a> , thank-you for writing in. At this time there isn\u2019t a method for creating a default parallel coordinate plot for sweeps across your entire workspace. However, you can generate a <a href=\"https://docs.wandb.ai/ref/app/features/custom-charts\">custom chart</a> to plot your metrics and save it as a preset to use.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-07T23:58:33.286Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Question regarding W&B server quick start",
		"Question_link": "https://community.wandb.ai/t/question-regarding-w-b-server-quick-start/2755",
		"Question_created_time": "2022-07-15T01:59:48.717Z",
		"Question_answer_count": 16,
		"Question_score_count": 0,
		"Question_view_count": 792,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>hi folks, when I was trying to follow the instructions listed in this page (<a href=\"https://docs.wandb.ai/guides/self-hosted\">https://docs.wandb.ai/guides/self-hosted</a>), I encountered an issue.  I successfully finished step1 and step 2 under section \u201cW&amp;B server quick start\u201d, however, when I was trying to do step3, it always asked me to create a new account and even I click the button \u201clog in with another account\u201d, it will directly forward me to the signup page again. So there is no chance for me to follow the instruction in step3.<br>\nAnyone encountered this issue before? Can you pls share how you fixed this issue ?</p>\n<p>Thank you !</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-15T20:45:49.854Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ez2022\">@ez2022</a> ,</p>\n<p>When attempting step 3,  what is the link you are direct to initially? When attempting to login you are directed to a new link, what is this link?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-16T04:50:46.534Z",
				"Answer_body": "<p>hi, thanks for your reply !<br>\nboth the initial link and the redirect link are the same, which is <a href=\"http://localhost:8080/signup\" rel=\"noopener nofollow ugc\">http://localhost:8080/signup</a>.<br>\nSo basically no matter what I click it will forward me to <a href=\"http://localhost:8080/signup\" rel=\"noopener nofollow ugc\">http://localhost:8080/signup</a>.<br>\nAny idea how to fix this issue ?</p>\n<p>Thank you !</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-18T22:54:17.291Z",
				"Answer_body": "<p>hi Mohammad,</p>\n<pre><code>  I just checked the page again and found there is no new comment there since my last response.  Could you pls take a look?\n</code></pre>\n<p>Thanks</p>\n<p>Edison</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-18T23:11:39.972Z",
				"Answer_body": "<p>hi, thanks for your reply !<br>\nboth the initial link and the redirect link are the same, which is <a href=\"http://localhost:8080/signup\" rel=\"noopener nofollow ugc\">http://localhost:8080/signup</a>.<br>\nSo basically no matter what I click it will forward me to <a href=\"http://localhost:8080/signup\" rel=\"noopener nofollow ugc\">http://localhost:8080/signup</a>.<br>\nAny idea how to fix this issue ?</p>\n<p>Thank you !</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-19T17:09:20.301Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ez2022\">@ez2022</a> , signup using your existing wandb cloud credentials email/username. If you otherwise are continually prompted to login and don\u2019t have one, perform the following:</p>\n<ul>\n<li>Stop and delete wandb docker container</li>\n<li>Uninstall wandb</li>\n<li>Delete <code>~/.netrc</code> file (typically found in home directory) associated with your wandb API keys</li>\n<li>Reinstall wandb and go through the <a href=\"https://docs.wandb.ai/guides/self-hosted#w-and-b-server-quickstart\">W&amp;B Server Quickstart</a> Steps again</li>\n<li>When prompted to signup, use your existing wandb email and username,</li>\n</ul>\n<p>You should now be able to access your local instance. If not, please provide a screen recording of the steps you are taking for further review.</p>\n<p>Thanks,<br>\nMohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-21T19:01:29.825Z",
				"Answer_body": "<p>hi Mohammad,</p>\n<p>I tried the solution you provided, however it still doesn\u2019t work, so I did the screen recording and sent to you via email, could you pls help take a look?</p>\n<p>Thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-22T06:33:05.240Z",
				"Answer_body": "<p>Thank you <a class=\"mention\" href=\"/u/ez2022\">@ez2022</a> , I requested access to the video via the link you provided. I will review immediately, thanks.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-22T20:28:01.734Z",
				"Answer_body": "<p>Thank you for the video <a class=\"mention\" href=\"/u/ez2022\">@ez2022</a> . Perform the following which will prompt you to input a new password. You should now be able to login directly. Please let me know if this works.</p>\n<pre><code class=\"lang-auto\">docker exec -ti wandb-local bash\n/usr/local/bin/local password &lt;user_email@domain.com&gt;\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-25T20:32:01.056Z",
				"Answer_body": "<p>hi Mohammad,   With this solution, now I can log into the system successfully.   Thanks for your kind help !</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-25T21:23:41.255Z",
				"Answer_body": "<p>Hi Mohammad,</p>\n<pre><code>So I just successfully logged into the system and generated a license key , however when I clicked the button \"Add license\" it always forwarded me to a \"403\" page and asked me to log in again and that log in button isn't working.  Could you help take a look ? Thank you !\n</code></pre>\n<p>Attached is a screenshot of the \u201c403\u201d page.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/6aed9ca9282204b1c6dbdb76df961ab839af9005.png\" data-download-href=\"/uploads/short-url/ffVGYpEF5E5LKNt04c9FODa72Pr.png?dl=1\" title=\"Screen Shot 403\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/6aed9ca9282204b1c6dbdb76df961ab839af9005_2_571x499.png\" alt=\"Screen Shot 403\" data-base62-sha1=\"ffVGYpEF5E5LKNt04c9FODa72Pr\" width=\"571\" height=\"499\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/6aed9ca9282204b1c6dbdb76df961ab839af9005_2_571x499.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/6aed9ca9282204b1c6dbdb76df961ab839af9005_2_856x748.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/6aed9ca9282204b1c6dbdb76df961ab839af9005.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/6aed9ca9282204b1c6dbdb76df961ab839af9005_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 403</span><span class=\"informations\">942\u00d7824 22.8 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-28T00:35:40.153Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ez2022\">@ez2022</a> , I\u2019m glad to hear you you were able to login successfully. This 403 error isn\u2019t directly associated with our wandb local version but rather a recent issue we had with our gmail authentication system that was fixed today. Please attempt to re login and let me know if this is still an issue.</p>\n<p>Note: We released our newest version of local, 0.16.0 today with updated features. To update run  <code>wandb server start --upgrade</code>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-29T20:42:12.311Z",
				"Answer_body": "<p>Thank you Mohammad for your  instruction and kind help !</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-29T21:15:00.663Z",
				"Answer_body": "<p>Hi Mohammad, I just upgraded wandb and retried adding the license, however, I got the same page 403 issue.</p>\n<p>Is there anything else I need to change ?</p>\n<p>Thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-03T19:46:24.915Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ez2022\">@ez2022</a> ,  we addressed an issue with our authentication server within past week. Are you still running into this?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-08T22:21:45.940Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ez2022\">@ez2022</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-07T22:22:28.471Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Mutually exclusive parameters for sweeps",
		"Question_link": "https://community.wandb.ai/t/mutually-exclusive-parameters-for-sweeps/2808",
		"Question_created_time": "2022-07-27T22:35:38.889Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 223,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Can I pass exclusive parameters for a sweep? E.g. for a particular pre-trained model, I want to try learning rate values of [0.1, 0.2]. For another model I want to use [0.3, 0.4].  if I use the sweep configuration below, then grid search will try all the four learning rate values for each model. However, for model 1 - I want to use a learning rate of 0.1, 0.2 whereas, for model2, I want to use 0.3, 0.4.</p>\n<p>project: my_project<br>\nprogram: main.py<br>\nname: grid_search<br>\nmethod: grid<br>\nparameters:<br>\nlearning_rate:<br>\nvalues: [0.1, 0.2, 0.3, 0.4]<br>\narch:<br>\nvalues: [\u2018model1\u2019, \u2018model2\u2019]</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-01T19:28:37.298Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hsingh-utd\">@hsingh-utd</a>,<br>\nAre you hoping for <code>model1</code> to always receive [0.1, 0.2] or would you like the sweep to pair [0.3, 0.4] with <code>model1</code> at some point during the sweep?</p>\n<p>For instance, you could say <code>values:{(0.1, 0.2), (0.3, 0.4)]</code> to give <code>model1</code> either one of the sets at any point.</p>\n<p>Or if you would like try different combinations of the 2 different learning rates you could use</p>\n<pre><code class=\"lang-auto\">learning_rate_1:\nvalues: [0.1, 0.2, 0.3, 0.4]\nlearning_rate_2:\nvalues: [0.1, 0.2, 0.3, 0.4]\n</code></pre>\n<p>Feel free to clarify your goal if I\u2019m not pointing you in the right direction.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-08T13:23:42.847Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hsingh-utd\">@hsingh-utd</a>, I wanted to follow up and see if you were still looking for help with this?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-07T13:24:31.482Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Combining multiple sweeps with the same name",
		"Question_link": "https://community.wandb.ai/t/combining-multiple-sweeps-with-the-same-name/2846",
		"Question_created_time": "2022-08-03T14:20:58.411Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 403,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have figured out how to do hyperparameter sweeps, and I am pleased. However, I would like to combine sweep results from multiple sweeps with the same name, and this does not appear to be possible without rerunning the simulations. If it not possible, I would like to know why not since all the information necessary to combine them is available. The runs from these multiple sweeps are all available in a single table. Thanks. Gordon.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-05T19:19:52.844Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/erlebacher\">@erlebacher</a>,</p>\n<p>We don\u2019t have a method to combine multiple sweeps, they are meant to be collections of runs on their own. However, you should be able to filter by multiple sweeps in your workspace and to get a workspace consisting runs from different sweeps.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-11T05:19:37.235Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/erlebacher\">@erlebacher</a>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-16T18:41:35.104Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/erlebacher\">@erlebacher</a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-04T19:20:42.339Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Hypersweep metric with a dictionary hierarchy",
		"Question_link": "https://community.wandb.ai/t/hypersweep-metric-with-a-dictionary-hierarchy/2839",
		"Question_created_time": "2022-08-02T18:54:35.629Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 77,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am creating hyper parameter sweeps of a linear regression problem, which has gone without a hitch so far. However, I am working to improve my skills with wand. In particular, I logged dictionaries of dictionaries. Here is an example:</p>\n<pre><code class=\"lang-python\"> wandb.log({\n    'epoch': epoch,     \n    'train':{'min_loss': t_min_loss, 'min_loss_epoch': t_min_loss_epoch},                  \n    'valid':{'min_loss': t_min_loss, 'min_loss_epoch': t_min_loss_epoch}\n  } , step=epoch, commit=True)\n</code></pre>\n<p>The metric should be the training loss. How does one specify it when using dictionary hierarchies? Have I done it correctly below?</p>\n<pre><code class=\"lang-python\"># docs: https://docs.wandb.ai/guides/sweeps/configuration\nsweep_config3 = {\n    'name' : 'broad_sweep', \n    'method' : 'random',\n    'metric' : {\n                'name': {'train': 'loss'},\n                'goal': 'minimize',\n               },\n    'parameters' : {\n        'lr' : {\n            'distribution': 'log_uniform_values',\n            'min': 1.e-3, \n            'max': 1.e-1},\n        'batch_size' : { 'value': 32 },\n        'optim' : { 'value': 'adamw' },\n        'nb_layers' : { 'values': [0, 2, 4] },\n        'pts_layer': { 'values': [5, 10, 30] },\n        'nb_epochs': { 'value': 200},\n    }\n}\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-04T23:52:12.738Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/erlebacher\">@erlebacher</a> , for your initial block of code, you can log dictionary of dictionaries just fine in a single run. However you cannot set a sweep up to optimize for multiple metrics at the same time. This will results in the following error message when attempting to do so:</p>\n<pre><code class=\"lang-auto\">wandb: WARNING Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\nwandb: WARNING To avoid this, please fix the sweep config schema violations below:\nwandb: WARNING   Violation 1. {'loss': None, 'train': None} is not of type 'string'\n</code></pre>\n<p>You will have to pass a single value in <code>metric</code> within your sweep config.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-05T02:40:29.269Z",
				"Answer_body": "<p>Thank you, <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> . I do understand the point you make. But what if in the example above, I wish the metric to be <code>min_loss</code>, defined under <code>train</code>?</p>\n<pre><code class=\"lang-python\"> wandb.log({\n    'epoch': epoch,     \n    'train':{'min_loss': t_min_loss, 'min_loss_epoch': t_min_loss_epoch},                  \n    'valid':{'min_loss': t_min_loss, 'min_loss_epoch': t_min_loss_epoch}\n  } , step=epoch, commit=True)\n</code></pre>\n<p>Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-04T02:40:54.441Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Cant see the team after accepting invite",
		"Question_link": "https://community.wandb.ai/t/cant-see-the-team-after-accepting-invite/2823",
		"Question_created_time": "2022-07-29T09:49:38.684Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 721,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi! I can\u2019t see my team after accepting the invite, it says \u201cReceived an invite but still can\u2019t see the team? Make sure you are logged in with the email where you received the invite.\u201d but it does not tell you what to do when this is already checked <img src=\"https://emoji.discourse-cdn.com/twitter/stuck_out_tongue.png?v=12\" title=\":stuck_out_tongue:\" class=\"emoji\" alt=\":stuck_out_tongue:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<p>regards<br>\nR</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-30T00:10:33.264Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/molen\">@molen</a> , it shows on our end you are already a member of the team <strong>miselbo</strong>. Do let me know if you can\u2019t access the team from your wandb profile and we will take a closer look.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-30T06:58:02.916Z",
				"Answer_body": "<p>hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> , thanks for getting back to me. the team im trying to join is <strong>calejo-dev</strong><br>\nregards<br>\nR</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-04T23:36:37.689Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/molen\">@molen</a> , I checked the <strong>calejo-dev</strong> team and you are member of it. It\u2019s listed under your teams on your profile page, <a href=\"https://wandb.ai/ricky_molen\" class=\"inline-onebox\">Weights &amp; Biases</a>. Please confirm if you can see the team as well and if you need further assistance. Thank-you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-03T23:37:27.316Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Custom Chat Application Integration",
		"Question_link": "https://community.wandb.ai/t/custom-chat-application-integration/2844",
		"Question_created_time": "2022-08-03T12:21:13.332Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 134,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I would like to get some references to integrate wandb alert to a custom chat application(discord bot or other slack like app for example). how do i go about achieving that?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-03T19:19:47.460Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sripaadsrinivasan\">@sripaadsrinivasan</a> , check out <a href=\"https://docs.wandb.ai/guides/track/alert\">this alerts document</a> for more details.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-02T19:20:04.559Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Understanding define_metric parameters",
		"Question_link": "https://community.wandb.ai/t/understanding-define-metric-parameters/2836",
		"Question_created_time": "2022-08-02T13:30:36.761Z",
		"Question_answer_count": 3,
		"Question_score_count": 2,
		"Question_view_count": 76,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I would like to understand the difference between those two function calls:</p>\n<p>I am referring to the <a href=\"https://docs.wandb.ai/guides/track/log#customize-the-summary\">documentation of define_metric</a>:</p>\n<pre data-code-wrap=\"py\"><code class=\"lang-nohighlight\">wandb.define_metric(\"acc\", summary=\"max\")\nwandb.define_metric(\"acc\", summary=\"best\", objective=\"maximize\")\n</code></pre>\n<p>Is it the \u201cbest\u201d accuracy ever measured (during training) versus the accuracy of the \u201cbest\u201d (validation) model? I understand that wandb does not care what metric I log, but what is the intended use?</p>\n<p>Thank you for clarification.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-02T14:00:10.923Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hogru\">@hogru</a>,</p>\n<p>For each metric logged, there is a summary metric that\u2019ll summarize the logged values as <em>one</em> value for each run. By default, W&amp;B uses the <em>latest</em> value, but you can update it with <code>wandb.summary['acc'] = best_acc</code> or using the two <code>define_metric</code> calls you show.</p>\n<p>This is then used to decide which value is displayed in plots that only use one value for each run (e.g. Scatter plots).</p>\n<pre><code class=\"lang-auto\">wandb.define_metric(\"acc\", summary=\"max\")\nwandb.define_metric(\"acc\", summary=\"best\", objective=\"maximize\")\n</code></pre>\n<p>These two calls are both functionally the same, one will show <code>acc.best</code> and one will show as <code>acc.max</code> in the summary metrics of your run. Both will be the maximum value that you log for <code>acc</code> like <code>wandb.log('acc':acc)</code> during a run.</p>\n<p>You can see the summary metrics of each run by clicking the <img src=\"https://emoji.discourse-cdn.com/twitter/information_source.png?v=12\" title=\":information_source:\" class=\"emoji\" alt=\":information_source:\" loading=\"lazy\" width=\"20\" height=\"20\"> icon in the top left nav bar in a run.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-08-02T15:11:02.069Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/_scott\">@_scott</a>, thank you very much for the swift and in-depth response which is always good as a confirmation of one\u2019s understanding/assumptions. I am glad that the only difference is the name of the summary metrics (<code>.best</code> vs <code>.max</code>). I worried that I missed something.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-10-01T15:11:46.430Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Artifacts logged with run_id",
		"Question_link": "https://community.wandb.ai/t/artifacts-logged-with-run-id/2759",
		"Question_created_time": "2022-07-16T15:11:27.757Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 486,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello everyone,<br>\nI am new to w&amp;b, so this might be a beginner question, but I was wondering why when I run<br>\n<code> wandb.log_artifact(file_path, name='dataset', type='dataset')</code><br>\nI am able to log artifacts correctly without many issues,  whereas if I use the example provided <a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-artifacts/Pipeline_Versioning_with_W%26B_Artifacts.ipynb#scrollTo=Mb8GiolzPgUU\" rel=\"noopener nofollow ugc\">here</a></p>\n<pre><code class=\"lang-auto\">def load_and_log():\n\n    # \ud83d\ude80 start a run, with a type to label it and a project it can call home\n    with wandb.init(project=\"artifacts-example\", job_type=\"load-data\") as run:\n        \n        datasets = load()  # separate code for loading the datasets\n        names = [\"training\", \"validation\", \"test\"]\n\n        # \ud83c\udffa create our Artifact\n        raw_data = wandb.Artifact(\n            \"mnist-raw\", type=\"dataset\",\n            description=\"Raw MNIST dataset, split into train/val/test\",\n            metadata={\"source\": \"torchvision.datasets.MNIST\",\n                      \"sizes\": [len(dataset) for dataset in datasets]})\n\n        for name, data in zip(names, datasets):\n            # \ud83d\udc23 Store a new file in the artifact, and write something into its contents.\n            with raw_data.new_file(name + \".pt\", mode=\"wb\") as file:\n                x, y = data.tensors\n                torch.save((x, y), file)\n\n        # \u270d\ufe0f Save the artifact to W&amp;B.\n        run.log_artifact(raw_data)\n\nload_and_log()\n</code></pre>\n<p>I get the artifacts stored in a run_table, and it makes versioning impossible.<br>\nAm I doing something wrong? Below you can find the same function as I modified it for my project, in case I might have missed something</p>\n<pre><code class=\"lang-auto\">from wandb.sdk import wandb_init\ndef load_and_log():\n\n    # \ud83d\ude80 start a run, with a type to label it and a project it can call home\n    with wandb.init(project=\"project\", job_type=\"load-data\", resume=\"allow\") as run:\n        \n        dataset = my_function(dir_path + '/datas', MAX_SAMPLES, MAX_LENGTH) #returns a tuple of lists\n        datasets = dataset.load()  # separate code for loading the datasets\n        names = [\"questions\", \"answers\"]\n\n        # \ud83c\udffa create our Artifact\n        raw_data = wandb.Artifact(\n            \"dataset\", type=\"dataset\",\n            description=\"json of the preprocessed dataset - not split\",\n            metadata={\"source\": \"https://source.php\",\n                      \"sizes\": [len(dataset) for dataset in datasets]})\n\n        # transfer lists into table\n        table = wandb.Table(columns=[], data=[])\n        for name, dataset in zip(names, datasets):\n          table.add_column(name=f\"{name}\", data=dataset)\n\n        # \u270d\ufe0f Save the artifact to W&amp;B.\n        wandb.log({f\"dataset_{MAX_SAMPLES}_{MAX_LENGTH}\": table})\n\nload_and_log()\n</code></pre>\n<p>Thank you in advance if you have an answer!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-20T17:40:54.801Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/guen\">@guen</a> ,</p>\n<p>In our example we are creating an artifact of the <code>Raw MNIST dataset, split into train/val/test</code>and logging it using <code>run.log_artifact(raw_data)</code>. In your code you are generating a table of your dataset and logging the Table to wandb, <code>wandb.log({f\"dataset_{MAX_SAMPLES}_{MAX_LENGTH}\": table})</code>. Is this your intended approach?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-25T23:36:59.336Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/guen\">@guen</a> ,</p>\n<p>Following up on this request. Please let us know if you have any questions on the above.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-29T17:58:15.729Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/guen\">@guen</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-27T17:58:24.360Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Update offline run before syncing",
		"Question_link": "https://community.wandb.ai/t/update-offline-run-before-syncing/2794",
		"Question_created_time": "2022-07-25T09:29:20.433Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 144,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi! During training, my script crashed unexpectedly and did not save the latest epoch information.  I restarted training without being aware of it, and now my epochs are offset by a large number.</p>\n<p>Is it possible to edit the epoch number (index) and add a certain value to each entry? I have tried opening the \u201crun_name.wandb\u201d file and I can already see the \u2018_step\u2019 variable for each entry, but I was wondering if there is a cleaner way to perform such an update.</p>\n<p>Thank you in advance for your help!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-25T20:38:33.756Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/vandrew\">@vandrew</a> , you can currently update a <a href=\"https://docs.wandb.ai/ref/python/run\">run</a> after it has logged using our <a href=\"https://docs.wandb.ai/guides/track/public-api-guide#update-metrics-for-a-run-after-the-run-has-finished\">API</a> . Would this functionality work for your intended use case?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-27T13:28:45.321Z",
				"Answer_body": "<p>Thanks for the response, <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> ! Sorry for not mentioning this yet, but the run I am trying to update is an offline run. The issue I am facing is not being able to upload it to wandb before updating it, as the two resulting wandb runs have conflicting step numbers. This would lead to overwriting some data that was logged.</p>\n<p>The <code>wandb.Api().run()</code> command seems to only take as an argument a path in the form <code>&lt;entity&gt;/&lt;project&gt;/&lt;run_id&gt;</code>, so this does not seem to help with offline runs. I have also tried initializing an empty run with <code>run = wandb.init()</code>, after which I tried changing the run directory with <code>run.dir = \"path_to_old_run\"</code>, but this was not successful.</p>\n<p>I assume there is currently no functionality to achieve this?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-28T22:36:27.071Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/vandrew\">@vandrew</a> , I understand what you are attempting to achieve now. At this time our API doesn\u2019t support offline mode to access local log files. We do have this planned as a future feature but I can\u2019t speak to a specific timeline. At this time you will have to sync your runs first in online mode, then update metrics using the API.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-09-26T22:37:14.338Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "RuntimeError: max must be larger than min SCALER",
		"Question_link": "https://community.wandb.ai/t/runtimeerror-max-must-be-larger-than-min-scaler/2796",
		"Question_created_time": "2022-07-25T11:16:28.348Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 104,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi all,<br>\nI have this weird Runtime error during training @ epoch 129.</p>\n<p>Traceback (most recent call last):<br>\nFile \u201c/home/anton/Documents/GitHub/horse2depth_Pix2Pix/train_depth_loss.py\u201d, line 715, in <br>\nFile \u201c/home/anton/Documents/GitHub/horse2depth_Pix2Pix/train_depth_loss.py\u201d, line 630, in main<br>\nFile \u201c/home/anton/Documents/GitHub/horse2depth_Pix2Pix/train_depth_loss.py\u201d, line 315, in train_fn<br>\n# g_scaler.scale(G_loss).backward()<br>\nFile \u201c/usr/anaconda3/envs/CGAN/lib/python3.10/site-packages/torch/_tensor.py\u201d, line 396, in backward<br>\ntorch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)<br>\nFile \u201c/usr/anaconda3/envs/CGAN/lib/python3.10/site-packages/torch/autograd/<strong>init</strong>.py\u201d, line 173, in backward<br>\nVariable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass<br>\nFile \u201c/usr/anaconda3/envs/CGAN/lib/python3.10/site-packages/wandb/wandb_torch.py\u201d, line 264, in <br>\nhandle = var.register_hook(lambda grad: _callback(grad, log_track))<br>\nFile \u201c/usr/anaconda3/envs/CGAN/lib/python3.10/site-packages/wandb/wandb_torch.py\u201d, line 262, in _callback<br>\nself.log_tensor_stats(grad.data, name)<br>\nFile \u201c/usr/anaconda3/envs/CGAN/lib/python3.10/site-packages/wandb/wandb_torch.py\u201d, line 213, in log_tensor_stats<br>\ntensor = flat.histc(bins=self._num_bins, min=tmin, max=tmax)<br>\nRuntimeError: max must be larger than min</p>\n<p>First time it happened.</p>\n<p>Any help?</p>\n<p>Thanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-25T20:05:13.675Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/aa_technion\">@aa_technion</a> ,</p>\n<p>It sounds to me like you may be encountering an exploding or vanishing gradient which could be leading to overflow / underflow issues. Here are some debugging steps I can suggest.</p>\n<ul>\n<li>Ensure that you\u2019re calling <code>optimizer.zero_grad()</code> before each batch</li>\n<li>Try normalizing the weights and inputs</li>\n<li>Try implementing gradient clipping.</li>\n<li>Set wandb.watch(log=None), and if your train loss becomes NaN, should be addresses by normalizing the data.</li>\n</ul>\n<p>Please let me know if any of these work for you. If they don\u2019t:</p>\n<ul>\n<li>Provide code example in the form of a colab for us to attempt to reproduce your specific issue.</li>\n<li>Additionally include the run debug logs (<code>debug.log</code> and <code>debug-internal.log</code>) for the runs that error our. They are located in <code>wandb/run-DATETIME-ID/</code> <code>logs</code> relative to your working directory,</li>\n</ul>\n<p>Thank-you,</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-28T22:13:08.580Z",
				"Answer_body": "<p>HI <a class=\"mention\" href=\"/u/aa_technion\">@aa_technion</a> ,  since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-26T22:13:09.630Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Can't associate sweeps with project",
		"Question_link": "https://community.wandb.ai/t/cant-associate-sweeps-with-project/2636",
		"Question_created_time": "2022-06-19T18:57:34.170Z",
		"Question_answer_count": 9,
		"Question_score_count": 0,
		"Question_view_count": 813,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi,</p>\n<p>I\u2019m using wandb (great product!!!) and have been able to set up projects, do runs and am now working with sweeps (FANTASTIC!). However I can\u2019t figure out how to associate my sweeps with a project.</p>\n<p>I have:</p>\n<pre><code class=\"lang-auto\">import wandb\n\nsweep_config = {\n  \"project\" : \"HDBSCAN_Clustering\",\n  \"method\" : \"random\",\n  \"parameters\" : {\n    \"min_cluster_size\" :{\n      \"values\": [*range(20,500)]\n    },\n    \"min_sample_pct\" :{\n      \"values\": [.25, .5, .75, 1.0]\n    }\n  }\n}\n</code></pre>\n<p>Then when I:</p>\n<p>sweep_id = wandb.sweep(sweep_config)</p>\n<p>I get</p>\n<p><code>Sweep URL: https://wandb.ai/teamberkeley/uncategorized/sweeps/jk9c1l8q</code></p>\n<p>Note:  teamberkeley/<em>uncategorized</em>/sweeps</p>\n<p>They are of course uncategorized in the projects interface as well.</p>\n<p>No luck with running wandb.init beforehand either thusly:</p>\n<p>wandb.init(project=\u2018HDBSCAN_Clustering\u2019)</p>\n<p>Same result (despite the fact that at this point if I do \u2018runs\u2019 with wandb they are attached to the correct project after this init). Please let me know what I\u2019m doing wrong!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-23T14:41:11.689Z",
				"Answer_body": "<p>I\u2019d really like to fix this. I\u2019m sure I\u2019m doing something wrong but after looking through the doc, following examples and googling I can\u2019t figure it out. Please help.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-23T23:04:52.042Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/drob\">@drob</a>, could you try the following?</p>\n<p>When calling <code>wandb.sweep</code>, try setting the <code>project</code> and <code>entity</code> attributes there, like:</p>\n<pre data-code-wrap=\"python3\"><code class=\"lang-nohighlight\">wandb.sweep(sweep_config, enitity='drob', project='HDBSCAN_Clustering')\n</code></pre>\n<p>Let me know how it goes.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-23T23:18:51.248Z",
				"Answer_body": "<p>Thanks very much, really appreciated.</p>\n<p>Better kinda\u2026</p>\n<p>So I added \u2018entity\u2019 and \u2018project\u2019 to wandb.sweep.</p>\n<p>First time - timed out<br>\nSecond time - seemed like it worked - I saw that the sweep url was with the correct projects\u2026 So YAY!  Then it errored out.</p>\n<p>Tried a couple more times - error, then restarted the VM (Colab+)\u2026 no luck :(.  Here\u2019s the error:</p>\n<pre><code class=\"lang-auto\">wandb: Currently logged in as: drob707 (teamberkeley). Use `wandb login --relogin` to force relogin\n\nTracking run with wandb version 0.12.19\n\nRun data is saved locally in `/content/drive/MyDrive/Projects/StepWiseTuning/wandb/run-20220623_231502-cp4idak5`\n\nSyncing run **[generous-meadow-26](https://wandb.ai/teamberkeley/HDBSCAN_Clustering/runs/cp4idak5)** to [Weights &amp; Biases](https://wandb.ai/teamberkeley/HDBSCAN_Clustering) ([docs](https://wandb.me/run))\n\nwandb: ERROR Error while calling W&amp;B API: permission denied (&lt;Response [403]&gt;)\n\n---------------------------------------------------------------------------\n\nHTTPError Traceback (most recent call last)\n\n[/usr/local/lib/python3.7/dist-packages/wandb/sdk/lib/retry.py](https://localhost:8080/#) in __call__(self, *args, **kwargs) 101 try: --&gt; 102 result = self._call_fn(*args, **kwargs) 103 # Only print resolved attempts once every minute\n\n---\n18 frames\n---\n\nHTTPError: 403 Client Error: Forbidden for url: https://api.wandb.ai/graphql\n\nDuring handling of the above exception, another exception occurred:\n\nUsageError Traceback (most recent call last)\n\nUsageError: permission denied\n\nDuring handling of the above exception, another exception occurred:\n\nCommError Traceback (most recent call last)\n\n[/usr/local/lib/python3.7/dist-packages/wandb/sdk/internal/internal_api.py](https://localhost:8080/#) in no_retry_4xx(e) 1890 return True 1891 body = json.loads(e.response.content) -&gt; 1892 raise UsageError(body[\"errors\"][0][\"message\"]) 1893 1894 # TODO(dag): replace this with a query for protocol versioning\n\nCommError: permission denied\nBut\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-27T22:04:14.148Z",
				"Answer_body": "<p>Any chance we could figure this out?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-29T20:35:49.863Z",
				"Answer_body": "<p>Hmm, that\u2019s odd. Can you share the full traceback for me to look into? From a quick glance though, I see you have an HTTP 403 (Forbidden) - are you sure you are logging to the correct entity?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-30T02:36:52.835Z",
				"Answer_body": "<p>Please see a complete traceback below.</p>\n<blockquote>\n<p>are you sure you are logging to the correct entity?</p>\n</blockquote>\n<p>I go through the authentication without a problem.</p>\n<p>I used the params that you suggested (adjusted for spelling) -</p>\n<pre><code class=\"lang-auto\">wandb.init(project='HDBSCAN_Clustering')\nsweep_id = wandb.sweep(hdbscan_config, entity='drob', project='HDBSCAN_Clustering')\n</code></pre>\n<p>I have also tried:</p>\n<pre><code class=\"lang-auto\">wandb.init(project='HDBSCAN_Clustering')\nsweep_id = wandb.sweep(hdbscan_config, entity='teamberkeley', project='HDBSCAN_Clustering')\n</code></pre>\n<p>Neither works. If I remove the \u2018entity\u2019 setting from sweep() I am definately logged in because I can execute sweeps and everything works. However, the issue is that everything winds up in \u2018uncategorized\u2019.</p>\n<p>Here is a link to my colab notebook. As you can see it is very stripped down:</p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://colab.research.google.com/drive/1YsOomYMZ0jToWpb_T-rdnIcjZgMJKwBW?usp=sharing\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/5cb5b62061baedc4f7e8e3c3086a7b516b1b7cc1.png\" class=\"site-icon\" width=\"16\" height=\"16\">\n\n      <a href=\"https://colab.research.google.com/drive/1YsOomYMZ0jToWpb_T-rdnIcjZgMJKwBW?usp=sharing\" target=\"_blank\" rel=\"noopener nofollow ugc\">colab.research.google.com</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/e2eb089e1834a0581da1d893b1624f376f01ad6a.png\" class=\"thumbnail onebox-avatar\" width=\"260\" height=\"260\">\n\n<h3><a href=\"https://colab.research.google.com/drive/1YsOomYMZ0jToWpb_T-rdnIcjZgMJKwBW?usp=sharing\" target=\"_blank\" rel=\"noopener nofollow ugc\">Google Colaboratory</a></h3>\n\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>Perhaps you could point me to code that works that does what I\u2019m trying to do?</p>\n<pre><code class=\"lang-auto\">Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to the W&amp;B docs.\nProblem at: &lt;ipython-input-13-68824eaa576c&gt; 1 &lt;module&gt;\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\", line 999, in init\n    run = wi.init()\n  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\", line 651, in init\n    backend.cleanup()\n  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/backend/backend.py\", line 246, in cleanup\n    self.interface.join()\n  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py\", line 475, in join\n    super().join()\n  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface.py\", line 666, in join\n    _ = self._communicate_shutdown()\n  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py\", line 472, in _communicate_shutdown\n    _ = self._communicate(record)\n  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py\", line 226, in _communicate\n    return self._communicate_async(rec, local=local).get(timeout=timeout)\n  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py\", line 231, in _communicate_async\n    raise Exception(\"The wandb backend process has shutdown\")\nException: The wandb backend process has shutdown\nwandb: ERROR Abnormal program exit\n---------------------------------------------------------------------------\nException                                 Traceback (most recent call last)\n/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py in init(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\n    998         try:\n--&gt; 999             run = wi.init()\n   1000             except_exit = wi.settings._except_exit\n\n8 frames\n/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py in init(self)\n    650                     # we don't need to do console cleanup at this point\n--&gt; 651                     backend.cleanup()\n    652                     self.teardown()\n\n/usr/local/lib/python3.7/dist-packages/wandb/sdk/backend/backend.py in cleanup(self)\n    245         if self.interface:\n--&gt; 246             self.interface.join()\n    247         if self.wandb_process:\n\n/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py in join(self)\n    474     def join(self) -&gt; None:\n--&gt; 475         super().join()\n    476 \n\n/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface.py in join(self)\n    665             return\n--&gt; 666         _ = self._communicate_shutdown()\n    667 \n\n/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py in _communicate_shutdown(self)\n    471         record = self._make_record(request=request)\n--&gt; 472         _ = self._communicate(record)\n    473 \n\n/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py in _communicate(self, rec, timeout, local)\n    225     ) -&gt; Optional[pb.Result]:\n--&gt; 226         return self._communicate_async(rec, local=local).get(timeout=timeout)\n    227 \n\n/usr/local/lib/python3.7/dist-packages/wandb/sdk/interface/interface_shared.py in _communicate_async(self, rec, local)\n    230         if self._process_check and self._process and not self._process.is_alive():\n--&gt; 231             raise Exception(\"The wandb backend process has shutdown\")\n    232         future = self._router.send_and_receive(rec, local=local)\n\nException: The wandb backend process has shutdown\n\nThe above exception was the direct cause of the following exception:\n\nException                                 Traceback (most recent call last)\n&lt;ipython-input-13-68824eaa576c&gt; in &lt;module&gt;()\n----&gt; 1 wandb.init(project='HDBSCAN_Clustering')\n      2 sweep_id = wandb.sweep(hdbscan_config, entity='drob', project='HDBSCAN_Clustering')\n\n/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py in init(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\n   1035             if except_exit:\n   1036                 os._exit(-1)\n-&gt; 1037             raise Exception(\"problem\") from error_seen\n   1038     return run\n\nException: problem\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-30T02:42:41.635Z",
				"Answer_body": "<p>Ahhh fixed.  The entity is \u2018drob707\u2019, not \u2018drob\u2019.  Thanks!</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-07-28T18:54:59.366Z",
				"Answer_body": "<p>sweep_id = wandb.sweep(sweep_config, project=\u201cProject Name\u201d)</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-26T18:55:53.345Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Waiting for W&B process to finish (success)",
		"Question_link": "https://community.wandb.ai/t/waiting-for-w-b-process-to-finish-success/2818",
		"Question_created_time": "2022-07-28T18:54:55.533Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 663,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>When using wandb I don\u2019t have any runs at the moment however it won\u2019t let me start any new runs. When the python script is run the bellow message is shown and the run is \u2018synced\u2019 doesn\u2019t appear to be running on the PC. I have checked the system processes and there is no instance of a wandb script running. On my wandb profile, all runs appear to be failed, finished or killed.<br>\nIs there a way to manually override this? I have tried running in offline mode and it still has no effect and I cannot test the changes to my code.</p>\n<p>EDIT: Elaborated description and provided console output:</p>\n<p>wandb: Currently logged in as: username. Use <code>wandb login --relogin</code> to force relogin</p>\n<p>wandb: Tracking run with wandb version 0.12.19</p>\n<p>wandb: Run data is saved locally in /tmp/tmpjjlzygaw/wandb/run-<br>\n20220627_121802-X_training18</p>\n<p>wandb: Run <code>wandb offline</code> to turn off syncing.</p>\n<p>wandb: Syncing run 88_DCAC_training18<br>\nwandb: <img src=\"https://emoji.discourse-cdn.com/twitter/star.png?v=12\" title=\":star:\" class=\"emoji\" alt=\":star:\" loading=\"lazy\" width=\"20\" height=\"20\"> View project at <a href=\"https://wandb.ai/username/X\" class=\"inline-onebox\">Weights &amp; Biases</a><br>\nwandb: <img src=\"https://emoji.discourse-cdn.com/twitter/rocket.png?v=12\" title=\":rocket:\" class=\"emoji\" alt=\":rocket:\" loading=\"lazy\" width=\"20\" height=\"20\"> View run at <a href=\"https://wandb.ai/username/X/runs/X_training18\" class=\"inline-onebox\">Weights &amp; Biases</a></p>\n<p>continuing\u2026</p>\n<p>wandb: Waiting for W&amp;B process to finish\u2026 (success).<br>\nwandb:<br>\nwandb: Synced X_training18: <a href=\"https://wandb.ai/lucmc/DCAC%20L-Reacher/runs/X_training18\" class=\"inline-onebox\">Weights &amp; Biases</a><br>\nwandb: Synced 6 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)<br>\nwandb: Find logs at: /tmp/tmpjjlzygaw/wandb/run-20220627_121802-X_training18/logs</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-02T15:47:50.557Z",
				"Answer_body": "<p>Hi Luc, thank you for writing in! Can you send me your debug logs? They can be found in your wandb run directory. Also, I see that you are using 0.12.19, can you update to the most recent version please and see if that\u2019s able to help?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-08T23:15:46.028Z",
				"Answer_body": "<p>Hi again Luc, was the upgrade able to help?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-12T15:32:03.317Z",
				"Answer_body": "<p>Hi Luc, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-26T18:55:53.339Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "What are your requirements for a cloud server?",
		"Question_link": "https://community.wandb.ai/t/what-are-your-requirements-for-a-cloud-server/2816",
		"Question_created_time": "2022-07-28T18:54:52.111Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 188,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Amazon Web Services (AWS) presently services over 7,500 government entities and 5000 educational institutions.</p>\n<p>If that isn\u2019t an endorsement, we don\u2019t know what is! AWS, known as one of the world\u2019s premier IT corporations, is now one of the top four public cloud computing companies in the world.</p>\n<p>Source : <a href=\"https://www.sevenmentor.com/amazon-web-services-training-institute-in-pune.php\" rel=\"noopener nofollow ugc\">AWS Course In Pune</a></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-26T18:54:55.342Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Integration of Wandb with AWS Lambda",
		"Question_link": "https://community.wandb.ai/t/integration-of-wandb-with-aws-lambda/2280",
		"Question_created_time": "2022-04-20T19:19:11.842Z",
		"Question_answer_count": 9,
		"Question_score_count": 0,
		"Question_view_count": 739,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi Community,</p>\n<p>I was trying to integrate the WandB inside the AWS lambda. The code was deployed successfully but during testing I am facing an issue with WandB.</p>\n<p>OSError: [Errno 38] Function not implemented</p>\n<p>This error is being raised by the WandB library inside the  AWS lambda. This is probably because of multiprocessing utilized by WandB.  Below are more details about the Lambda configuration and env variables:</p>\n<p><strong>CONFIGURATION:</strong><br>\nPython Version= 3.7<br>\nArchitecture = x86_64</p>\n<p><strong>ENV VARIABLES</strong><br>\nWANDB_API_KEY = Key<br>\nWANDB_CACHE_DIR= /tmp/<br>\nWANDB_CONFIG_DIR=/tmp/<br>\nWANDB_DIR=/tmp/<br>\nWANDB_SILENT=true</p>\n<p>Is there any suggestion how to deal with this bug?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-21T11:04:59.952Z",
				"Answer_body": "<p>Hey Akshey, can you send the full stack trace?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-21T13:10:59.319Z",
				"Answer_body": "<p>022-04-21T08:16:02.301-03:00</p>\n<p>wandb: WARNING Path wandb/ wasn\u2019t writable, using system temp directory.</p>\n<p>2022-04-21T08:16:02.678-03:00</p>\n<p>Problem at: /var/task/execution.py 103 lambda_handler_dummy</p>\n<p>2022-04-21T08:16:02.682-03:00</p>\n<p>Traceback (most recent call last):</p>\n<p>2022-04-21T08:16:02.683-03:00</p>\n<p>Copy<br>\nFile \u201c/var/task/wandb/sdk/wandb_init.py\u201d, line 996, in init</p>\n<p>2022-04-21T08:16:02.683-03:00</p>\n<p>run = wi.init()</p>\n<p>2022-04-21T08:16:02.683-03:00</p>\n<p>File \u201c/var/task/wandb/sdk/wandb_init.py\u201d, line 532, in init</p>\n<p>2022-04-21T08:16:02.683-03:00</p>\n<p>backend.ensure_launched()</p>\n<p>2022-04-21T08:16:02.683-03:00</p>\n<p>File \u201c/var/task/wandb/sdk/backend/backend.py\u201d, line 188, in ensure_launched</p>\n<p>2022-04-21T08:16:02.683-03:00</p>\n<p>self.record_q = self._multiprocessing.Queue()</p>\n<p>2022-04-21T08:16:02.683-03:00</p>\n<p>File \u201c/var/lang/lib/python3.7/multiprocessing/context.py\u201d, line 102, in Queue</p>\n<p>2022-04-21T08:16:02.683-03:00</p>\n<p>return Queue(maxsize, ctx=self.get_context())</p>\n<p>2022-04-21T08:16:02.683-03:00</p>\n<p>File \u201c/var/lang/lib/python3.7/multiprocessing/queues.py\u201d, line 42, in <strong>init</strong></p>\n<p>2022-04-21T08:16:02.683-03:00</p>\n<p>self._rlock = ctx.Lock()</p>\n<p>2022-04-21T08:16:02.683-03:00</p>\n<p>File \u201c/var/lang/lib/python3.7/multiprocessing/context.py\u201d, line 67, in Lock</p>\n<p>2022-04-21T08:16:02.683-03:00</p>\n<p>return Lock(ctx=self.get_context())</p>\n<p>2022-04-21T08:16:02.683-03:00</p>\n<p>File \u201c/var/lang/lib/python3.7/multiprocessing/synchronize.py\u201d, line 162, in <strong>init</strong></p>\n<p>2022-04-21T08:16:02.683-03:00</p>\n<p>SemLock.<strong>init</strong>(self, SEMAPHORE, 1, 1, ctx=ctx)</p>\n<p>2022-04-21T08:16:02.683-03:00</p>\n<p>File \u201c/var/lang/lib/python3.7/multiprocessing/synchronize.py\u201d, line 59, in <strong>init</strong></p>\n<p>2022-04-21T08:16:02.683-03:00</p>\n<p>unlink_now)</p>\n<p>2022-04-21T08:16:02.683-03:00</p>\n<p>OSError: [Errno 38] Function not implemented</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-25T17:45:24.198Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/armanharutyunyan\">@armanharutyunyan</a>  ,I experience the same</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-03T03:22:26.230Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/lexofir\">@lexofir</a> <a class=\"mention\" href=\"/u/akshey\">@akshey</a>, we have made some changes that should fix this. Can you update your client and check if you still get the error?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-05T15:25:54.862Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-10T03:18:22.937Z",
				"Answer_body": "<p>Hey there, since we have not heard back from you, I\u2019ll be closing the ticket. But please ping me if you still experience this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-27T09:32:57.266Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/armanharutyunyan\">@armanharutyunyan</a><br>\nI am having the same issue with using wandb within AWS Lambda ( which does not support python multiprocessing )</p>\n<p>How do i resolve this? Is there a way to disable multiprocessing within wandb via an environment variable?</p>\n<p>For fastai to work within a lambda, we just have to set num_workers=0 \u2026is there a similar fix available here?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-28T18:51:49.593Z",
				"Answer_body": "<p>Im having the same issue</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-26T18:51:54.400Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Hide Command from Overview Run Page Bug - Reopen",
		"Question_link": "https://community.wandb.ai/t/hide-command-from-overview-run-page-bug-reopen/2802",
		"Question_created_time": "2022-07-26T19:38:34.475Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 211,
		"Question_has_accepted_answer": false,
		"Question_body": "<aside class=\"quote\" data-post=\"1\" data-topic=\"2231\">\n  <div class=\"title\">\n    <div class=\"quote-controls\"></div>\n    <img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/k/ed8c4c/40.png\" class=\"avatar\">\n    <a href=\"https://community.wandb.ai/t/hide-command-from-overview-run-page/2231\">Hide Command from Overview Run Page</a> <a class=\"badge-wrapper  bullet\" href=\"/c/w-b-support/36\"><span class=\"badge-category-bg\" style=\"background-color: #0088CC;\"></span><span style=\"\" data-drop-close=\"true\" class=\"badge-category clear-badge\" title=\"Ask your W&amp;B questions here. Let us know if you have an issue and one of our engineers or community experts will get back to you ASAP.\">W&amp;B Support</span></a>\n  </div>\n  <blockquote>\n    On the Run Page (<a href=\"https://docs.wandb.ai/ref/app/pages/run-page\">https://docs.wandb.ai/ref/app/pages/run-page</a>) it shows on the left incognito that it shouldn\u2019t show your command when the public is viewing your page. \nHowever, on my page, when public and I view as not-me, it still shows the command that launched it, and that includes my Windows username, which I\u2019d rather not. I can\u2019t find anything to override or hide this. What am I missing? \nThanks.\n  </blockquote>\n</aside>\n\n<p>Reopening the above, this still isn\u2019t fixed and it\u2019s still bothering me.</p>\n<p>Any updates?</p>\n<p><a class=\"mention\" href=\"/u/armanharutyunyan\">@armanharutyunyan</a></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-27T21:59:13.438Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kaiyotech\">@kaiyotech</a>, I\u2019ll be taking over this ticket. There is currently no update on the ticket because it hasn\u2019t been picked up by an engineer yet. I have boosted the priority on it and I\u2019ll let you know if there are any updates.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-25T21:59:22.552Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to kill a specific agent using a command in terminal?",
		"Question_link": "https://community.wandb.ai/t/how-to-kill-a-specific-agent-using-a-command-in-terminal/2782",
		"Question_created_time": "2022-07-20T15:21:29.646Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 159,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I run several agents in one sweep.<br>\nI want to stop a specific agent among them, but I don\u2019t know how to stop it.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-22T06:22:37.452Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/jeongwhanchoi\">@jeongwhanchoi</a> , please see this <a href=\"https://community.wandb.ai/t/hp-sweep-correct-way-to-stop-a-specific-agent-and-not-the-entire-sweep/1173\">post</a> for stopping agents. Please let me know if you have additional questions.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-07-27T18:57:22.868Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/jeongwhanchoi\">@jeongwhanchoi</a> , Since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-25T18:58:08.554Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Error while hyperparameter search",
		"Question_link": "https://community.wandb.ai/t/error-while-hyperparameter-search/2751",
		"Question_created_time": "2022-07-14T17:30:42.704Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 298,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>When I try wandb.sweep, it gives following error:  wandb.errors.CommError: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand.</p>\n<p>Following this, is my sweep config<br>\n{\u2018method\u2019: \u2018random\u2019,<br>\n\u2018metric\u2019: {\u2018goal\u2019: \u2018minimize\u2019, \u2018name\u2019: \u2018loss\u2019},<br>\n\u2018parameters\u2019: {\u2018batch_size\u2019: {\u2018distribution\u2019: \u2018q_log_uniform_values\u2019,<br>\n\u2018max\u2019: 256,<br>\n\u2018min\u2019: 32,<br>\n\u2018q\u2019: 8},<br>\n\u2018epochs\u2019: {\u2018value\u2019: 10},<br>\n\u2018fc_layer_size\u2019: {\u2018values\u2019: [16, 32, 64]},<br>\n\u2018learning_rate\u2019: {\u2018distribution\u2019: \u2018uniform\u2019,<br>\n\u2018max\u2019: 0.1,<br>\n\u2018min\u2019: 0},<br>\n\u2018optimizer\u2019: {\u2018values\u2019: [\u2018adam\u2019, \u2018sgd\u2019]},<br>\n\u2018training_snr\u2019: {\u2018values\u2019: [0.3981071705534972,<br>\n0.44668359215096315,<br>\n0.5011872336272722,<br>\n0.5623413251903491,<br>\n0.6309573444801932,<br>\n0.7079457843841379,<br>\n0.7943282347242815,<br>\n0.8912509381337456,<br>\n1.0,<br>\n1.1220184543019633,<br>\n1.2589254117941673,<br>\n1.4125375446227544,<br>\n1.5848931924611136,<br>\n1.7782794100389228,<br>\n1.9952623149688795,<br>\n2.2387211385683394,<br>\n2.51188643150958,<br>\n2.8183829312644537,<br>\n3.1622776601683795,<br>\n3.548133892335755,<br>\n3.9810717055349722,<br>\n4.466835921509632,<br>\n5.011872336272722,<br>\n5.623413251903491,<br>\n6.309573444801933,<br>\n7.079457843841379,<br>\n7.943282347242816,<br>\n8.912509381337454,<br>\n10.0]}}}</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-15T19:30:39.279Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/raikar_sumanth\">@raikar_sumanth</a> ,<br>\nCould you share the <code>debug.log</code> and <code>debug-internal.log</code> files associated with one of the runs which displays this error? It would be very helpful in order to gain more visibility into this error and understand why you are seeing CommErrors here.</p>\n<p>Thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-16T06:40:28.428Z",
				"Answer_body": "<p>There was no run, it gets stuck at wandb.sweep(sweep_config). if I disable the training_snr parameter from the sweep config , it works perfectly.<br>\nthe training_snr parameter is given at the forward pass in pytorch like this<br>\nfor epoch in range(config.epochs):<br>\navg_loss = train_epoch(network,loader,optimizer,training_snr)<br>\nwandb.log({\u201closs\u201d:avg_loss, \u201cepoch\u201d:epoch,\u201ctraining_snr\u201d:config.training_snr})</p>\n<p>Can you suggest any changes?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-21T03:52:45.679Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/raikar_sumanth\">@raikar_sumanth</a> ,</p>\n<p>Your sweep dictionary configuration is setup correctly and I was able to use it for a an experiment and didn\u2019t run into the same error. To better assist you can you please provide the following:</p>\n<ul>\n<li>wandb version</li>\n<li>Full traceback of error</li>\n<li>Description/Summary of the experiment you are running and which integration ,if any,  you are using</li>\n<li>Example colab of your code to attempt to reproduce your specific error</li>\n</ul>\n<p>Thank-you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-26T21:22:23.547Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/raikar_sumanth\">@raikar_sumanth</a> ,</p>\n<p>Since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-24T21:22:29.900Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Cannot compare artifcats anymore",
		"Question_link": "https://community.wandb.ai/t/cannot-compare-artifcats-anymore/2800",
		"Question_created_time": "2022-07-26T15:51:53.295Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 344,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>I work a project using GANs to generate images. At each iteration I would log artifacts containing the generated images. Up until now I could visualize the generated images in a table and compare multiple artifact versions visually by joining the tables in the artifact view.<br>\nIt seems that view has been updated and this functionality does not exist anymore or is hidden. Could anyone help me find back this functionality in case it still exists. Thank you!</p>\n<p>Mahmoud</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-28T16:26:28.637Z",
				"Answer_body": "<p>Hi Mahmoud,</p>\n<p>This is a known issue that we have and there\u2019s a ticket out to fix this. I\u2019ll let you know when I receive an update on it.</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-24T15:51:58.398Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Question\uff1aCan I use multiple accounts (i.e. adopting multiple API keys) in one machine?",
		"Question_link": "https://community.wandb.ai/t/question-can-i-use-multiple-accounts-i-e-adopting-multiple-api-keys-in-one-machine/2397",
		"Question_created_time": "2022-05-10T14:29:14.062Z",
		"Question_answer_count": 9,
		"Question_score_count": 0,
		"Question_view_count": 1249,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Can I use multiple accounts (i.e. adopting multiple API keys) in one machine?<br>\nAre there any ways I can do that?<br>\nLooking forward to helping! <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-11T22:00:22.369Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/correr\">@correr</a>!</p>\n<p>Yes, you can simply call <code>wandb login</code> from your terminal and pass in the API key from <a href=\"https://wandb.ai/authorize\" class=\"inline-onebox\">Weights &amp; Biases</a> when the prompt is displayed. This will log you in to the desired account.</p>\n<p>By default, we store the API key of the last logged in account on your device and you will be logged in to the last account you logged in to every time you call <code>wandb.init()</code></p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-16T19:49:23.223Z",
				"Answer_body": "<p>Hi Correr,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-19T21:28:00.348Z",
				"Answer_body": "<p>Hi Correr, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-26T07:58:48.209Z",
				"Answer_body": "<p>Hi, Goolry\uff01</p>\n<p>What I want to do is to use multiple accounts <strong>simultaneously</strong>, that is, I use my API key in a running program and at the same time the other guy can use his/her API key in his/her running program.</p>\n<p>This is because my fellow and I use the same server in our lab and both of us want to use W&amp;B.</p>\n<p>I am curious about how to solve this problem.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-08T03:45:16.528Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/correr\">@correr</a>,</p>\n<p>I see. You should be able to log into an individual account directly from your python script:</p>\n<pre><code class=\"lang-auto\">wandb.login(key = '&lt;YOUR-KEY-HERE&gt;')\nwandb.init(...)\n</code></pre>\n<p>This will allow you to log in directly on  a per-process basis through the python script.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-08T14:11:23.473Z",
				"Answer_body": "<p>You can also define environment variables to control who is logged in.</p>\n<pre><code class=\"lang-auto\">export WANDB_API_KEY=123alksdjasl\n</code></pre>\n<p>Running that and then running your script will control which account is logged in.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-26T04:53:51.863Z",
				"Answer_body": "<p>Thank for your suggestion! I will try it at my code.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-26T04:54:34.474Z",
				"Answer_body": "<p>Thank for your suggestion! It\u2019s a more direct way to solve this problem.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-24T04:55:24.624Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Automatically repeating experiments and plots with error bars",
		"Question_link": "https://community.wandb.ai/t/automatically-repeating-experiments-and-plots-with-error-bars/2791",
		"Question_created_time": "2022-07-22T11:34:38.841Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 107,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Is it possible to use wandb to do repeats of certain machine learning experiments and automatically plot a learning curve with uncertainty regions?</p>\n<p>Something like this <a href=\"https://stackoverflow.com/questions/43064524/plotting-shaded-uncertainty-region-in-line-plot-in-matplotlib-when-data-has-nans\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">python - Plotting shaded uncertainty region in line plot in matplotlib when data has NaNs - Stack Overflow</a></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-25T21:43:23.787Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/thiviyan\">@thiviyan</a> , at this time this feature is not available. However, we have it planed for the future. I will add you to the feature request ticket and will ping you when an update is available.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-23T21:43:41.373Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "TypeError when uploading pixel value bounding box",
		"Question_link": "https://community.wandb.ai/t/typeerror-when-uploading-pixel-value-bounding-box/2684",
		"Question_created_time": "2022-06-30T20:20:00.089Z",
		"Question_answer_count": 8,
		"Question_score_count": 0,
		"Question_view_count": 481,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi,<br>\nI was just trying to log a 2D bounding box with pixel coordinates, but I keep on running into this error:<br>\n<code>TypeError: Object of type int is not JSON serializable</code></p>\n<p>The code I used:</p>\n<pre><code class=\"lang-auto\">box_data = []\n\nclass_labels = {\n    0: \"face\"\n}\n\nfor (x,y,w,h) in face_rects:\n    frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n\n    midX = int(x+w/2)\n    midY = int(y+h/2) \n    box = {\n                \"position\": {\n                    \"middle\": [midX, midY],\n                    \"width\": w,\n                    \"height\": h\n                },\n                \"domain\" : \"pixel\",\n                \"class_id\" : 0\n            }\n    box_data.append(box)\n\npredictions = {\"predictions\": {\n        \"box_data\": box_data,\n        \"class_labels\": class_labels\n    }\n    }\n\nimg = wandb.Image(frame, boxes=predictions)\n</code></pre>\n<p>It works when I\u2019m using the relational notation instead of pixel values, but I\u2019d rather keep the pixel values for simplicity in the code.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-01T21:34:30.712Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/johko-cel\">@johko-cel</a> ,</p>\n<p>Will be glad to look into this for you. I utilized your code example and was successful in using pixel values without issue.  I\u2019m suspecting this isn\u2019t wandb related, but in order to troubleshoot, we will require the following please.</p>\n<ul>\n<li>Wandb Verion you are using</li>\n<li>Link to your workspace where you were attempting to log this image</li>\n<li>Complete traceback when experiencing this error</li>\n<li>If possible more extensive code sample in the form of a Colab so we can follow the steps you took in order to reproduce the error.</li>\n</ul>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-02T21:40:58.350Z",
				"Answer_body": "<p>Hi Mohammad,</p>\n<p>thanks for getting back to me so quickly. I also suspect that it might not be directly wandb related, but also have no idea where else it might come from.</p>\n<ul>\n<li>Wandb version: 0.12.18</li>\n<li>Workspace: <a href=\"https://wandb.ai/johko-cel/haar_cascades?workspace=user-johko-cel\" class=\"inline-onebox\">Weights &amp; Biases</a>\n</li>\n<li>Here is a colab I quickly whipped up: <a href=\"https://colab.research.google.com/drive/1dyrgGANhitXN8RND8nSDItDvX6OE4-FF?usp=sharing\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Google Colab</a>\n</li>\n<li>Complete Traceback:</li>\n</ul>\n<pre><code class=\"lang-auto\">{\n\t\"name\": \"TypeError\",\n\t\"message\": \"Object of type int is not JSON serializable\",\n\t\"stack\": \"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\\n\\u001b[0;31mTypeError\\u001b[0m                                 Traceback (most recent call last)\\n\\u001b[1;32m/home/johannes/Projects/blog/haar/haar_cascade.ipynb Cell 5'\\u001b[0m in \\u001b[0;36m&lt;cell line: 37&gt;\\u001b[0;34m()\\u001b[0m\\n\\u001b[1;32m     &lt;a href='vscode-notebook-cell:/home/johannes/Projects/blog/haar/haar_cascade.ipynb#ch0000005?line=28'&gt;29&lt;/a&gt;\\u001b[0m     box_data\\u001b[39m.\\u001b[39mappend(box)\\n\\u001b[1;32m     &lt;a href='vscode-notebook-cell:/home/johannes/Projects/blog/haar/haar_cascade.ipynb#ch0000005?line=30'&gt;31&lt;/a&gt;\\u001b[0m predictions \\u001b[39m=\\u001b[39m {\\u001b[39m\\\"\\u001b[39m\\u001b[39mpredictions\\u001b[39m\\u001b[39m\\\"\\u001b[39m: {\\n\\u001b[1;32m     &lt;a href='vscode-notebook-cell:/home/johannes/Projects/blog/haar/haar_cascade.ipynb#ch0000005?line=31'&gt;32&lt;/a&gt;\\u001b[0m         \\u001b[39m\\\"\\u001b[39m\\u001b[39mbox_data\\u001b[39m\\u001b[39m\\\"\\u001b[39m: box_data,\\n\\u001b[1;32m     &lt;a href='vscode-notebook-cell:/home/johannes/Projects/blog/haar/haar_cascade.ipynb#ch0000005?line=32'&gt;33&lt;/a&gt;\\u001b[0m         \\u001b[39m\\\"\\u001b[39m\\u001b[39mclass_labels\\u001b[39m\\u001b[39m\\\"\\u001b[39m: class_labels\\n\\u001b[1;32m     &lt;a href='vscode-notebook-cell:/home/johannes/Projects/blog/haar/haar_cascade.ipynb#ch0000005?line=33'&gt;34&lt;/a&gt;\\u001b[0m     }\\n\\u001b[1;32m     &lt;a href='vscode-notebook-cell:/home/johannes/Projects/blog/haar/haar_cascade.ipynb#ch0000005?line=34'&gt;35&lt;/a&gt;\\u001b[0m     }\\n\\u001b[0;32m---&gt; &lt;a href='vscode-notebook-cell:/home/johannes/Projects/blog/haar/haar_cascade.ipynb#ch0000005?line=36'&gt;37&lt;/a&gt;\\u001b[0m img \\u001b[39m=\\u001b[39m wandb\\u001b[39m.\\u001b[39;49mImage(frame, boxes\\u001b[39m=\\u001b[39;49mpredictions)\\n\\u001b[1;32m     &lt;a href='vscode-notebook-cell:/home/johannes/Projects/blog/haar/haar_cascade.ipynb#ch0000005?line=38'&gt;39&lt;/a&gt;\\u001b[0m wandb\\u001b[39m.\\u001b[39mlog({\\u001b[39m\\\"\\u001b[39m\\u001b[39mobama_pc\\u001b[39m\\u001b[39m\\\"\\u001b[39m: img})\\n\\nFile \\u001b[0;32m~/.local/share/virtualenvs/haar-tXjf4l0j/lib/python3.9/site-packages/wandb/sdk/data_types/image.py:147\\u001b[0m, in \\u001b[0;36mImage.__init__\\u001b[0;34m(self, data_or_path, mode, caption, grouping, classes, boxes, masks)\\u001b[0m\\n\\u001b[1;32m    144\\u001b[0m \\u001b[39melse\\u001b[39;00m:\\n\\u001b[1;32m    145\\u001b[0m     \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39m_initialize_from_data(data_or_path, mode)\\n\\u001b[0;32m--&gt; 147\\u001b[0m \\u001b[39mself\\u001b[39;49m\\u001b[39m.\\u001b[39;49m_set_initialization_meta(grouping, caption, classes, boxes, masks)\\n\\nFile \\u001b[0;32m~/.local/share/virtualenvs/haar-tXjf4l0j/lib/python3.9/site-packages/wandb/sdk/data_types/image.py:175\\u001b[0m, in \\u001b[0;36mImage._set_initialization_meta\\u001b[0;34m(self, grouping, caption, classes, boxes, masks)\\u001b[0m\\n\\u001b[1;32m    172\\u001b[0m         boxes_final[key] \\u001b[39m=\\u001b[39m box_item\\n\\u001b[1;32m    173\\u001b[0m     \\u001b[39melif\\u001b[39;00m \\u001b[39misinstance\\u001b[39m(box_item, \\u001b[39mdict\\u001b[39m):\\n\\u001b[1;32m    174\\u001b[0m         \\u001b[39m# TODO: Consider injecting top-level classes if user-provided is empty\\u001b[39;00m\\n\\u001b[0;32m--&gt; 175\\u001b[0m         boxes_final[key] \\u001b[39m=\\u001b[39m BoundingBoxes2D(box_item, key)\\n\\u001b[1;32m    176\\u001b[0m     total_classes\\u001b[39m.\\u001b[39mupdate(boxes_final[key]\\u001b[39m.\\u001b[39m_class_labels)\\n\\u001b[1;32m    177\\u001b[0m \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39m_boxes \\u001b[39m=\\u001b[39m boxes_final\\n\\nFile \\u001b[0;32m~/.local/share/virtualenvs/haar-tXjf4l0j/lib/python3.9/site-packages/wandb/sdk/data_types/helper_types/bounding_boxes_2d.py:214\\u001b[0m, in \\u001b[0;36mBoundingBoxes2D.__init__\\u001b[0;34m(self, val, key)\\u001b[0m\\n\\u001b[1;32m    182\\u001b[0m \\u001b[39mdef\\u001b[39;00m \\u001b[39m__init__\\u001b[39m(\\u001b[39mself\\u001b[39m, val: \\u001b[39mdict\\u001b[39m, key: \\u001b[39mstr\\u001b[39m) \\u001b[39m-\\u001b[39m\\u001b[39m&gt;\\u001b[39m \\u001b[39mNone\\u001b[39;00m:\\n\\u001b[1;32m    183\\u001b[0m     \\u001b[39m\\\"\\\"\\\"\\u001b[39;00m\\n\\u001b[1;32m    184\\u001b[0m \\u001b[39m    Arguments:\\u001b[39;00m\\n\\u001b[1;32m    185\\u001b[0m \\u001b[39m        val: (dictionary) A dictionary of the following form:\\u001b[39;00m\\n\\u001b[0;32m   (...)\\u001b[0m\\n\\u001b[1;32m    212\\u001b[0m \\u001b[39m            The readable name or id for this set of bounding boxes (e.g. predictions, ground_truth)\\u001b[39;00m\\n\\u001b[1;32m    213\\u001b[0m \\u001b[39m    \\\"\\\"\\\"\\u001b[39;00m\\n\\u001b[0;32m--&gt; 214\\u001b[0m     \\u001b[39msuper\\u001b[39;49m()\\u001b[39m.\\u001b[39;49m\\u001b[39m__init__\\u001b[39;49m(val)\\n\\u001b[1;32m    215\\u001b[0m     \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39m_val \\u001b[39m=\\u001b[39m val[\\u001b[39m\\\"\\u001b[39m\\u001b[39mbox_data\\u001b[39m\\u001b[39m\\\"\\u001b[39m]\\n\\u001b[1;32m    216\\u001b[0m     \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39m_key \\u001b[39m=\\u001b[39m key\\n\\nFile \\u001b[0;32m~/.local/share/virtualenvs/haar-tXjf4l0j/lib/python3.9/site-packages/wandb/sdk/data_types/base_types/json_metadata.py:36\\u001b[0m, in \\u001b[0;36mJSONMetadata.__init__\\u001b[0;34m(self, val)\\u001b[0m\\n\\u001b[1;32m     34\\u001b[0m tmp_path \\u001b[39m=\\u001b[39m os\\u001b[39m.\\u001b[39mpath\\u001b[39m.\\u001b[39mjoin(MEDIA_TMP\\u001b[39m.\\u001b[39mname, util\\u001b[39m.\\u001b[39mgenerate_id() \\u001b[39m+\\u001b[39m ext)\\n\\u001b[1;32m     35\\u001b[0m \\u001b[39mwith\\u001b[39;00m codecs\\u001b[39m.\\u001b[39mopen(tmp_path, \\u001b[39m\\\"\\u001b[39m\\u001b[39mw\\u001b[39m\\u001b[39m\\\"\\u001b[39m, encoding\\u001b[39m=\\u001b[39m\\u001b[39m\\\"\\u001b[39m\\u001b[39mutf-8\\u001b[39m\\u001b[39m\\\"\\u001b[39m) \\u001b[39mas\\u001b[39;00m fp:\\n\\u001b[0;32m---&gt; 36\\u001b[0m     util\\u001b[39m.\\u001b[39;49mjson_dump_uncompressed(\\u001b[39mself\\u001b[39;49m\\u001b[39m.\\u001b[39;49m_val, fp)\\n\\u001b[1;32m     37\\u001b[0m \\u001b[39mself\\u001b[39m\\u001b[39m.\\u001b[39m_set_file(tmp_path, is_tmp\\u001b[39m=\\u001b[39m\\u001b[39mTrue\\u001b[39;00m, extension\\u001b[39m=\\u001b[39mext)\\n\\nFile \\u001b[0;32m~/.local/share/virtualenvs/haar-tXjf4l0j/lib/python3.9/site-packages/wandb/util.py:820\\u001b[0m, in \\u001b[0;36mjson_dump_uncompressed\\u001b[0;34m(obj, fp, **kwargs)\\u001b[0m\\n\\u001b[1;32m    818\\u001b[0m \\u001b[39mdef\\u001b[39;00m \\u001b[39mjson_dump_uncompressed\\u001b[39m(obj: Any, fp: IO[\\u001b[39mstr\\u001b[39m], \\u001b[39m*\\u001b[39m\\u001b[39m*\\u001b[39mkwargs: Any) \\u001b[39m-\\u001b[39m\\u001b[39m&gt;\\u001b[39m \\u001b[39mNone\\u001b[39;00m:\\n\\u001b[1;32m    819\\u001b[0m     \\u001b[39m\\\"\\\"\\\"Convert obj to json, with some extra encodable types.\\\"\\\"\\\"\\u001b[39;00m\\n\\u001b[0;32m--&gt; 820\\u001b[0m     \\u001b[39mreturn\\u001b[39;00m json\\u001b[39m.\\u001b[39;49mdump(obj, fp, \\u001b[39mcls\\u001b[39;49m\\u001b[39m=\\u001b[39;49mJSONEncoderUncompressed, \\u001b[39m*\\u001b[39;49m\\u001b[39m*\\u001b[39;49mkwargs)\\n\\nFile \\u001b[0;32m/usr/lib/python3.9/json/__init__.py:179\\u001b[0m, in \\u001b[0;36mdump\\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\\u001b[0m\\n\\u001b[1;32m    173\\u001b[0m     iterable \\u001b[39m=\\u001b[39m \\u001b[39mcls\\u001b[39m(skipkeys\\u001b[39m=\\u001b[39mskipkeys, ensure_ascii\\u001b[39m=\\u001b[39mensure_ascii,\\n\\u001b[1;32m    174\\u001b[0m         check_circular\\u001b[39m=\\u001b[39mcheck_circular, allow_nan\\u001b[39m=\\u001b[39mallow_nan, indent\\u001b[39m=\\u001b[39mindent,\\n\\u001b[1;32m    175\\u001b[0m         separators\\u001b[39m=\\u001b[39mseparators,\\n\\u001b[1;32m    176\\u001b[0m         default\\u001b[39m=\\u001b[39mdefault, sort_keys\\u001b[39m=\\u001b[39msort_keys, \\u001b[39m*\\u001b[39m\\u001b[39m*\\u001b[39mkw)\\u001b[39m.\\u001b[39miterencode(obj)\\n\\u001b[1;32m    177\\u001b[0m \\u001b[39m# could accelerate with writelines in some versions of Python, at\\u001b[39;00m\\n\\u001b[1;32m    178\\u001b[0m \\u001b[39m# a debuggability cost\\u001b[39;00m\\n\\u001b[0;32m--&gt; 179\\u001b[0m \\u001b[39mfor\\u001b[39;00m chunk \\u001b[39min\\u001b[39;00m iterable:\\n\\u001b[1;32m    180\\u001b[0m     fp\\u001b[39m.\\u001b[39mwrite(chunk)\\n\\nFile \\u001b[0;32m/usr/lib/python3.9/json/encoder.py:431\\u001b[0m, in \\u001b[0;36m_make_iterencode.&lt;locals&gt;._iterencode\\u001b[0;34m(o, _current_indent_level)\\u001b[0m\\n\\u001b[1;32m    429\\u001b[0m     \\u001b[39myield from\\u001b[39;00m _iterencode_list(o, _current_indent_level)\\n\\u001b[1;32m    430\\u001b[0m \\u001b[39melif\\u001b[39;00m \\u001b[39misinstance\\u001b[39m(o, \\u001b[39mdict\\u001b[39m):\\n\\u001b[0;32m--&gt; 431\\u001b[0m     \\u001b[39myield from\\u001b[39;00m _iterencode_dict(o, _current_indent_level)\\n\\u001b[1;32m    432\\u001b[0m \\u001b[39melse\\u001b[39;00m:\\n\\u001b[1;32m    433\\u001b[0m     \\u001b[39mif\\u001b[39;00m markers \\u001b[39mis\\u001b[39;00m \\u001b[39mnot\\u001b[39;00m \\u001b[39mNone\\u001b[39;00m:\\n\\nFile \\u001b[0;32m/usr/lib/python3.9/json/encoder.py:405\\u001b[0m, in \\u001b[0;36m_make_iterencode.&lt;locals&gt;._iterencode_dict\\u001b[0;34m(dct, _current_indent_level)\\u001b[0m\\n\\u001b[1;32m    403\\u001b[0m         \\u001b[39melse\\u001b[39;00m:\\n\\u001b[1;32m    404\\u001b[0m             chunks \\u001b[39m=\\u001b[39m _iterencode(value, _current_indent_level)\\n\\u001b[0;32m--&gt; 405\\u001b[0m         \\u001b[39myield from\\u001b[39;00m chunks\\n\\u001b[1;32m    406\\u001b[0m \\u001b[39mif\\u001b[39;00m newline_indent \\u001b[39mis\\u001b[39;00m \\u001b[39mnot\\u001b[39;00m \\u001b[39mNone\\u001b[39;00m:\\n\\u001b[1;32m    407\\u001b[0m     _current_indent_level \\u001b[39m-\\u001b[39m\\u001b[39m=\\u001b[39m \\u001b[39m1\\u001b[39m\\n\\nFile \\u001b[0;32m/usr/lib/python3.9/json/encoder.py:325\\u001b[0m, in \\u001b[0;36m_make_iterencode.&lt;locals&gt;._iterencode_list\\u001b[0;34m(lst, _current_indent_level)\\u001b[0m\\n\\u001b[1;32m    323\\u001b[0m         \\u001b[39melse\\u001b[39;00m:\\n\\u001b[1;32m    324\\u001b[0m             chunks \\u001b[39m=\\u001b[39m _iterencode(value, _current_indent_level)\\n\\u001b[0;32m--&gt; 325\\u001b[0m         \\u001b[39myield from\\u001b[39;00m chunks\\n\\u001b[1;32m    326\\u001b[0m \\u001b[39mif\\u001b[39;00m newline_indent \\u001b[39mis\\u001b[39;00m \\u001b[39mnot\\u001b[39;00m \\u001b[39mNone\\u001b[39;00m:\\n\\u001b[1;32m    327\\u001b[0m     _current_indent_level \\u001b[39m-\\u001b[39m\\u001b[39m=\\u001b[39m \\u001b[39m1\\u001b[39m\\n\\nFile \\u001b[0;32m/usr/lib/python3.9/json/encoder.py:405\\u001b[0m, in \\u001b[0;36m_make_iterencode.&lt;locals&gt;._iterencode_dict\\u001b[0;34m(dct, _current_indent_level)\\u001b[0m\\n\\u001b[1;32m    403\\u001b[0m         \\u001b[39melse\\u001b[39;00m:\\n\\u001b[1;32m    404\\u001b[0m             chunks \\u001b[39m=\\u001b[39m _iterencode(value, _current_indent_level)\\n\\u001b[0;32m--&gt; 405\\u001b[0m         \\u001b[39myield from\\u001b[39;00m chunks\\n\\u001b[1;32m    406\\u001b[0m \\u001b[39mif\\u001b[39;00m newline_indent \\u001b[39mis\\u001b[39;00m \\u001b[39mnot\\u001b[39;00m \\u001b[39mNone\\u001b[39;00m:\\n\\u001b[1;32m    407\\u001b[0m     _current_indent_level \\u001b[39m-\\u001b[39m\\u001b[39m=\\u001b[39m \\u001b[39m1\\u001b[39m\\n\\nFile \\u001b[0;32m/usr/lib/python3.9/json/encoder.py:405\\u001b[0m, in \\u001b[0;36m_make_iterencode.&lt;locals&gt;._iterencode_dict\\u001b[0;34m(dct, _current_indent_level)\\u001b[0m\\n\\u001b[1;32m    403\\u001b[0m         \\u001b[39melse\\u001b[39;00m:\\n\\u001b[1;32m    404\\u001b[0m             chunks \\u001b[39m=\\u001b[39m _iterencode(value, _current_indent_level)\\n\\u001b[0;32m--&gt; 405\\u001b[0m         \\u001b[39myield from\\u001b[39;00m chunks\\n\\u001b[1;32m    406\\u001b[0m \\u001b[39mif\\u001b[39;00m newline_indent \\u001b[39mis\\u001b[39;00m \\u001b[39mnot\\u001b[39;00m \\u001b[39mNone\\u001b[39;00m:\\n\\u001b[1;32m    407\\u001b[0m     _current_indent_level \\u001b[39m-\\u001b[39m\\u001b[39m=\\u001b[39m \\u001b[39m1\\u001b[39m\\n\\nFile \\u001b[0;32m/usr/lib/python3.9/json/encoder.py:438\\u001b[0m, in \\u001b[0;36m_make_iterencode.&lt;locals&gt;._iterencode\\u001b[0;34m(o, _current_indent_level)\\u001b[0m\\n\\u001b[1;32m    436\\u001b[0m         \\u001b[39mraise\\u001b[39;00m \\u001b[39mValueError\\u001b[39;00m(\\u001b[39m\\\"\\u001b[39m\\u001b[39mCircular reference detected\\u001b[39m\\u001b[39m\\\"\\u001b[39m)\\n\\u001b[1;32m    437\\u001b[0m     markers[markerid] \\u001b[39m=\\u001b[39m o\\n\\u001b[0;32m--&gt; 438\\u001b[0m o \\u001b[39m=\\u001b[39m _default(o)\\n\\u001b[1;32m    439\\u001b[0m \\u001b[39myield from\\u001b[39;00m _iterencode(o, _current_indent_level)\\n\\u001b[1;32m    440\\u001b[0m \\u001b[39mif\\u001b[39;00m markers \\u001b[39mis\\u001b[39;00m \\u001b[39mnot\\u001b[39;00m \\u001b[39mNone\\u001b[39;00m:\\n\\nFile \\u001b[0;32m~/.local/share/virtualenvs/haar-tXjf4l0j/lib/python3.9/site-packages/wandb/util.py:804\\u001b[0m, in \\u001b[0;36mJSONEncoderUncompressed.default\\u001b[0;34m(self, obj)\\u001b[0m\\n\\u001b[1;32m    802\\u001b[0m \\u001b[39melif\\u001b[39;00m np \\u001b[39mand\\u001b[39;00m \\u001b[39misinstance\\u001b[39m(obj, np\\u001b[39m.\\u001b[39mgeneric):\\n\\u001b[1;32m    803\\u001b[0m     obj \\u001b[39m=\\u001b[39m obj\\u001b[39m.\\u001b[39mitem()\\n\\u001b[0;32m--&gt; 804\\u001b[0m \\u001b[39mreturn\\u001b[39;00m json\\u001b[39m.\\u001b[39;49mJSONEncoder\\u001b[39m.\\u001b[39;49mdefault(\\u001b[39mself\\u001b[39;49m, obj)\\n\\nFile \\u001b[0;32m/usr/lib/python3.9/json/encoder.py:179\\u001b[0m, in \\u001b[0;36mJSONEncoder.default\\u001b[0;34m(self, o)\\u001b[0m\\n\\u001b[1;32m    160\\u001b[0m \\u001b[39mdef\\u001b[39;00m \\u001b[39mdefault\\u001b[39m(\\u001b[39mself\\u001b[39m, o):\\n\\u001b[1;32m    161\\u001b[0m     \\u001b[39m\\\"\\\"\\\"Implement this method in a subclass such that it returns\\u001b[39;00m\\n\\u001b[1;32m    162\\u001b[0m \\u001b[39m    a serializable object for ``o``, or calls the base implementation\\u001b[39;00m\\n\\u001b[1;32m    163\\u001b[0m \\u001b[39m    (to raise a ``TypeError``).\\u001b[39;00m\\n\\u001b[0;32m   (...)\\u001b[0m\\n\\u001b[1;32m    177\\u001b[0m \\n\\u001b[1;32m    178\\u001b[0m \\u001b[39m    \\\"\\\"\\\"\\u001b[39;00m\\n\\u001b[0;32m--&gt; 179\\u001b[0m     \\u001b[39mraise\\u001b[39;00m \\u001b[39mTypeError\\u001b[39;00m(\\u001b[39mf\\u001b[39m\\u001b[39m'\\u001b[39m\\u001b[39mObject of type \\u001b[39m\\u001b[39m{\\u001b[39;00mo\\u001b[39m.\\u001b[39m\\u001b[39m__class__\\u001b[39m\\u001b[39m.\\u001b[39m\\u001b[39m__name__\\u001b[39m\\u001b[39m}\\u001b[39;00m\\u001b[39m \\u001b[39m\\u001b[39m'\\u001b[39m\\n\\u001b[1;32m    180\\u001b[0m                     \\u001b[39mf\\u001b[39m\\u001b[39m'\\u001b[39m\\u001b[39mis not JSON serializable\\u001b[39m\\u001b[39m'\\u001b[39m)\\n\\n\\u001b[0;31mTypeError\\u001b[0m: Object of type int is not JSON serializable\"\n}\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-06T22:58:23.111Z",
				"Answer_body": "<p>It\u2019s your class labels:</p>\n<pre><code class=\"lang-auto\">class_labels = {\n    0: \"face\"\n}\n</code></pre>\n<p>json does not support numerics as keys</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-12T23:02:04.030Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/johko-cel\">@johko-cel</a> , apologies for delayed response, I was out of office. Upon review of your colab work, the error stems from you attempting to predict outside the dimensions of the frame set. Example: If I was to divide the  width and height by 2,  then you will not hit an error as the prediction box will be within the dimensions of the frame.</p>\n<pre><code class=\"lang-auto\"> box = {\n                \"position\": {\n                    \"middle\": [midX, midY],\n                    \"width\": w/2,\n                    \"height\": h/2\n                },\n</code></pre>\n<p>The confusion is unfortunately due to  our printed traceback message, this is not a <code>JSON</code> related error.  I will file a report with engineering to address this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-13T13:21:31.971Z",
				"Answer_body": "<p>Thank you for investigating <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> , I also was out of office for a while, so no worries.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-13T13:24:00.843Z",
				"Answer_body": "<p>Actually when I turn the <code>0</code> into a string, it gives me the error <code>TypeError: Class labels must be a dictionary of numbers to string</code><br>\nBut I guess <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> found the right issue in the code.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-25T19:30:25.744Z",
				"Answer_body": "<p>Hey Mohammad,<br>\nactually today I came back to the project and found something interesting about the bounding box.<br>\nActually, it is not outside of the dimensions of the frame set and I can do a little trick to get the right size of the bounding box working:</p>\n<pre><code class=\"lang-auto\"> box = {\n                \"position\": {\n                    \"middle\": [midX, midY],\n                    \"width\": (w/2)+(w/2),\n                    \"height\": (h/2)+(h/2)\n                },\n\n</code></pre>\n<p>So what is the difference here? After dividing, the coordinates are <code>float</code> values and not <code>int</code> anymore and this makes it work(can also just cast them). Sounds like a bug and I just created an issue for it: <a href=\"https://github.com/wandb/wandb/issues/3982\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">[CLI]: Logging bounding boxes only works with float dimensions, not int \u00b7 Issue #3982 \u00b7 wandb/wandb \u00b7 GitHub</a></p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-09-23T19:31:09.385Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Hello\uff0cI save my wandb offline, how can I upload it",
		"Question_link": "https://community.wandb.ai/t/hello-i-save-my-wandb-offline-how-can-i-upload-it/2793",
		"Question_created_time": "2022-07-25T03:36:14.078Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 66,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I save my wandb log offline but I can\u2019t upload it, No matter what code I try , it comes the error wandb: ERROR Nothing to sync. I want to know with my runs path(with each runs like offline-run-20220725_105335-3c4wo6kf),how to upload this run online. and how to upload a project?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-09-23T03:36:15.699Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to group runs (e.g., different random seeds) together on the wandb report function for plots?",
		"Question_link": "https://community.wandb.ai/t/how-to-group-runs-e-g-different-random-seeds-together-on-the-wandb-report-function-for-plots/2634",
		"Question_created_time": "2022-06-18T18:46:32.183Z",
		"Question_answer_count": 6,
		"Question_score_count": 1,
		"Question_view_count": 459,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am running some experiments where I have multiple random seeds per experiment setting, so I am trying to group the runs together to get their average and standard deviation (this is standard in reinforcement learning research these days). However, I can\u2019t seem to figure out how to get this to reliably work on wandb \u2013 sometimes it works and sometimes it doesn\u2019t.</p>\n<p>For reference, this is the kind of plot that I am trying to generate:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/7dfb019e4801f1aa0f88fc7e4a50aa7df66f68eb.jpeg\" data-download-href=\"/uploads/short-url/hYtsFlCoHHY8wJNPJseLDMnC29R.jpeg?dl=1\" title=\"Screen Shot 2022-06-18 at 2.32.22 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7dfb019e4801f1aa0f88fc7e4a50aa7df66f68eb_2_565x500.jpeg\" alt=\"Screen Shot 2022-06-18 at 2.32.22 PM\" data-base62-sha1=\"hYtsFlCoHHY8wJNPJseLDMnC29R\" width=\"565\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7dfb019e4801f1aa0f88fc7e4a50aa7df66f68eb_2_565x500.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7dfb019e4801f1aa0f88fc7e4a50aa7df66f68eb_2_847x750.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/7dfb019e4801f1aa0f88fc7e4a50aa7df66f68eb.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7dfb019e4801f1aa0f88fc7e4a50aa7df66f68eb_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-06-18 at 2.32.22 PM</span><span class=\"informations\">1070\u00d7946 97.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>There are two overall curves, but these are averaged among several runs, which is why you see a shaded region for standard deviation.</p>\n<p>I make this figure in a wandb report by going to the panel grid and assigning different runs together to a group manually. Here is a screen recording of the process of how I try to do this.</p>\n<aside class=\"onebox googledrive\" data-onebox-src=\"https://drive.google.com/file/d/10mX_1EqWC5UUchSy2giluDv8lvKvvA2a/view?usp=sharing\">\n  <header class=\"source\">\n\n      <a href=\"https://drive.google.com/file/d/10mX_1EqWC5UUchSy2giluDv8lvKvvA2a/view?usp=sharing\" target=\"_blank\" rel=\"noopener nofollow ugc\">drive.google.com</a>\n  </header>\n\n  <article class=\"onebox-body\">\n      <a href=\"https://drive.google.com/file/d/10mX_1EqWC5UUchSy2giluDv8lvKvvA2a/view?usp=sharing\" target=\"_blank\" rel=\"noopener nofollow ugc\"><span class=\"googledocs-onebox-logo g-drive-logo\"></span></a>\n\n\n\n<h3><a href=\"https://drive.google.com/file/d/10mX_1EqWC5UUchSy2giluDv8lvKvvA2a/view?usp=sharing\" target=\"_blank\" rel=\"noopener nofollow ugc\">wandb_cannot_group.mov</a></h3>\n\n<p>Google Drive file.</p>\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>Here, I\u2019m showing another set of runs that I\u2019m trying to group together (it\u2019s about 15 total individual runs, but in 3-4 groups, so I\u2019m trying to group the curves). However, clicking on the \u201cRuns\u201d button means nothing changes! This is strange since it\u2019s how I do this to create my other grouping plots. Sometimes it works, sometimes it does not. Does anyone have suggestions on how to make this function work more reliably? Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-12T13:12:18.532Z",
				"Answer_body": "<p>Hi all,<br>\nJust curious if anyone had any response or thoughts on how to address?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-13T19:47:23.394Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/danieltakeshi\">@danieltakeshi</a> ,</p>\n<p>To grouping using wandb, a user will have to perform any of the following:</p>\n<ul>\n<li>sett a group id in script for the runs</li>\n<li>set a group environmental variable within your project that is shared by all runs in the group</li>\n</ul>\n<p>The above approaches will automatically group runs in the UI when logged.</p>\n<ul>\n<li>When grouping through the UI for groups that were not initially set to share a group via script, you first group by a common metric, then within the chart that now shares the runs, aggregate across them.</li>\n</ul>\n<p>More on those <a href=\"https://docs.wandb.ai/guides/track/advanced/grouping\">here</a></p>\n<p>Can you please review the above to see if this helps. Additionally, please share a link to your workspace for us to review.</p>\n<p>Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-15T14:15:44.845Z",
				"Answer_body": "<p>Hi! Thanks so much for the advice.<br>\nTo be specific here is the report that I used which I showed in the screen recording video:</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://wandb.ai/mooey5775/mixed_media/reports/BC04-Pouring-SVD-Flow-Based-Methods--VmlldzoyMTQ5MDMy\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/18b592222b97bc09df3743831bb4929dec23611c.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https://wandb.ai/mooey5775/mixed_media/reports/BC04-Pouring-SVD-Flow-Based-Methods--VmlldzoyMTQ5MDMy\" target=\"_blank\" rel=\"noopener\" title=\"08:24PM - 10 June 2022\">W&amp;B \u2013 10 Jun 22</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/cf9e1ba973281ce03a0112b895e3f727d93c3e20_2_500x500.jpeg\" class=\"thumbnail onebox-avatar\" width=\"500\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/cf9e1ba973281ce03a0112b895e3f727d93c3e20_2_500x500.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/cf9e1ba973281ce03a0112b895e3f727d93c3e20_2_750x750.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/cf9e1ba973281ce03a0112b895e3f727d93c3e20.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/cf9e1ba973281ce03a0112b895e3f727d93c3e20_2_10x10.png\">\n\n<h3><a href=\"https://wandb.ai/mooey5775/mixed_media/reports/BC04-Pouring-SVD-Flow-Based-Methods--VmlldzoyMTQ5MDMy\" target=\"_blank\" rel=\"noopener\">BC04 (Pouring) SVD Flow-Based Methods</a></h3>\n\n  <p>This should be for our 'proposed' 3D and 6D flow methods; ablations can go elsewhere. . Made by Daniel Seita using Weights &amp; Biases</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n<p>\nThis report links to a bunch of runs in the workspace that I am using.<br>\nI updated the report today (July 15, 2022, or 07/15/2022) with a link to this post, to indicate where I was trying to group runs.</p>\n<p>To clarify, these are for runs that (I believe) were not initially set to share a group via a script. I think this is the case you are talking about with \u201cgrouping through the UI for groups that were not initially set to share a group\u201d.</p>\n<p>I have indeed seen this link here: <a href=\"https://docs.wandb.ai/guides/track/advanced/grouping\" class=\"inline-onebox\">Group Runs - Documentation</a></p>\n<p>I think the relevant part for me is \u201cGrouping dynamically in the UI\u201d. However the challenge in my case is that I am not trying to group by a hyperparameter. I\u2019m trying to group an arbitrary set of runs that may or may not share some hyperparameters.</p>\n<p>Also is there a way to do this in a wandb report <em>after</em> it has been created? I can actually somewhat reliably (I think) group runs if I accumulate the set of runs I want (by clicking on the \u201ceye\u201d button to the left of each run in the table) and make a new wandb report. However sometimes I want to modify existing reports.</p>\n<p>Thanks for your reply!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-22T07:01:34.748Z",
				"Answer_body": "<p>Thank you for providing clarification <a class=\"mention\" href=\"/u/danieltakeshi\">@danieltakeshi</a> and providing the report link. I do recognize that there is a sight limitation in our platform in allowing users to group runs after they had completed them when they don\u2019t have any obvious distinguishing features the runs could be grouped against. We currently have a feature request in place to expand grouping functionality post logging to include arbitrary grouping. I will add you to this ticket and provide an update when available.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-22T17:30:30.425Z",
				"Answer_body": "<p>Thanks for clarifying, and it would be great if such a feature is available.</p>\n<p>I am able to group reliably if I click on ALL the runs I want to consider for any possible groups, then I make a report from the existing stats that are logged. If I am able to do that then it seems like clicking dynamically on the wandb report UI will group them correctly. Also, interestingly, when I do this I am also able to add future runs.</p>\n<p>So the key seems to be: make an initial report with the statistics I want to log already there and an initial set of runs to group in whatever way. Then I can group and add more runs later. If I try to add other statistics later, it will not let me group. It\u2019s a lot of trial and error but I think I have something reliable, happy to clarify if needed.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-20T17:30:31.655Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Select runs and parameters for Run Comparer",
		"Question_link": "https://community.wandb.ai/t/select-runs-and-parameters-for-run-comparer/2787",
		"Question_created_time": "2022-07-21T10:19:36.489Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 123,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019d like the idea of using the Run Comparer, but I can find a way to select which runs to display, nor which parameters I want to display. As I have 100 runs in my project, it seems to be selecting 10 runs at random, none of which are actually the ones I want to compare. There are also lots of parameters that I\u2019m not interested in for this particular evaluation. Unless I\u2019m missing something, I assume a feature would need to be added to allow the user the select the runs and parameters.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-21T10:57:05.293Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/jearly\">@jearly</a><br>\nYou can control which runs to display by clicking the <img src=\"https://emoji.discourse-cdn.com/twitter/eye.png?v=12\" title=\":eye:\" class=\"emoji\" alt=\":eye:\" loading=\"lazy\" width=\"20\" height=\"20\"> icon on the Run set below your panels. You can toggle \u201cdiff only\u201d to show only the parameters which have different values across the runs displayed.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-21T11:17:16.106Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/_scott\">@_scott</a></p>\n<p>Thanks for the quick response!</p>\n<p>Just to clarify, I have the runs on the LHS with 100 visualised. I can see that if I deselect the eye icon for a run, then it does indeed disappear from the Run Comparer, but it also disappears from my other plots. Selecting \u201cdiff only\u201d helps somewhat with reducing the parameters, but there remains a lot of info there that I would prefer to be hidden (for simplicity).</p>\n<p>To give a bit more detail on my use case:</p>\n<ul>\n<li>I have optimised an ML model with 100 different param configs, and have plots like this (i.e., displaying all 100 runs).<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/38d37a27d720d6582c39070c45ea718cab864f9f.png\" data-download-href=\"/uploads/short-url/86HPdv7RfQnqu4nDaYm1gszftuL.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/38d37a27d720d6582c39070c45ea718cab864f9f_2_690x361.png\" alt=\"image\" data-base62-sha1=\"86HPdv7RfQnqu4nDaYm1gszftuL\" width=\"690\" height=\"361\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/38d37a27d720d6582c39070c45ea718cab864f9f_2_690x361.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/38d37a27d720d6582c39070c45ea718cab864f9f_2_1035x541.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/38d37a27d720d6582c39070c45ea718cab864f9f_2_1380x722.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/38d37a27d720d6582c39070c45ea718cab864f9f_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1554\u00d7815 160 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div>\n</li>\n<li>For a select number of runs, I would then like to compare the parameters that were found using the Run Comparer. But currently the run comparer is very big with a lot of information that I want to reduce.</li>\n<li>So ideally I\u2019d like to keep all 100 runs for the top plots, and then select specific runs in the run comparer, which I believe I\u2019m not currently able to do.</li>\n</ul>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-21T11:18:08.237Z",
				"Answer_body": "<p>Here\u2019s what the run comparer looks like for me:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/644afd910b2dbbdbdf5768bed4e280d06430bd3d.png\" data-download-href=\"/uploads/short-url/ejepDfUD84gHigpvPHvXF092TJX.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/644afd910b2dbbdbdf5768bed4e280d06430bd3d_2_690x361.png\" alt=\"image\" data-base62-sha1=\"ejepDfUD84gHigpvPHvXF092TJX\" width=\"690\" height=\"361\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/644afd910b2dbbdbdf5768bed4e280d06430bd3d_2_690x361.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/644afd910b2dbbdbdf5768bed4e280d06430bd3d_2_1035x541.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/644afd910b2dbbdbdf5768bed4e280d06430bd3d_2_1380x722.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/644afd910b2dbbdbdf5768bed4e280d06430bd3d_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1552\u00d7813 35.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-22T09:39:03.291Z",
				"Answer_body": "<p>This would be a great opportunity to create a Report and do your analysis there. You can add multiple plots with different Run Sets. To do so, click \u201cCreate Report\u201d and within the Report, type \u2018/\u2019 and add a PanelGrid and add the panels you care about (your line plots and run comparers).</p>\n<p>Let me know if you have any issues with this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-25T17:26:44.318Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-20T09:39:32.420Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How do I do probabilistic logging?",
		"Question_link": "https://community.wandb.ai/t/how-do-i-do-probabilistic-logging/2747",
		"Question_created_time": "2022-07-13T23:09:41.053Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 86,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m currently doing all my logging like this:</p>\n<pre><code class=\"lang-auto\">wandb.log(\n{ \"loss\": loss, \"step\": step }, commit=should_commit())\n# step increments with each batch\n\ndef should_commit():\n    return random.randint(0, 100) == 0\n</code></pre>\n<p>The goal is to only sync metrics to the server once every 100 or so calls to log. I\u2019m doing this because otherwise my training speed is halved, if I just do the default.</p>\n<p>But, I notice this isn\u2019t working. My charts look very odd for some reason.<br>\nWhat is the correct way to only sync all my metrics every so often?</p>\n<p>To be clear, I want the end result to be such that all my metrics are on the server for every time-step, however, I want to do the syncing infrequently instead of every time I call <code>wandb.log</code>, because that\u2019s slow.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-15T21:29:56.145Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/vroomerify\">@vroomerify</a> ,</p>\n<p>Our global step must always increase and we will automatically increment it if you don\u2019t specify it or set <code>commit=False</code> in <code>wandb.init</code>. If you want to log metrics against multiple x-axis you can log those axis as separate metrics, I.E.</p>\n<p>wandb.log({\u201closs\u201d: 0.3, \u201cbatch\u201d: 1000, \u201cepoch\u201d: 2})</p>\n<p>Then you can choose a custom x-axis in the ui to be whatever you\u2019ve logged against your metrics.</p>\n<p>Additionally, we allow for Stepwise and Incremental Logging, see <a href=\"https://docs.wandb.ai/guides/track/log#stepwise-and-incremental-logging\">here</a> for more details on how to do so.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-22T06:34:10.759Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/vroomerify\">@vroomerify</a> ,  since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-20T06:34:47.378Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Class Label miscount while creating image masks for semantic segmentation",
		"Question_link": "https://community.wandb.ai/t/class-label-miscount-while-creating-image-masks-for-semantic-segmentation/2734",
		"Question_created_time": "2022-07-11T14:26:28.807Z",
		"Question_answer_count": 5,
		"Question_score_count": 1,
		"Question_view_count": 125,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey all,</p>\n<p>When making a table of images with image masks, I realized wandb keeps the greatest amount of labels out of all the images as opposed to giving each image in a column its appropriate amount of labels. Ex: If I have 2 images, 1 with 5 labels and another with 11 labels, both image will have 11 labels as opposed to one with 5 and another with 11. I already debugged my code to make sure every time I created a dictionary with the appropriate amount of labels and passed it in as an argument, not sure why the final outcome in wandb still comes out with the wrong labels.</p>\n<p>Thanks!<br>\nUmama</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-12T20:24:19.237Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/uahmed1\">@uahmed1</a> , I will take a look at this for you. Can you please provide me the following:</p>\n<ul>\n<li>Link to your workspace where you are experiencing this behavior</li>\n<li>Code example of how you are generating table, adding images, and assigning their labels. This will help me in attempting to recreate your specific issue.</li>\n</ul>\n<p>Thanks,<br>\nMohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-12T21:11:25.660Z",
				"Answer_body": "<p>Working on a locked workspace but here are some snippets of the issue:</p>\n<pre><code class=\"lang-auto\">for x in range(0, subset_val):\n        example_id = dataset[x][0]\n        data = dict(zip(field_names, dataset[x][1:]))\n        AddToTable(tbl, x, example_id, data)\n   \n\ndef AddToTable(table, indx, ex_id, data):\n \"\"\"Creating Face Label then adding to table\"\n   face_labels = wandb.Image(img, masks={\n        \"predictions\": {\n            \"mask_data\": face_data,\n            \"class_labels\": LabelMaker(face_data, \"face\")\n           }\n\n    })\n    table.add_data(indx, ex_id, roof_img, face_labels.....)\n\n\ndef LabelMaker(data, labelName):\n    total_unique_values = np.unique(data).size\n    myDict = {}\n    for x in range(0, total_unique_values):\n        myDict[x] = labelName + '_' + str(x+1)\n    return myDict\n</code></pre>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/4efefde7ec719eabb00ac07917331ad3c7497ea8.jpeg\" data-download-href=\"/uploads/short-url/bgPyJdrn1l7gIzi0FTcxI8RGEas.jpeg?dl=1\" title=\"Screen Shot 2022-07-12 at 5.05.45 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/4efefde7ec719eabb00ac07917331ad3c7497ea8_2_690x385.jpeg\" alt=\"Screen Shot 2022-07-12 at 5.05.45 PM\" data-base62-sha1=\"bgPyJdrn1l7gIzi0FTcxI8RGEas\" width=\"690\" height=\"385\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/4efefde7ec719eabb00ac07917331ad3c7497ea8_2_690x385.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/4efefde7ec719eabb00ac07917331ad3c7497ea8_2_1035x577.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/4efefde7ec719eabb00ac07917331ad3c7497ea8_2_1380x770.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/4efefde7ec719eabb00ac07917331ad3c7497ea8_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-07-12 at 5.05.45 PM</span><span class=\"informations\">1920\u00d71072 92.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Thanks!!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-12T21:13:39.945Z",
				"Answer_body": "<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d8c75acec2533edf97550ebba8004b38c189e2ff.jpeg\" data-download-href=\"/uploads/short-url/uVIfrEsos6BM91lb3hIEGK50gfd.jpeg?dl=1\" title=\"Screen Shot 2022-07-12 at 5.05.29 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d8c75acec2533edf97550ebba8004b38c189e2ff_2_447x500.jpeg\" alt=\"Screen Shot 2022-07-12 at 5.05.29 PM\" data-base62-sha1=\"uVIfrEsos6BM91lb3hIEGK50gfd\" width=\"447\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d8c75acec2533edf97550ebba8004b38c189e2ff_2_447x500.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d8c75acec2533edf97550ebba8004b38c189e2ff_2_670x750.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d8c75acec2533edf97550ebba8004b38c189e2ff_2_894x1000.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d8c75acec2533edf97550ebba8004b38c189e2ff_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-07-12 at 5.05.29 PM</span><span class=\"informations\">1008\u00d71126 78.4 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-21T21:49:49.801Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/uahmed1\">@uahmed1</a> , wanted to followup with you on this. If you were to log individual images with masks then yes, their unique classes get logged with them. In tables however we populated all class labels in the UI regardless of user input. I can understand why this leads to confusion for some users. I will bring it up to our teams attention for review on addressing this confusion.</p>\n<p>Regards</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-19T21:50:20.342Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Population Based Training",
		"Question_link": "https://community.wandb.ai/t/population-based-training/2773",
		"Question_created_time": "2022-07-19T05:18:05.013Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 210,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m interested in using population-based training as a WandB Sweep methodology as referenced in the article <a href=\"https://wandb.ai/wandb/DistHyperOpt/reports/Modern-Scalable-Hyperparameter-Tuning-Methods--VmlldzoyMTQxODM\">here</a>.</p>\n<p>However, I can\u2019t find any mention or tutorials for PBT with WandB outside of this article. I\u2019m interested in using PBT with a <a href=\"https://github.com/spaceml-org/Self-Supervised-Learner\" rel=\"noopener nofollow ugc\">self-supervised learner</a> and configuring the sweep in a YAML. Does anyone have any advice on how to go about this? I\u2019m familiar with configuring sweeps in a YAML or jupyter notebook but, I\u2019m unsure how to make the PBT scheduler and tuner (as outlined in the article) compatible with the SSL code I\u2019m using which is run from the command line.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-21T16:26:17.164Z",
				"Answer_body": "<p>Hi Anmol!</p>\n<p>Thanks for reaching out. We don\u2019t really have tutorials on PBT, but I found this repo with an implementation on PBT : <a href=\"https://github.com/voiler/PopulationBasedTraining\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">GitHub - voiler/PopulationBasedTraining: A simple PyTorch implementation of Population Based Training of Neural Networks.</a>, which should give you something to start with to integrate into your code.</p>\n<p>Is there anything specific to W&amp;B you are strugging with which I can help out with here?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-19T16:26:53.567Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Group runs from the UI after they all have finished",
		"Question_link": "https://community.wandb.ai/t/group-runs-from-the-ui-after-they-all-have-finished/2785",
		"Question_created_time": "2022-07-21T08:54:33.471Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 75,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I have some runs in my dashboard that I would like to group but I can\u2019t find a way to do it from the UI since from code is now impossible being them all finished. Is there a way to do it ?<br>\nThank you</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-21T11:08:03.616Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/riccardodm97\">@riccardodm97</a>, at the moment this is not possible, but we have an internal ticket tracking the request. I\u2019ll bump up its priority and let you know once this is possible.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-19T11:08:16.362Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Run crashed at end of epoch due to invalid name",
		"Question_link": "https://community.wandb.ai/t/run-crashed-at-end-of-epoch-due-to-invalid-name/2776",
		"Question_created_time": "2022-07-19T12:34:33.854Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 153,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I walked away from my run, only to come back and see it stopped after 1 epoch with:</p>\n<pre><code class=\"lang-auto\">  File \"/home/ubuntu/src/polez/conda/polez/lib/python3.9/site-packages/wandb/integration/keras/keras.py\", line 1019, in _save_model_as_artifact\n    model_artifact = wandb.Artifact(f\"model-{wandb.run.name}\", type=\"model\")\n  File \"/home/ubuntu/src/polez/conda/polez/lib/python3.9/site-packages/wandb/sdk/wandb_artifacts.py\", line 137, in __init__\n    raise ValueError(\nValueError: Artifact name may only contain alphanumeric characters, dashes, underscores, and dots. Invalid name: \"model-point-tall-fine,temp=0.2,batch=1024,custom_sched=false\"\n</code></pre>\n<p>I would much rather have found this out at the beginning when I called <code>wandb.init</code></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-20T20:14:39.666Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tbirch\">@tbirch</a>, This is not the run name which errors out, but the artifact name, which is why your program errored out after an epoch, on the call to <code>wandb.Artifact</code>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-26T21:53:04.140Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tbirch\">@tbirch</a>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-30T07:30:11.088Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tbirch\">@tbirch</a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-18T20:15:34.467Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Where is the confusion matrix saved on the dashboard?",
		"Question_link": "https://community.wandb.ai/t/where-is-the-confusion-matrix-saved-on-the-dashboard/2689",
		"Question_created_time": "2022-07-01T17:02:48.455Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 107,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019ve logged a confusion matrix like the below but I cannot find it listed anywhere on the dashboard of my project for any run. Indeed, I logged this for every step of the training (not every epoch). So where is the confusion matrix stored?</p>\n<pre><code class=\"lang-auto\">wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n                                y_true=target, preds=pred[0],\n                                class_names=class_names)})\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-01T22:19:29.260Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mesllo\">@mesllo</a> ,</p>\n<p>Would be happy to look into this for you. The matrix will be logged under the custom charts panel. Can you please provide the following:</p>\n<ul>\n<li>Wandb Version you are using</li>\n<li>Link to workspace where matrix isn\u2019t being logged</li>\n<li>Full traceback if available</li>\n<li>Also, if possible, a working colab with code example to take an attempt at replicating your work</li>\n</ul>\n<p>Thanks,</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-03T16:54:02.646Z",
				"Answer_body": "<p>I found out I had a bug in my code, now it is showing. However, I\u2019d like to show the counts for all steps rather than a single one. How I can use log() to aggregate all the counts for the confusion matrix like we do for loss and such?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-15T01:11:09.015Z",
				"Answer_body": "<p>HI <a class=\"mention\" href=\"/u/mesllo\">@mesllo</a> , I\u2019m glad you discovered that bug that was impacting your chart. In regards to show counts for all steps, that\u2019s not currently doable directly. This would have to be done locally where you keep track of your class predictions per step, aggregate the results and then log the confusion matrix to wandb.</p>\n<p>Although this doesn\u2019t address your particular request, you can generate a step slider for your matrix, see <a href=\"https://docs.wandb.ai/ref/app/features/custom-charts#how-to-show-a-step-slider-in-a-custom-chart\">here</a>, and you can see your confusion matrix results per step.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-20T18:37:12.884Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mesllo\">@mesllo</a> ,</p>\n<p>Since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-18T18:37:28.434Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Scatter plot instead of Line plot",
		"Question_link": "https://community.wandb.ai/t/scatter-plot-instead-of-line-plot/2706",
		"Question_created_time": "2022-07-06T15:08:14.265Z",
		"Question_answer_count": 7,
		"Question_score_count": 3,
		"Question_view_count": 240,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi everyone,</p>\n<p>regarding the different chart types, I am somehow missing the option \u2018<strong>Scatter plot</strong>\u2019 next to \u2018Line plot\u2019, \u2018Area plot\u2019, and \u2018Percent area plot\u2019. Would be great if you could add this feature in the future (or in case it can easily be done somehow else, please let me know how it works \u2013 I already tried custom scatter plots, but it seems as if they are meant for comparing different runs, not matrices from a single run).</p>\n<p>Thanks <img src=\"https://emoji.discourse-cdn.com/twitter/wink.png?v=12\" title=\":wink:\" class=\"emoji\" alt=\":wink:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-06T15:17:29.543Z",
				"Answer_body": "<p>I have been struggling with this as well. Would be very thankful about anyone\u2019s help!<br>\nThanks <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-07T21:39:29.598Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/aichberger\">@aichberger</a>  and <a class=\"mention\" href=\"/u/sflattinger\">@sflattinger</a> , you can log a custom scatter plot\u2014a list of points (x, y) on a pair of arbitrary axes x and y, see <a href=\"https://docs.wandb.ai/guides/track/log/plots#basic-charts\">here</a>, or directly in the UI under <strong>+ Add Panel</strong>, see screenshot.  Please let me know if you have additional questions.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/8af4bfd941934dbb8a3f15acd328a48055cebd3c.png\" data-download-href=\"/uploads/short-url/jPggnfhgHQp1P9staS6HiVjut6Q.png?dl=1\" title=\"ScatterPlot\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/8af4bfd941934dbb8a3f15acd328a48055cebd3c_2_283x375.png\" alt=\"ScatterPlot\" data-base62-sha1=\"jPggnfhgHQp1P9staS6HiVjut6Q\" width=\"283\" height=\"375\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/8af4bfd941934dbb8a3f15acd328a48055cebd3c_2_283x375.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/8af4bfd941934dbb8a3f15acd328a48055cebd3c.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/8af4bfd941934dbb8a3f15acd328a48055cebd3c.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/8af4bfd941934dbb8a3f15acd328a48055cebd3c_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">ScatterPlot</span><span class=\"informations\">407\u00d7537 27.2 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-11T13:22:51.755Z",
				"Answer_body": "<p>Thank you for the reply!<br>\nI have already tried to create scatter plots directly in the UI, but if I choose \u2018Step\u2019 on the x-axis and the metric of interest on the y-axis, each data point represents a total run within the project. However, I would like to plot the metric at each step of a single run (just like the line plot but without connecting the points). Also, changing the way this metric is logged isn\u2019t possible retrospectively.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-14T20:45:41.559Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/aichberger\">@aichberger</a> ,</p>\n<p>You can create a line chart with a dotted non connected line through the legend category within chart edit.  I believe that is what you are looking for, see image below. In terms of modifying how a metric is being logged, can you expand on your meaning behind this? You can currently update metrics for a run, after it has finished., see <a href=\"https://wandb.ai/mohammadbakir/Finance-Prediction?workspace=user-mohammadbakir\">here</a>.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/e4b37129b3b2dca4efe8af5082b5662e1e7fe5ea.png\" data-download-href=\"/uploads/short-url/wDbjAXgfUtaaLAXhq2VTVU9YU6C.png?dl=1\" title=\"DotChart\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e4b37129b3b2dca4efe8af5082b5662e1e7fe5ea_2_690x198.png\" alt=\"DotChart\" data-base62-sha1=\"wDbjAXgfUtaaLAXhq2VTVU9YU6C\" width=\"690\" height=\"198\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e4b37129b3b2dca4efe8af5082b5662e1e7fe5ea_2_690x198.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e4b37129b3b2dca4efe8af5082b5662e1e7fe5ea_2_1035x297.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e4b37129b3b2dca4efe8af5082b5662e1e7fe5ea_2_1380x396.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e4b37129b3b2dca4efe8af5082b5662e1e7fe5ea_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">DotChart</span><span class=\"informations\">1819\u00d7524 30 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-07-15T15:22:24.698Z",
				"Answer_body": "<p>Yeah that is exactly what I was looking for, thank you!<br>\nHowever, this has to be set for each run individually. This is why I suggested adding the option \u2018Scatter plot \u2019 next to \u2018Line plot\u2019, \u2018Area plot\u2019, and \u2018Percent area plot\u2019.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-20T18:17:17.462Z",
				"Answer_body": "<p>Thank you <a class=\"mention\" href=\"/u/aichberger\">@aichberger</a> , we are currently enhancing and improving our chart options, I will make note of your comments and share them with our app team. If you have any additional questions, please do reach back out again. I will mark this matter closed for now.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-18T18:17:28.737Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Point Clouds no longer 3D-viewable?",
		"Question_link": "https://community.wandb.ai/t/point-clouds-no-longer-3d-viewable/2770",
		"Question_created_time": "2022-07-18T23:34:53.727Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 109,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019ve been using the WandB 3D point cloud feature for a few months now to view my model\u2019s embeddings in 3D.  But recently my collaborators and I have notice that this feature seems to have been disabled\u2026?<br>\nNow when we mouse over a point cloud image, instead of getting the \u201cX\u201d in the top right in order to expand and going into 3D mode\u2026 nothing happens.<br>\n(How) Can we get 3D viz back for point clouds? This was an important feature.</p>\n<p>To reproduce: go to any WandB page for point cloud that used to be viewable in 3D, whether in documentation or in your own runs.  You will see that there is no longer a way to make it 3D.</p>\n<p>UPDATE: I notice that also <a href=\"https://wandb.ai/stacey/alphafold?workspace=user-stacey\">\u201c3D Molecules\u201d</a> are also no longer offered in 3D, rather only as static images.</p>\n<p>UPDATE 2: Yea I\u2019m thinking this is an unintentional bug.  Your <a href=\"https://wandb.ai/nbaryd/SparseConvNet-examples_3d_segmentation/reports/Point-Clouds--Vmlldzo4ODcyMA\">\u201c3D Objects Live Example\u201d</a> also no longer is 3D-viewable.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-19T16:20:26.502Z",
				"Answer_body": "<p>Update 3:<br>\nLooking at the JS console in Brave, I see several different sets of error messages.  One reads:</p>\n<pre><code class=\"lang-auto\">o151352.ingest.sentry.io/api/1201719/envelope/?sentry_key=6a30939a85c7404f9a1bc8e02147e62e&amp;sentry_version=7:1          Failed to load resource: net::ERR_BLOCKED_BY_CLIENT\n</code></pre>\n<p>another is</p>\n<pre><code class=\"lang-auto\">Failed to load resource: the server responded with a status of 422 ()\n</code></pre>\n<p>If I look at the one with molecules I see</p>\n<pre><code class=\"lang-auto\">3helpers.js:76 Uncaught TypeError: Failed to execute 'shaderSource' on 'WebGLRenderingContext': parameter 1 is not of type 'WebGLShader'.\n    at Kp (ngl.esm.js:17305:5)\n    at new Uw (ngl.esm.js:17890:23)\n    at Gw.acquireProgram (ngl.esm.js:18321:14)\n    at Nt (ngl.esm.js:23961:27)\n    at Rt (ngl.esm.js:24121:4)\n    at Ld.renderBufferDirect (ngl.esm.js:23114:17)\n    at vt (ngl.esm.js:23865:10)\n    at Ye (ngl.esm.js:23835:5)\n    at Ld.render (ngl.esm.js:23589:39)\n    at St.__renderSuperSample (ngl.esm.js:56300:25)\n    at St.__render (ngl.esm.js:56335:14)\n    at St.render (ngl.esm.js:56359:14)\n    at St.animate (ngl.esm.js:56043:14)\n    at i (helpers.js:73:23)\n</code></pre>\n<p>another other is</p>\n<pre><code class=\"lang-auto\">Failed to load resource: net::ERR_NAME_NOT_RESOLVED   api.wandb.ai/graphgl:1\n</code></pre>\n<p>and another is</p>\n<pre><code class=\"lang-auto\">Failed to load resource: the server responded with a status of 500 ()  api.wandb.ai/graphgl:1\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-19T16:27:00.836Z",
				"Answer_body": "<p>Here\u2019s <a href=\"https://wandb.ai/drscotthawley/dubstep-diffgan\">my example</a>, that\u2019s not working but used to.</p>\n<p>LINK FAILURE: In the WandB run page, I went to the point cloud panel I wanted to share and selected \u201cShare panel\u201d and then \u201cAnyone with the link can view\u201d but it\u2019s still not giving you a direct link to the pane.  So because it\u2019s not linking directly to the panel you\u2019ll have to scroll through \u201cMedia\u201d until you find \u201cembeddings_3dpca\u201d.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-20T11:09:52.099Z",
				"Answer_body": "<p>Thanks Scott, I\u2019ve filed a ticket for this. Will keep you updated.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-18T11:10:37.344Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sweep on remote cluster GPUs",
		"Question_link": "https://community.wandb.ai/t/sweep-on-remote-cluster-gpus/2731",
		"Question_created_time": "2022-07-09T17:40:56.681Z",
		"Question_answer_count": 5,
		"Question_score_count": 1,
		"Question_view_count": 279,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey. I\u2019m trying to run a sweep on a cluster GPUs by submitting it as a new job.<br>\nThe problem is that the job runs, but keep logging a network error:</p>\n<blockquote>\n<p>wandb: Network error (ConnectionError), entering retry loop.</p>\n</blockquote>\n<p>The script works fine if I\u2019m trying to run it \u201clocally\u201d in the cluster i.e. without submitting a GPU job.<br>\nMy intuition is that W&amp;B doesn\u2019t find my creds (.netrc file) on the node its running. So I was wondering if there is a way to directly pass my API key to the wandb.agent function, so that the script is independent of its execution environment?</p>\n<p>Thanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-13T13:45:56.973Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/andreakiro\">@andreakiro</a>,<br>\nYou can also use the environment variables <code>WANDB_API_KEY</code> and <code>WANDB_BASE_URL</code> (if using local server and not connecting to <a href=\"http://wandb.ai\">wandb.ai</a>) and <code>wandb</code> will look there instead of a <code>.netrc</code> file. Alternatively in Python you can use <code>wandb.login(key=&lt;your_api_key&gt;)</code> but we recommend using caution with this as you can potentially expose your API key since it is getting hard coded into your script.</p>\n<p>I\u2019m a little suspicious that this is the cause of your issues though as this usually shows up as an \u201cInvalid or missing API key\u201d error. If this doesn\u2019t resolve the issue, could you try to run <code>ping api.wandb.ai</code> (or whichever url endpoint you are trying to create runs to) on the cluster GPU to confirm that the GPU has no issue sending network packets to our backend?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-18T22:42:25.200Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/andreakiro\">@andreakiro</a> , sometimes cluster admins disable network access on compute nodes for security reasons. You may need to load a proxy module (this may depend on your cluster) before running your sweep so that it gets logged during training.<br>\nGood luck!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-20T04:06:17.665Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/andreakiro\">@andreakiro</a>,<br>\nI just wanted to follow up and see if you were still looking for help with this and if you had a chance to try running <code>ping</code> against <a href=\"http://api.wandb.ai\">api.wandb.ai</a>?<br>\nThank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-25T17:14:55.624Z",
				"Answer_body": "<p>Hi Andrea, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-18T04:06:33.472Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "WandbCallback of fastai crashing the colab session!",
		"Question_link": "https://community.wandb.ai/t/wandbcallback-of-fastai-crashing-the-colab-session/2743",
		"Question_created_time": "2022-07-13T10:02:31.185Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 292,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am trying to fine-tune the ULMFit language model using fastai library.</p>\n<p>For logging, I want to use wandb.</p>\n<p>To implement wandb in the model, I used WandbCallback.</p>\n<p>But, it always crashes the colab session at the end of training of an epoch.</p>\n<p>Initially, I thought the session is getting crashed due to a memory issue but when I used the same model with the same data but without wandb callback, it ran successfully.</p>\n<p>Below is the code that I have used.</p>\n<pre><code class=\"lang-auto\">from fastai.text.all import *\n\nfiles = get_text_files('digital_marketing_data')\n# digital_marketing_data is a folder that contains text files.\n\n# Here's how we use TextBlock to create a language model, using fastai's defaults:\n\nget_db = partial(get_text_files)\n\ndls_lm = DataBlock(\n    blocks=TextBlock.from_folder('digital_marketing_data', is_lm=True),\n    get_items=get_db, splitter=RandomSplitter(0.1)\n).dataloaders('digital_marketing_data', path='digital_marketing_data', bs=64//2, seq_len=100)\n\nimport wandb\nfrom fastai.callback.wandb import *\nimport os\n\nwandb.login()\n\n# Initializing a wandb run\nwandb.init(project='ulmfit_digital_marketing_finetune', name='Default Param with Minimum LR')\n\n# Model\ncp_name = 'model_with_minimum_lr'\nlearn = language_model_learner(\n    dls_lm, AWD_LSTM, drop_mult=0.3, cbs=[GradientAccumulation(n_acc=64),WandbCallback(),SaveModelCallback(fname=cp_name, every_epoch=True, with_opt=True)],\n    metrics=[accuracy, Perplexity()]).to_fp16()\n</code></pre>\n<p>When I ran the same code without WandbCallback(), then it ran successfully, but with WandbCallback() it always crashes the colab session.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-13T21:01:38.981Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sumit-wnb\">@sumit-wnb</a> ,</p>\n<p>We will take a look at this for you. Please provide a link to your workspace where you are experiencing this crash and debug logs associated with the run that is crashing. Logs can be found in the wandb folder in colab and will be within the folder sharing the run name.</p>\n<p>Thanks,<br>\nMohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-14T04:57:10.839Z",
				"Answer_body": "<p>Hi,</p>\n<p>Thanks for the reply.<br>\nBut I got the solution, which worked.</p>\n<p>So, WandbCallback(log_preds=False) with log_preds as False solves this issue.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-19T15:53:49.810Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sumit-wnb\">@sumit-wnb</a> , thank-you for updating us that you were able to resolve this issue. We will mark this closed.</p>\n<p>Regards,<br>\nMohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-17T15:54:09.994Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Rendering confusion matrix from 2D array",
		"Question_link": "https://community.wandb.ai/t/rendering-confusion-matrix-from-2d-array/2775",
		"Question_created_time": "2022-07-19T11:09:38.386Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 109,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have a ConfusionMatrix metric implemented as a subclass of tf.keras.metrics.Metric where the only value is a tf.Variable with shape=(13,13) and dtype=tf.uint32. In wandb UI this just shows up as a histogram, is there some way to reinterpret this as a multilabel confusion matrix?</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/ce373dcc3a5f1e93c916b79e77166b17d8006c2c.png\" data-download-href=\"/uploads/short-url/tqgId0mKmRahaQW7TqrvTeIns4Y.png?dl=1\" title=\"Screen Shot 2022-07-19 at 9.09.20 pm\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ce373dcc3a5f1e93c916b79e77166b17d8006c2c_2_690x446.png\" alt=\"Screen Shot 2022-07-19 at 9.09.20 pm\" data-base62-sha1=\"tqgId0mKmRahaQW7TqrvTeIns4Y\" width=\"690\" height=\"446\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ce373dcc3a5f1e93c916b79e77166b17d8006c2c_2_690x446.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/ce373dcc3a5f1e93c916b79e77166b17d8006c2c.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/ce373dcc3a5f1e93c916b79e77166b17d8006c2c.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ce373dcc3a5f1e93c916b79e77166b17d8006c2c_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-07-19 at 9.09.20 pm</span><span class=\"informations\">874\u00d7566 16.8 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-20T11:01:34.485Z",
				"Answer_body": "<p>Hey Tom, it\u2019s not possible at the moment. You\u2019ll need to use wandb.plot.confusion_matrix() for that.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-17T11:10:29.341Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Track power/energy consumption?",
		"Question_link": "https://community.wandb.ai/t/track-power-energy-consumption/2774",
		"Question_created_time": "2022-07-19T07:47:56.213Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 79,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hey all,</p>\n<p>I wondered if there was a way to track system power consumption caused by model development? I\u2019ve checked the W&amp;B docs and can\u2019t see anything.<br>\nIdeally I\u2019d love to be able to keep track of runs to see how much power is used by different runs but also the whole project.</p>\n<p>Elsewhere I\u2019ve seen packages such as <a href=\"https://pypi.org/project/energyusage/\" rel=\"noopener nofollow ugc\">energyusage</a> but ideally would like to use something more integrated and could be aggregated across runs for whole projects.<br>\nIf something already exists I\u2019d love to hear about it, otherwise either if W&amp;B fancied adding this functionality that would be great or if it came to it if anyone would like to help me with this project.</p>\n<p>Thanks,</p>\n<p>Jeff.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-19T08:08:15.949Z",
				"Answer_body": "<p>Hi,<br>\nWe have this example that shows how to do this with CodeCarbon.<br>\n<a href=\"https://wandb.ai/amanarora/codecarbon/reports/Tracking-CO2-Emissions-of-Your-Deep-Learning-Models-with-CodeCarbon-and-Weights-Biases--VmlldzoxMzM1NDg3\">https://wandb.ai/amanarora/codecarbon/reports/Tracking-CO2-Emissions-of-Your-Deep-Learning-Models-with-CodeCarbon-and-Weights-Biases\u2013VmlldzoxMzM1NDg3</a></p>\n<p>You would use that library and log the info yourself. I do appreciate the feature request to integrate these more tightly.<br>\nThanks, hope this helps</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-07-19T08:12:32.212Z",
				"Answer_body": "<p>Hi Scott,</p>\n<p>This is great, thank you. I wasn\u2019t aware of CodeCarbon so I\u2019ll take a look. Great as always that W&amp;B has a nice article with an example to follow along with.</p>\n<p>Thanks,<br>\nJeff.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-17T08:12:38.581Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "W&B Sweeps w/ Self-Supervised Learning",
		"Question_link": "https://community.wandb.ai/t/w-b-sweeps-w-self-supervised-learning/2579",
		"Question_created_time": "2022-06-08T20:21:31.416Z",
		"Question_answer_count": 6,
		"Question_score_count": 1,
		"Question_view_count": 569,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m reaching out to get some thoughts on integrating W&amp;B Sweeps with some of the code we\u2019re interested in using. An example of the code we\u2019re running is linked <a href=\"https://streaklinks.com/BEDYVhxBgS02lmUdIwa1e2xV/https%3A%2F%2Fgithub.com%2Fspaceml-org%2FSelf-Supervised-Learner%2Fblob%2Fmain%2Ftutorials%2FPythonColabTutorial_Merced.ipynb\" rel=\"noopener nofollow ugc\">here</a>. Note the 2 key sections \u2018Training Self-Supervised Learning Model\u2019 and \u2018Fine Tuning Model\u2019 which contain the !python commands we\u2019re interested in tuning (model, technique, learning rate, etc.)</p>\n<p>Based on <a href=\"https://streaklinks.com/BEDYVh1Fxefx8VZVJQh5ZZi-/https%3A%2F%2Fdocs.wandb.ai%2Fguides%2Fsweeps%2Fpython-api\" rel=\"noopener nofollow ugc\">this documentation</a>, I\u2019ve set up sweep_config but I\u2019m unsure how to incorporate the 2 !python commands in train() when running an agent. Do you have any input on how to integrate a wandb sweep with these 2 commands?</p>\n<p>An additional point I wanted to discuss was the strategy for a Sweep. The SSL code we\u2019re running requires training 2 sequential models (the SSL and the final classification Model) where the output SSL model is the input to the final classification model (see the linked code above). We\u2019re interested in doing hyperparameter tuning for both of the models - should we set up 2 independent sweeps for each? Or should we run a sweep on the first SSL model, pick the best performing model and use that as the input into the second classification model where we run a second sweep?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-13T14:54:29.653Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/anmolseth\">@anmolseth</a>, thank you for writing in!</p>\n<p>Have you looked into using a custom command in your sweep config? <a href=\"https://docs.wandb.ai/guides/sweeps/configuration#command\">Here</a> is some information on this. You can pass any arguments for the sweep in via the command line so that your train.py can pick them up there instead of through <code>wandb.config</code></p>\n<p>As for the second part of your question,  I can\u2019t speak to which method would give better accuracy but my intuition would tell me that optimizing your input model first, and then using that model in the sweep for the second model would give a better result. Sweeping over both independently may lead the second model to expect input data to look differently than it will look from an optimized version of the first model.</p>\n<p>Let me know if you have any further questions on either of these and I\u2019d be happy help out.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-17T17:48:44.850Z",
				"Answer_body": "<p>Thanks <a class=\"mention\" href=\"/u/nathank\">@nathank</a>! The custom command functionality seems to be well-suited for my use case. I wanted to follow up on how to set up SSL\u2019s train.py to be compatible with command line Sweeps. The <a href=\"https://github.com/spaceml-org/Self-Supervised-Learner/blob/c1a20d1ba417fc1dd47438ab4a066396af31f98b/train.py\" rel=\"noopener nofollow ugc\">SSL train.py</a> <code>cli_main()</code> method includes <code>ArgumentParser()</code> to pull out the arguments from command line but this parser doesn\u2019t seem to be present in any of the W&amp;B examples online.</p>\n<p>Do you know if this parser is needed to be compatible with W&amp;B command line sweeps? Additionally, are there are any other changes I should be making to the <a href=\"https://github.com/spaceml-org/Self-Supervised-Learner/tree/main\" rel=\"noopener nofollow ugc\">SSL code</a> to get prepped for my first Sweep?</p>\n<p>Thank you,<br>\nAnmol</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-24T22:24:26.496Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/anmolseth\">@anmolseth</a>,<br>\nWhat parameters would you like to sweep over? It looks like the <code>ArgumentParser()</code> is already setup to take in a number of arguments. If you are sweeping over parameters that <code>ArgumentParser()</code> already handles then it will simply grab them automatically from the sweep if you use the same name for them.</p>\n<p>If not you will need to add arguments to the parser for any additions parameters you would like to sweep over and make sure your model is using the arguments passed in via the <code>ArgumentParser()</code></p>\n<p>Other than that, you should be ready to start your sweep. Let me know if you have any issues and I\u2019d be happy to help!</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-01T13:59:35.299Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/anmolseth\">@anmolseth</a>,<br>\nI wanted to follow up and see if you would like any additional help with this or if you were able to get your sweep running?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-19T05:12:20.280Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nathank\">@nathank</a> ,</p>\n<p>Thanks for following up. I\u2019ve run into a few issues which I suspect are related. I\u2019ve set up and tried running a random sweep and bayesian sweep with asynchronous hyperband but both are running into the same errors. Here\u2019s the YAML file for my random sweep as reference:</p>\n<pre><code class=\"lang-auto\">&gt; method: random\n&gt; metric:\n&gt;   goal: minimize\n&gt;   name: 'loss'\n&gt; parameters:\n&gt;   model:\n&gt;     distribution: categorical\n&gt;     values:\n&gt;       - imagenet_resnet18\n&gt;       - imagenet_resnet50\n&gt;       - resnet18\n&gt;       - resnet50\n&gt;       - minicnn32\n&gt;   technique:\n&gt;     distribution: categorical\n&gt;     values:\n&gt;       - SIMCLR\n&gt;       - SIMSIAM\n&gt;   log_name:\n&gt;     value: log_name\n&gt;   DATA_PATH:\n&gt;     value: /home/jovyan/efs/split_data_SIMCLR_rad_mini/train\n&gt;   VAL_PATH:\n&gt;     value: /home/jovyan/efs/split_data_SIMCLR_rad_mini/val\n&gt;   batch_size:\n&gt;     distribution: categorical\n&gt;     values:\n&gt;         - 8\n&gt;         - 16\n&gt;         - 32\n&gt;         - 64\n&gt;         - 128\n&gt;         - 256\n&gt;   learning_rate:\n&gt;     distribution: categorical\n&gt;     values:\n&gt;         - 1\n&gt;         - 1e-1\n&gt;         - 1e-2\n&gt;         - 1e-3\n&gt;         - 1e-4\n&gt;         - 1e-5\n&gt;         - 1e-6\n&gt;         - 1e-7\n&gt;   patience:\n&gt;     distribution: categorical\n&gt;     values:\n&gt;         - 1\n&gt;         - 5\n&gt;         - 10\n&gt;         - 20\n&gt;   CPU:\n&gt;     value: 4\n&gt;   GPU:\n&gt;     value: 1\n&gt; program: /home/jovyan/efs/SSL/train.py\n</code></pre>\n<p>I\u2019m trying to log a relevant metric to evaluate model performance and have tried both \u2018loss\u2019 and \u2018val_loss\u2019 which are present in the SSL model training outputs. However, the following error message shows up whenever I queue up a sweep: <code>RuntimeError: Early stopping conditioned on metric </code>val_loss<code>which is not available. Pass in or modify your</code>EarlyStopping<code>callback to use any of the following:</code>loss``</p>\n<p>Here\u2019s the full error message for reference:</p>\n<pre><code class=\"lang-auto\">\n&gt; Traceback (most recent call last):\n  File \"/home/jovyan/efs/SSL/train.py\", line 169, in &lt;module&gt;\n    cli_main()\n  File \"/home/jovyan/efs/SSL/train.py\", line 162, in cli_main\n    trainer.fit(model)\n  File \"/home/jovyan/ai4ls2/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 510, in fit\n    results = self.accelerator_backend.train()\n  File \"/home/jovyan/ai4ls2/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 57, in train\n    return self.train_or_test()\n  File \"/home/jovyan/ai4ls2/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 74, in train_or_test\n    results = self.trainer.train()\n  File \"/home/jovyan/ai4ls2/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 561, in train\n    self.train_loop.run_training_epoch()\n  File \"/home/jovyan/ai4ls2/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\", line 625, in run_training_epoch\n    self.trainer.run_evaluation(on_epoch=True)\n  File \"/home/jovyan/ai4ls2/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 669, in run_evaluation\n    self.evaluation_loop.on_evaluation_end()\n  File \"/home/jovyan/ai4ls2/lib/python3.8/site-packages/pytorch_lightning/trainer/evaluation_loop.py\", line 101, in on_evaluation_end\n    self.trainer.call_hook('on_validation_end', *args, **kwargs)\n  File \"/home/jovyan/ai4ls2/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 926, in call_hook\n    trainer_hook(*args, **kwargs)\n  File \"/home/jovyan/ai4ls2/lib/python3.8/site-packages/pytorch_lightning/trainer/callback_hook.py\", line 177, in on_validation_end\n    callback.on_validation_end(self, self.get_model())\n  File \"/home/jovyan/ai4ls2/lib/python3.8/site-packages/pytorch_lightning/callbacks/early_stopping.py\", line 162, in on_validation_end\n    self._run_early_stopping_check(trainer, pl_module)\n  File \"/home/jovyan/ai4ls2/lib/python3.8/site-packages/pytorch_lightning/callbacks/early_stopping.py\", line 173, in _run_early_stopping_check\n    or not self._validate_condition_metric(logs)  # short circuit if metric not present\n  File \"/home/jovyan/ai4ls2/lib/python3.8/site-packages/pytorch_lightning/callbacks/early_stopping.py\", line 132, in _validate_condition_metric\n    raise RuntimeError(error_msg)\nRuntimeError: Early stopping conditioned on metric `val_loss` which is not available. Pass in or modify your `EarlyStopping` callback to use any of the following: `loss`\n\n</code></pre>\n<p>This causes all runs to fail and often not log any relevant metrics for evaluation. For example, here\u2019s one of the outputs of a recent sweep which trained multiple models but didn\u2019t log loss for any of them:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/dbc7a0e386a650047425be7afbd5e92006bfb361.jpeg\" data-download-href=\"/uploads/short-url/vmggCpnXAeThluYy7Anc75Pw8sF.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dbc7a0e386a650047425be7afbd5e92006bfb361_2_690x150.jpeg\" alt=\"image\" data-base62-sha1=\"vmggCpnXAeThluYy7Anc75Pw8sF\" width=\"690\" height=\"150\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dbc7a0e386a650047425be7afbd5e92006bfb361_2_690x150.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dbc7a0e386a650047425be7afbd5e92006bfb361_2_1035x225.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dbc7a0e386a650047425be7afbd5e92006bfb361_2_1380x300.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dbc7a0e386a650047425be7afbd5e92006bfb361_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1562\u00d7340 123 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>My current sweep workflow entails logging in to wandb, creating a sweep from the YAML, and then executing the sweep using the wandb agent.</p>\n<p>Do you have any advice on how to resolve this logging issue? The bayesian sweeps I\u2019ve tried are running into the same issues.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-17T05:12:34.035Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "WandB icevision not showing prediction",
		"Question_link": "https://community.wandb.ai/t/wandb-icevision-not-showing-prediction/2767",
		"Question_created_time": "2022-07-18T10:53:29.792Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 215,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello everyone,</p>\n<p>I am using WanbB in IceVision through the fastai integration, you could have a look here for <a href=\"https://airctic.com/0.12.0/wandb_efficientdet/\" rel=\"noopener nofollow ugc\">IceVision WandB</a> but i get the following message:</p>\n<pre><code class=\"lang-auto\">Could not gather input dimensions\nWandbCallback was not able to prepare a DataLoader for logging prediction samples -&gt; 'Dataset' object has no attribute 'items'\n</code></pre>\n<p>Any help appreciated.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-20T17:21:42.676Z",
				"Answer_body": "<p>Hi Fabio, can you give me more information on your case? For example, how are you implementing IceVision WandB and what tools are you using when you do so?</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-25T21:48:48.036Z",
				"Answer_body": "<p>Hi Fabio, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-16T10:54:22.351Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Confusion with resume=true",
		"Question_link": "https://community.wandb.ai/t/confusion-with-resume-true/2765",
		"Question_created_time": "2022-07-17T20:01:10.757Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 115,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I just started using wandb,  and I wanted to train two models over the weekend on 1 GPU, but after a while one of them crashed due to lack of memory. I reduced the val batch size then added <code>resume=true</code> to the call to <code>wandb.init</code> and things started progressing. Checking in over the weekend I saw that only one run was \u201crunning\u201d, the other was \u201ccrashed\u201d. I went to look at the actual terminal session where I launched the jobs, and they were both still running.</p>\n<p>At this point I had 2 runs under my project, as I\u2019d deleted all the previous failed attempts. I assumed I\u2019d accidentally deleted the wrong run from the UI, but when I looked at the graphs I saw that training accuracy and loss went backwards at one epoch.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/29dbf206a3c71f94328089a40ddcafa4b6a0b523.png\" data-download-href=\"/uploads/short-url/5YiO2JPEIhGDLezHYJTY91QO9BV.png?dl=1\" title=\"Screen Shot 2022-07-18 at 5.28.13 am\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/29dbf206a3c71f94328089a40ddcafa4b6a0b523_2_381x500.png\" alt=\"Screen Shot 2022-07-18 at 5.28.13 am\" data-base62-sha1=\"5YiO2JPEIhGDLezHYJTY91QO9BV\" width=\"381\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/29dbf206a3c71f94328089a40ddcafa4b6a0b523_2_381x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/29dbf206a3c71f94328089a40ddcafa4b6a0b523_2_571x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/29dbf206a3c71f94328089a40ddcafa4b6a0b523_2_762x1000.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/29dbf206a3c71f94328089a40ddcafa4b6a0b523_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-07-18 at 5.28.13 am</span><span class=\"informations\">920\u00d71206 49.8 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>This shouldn\u2019t happen, so I went to look at the logs for the runs in MLFlow (still using it as I try out wandb) and the train accuracy for both runs was monotonically increasing. Looking closer at the actual values and the logs, I think both runs are submitting values to the same \u201crun\u201d. The graph was saying accuracy was 0.973 at epoch 6, and 0.9711 at epoch 7. Looking at my terminal logs for the most recent epoch for each run, I saw:</p>\n<p>point-tall-fine:  loss: 0.3797 - acc: 0.9730<br>\npoint-tall-baseline: loss: 0.3842 - acc: 0.9711</p>\n<p>Scrolling up to the top of each log, I see both are using <code>runs/ajydp67n</code>. I\u2019m guessing  this is because I didn\u2019t specify anything other than config when calling init,  does wandb not disambiguate runs based on the value of <code>config</code>?</p>\n<p><code>wandb.init(config=wandb_args, resume=True)</code></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-17T20:17:20.547Z",
				"Answer_body": "<p>Potentially unrelated, I saw logs re: saving my model:</p>\n<pre><code class=\"lang-auto\">wandb: ERROR Can't save model in the h5py format. The model will be saved as W&amp;B Artifacts in the SavedModel format.\nWARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_2 in the SavedModel.\nWARNING:absl:Found untraced functions such as _precision, _recall, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 22). These functions will not be directly callable after loading.\nwandb: Adding directory to artifact (/.../wandb/run-20220717_000101-ajydp67n/files/model-best)... Done. 0.1s\n</code></pre>\n<p>but when I look, there\u2019s nothing called \u201cmodel-best\u201d in <code>wandb/run-20220717_000101-ajydp67n/files</code>. There are a bunch of logs there, but nothing that looks like a serialized model.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-18T05:31:59.765Z",
				"Answer_body": "<p>Reading the docs it seems like this is expected behaviour, still annoying though. I feel like at least wandb should crash if trying to join a run that is already \u201crunning\u201d, and even better would be to automatically discover the run-ID to resume based on config values.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-20T17:50:58.601Z",
				"Answer_body": "<p>Hi Tom thank you for writing in regarding this issue. May I ask if you had wandb.finish() at the end of 1st run?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-01T09:13:10.995Z",
				"Answer_body": "<p>Hi TomBirch,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-08T09:44:18.154Z",
				"Answer_body": "<p>Hi Tom, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-16T05:32:58.657Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Runs log stops at 50",
		"Question_link": "https://community.wandb.ai/t/runs-log-stops-at-50/2696",
		"Question_created_time": "2022-07-04T12:02:27.013Z",
		"Question_answer_count": 9,
		"Question_score_count": 0,
		"Question_view_count": 220,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello, i am running wandb locally in my computer. I start a sweep and it runs smoothly, but when it reaches 50 runs it stops. Although kernel seems to be running it does not show any runs in the wandb site nor locally files in my computer. Does anyone know what seems to be the problem? I can provide any logs if requested, i don\u2019t know what to post and be helpful.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-07T00:31:30.034Z",
				"Answer_body": "<p>Hi John, can you give me more information on how you set up your Sweep? For example, are you using grid search? If so, can you change to random search and see if you are still running into the same problem with it crashing at 50 runs? This might be due to a specific parameter configuration crashing the sweeps.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-09T13:23:13.763Z",
				"Answer_body": "<p>Hello, i have the same issue with another computer, this one stopped at 32 runs. The same code in google colab runs just fine. Could be a hardware issue? It is a grid search.</p>\n<p>sweep_config = {<br>\n\u2018method\u2019: \u2018grid\u2019<br>\n}</p>\n<p>metric = {<br>\n\u2018name\u2019: \u2018loss\u2019,<br>\n\u2018goal\u2019: \u2018minimize\u2019<br>\n}</p>\n<p>sweep_config[\u2018metric\u2019] = metric</p>\n<p>parameters_dict = {<br>\n\u2018learning-rate\u2019:{<br>\n\u2018values\u2019: [0.001, 0.0001, 0.002]<br>\n},<br>\n\u2018conv1\u2019: {<br>\n\u2018values\u2019: [32, 48, 64]<br>\n},<br>\n\u2018conv2\u2019: {<br>\n\u2018values\u2019: [48, 64, 128]<br>\n},<br>\n\u2018conv3\u2019: {<br>\n\u2018values\u2019: [64, 128, 256]<br>\n},<br>\n\u2018dropout\u2019: {<br>\n\u2018values\u2019: [0.2, 0.3]<br>\n},<br>\n\u2018batch_size\u2019: {<br>\n\u2018values\u2019: [64, 128, 256]<br>\n},<br>\n}</p>\n<p>sweep_config[\u2018parameters\u2019] = parameters_dict<br>\nparameters_dict.update({<br>\n\u2018epochs\u2019: {<br>\n\u2018value\u2019: 10}<br>\n})</p>\n<p>pprint.pprint(sweep_config)</p>\n<p>Last log:<br>\n2022-07-08T17:17:49.759534 Sending commands to agent c6swh3i1: [{\u201crun_id\u201d:\u201ckbabazlh\u201d,\u201cprogram\u201d:\u201c\u201d,\u201ctype\u201d:\u201crun\u201d,\u201cargs\u201d:{\u201cbatch_size\u201d:{\u201cvalue\u201d:64},\u201cconv1\u201d:{\u201cvalue\u201d:32},\u201cconv2\u201d:{\u201cvalue\u201d:64},\u201cconv3\u201d:{\u201cvalue\u201d:256},\u201cdropout\u201d:{\u201cvalue\u201d:0.2},\u201cepochs\u201d:{\u201cvalue\u201d:10},\u201clearning-rate\u201d:{\u201cvalue\u201d:0.001}},\u201crunqueue_item_id\u201d:\u201cUnVuUXVldWVJdGVtOjEyNTk3MDUzNQ==\u201d,\u201clogs\u201d:<span class=\"chcklst-box fa fa-square-o fa-fw\"></span>,\u201crun_storage_id\u201d:\u201cUnVuOnYxOmtiYWJhemxoOkVNR18xOnBvZGlrYWtvcw==\u201d}]</p>\n<p>2022-07-08T17:19:21.436651 Launched new run 113o3dnp (decent-sweep-32)</p>\n<p>2022-07-08T17:19:21.465885 Sending commands to agent c6swh3i1: [{\u201crun_id\u201d:\u201c113o3dnp\u201d,\u201cprogram\u201d:\u201c\u201d,\u201ctype\u201d:\u201crun\u201d,\u201cargs\u201d:{\u201cbatch_size\u201d:{\u201cvalue\u201d:64},\u201cconv1\u201d:{\u201cvalue\u201d:32},\u201cconv2\u201d:{\u201cvalue\u201d:64},\u201cconv3\u201d:{\u201cvalue\u201d:256},\u201cdropout\u201d:{\u201cvalue\u201d:0.2},\u201cepochs\u201d:{\u201cvalue\u201d:10},\u201clearning-rate\u201d:{\u201cvalue\u201d:0.0001}},\u201crunqueue_item_id\u201d:\u201cUnVuUXVldWVJdGVtOjEyNTk3MDUzNg==\u201d,\u201clogs\u201d:<span class=\"chcklst-box fa fa-square-o fa-fw\"></span>,\u201crun_storage_id\u201d:\u201cUnVuOnYxOjExM28zZG5wOkVNR18xOnBvZGlrYWtvcw==\u201d}]</p>\n<p>2022-07-08T17:35:19.290112 Agent c6swh3i1 state changed from ERROR to RUNNING</p>\n<p>2022-07-08T17:55:11.671631 Agent c6swh3i1 state changed from ERROR to RUNNING</p>\n<p>2022-07-08T18:15:13.199534 Agent c6swh3i1 state changed from ERROR to RUNNING</p>\n<p>2022-07-08T18:35:13.31471 Agent c6swh3i1 state changed from ERROR to RUNNING</p>\n<p>2022-07-08T18:55:15.914243 Agent c6swh3i1 state changed from ERROR to RUNNING</p>\n<p>2022-07-08T19:15:11.71383 Agent c6swh3i1 state changed from ERROR to RUNNING</p>\n<p>2022-07-08T19:35:17.42472 Agent c6swh3i1 state changed from ERROR to RUNNING</p>\n<p>2022-07-08T19:55:16.585164 Agent c6swh3i1 state changed from ERROR to RUNNING</p>\n<p>2022-07-08T20:15:17.665501 Agent c6swh3i1 state changed from ERROR to RUNNING</p>\n<p>2022-07-08T20:35:13.42555 Agent c6swh3i1 state changed from ERROR to RUNNING</p>\n<p>2022-07-08T20:55:16.863404 Agent c6swh3i1 state changed from ERROR to RUNNING</p>\n<p>2022-07-08T21:15:12.686781 Agent c6swh3i1 state changed from ERROR to RUNNING</p>\n<p>2022-07-08T21:35:11.491317 Agent c6swh3i1 state changed from ERROR to RUNNING</p>\n<p>2022-07-08T21:55:11.980649 Agent c6swh3i1 state changed from ERROR to RUNNING</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-12T16:31:15.460Z",
				"Answer_body": "<p>Hi John, is there a reason why you need to use grid search? Because of the configuration that is not working properly, it would be better to use random search in this circumstance.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-15T19:41:14.016Z",
				"Answer_body": "<p>Hi John,</p>\n<p>Do you still need help here?</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-17T21:51:30.158Z",
				"Answer_body": "<p>Hello,</p>\n<p>this configuration runs properly in google colab. The reason i use grid search is because i need to explore all possible configurations. Why do i get this error? Any ideas? Is grid search problematic with any particular version of python or tensorflow?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-28T19:49:49.416Z",
				"Answer_body": "<p>That\u2019s interesting, if it works in one place, it should work in the other. Can you send me the debug logs of when you ran it in your terminal please?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-05T15:13:09.352Z",
				"Answer_body": "<p>Do you still need help here John?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-10T17:28:59.862Z",
				"Answer_body": "<p>Hi John, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-15T21:52:23.432Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sweep run not closing",
		"Question_link": "https://community.wandb.ai/t/sweep-run-not-closing/2639",
		"Question_created_time": "2022-06-21T22:07:39.393Z",
		"Question_answer_count": 10,
		"Question_score_count": 1,
		"Question_view_count": 258,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am trying to run sweep for hyperparameter tuning. This was to get the best parameters according to val_loss and use those to retrain another model.<br>\nBut the problem is that when I implement both these steps instead of creating a separate run for the retraining of model it repeats the last run of sweep.<br>\nA template of my script</p>\n<pre><code class=\"lang-auto\">#Login into account\nwandb.login()\n\nsweep_config_up = {\n    'method': 'bayes',\n    'metric':{\n    'name': 'val_loss',\n    'goal': 'minimize'\n    },\n    'parameters': {\n        'dropout':{\n          'values':[0.2, 0.25]\n        },\n        'hidden_layer_size':{\n          'values':[128,256]\n        },\n        'layer_1_size':{\n          'values':[8,16,32]\n        },\n        'layer_2_size': {\n          'values': [32, 64, 96]\n      },\n          'decay':{\n            'values':[1e-6, 1e-5]\n          },\n          'momentum':{\n            'values':[0.85, 0.9]\n          },\n          'epoch': {\n            'values' : [5, 10]\n      },\n          'learn_rate': {\n        # a flat distribution between 0 and 0.1\n        'distribution': 'uniform',\n        'min': 0,\n        'max': 0.01\n        }\n    }\n}\n\ndef build_model(config, img_width, img_height, num_classes):\n  config = config\n  model = Sequential()\n  model.add(Conv2D(config.layer_1_size, (5, 5), activation='relu',\n                    input_shape=(img_width, img_height, 1)))\n  model.add(MaxPooling2D(pool_size=(2, 2)))\n  model.add(Conv2D(config.layer_2_size, (5, 5), activation='relu'))\n  model.add(MaxPooling2D(pool_size=(2, 2)))\n  model.add(Dropout(config.dropout))\n  model.add(Flatten())\n  model.add(Dense(config.hidden_layer_size, activation='relu'))\n  model.add(Dense(num_classes, activation='softmax'))\n  return model\n\ndef load_data(width, height):\n  (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n  labels = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n            \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n\n  img_width, img_height = width, height\n\n  X_train = X_train.astype('float32') / 255.\n  X_test = X_test.astype('float32') / 255.\n\n  # reshape input data -- add channel dimension\n  X_train = X_train.reshape(X_train.shape[0], img_width, img_height, 1)\n  X_test = X_test.reshape(X_test.shape[0], img_width, img_height, 1)\n\n  # one hot encode outputs\n  y_train = np_utils.to_categorical(y_train)\n  y_test = np_utils.to_categorical(y_test)\n  num_classes = y_test.shape[1]\n  return X_train, y_train, X_test, y_test, num_classes, labels\n\ndef model_train():\n  #intialize the wandb\n  config_defaults = dict(\n    dropout=0.2,\n    hidden_layer_size=128,\n    layer_1_size=16,\n    layer_2_size=32,\n    learn_rate=0.01,\n    decay=1e-6,\n    momentum=0.9,\n    epoch=30,\n    )\n  run = wandb.init(reinit = True, config=config_defaults, magic=True, group='sweep_runings', job_type = 'training_new')\n  with run: \n    config = wandb.config\n    #specify height and width of the image\n    img_width, img_height = 28, 28\n    #load the data\n    X_train, y_train, X_test, y_test, num_classes, labels = load_data(img_width, img_height)\n    #build the model\n    model = build_model(config, img_width, img_height, num_classes)\n    #define the callbacks \n    callbacks = [WandbCallback(data_type=\"image\", labels=labels)]\n    #define the optimizer\n    sgd = SGD(learning_rate=config.learn_rate, decay=config.decay, momentum=config.momentum,\n            nesterov=True)\n    #compile and fit the model\n    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n    model.fit(X_train, y_train,  validation_data=(X_test, y_test),\n            epochs=config.epoch,\n            callbacks=callbacks\n            )\n\nsweep_id = wandb.sweep(sweep_config_up, project=\"sweeps\")\n\nwandb.agent(sweep_id, function = model_train, count=2)\n\nwandb.finish()\n\nprint('--------------------------------------------------------finish_train model-------------------------------------------------')\n\n\nprint('--------------------------------------------------------Retrain model-------------------------------------------------')\n\n#get best model paramaters\napi = wandb.Api()\napi_dir = 'some/sweeps/'\nsweep = api.sweep(os.path.join(api_dir,sweep_id))\n\n# Get best run parameters\nbest_run = sweep.best_run()\nbest_parameters = best_run.config\nprint(best_parameters)\n\nwandb.finish()\n\nmodel_path = os.getcwd()\nmodel_name = 'model.h5'\nprefix = 'cnn_model'\n\n#retrain the model and log weights \ndef retrain_model(best_parameters, model_path, model_name, prefix):\n  project_name = \"sweeps\"\n  run = wandb.init(reinit=True ,config=best_parameters, project = project_name, group='best_model', job_type = 'training_new_model' )\n  #specify height and width of the image\n  with run:\n    config = wandb.config\n    img_width, img_height = 28, 28\n    #load the data\n    X_train, y_train, X_test, y_test, num_classes, labels = load_data(img_width, img_height)\n    #build the model\n    model = build_model(config, img_width, img_height, num_classes)\n    #define the callbacks \n    callbacks = [WandbCallback(data_type=\"image\", labels=labels, log_weights=True)]\n    #define the optimizer\n    sgd = SGD(learning_rate=config.learn_rate, decay=config.decay, momentum=config.momentum,\n          nesterov=True)\n    #compile and fit the model\n    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n    model.fit(X_train, y_train,  validation_data=(X_test, y_test),\n          epochs=config.epoch,\n          callbacks=callbacks\n            )\n    model.save(model_name)\n\n    #weight model display structure\n    weight_at = \"_\".join([prefix, \"weights\"])\n    #create artifact\n    weight_model_at = wandb.Artifact(weight_at, type=\"model_weight\", metadata = best_parameters)            \n\n    # save trained model as artifact\n    weight_model_at.add_file(os.path.join(model_path, model_name))            \n                \n    # save artifact to W&amp;B\n    run.log_artifact(weight_model_at)\n\n    run.finish()\n\nretrain_model(best_parameters, model_path, model_name, prefix)\n\nprint('--------------------------------------------------------finish_Retrain model-------------------------------------------------')\n\n\n</code></pre>\n<p>Here is an image of the resulting runs</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/05b833eb6f6ee05cd2afa1b50acfc755e3878d51.png\" data-download-href=\"/uploads/short-url/OB2tYgbhTKU83XM1uVZZrotC37.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/05b833eb6f6ee05cd2afa1b50acfc755e3878d51_2_337x500.png\" alt=\"image\" data-base62-sha1=\"OB2tYgbhTKU83XM1uVZZrotC37\" width=\"337\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/05b833eb6f6ee05cd2afa1b50acfc755e3878d51_2_337x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/05b833eb6f6ee05cd2afa1b50acfc755e3878d51.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/05b833eb6f6ee05cd2afa1b50acfc755e3878d51.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/05b833eb6f6ee05cd2afa1b50acfc755e3878d51_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">489\u00d7724 21.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>I would be extremely grateful if you can provide a suggestion or highlight the mistake. Thanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-24T00:50:59.273Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hassanw65\">@hassanw65</a> , thank you for writing in and submitting code to reproduce your particular issue. We will review and get back to you soon.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-27T11:15:52.078Z",
				"Answer_body": "<p>Any update <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-27T22:39:37.280Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hassanw65\">@hassanw65</a> ,</p>\n<p>From your code, after running the  sweep  and grouping all its runs under <code>sweep_runings</code>  and job type <code>training_new</code>, you retrieve the best run, <code>sweep.best_run()</code>, from the sweep and its associated configuration.</p>\n<pre><code class=\"lang-auto\"># Get best run parameters\nbest_run = sweep.best_run()\nbest_parameters = best_run.config\n</code></pre>\n<p>When calling <code>sweep.best_run()</code> The API first sorts runs by the <code>val_loss</code> score and returns the configuration of the run that most minimized the score (which could very much be the last run of the sweep). In the image attached you have a single run, thus the configurations of this run will be used.</p>\n<p>You then pass these configurations to the <code>retrain_model()</code> function as  <code>best_parameters</code>  which are then used in the function to retrain the model under a new group, <code>best_model</code> and new job type <code>training_new_model</code>.</p>\n<p>The single issue I see with your code that would cause a user to perceive unusual behavior when reading logs is the following.</p>\n<p>In your <code>model_train function()</code> you are initializing a run with default config <code>config_defaults</code> that is defined within your function. This is passed to <code>wandb.init(config=config_defaults...)</code> and is used to log runs. These runs will be logged to the project <code>uncategorized</code> as no project name is defined in wandb.init. The sweep runs will be logged to the project <code>sweeps</code> per the line <code>sweep_id = wandb.sweep(sweep_config_up, project=\"sweeps\")</code>. Was this intended by you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-30T08:38:40.944Z",
				"Answer_body": "<p><span class=\"mention\">@muhmammadbakir</span> The problem is that in the image attached I have done 2 run in sweep. But after  the model is retrain again according to best parameter the last run of sweep is repeated and grouped. The run with the best parameter is not started at all.<br>\nHowever if I run sweep and then restart the notebook session and then I retrain according to best parameter then a new  run  with best config is started. This is with addition to 2 runs in sweep (Which is what I want).</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-30T09:00:47.503Z",
				"Answer_body": "<p>And for your second question I havent project name in init because if I do it with addition to project name in sweep then I get error that I cant do it two times. Moreover in the wandb collab notebook in almost all sweep project name is defined inside the sweep instead of init in model_train function.<br>\nMoreover No run is created under uncategorized project.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-07T08:26:18.046Z",
				"Answer_body": "<p>Any update <span class=\"mention\">@muhmammadbakir</span></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-12T04:54:09.107Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hassanw65\">@hassanw65</a> ,</p>\n<p>Apologies for the delayed response, I\u2019ve been out of office. I recommend you no longer initialize a default parameter configurations inside your <code>model_train</code> function which is run before this sweep. The sweep is then continued from that run, which is causing inconsistencies. I recommend reviewing this <a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W%26B.ipynb#scrollTo=Zn6i5o1cuG6I\" rel=\"noopener nofollow ugc\">colab</a> notebook of our sweeps example and how we pass the intended parameter configuration into the training function <code>def train(config=None)</code>. This will resolve the issues you are seeing. Please let me know if you have any questions.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-15T17:10:33.060Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hassanw65\">@hassanw65</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-16T12:43:23.615Z",
				"Answer_body": "<p>I applied this change but it is still not working</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-14T12:44:11.463Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Logging Metrics for each sample per epoch",
		"Question_link": "https://community.wandb.ai/t/logging-metrics-for-each-sample-per-epoch/2678",
		"Question_created_time": "2022-06-29T20:28:00.479Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 232,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hey everyone,<br>\nLet\u2019s say that I have a dataset with 50000 samples and I am training my model for 10 epochs. Now, in each epoch, I am recording the <em>per sample loss</em> (i.e. loss of each sample - Not the average loss of all samples). This means that there are 50000 loss values per epoch. I want to log these values for <em>each epoch</em>, so that I can later perform some analysis on how the loss values for the samples change as training progresses (And, if possible, observe the loss values of a particular sample across epochs). For reference, <a href=\"https://proceedings.neurips.cc/paper/2020/file/62000dee5a05a6a71de3a6127a68778a-Paper.pdf\" rel=\"noopener nofollow ugc\">this</a> paper tracks such  statistics. Here are two ways I can think of doing this -</p>\n<ul>\n<li>A simple way to do this is to update the values in a 50000x10 array, then log the array as a table at the end of training (I would obviously need to track which indices belong to which samples). However, I need to wait for the training to end in this scenario.</li>\n<li>I can also log each sample\u2019s statistic with wandb.log (Maybe put them under \u201csample_statistics/\u201d to pull them more easily). This ensures that the metrics are logged as and when they are observed, however, I am not sure if this is the most optimal solution.</li>\n</ul>\n<p>Is there any other way in which I can do this so that I can analyse the resulting data effectively? Open to all suggestions!<br>\nThank you!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-01T23:32:44.004Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tataganesh\">@tataganesh</a> ,</p>\n<p>Thank you for writing in with your question.   Ideally what would be best in your case here is to create an Empty table and log per sample loss values per epoch and be able to see your data live in the UI. However, we currently,  don\u2019t support adding new rows to existing tables that you\u2019ve already logged. We are working on adding this functionality.</p>\n<p>In the meantime here are two approaches</p>\n<ol>\n<li>Keep the wandb.Table locally holding all the data in memory and logging it once.</li>\n<li>Keep logging the same table at each step, and just add new rows to it. The final table you log will have all the rows you want, and you\u2019ll be able to see the latest table logged in the UI. This would be risky if you have large table sizes.</li>\n</ol>\n<p>Please Note: If you were to look through our docs and come across the<a href=\"https://docs.wandb.ai/guides/data-vis/log-tables#add-data\"> Add Data Incrementally</a> to  Tables doc, this functionality is currently broken and we are working on an active fix.  There is github issues thread <a href=\"https://github.com/wandb/client/issues/2981\" rel=\"noopener nofollow ugc\">here</a> where community members have posted workarounds for this, you may find it helpful.</p>\n<p>Please let me know if you have any questions.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-07-12T05:11:33.603Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tataganesh\">@tataganesh</a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-15T20:15:15.953Z",
				"Answer_body": "<p>That makes sense, thank you for the suggestions!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-13T20:16:15.457Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sweep command",
		"Question_link": "https://community.wandb.ai/t/sweep-command/2749",
		"Question_created_time": "2022-07-14T10:06:58.155Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 183,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\nI am trying to create a sweep YAML config but the hp are not passed as cli args to my script.</p>\n<p>The yaml:</p>\n<pre data-code-wrap=\"yaml\"><code class=\"lang-nohighlight\">\nprogram: src.stance_detection.bert.simpletransformers.sweep_tests\nmethod: grid\nmetric:\n  goal: minimize\n  name: loss\nparameters:\n  n:\n    values: [1, 2]\ncommand:\n  - ${env}\n  - ${interpreter}\n  - \"-m\"\n  - ${program}\n  - ${args_no_boolean_flags}\n</code></pre>\n<p>The script:</p>\n<pre><code class=\"lang-python\">import wandb\nfrom pprint import pprint\nimport sys\n\nif __name__ == \"__main__\":\n    pprint(sys.argv)\n    wandb.init()\n    wandb.log({\"loss\": 0})\n</code></pre>\n<p>I was expecting <code>sys.argv</code> to contain <code>--n=[value]</code>. What am I doing wrong?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-14T14:41:22.428Z",
				"Answer_body": "<p>It seems to have been a bug in wandb. Updating to <code>0.12.21 </code> fixed it.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-15T19:01:19.174Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/maxreimer\">@maxreimer</a> ,  glad you were able to successfully resolve this. Please do reach back out again with any additional questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-13T19:02:04.327Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Retrieving Models (Aliases) held in the Model Registry",
		"Question_link": "https://community.wandb.ai/t/retrieving-models-aliases-held-in-the-model-registry/2700",
		"Question_created_time": "2022-07-05T08:51:11.943Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 138,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m trying a new model management set-up leveraging the model registry. My previous model management loop would go and check for any new aliases in a model which contained the word \u2018challenger\u2019, these models would then be pulled through to an evaluation job against the current \u2018champion\u2019 model to check whether any new challenger models should be staged for evaluation by a ML Eng to decide whether it should be promoted to production.</p>\n<p>The previous code used to do this was leveraging <code>api.artifact_versions</code>:</p>\n<pre><code class=\"lang-auto\">api = wandb.Api(overrides={\"project\": \"test-project\"})\nartifacts = api.artifact_versions(\"model\", \"model-name\")\n</code></pre>\n<p>This returns the different versions of that model which exist (with all the alias names) as a list of lists of aliases</p>\n<p>When applying this same logic against a model-registry (collection) the api no longer works / isn\u2019t able to resolve the items held in the model registry.</p>\n<p>Is there a different way to access the items held in the model registry?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-07T15:42:58.077Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kayvane\">@kayvane</a>,<br>\nIt looks like this doesn\u2019t exist currently in the same way that it would for a standard Artifact. You can use <code>wandb.use_artifact()</code> which will return an Artifact object. The Artifact will have an attribute <code>.aliases</code> that you could check to automate calling an evaluation job. I may be misunderstanding exactly how you intent to use this though so feel free to clarify if this isn\u2019t the solution you are looking for.</p>\n<p>As a side note, I\u2019d encourage you to check out our <a href=\"https://docs.wandb.ai/guides/launch\">Launch</a> feature that is currently in Beta. Some of the functionality of this is not yet built out but in the future this will be a solution for triggering these types of jobs automatically.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-15T15:49:25.979Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/kayvane\">@kayvane</a> I wanted to see if I was able to answer your question or if you still had questions around this?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-13T15:50:11.478Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Store trained models without wandb as artifacts",
		"Question_link": "https://community.wandb.ai/t/store-trained-models-without-wandb-as-artifacts/2722",
		"Question_created_time": "2022-07-07T10:37:50.706Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 303,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello wandb community!</p>\n<p>I have a large collection of trained models (with pytorch-lightning), but unfortunately without using wandb back then. So, I am wondering if there is a way to store them as artifacts in a model registry.</p>\n<p>Thanks in advance! <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-11T16:21:26.495Z",
				"Answer_body": "<p>Hi Dimitris, you can definitely create a new model collection, log models and then link them to the collection via Model Registry. Please refer to a <a href=\"https://docs.wandb.ai/guides/models/walkthrough#workflow\">detailed guide on how to do so here</a>.</p>\n<p>Note: A companion notebook is also provided to walk you through all <a href=\"https://docs.wandb.ai/guides/models/walkthrough#2.-train-and-log-model-versions\">these steps</a> in detail. Please let us know in case of any further questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-13T23:21:07.369Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/wdika\">@wdika</a> , I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-14T00:39:44.329Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/anmolmann\">@anmolmann</a>, thanks for your kind reply! I have seen your comment, but unfortunately I didn\u2019t have the time yet to go through it. Eventually, I haven\u2019t read the section from the documentation you pointed me to. I will catch up as soon as I find some time to work on this <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-12T00:39:54.383Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Logging a table from a list of python dicts",
		"Question_link": "https://community.wandb.ai/t/logging-a-table-from-a-list-of-python-dicts/2701",
		"Question_created_time": "2022-07-05T16:18:18.222Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 173,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Is it possible to log tables to WANDB from a list /sequence of dicts where the keys are the column names and the values wandb.Images (for example)?</p>\n<p>Once the my tables are logged to WANDB, if they share a column, can I join them in the WANDB web GUI?</p>\n<p>Thanks  beforehand!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-07T19:38:05.552Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/fisikillo\">@fisikillo</a> ,</p>\n<p>Thanks for writing in. We support logging tables using list/nested listed  with multiple images, see <a href=\"https://docs.wandb.ai/guides/data-vis/log-tables#create-tables\">here.</a> You can also join tables directly from the web GUI.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-07-13T18:21:51.238Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/fisikillo\">@fisikillo</a> , following up on this. Do you still need assistance when logging to workspace?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-13T18:44:39.826Z",
				"Answer_body": "<p>Hi Mohammad,</p>\n<p>No, it\u2019s cristal clear, sorry for the delay ;).</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-11T18:45:04.344Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "WandB doesn't track my metrics after a certain step onwards",
		"Question_link": "https://community.wandb.ai/t/wandb-doesnt-track-my-metrics-after-a-certain-step-onwards/2709",
		"Question_created_time": "2022-07-06T16:14:43.051Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 97,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi! My issue is that I can track the trend of my metrics in wandb panels till around 820 steps (or epochs, I run 250 epochs for each task of a Continual Learning scenario, and the tasks are 10, so in the end I should have around 2500 steps), then the panels don\u2019t show the metrics anymore. The experiment is running smoothly and I don\u2019t get any error in the terminal. Is there any kind of cap on the max steps? Do I have to set it? I just log 3 metrics.<br>\nThank you.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-07T21:49:23.032Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/umbertocappellazzo\">@umbertocappellazzo</a> ,</p>\n<p>Thank yo for writing in. The charts will automatically display the logged metrics to fit, unless the user modifies the min-max range in the chart edit menu. Can you please provide sample code of how you are logging your metris.</p>\n<p>Note: If you are visualizing your metrics against something other than <code>Step</code> on your X-Axis, you might see fewer data points than you expect. This is because we require the metrics to be plotted against one another to be logged at the same <code>Step</code> - that is how we keep your metrics synchronized. See <a href=\"https://docs.wandb.ai/guides/track/log/logging-faqs#why-am-i-seeing-fewer-data-points-than-i-logged\">here</a> for more details.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-09T07:22:37.100Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> ,<br>\nThx for your reply. Presumably I tried to set the max range bcs I was not able to display the full horizon of steps, and so I think I made this mistake. Now the metrics are fully visualized, so the issue is solved.<br>\nThank you for your help! <img src=\"https://emoji.discourse-cdn.com/twitter/grinning.png?v=12\" title=\":grinning:\" class=\"emoji\" alt=\":grinning:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-13T18:13:15.016Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/umbertocappellazzo\">@umbertocappellazzo</a> , thank\u2019s for letting me know. I will mark this closed.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-11T18:14:08.685Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Save long tensors using wandb.save OR wandb.log?",
		"Question_link": "https://community.wandb.ai/t/save-long-tensors-using-wandb-save-or-wandb-log/2737",
		"Question_created_time": "2022-07-11T18:27:04.663Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 257,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi all,<br>\nIn my experimentation, I want to save some tensor_10k_size for a dataset which has 90k samples.  so that I can compare how the tensors look for different datasets. It\u2019s part of my thesis.<br>\nWhich is a better option to save tensors in my scripts using wandb.save(\u2018filename\u2019)<br>\nor<br>\nwandb.log(tensor)</p>\n<p>Thanks,<br>\nPrachi</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-11T18:57:46.141Z",
				"Answer_body": "<p>Hi Prachi,</p>\n<p>It completely depends on what you are trying to do with the tensor. If you are trying to visualize the tensor (a tensor is usually presented as a histogram - unless it is of shape (W, H, C) in which case it can be coerced to an image - it can be logged using <code>wandb.log</code>.</p>\n<p>If you want to load up those tensors again to be used in your code -<code>wandb.save</code> would be the way to go.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-13T01:42:51.237Z",
				"Answer_body": "<p>Hi Ramit,<br>\nThat was my hazy view, you made it clear.</p>\n<p>Thanks,<br>\nPrachi</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-11T01:43:35.647Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Plot array, over time",
		"Question_link": "https://community.wandb.ai/t/plot-array-over-time/2690",
		"Question_created_time": "2022-07-01T20:44:41.950Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 100,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi all,</p>\n<p>I have a simple 1D array (e.g. norm of each layer), that I want to plot over time (e.g. plot \u201cnorm against array index\u201d, each time step). Should I create a line plot? How can I overlay line plots as they are updated?</p>\n<p>Thanks! Carlos</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-06T23:28:54.166Z",
				"Answer_body": "<p>Hi Carlos,</p>\n<p>Yes absolutely! A line plot can work to display the norm of a layer. You can also log the weights of a layer individually as a histogram to get a more granular sense of your layers. This is done as</p>\n<pre><code class=\"lang-auto\">wandb.log({\n    'layer' : wandb.Histogram(&lt;array-like&gt;)\n})\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-07T16:33:29.909Z",
				"Answer_body": "<p>Ok, thanks for replying! But if I want to have a chart that overlays line plots for each epoch, generated e.g. like this:</p>\n<p>data = [[x, y] for (x, y) in zip(range(len(norms)), norms)]<br>\ntable = wandb.Table(data = norms, columns = [\u201cindex\u201d, \u201cnorm\u201d])<br>\nnorms_line = wandb.plot.line(table, \u201cindex\u201d, \u201cnorm\u201d, title=\u201cNorms by layer\u201d)<br>\nwandb.log({\u201cepoch\u201d: epoch, \u201cnorms\u201d: norms_line})</p>\n<p>It creates a chart with the line plot, but I couldn\u2019t figure out how to modify the chart to overlay the lines for all epochs.</p>\n<p>A related question, media charts created for each step seem to generate a scroll bar below automatically, to navigate the step/epoch. Can I add the same to this line plot, to navigate how it changed during each epoch?</p>\n<p>Thanks again for taking the time.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-12T19:27:12.292Z",
				"Answer_body": "<p>Hey <span class=\"mention\">@cstein</span>!</p>\n<p>The easiest way to do this would be to use <code>wandb.log</code> to log your metrics and them overlaying them through the UI. As an example, let\u2019s assume we have 2 metrics - <code>Test/Loss</code> and <code>Test/Accuracy</code> which have been logged through <code>wandb.log</code>. They can be overlayed as:</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/1caa01b281ddb26aa2a65d75465bf177d3b23237.gif\" alt=\"output\" data-base62-sha1=\"45zBC91TIL7F5YKwx7gKLUrPhWf\" width=\"690\" height=\"225\" class=\"animated\"></p>\n<p>Please let me know if you face any issues!</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-10T19:28:04.507Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "ValueError: Value out of range: 15263439326086220952",
		"Question_link": "https://community.wandb.ai/t/valueerror-value-out-of-range-15263439326086220952/2729",
		"Question_created_time": "2022-07-08T14:08:59.847Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 138,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am trying sweep in a remote server,whose system is Centos 7.6.<br>\nAfter the first run ,it occered  an  ERROR as folow:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/6a868c651662464dfba15f99745bf91fd688ff00.png\" data-download-href=\"/uploads/short-url/fcmSAJb5vDbYn8vgBpfwfFB8mZO.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/6a868c651662464dfba15f99745bf91fd688ff00.png\" alt=\"image\" data-base62-sha1=\"fcmSAJb5vDbYn8vgBpfwfFB8mZO\" width=\"690\" height=\"265\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/6a868c651662464dfba15f99745bf91fd688ff00_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1134\u00d7436 19.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nAnd  the code is ok to run in my conputer.<br>\nwhen i remove all the sweep code,the code is able ro run successfully in the remote server too.<br>\nIs this error attributed to my remote server?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-12T11:53:40.123Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/guoxiaobo\">@guoxiaobo</a>, can you share a code snippet that causes the error for you? Also which client version are you using?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-15T16:44:34.820Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-20T13:04:04.576Z",
				"Answer_body": "<p>Hey there, since we have not heard back from you, I\u2019ll be closing this ticket. Please message me if you want to reopen the issue.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-10T11:54:02.259Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Compare different architectures for a same task",
		"Question_link": "https://community.wandb.ai/t/compare-different-architectures-for-a-same-task/2724",
		"Question_created_time": "2022-07-07T13:53:24.620Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 502,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey there.</p>\n<p>I discovered W&amp;B recently and decided to use it for my current research project. The thing is that I have a specific task to solve and would like to evaluate a bunch of completely different model architectures, having different sets of hyper-parameters.</p>\n<p>Most of the online resources and tutorials I\u2019ve found only shows examples of W&amp;B usage to evaluate different experiments with different params selections (e.g. optimized using sweeps). However none of the examples I found explained how to optimally organize a W&amp;B project including different architectures to solve the same task, and thus being able to compare in a glimpse the different performances in a single view / report.</p>\n<p>My idea was to make use of the job_type flag and group every architecture instances together under a same job_type flag. But still seems like not the best solution and was wondering if there is some special feature or built-in tool that I\u2019ve not noticed yet (or even good practices?).</p>\n<p>(Other than that, W&amp;B looks really insane).</p>\n<p>Many thanks <img src=\"https://emoji.discourse-cdn.com/twitter/smile.png?v=12\" title=\":smile:\" class=\"emoji\" alt=\":smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-11T08:46:13.390Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/andreakiro\">@andreakiro</a>, apologies abou the late response on this. Grouping is the solution I\u2019d suggest here. You can pass a group argument to <a href=\"https://docs.wandb.ai/ref/python/init\">wandb.init</a>. After that you\u2019ll be able to <a href=\"https://docs.wandb.ai/ref/app/features/runs-table#filter-and-delete-unwanted-runs\">filter</a> the dashboard based on the architecture you are interested. You can also use <a href=\"https://docs.wandb.ai/ref/app/features/tags\">tags</a> for this purpose.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-09T08:46:30.394Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to log custom criterion function?",
		"Question_link": "https://community.wandb.ai/t/how-to-log-custom-criterion-function/2703",
		"Question_created_time": "2022-07-05T22:59:47.579Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 110,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>We can use <code>wandb.watch(model, criterion, ...)</code> in order to log a model + a loss function.<br>\nBut my loss function is not something simple like: <code>criterion = nn.CrossEntropyLoss()</code>.</p>\n<p>Rather, here\u2019s how I calculate my loss:</p>\n<pre><code class=\"lang-auto\">            # `set_to_none=True` boosts performance\n            optimizer.zero_grad(set_to_none=True)\n            masks_pred = model(imgs)\n\n            probs = F.softmax(masks_pred, dim=1).float()\n            ground_truth = F.one_hot(masks, model.n_classes).permute(0, 3, 1, 2).float()\n\n            loss = criterion(masks_pred, masks) + dice_loss(probs, ground_truth)\n            loss.backward()\n            optimizer.step()\n</code></pre>\n<p>As you can see, the loss is a composition of 2 functions: the criterion and the <code>dice_loss</code> function.<br>\nWhat should I pass to <code>wandb.watch</code> for the <code>criterion</code> argument?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-08T18:53:54.861Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/vroomerify\">@vroomerify</a>,</p>\n<p>Thanks for reaching out. <code>wandb.watch</code> expects a torch function as a criterion parameter. You can set up a custom criterion function by subclassing <code>torch.nn.Module</code>.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-07-13T23:00:09.811Z",
				"Answer_body": "<p>Hi Vedant,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-19T18:13:41.309Z",
				"Answer_body": "<p>Hi Vedant, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-06T18:54:20.439Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to automatically add new panel to group",
		"Question_link": "https://community.wandb.ai/t/how-to-automatically-add-new-panel-to-group/2715",
		"Question_created_time": "2022-07-06T19:08:10.574Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 110,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I create a group of runs, that is similar to parameter sweeping, and want to show the parallel coordinates panel. I can do that manually, but wonder how to programmatically add than when creating a group?</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/1faad3341c2660e4e3ed774e8cff3f87334aa851.png\" data-download-href=\"/uploads/short-url/4w8N8k8sYvcpJ5hhRM9TWr8fxK1.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1faad3341c2660e4e3ed774e8cff3f87334aa851_2_690x304.png\" alt=\"image\" data-base62-sha1=\"4w8N8k8sYvcpJ5hhRM9TWr8fxK1\" width=\"690\" height=\"304\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1faad3341c2660e4e3ed774e8cff3f87334aa851_2_690x304.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1faad3341c2660e4e3ed774e8cff3f87334aa851_2_1035x456.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/1faad3341c2660e4e3ed774e8cff3f87334aa851.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1faad3341c2660e4e3ed774e8cff3f87334aa851_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1377\u00d7608 84.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-06T19:09:00.784Z",
				"Answer_body": "<p>I understand you have sweep, but I really want to make this work without sweep.</p>\n<p>Thanks<br>\nHan</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-08T08:38:12.369Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/goodwanghan\">@goodwanghan</a>, unfortunately we don\u2019t have an option to create this chart automatically. You\u2019ll need to add the parallel coordinates chart manually.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-08T13:12:51.655Z",
				"Answer_body": "<p>If you\u2019re happy to use Reports, there\u2019s a very new feature to programmatically create Parallel Coordinates plots within Reports:</p>\n<aside class=\"quote quote-modified\" data-post=\"4\" data-topic=\"2719\">\n  <div class=\"title\">\n    <div class=\"quote-controls\"></div>\n    <img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://sea2.discourse-cdn.com/business7/user_avatar/community.wandb.ai/_scott/40/95_2.png\" class=\"avatar\">\n    <a href=\"https://community.wandb.ai/t/analyzing-hyperparameters-without-actualy-performing-a-sweep/2719/4\">Analyzing hyperparameters without actualy performing a sweep</a> <a class=\"badge-wrapper  bullet\" href=\"/c/w-b-support/36\"><span class=\"badge-category-bg\" style=\"background-color: #0088CC;\"></span><span style=\"\" data-drop-close=\"true\" class=\"badge-category clear-badge\" title=\"Ask your W&amp;B questions here. Let us know if you have an issue and one of our engineers or community experts will get back to you ASAP.\">W&amp;B Support</span></a>\n  </div>\n  <blockquote>\n    I can\u2019t see the images above, but if you would like to create a <a href=\"https://docs.wandb.ai/ref/app/features/panels/parallel-coordinates\">parallel coordinates plot</a>, you can do so using the UI by clicking \u201cadd panel\u201d in your workspace and choosing Parallel Coordinates. \nIf you need to do this programmatically, one very recent feature would be to create a W&amp;B Report using our Api. You can programatically define what plots show up. It is a very new feature so it\u2019ll become better documented and more stable over time. \nHere\u2019s how you would create a Parallel Coordinates plo\u2026\n  </blockquote>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-06T13:13:19.395Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Analyzing hyperparameters without actualy performing a sweep",
		"Question_link": "https://community.wandb.ai/t/analyzing-hyperparameters-without-actualy-performing-a-sweep/2719",
		"Question_created_time": "2022-07-07T08:09:02.018Z",
		"Question_answer_count": 5,
		"Question_score_count": 1,
		"Question_view_count": 129,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hy, I\u2019m in love with wandb, but I have a problem\u2026</p>\n<p>I have a simple question\u2026</p>\n<p>How can I analyze hyperparameters\u2026As seen in this picture, without actually creating a sweep.</p>\n<p>In my own code\u2026</p>\n<p><img src=\"https://mail.google.com/mail/u/0?ui=2&amp;ik=8824e8d63e&amp;attid=0.1&amp;permmsgid=msg-a:r-1242756300606160728&amp;th=181d7b1a169f2ed0&amp;view=fimg&amp;fur=ip&amp;sz=s0-l75-ft&amp;attbid=ANGjdJ9LbpPclu5VUg_KiYT_9MyY2AbgyxXn6tmqz8qoKH2kUghMnyxeJstBhkIK4wCOgqfFHueuZ6ul6juIl6zvWD3lcsPXIvZAnZatibVLxPjneVvO-xSUoWLyCpM&amp;disp=emb&amp;realattid=ii_l5aqmkag2\" alt=\"68747470733a2f2f692e696d6775722e636f6d2f5455333451465a2e706e67.png\" width=\"339\" height=\"205\"></p>\n<p>I\u2019m preforming learning and for every model i\u2019m sending config with hyperparams\u2026</p>\n<p>wandb.finish(quiet=True)<br>\nwandb.init(<br>\nentity=var.WANDB_ENTITY,<br>\nproject=f\u2019{var.version} | {var.INPUT_DATASET}',<br>\ndir=str(var.working_dir),<br>\nconfig=utils.keras.hyper_params(hp))</p>\n<p>But in dashboard I dont see hyperparameters dashboard\u2026 And this makes me really sad !</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-07T08:09:39.921Z",
				"Answer_body": "<p>This is my project view\u2026</p>\n<p><img src=\"https://mail.google.com/mail/u/0?ui=2&amp;ik=8824e8d63e&amp;attid=0.2&amp;permmsgid=msg-a:r-1242756300606160728&amp;th=181d7b1a169f2ed0&amp;view=fimg&amp;fur=ip&amp;sz=s0-l75-ft&amp;attbid=ANGjdJ8DnhFyENGDIPIM7ASNAvo8zDMxRkPPg4T64y7n_PDGfaFafO-BtYwsjGHvK9Zir7CTjiC-Tv2Zxm7oRkDY2vip3gc5Ui1UvrWr8PG80p2mWmhrBRb9qsCs2D4&amp;disp=emb&amp;realattid=ii_l5aqthrw4\" alt=\"image.png\" width=\"543\" height=\"332\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-07T08:10:24.887Z",
				"Answer_body": "<p>And this is my table view\u2026</p>\n<p><img src=\"https://mail.google.com/mail/u/0?ui=2&amp;ik=8824e8d63e&amp;attid=0.3&amp;permmsgid=msg-a:r-1242756300606160728&amp;th=181d7b1a169f2ed0&amp;view=fimg&amp;fur=ip&amp;sz=s0-l75-ft&amp;attbid=ANGjdJ8GijPoQqT-6lpCvkV5gW1tUKKzvmkiHWx6IFFMNiBMknR0Xx6_rcgbQoLZxhFDhEi_k3Lb4yHy_0BXBd3_s9lJUXHQpsfyiztimA8yKDf98gCMvdoywQj00_0&amp;disp=emb&amp;realattid=ii_l5aqv44q5\" alt=\"image.png\" width=\"543\" height=\"250\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-07T18:37:19.909Z",
				"Answer_body": "<p>I can\u2019t see the images above, but if you would like to create a <a href=\"https://docs.wandb.ai/ref/app/features/panels/parallel-coordinates\">parallel coordinates plot</a>, you can do so using the UI by clicking \u201cadd panel\u201d in your workspace and choosing Parallel Coordinates.</p>\n<p>If you need to do this programmatically, one <em>very</em> recent feature would be to create a W&amp;B Report using our Api. You can programatically define what plots show up. It is a very new feature so it\u2019ll become better documented and more stable over time.</p>\n<p>Here\u2019s how you would create a Parallel Coordinates plot programmatically and save it in a report using Python.</p>\n<pre><code class=\"lang-auto\">import wandb\nimport wandb.apis.reports as wb\napi = wandb.Api()\nproject = 'pytorch-sweeps-demo'\nwandb.require('report-editing') # this is needed as of version 0.12.21 but will likely not be needed in future.\nreport = wb.Report(\n    project=project,\n    title='Sweep Results',\n    blocks=[\n            wb.PanelGrid(panels=[\n                 wb.ParallelCoordinatesPlot(\n                     columns=[wb.reports.PCColumn('batch_size'), wb.reports.PCColumn('epoch'), wb.reports.PCColumn('loss')])\n            ], runsets=[wb.RunSet(project=project)]),\n    ]\n)\nreport.save()\n</code></pre>\n<p>This will then show up in the Reports tab on your project.<br>\nAs this is a very fresh API, there may be issues or features that are not supported yet. I do apologise if that happens to you, I\u2019ll be happy to follow up and provide help.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-07-07T20:03:14.632Z",
				"Answer_body": "<p>I have figured it out with the help of your support team, I would really suggest that you guys build the parallel coordinates plot by default since it\u2019s really hard for newcomers to figure this out.</p>\n<p>Now with this my soul is satisfied! Congratulation on such a great product!!!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-05T20:03:18.514Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Benchmarking function calls using python decorators",
		"Question_link": "https://community.wandb.ai/t/benchmarking-function-calls-using-python-decorators/2713",
		"Question_created_time": "2022-07-06T18:49:13.203Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 142,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>To visualize performance bottlenecks, we want to know execution times for functions calls<br>\nUsing  <code>time.time()</code>  makes the code ugly<br>\nCan we write a python decorator for this so that users only need to decorate their definitions</p>\n<pre><code class=\"lang-python\">@wandb.timeit\ndef my_function(args)\n    pass</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-08T21:57:37.589Z",
				"Answer_body": "<p>Hi Parthe! Currently we do not support timers using decorators like this, but this sounds like a great feature that can be added to W&amp;B! I\u2019ll create a feature request for this and I\u2019ll keep you posted with updates. For now, logging <code>time.time()</code> would be the best way to do this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-04T18:49:28.416Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Logging values to ongoing run from a different process",
		"Question_link": "https://community.wandb.ai/t/logging-values-to-ongoing-run-from-a-different-process/2671",
		"Question_created_time": "2022-06-28T04:42:52.182Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 84,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi there!<br>\nIn my use case I\u2019m running a training loop and storing a model at a regular interval. During training, I also want to evaluate metrics such as the CIDEr score for image captioning. The problem is, computing these metrics takes a lot of time (~40 minutes), and the training is running on a cluster where I can\u2019t evaluate the metrics for several reasons.</p>\n<p>So my plan is to load the stored models on a separate machine after every update, and evaluate the metrics there. Once done, I would like to log the metrics to the ongoing training runs, with a step parameter set to the time when the model was stored. So by the time the evaluation is finished, the training runs will have progressed in steps.</p>\n<p>Is this possible using the wandb api, without getting concurrency problems?</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-29T20:16:49.870Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/dhansmair\">@dhansmair</a> ,</p>\n<p>Thank-you for writing in with your support question. At this time you cannot update/log new metrics of an active run, however you can do the following:</p>\n<ul>\n<li>Once a run has finished, update its metrics, see <a href=\"https://docs.wandb.ai/guides/track/public-api-guide#update-metrics-for-a-run-after-the-run-has-finished\">here</a>\n</li>\n</ul>\n<p>Please let me know if you have additional questions.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-30T08:33:21.896Z",
				"Answer_body": "<p>Hello Mohammad,<br>\nthanks for the reply. I see. It does not help directly but may be useful for me still, thank you. Meanwhile I managed to circumvent the problem by moving to a different server.</p>\n<p>Best,<br>\nDavid</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-06T17:32:08.029Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/dhansmair\">@dhansmair</a> ,</p>\n<p>Thank-you for letting me know you resolved your issued. I will mark this closed.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-04T17:32:38.300Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Is it possible to make parametric plots?",
		"Question_link": "https://community.wandb.ai/t/is-it-possible-to-make-parametric-plots/2662",
		"Question_created_time": "2022-06-27T07:58:30.393Z",
		"Question_answer_count": 7,
		"Question_score_count": 1,
		"Question_view_count": 239,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello, I would like to make plots such as the ones that can be seen in this video at this timestamp (59:59): <a href=\"https://youtu.be/XL07WEc2TRI?t=3599\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Stanford Seminar - Information Theory of Deep Learning - YouTube</a></p>\n<p>Basically, I have two variables (let\u2019s say X and Y) that are measured at each layer and epoch, and I would like to have a unified plot where each layer is represented as a parametric curve. Connecting points in a same epoch by neighboring layers would be a plus but that\u2019s optional.<br>\nSo for each epoch and layer, I would like to plot a point at coordinates (X,Y) connected to the corresponding previous point of the previous epoch. If possible, I would like to color each point according to the epoch so that we can see the progression.</p>\n<p>I tried to plot a line series like this:</p>\n<pre><code class=\"lang-python\">wandb.log({\"XY\": wandb.plot.line_series(self.layers_x, self.layers_y, self.layer_names,\n                                        \"XY by layer and epoch\", \"X\")}, step=step)\n</code></pre>\n<p>But there are three issues with this:</p>\n<ol>\n<li>The points of the curves aren\u2019t connected in the correct order, it seems they are implicitly connected according to their sorted X values. So the resulting curves are incorrect, even if I can guess the true shapes they should have.</li>\n<li>I haven\u2019t managed to get point coloring according to the epoch number, and I had to manually modify the plot in the dashboard so that I had all curves correctly displayed in the same plot. I had to use custom plots but I am not familiar with these. I also don\u2019t know how to set the display name of the y axis which is \u201cy\u201d by default.</li>\n<li>I have to manually keep track of the table values, if possible I would like to log the values for each step normally, like any other value like the accuracy at each epoch.</li>\n</ol>\n<p>So, is it possible to make such plots? Thank you.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-29T16:33:25.375Z",
				"Answer_body": "<p>Hi Ben,</p>\n<p>Thanks for being in touch with this interesting question. So that I can get a clear picture of what you are trying to achieve would you be able to share a link to the workplace where you are trying to plot this? Look forward to hearing from you. ~Frida</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-01T10:54:53.813Z",
				"Answer_body": "<p>Hi Frida,</p>\n<p>You can see the issue here <a href=\"https://wandb.ai/bencrulis/mnist%20custom%202?workspace=user-bencrulis\">https://wandb.ai/bencrulis/mnist%20custom%202?workspace=user-bencrulis</a></p>\n<p>As you can see in the custom chart, the line corresponding to layer_8 should arc from left to right then right to left while going up at all times, but the first point is connected to the last and make the trajectory incorrect.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-05T12:28:16.977Z",
				"Answer_body": "<p>Hi Ben,</p>\n<p>I think that weave plots will likely give you much closer functionality to the image at the timestamp of the video that you shared. I have attached a screengrab of this, alongside steps that you would need to take, you can see an arc where the colour is each layer and x and y values on a scatter follow the same logic as you have shared. To reproduce this you would need to add a panel, and use Weave to select \u2018Merge Tables Plot\u2019. set the x dim and y dim, this will colour by step.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-06T09:52:18.708Z",
				"Answer_body": "<p>Hi,</p>\n<p>The Weave plot is indeed a easier to read, but I didn\u2019t manage to get the correct coloring of the points. I guess this is because the epoch variable isn\u2019t in the table.<br>\nChanging the style to \u201cline\u201d instead of \u201cpoint\u201d also displays the line incorrectly, I guess the available plots weren\u2019t designed to do this.</p>\n<p>Well in any case thank you, I will adapt.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-06T14:16:13.038Z",
				"Answer_body": "<p>Hey Ben thanks for being back in touch and always happy to help. I think that this would make an interesting use case, and yes I did notice the same behaviour when adding a line. I will log this as a feature request for your (line group by) functionality, where the order of precedence is not dictated by the x axis). One interesting point of using weave is that you can use feature embedding such as PCA (principal component analysis) which I notice produces some interesting results for this and may add value/insight to your use case.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-07T14:14:23.819Z",
				"Answer_body": "<p>Hey Ben, Updating you that I have created a feature request for you on this. Let me know if you need any further help just now.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-04T09:53:09.474Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Which stream is captured on Run Log page?",
		"Question_link": "https://community.wandb.ai/t/which-stream-is-captured-on-run-log-page/2669",
		"Question_created_time": "2022-06-27T15:36:52.897Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 83,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I noticed that there is a log page for each run. Which stream does the log page capture? In my case it seems only capture stderr but no stdout</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-29T11:51:55.786Z",
				"Answer_body": "<p>Hey Kevin, W&amp;B should capture the stdout stream. Can you share a link to a project so I can look into this?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-06T06:39:44.159Z",
				"Answer_body": "<p>\u200bHi <a class=\"mention\" href=\"/u/kevindong\">@kevindong</a>, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-06T07:03:57.253Z",
				"Answer_body": "<p>Thanks for the reply. My problem is solved</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-09-04T07:04:19.253Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Runs not listed in workspace",
		"Question_link": "https://community.wandb.ai/t/runs-not-listed-in-workspace/2593",
		"Question_created_time": "2022-06-10T13:21:04.003Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 108,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>In my workspace (on the left) runs are not listed, although they appear in the plots.</p>\n<p>I tried turning filters on and off but this didn\u2019t change anything.</p>\n<p>When I switch to the table view all the runs are there.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/01aa72c7785a58ce3e6d6471225787ec7e235db8.jpeg\" data-download-href=\"/uploads/short-url/eJF0nB5WgI7JkvFgmKGP6rnRJ6.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/01aa72c7785a58ce3e6d6471225787ec7e235db8_2_690x268.jpeg\" alt=\"image\" data-base62-sha1=\"eJF0nB5WgI7JkvFgmKGP6rnRJ6\" width=\"690\" height=\"268\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/01aa72c7785a58ce3e6d6471225787ec7e235db8_2_690x268.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/01aa72c7785a58ce3e6d6471225787ec7e235db8_2_1035x402.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/01aa72c7785a58ce3e6d6471225787ec7e235db8_2_1380x536.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/01aa72c7785a58ce3e6d6471225787ec7e235db8_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1920\u00d7746 70.5 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-10T16:19:21.353Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/fryderykkogl\">@fryderykkogl</a>, did you happen to unpin or turn off the \u201cName\u201d column from the runs table tab? If so this is a known bug but you can simply go to the runs table and turn this back on.</p>\n<p>If this is not the issue can you send me a link to your workspace and I can look into this some more?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-10T17:30:55.484Z",
				"Answer_body": "<p>Hi, no, it was still pinned - I tried unpinning and pinning it but nothing changed</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-16T19:33:01.607Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/fryderykkogl\">@fryderykkogl</a>, sorry for the delay on this and thank you for the update. Could you possibly send me a link to your workspace and I can take a look to try to determine what the issue may be?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-01T19:55:04.150Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/fryderykkogl\">@fryderykkogl</a>, I wanted to follow up and see if you were still looking for help with this?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-30T19:55:32.459Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Run sweep on cluster",
		"Question_link": "https://community.wandb.ai/t/run-sweep-on-cluster/2629",
		"Question_created_time": "2022-06-17T09:06:42.852Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 426,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I want to run a sweep on a cluster, say I want to use just 1/4th of a node which has 32 cpus (It\u2019s an RNN so cpus are fine and cheaper). One cpu has enough memory to do a run, but of course I want to use all, so ideally I\u2019d want to do 32 training loops in parallel.</p>\n<p>How do I get this to work?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-21T17:47:44.609Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/apjansen\">@apjansen</a> ,</p>\n<p>Thank you for writing in with your question. W&amp;B does support Distributed training, see <a href=\"https://docs.wandb.ai/guides/track/advanced/distributed-training\">here</a>.  In addition, we highly recommend using <code>wandb service</code> , see <a href=\"https://docs.wandb.ai/guides/track/advanced/distributed-training#wandb-service\">here</a> , which enhances how W&amp;B handles multiprocessing runs and thus improves reliability in a distributed training setting. Please let me know if you have additional questions.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-24T22:42:13.187Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/apjansen\">@apjansen</a> , following up on your request regarding distributed training. Is there anything I can help clarify for you from our docs on how to implement your process?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-30T20:28:05.608Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/apjansen\">@apjansen</a>  since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-29T20:28:57.386Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How do I create a custom metric for bayesian sweeps?",
		"Question_link": "https://community.wandb.ai/t/how-do-i-create-a-custom-metric-for-bayesian-sweeps/2622",
		"Question_created_time": "2022-06-15T22:53:31.703Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 292,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am trying to figure out how to integrate a custom metric for sweeps. It should be a composite of the number of clusters created as well as the number of outliers. I\u2019m just getting started and the answer doesn\u2019t jump out from the documentation. Thanks in advance.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-17T21:35:20.632Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/drob707\">@drob707</a> ,</p>\n<p>Thank you for writing in. If you are intending to track a single metric that is derived from others, then declare that variable in your script, example, <code>count_clusters_outliers = num_clusters_created + num_outliers</code>. You would then set the metric name in your sweep config to the variable declared above, more on sweep configuration <a href=\"https://docs.wandb.ai/guides/sweeps/quickstart#2.-configure-your-sweep\">here</a>.</p>\n<pre><code class=\"lang-auto\">metric:\n  name: count_cluster_outliers\n  goal: minimize\n</code></pre>\n<p>If you want to optimize multiple metrics, consider using a <a href=\"https://docs.wandb.ai/guides/sweeps/faq#optimizing-multiple-metrics\">weighted optimization metric</a>. Lastly, we do support <a href=\"https://docs.wandb.ai/guides/sweeps/advanced-sweeps/local-controller\">custom controllers</a> allowing for you to create your algorithms with sweeps if you are more interested in this route.</p>\n<p>Please let me know if you have any questions.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-18T15:57:03.793Z",
				"Answer_body": "<p>That is super Mohammad, thanks for the link. I knew I had seen it somewhere but I just couldn\u2019t find the reference. In my case I\u2019m optimizing for two factors. One is the resultant number of clusters generated using HDBSCAN parameters and the other is the number of outliers identified.  So in this case a particular sweep may produce 14 clusters with 1200 outliers. Two other runs might create outputs with 13/400 and 15/500. In this scenario 14/1200 is better than 13/400 or 15/500. The raw loss function values would be 0/1200, 1/400 and 1/500. The question is how should can I weight these outputs so that the bayesian algorithm doesn\u2019t over/under compensate on for a given result?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-30T18:42:36.001Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/drob707\">@drob707</a> ,</p>\n<p>Apologies for my delayed response, I missed the notification of your reply Thank-you for following up though. This would be tricky and unfortunately I can\u2019t come up with an equation that would work. I did come across this article online on how to balance metrics using Bayesian optimization, see <a href=\"https://engineering.linkedin.com/blog/2022/using-bayesian-optimization-for-balancing-metrics-in-recommendat\" rel=\"noopener nofollow ugc\">here</a>. Hope this helps.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-29T18:43:01.559Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Empty group name",
		"Question_link": "https://community.wandb.ai/t/empty-group-name/2452",
		"Question_created_time": "2022-05-19T23:45:21.104Z",
		"Question_answer_count": 9,
		"Question_score_count": 0,
		"Question_view_count": 135,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>By my mistake, group name is changed to empty.<br>\nWhen I click the group with empty name, it always redirect to project workspace.<br>\nI can\u2019t find any options make me enable to change the empty group name.<br>\nHow can I change the empty group name.<br>\nIt\u2019s so inconvenient.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-20T11:53:52.413Z",
				"Answer_body": "<p>Hey there, can you share the link to the project where this happens?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-21T19:40:52.862Z",
				"Answer_body": "<p>Here is the link.</p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://wandb.ai/kbjpc123/GSA_V2/table?workspace=user-kbjpc123\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/18b592222b97bc09df3743831bb4929dec23611c.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https://wandb.ai/kbjpc123/GSA_V2/table?workspace=user-kbjpc123\" target=\"_blank\" rel=\"noopener\">W&amp;B</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/0b611df4a0626d2acc4776ea93cc03b3bb48152a.png\" class=\"thumbnail onebox-avatar\" width=\"96\" height=\"96\">\n\n<h3><a href=\"https://wandb.ai/kbjpc123/GSA_V2/table?workspace=user-kbjpc123\" target=\"_blank\" rel=\"noopener\">kbjpc123</a></h3>\n\n  <p>Weights &amp; Biases, developer tools for machine learning</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>There are 4 groups as following:<br>\nGroup: CIFAR10_CUSTOM<br>\nGroup: CIFAR10<br>\nGroup:                         \u2190 this is issue<br>\nGroup: rotMNIST</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-25T19:59:06.946Z",
				"Answer_body": "<p>Thank you, we are investigating the issue.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-27T12:12:23.366Z",
				"Answer_body": "<p>Hey Byungjin,</p>\n<p>Thanks for sharing your workspace, this was escalated to me and after a bit of further investigation I can confirm that there are two ways that you can fix this:</p>\n<ol>\n<li>\n<p>A quick User Interface(UI) fix would be to select all groups <code>not in \"\"</code> when using filters on your runs, I have attached a screengrab of this.</p>\n</li>\n<li>\n<p>To use API with the following code- or something similar in your own logic. I have left print statements in to show that empty strings are actually being printed.<br>\n<code>api = wandb.Api()</code><br>\n<code>runs_in_project = api.runs('&lt;project_name&gt;')</code><br>\n<code>rename = 'new name'</code><br>\n<code>for run in runs_in_project:</code><br>\n<code>if run.group=='':</code><br>\n<code>print(f'empty run {run.group}')</code><br>\n<code>run.group = rename</code><br>\n<code>print(f'renamed run{run.group}')</code><br>\n<code>run.update()</code></p>\n</li>\n</ol>\n<p>I would also like to submit this as a bug report and we will fix this as a UI issue.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-31T15:09:30.977Z",
				"Answer_body": "<p>Hi Byungjin,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-30T14:54:04.904Z",
				"Answer_body": "<p>Hi,</p>\n<p>sorry for late response.<br>\nUnfortunately, the \u2018run\u2019 doesn\u2019t have group attribute.<br>\nThe \u2018group\u2019 is a attribute of wandb.Run, not api.run.<br>\nTherefore your 2nd solution is not working.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-04T09:06:45.494Z",
				"Answer_body": "<p>HI Byungjin,</p>\n<p>Thanks for being back in touch. I can update you that our engineering team are taking this forward to fix this for you. Could I ask you to share a code snippet of how you are calling the api and attempting to access the group attribute as well as any error(s) tracebacks/messages that you are seeing?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-07T11:05:51.629Z",
				"Answer_body": "<p>Hi Byungjin,<br>\nI am messaging to ask if you needed any further help with this and can confirm that the bug that you reported is now fixed in our UI.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-29T14:54:23.356Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Overlaying two point clouds",
		"Question_link": "https://community.wandb.ai/t/overlaying-two-point-clouds/2676",
		"Question_created_time": "2022-06-29T16:14:14.609Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 70,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Is it possible to visualize two point clouds on top of each other with different colors to differentiate them? So far I\u2019ve been using the following format to visualize only one point cloud:</p>\n<pre><code class=\"lang-auto\">points = np.random.uniform(size=(250, 3))\nwandb.log(\n        {\n            \"point_scene\": wandb.Object3D(\n                {   \"type\": \"lidar/beta\",\n                    \"points\": points\n                }\n            )\n        }\n    )\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-29T17:05:05.535Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/nicoca\">@nicoca</a>,</p>\n<p>Unfortunately at this time you can only have one plot of <code>Object3D</code> in a single plot at this point. I will put in a feature request for the engineers to review. Can you let me know the use case you would like to support and how you imagine this type of functionality to look/feel?</p>\n<p>As a workaround you can log HTML and Plotly objects to <code>wandb</code> and as such you can pre-generate these graphs and log it into <code>wandb</code> if this is urgent!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-29T17:28:56.274Z",
				"Answer_body": "<p>Thank you for the response and putting in a request! I was hoping to use this functionality to visualize point cloud registration at every iteration of a network, e.g. to show the source and template point clouds after applying the predicted transformation . Would also be great to have the point clouds be differentiated by color in the same plot.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-28T17:29:07.338Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Strange message when running wandb sync from commandline",
		"Question_link": "https://community.wandb.ai/t/strange-message-when-running-wandb-sync-from-commandline/2657",
		"Question_created_time": "2022-06-24T00:36:07.764Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 72,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m running wandb sync from the command line for offline runs in a cluster, and recently whenever I run it I get the message</p>\n<p><code>Seen metric with glob (shouldnt happen)</code></p>\n<p>being output in the console hundreds of times. It doesn\u2019t affect anything; I can still see the runs synced to my account, but I don\u2019t think this message should appear, given that it says \u201cshouldnt happen\u201d in the log line.</p>\n<p>My wandb library version is 0.11.2 and my python version is 3.9.6, both installed via conda. I had the same version for quite a while and I didn\u2019t run into this until a few months ago.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-28T15:55:52.466Z",
				"Answer_body": "<p>Hi Sanjeev, when you run wandb sync do you specify the path in it, for example: <code>wandb sync --project path/to/run/directory</code>, if not can you put the path name and see if this is able to help? Also, is there a reason why you want to use 0.11.2 instead of our most recent CLI version 0.12.19?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-29T08:47:27.930Z",
				"Answer_body": "<p>Hi Leslie, I run the following command to sync my runs:</p>\n<p><code>$ cd /scratch/&lt;job ID&gt; &amp;&amp; wandb sync wandb/offline-run-2022*</code></p>\n<p>I tried</p>\n<p><code>$ cd /scratch/&lt;jobid&gt;</code><br>\n<code>$ wandb sync --project ./</code></p>\n<p>but then it told me there were 5 runs to sync and that I should run <code>wandb sync --sync-all</code>. When I did that, I got the same message.</p>\n<p>I\u2019m using 0.11.2 because I didn\u2019t upgrade, this is from an old installation. I\u2019ll try that the next time I sync another run.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-07T01:50:12.246Z",
				"Answer_body": "<p>Thank you for the extra information Sanjeev. There have been a lot of bug fixes since 0.11.2, so please let me know if the upgrade is able to help with this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-12T16:11:05.528Z",
				"Answer_body": "<p>Hi Sanjeev, were you able to do the upgrade?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-15T19:48:15.700Z",
				"Answer_body": "<p>Hi again Sanjeev, because we haven\u2019t heard back from you I\u2019m going to close this ticket. But if you\u2019re still running into this issue please let me know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-28T08:47:59.490Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to compare (parameter & gradient) histograms from different runs?",
		"Question_link": "https://community.wandb.ai/t/how-to-compare-parameter-gradient-histograms-from-different-runs/2660",
		"Question_created_time": "2022-06-26T09:09:35.899Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 122,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Usually when logging a metric from different runs wandb will plot the results in the same graph (for different runs).</p>\n<p>This is not the case for histograms, is there a way to compare the histograms from different runs other than manually switching between tabs that contain the histogram plots for different runs?</p>\n<p>In general I\u2019m curious what the best way to compare gradients between different runs is. Maybe just tracking the magnitude is enough and one doesn\u2019t need histograms (I presume in this case, since the logging value is just a scalar the graphs from different runs would end up in the same plot)? Curious whether other engineers may have found this to be the case.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-29T16:29:40.882Z",
				"Answer_body": "<p>Hi Rudolf, I feel like you are asking two different questions here? Are you wanting to compare histograms or gradients. If you want to compare histograms, you can do so by creating a custom chart (<a href=\"https://wandb.ai/wandb/plots/reports/Extend-a-Preset-Histogram-Bins--VmlldzozMTAxMjU\" class=\"inline-onebox-loading\">https://wandb.ai/wandb/plots/reports/Extend-a-Preset-Histogram-Bins--VmlldzozMTAxMjU</a>). However regarding gradients through wandb.watch() we currently don\u2019t have a way to compare those charts. I can create a feature request ticket regarding this if you would like?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-06T13:00:56.192Z",
				"Answer_body": "<p>Hi Rudolf, do you still need help here?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-12T16:10:38.317Z",
				"Answer_body": "<p>Hi again Rudolf, since you haven\u2019t responded I\u2019m going to close out this ticket. However, please let me know if you want to continue this conversation!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-25T09:09:44.323Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Logging linear evaluation results asynchronously in SimCLR",
		"Question_link": "https://community.wandb.ai/t/logging-linear-evaluation-results-asynchronously-in-simclr/2646",
		"Question_created_time": "2022-06-22T17:37:05.378Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 78,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello! I\u2019m currently investigating SimCLR, which consists of a pretraining and fine-tuning/linear evaluation step. I can log pretraining loss and linear eval accuracy metrics in the same W&amp;B run by running eval after every pretraining epoch, but the pretraining script has to wait until eval is done before continuing with the next epoch. Is there any way to run linear eval <em>after</em> pretraining is done (e.g., in a separate <code>eval.py</code> script, and log the results to the same run_id?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/75c2e2de900389d008ad3df1a0c3f242bed1606d.png\" data-download-href=\"/uploads/short-url/gNLp9XWDciUbXa3tmRjGtU7axqZ.png?dl=1\" title=\"wandb_fig\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75c2e2de900389d008ad3df1a0c3f242bed1606d_2_690x456.png\" alt=\"wandb_fig\" data-base62-sha1=\"gNLp9XWDciUbXa3tmRjGtU7axqZ\" width=\"690\" height=\"456\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75c2e2de900389d008ad3df1a0c3f242bed1606d_2_690x456.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/75c2e2de900389d008ad3df1a0c3f242bed1606d.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/75c2e2de900389d008ad3df1a0c3f242bed1606d.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75c2e2de900389d008ad3df1a0c3f242bed1606d_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">wandb_fig</span><span class=\"informations\">835\u00d7553 56.7 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-24T16:41:50.356Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/goh\">@goh</a>,</p>\n<p>You can resume a run from another script using the <code>resume</code> argument in <code>wandb.init</code>. <a href=\"https://docs.wandb.ai/guides/track/advanced/resuming\">Here</a> is a link to our docs describing hot do do this.</p>\n<p>Does this work for your use case?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-29T19:54:59.527Z",
				"Answer_body": "<p>Hi Edwin,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-05T20:20:45.749Z",
				"Answer_body": "<p>Hi Edwin, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-23T16:42:38.897Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "BUG: Sweep in Jupyter makes new runs impossible to start",
		"Question_link": "https://community.wandb.ai/t/bug-sweep-in-jupyter-makes-new-runs-impossible-to-start/2645",
		"Question_created_time": "2022-06-22T08:32:54.292Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 75,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Let\u2019s say I\u2019m working on a jupyter notebook and I run a sweep</p>\n<pre><code class=\"lang-auto\">sweep_id = wandb.sweep(sweep_config, entity=WANDB_ENTITY, project=WANDB_PROJECT, )\nwandb_agent = wandb.agent(sweep_id, project=WANDB_PROJECT, function=pipeline)\n</code></pre>\n<p>After an hour I\u2019m happy with the sweep results and I stop execution, not here\u2019s the bug, I CANNOT start a new run manually. Here\u2019s what happens when I run the following code</p>\n<blockquote>\n<p>run = wandb.init()<br>\nprint(\u201c------ RUN NAME ------\u201d, run.name)<br>\nrun.finish()</p>\n<p>run = wandb.init()<br>\nprint(\u201c------ RUN NAME ------\u201d, run.name)<br>\nrun.finish()</p>\n</blockquote>\n<p>Output:</p>\n<pre><code class=\"lang-auto\">\nChanges to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to the W&amp;B docs.\nFinishing last run (ID:ln732mvm) before initializing another...\nWaiting for W&amp;B process to finish... (success).\nSynced fresh-sweep-32: https://wandb.ai/arkareem/test/runs/ln732mvm\nSynced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nFind logs at: ./wandb/run-20220622_111904-ln732mvm/logs\nSuccessfully finished last run (ID:ln732mvm). Initializing new run:\nTracking run with wandb version 0.12.18\nRun data is saved locally in /mnt/m/MyFiles/Classes/wandb/run-20220622_112014-ln732mvm\nSyncing run fresh-sweep-32 to Weights &amp; Biases (docs)\nSweep page: https://wandb.ai/arkareem/test/sweeps/9t3sbtv5\n------ RUN NAME ------ fresh-sweep-32\nWaiting for W&amp;B process to finish... (success).\nSynced fresh-sweep-32: https://wandb.ai/arkareem/test/runs/ln732mvm\nSynced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nFind logs at: ./wandb/run-20220622_112014-ln732mvm/logs\nChanges to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to the W&amp;B docs.\nTracking run with wandb version 0.12.18\nRun data is saved locally in /mnt/m/MyFiles/Classes/wandb/run-20220622_112037-ln732mvm\nSyncing run fresh-sweep-32 to Weights &amp; Biases (docs)\nSweep page: https://wandb.ai/arkareem/test/sweeps/9t3sbtv5\n------ RUN NAME ------ fresh-sweep-32\nWaiting for W&amp;B process to finish... (success).\nSynced fresh-sweep-32: https://wandb.ai/arkareem/test/runs/ln732mvm\nSynced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nFind logs at: ./wandb/run-20220622_112037-ln732mvm/logs\n\n</code></pre>\n<p>How do I start a new run without restarting the notebook and starting everything from scratch???</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-23T22:41:23.872Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/arkareem\">@arkareem</a></p>\n<p>Thank-you for writing in, we will take a look at this for you. Would it be possible for you to share a reproduction of this issue as a <code>Google Colab</code> Notebook? It will help me start off my investigation on my end.</p>\n<p>Additionally, the <code>debug.log</code> and <code>debug-internal.log</code> files associated with the affected runs would be very helpful.</p>\n<p>Thanks,<br>\nMohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-30T00:20:58.558Z",
				"Answer_body": "<p>Hi Abdulrahman,</p>\n<p>Since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-22T22:41:33.201Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Error while calling W&B API iinternal database error (<Response [500]>)",
		"Question_link": "https://community.wandb.ai/t/error-while-calling-w-b-api-iinternal-database-error-response-500/2624",
		"Question_created_time": "2022-06-16T06:31:15.016Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 1048,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am running four experiments from the same system (a google cloud VM) and while one is running fine: three have frozen (no progress but program still active/has not errored out). Curious if anyone knows how to fix this?<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/19876a837127852045cb70c484da66f5a3c28d52.png\" alt=\"image\" data-base62-sha1=\"3DQ3Zmd1Ly9oF4hn1gpJ6jJ9bB8\" width=\"681\" height=\"130\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-18T00:25:13.707Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/usman391\">@usman391</a> ,</p>\n<p>Thank you for reaching out with your support request. We will be glad to look into this to determine the cause.<br>\nCan you please provide the following:</p>\n<ul>\n<li>Description of the experiment you are running (single runs from four agents, or parallel processes?)</li>\n<li>Sample code for you how you are initializing/executing runs</li>\n<li>\n<code>debug</code> logs for the runs this error is occurring, they live in the <code>WANDB_DIR</code> which defaults to <code>./wandb</code> in your project folder.</li>\n</ul>\n<p>Please attach the code sample/logs here or send  directly to me at <a href=\"mailto:mohammad.bakir@wandb.com\">mohammad.bakir@wandb.com</a>.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-18T16:08:37.108Z",
				"Answer_body": "<p>Thanks for the response Mohammad Bakir.  The error actually went away after I rebooted the system and has not occurred again since. If it occurs again, I will let you know.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-22T20:41:43.593Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/usman391\">@usman391</a> , thank you for updating us that this error has gone away. Yes please do let us know if this occurs again. I will mark this matter closed in the meantime.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-21T20:42:26.367Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Coordinate wandb local across two laptops",
		"Question_link": "https://community.wandb.ai/t/coordinate-wandb-local-across-two-laptops/2620",
		"Question_created_time": "2022-06-15T21:07:48.687Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 166,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi Wandb Community!</p>\n<p>I have a laptop in my office that I am able to run <code>wandb local</code> on and sync my ML experiments to my account email address. My company gave me another laptop to work from on the road and I would like to set up <code>wandb local</code> on that laptop to streamline ML experiments I do in office and on the road.</p>\n<p>On my laptop, I have <code>wandb</code> and <code>docker</code> installed successfully. I can also run <code>wandb local</code> successfully. However, I\u2019m not sure if I need to copy the same api key and license over for the single account to work on both machines. Is there a smart way to do this?</p>\n<p>Thanks in advance!</p>\n<p>wand: 0.12.18<br>\nOS: Ubuntu 22.04<br>\ndocker: 20.10.17</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-17T20:51:46.274Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/aclifton314\">@aclifton314</a> ,</p>\n<p>Thank you for writing in with your question. Local is explicitly an \u201con-device\u201d service.If you want to share data across devices,  you would want to host you instance on a server to be able to reach it from anywhere, otherwise your two laptops wont share data. You can however still use the individual machine to sync data back/forth to W&amp;B cloud,  pull experiments/runs/metrics/ ect. to the individual machines. If this is your intended approach then you can copy the same API and Local License key to both machines.  <a href=\"https://docs.wandb.ai/guides/self-hosted/local#login\">Here</a> is a quick reference on how to switch between a private instance and the wandb cloud when you need to sync the data. Please let us know if you have additional questions.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-08-16T20:52:30.446Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to deal with artifact.wait() when running in mode \"DISABLED\"",
		"Question_link": "https://community.wandb.ai/t/how-to-deal-with-artifact-wait-when-running-in-mode-disabled/2607",
		"Question_created_time": "2022-06-13T15:18:04.499Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 114,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>During the preparation for a training (in <code>prepare_data</code> in pytorch lightning) I either create or update local data (download, prepare different encodings). I then create a W&amp;B artifact and wait for the upload to be complete. Later in the code (in <code>setup()</code> in pytorch lightning) I use the data. Strictly speaking, this is not necessary, because I have the files locally, but I want to track the usage of the data (and the IDs of the data used for training, validation, \u2026). I added the <code>wait()</code> statement, because wandb would download the previous version (v=n-1) of the data /without the enoding just added). In mode <code>ONLINE</code> this works nicely. However, in mode <code>DISABLED</code> I get this error: <code>ValueError: Cannot call wait on an artifact before it has been logged or in offline mode</code>. How am I supposed to handle <code>wait()</code>in order to have it work in all modes? (it would be nice if <code>wait()</code> would do it).</p>\n<p>This is the sample code:</p>\n<pre><code class=\"lang-python\"># Upload the data\nartifact = wandb.Artifact(name=..., type=...)\nartifact.description = ...\nartifact.metadata = ...\nartifact.add_file(local_path=...)\nwandb.run.log_artifact(artifact)\nartifact.save()  # I think I don't need this, playing around because of this issue\nartifact.wait()\n</code></pre>\n<pre><code class=\"lang-python\"># Use (Download) the data\nartifact = wandb.run.use_artifact(artifact_or_name=... + \":latest\")\nartifact_entry = artifact.get_path(...)\nartifact_entry.download(root=...)\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-14T06:40:31.480Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/hogru\">@hogru</a>, \u201cdisabled\u201d mode returns mocked objects and prevents all network communication. So when you call the log_artifact function, nothing will be logged which causes the error message when calling artifact.wait().</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-14T07:37:51.854Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/armanharutyunyan\">@armanharutyunyan</a>, I understand what\u2019s going on and the technical reason for it, but what is your suggested way to deal with it? I need <code>artifact.wait()</code> when online, but need the code to work when offline. Is there a simple way to check the mode of wandb or see whether there are pending uploads or\u2026? My question is how to handle the situation properly.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-17T10:48:43.780Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/hogru\">@hogru</a>, sorry about the late response. Runs have a <code>disabled</code> attribute. Here is a code snippet you can use:</p>\n<pre><code class=\"lang-auto\">run = wandb.init(mode=\"disabled\")\nif run.disabled:\n    // your code\n</code></pre>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-06-17T15:25:46.147Z",
				"Answer_body": "<p>Ah, that definitely helps, thank you. And apparently there\u2019s also <code>run.offline</code>. Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-16T15:25:54.451Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Config and summary logs gone after initialising a run again",
		"Question_link": "https://community.wandb.ai/t/config-and-summary-logs-gone-after-initialising-a-run-again/2556",
		"Question_created_time": "2022-06-05T03:16:54.146Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 156,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>After I finished a training run I wanted to upload a file, like shown here <a href=\"https://community.wandb.ai/t/add-files-to-run/1066/2\" class=\"inline-onebox\">Add files to run - #2 by _scott</a><br>\nThis worked fine, but after that all the config and summary logs were gone.</p>\n<p>Is there a way to restore them?</p>\n<p>If no, how can I save this file without loosing the logs?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-07T07:51:07.930Z",
				"Answer_body": "<p>Hey there, did. you use this code snippet?</p>\n<pre><code class=\"lang-auto\">run = wandb.init(project=&lt;project_name&gt;, id=&lt;id&gt;)\nwandb.save(&lt;file&gt;)\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-07T14:43:24.715Z",
				"Answer_body": "<p>Yes, I used exactly this code snippet.</p>\n<p>I tried with several old runs and every time all the logs were deleted</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-14T17:13:08.735Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/fryderykkogl\">@fryderykkogl</a>, apologies about the delay. The issue is that the code snippet is wrong. It reinitializes a run which cause the config and the summary to get overwritten. You should use this <a href=\"https://docs.wandb.ai/guides/track/public-api-guide#upload-files-to-a-finished-run\">snippet</a> if you want to upload files to a run.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-17T10:03:33.767Z",
				"Answer_body": "<p>\u200bHi <a class=\"mention\" href=\"/u/fryderykkogl\">@fryderykkogl</a>, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>\u200b</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-16T10:04:22.393Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sweep creation down? (Resolved)",
		"Question_link": "https://community.wandb.ai/t/sweep-creation-down-resolved/2615",
		"Question_created_time": "2022-06-15T19:28:54.078Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 152,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello, I thought you\u2019d like to know that creating a sweep seems to be broken for me. I get a new sweep ID, but going to the URL in question gets a 404, and it doesn\u2019t appear in the sweep list either. I\u2019ve tried via CLI and browser.</p>\n<p>Edit: Seems to be back up!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-16T08:46:47.497Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/dcx\">@dcx</a>, glad it\u2019s working now for you. Please let us know if you experience any issues like this again.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-15T08:46:55.391Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Upload model weights to the Artifacts of a finished run",
		"Question_link": "https://community.wandb.ai/t/upload-model-weights-to-the-artifacts-of-a-finished-run/2540",
		"Question_created_time": "2022-06-03T00:26:07.487Z",
		"Question_answer_count": 4,
		"Question_score_count": 2,
		"Question_view_count": 220,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I was training a yolov5 model, using the pre-configured wandb settings. But the weights weren\u2019t uploaded because the session was killed. I tried <code>wandb sync path/to/run</code> but the model file didn\u2019t get synced.</p>\n<p>I want to upload the resulting <code>best.pt</code> file to the artifacts regardless without messing up with the current summary and results of the finished run. I looked up in the documentation and tried multiple guides but couldn\u2019t manage to do that.</p>\n<p>TL;DR: I have a finished run and a weights file. I need to upload the weights file as a model artifact to that finished run using the run path.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-03T08:42:43.908Z",
				"Answer_body": "<p>hey <a class=\"mention\" href=\"/u/alyetama\">@alyetama</a> , I think you can 1) resume the run 2) upload the model weights to that run</p>\n<ol>\n<li>Resume a run</li>\n</ol>\n<p>Pass your run_id to wandb.init to resume the run. You can get the id from the url of the run page or from the \u201cinfo\u201d section (click the (i) button in the top left corner of the run page.</p>\n<pre><code class=\"lang-auto\">wandb.init(id=run_id, resume=\"must\")\n</code></pre>\n<ol start=\"2\">\n<li>Upload an artifact to that run</li>\n</ol>\n<pre><code class=\"lang-auto\">wandb.log_artifact(file_path, name='new_artifact', type='model') \n\nwandb.finish()\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-07T07:41:19.840Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/alyetama\">@alyetama</a>, here is a code snippet you can use: <a href=\"https://docs.wandb.ai/guides/artifacts/artifacts-faqs#how-do-i-log-an-artifact-to-an-existing-run\">https://docs.wandb.ai/guides/artifacts/artifacts-faqs#how-do-i-log-an-artifact-to-an-existing-run</a></p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-06-14T12:31:09.632Z",
				"Answer_body": "<aside class=\"quote no-group quote-modified\" data-username=\"alyetama\" data-post=\"4\" data-topic=\"2540\" data-full=\"true\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/a/c6cbf5/40.png\" class=\"avatar\"> alyetama:</div>\n<blockquote>\n<p>This initially uploaded my artifact to a different project. But it worked after I specified the project name in <code>wandb.init</code>.<br>\nThanks!</p>\n</blockquote>\n</aside>\n<p>This initially uploaded my artifact to a different project. But it worked after I specified the project name in wandb.init.<br>\nThanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-13T12:32:10.450Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to save configs?",
		"Question_link": "https://community.wandb.ai/t/how-to-save-configs/2587",
		"Question_created_time": "2022-06-09T17:16:40.865Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 93,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I can\u2019t figure out how to save configurations.</p>\n<p>After initilization I do <code>wandb.config.update(model_config)</code> where <code>model_config</code> is a dict.</p>\n<p>However, it does not sync with the user interface, that\u2019s still true after calling <code>wandb.finish()</code>.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b7062521caebaa48838e51e3df8a358947ae83f1.png\" data-download-href=\"/uploads/short-url/q76xEv6yugWsGPOs0ho5RCULGGl.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b7062521caebaa48838e51e3df8a358947ae83f1_2_690x271.png\" alt=\"image\" data-base62-sha1=\"q76xEv6yugWsGPOs0ho5RCULGGl\" width=\"690\" height=\"271\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b7062521caebaa48838e51e3df8a358947ae83f1_2_690x271.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b7062521caebaa48838e51e3df8a358947ae83f1_2_1035x406.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b7062521caebaa48838e51e3df8a358947ae83f1.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b7062521caebaa48838e51e3df8a358947ae83f1_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1245\u00d7490 30.5 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-10T15:50:11.687Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/scientya\">@scientya</a>, can you try passing the config to <a href=\"https://docs.wandb.ai/ref/python/init\">wandb.init</a>?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-14T02:23:10.824Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-14T04:51:57.377Z",
				"Answer_body": "<p>Hey there, since we have not heard back from you, I\u2019ll be closing this ticket. But please message me if you need assistance on this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-13T04:52:27.317Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb in academic work as a PhD student with industry collaborations/internship)?",
		"Question_link": "https://community.wandb.ai/t/wandb-in-academic-work-as-a-phd-student-with-industry-collaborations-internship/2529",
		"Question_created_time": "2022-06-01T20:09:38.109Z",
		"Question_answer_count": 4,
		"Question_score_count": 2,
		"Question_view_count": 165,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I was wondering on a use case most graduate students (PhD) in machine learning often come across and thought it would be better to open it up. We often do <strong>academic research</strong> (not for commercial) while doing an internship at a company while still affiliated to our university institution.</p>\n<p>In that case is it ok to use the academic teams we usually use during the semester for our internship?</p>\n<p>Does that fall this use:</p>\n<blockquote>\n<p>And guess what? W&amp;B is free for personal and academic use. (The latter is especially important for students and academics and something we\u2019ve championed since we started the company).</p>\n</blockquote>\n<p>from this site: <a href=\"https://wandb.ai/ivangoncharov/wandb-teams-for-students/reports/How-to-Use-W-B-Teams-For-Your-University-Machine-Learning-Projects-For-Free---VmlldzoxMjk1Mjkx\" class=\"inline-onebox\">Weights &amp; Biases</a></p>\n<p>PS: I thought I had asked this already\u2026if yes link the question if it has an answer and my apologies before hand. If not I will remove this ps later.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-03T21:30:04.276Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/brando\">@brando</a> ,</p>\n<p>Thank you for reaching out. We will look into this for you and let you know if you can continue  using your academic account while interning.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-06T14:27:52.086Z",
				"Answer_body": "<p>Thank you! Really appreciate this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-13T21:23:16.829Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/brando\">@brando</a> ,</p>\n<p>Thank-you for your patience on this. You may use your account while you are interning. Please let us know if you have additional requests/questions.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-12T21:23:17.386Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sagemaker blazingtext logging loss and accuracy",
		"Question_link": "https://community.wandb.ai/t/sagemaker-blazingtext-logging-loss-and-accuracy/2542",
		"Question_created_time": "2022-06-03T00:42:06.810Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 95,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello! I have recently trained a sagemaker estimator called blazingtext  for text classification. I am struggling on how to log the accuracy and loss with wandb.log(). Would love some help with this. Thanks a ton!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-07T17:14:36.631Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/twhitehurst3\">@twhitehurst3</a>!</p>\n<p>I\u2019m glad to hear you\u2019re interested in using W&amp;B <img src=\"https://emoji.discourse-cdn.com/twitter/handshake.png?v=12\" title=\":handshake:\" class=\"emoji\" alt=\":handshake:\" loading=\"lazy\" width=\"20\" height=\"20\"> Sagemaker. We offer a variety of resources which show how to train a Sagemaker estimator alongside Weights &amp; Biases. I have personally not used the BlazingText offering that they provide so any details/code you can provide will help us provide a more pointed solution for your question.</p>\n<p>In the interim let me provide you resources which can make this W&amp;B <img src=\"https://emoji.discourse-cdn.com/twitter/handshake.png?v=12\" title=\":handshake:\" class=\"emoji\" alt=\":handshake:\" loading=\"lazy\" width=\"20\" height=\"20\"> Sagemaker process easier.</p>\n<ul>\n<li>Docs: <a href=\"https://docs.wandb.ai/guides/integrations/other/sagemaker\">https://docs.wandb.ai/guides/integrations/other/sagemaker</a>\n</li>\n<li>Blog: <a href=\"https://wandb.ai/site/articles/running-sweeps-with-sagemaker\" class=\"inline-onebox\">Optimizing CIFAR-10 Hyperparameters with W&amp;B and SageMaker on Weights &amp; Biases</a>\n</li>\n<li>Report: <a href=\"https://wandb.ai/authors/sagemaker/reports/Deploy-Sentiment-Analyzer-Using-SageMaker-and-W-B--VmlldzoxODA1ODE\" class=\"inline-onebox\">Weights &amp; Biases</a>\n</li>\n<li>Example: <a href=\"https://github.com/wandb/examples/blob/master/examples/sagemaker/text_classification/text_classification.ipynb\" class=\"inline-onebox\">examples/text_classification.ipynb at master \u00b7 wandb/examples \u00b7 GitHub</a>\n</li>\n</ul>\n<p>I hope this is able to help!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-13T15:08:31.447Z",
				"Answer_body": "<p>Hello! I was wondering if there was anything else I could do to help here/if the resources I provided were helpful!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-12T15:08:44.389Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Add run to existing sweep",
		"Question_link": "https://community.wandb.ai/t/add-run-to-existing-sweep/2604",
		"Question_created_time": "2022-06-12T17:46:28.205Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 76,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>The last run of my sweep crashed, so I run the last one again, but now it\u2019s not in the sweep. Can I add this run to the sweep somehow?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-11T17:46:36.852Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Why is only the final logged value counted towards min or max of a metric?",
		"Question_link": "https://community.wandb.ai/t/why-is-only-the-final-logged-value-counted-towards-min-or-max-of-a-metric/2601",
		"Question_created_time": "2022-06-11T15:06:07.646Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 104,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I wanted to find the run with the best validation accuracy, however, I noticed that to calculate the maximum only the  last logged values are used.</p>\n<p>You can see this on the screenshot below - it says the run with the maximum validation accuracy is run \u201821-\u2026\u2019 (the one that stopped earlier), even though run \u201818-\u2026\u2019 had a higher value one epoch after the other ones end. The problem is that one epoch later run 18 dropped in accuracy again, so it doesn\u2019t have \u2018final maximum\u2019 accuracy\u2026</p>\n<p>This is a bit problematic for me - I\u2019m saving my models after each epoch, so I don\u2019t really care only about the last model - precisely to prevent such a problem where the accuracy would suddenly drop at the end.</p>\n<p>I think this is a bit similar to this post: <a href=\"https://community.wandb.ai/t/can-i-plot-the-value-of-a-metric-at-a-single-step/1971\" class=\"inline-onebox\">Can I plot the value of a metric at a single step?</a></p>\n<p>Is this a feature, or is this a bug?</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/c54fbc738774c965e52b5c6cea75de46d5e889ff.png\" data-download-href=\"/uploads/short-url/s9uTwyqB1GUIxqL7kJT4rjYgf8P.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/c54fbc738774c965e52b5c6cea75de46d5e889ff_2_478x500.png\" alt=\"image\" data-base62-sha1=\"s9uTwyqB1GUIxqL7kJT4rjYgf8P\" width=\"478\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/c54fbc738774c965e52b5c6cea75de46d5e889ff_2_478x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/c54fbc738774c965e52b5c6cea75de46d5e889ff_2_717x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/c54fbc738774c965e52b5c6cea75de46d5e889ff_2_956x1000.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/c54fbc738774c965e52b5c6cea75de46d5e889ff_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1094\u00d71144 56.3 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-10T15:06:27.188Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Keras tuner integration with WandB",
		"Question_link": "https://community.wandb.ai/t/keras-tuner-integration-with-wandb/2538",
		"Question_created_time": "2022-06-02T17:09:15.046Z",
		"Question_answer_count": 8,
		"Question_score_count": 1,
		"Question_view_count": 152,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I\u2019m a new WandB user and I\u2019m trying to integrate WandB with my keras tuner in order to keep track of my hyper parameter tunning.</p>\n<p>I tried to follow an online guide I found but I\u2019m getting errors when I try to load the models with the tuner.get_best_models() function</p>\n<p><strong>NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for DAM_Aggr_tuning_129_cc/DAM_Aggr_tuning_129_cc_project/trial_2/checkpoint</strong></p>\n<p>Here I leave a link to my colab notebook, anyone that can help it would be really appreciated, I feel stuck\u2026</p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://colab.research.google.com/drive/1RIqFRqmDMg48KF64ZkzN1BDLNx1y_fef?usp=sharing\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/15b193ca15faf45091ba185f7b8a62df5d7d3566.png\" class=\"site-icon\" width=\"16\" height=\"16\">\n\n      <a href=\"https://colab.research.google.com/drive/1RIqFRqmDMg48KF64ZkzN1BDLNx1y_fef?usp=sharing\" target=\"_blank\" rel=\"noopener nofollow ugc\">colab.research.google.com</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/e2eb089e1834a0581da1d893b1624f376f01ad6a.png\" class=\"thumbnail onebox-avatar\" width=\"260\" height=\"260\">\n\n<h3><a href=\"https://colab.research.google.com/drive/1RIqFRqmDMg48KF64ZkzN1BDLNx1y_fef?usp=sharing\" target=\"_blank\" rel=\"noopener nofollow ugc\">Google Colaboratory</a></h3>\n\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-03T09:43:12.215Z",
				"Answer_body": "<p>Hi,<br>\nSomeone on the team is having a look at this and will be in touch with some help ASAP.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-06T11:39:22.877Z",
				"Answer_body": "<p>Hello,<br>\nThank you very much for looking into my issue,</p>\n<p>if there is anything I could provide you with please let me know.</p>\n<p>It it would be amazing if there was a solution, thank you so much!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-07T20:49:32.712Z",
				"Answer_body": "<p>Hi Loannis,</p>\n<p>Thank you for writing in, and apologies for the delay, we just happened to miss this request.I will review this material immediately and follow up by end of day tomorrow.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-08T07:12:34.580Z",
				"Answer_body": "<p>Thank you very much! Let me also provide you with a link to my github folder in case that can help you more.<br>\nThere is the full code suposed to be working along with the data i\u2019m trying to use.</p>\n<aside class=\"onebox githubfolder\" data-onebox-src=\"https://github.com/iaioanno/WandB/tree/main/HUB\">\n  <header class=\"source\">\n      <img src=\"https://github.githubassets.com/favicons/favicon.svg\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https://github.com/iaioanno/WandB/tree/main/HUB\" target=\"_blank\" rel=\"noopener nofollow ugc\">github.com</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <h3><a href=\"https://github.com/iaioanno/WandB/tree/main/HUB\" target=\"_blank\" rel=\"noopener nofollow ugc\">WandB/HUB at main \u00b7 iaioanno/WandB</a></h3>\n\n  <p><a href=\"https://github.com/iaioanno/WandB/tree/main/HUB\" target=\"_blank\" rel=\"noopener nofollow ugc\">main/HUB</a></p>\n\n  <p><span class=\"label1\">Help please. Contribute to iaioanno/WandB development by creating an account on GitHub.</span></p>\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-08T23:31:56.480Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/johnioanno\">@johnioanno</a> ,</p>\n<p>I verified that this error is not attributed to wandb.  You are creating a python subclass, <code>MyTuner(kt.Tuner)</code> to customize the Keras tuner base  class <code>BaseTuner</code>, see <a href=\"https://github.com/keras-team/keras-tuner/blob/a45341c940e33abb4940a10bad4886f3cb66e88e/keras_tuner/engine/base_tuner.py#L34\" rel=\"noopener nofollow ugc\">here</a> for source, and you intend to save the model within this subclass. You must define the <code>save_model</code> method, see <a href=\"https://github.com/keras-team/keras-tuner/blob/a45341c940e33abb4940a10bad4886f3cb66e88e/keras_tuner/engine/base_tuner.py#L208\" rel=\"noopener nofollow ugc\">here</a> within you subclass. Otherwise you do get the <code>NotImplementedError</code> reminding you to implement it.</p>\n<p>This impacts your ability to load a model(s), resulting in the <code>NotFoundError</code> exception.</p>\n<p>Hope this helps you to move forward with your implementation. Please do reach out again if you run into errors while logging  with <code>WandbCallback()</code>.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-10T23:39:11.275Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/johnioanno\">@johnioanno</a> ,</p>\n<p>As we have not heard back from you, we are going to close this request. If you would like to re-open the conversation, please let us know!</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-11T14:45:40.036Z",
				"Answer_body": "<p>ok, Thank you very much for the help!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-10T14:46:23.692Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Bug report",
		"Question_link": "https://community.wandb.ai/t/bug-report/2566",
		"Question_created_time": "2022-06-07T08:33:23.112Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 121,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi<br>\nwhen trying to  export panel with multiple groups to PDF/PNG much of the information being cut (even for maximal height and width).<br>\nwhen trying to CSV the plot it seems to be ignoring the grouping .</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-07T19:04:09.966Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/amirhagai\">@amirhagai</a> ,</p>\n<p>Thank you for writing in. I\u2019d be happy to look into that for you. My responses to your two requests:</p>\n<ul>\n<li>\n<p>For the issue you are experiencing with your PDF/PNG exports being cut off, can you please provide a look to your workspace and reference the panel chart you are exporting. Once received I will attempt to replicate your issue and can provide you an update.</p>\n</li>\n<li>\n<p>In terms of being able to export run data that is grouped, this is not currently supported. We do have a feature request open for this and I have added your details to the ticket. If the feature is deployed we will update you.</p>\n</li>\n</ul>\n<p>Please let me know if you have any questions.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-09T06:29:46.117Z",
				"Answer_body": "<p>Thanks!<br>\nthe work space is  at <a href=\"https://wandb.ai/amirhagai/ROBUST_VS_ACC_TRADES?workspace=user-amirhagai\" class=\"inline-onebox\">Weights &amp; Biases</a><br>\nthe grouping is by architecture and kernel ( second).<br>\nthe plot I want to export is the acc on steps plot.<br>\nthere is a good preview for the pdf, but when trying to download it it truncate itself to regular size page without additional adaptation<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/8141d720972231e7e9ce6aef24bab36b16e70fef.png\" data-download-href=\"/uploads/short-url/irsEFxy3w9vKxEqeupIqqyskgdF.png?dl=1\" title=\"this is ok\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/8141d720972231e7e9ce6aef24bab36b16e70fef_2_488x500.png\" alt=\"this is ok\" data-base62-sha1=\"irsEFxy3w9vKxEqeupIqqyskgdF\" width=\"488\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/8141d720972231e7e9ce6aef24bab36b16e70fef_2_488x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/8141d720972231e7e9ce6aef24bab36b16e70fef_2_732x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/8141d720972231e7e9ce6aef24bab36b16e70fef.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/8141d720972231e7e9ce6aef24bab36b16e70fef_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">this is ok</span><span class=\"informations\">901\u00d7922 232 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-09T06:30:18.270Z",
				"Answer_body": "<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/4c13eef461bfa49bceb27db41475174c3877a884.jpeg\" data-download-href=\"/uploads/short-url/aR0ZGoZybs18ueTCO70jeRSmzkg.jpeg?dl=1\" title=\"pop up window - good image but can&amp;#39;t be download\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/4c13eef461bfa49bceb27db41475174c3877a884_2_690x360.jpeg\" alt=\"pop up window - good image but can't be download\" data-base62-sha1=\"aR0ZGoZybs18ueTCO70jeRSmzkg\" width=\"690\" height=\"360\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/4c13eef461bfa49bceb27db41475174c3877a884_2_690x360.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/4c13eef461bfa49bceb27db41475174c3877a884_2_1035x540.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/4c13eef461bfa49bceb27db41475174c3877a884_2_1380x720.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/4c13eef461bfa49bceb27db41475174c3877a884_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">pop up window - good image but can&amp;#39;t be download</span><span class=\"informations\">1590\u00d7830 309 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-09T06:33:13.428Z",
				"Answer_body": "<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/72c656810af4dc76f5f90b052953ccb02e353ef4.jpeg\" data-download-href=\"/uploads/short-url/gnlmR2jK7Mnq2xSQTbImneznxVG.jpeg?dl=1\" title=\"resulting pdf\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/72c656810af4dc76f5f90b052953ccb02e353ef4_2_690x339.jpeg\" alt=\"resulting pdf\" data-base62-sha1=\"gnlmR2jK7Mnq2xSQTbImneznxVG\" width=\"690\" height=\"339\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/72c656810af4dc76f5f90b052953ccb02e353ef4_2_690x339.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/72c656810af4dc76f5f90b052953ccb02e353ef4_2_1035x508.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/72c656810af4dc76f5f90b052953ccb02e353ef4_2_1380x678.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/72c656810af4dc76f5f90b052953ccb02e353ef4_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">resulting pdf</span><span class=\"informations\">1784\u00d7878 143 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-10T17:23:33.635Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/amirhagai\">@amirhagai</a> ,</p>\n<p>Thank you for providing the requested material. The source of the issue is the legend. They legend attempt\u2019s to fit all run names, pushing the chart further down the PDF. I have put in an internal request for our web team to review the export feature. If a fix is implemented, I will provide you an update.</p>\n<p>In the mean time, one way of getting around this, is to modify the legend labels (This does not affect run names in the runs table) from the <strong>Legend Tab</strong> in the chart configuration window, see <strong>LegendRename.png</strong> for example. After doing this I was able to export reasonable PDFs in both <strong>portrait</strong> and <strong>landscape</strong> orientations, see  screen shots for examples. Note that the file names include the export Width/Height configs I used.</p>\n<p>Hope this helps for now. Please let me know if you have any questions.</p>\n<p>Mohammad</p>\n<p>Regards,<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/0cb7e8528ceb0705564010463d3cf64d4bafe3a2.png\" data-download-href=\"/uploads/short-url/1OvKtILAxMgnLv8F5SI6YLSNVAe.png?dl=1\" title=\"LegendRename\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0cb7e8528ceb0705564010463d3cf64d4bafe3a2_2_690x491.png\" alt=\"LegendRename\" data-base62-sha1=\"1OvKtILAxMgnLv8F5SI6YLSNVAe\" width=\"690\" height=\"491\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0cb7e8528ceb0705564010463d3cf64d4bafe3a2_2_690x491.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/0cb7e8528ceb0705564010463d3cf64d4bafe3a2.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/0cb7e8528ceb0705564010463d3cf64d4bafe3a2.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0cb7e8528ceb0705564010463d3cf64d4bafe3a2_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">LegendRename</span><span class=\"informations\">731\u00d7521 53.3 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/0a033390091fe7081ad0b4b4a7d3acbe6861e0ea.png\" data-download-href=\"/uploads/short-url/1qzDhYjUko43BV2yDwi5y1bHmqe.png?dl=1\" title=\"ChangedRunNames_Portrait_850W_700H\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0a033390091fe7081ad0b4b4a7d3acbe6861e0ea_2_575x500.png\" alt=\"ChangedRunNames_Portrait_850W_700H\" data-base62-sha1=\"1qzDhYjUko43BV2yDwi5y1bHmqe\" width=\"575\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0a033390091fe7081ad0b4b4a7d3acbe6861e0ea_2_575x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/0a033390091fe7081ad0b4b4a7d3acbe6861e0ea.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/0a033390091fe7081ad0b4b4a7d3acbe6861e0ea.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0a033390091fe7081ad0b4b4a7d3acbe6861e0ea_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">ChangedRunNames_Portrait_850W_700H</span><span class=\"informations\">857\u00d7745 163 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/063d83a52b590feedc43413fc1650588c6ead8db.png\" data-download-href=\"/uploads/short-url/TcEPajuZcFdUF6iRSz2IjjS3fd.png?dl=1\" title=\"ChangedRunNames_Landscape_1050W_550H\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/063d83a52b590feedc43413fc1650588c6ead8db_2_690x404.png\" alt=\"ChangedRunNames_Landscape_1050W_550H\" data-base62-sha1=\"TcEPajuZcFdUF6iRSz2IjjS3fd\" width=\"690\" height=\"404\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/063d83a52b590feedc43413fc1650588c6ead8db_2_690x404.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/063d83a52b590feedc43413fc1650588c6ead8db_2_1035x606.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/063d83a52b590feedc43413fc1650588c6ead8db.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/063d83a52b590feedc43413fc1650588c6ead8db_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">ChangedRunNames_Landscape_1050W_550H</span><span class=\"informations\">1058\u00d7620 173 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-09T17:24:37.283Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Resuming run/training",
		"Question_link": "https://community.wandb.ai/t/resuming-run-training/2487",
		"Question_created_time": "2022-05-23T22:28:02.230Z",
		"Question_answer_count": 9,
		"Question_score_count": 0,
		"Question_view_count": 1540,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi (Please note the codes are in italic),<br>\nI created a new run using code below:</p>\n<p><em>id = wandb.util.generate_id()</em><br>\n<em>run = wandb.init(project=\u2018checkpoint\u2019,  name=\u2018new_load\u2019,  id=id, config=configs)</em></p>\n<p>and the results (lets say for 10 epochs) were stored in my account as expected. I also saved the last model in the run using <em>wandb.save(\u2018last_model.h5\u2019)</em>.  Now, I want to continue learning from epoch 10 for 10 more epochs till epoch 20 for the last_model. So, I first restore the model using the code below:</p>\n<p><em>restored_model = wandb.restore(\u2018last_model.h5\u2019,  run_path=\"\u2026/checkpoint/id\")</em></p>\n<p>then, I load the weights from restored_model to the model:</p>\n<p><em>model = build_model()</em><br>\n<em>model.load_weights(restored_model.name)</em></p>\n<p>and then I compiled the model. However, when I execute <em>model.fit()</em>, nothing happens, that is the code is executed without any error but there is no training and no epoch just like executing an empty cell.</p>\n<p><em>num_epoch = config.epochs - wandb.run.step</em><br>\n<em>model.fit(x_train, y_train, batch_size=config.batch_size, verbose=1, epochs=num_epoch, validation_data=(x_valid, y_valid), shuffle=False,  initial_epoch=wandb.run.step, callbacks=[ WandbCallback(training_data=(x_train, y_train),  validation_data=(x_valid, y_valid))])</em></p>\n<p>I really appreciate any help as I am so in need of resuming training.</p>\n<p>By the way, I have been wondering why in the example below which is in the resume documentation you use model.compile() while  loading the entire model. You won\u2019t need compile the model when you load the entire model. I believe it is not correct and you need to edit the code:<br>\nimport keras<br>\nimport numpy as np<br>\nimport wandb<br>\nfrom wandb.keras import WandbCallback</p>\n<p>wandb.init(project=\u201cpreemptible\u201d, resume=True)</p>\n<p>if wandb.run.resumed:<br>\n# restore the best model<br>\n<strong>model = keras.models.load_model(wandb.restore(\u201cmodel-best.h5\u201d).name)</strong><br>\nelse:<br>\na = keras.layers.Input(shape=(32,))<br>\nb = keras.layers.Dense(10)(a)<br>\nmodel = keras.models.Model(input=a, output=b)</p>\n<p><strong>model.compile(\u201cadam\u201d, loss=\u201cmse\u201d)</strong><br>\nmodel.fit(np.random.rand(100, 32), np.random.rand(100, 10),<br>\n# set the resumed epoch<br>\ninitial_epoch=wandb.run.step, epochs=300,<br>\n# save the best model if it improved each epoch<br>\ncallbacks=[WandbCallback(save_model=True, monitor=\u201closs\u201d)])</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-25T22:32:59.499Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sajmahmo\">@sajmahmo</a>,</p>\n<p>I\u2019m sorry this is happening to you - this is very odd behavior. We\u2019ll have to run some tests to get a better sense of the situation here. To start, could you restore the model and call model.evaluate on a hold out set to make sure that the weights are restored correctly? Additionally, it might help to check the value of <code>num_epoch</code> that is being sent to <code>model.fit</code>. The values of <code>config.epochs</code> and <code>wandb.run.step</code> might not be aligned.</p>\n<p>I\u2019ll try to reproduce this issue on my end as well, but it certainly would help to know the results on your end where this issue is known to appear.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-26T12:50:18.822Z",
				"Answer_body": "<p>Hi,</p>\n<p>I tried what you said and seems the weights are correctly restored. The metric is quite high, so it can\u2019t be weights. <code>num_epoch</code> is also fine because I tested before. For example, If I already trained the model with 100 epochs, and I want to continue training to another 100 epochs, I will set <code>config.epochs=200</code>, and <code>wandb.run.step</code> is equal to 100, so when I pass <code>num_epoch</code> to <code>model.fit()</code>, it will train the model for 100 more epochs until the epoch 200 (considering that <code>initial_epoch=wandb.run.step</code>).</p>\n<p>I think it must be the argument \u201cresume\u201d in <code>wandb.init()</code>. It is somehow confusing whether it should be True or \u201cmust\u201d although I tried both, but both resulted in the same issue. I believe resume simply does not match with <code>model.fit()</code> because for other things, it works well. For instance, when I wanted to correct the info of configs for a run,  I used <code>resume=True or 'must'</code>, and it was corrected in the run overview.</p>\n<p>Thanks for your support,<br>\nSajjad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-03T08:28:08.313Z",
				"Answer_body": "<p>Dear Ramit,</p>\n<p>It is been while since your response to my question. I wonder whether you have been working on my problem or what. Please let me know what is going on or it is closed as your point of view.</p>\n<p>Regards,<br>\nSajjad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-03T20:03:54.844Z",
				"Answer_body": "<p>Hi Sajjad,</p>\n<p>Apologies about the delay here. I did look into your problem and tried to reproduce it on my end, but I was not able to reproduce the bug you are seeing. On my end, the restored model seems to train fine and learn correctly. Would it be possible for you to share a google colab with a reproduction of your issue?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-05T22:51:19.870Z",
				"Answer_body": "<p>Hi Ramit,</p>\n<p>I can\u2019t upload ipynb file here. How can I share the file with you?</p>\n<p>Regards,<br>\nSajjad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-06T17:00:40.256Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/sajmahmo\">@sajmahmo</a>,</p>\n<p>You can email us at <a href=\"mailto:support@wandb.com\">support@wandb.com</a> with the file!</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-09T19:39:11.708Z",
				"Answer_body": "<p>Hi Sajjad,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-10T11:51:21.184Z",
				"Answer_body": "<p>Dear Ramit,</p>\n<p>I sent the email containing the colab file with the title, Resuming run/training.</p>\n<p>Regards,<br>\nSajjad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-09T11:51:38.825Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Can I manually cancel a run in a sweep?",
		"Question_link": "https://community.wandb.ai/t/can-i-manually-cancel-a-run-in-a-sweep/2583",
		"Question_created_time": "2022-06-09T17:08:32.062Z",
		"Question_answer_count": 2,
		"Question_score_count": 1,
		"Question_view_count": 168,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Can I manually stop a run in a sweep so that the sweep agent will just continue with the next run?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-10T02:59:49.273Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/fryderykkogl\">@fryderykkogl</a> ,</p>\n<p>Yes, you can manually stop runs directly from the webUI. In the sweeps run table, select the options menu for the run you want to stop, and select  <code>stop run</code>. The sweep will continue to the next run configuration. See this image for reference. Please let us know if you have any followup questions.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/51667cd84dc068e0d2d43d2997688afbb76431fc.png\" data-download-href=\"/uploads/short-url/bC6fK8EPrbIPohDGGY4pPBG24Ec.png?dl=1\" title=\"Screen Shot 2022-06-09 at 7.57.28 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/51667cd84dc068e0d2d43d2997688afbb76431fc_2_394x500.png\" alt=\"Screen Shot 2022-06-09 at 7.57.28 PM\" data-base62-sha1=\"bC6fK8EPrbIPohDGGY4pPBG24Ec\" width=\"394\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/51667cd84dc068e0d2d43d2997688afbb76431fc_2_394x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/51667cd84dc068e0d2d43d2997688afbb76431fc_2_591x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/51667cd84dc068e0d2d43d2997688afbb76431fc_2_788x1000.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/51667cd84dc068e0d2d43d2997688afbb76431fc_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-06-09 at 7.57.28 PM</span><span class=\"informations\">952\u00d71206 94.7 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-08-09T03:00:29.475Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb.watch with PyTorch Lightning not logging",
		"Question_link": "https://community.wandb.ai/t/wandb-watch-with-pytorch-lightning-not-logging/2589",
		"Question_created_time": "2022-06-09T22:56:34.134Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 306,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I moved all of my calls to wandb  from the training loop to PyTorch Lightning (PL)'s <code>Callback</code> module. All of my <code>wandb.log()</code> calls are working properly, but the gradients and parameter tabs in my wandb dashboard are empty.  I checked two threads:</p>\n<ul>\n<li>Wandb.watch with pytorch not logging anything</li>\n<li>When is one supposed to run wandb.watch so that weights and biases tracks params and gradients?</li>\n</ul>\n<p>For the first thread, the link to the run has expired and I don\u2019t fully understand the context of the solution \"\u2026 was using <code>forward()</code> instead of <code>__call__()</code>\".</p>\n<p>For the second thread, <code>wandb.log</code> is getting called after PL\u2019s Callback hook <a href=\"https://pytorch-lightning.readthedocs.io/en/latest/extensions/callbacks.html#on-train-batch-end\" rel=\"noopener nofollow ugc\"><code>on_train_batch_end</code></a>, so <code>wandb.log</code> should be getting called after a backward pass.</p>\n<p>Below is a portion of the code defined in the Callback Module. At the start of training (<code>on_fit_start</code>) I initialize the wandb run and call <code>wandb.watch</code>.  And after a batch is completed, (<code>on_train_batch_end</code>) I log all the metrics.</p>\n<pre><code class=\"lang-auto\">Class PatentLoggerCallback(Callback):\n \n   # Omitted non-relevant code \n\n    def on_fit_start(self, trainer, pl_module):\n        wandb.init(project=self.project,\n                   config=pl_module.hparams,\n                   dir=self.save_dir)\n\n        wandb.watch(pl_module,\n                    criterion=torch.nn.functional.binary_cross_entropy_with_logits,\n                    log='all',\n                    log_freq=10,\n                    log_graph=True)\n\n    def on_train_batch_end(\n        self,\n        trainer: Trainer,\n        pl_module: LightningModule,\n        outputs: Sequence,\n        batch: Sequence,\n        batch_idx: int,\n        dataloader_idx: int,\n    ) -&gt; None:\n\n        metrics = outputs['metrics']\n        for metric, value in metrics.items():\n            wandb.log({f'train/{metric}': value})\n</code></pre>\n<p>I would like to have produced a google collab for reproducibility, but there is a lot of code involved. The next best thing I can offer is this <a href=\"https://github.com/DennisMinn/patent-phrase-matching/blob/nakama/Workspace.ipynb\" rel=\"noopener nofollow ugc\">Jupyter Notebook</a> that runs through my entire code.  I\u2019m not expecting you to clone to repository, but if you do make sure you\u2019re on the \u201cnakama\u201d branch.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-10T00:12:42.603Z",
				"Answer_body": "<p><strong>RESOLVED</strong></p>\n<p>In my model\u2019s forward pass I wrote <code>return torch.rand(input_ids.shape[0], requires_grad=True)</code> to faster debug other <code>wandb.log</code> calls by skipping expensive computation. B/c none of the model\u2019s parameters were being updated, there  was no backward pass over the model being watched. The only thing that underwent the backward pass was the <code>torch.rand()</code>  hence no histograms.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-09T00:13:37.833Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "[fixed] Cannot use Sweeps - metric value [null]",
		"Question_link": "https://community.wandb.ai/t/fixed-cannot-use-sweeps-metric-value-null/2576",
		"Question_created_time": "2022-06-08T17:41:48.211Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 361,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi! <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<p>I am using <a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/boosting/Using_W%26B_Sweeps_with_XGBoost.ipynb#scrollTo=VCRlDRL6_5aA\" rel=\"noopener nofollow ugc\">this notebook</a> as a tutorial to log sweeps into <a href=\"https://wandb.ai/andrada/AI4Code?workspace=user-andrada\">my Dashboard</a>.</p>\n<p>Everything works very well besides the Metric, which loggs with the value Null (<a href=\"https://wandb.ai/andrada/AI4Code/sweeps/6831zeoz?workspace=user-andrada\">see this run for details</a>)</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/3ed36db8c7cb03fbacf376fc1167163c09034ba2.png\" data-download-href=\"/uploads/short-url/8XMAnSbrBXqOrZuGJcQDg6tQrGq.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3ed36db8c7cb03fbacf376fc1167163c09034ba2_2_690x249.png\" alt=\"image\" data-base62-sha1=\"8XMAnSbrBXqOrZuGJcQDg6tQrGq\" width=\"690\" height=\"249\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3ed36db8c7cb03fbacf376fc1167163c09034ba2_2_690x249.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3ed36db8c7cb03fbacf376fc1167163c09034ba2_2_1035x373.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3ed36db8c7cb03fbacf376fc1167163c09034ba2_2_1380x498.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3ed36db8c7cb03fbacf376fc1167163c09034ba2_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1471\u00d7532 98.8 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>My process is as follows:</p>\n<p><strong>Create a train function</strong></p>\n<pre><code class=\"lang-auto\">def train_XGBRanker(config_defaults):\n    \n    # \ud83d\udc1d W&amp;B Experiment\n    config_defaults.update(CONFIG)\n    run = wandb.init(project='AI4Code', name='xgbRanker', config=config_defaults)\n    config = wandb.config\n    \n    # Initiate the model\n    model = XGBRanker(tree_method = config.tree_method,\n                      booster=config.booster,\n                      objective=config.objective,\n                      random_state=config.random_state, \n                      learning_rate=config.learning_rate,\n                      colsample_bytree=config.colsample_bytree, \n                      eta=config.eta, \n                      max_depth=config.max_depth, \n                      n_estimators=config.n_estimators, \n                      subsample=config.subsample,\n                      min_child_weight=config.min_child_weight)\n\n    # Train the model\n    model.fit(X_train, y_train, group=groups, verbose=True)\n\n    # Create df containing the cell_id and the prediction\n    predict = pd.DataFrame({\"cell_id\" : df_valid[\"cell_id\"],\n                            \"pred\" : model.predict(X_valid)}, index = df_valid.index)\n\n    # Sort (using the predicted rank) and then group\n    predict = predict.sort_values(by = ['id', 'pred'], ascending = [False, True])\\\n                        .groupby('id')['cell_id'].apply(list)\n\n    # Create the same but for actual data\n    actual = df_valid.sort_values(by = ['id', 'rank'], ascending = [False, True])\\\n                            .groupby('id')['cell_id'].apply(list)\n\n    # Kendall Metric\n    metric = kendall_tau(actual, predict)\n    print(clr.S+\"Kendall Tau\"+clr.E, metric)\n    wandb.log({\"kendall_tau\": np.float(metric)})\n</code></pre>\n<p><strong>try a first baseline experiment</strong></p>\n<pre><code class=\"lang-auto\">config_defaults = {\"tree_method\":'hist',\n                   \"booster\":'gbtree',\n                   \"objective\":'rank:pairwise',\n                   \"random_state\":24, \n                   \"learning_rate\":0.1,\n                   \"colsample_bytree\":0.9, \n                   \"eta\":0.05, \n                   \"max_depth\":6, \n                   \"n_estimators\":110, \n                   \"subsample\":0.75,\n                   \"min_child_weight\":10}\n\ntrain_XGBRanker(config_defaults)\n</code></pre>\n<p>which returns a <code>kendall_tau</code> of 0.5479588742699661 (so the metric isn\u2019t null).</p>\n<p><strong>and then I am running the Sweeps as follows:</strong></p>\n<pre><code class=\"lang-auto\"># Sweep Config\nsweep_config = {\n    \"method\": \"random\", # grid for all\n    \"metric\": {\n      \"name\": \"kendall_tau\",\n      \"goal\": \"maximize\"   \n    },\n    \"parameters\": {\n        \"booster\": {\n            \"values\": [\"gbtree\",\"gblinear\"]\n        },\n        \"max_depth\": {\n            \"values\": [3, 6, 9, 12]\n        },\n        \"learning_rate\": {\n            \"values\": [0.1, 0.05, 0.2]\n        },\n        \"subsample\": {\n            \"values\": [1, 0.5, 0.3]\n        }\n    }\n}\n\n# Sweep ID\nsweep_id = wandb.sweep(sweep_config, project=\"AI4Code\")\n\n# \ud83d\udc1d RUN SWEEPS\nconfig_defaults = {\"tree_method\":'hist',\n                   \"booster\":'gbtree',\n                   \"objective\":'rank:pairwise',\n                   \"random_state\":24, \n                   \"learning_rate\":0.1,\n                   \"colsample_bytree\":0.9, \n                   \"eta\":0.05, \n                   \"max_depth\":6, \n                   \"n_estimators\":110, \n                   \"subsample\":0.75,\n                   \"min_child_weight\":10}\n\n# count = the number of trials to run\nwandb.agent(sweep_id, train_XGBRanker(config_defaults), count=8)\n</code></pre>\n<p>Could you please advise? I don\u2019t know if this is related, but I also can\u2019t run the sweeps for more than a <code>count=5</code> as I get the following error:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/88e725be8086de062b815ebe6c25710b0ba23b89.png\" data-download-href=\"/uploads/short-url/jx6amgBaQRJiD3N6IIcvKyT4sNH.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/88e725be8086de062b815ebe6c25710b0ba23b89.png\" alt=\"image\" data-base62-sha1=\"jx6amgBaQRJiD3N6IIcvKyT4sNH\" width=\"690\" height=\"487\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/88e725be8086de062b815ebe6c25710b0ba23b89_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">922\u00d7652 21.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Thank you lots!<br>\nAndrada</p>\n<p>UPDATE:</p>\n<p>The issue was from the fact that I was having arguments within the <code>train_XGBRanker()</code> - moving <code>config_defaults</code> from outside the function to in the function an then passing it to <code>wandb.agent(sweep_id, train_XGBRanker, count=20)</code> did the job.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-09T19:31:59.719Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/andrada\">@andrada</a> ,</p>\n<p>Thank you for writing in with your question and providing an update. I\u2019m glad you were able to successfully resolve this issue. Please do reach back out again if you run into any other issues.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-08T19:32:48.769Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to early stop bad runs in sweeps to save time",
		"Question_link": "https://community.wandb.ai/t/how-to-early-stop-bad-runs-in-sweeps-to-save-time/2563",
		"Question_created_time": "2022-06-07T06:44:10.764Z",
		"Question_answer_count": 5,
		"Question_score_count": 1,
		"Question_view_count": 628,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hello,<br>\nthat\u2019s my first topic in the community, so I hope I am posting that in the correct category <img src=\"https://emoji.discourse-cdn.com/twitter/wink.png?v=12\" title=\":wink:\" class=\"emoji\" alt=\":wink:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<p>I started exploring sweeps last week for a university project, and it is incredible! As we also got a new PyTorch version with support for the new apple silicon, I wanted to try that on my M1 Pro. As this is not as powerful as, for example, using GoogleColab for a fraction of the time, I wanted to ask if it is somehow possible to stop bad runs after a few epochs.</p>\n<p>As you can see in the report linked below, the run hopeful-sweep-2 does not look promising. It would be nice to cancel that run and start a new one instead.</p>\n<p>Thanks,<br>\nMarkus</p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://wandb.ai/markuskarner/AILS-Challenge%203%20Microscopic%20Images/reports/Sweep-on-some-image-data--VmlldzoyMTI2MDA3?accessToken=9h1rd20e7e6smpxm2cvtm3plk3rrauhkbb39w2rs46fv0htwvf0tx9r4ixjhkolk\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/18b592222b97bc09df3743831bb4929dec23611c.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https://wandb.ai/markuskarner/AILS-Challenge%203%20Microscopic%20Images/reports/Sweep-on-some-image-data--VmlldzoyMTI2MDA3?accessToken=9h1rd20e7e6smpxm2cvtm3plk3rrauhkbb39w2rs46fv0htwvf0tx9r4ixjhkolk\" target=\"_blank\" rel=\"noopener\">W&amp;B</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/cf9e1ba973281ce03a0112b895e3f727d93c3e20_2_500x500.jpeg\" class=\"thumbnail onebox-avatar\" width=\"500\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/cf9e1ba973281ce03a0112b895e3f727d93c3e20_2_500x500.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/cf9e1ba973281ce03a0112b895e3f727d93c3e20_2_750x750.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/cf9e1ba973281ce03a0112b895e3f727d93c3e20.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/cf9e1ba973281ce03a0112b895e3f727d93c3e20_2_10x10.png\">\n\n<h3><a href=\"https://wandb.ai/markuskarner/AILS-Challenge%203%20Microscopic%20Images/reports/Sweep-on-some-image-data--VmlldzoyMTI2MDA3?accessToken=9h1rd20e7e6smpxm2cvtm3plk3rrauhkbb39w2rs46fv0htwvf0tx9r4ixjhkolk\" target=\"_blank\" rel=\"noopener\">Weights &amp; Biases</a></h3>\n\n  <p>Weights &amp; Biases, developer tools for machine learning</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-07T18:41:53.182Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/markuskarner\">@markuskarner</a> ,</p>\n<p>Thank you for writing in with your question. We do support early termination of sweeps, this reference <a href=\"https://docs.wandb.ai/guides/sweeps/configuration#early_terminate\">doc</a> covers this. When the early stopping is triggered, the agent stops the current run and gets the next set of hyperparameters to try. Here is a <a href=\"https://github.com/wandb/examples/blob/master/examples/keras/keras-cnn-fashion/sweep-bayes-hyperband.yaml\" rel=\"noopener nofollow ugc\">link</a> to an example sweep configuration for reference. If after setting up your configuration and your require review / feedback. Please do write back in this thread and we can review your work more closely.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-06-08T05:11:46.045Z",
				"Answer_body": "<p>Thanks a lot <img src=\"https://emoji.discourse-cdn.com/twitter/smiley.png?v=12\" title=\":smiley:\" class=\"emoji\" alt=\":smiley:\" loading=\"lazy\" width=\"20\" height=\"20\"><br>\nThat was exactly what I was looking for, just searched for early stopping and not terminating and somehow didn\u2019t find it <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<p>Is there also a way to change the configuration of a running sweep? Or stop it and continue it with a new configuration?</p>\n<p>Thanks &amp; Regards,<br>\nMarkus</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-08T19:54:18.740Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/markuskarner\">@markuskarner</a>,</p>\n<p>You\u2019re welcome, glad that helped.</p>\n<p>Currently we do not allow the modification of a running sweep. A sweep is inherently tied to its config, so once it is set there is no way to change it. You can however, create a new sweep and seed it with existing runs, see <a href=\"https://docs.wandb.ai/guides/sweeps/existing-project#seed-a-new-sweep-with-existing-runs\">here</a>. Hope this helps.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-09T08:13:38.558Z",
				"Answer_body": "<p>Thanks for your kind reply <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-08T08:14:38.630Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to visualize model graph in weights and biases",
		"Question_link": "https://community.wandb.ai/t/how-to-visualize-model-graph-in-weights-and-biases/2547",
		"Question_created_time": "2022-06-03T12:47:19.117Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 578,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I have been trying to find an example on how to write a model graph in weights and biases just like we can do in Tensorboard using  writer.add_graph() similar to as given <a href=\"https://www.tensorflow.org/tensorboard/graphs\" rel=\"noopener nofollow ugc\">here</a>.<br>\nI am working with Pytorch lightning.</p>\n<p>If someone can please refer me to a correct documentation or an example.</p>\n<p>Thanks in advance.<br>\nNikhil</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-06T09:48:27.391Z",
				"Answer_body": "<p>Hey Nikhil, if you have uploaded the .h5 file, you can click on the name of the file in the Files section of the run and that will open up Netron<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/c346c90e84039cd4af80a7c6d573d216d68ecfa6.png\" data-download-href=\"/uploads/short-url/rRuLlHsIp6X8QYlXRfaHBrd0UDA.png?dl=1\" title=\"Screen Shot 2022-06-06 at 13.47.34\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/c346c90e84039cd4af80a7c6d573d216d68ecfa6_2_332x500.png\" alt=\"Screen Shot 2022-06-06 at 13.47.34\" data-base62-sha1=\"rRuLlHsIp6X8QYlXRfaHBrd0UDA\" width=\"332\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/c346c90e84039cd4af80a7c6d573d216d68ecfa6_2_332x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/c346c90e84039cd4af80a7c6d573d216d68ecfa6_2_498x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/c346c90e84039cd4af80a7c6d573d216d68ecfa6.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/c346c90e84039cd4af80a7c6d573d216d68ecfa6_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-06-06 at 13.47.34</span><span class=\"informations\">568\u00d7854 35.4 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9bdcd7ac919d96e2357b44ae6158acceea6ae99b.png\" data-download-href=\"/uploads/short-url/meP9XTRFvAG04crBuAwtnFrUtxp.png?dl=1\" title=\"Screen Shot 2022-06-06 at 13.48.08\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9bdcd7ac919d96e2357b44ae6158acceea6ae99b_2_324x500.png\" alt=\"Screen Shot 2022-06-06 at 13.48.08\" data-base62-sha1=\"meP9XTRFvAG04crBuAwtnFrUtxp\" width=\"324\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9bdcd7ac919d96e2357b44ae6158acceea6ae99b_2_324x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9bdcd7ac919d96e2357b44ae6158acceea6ae99b_2_486x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9bdcd7ac919d96e2357b44ae6158acceea6ae99b.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9bdcd7ac919d96e2357b44ae6158acceea6ae99b_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-06-06 at 13.48.08</span><span class=\"informations\">608\u00d7936 34.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-09T07:04:38.613Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/nikhilsalodkar\">@nikhilsalodkar</a>, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-08T07:04:44.671Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Summarize Complex Configuration Dictionaries",
		"Question_link": "https://community.wandb.ai/t/summarize-complex-configuration-dictionaries/2481",
		"Question_created_time": "2022-05-23T07:33:54.729Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 184,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,<br>\nIs there a way I can access the nested dictionaries in the <code>run.config</code> object for custom panels, weaves and reports. Apart from sweeps, I am manipulating a variable space and logging them as an array to the config as below:</p>\n<pre><code class=\"lang-python\">wandb.config.update({'observation/experiment': AN_ARRAY })\n</code></pre>\n<p>I would like to access and visualize/summarize this variable in text or weave form. However when I call <code>run.config</code> in a weave, this variable doesn\u2019t show up even though I can see it in the run overview.<br>\nThank you for your support!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-24T17:31:48.155Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/gsaltintas\">@gsaltintas</a> ,</p>\n<p>Thank you for writing in. Can you please provide me a link to your workspace as a reference and also list the specific panel you are attempting to perform this action.  Thank you</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-31T16:35:32.188Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/gsaltintas\">@gsaltintas</a> ,</p>\n<p>As we have not heard back from you regarding this request on weaves. I will be closing out this support request. Please do reach back out again if you have any questions or require additional support.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-09T00:14:45.758Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a>,</p>\n<p>Sorry for my late reply and thank you for your response. I replicated the issue in this <a href=\"https://wandb.ai/gsaltintas/config/runs/242bu9vj?workspace=user-gsaltintas\">project</a>. I would like to access <code>config.observation.experiment</code>, which is a dict  of the form <code>{'observation/experiment': {'A': True, 'B': False}}</code> but as you see in the sample panel I am unable to get a meaningful summary.</p>\n<p>Thanks<br>\nG\u00fcl Sena</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-08T00:14:52.432Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Visual Bug in Documentation",
		"Question_link": "https://community.wandb.ai/t/visual-bug-in-documentation/2572",
		"Question_created_time": "2022-06-08T07:12:19.920Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 176,
		"Question_has_accepted_answer": false,
		"Question_body": "<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/fd0f258d7049524defde72d94701022480abd440.png\" data-download-href=\"/uploads/short-url/A6FfBmGoIRNds6FR4YCdptOz7Fe.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/fd0f258d7049524defde72d94701022480abd440_2_690x264.png\" alt=\"image\" data-base62-sha1=\"A6FfBmGoIRNds6FR4YCdptOz7Fe\" width=\"690\" height=\"264\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/fd0f258d7049524defde72d94701022480abd440_2_690x264.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/fd0f258d7049524defde72d94701022480abd440_2_1035x396.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/fd0f258d7049524defde72d94701022480abd440_2_1380x528.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/fd0f258d7049524defde72d94701022480abd440_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">2560\u00d7981 120 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>I think there is a missing ``` to finish the code block</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-08T09:08:22.120Z",
				"Answer_body": "<p>Hey Aryan, thank you for flagging this. I\u2019ll update the docs to fix this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-07T07:12:39.513Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to compute FID score for different checkpoints",
		"Question_link": "https://community.wandb.ai/t/how-to-compute-fid-score-for-different-checkpoints/2506",
		"Question_created_time": "2022-05-29T05:01:02.853Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 185,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have a hyper spectral image of 170 bands.  I have used auto-encoder to reconstruct the image. Now I want to plot the FID score for 100 epochs like we can do for MSE plot.</p>\n<p>like we do for MSE polt:</p>\n<p>model.compile(optimizer=\u2018adam\u2019, loss=\u2018mean_absolute_error\u2019, metrics=[\u2018accuracy\u2019])</p>\n<p>history = model.fit(img, img,<br>\nepochs=100, batch_size=1, verbose=1,<br>\nvalidation_split=0.33, shuffle=True)</p>\n<h1>\n<a name=\"list-all-data-in-history-1\" class=\"anchor\" href=\"#list-all-data-in-history-1\"></a>list all data in history</h1>\n<p>print(history.history.keys())</p>\n<h1>\n<a name=\"summarize-history-for-accuracy-2\" class=\"anchor\" href=\"#summarize-history-for-accuracy-2\"></a>summarize history for accuracy</h1>\n<p>plt.plot(history.history[\u2018accuracy\u2019])<br>\nplt.plot(history.history[\u2018val_accuracy\u2019])<br>\nplt.title(\u2018model accuracy\u2019)<br>\nplt.ylabel(\u2018accuracy\u2019)<br>\nplt.xlabel(\u2018epoch\u2019)<br>\nplt.legend([\u2018train\u2019, \u2018test\u2019], loc=\u2018upper left\u2019)<br>\nplt.show()</p>\n<p>Is there a simple way to do that? If so can anyone assist me with a demo code is possible\u2026</p>\n<p>Thanks in advance\u2026</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-01T22:36:10.408Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/shuvro\">@shuvro</a> ,</p>\n<p>I\u2019d be glad to look into this for you. Although I can\u2019t give provide specific examples I will provide online references on FID scores and plotting.</p>\n<ul>\n<li>In terms of how to setup an FID evaluation pipeline, please check out this wandb<a href=\"https://wandb.ai/ayush-thakur/gan-evaluation/reports/How-to-Evaluate-GANs-using-Frechet-Inception-Distance-FID---Vmlldzo0MTAxOTI\">report</a> for potential tips</li>\n<li>In regards to plotting FID scores, I found this <a href=\"https://colab.research.google.com/github/pytorch-ignite/pytorch-ignite.ai/blob/gh-pages/blog/2021-08-11-GAN-evaluation-using-FID-and-IS.ipynb#scrollTo=z4LdevwP7XC5\" rel=\"noopener nofollow ugc\">colab</a> reference online that may include examples of what you are looking for.</li>\n</ul>\n<p>If after you are successful in producing your plots and require assistance when logging them using wandb, please do reach out again.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-07T17:06:34.612Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/shuvro\">@shuvro</a> ,</p>\n<p>Since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-06T17:06:57.384Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Problem loading code",
		"Question_link": "https://community.wandb.ai/t/problem-loading-code/2470",
		"Question_created_time": "2022-05-21T05:46:18.658Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 404,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I\u2019m new to W&amp;B and already liked it a lot. But found some unexpected behavior: I want to compare two .py files when receiving the error in my Dashboard panel:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9ac14983e976292bdc26420fa959598cb2e12855.png\" data-download-href=\"/uploads/short-url/m51E4n99eRFPkiAvGeuLOAGTLWB.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9ac14983e976292bdc26420fa959598cb2e12855_2_690x258.png\" alt=\"image\" data-base62-sha1=\"m51E4n99eRFPkiAvGeuLOAGTLWB\" width=\"690\" height=\"258\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9ac14983e976292bdc26420fa959598cb2e12855_2_690x258.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9ac14983e976292bdc26420fa959598cb2e12855.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9ac14983e976292bdc26420fa959598cb2e12855.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9ac14983e976292bdc26420fa959598cb2e12855_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">940\u00d7352 11.6 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-23T20:35:05.399Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/vitaliykoren\">@vitaliykoren</a> ,</p>\n<p>I\u2019ll be glad to look into this for you. Can you please provide me with a link to your workspace, and a code example of how you logging your  results. Lastly, can you please expand on what you meant by comparing <code>two .py</code> files (are you using two python scripts to log to the same project?)</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-25T15:15:51.357Z",
				"Answer_body": "<p>Thanks for the reply <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> )</p>\n<ul>\n<li>About the link to the workspace - do you mean the link for the project?</li>\n<li>How I log files:<br>\n<code>wandb.run.log_code(root=config_root, include_fn=lambda file_path: file_path.endswith(self.config_path))</code>\n</li>\n<li>Explanation of the code snippet + answer to your last question: To set up run I use the config file (but instead of having some <code>.yaml</code> or <code>.json</code> as the common configuration file extensions, I use <code>.py</code> files with defined entities I gonna use for the run), so the <code>config_root</code> variable is the path of the folder containing this config file, while <code>self.config_path</code> is the name of it. So, I would like to have the ability to compare such files.</li>\n</ul>\n<p>Vitaliy</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-01T00:49:07.268Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/vitaliykoren\">@vitaliykoren</a> ,</p>\n<p>Yes please, I would need a reference to your workspace to look at the specific compare panel  that isn\u2019t loading. We did have a similar issue with a previous version of the client. Please update to the latest version of wandb if you haven\u2019t already done so. Once I receive the workspace link, I will investigate and provide an answer this week.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-01T09:29:37.798Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"mohammadbakir\" data-post=\"4\" data-topic=\"2470\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/m/a9a28c/40.png\" class=\"avatar\"> mohammadbakir:</div>\n<blockquote>\n<p>I would need a reference to your workspace to look</p>\n</blockquote>\n</aside>\n<p>Oh, got it. Sorry, I wouldn\u2019t like to make my project public, and wonder will you have access to it if it\u2019s private?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-01T19:41:45.882Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/vitaliykoren\">@vitaliykoren</a> ,</p>\n<p>Yes I can access your private workspace on the cloud.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-06T18:52:12.467Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/vitaliykoren\">@vitaliykoren</a> ,</p>\n<p>Since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-05T18:53:04.402Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How do I logout of my account?",
		"Question_link": "https://community.wandb.ai/t/how-do-i-logout-of-my-account/2531",
		"Question_created_time": "2022-06-01T21:44:26.279Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 260,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>There\u2019s a <code>wandb login</code> command, but I couldn\u2019t find any way to log out.  How does one logout?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-02T07:08:00.136Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/gcx\">@gcx</a>, at the moment we don\u2019t have a specific command for that. But if you remove the line that contains your api key in the .netrc file in your home directory, it will effectively log you out.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-06T04:02:11.854Z",
				"Answer_body": "<p>Hey there, I wanted to follow up on this. Please let me know if you have any further questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-06T14:03:56.608Z",
				"Answer_body": "<p>No further questions. Thanks for the response!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-05T14:04:21.441Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to sync name on wandb web with images saved on the disk",
		"Question_link": "https://community.wandb.ai/t/how-to-sync-name-on-wandb-web-with-images-saved-on-the-disk/2392",
		"Question_created_time": "2022-05-10T09:55:58.669Z",
		"Question_answer_count": 12,
		"Question_score_count": 0,
		"Question_view_count": 383,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I use pytotch-lightning and wandb. After using wandblogger, the image with a name like \u2018bird 1\u2019 on the web shows correct. But the image saved  on disk with a name like \u2018test_image_21_0\u2019, which is quite different from my name \u2018bird 1\u2019. This also happens in other frameworks.<br>\nWhat should I do to keep the name of images shown on the web the same as the image names saved on the disk?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-11T21:59:58.907Z",
				"Answer_body": "<p>Hi LAngelo,</p>\n<p>I\u2019m happy to help you with this. At this time we maintain unique image file names for runs on disk (Projects \u2192  \u2192 Runs \u2192  \u2192 Files) vs what is displayed in the media panels on the wandb web interface. Could you please help me understand your use case as to why you want the image name displayed and image file name to match?</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-13T09:22:27.078Z",
				"Answer_body": "<p>My jobs is related to super resolution. Sometimes web is not efficient to display big image. When I wanted to go back to the original image , I got big trouble.  As you know, I can download some images, but I can\u2019t download them one by one. So  I really need the image name displayed matches to image file name.  I wonder where is the file recording the match information between them.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-13T17:43:43.782Z",
				"Answer_body": "<p>Hi LAngelo,</p>\n<p>I understand why working with large sized files could be frustrating when attempting to load them in the workspace, we are aware of slow load times on some large file sizes. Can you please provide me a link to your workspace, I\u2019d like to get a better understanding of what you are experiencing/viewing.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-16T17:08:12.936Z",
				"Answer_body": "<p>Hi LAngelo,</p>\n<p>I am following up on your ticket from last week regarding our media panel file naming conventions. Please let me know if you require further assistance.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-17T01:55:50.337Z",
				"Answer_body": "<p>Thank you for your kindness. Unfortunately  I can\u2019t provide my workspace. But I can tell you the problem in greater detail.<br>\nTake this image as an example:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/238df9d36f8ef0b96d555d8688643d9f5d237ad9.png\" data-download-href=\"/uploads/short-url/54wToc7dbeEz6yryt2jYp4uIT7b.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/238df9d36f8ef0b96d555d8688643d9f5d237ad9_2_690x364.png\" alt=\"image\" data-base62-sha1=\"54wToc7dbeEz6yryt2jYp4uIT7b\" width=\"690\" height=\"364\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/238df9d36f8ef0b96d555d8688643d9f5d237ad9_2_690x364.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/238df9d36f8ef0b96d555d8688643d9f5d237ad9.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/238df9d36f8ef0b96d555d8688643d9f5d237ad9.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/238df9d36f8ef0b96d555d8688643d9f5d237ad9_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">856\u00d7452 78.3 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>I need to generate texture on this clothes.</p>\n<p>Without matching names, my workflow is: select next step. Zoom image. Close Image. Select next step.  Zoom image. Close Image.Until find the step I need.  Write down the step information.</p>\n<p>With matching names, my workflow will be: open image. Zoom image. Press left arrow . Press left arrow .  Until find the step I need. But the name has no information related to step.</p>\n<p>Obviously the second solution is more convenient. In reality, I only need to press one key rather than switch from window to window.</p>\n<p>I wonder if you have a better idea to improve my workflow. Or if I can find a file in wandb to transform the label on desk to a easy-to-read label.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-19T20:02:10.600Z",
				"Answer_body": "<p>Hi LAngelo,</p>\n<p>I appreciate the follow-up with your use case. I do have two pointers that could assist with you with your workflow. If you are using <code>wandb.data_types.Image</code> (see here) to format the images when logging them to W&amp;B, setting the <code>data_or_path\u00a0</code> to your image on disk will log the image with the name on disk, example, <code>\"../images/test_run/TexturedShirt.png\"</code> will get logged with W&amp;B as <code>TexturedShirt.png</code>. One other tip that could assist is adding a caption to your image using the <code>caption</code> variable.</p>\n<p>If you are using integrations such as Keras, the process will continue to be automated and there isn\u2019t a method now to change the logged image names, yet we are working on adding more functionality to our logged media.</p>\n<p>Hope this helps, please let me know if you have additional questions.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-20T01:57:12.374Z",
				"Answer_body": "<p>I have already used the caption variable. The name in the chart-media-image has already changed. I find the image name saved in files-media-images is different from the name shown in chart-media-image. So I think there should be a file record the relationship between them . Where it is? Or the image shown on the board is not based on the image save in files-media-images.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/bb7ecb30f0e0c538db5ac6157c91546487146f3b.png\" data-download-href=\"/uploads/short-url/qKEWmbOlJtODeIrInl5tyAIqw9t.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/bb7ecb30f0e0c538db5ac6157c91546487146f3b_2_376x500.png\" alt=\"image\" data-base62-sha1=\"qKEWmbOlJtODeIrInl5tyAIqw9t\" width=\"376\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/bb7ecb30f0e0c538db5ac6157c91546487146f3b_2_376x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/bb7ecb30f0e0c538db5ac6157c91546487146f3b.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/bb7ecb30f0e0c538db5ac6157c91546487146f3b.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/bb7ecb30f0e0c538db5ac6157c91546487146f3b_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">430\u00d7571 26.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/95bbb0a6e656ad65e4ed92757a2a99c243b49a94.png\" data-download-href=\"/uploads/short-url/lmBgyZsI42hK4g56Rp76QYKOr9G.png?dl=1\" title=\"FireShot Capture 052 - balmy-dust-51 - deepfillv2_512x512_dv5_0pv8_2 \u2013 Weights &amp;amp; Biases_ - 192.168.23.40\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/95bbb0a6e656ad65e4ed92757a2a99c243b49a94_2_690x135.png\" alt=\"FireShot Capture 052 - balmy-dust-51 - deepfillv2_512x512_dv5_0pv8_2 \u2013 Weights &amp; Biases_ - 192.168.23.40\" data-base62-sha1=\"lmBgyZsI42hK4g56Rp76QYKOr9G\" width=\"690\" height=\"135\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/95bbb0a6e656ad65e4ed92757a2a99c243b49a94_2_690x135.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/95bbb0a6e656ad65e4ed92757a2a99c243b49a94_2_1035x202.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/95bbb0a6e656ad65e4ed92757a2a99c243b49a94_2_1380x270.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/95bbb0a6e656ad65e4ed92757a2a99c243b49a94_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">FireShot Capture 052 - balmy-dust-51 - deepfillv2_512x512_dv5_0pv8_2 \u2013 Weights &amp;amp; Biases_ - 192.168.23.40</span><span class=\"informations\">1778\u00d7350 56.3 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-23T21:47:39.206Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/langelo\">@langelo</a> ,</p>\n<p>To attempt to reproduce your work I would need to see the see the code you used to log the images. From the second image presented above, the media panel represents an image logged with <code>wandb.log({\"val_image\": [wandb.Image(&lt;image path&gt;, caption=\"val_BGMG....\")]</code>. The text appearing on the medial panel is user set. For example if log the same image twice:</p>\n<pre><code class=\"lang-auto\"># Log the image\nim = plt.imread(path_to_img)\nwandb.log({\"Cafe_Image_1\": [wandb.Image(im, caption=\"Cafe1\")],\n          \"Cafe_Image_2\": [wandb.Image(im, caption=\"Cafe2\")]})\nwandb.finish()\n</code></pre>\n<p>The logged media is \u201cCafe_Image_1\u201d and \u201cCafe_Image_2\u201d with the assigned captions. The files appear in the projects files/media/images as</p>\n<p>\u201cCafe_Image_1 <em>\u2026\" and \"Cafe_Image_2</em>\u2026\u201d with a series of random value (that cannot be modified)  appended to the file name.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/46728b9ee6d9c9fe419a96425d77296d1b4c4a90.jpeg\" data-download-href=\"/uploads/short-url/a3cPMUyKJirsbntiqAJvduGz8c0.jpeg?dl=1\" title=\"Compare\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/46728b9ee6d9c9fe419a96425d77296d1b4c4a90_2_690x418.jpeg\" alt=\"Compare\" data-base62-sha1=\"a3cPMUyKJirsbntiqAJvduGz8c0\" width=\"690\" height=\"418\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/46728b9ee6d9c9fe419a96425d77296d1b4c4a90_2_690x418.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/46728b9ee6d9c9fe419a96425d77296d1b4c4a90.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/46728b9ee6d9c9fe419a96425d77296d1b4c4a90.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/46728b9ee6d9c9fe419a96425d77296d1b4c4a90_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Compare</span><span class=\"informations\">863\u00d7523 77.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-27T00:13:03.073Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/langelo\">@langelo</a></p>\n<p>I wanted to follow up with you regarding  this request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-02T19:22:06.885Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/langelo\">@langelo</a>,</p>\n<p>Since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-06T04:48:22.977Z",
				"Answer_body": "<p>Do you mean I should write image name in keys position? Here is my code:</p>\n<pre><code class=\"lang-auto\">for i in range(5):\n  wandb.log({'pred':[wandb.Image(img,caption=f'cafe{i}'),wandb.Image(img,caption='cafe2')]})\n  wandb.log({'eval':[wandb.Image(img,caption=f'cafe{i}')]})\n</code></pre>\n<p>This runs well. But creates  random names in media file.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/c0afa7fd15790476a6e50fffe09b0379a2e9af7a.png\" data-download-href=\"/uploads/short-url/ruA0ZxPymGVdj4Ss35ZvtdvSwLU.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/c0afa7fd15790476a6e50fffe09b0379a2e9af7a_2_690x263.png\" alt=\"image\" data-base62-sha1=\"ruA0ZxPymGVdj4Ss35ZvtdvSwLU\" width=\"690\" height=\"263\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/c0afa7fd15790476a6e50fffe09b0379a2e9af7a_2_690x263.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/c0afa7fd15790476a6e50fffe09b0379a2e9af7a_2_1035x394.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/c0afa7fd15790476a6e50fffe09b0379a2e9af7a_2_1380x526.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/c0afa7fd15790476a6e50fffe09b0379a2e9af7a_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1540\u00d7588 63.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d3236a317936fae44011c401057902b75e73e299.png\" data-download-href=\"/uploads/short-url/u7OCzApxQp2sB3Z06JNSr57FcWl.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d3236a317936fae44011c401057902b75e73e299_2_218x500.png\" alt=\"image\" data-base62-sha1=\"u7OCzApxQp2sB3Z06JNSr57FcWl\" width=\"218\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d3236a317936fae44011c401057902b75e73e299_2_218x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d3236a317936fae44011c401057902b75e73e299.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d3236a317936fae44011c401057902b75e73e299.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d3236a317936fae44011c401057902b75e73e299_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">315\u00d7720 47.7 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<pre><code class=\"lang-auto\">for i in range(5):\n  wandb.log({f'pred{i}':[wandb.Image(img,caption=f'cafe{i}'),wandb.Image(img,caption='cafe2')]})\n  wandb.log({'eval':[wandb.Image(img,caption=f'cafe{i}')]})\n</code></pre>\n<p>This displays incorrectly.(The fist slider is lost.) But names in order.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/63a992dc76104302687c14f30f0388e051484a38.png\" data-download-href=\"/uploads/short-url/edEzVBfsvHWlxCZ3pOpllIZuZK0.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/63a992dc76104302687c14f30f0388e051484a38_2_690x277.png\" alt=\"image\" data-base62-sha1=\"edEzVBfsvHWlxCZ3pOpllIZuZK0\" width=\"690\" height=\"277\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/63a992dc76104302687c14f30f0388e051484a38_2_690x277.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/63a992dc76104302687c14f30f0388e051484a38_2_1035x415.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/63a992dc76104302687c14f30f0388e051484a38_2_1380x554.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/63a992dc76104302687c14f30f0388e051484a38_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1588\u00d7638 87.6 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/5cd17bd5c523f26cd3823f3ac680904d5f198148.png\" alt=\"image\" data-base62-sha1=\"df6K8kSqvAaN4EYsyInTQFK0ejS\" width=\"373\" height=\"244\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-05T04:48:24.424Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Hide projects on googling",
		"Question_link": "https://community.wandb.ai/t/hide-projects-on-googling/2388",
		"Question_created_time": "2022-05-10T08:11:18.096Z",
		"Question_answer_count": 10,
		"Question_score_count": 0,
		"Question_view_count": 244,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I\u2019m a user of wandb.<br>\nI\u2019m in several projects now, but others can search some of them on google despite I already locked them.<br>\nHow to prevent it to come out?</p>\n<p>Sincerely</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-11T08:40:26.262Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/wooshik-m\">@wooshik-m</a>, they shouldn\u2019t be able to access the projects. Can you share what you are seeing when searching in google?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-12T03:36:01.643Z",
				"Answer_body": "<p>Thank you for your reply.</p>\n<p>I checked others cannot access the project but it still is exposed simply on the web as below.<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9c408106b216bb1d54921a9b82562de4e1629da9.png\" alt=\"image\" data-base62-sha1=\"migGrz8ukVJogJ8HmfYHFxBKrbj\" width=\"649\" height=\"133\"></p>\n<p>Can I hide this?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-12T15:40:23.105Z",
				"Answer_body": "<p>Hi,<br>\nThis should disappear in an hour or two. It sometimes happens when googles crawler gets to it while the project is public, and takes a little time to remove it when it\u2019s become private.<br>\nWe made a removal request so that should expedite the process.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-13T07:11:49.352Z",
				"Answer_body": "<p>I tried today again, but it still can be searched\u2026</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/a6c48a57595ef909574aa768df472f87738f8048.png\" data-download-href=\"/uploads/short-url/nNilrPszcOGYxWQutS8qJAL9RkQ.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a6c48a57595ef909574aa768df472f87738f8048_2_690x159.png\" alt=\"image\" data-base62-sha1=\"nNilrPszcOGYxWQutS8qJAL9RkQ\" width=\"690\" height=\"159\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a6c48a57595ef909574aa768df472f87738f8048_2_690x159.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a6c48a57595ef909574aa768df472f87738f8048_2_1035x238.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/a6c48a57595ef909574aa768df472f87738f8048.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a6c48a57595ef909574aa768df472f87738f8048_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1362\u00d7314 40.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-17T18:32:24.248Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/wooshik-m\">@wooshik-m</a>, sorry about all the back and forth. Could you check again? It takes a while to update.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-18T00:37:50.597Z",
				"Answer_body": "<p>I still can search our project  on guest.<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/948ac6be412703c5fd120a891f7ac6dfcc65d8b3.png\" alt=\"image\" data-base62-sha1=\"lc3ZxpZy7WvCYnO7vmAQDVUtUUb\" width=\"659\" height=\"258\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-19T19:16:08.612Z",
				"Answer_body": "<p>Thanks, I am checking on this. Sorry about all the back and forth.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-02T13:38:59.858Z",
				"Answer_body": "<p>Hey there, we have made some updates on our end. Can you please double-check?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-06T03:50:43.528Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/wooshik-m\">@wooshik-m</a>,\u200b I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>\u200b</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-05T03:51:20.487Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to delete files like images and tables logged in the Files section",
		"Question_link": "https://community.wandb.ai/t/how-to-delete-files-like-images-and-tables-logged-in-the-files-section/2552",
		"Question_created_time": "2022-06-04T15:34:19.657Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 376,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey all,<br>\nHope everyone is doing well.<br>\nI was wondering if it\u2019s possible to delete files saved in the Files section of a run. It seems that the only option available is to download them locally.<br>\nI\u2019ve already checked out the docs and other posts here in the forum, but the few things I found referred specifically to artifacts like model checkpoints, whereas I\u2019m looking for a way to remove unwanted media files like images, tables and so on.</p>\n<p>Thanks in advance for your help!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-08-03T15:34:55.434Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "After 429 encountered (Filestream rate limit exceeded, it takes three days since I click stopping",
		"Question_link": "https://community.wandb.ai/t/after-429-encountered-filestream-rate-limit-exceeded-it-takes-three-days-since-i-click-stopping/2534",
		"Question_created_time": "2022-06-02T01:42:46.004Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 513,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello!</p>\n<p>The same code runs successfully and in a normal speed before, but last week, I have met the problem like: wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.441980818670473 seconds), retrying request.  After that, it runs extremely slower than before. Some runs does not report this issue in the logs runs much slower too(running the same code) .</p>\n<p>I tried to use \u2018wandb init\u2019 , start a new project, kill the processes and only keep &lt;10 runs running\u2026 but it does not solve this problem.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/40d3b3d032c52de4a182712ae8d41119c90f1090.jpeg\" data-download-href=\"/uploads/short-url/9fu7XzbPdtOV1epkLvmcIVx1CcE.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/40d3b3d032c52de4a182712ae8d41119c90f1090_2_150x499.jpeg\" alt=\"image\" data-base62-sha1=\"9fu7XzbPdtOV1epkLvmcIVx1CcE\" width=\"150\" height=\"499\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/40d3b3d032c52de4a182712ae8d41119c90f1090_2_150x499.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/40d3b3d032c52de4a182712ae8d41119c90f1090_2_225x748.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/40d3b3d032c52de4a182712ae8d41119c90f1090_2_300x998.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/40d3b3d032c52de4a182712ae8d41119c90f1090_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1822\u00d76042 2.05 MB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Meanwhile, some runs take&gt;3days to stop. It is stopping currently.</p>\n<p>Could you help me, please? Thank you very much~!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-02T01:43:52.398Z",
				"Answer_body": "<p>The run which use 3days to stop: <a href=\"https://wandb.ai/hdomoto/resromi/runs/1ugw820c/overview?workspace=user-hdomoto\" class=\"inline-onebox\">Weights &amp; Biases</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-03T18:38:30.047Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hdomoto\">@hdomoto</a> ,</p>\n<p>Thank you for writing in. This error is attributed to our imposed rate limits on user. I have gone ahead and increased your rate limit for you. If you still face issues logging your data, you might want to consider a <a href=\"https://docs.wandb.ai/guides/self-hosted\">self hosted</a> solution, where we do not impose any sort of rate limits. Please do let us know if you require further assistance.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-02T18:39:00.482Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb: ERROR Error while calling W&B API: (<Response [500]>)",
		"Question_link": "https://community.wandb.ai/t/wandb-error-error-while-calling-w-b-api-response-500/2509",
		"Question_created_time": "2022-05-30T14:51:15.888Z",
		"Question_answer_count": 5,
		"Question_score_count": 1,
		"Question_view_count": 142,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I\u2019ve just started to use <strong>wandb</strong> and I love it.  I use v 0.12.17 and the code below to log from a json file that contains my key, because I don\u2019t want to expose it to the public (I have my script in Github)</p>\n<pre><code class=\"lang-auto\">wandb_path = Path('~/.wandb/wandb.json').expanduser()\nwith open(wandb_path) as fp:\n    mykey = json.load(fp)['key']\nwandb.login(key = mykey)\n</code></pre>\n<p>I\u2019m able to login, but after a few seconds, I get the following error message:</p>\n<blockquote>\n<p>wandb: ERROR Error while calling W&amp;B API: json: cannot unmarshal array into Go value of type map[string]interface {} (&lt;Response [500]&gt;)</p>\n</blockquote>\n<p>Any ideas on how to solve it?</p>\n<p>Thanks</p>\n<p>Jose</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-31T08:07:01.309Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/jguzman\">@jguzman</a>, can you try setting the <a href=\"https://docs.wandb.ai/guides/track/advanced/environment-variables#optional-environment-variables\">WANDB_API_KEY</a> environment variable. That way you won\u2019t need to call the wandb.login() function.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-03T03:33:05.616Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/jguzman\">@jguzman</a> I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>\u200b</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-03T04:10:58.911Z",
				"Answer_body": "<p>Thank you very much for your assistance. That worked like a charm!!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-03T14:14:29.233Z",
				"Answer_body": "<p>Glad to hear that! Have a great weekend!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-02T04:11:37.484Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Grouping and comparing across two dimensions",
		"Question_link": "https://community.wandb.ai/t/grouping-and-comparing-across-two-dimensions/2525",
		"Question_created_time": "2022-06-01T13:53:31.752Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 90,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have two hyperparameters, lets say p1 with values {A, B,C} and p2 with values {0, 1} and a metric I want to compare. Now I want to  group my runs to visualize how p2 affects the metric for each value of p1 separately. Something like on the image below.<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/6fc197c9a83f96d5196805c315c0edb402521d2d.png\" alt=\"wandb_classes\" data-base62-sha1=\"fWDLKpRDMuRYnyft4eMiPsGXkbH\" width=\"371\" height=\"250\"></p>\n<p>When I group my runs by both p1 and p2 and do a bar plot I lose the information which pairs of bars I want to compare. Is there any way to achieve what I want on a report?<br>\nThe best I could think of is to have separate sets of runs each filtered on A, B, C and then do multiple plots with just the two bars. But I\u2019d much rather have all the information together.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-02T22:07:18.444Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/slawekbiel\">@slawekbiel</a>,</p>\n<p>Thanks for writing in! You should be able to group your runs using p2 {0, 1} and then create a bar chart on p1 to assess how p2 impacts runs metrics. In order to help you better, It would be great if you could share your project page for greater visibility so that I can help you better.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-08T17:20:52.591Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/slawekbiel\">@slawekbiel</a>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-13T22:11:33.154Z",
				"Answer_body": "<p>Hi S\u0142awek, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-01T22:08:16.786Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sweeps while using MPI and SLURM",
		"Question_link": "https://community.wandb.ai/t/sweeps-while-using-mpi-and-slurm/2427",
		"Question_created_time": "2022-05-16T10:04:13.529Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 736,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello! I am attempting to perform a hyperparameter search on my project, which uses MPI under the hood to aggregate the results of multiple agents. I have 63 agents that run an episode, returning a total reward at the end. At the end, each worker node sends their results to the main node, which logs the total reward of every 5th training run.</p>\n<p>I have tried to create a sweep with a custom command to use <code>mpirun</code>(as seen below) and running <code>wandb agent sweepid --count 1</code> in the SLURM script.  This results in using all the cores of the machine to start a sweep, effectively blocking my other agents from training.</p>\n<pre><code class=\"lang-auto\">program: src.sweep_mpi \ncommand:\n  - mpirun\n  - \"--mca\" \n  - opal_warn_on_missing_libcuda\n  - 0\n  - python\n  - \"-m\"\n  - ${program}\n  - ${args}\n</code></pre>\n<p>Next, I have tried setting up the sweeping agent inside the python code with a local controller, but this also led to issues regarding the parallelization. Currently, I need to initialize wandb using <code>settings=wandb.Settings(start_method=\"fork\")</code>, but I cannot find any way to specify this as a sweep parameter. Therefore, each  run crashes since it is not using the correct parallelization procedure.</p>\n<p>Is there anything I can do in this case? Or should I implement my own parameter search?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-18T01:10:23.620Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/vandrew\">@vandrew</a>,</p>\n<p>You are right, the <code>settings</code> parameter can not be initialized through a sweep config, but it should be possible to place this parameter in the call to <code>wandb.init()</code>. Could you share the traceback you get when your run crashes? It will give us greater visibility into your issue and enable us in assisting you further.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-19T11:54:04.180Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a>!</p>\n<p>After a bit more tweaking, I made a secondary script that would intercept the configurations from the API with a local controller. Following this, I saved each configuration in a yaml file, which I then loaded using argparse.</p>\n<p>Nevertheless, the issue regarding the parallelization sometimes persists, but is irregular. It will sometimes crash when using the exact same configuration file, without any changes to my code:</p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"/software/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/software/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/user/project/src/sweep_mpi.py\", line 1, in &lt;module&gt;\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 991, in _find_and_load\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 971, in _find_and_load_unlocked\n  File \"&lt;frozen importlib._bootstrap&gt;\", line 914, in _find_spec\n  File \"&lt;frozen importlib._bootstrap_external&gt;\", line 1342, in find_spec\n  File \"&lt;frozen importlib._bootstrap_external&gt;\", line 1314, in _get_spec\n  File \"&lt;frozen importlib._bootstrap_external&gt;\", line 1443, in find_spec\n  File \"&lt;frozen importlib._bootstrap_external&gt;\", line 1483, in _fill_cache\nBrokenPipeError: [Errno 108] Cannot send after transport endpoint shutdown: '/home/user/project'\n--------------------------------------------------------------------------\nPrimary job  terminated normally, but 1 process returned\na non-zero exit code. Per user-direction, the job has been aborted.\n--------------------------------------------------------------------------\n--------------------------------------------------------------------------\nmpirun detected that one or more processes exited with non-zero status, thus causing\nthe job to be terminated. The first process to do so was:\n\n  Process name: [[19849,1],3]\n  Exit code:    1\n--------------------------------------------------------------------------\n</code></pre>\n<p>This seems to result from a read operation timeout, as indicated by the debug log:</p>\n<pre><code class=\"lang-auto\">2022-05-19 10:23:11,048 ERROR   SenderThread:7114 [retry.py:__call__():126] Retry attempt failed:\nTraceback (most recent call last):\n  File \"/data/user/.envs/osim/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 449, in _make_request\n    six.raise_from(e, None)\n  File \"&lt;string&gt;\", line 3, in raise_from\n  File \"/data/user/.envs/osim/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 444, in _make_request\n    httplib_response = conn.getresponse()\n  File \"/software/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/http/client.py\", line 1347, in getresponse\n    response.begin()\n  File \"/software/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/http/client.py\", line 307, in begin\n    version, status, reason = self._read_status()\n  File \"/software/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/http/client.py\", line 268, in _read_status\n    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n  File \"/software/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/socket.py\", line 669, in readinto\n    return self._sock.recv_into(b)\n  File \"/software/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/ssl.py\", line 1241, in recv_into\n    return self.read(nbytes, buffer)\n  File \"/software/software/Python/3.8.6-GCCcore-10.2.0/lib/python3.8/ssl.py\", line 1099, in read\n    return self._sslobj.read(len, buffer)\nsocket.timeout: The read operation timed out\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/data/user/.envs/osim/lib/python3.8/site-packages/requests/adapters.py\", line 440, in send\n    resp = conn.urlopen(\n  File \"/data/user/.envs/osim/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 785, in urlopen\n    retries = retries.increment(\n  File \"/data/user/.envs/osim/lib/python3.8/site-packages/urllib3/util/retry.py\", line 550, in increment\n    raise six.reraise(type(error), error, _stacktrace)\n  File \"/data/user/.envs/osim/lib/python3.8/site-packages/urllib3/packages/six.py\", line 770, in reraise\n    raise value\n  File \"/data/user/.envs/osim/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 703, in urlopen\n    httplib_response = self._make_request(\n  File \"/data/user/.envs/osim/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 451, in _make_request\n    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n  File \"/data/user/.envs/osim/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 340, in _raise_timeout\n    raise ReadTimeoutError(\nurllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='api.wandb.ai', port=443): Read timed out. (read timeout=10)\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/data/user/.envs/osim/lib/python3.8/site-packages/wandb/sdk/lib/retry.py\", line 102, in __call__\n    result = self._call_fn(*args, **kwargs)\n  File \"/data/user/.envs/osim/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 140, in execute\n    return self.client.execute(*args, **kwargs)\n  File \"/data/user/.envs/osim/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\", line 52, in execute\n    result = self._get_result(document, *args, **kwargs)\n  File \"/data/user/.envs/osim/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\", line 60, in _get_result\n    return self.transport.execute(document, *args, **kwargs)\n  File \"/data/user/.envs/osim/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/transport/requests.py\", line 38, in execute\n    request = requests.post(self.url, **post_args)\n  File \"/data/user/.envs/osim/lib/python3.8/site-packages/requests/api.py\", line 117, in post\n    return request('post', url, data=data, json=json, **kwargs)\n  File \"/data/user/.envs/osim/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n    return session.request(method=method, url=url, **kwargs)\n  File \"/data/user/.envs/osim/lib/python3.8/site-packages/requests/sessions.py\", line 529, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"/data/user/.envs/osim/lib/python3.8/site-packages/requests/sessions.py\", line 645, in send\n    r = adapter.send(request, **kwargs)\n  File \"/data/user/.envs/osim/lib/python3.8/site-packages/requests/adapters.py\", line 532, in send\n    raise ReadTimeout(e, request=request)\nrequests.exceptions.ReadTimeout: HTTPSConnectionPool(host='api.wandb.ai', port=443): Read timed out. (read timeout=10)\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-26T17:16:10.539Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/vandrew\">@vandrew</a>!</p>\n<p>Apologies for the delay here. This error might be happening due to memory pressure  on your computer. Were you able to successfully able to use <code>fork</code> mode for this? Additionally, it would be really helpful to us if you could provide the full <code>debug.log</code> and <code>debug-internal.log</code> associated to the run affected.</p>\n<p>Some more information that could be helpful here:</p>\n<ul>\n<li>What kind of machine are you running this experiment on?</li>\n<li>What SDK version of <code>wandb</code> are you using?</li>\n<li>Is the machine reliably connected to the internet?</li>\n</ul>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-02T17:50:39.484Z",
				"Answer_body": "<p>Hi Andrei,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-02T17:50:40.575Z",
				"Answer_body": "<p>Hello!</p>\n<p>It is indeed an issue on my end, so I think it is safe to say that this issue can be disregarded. I no longer have access to the debug-internal log, but the cluster I was running my code on was heavily under use.</p>\n<ul>\n<li>The system is based on a CentOS 7 distribution</li>\n<li>Version 0.12.16</li>\n<li>Yes, but the processes might take too long to run. I believe this was the cause of the timeouts in the previous case.</li>\n</ul>\n<p>Thank you for the help so far! The way to go seems to be using a local controller in the main thread, which then supplies the received configuration to the other nodes.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-01T17:51:22.531Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Integration for spacy v2",
		"Question_link": "https://community.wandb.ai/t/integration-for-spacy-v2/2536",
		"Question_created_time": "2022-06-02T06:35:54.004Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 122,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Is the way to integrate wandb with spacy v2 documented somewhere?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-02T07:39:40.974Z",
				"Answer_body": "<p>hi <a class=\"mention\" href=\"/u/abs\">@abs</a></p>\n<p>We didn\u2019t have a logger in spaCy until v3 unfortunately.<br>\n<a href=\"https://github.com/explosion/spaCy/pull/5971\">https://github.com/explosion/spaCy/pull/5971</a></p>\n<p>I\u2019m not very familiar with spaCy v2, but if you have access to metrics you could call <code>wandb.log({\u2018your_metric\u2019: metric})</code> and that\u2019ll plot it on W&amp;B.</p>\n<p>Here\u2019s more info on getting started if you need it:<br>\n<a href=\"https://docs.wandb.ai/quickstart\">https://docs.wandb.ai/quickstart</a></p>\n<p>Let me know if you give this a shot and have further issues.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-01T07:39:55.541Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How do I make a generated project sweep work with a jupyter notebook?",
		"Question_link": "https://community.wandb.ai/t/how-do-i-make-a-generated-project-sweep-work-with-a-jupyter-notebook/2472",
		"Question_created_time": "2022-05-21T20:14:55.287Z",
		"Question_answer_count": 5,
		"Question_score_count": 1,
		"Question_view_count": 132,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I really like that in my project  the config was automatically generated. So I would like to use that for running from jupyter notebook. All the examples I have seen are that you make the config file within the jupyter notebook and then also make the sweep in the same cell as your function. Is there anyway to use the auto-generated project config for my jupyter notebook in colab.</p>\n<p>I tried something like this, but it did not work:</p>\n<p>import sweep <span class=\"hashtag\">#trying</span> to import sweep.yaml file</p>\n<p>sweep_id=wandb.sweep(sweep)</p>\n<p>count = 1 # number of runs to execute</p>\n<p>wandb.agent(sweep_id, function=train_model, count=count)</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-22T11:04:53.612Z",
				"Answer_body": "<p>Being able to plug the sweep_id from the projects page to the jupyter notebook would be ideal. Is there a way to do that</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-23T21:30:33.696Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sdeleon\">@sdeleon</a> ,</p>\n<p>I\u2019ll be glad to assist you with this. This <a href=\"https://docs.wandb.ai/guides/sweeps/configuration\">Sweep Configuration</a> document is a great resource how to structure/configure your sweeps, and our <a href=\"https://docs.wandb.ai/guides/sweeps/quickstart#2.-configure-your-sweep\">Sweep Quickstart</a> goes into further details</p>\n<p>YAML files are best for sweeps from the command line and can be created using the following command,  <code>wandb sweep &lt;file name&gt;.yaml</code>. If you intend on importing a confg.yaml file to your jupyter notebook, then first parse the config.yaml to a dictionary, using for example, PyYAML, prior to  use with <code>wandb.sweep()</code></p>\n<pre><code class=\"lang-auto\">pip install pyyaml\nimport yaml\nwith open('config.yaml', 'r') as stream:\n        sweep_config_dic=yaml.safe_load(stream)\n</code></pre>\n<p>Please let me know if you have additional questions.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-26T23:14:01.433Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sdeleon\">@sdeleon</a> ,</p>\n<p>I am following up on your request to setting up sweeps in a Jupyter Notebook environment. Please let me know if you have any questions/comment about my initial response.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-02T00:24:16.683Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sdeleon\">@sdeleon</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-01T00:24:49.871Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Value Error: Instances of wandb.Artifact and wandb.apis.public.Artifact can only be top level keys i",
		"Question_link": "https://community.wandb.ai/t/value-error-instances-of-wandb-artifact-and-wandb-apis-public-artifact-can-only-be-top-level-keys-i/2500",
		"Question_created_time": "2022-05-27T15:35:02.174Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 146,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello, sorry for the bad english. I\u2019m using for a personal project wandb to train Yolov5 in a kaggle environment. Im getting this type of error:</p>\n<p>Traceback (most recent call last):<br>\nFile \u201ctrain.py\u201d, line 643, in<br>\nmain(opt)<br>\nFile \u201ctrain.py\u201d, line 539, in main<br>\ntrain(opt.hyp, opt, device, callbacks)<br>\nFile \u201ctrain.py\u201d, line 95, in train<br>\nloggers = Loggers(save_dir, weights, opt, hyp, LOGGER) # loggers instance<br>\nFile \u201c/content/yolov5/utils/loggers/ <strong>init</strong> .py\u201d, line 73, in <strong>init</strong><br>\nself.wandb = WandbLogger(self.opt, run_id)<br>\nFile \u201c/content/yolov5/utils/loggers/wandb/wandb_utils.py\u201d, line 185, in <strong>init</strong><br>\nallow_val_change=True)<br>\nFile \u201c/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_config.py\u201d, line 181, in update<br>\nsanitized = self._update(d, allow_val_change)<br>\nFile \u201c/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_config.py\u201d, line 175, in _update<br>\nparsed_dict, allow_val_change, ignore_keys=locked_keys<br>\nFile \u201c/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_config.py\u201d, line 227, in _sanitize_dict<br>\nself._raise_value_error_on_nested_artifact(config_dict)<br>\nFile \u201c/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_config.py\u201d, line 266, in _raise_value_error_on_nested_artifact<br>\n\u201cInstances of wandb.Artifact and wandb.apis.public.Artifact\u201d<br>\nValueError: Instances of wandb.Artifact and wandb.apis.public.Artifact can only be top level keys in wandb.config</p>\n<p>Here the debug log:</p>\n<p><a href=\"https://github.com/wandb/client/files/8171769/debug.log\" rel=\"noopener nofollow ugc\">debug.log</a><br>\n<a href=\"https://github.com/wandb/client/files/8171770/debug-internal.log\" rel=\"noopener nofollow ugc\">debug-internal.log</a></p>\n<p>With a dowgrade to version 0.12.10 just work.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-06-01T18:47:25.224Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/claudio9\">@claudio9</a>,</p>\n<p>It appears you had opened an alternative thread regarding this issue in our github client repo under issues, see <a href=\"https://github.com/wandb/client/issues/3319\" rel=\"noopener nofollow ugc\">here</a>. As this is a known bug, and unfortunately we don\u2019t have a fix out yet with our integration for versions 0.12.10+, please continue using wandb client version <code>0.12.10</code>. I will be closing this out, but please do reach back out again if you have additional questions/requests.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-01T19:10:36.217Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/mohammadbakir\">@mohammadbakir</a> , yep it\u2019s how you say. I will continue to use 0.12.10. Thanks for the support and for the effort <img src=\"https://emoji.discourse-cdn.com/twitter/smiley.png?v=12\" title=\":smiley:\" class=\"emoji\" alt=\":smiley:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-31T19:11:26.019Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Accessing logged values in a callback during run",
		"Question_link": "https://community.wandb.ai/t/accessing-logged-values-in-a-callback-during-run/2527",
		"Question_created_time": "2022-06-01T18:26:21.576Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 76,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi-</p>\n<p>I\u2019m trying  to access a logged value during a run (in a callback). When I examine <code>run.summary</code> it does not seem to have any of the values logged by <code>self.log</code> in either <code>train_step()</code> or <code>validation_step()</code>. Is there a correct pattern for accessing logged values during a run.</p>\n<p>My use case is trying to keep track of the minimum of a metric. I already use <code>define_metric</code>, but I want to see the minimum as a plot over <code>step</code> or <code>epoch</code> as opposed to just in the summary. Essentially trying to call <code>torchmetrics.MinMetric</code> in the <code>on_validation_epoch_end()</code> callback - but to update that metric I need to feed it the previously logged value for another metric.</p>\n<p>Thanks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-31T18:27:19.938Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Save_format of shared layers",
		"Question_link": "https://community.wandb.ai/t/save-format-of-shared-layers/2463",
		"Question_created_time": "2022-05-20T10:22:21.698Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 157,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I am running a model which uses the same embedding layer (and variables)  several places in the model. During training, I use the standard WandbCallback() with no additional parameters, however, I get this warning from TensorFlow:</p>\n<blockquote>\n<p>WARNING:tensorflow:Found duplicated <code>Variable</code>s in Model\u2019s <code>weights</code>. This is usually caused by <code>Variable</code>s being shared by Layers in the Model. These <code>Variable</code>s will be treated as separate <code>Variable</code>s when the Model is restored. To avoid this, please save with <code>save_format=\"tf\"</code>.</p>\n</blockquote>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-21T00:32:49.383Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/adrianlangseth\">@adrianlangseth</a> ,</p>\n<p>I\u2019ll be happy to look into this for you. Can you please provide me with the following:</p>\n<ul>\n<li>wandb version you are using</li>\n<li>keras/tensorflow versions</li>\n<li>Code you are running</li>\n</ul>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-21T09:09:23.021Z",
				"Answer_body": "<p>Versions:</p>\n<ul>\n<li>tf.<strong>version</strong>=\u20182.4.1\u2019</li>\n<li>tf.keras.<strong>version</strong>=\u20182.4.0\u2019</li>\n<li>wandb.<strong>version</strong>=\u20180.12.16\u2019</li>\n</ul>\n<p>The code I am running is way to long to post here, but the source of the issue is a \u201cKeras embedding\u201d layer being used multiple times in a layer. The standard save format used by wandb saves the weights of these independently and therefore on loading the model, these will no longer correspond to the same weights, as during further training, the backprop will update these layers independently. So the core issue is that the save_format which comes standard in W&amp;B, is not very functional for models with shared layers, and I cannot find a way to change this or pass some argument to W&amp;B which specifies save_format.</p>\n<p>Thank You,<br>\nAdrian</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-01T00:58:37.755Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/adrianlangseth\">@adrianlangseth</a> ,</p>\n<p>Apologies for the delay on my follow up response.  Currently is configured to work with the latest version of <code>Tensorflow TF 2.X</code> where the default model <code>save_format</code>  is <code>\"tf\"</code>. I agree we should support more customization here and allow the user to set their own format. I\u2019m making a feature request for this internally and will let you know when we make progress on this. In the meantime please let me know if you have additional questions.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-31T00:58:38.750Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "NaN loss causes incorrect X axis time scale",
		"Question_link": "https://community.wandb.ai/t/nan-loss-causes-incorrect-x-axis-time-scale/2410",
		"Question_created_time": "2022-05-12T08:39:53.002Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 104,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>NaN values are displayed with incorrect X axis values when \u201cRelative Time\u201d is selected.</p>\n<p>To reproduce, go to a plot with NaN values and select \u201cRelative Time (Wall)\u201d as unit for the X axis. The NaN values are still displayed by step number and not  by relative time:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/2dda6900e0c1e9986663091725820304b26465c4.png\" data-download-href=\"/uploads/short-url/6xDqwsQGPqpl4IB1TEP2WAgfX9y.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2dda6900e0c1e9986663091725820304b26465c4_2_345x244.png\" alt=\"image\" data-base62-sha1=\"6xDqwsQGPqpl4IB1TEP2WAgfX9y\" width=\"345\" height=\"244\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2dda6900e0c1e9986663091725820304b26465c4_2_345x244.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2dda6900e0c1e9986663091725820304b26465c4_2_517x366.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2dda6900e0c1e9986663091725820304b26465c4_2_690x488.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2dda6900e0c1e9986663091725820304b26465c4_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">888\u00d7630 14.4 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nThe screenshot is from a run that was only running for 160 minutes.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-12T09:34:30.538Z",
				"Answer_body": "<p>Hey there, thanks for flagging this. I\u2019ll try to reproduce this and file a ticket.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-26T10:18:25.304Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/cifkao\">@cifkao</a>, could you share the link to the chart? I am getting a different result when trying to reproduce this.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/1f653e9709a0aa8ca074f55dd26aa13a9a685d79.jpeg\" data-download-href=\"/uploads/short-url/4tJIrNeLOmx1CHcNO0FZsnW4sZz.jpeg?dl=1\" title=\"Screen Shot 2022-05-26 at 14.17.30\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1f653e9709a0aa8ca074f55dd26aa13a9a685d79_2_690x284.jpeg\" alt=\"Screen Shot 2022-05-26 at 14.17.30\" data-base62-sha1=\"4tJIrNeLOmx1CHcNO0FZsnW4sZz\" width=\"690\" height=\"284\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1f653e9709a0aa8ca074f55dd26aa13a9a685d79_2_690x284.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1f653e9709a0aa8ca074f55dd26aa13a9a685d79_2_1035x426.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1f653e9709a0aa8ca074f55dd26aa13a9a685d79_2_1380x568.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1f653e9709a0aa8ca074f55dd26aa13a9a685d79_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-05-26 at 14.17.30</span><span class=\"informations\">2816\u00d71162 104 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-31T03:41:49.324Z",
				"Answer_body": "<p>\u200bHi <a class=\"mention\" href=\"/u/cifkao\">@cifkao</a>, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-30T03:41:50.346Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Run.history() returns different values on almost each call",
		"Question_link": "https://community.wandb.ai/t/run-history-returns-different-values-on-almost-each-call/2431",
		"Question_created_time": "2022-05-16T15:00:29.122Z",
		"Question_answer_count": 5,
		"Question_score_count": 2,
		"Question_view_count": 829,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I recently started using the <code>wandb.Api()</code> in order not to manually download all the Charts in <code>.csv</code> format.</p>\n<p>The problem is that I cannot get consistent results, most of the times that I call the API  in a jupyter-notebook I get different results.</p>\n<p>I have made public one of my dashboards to tackle this issue. Here is a screenshot with a reproducible example:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/3bd006338d2541c672c4bf4c2f5e60aa6144e60c.png\" data-download-href=\"/uploads/short-url/8x7Rm9lNkSyg4pi6edKG0wNOxgE.png?dl=1\" title=\"2022-05-16-165542_647x517_scrot\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/3bd006338d2541c672c4bf4c2f5e60aa6144e60c.png\" alt=\"2022-05-16-165542_647x517_scrot\" data-base62-sha1=\"8x7Rm9lNkSyg4pi6edKG0wNOxgE\" width=\"625\" height=\"500\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3bd006338d2541c672c4bf4c2f5e60aa6144e60c_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">2022-05-16-165542_647x517_scrot</span><span class=\"informations\">647\u00d7517 50.3 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>In order to obtain the <code>csv_val_f1</code> variable one just needs to download the <code>Val F1</code> chart. Two things can be seen here:</p>\n<ol>\n<li>Multiple runs of the same code produce different results</li>\n<li>The maximum value obtained by the API differs from the maximum value obtained by manually downloading the <code>.csv</code> version of the Chart.</li>\n</ol>\n<p>Any ideas on what I\u2019m missing?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-27T06:59:45.338Z",
				"Answer_body": "<p>I am experiencing the same issue.<br>\nI wanted to generate matplotlib plots using the API, but run.history() shows different results at each call so that it is impossible to reproduce the wandb charts .</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-27T16:47:31.375Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/jaeheelee\">@jaeheelee</a> and <a class=\"mention\" href=\"/u/carloshernandezp\">@carloshernandezp</a>,<br>\nI believe you are seeing this because we sample the data points when you call <code>run.history()</code>. You can use <code>run.scan_history()</code> if you would like to have the entire history returned. <a href=\"https://docs.wandb.ai/guides/track/public-api-guide#sampling\">Here</a> is some more information on this.</p>\n<p>Let me know if this solves the issue for you.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-05-28T12:52:43.563Z",
				"Answer_body": "<p>Yes, this solved my problem. Thank you <a class=\"mention\" href=\"/u/nathank\">@nathank</a> !</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-30T09:41:55.473Z",
				"Answer_body": "<p>This indeed solved the issue. Thank you for answering!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-29T09:42:40.908Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Modify code during sweep",
		"Question_link": "https://community.wandb.ai/t/modify-code-during-sweep/2484",
		"Question_created_time": "2022-05-23T13:43:17.712Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 77,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>If I run a sweep, and while the sweep is running I modify code that gets called during the sweep, will it affect the sweep or does it save the state of the code when the sweep starts?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-23T22:20:03.995Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/apjansen\">@apjansen</a> ,</p>\n<p>Sweep configs are immutable once started. Starting a new sweep would be the best method to making any modifications. Please let me know if you have any additional questions.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-27T00:07:30.379Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/apjansen\">@apjansen</a> ,</p>\n<p>As we have not heard back from you, I will be closing out this support request. Please do reach back out again if you require further assistance or have any questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-26T00:08:17.610Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Instant crash",
		"Question_link": "https://community.wandb.ai/t/instant-crash/2468",
		"Question_created_time": "2022-05-20T21:24:25.643Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 78,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey Guys, if i wand.init my pc instantly blue screens after inpputing my Key. I have no idea how to figure out what the issue is here and if some of you have any idea please let me know.<br>\nThanks in advance.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-20T22:36:04.197Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/maxp0\">@maxp0</a> ,</p>\n<p>I\u2019ll be glad to look into this for you. We will need some additional information before we can proceed to troubleshoot. Please  provide me with the following:</p>\n<ul>\n<li>The code you were using when running wandb</li>\n<li>Is your code running any containers</li>\n<li>The version of wandb you are using</li>\n<li>An image of what happens when you see the blue screen</li>\n<li>Debug logs (internal-debug.log and debug.log) found in your wandb run directory</li>\n<li>Any additional details would be great for us to isolate the issue.</li>\n</ul>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-26T19:33:58.505Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/maxp0\">@maxp0</a>  ,</p>\n<p>As we have not heard from you with an update regarding your blue screen crash, I will be closing this thread out. Please do reach out again at any time if you require support.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-25T19:34:54.534Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Using wandb sweep with torch.distributed.launch",
		"Question_link": "https://community.wandb.ai/t/using-wandb-sweep-with-torch-distributed-launch/2483",
		"Question_created_time": "2022-05-23T12:30:50.747Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 230,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello</p>\n<p>I am using wandb sweep to perform hyperparameter tuning.</p>\n<p>Basically when I launch wandb agent with \u201cwandb agent &lt;USERNAME/PROJECTNAME/SWEEPID&gt;\u201d,</p>\n<p>It will automatically run  \u201c/usr/bin/env python train.py --param1=value1 --param2=value2\u201d according to the configurations.</p>\n<p>However my code is based on torch distributed data parallel and it has to be launched with torch.distributed.launch   train.py  rather than just  python train.py.</p>\n<p>How can I tackle this problem?</p>\n<p>Many thanks in advance!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-24T21:56:22.573Z",
				"Answer_body": "<p>Hi <span class=\"mention\">@rash</span>!</p>\n<p>Thanks for writing in. You can change the command that the agent runs by specifying the command structure in your sweep config. Specifically, you can change the <code>interpreter</code> variable to switch to <code>torch.distributed.launch</code>. <a href=\"https://docs.wandb.ai/guides/sweeps/configuration#command\">Here</a> is a link to our docs regarding how this can be done.</p>\n<p>Please let me know if I can be of further assistance.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-25T02:26:21.509Z",
				"Answer_body": "<p>Thanks Ramit</p>\n<p>I have  followed what you suggested but I am still unable to run with torch.distributed.launch.</p>\n<p>Below is my configuration yaml file.</p>\n<p>\u2018\u2019\u2019\u2019\u2019<br>\nmethod: random</p>\n<p>program: rae_wandb.py</p>\n<p>metric:</p>\n<p>name: total_mean_rank_sum</p>\n<p>goal: minimize</p>\n<p>command:</p>\n<ul>\n<li>\n<p>${env}</p>\n</li>\n<li>\n<p>torch.distributed.launch</p>\n</li>\n<li>\n<p>${program}</p>\n</li>\n<li>\n<p>${args}</p>\n</li>\n</ul>\n<p><span class=\"hashtag\">#command:</span></p>\n<p><span class=\"hashtag\">#-</span> python raw_wandb.py</p>\n<p><span class=\"hashtag\">#-</span> python -m torch.distributed.launch --nproc_per_node=4 rae_wandb.py  -m torch.distributed.launch --nproc_per_node=4</p>\n<p>parameters:</p>\n<p>lr:</p>\n<pre><code>min: 0.0\n\nmax: 0.01\n</code></pre>\n<p>coef_lr:</p>\n<pre><code>min: 0.0\n\nmax: 0.01\n</code></pre>\n<p>sim_header:</p>\n<pre><code>values: [\"meanP\", \"seqLSTM\", \"seqTransf\"]\n</code></pre>\n<p>\u2018\u2019\u2019\u2019\u2019\u2019\u2019\u2019</p>\n<p>when I launch an agent , it runs       /usr/bin/env torch.distributed.launch rae_wandb.py --coef_lr=0.0068455254534794605 --lr=0.008759887226936639 --sim_header=seqTransf</p>\n<p>what I really need is /usr/bin/env python -m torch.distributed.launch rae_wandb.py --coef_lr=0.0068455254534794605 --lr=0.008759887226936639 --sim_header=seqTransf</p>\n<p>I would like to find some descriptive examples.</p>\n<p>Many thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-25T16:13:23.113Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/raeh\">@raeh</a>,</p>\n<p>The following should work in this case then:</p>\n<pre data-code-wrap=\"yaml\"><code class=\"lang-nohighlight\">command:\n    - ${env}\n    - ${interpreter}\n    - \"-m\"\n    - \"torch.distributed.launch\"\n    - ${program}\n    - ${args}\n</code></pre>\n<p>Please let me know if this solves the issue for you.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-02T17:50:52.062Z",
				"Answer_body": "<p>Hi Ray,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-08T20:04:43.437Z",
				"Answer_body": "<p>Hi Ray, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-24T16:13:42.652Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Show baseline score in plots",
		"Question_link": "https://community.wandb.ai/t/show-baseline-score-in-plots/2492",
		"Question_created_time": "2022-05-25T10:55:26.544Z",
		"Question_answer_count": 2,
		"Question_score_count": 1,
		"Question_view_count": 187,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I\u2019m training N models and I\u2019m plotting on wandb their evaluation score. This results in having a run group where each panel has N plots, like in the figure below.<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/6bfd099e64d3d1327f97778eb9b5fd37605c3674.png\" alt=\"Screenshot from 2022-05-25 12-49-24\" data-base62-sha1=\"fpjdD3BHyP6hIa3uCWJUY9ZbVKk\" width=\"441\" height=\"210\"></p>\n<p>I want to also show a horizontal line that represents the baseline score that my model needs to beat. At the moment I\u2019m doing that manually by adding an expression like <code>baseline_value + 0 * ${evaluation}</code>. However, this is ugly since N lines will be created with the same name as the model runs.</p>\n<p>Is there a way to automate this, and only produce one line with a different name (e.g. <code>'baseline'</code>)?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-25T11:17:09.630Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/federico-taschin\">@federico-taschin</a>, at the moment this is not supported in the app, but we have an internal ticket tracking this request. I\u2019ll bump up its priority and let you know once there are updatess</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-24T11:17:53.435Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Custom Radar Plot",
		"Question_link": "https://community.wandb.ai/t/custom-radar-plot/2455",
		"Question_created_time": "2022-05-20T02:52:37.992Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 83,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi all,</p>\n<p>I\u2019ve been trying to set up a radar plot using the custom charts feature, but I\u2019m stuck!</p>\n<p>Ideally, I want to be able to display seven different summary metrics on the radar plot, and overlay multiple runs.<br>\nI\u2019ve found an example vega chart that would work perfectly (<a href=\"https://vega.github.io/vega/examples/radar-chart/\" rel=\"noopener nofollow ugc\">https://vega.github.io/vega/examples/radar-chart/</a>), however I cannot figure out how to integrate the summary metrics into it.</p>\n<p>I\u2019m sure this is just coming from a lack of experience, so any help would be much appreciated!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-24T04:33:48.148Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/yerren\">@yerren</a>!</p>\n<p>Thanks for writing in. I modified the example you sent over to allow it to work with summary metrics. You just need to change the <code>\"data\"</code> part of your vega spec to the following:</p>\n<pre><code class=\"lang-json\">\"data\": [\n    {\n      \"name\" : \"wandb\"\n    },\n    {\n      \"name\": \"table\",\n      \"source\" : \"wandb\",\n      \"transform\": [\n        {\n          \"type\" : \"fold\",\n          \"fields\" : [\"${field:key_0}\", \"${field:key_1}\", \"${field:key_2}\"],\n          \"as\": [\"key\", \"value\"]\n        }\n      ]\n    },\n    {\n      \"name\": \"keys\",\n      \"source\": \"table\",\n      \"transform\": [\n        {\n          \"type\": \"aggregate\",\n          \"groupby\": [\"key\"]\n        }\n      ]\n    }\n  ],\n</code></pre>\n<p>and then go ahead and replace all instances of <code>\"category\"</code> with <code>\"name\"</code>. It should give you the desired result. Also, you might want to extend the list <code>\"fields\"</code> to accommodate for the 7 metrics as you needed.</p>\n<p>Please let me know if I can help out in any other way.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-27T17:36:11.499Z",
				"Answer_body": "<p>Hi Yerren,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-02T20:14:39.665Z",
				"Answer_body": "<p>Hi Yerren,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-23T04:34:25.532Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "No config file and system plots for offline runs",
		"Question_link": "https://community.wandb.ai/t/no-config-file-and-system-plots-for-offline-runs/2337",
		"Question_created_time": "2022-04-28T08:48:39.417Z",
		"Question_answer_count": 9,
		"Question_score_count": 0,
		"Question_view_count": 736,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>When uploading offline runs, there is no config shown in the dashboard.<br>\nAdditionally, there are also no system plots.</p>\n<p>Is there any way to fix this issue?</p>\n<p>Thank you very much for your help!<br>\nCedric</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-02T14:32:38.462Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/vanillawhey\">@vanillawhey</a>, do you get any errors when calling <code>wandb sync</code> or does it seem that the run is synced without any issues?</p>\n<p>Also, would you mind sharing a link to one of your runs here and I can take a look?</p>\n<p>One last thing to check is the <code>wandb-summary.json</code> that should be located in your offline run directory on your machine. Is this empty or do you see all of the summary metrics you logged in there?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-02T16:31:14.481Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nathank\">@nathank</a>,<br>\nthank you for taking the time to help us with our problem.<br>\nWe get a warning when synchronizing, but uploading the files works.</p>\n<pre><code class=\"lang-auto\">wandb sync -e jgu-wandb -p peer-learning --id id_name Path_to_folder\n\nwandb: WARNING Found {} directories containing tfevent files. If these represent multiple experiments, sync them individually or pass a list of paths.\nFound 24 tfevent files in Path_to_folder\nSyncing: https://wandb.ai/jgu-wandb/peer-learning/runs/id_name ...\n</code></pre>\n<p>The link to a run:  <a href=\"https://wandb.ai/jgu-wandb/peer-learning/runs/peer_4_agent_Pendulum-v0_27_04_22__2022-04-29_14.55.19__34nb89hv/overview\">link</a></p>\n<p>The <code>wandb-summary.json</code> is written after the upload and contains only one line</p>\n<pre><code class=\"lang-auto\">&gt; '{\"_wandb\": {\"runtime\": 40591}}'\n</code></pre>\n<p>The<code> wandb-metadata.json</code> is more meaningful:</p>\n<pre><code class=\"lang-auto\">&gt; {\n&gt;     \"os\": \"Linux-4.18.0-348.12.2.el8_5.x86_64-x86_64-with-centos-8.5-Arctic_Sphynx\",\n&gt;     \"python\": \"3.7.4\",\n&gt;     \"heartbeatAt\": \"2022-04-27T17:42:33.863340\",\n&gt;     \"startedAt\": \"2022-04-27T17:42:32.829508\",\n&gt;     \"docker\": null,\n&gt;     \"cpu_count\": 40,\n&gt;     \"cuda\": null,\n&gt;     \"args\": [\n&gt;         \"--save-name\",\n&gt;         ...\n&gt;     ],\n&gt;     \"state\": \"running\",\n&gt;     \"program\": \"run_dictator_new.py\",\n&gt;     \"codePath\": \"run_dictator_new.py\",\n&gt;     \"git\": {\n&gt;         ...\n&gt;     },\n&gt;     \"email\": null,\n&gt;     \"root\": \"...\",\n&gt;     \"host\": \"...\",\n&gt;     \"username\": \"...\",\n&gt;     \"executable\": \"/cluster/easybuild/broadwell/software/Python/3.7.4-GCCcore-8.3.0/bin/python\"\n&gt; }\n</code></pre>\n<p>Our workflow is training  on a cluster without direct internet access.<br>\nAfter the training, the data is copied to a computer via SSH and synchronized from there with wandb.<br>\nI hope you can help us further,<br>\nJannis</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-09T14:01:58.450Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/wwjbrugger\">@wwjbrugger</a> no problem and thank you for the info!</p>\n<p>This looks like it could be a bug related to syncing this run. Are you possibly able to run this on a machine that has internet access such as a Colab and see if you are getting the same results? Even if it is a minimal example only training for 1 epoch.</p>\n<p>Also, how are you passing in the config to W&amp;B in your training script?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-09T15:36:51.311Z",
				"Answer_body": "<p>Hi Nathan,</p>\n<p>Thanks for looking into this. We\u2019re passing the config as dict into the wandb.init method. The config is correctly stored and uploaded on online runs. For offline runs, it doesn\u2019t work neither on a local machine with internet access nor with the results from the computing cluster. We\u2019ve realized that for those runs, a config.yaml is never created in contrast to the online runs.</p>\n<p>Bests,<br>\nCedric</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-13T23:38:19.088Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/vanillawhey\">@vanillawhey</a> thank you for the update. Are you logging anything outside of TensorBoard? For example with <code>wandb.log()</code>?</p>\n<p>Let\u2019s try to sync with <code>wandb sync --no-sync-tensorboard &lt;path/to/run&gt;</code> and see if we can get the config and summary metrics to show up.</p>\n<p>I still think this is a bug and related to combination of TensorBoard and offline mode. I\u2019m currently trying to replicate on my end.</p>\n<p>Lastly could you mention what version of W&amp;B you are running?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-19T20:47:40.936Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/vanillawhey\">@vanillawhey</a>, I wanted to check back and see if you had a chance to try this out?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-23T05:29:29.317Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nathank\">@nathank</a>,</p>\n<p>sorry for my late reply and  thank you very much for your help. <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"><br>\nWe\u2019gve managed to get the config displayed in the dashboard.</p>\n<p>Unfortunately, we specified the wrong path for the upload, i.e., the experiment folder.<br>\nThe config is uploaded and displayed correctly when we specify offline run folder.</p>\n<p>Example<br>\nold : wandb sync \u2026/experiment_name<br>\nnew : wandb sync \u2026/experiment_name/wandb/offline-run-20220515_002356-jdlxek9r</p>\n<p>Apparently, now, we get a new error:</p>\n<p>.wandb: ERROR Metric data exceeds maximum size of 10.4MB (12.4MB)<br>\nwandb: ERROR Summary data exceeds maximum size of 10.4MB. Dropping it.<br>\ndone.</p>\n<p>However, the configuration is displayed correctly on the website.<br>\nThanks again for your help and if we can\u2019t get the new error under control, we\u2019ll  ask in a new issue.</p>\n<p>Bests,<br>\nCedric and Jannis</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-05-23T19:29:33.682Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/vanillawhey\">@vanillawhey</a> glad this was able to resolve the issue for you!</p>\n<p>For the maximum upload size issue, one thing I would recommend is limiting the frequency of logging if you are logging any sort of histogram such as gradients with <code>wandb.watch()</code>.</p>\n<p>If you find that you\u2019re still struggling to stay under the limit feel free to start a new issue or use the chat in the UI and we can look into what specifically may be causing these large summary file sizes.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-22T19:29:59.380Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "404 response executing GraphQL",
		"Question_link": "https://community.wandb.ai/t/404-response-executing-graphql/2418",
		"Question_created_time": "2022-05-13T23:17:09.957Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 977,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>When I execute wandb.login() in pycharm or jupyter notebook, I got the error below:<br>\n404 response executing GraphQL<br>\n404 page not found</p>\n<p>and then True is printed. However, when I run wandb.restored(\u2026), I get the error below:<br>\nCommError: Permission denied, ask the project owner to grant you access</p>\n<p>It works well in colab. What is the issue?<br>\nI am using Win11 with the latest version of wandb</p>\n<p>I should add that I could log in to my wandb account without issue, but recently I get the errors mentioned.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-18T12:36:02.685Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sajmahmo\">@sajmahmo</a>,</p>\n<p>At a first glance, looks like the API key you have entered on your windows 11 machine might be wrong. Could you call <code>wandb.login(relogin=True)</code> and re enter your key from <a href=\"https://wandb.ai/authorize\" class=\"inline-onebox\">Weights &amp; Biases</a> in order to check if this could be the case?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-23T14:08:01.721Z",
				"Answer_body": "<p>Thanks for the response.<br>\nIt has been already solved. I don\u2019t know why it happened. Maybe because I remotely logged in to my account from another IP in US while I regularly connect from my local machine in Belgium .</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-22T14:08:06.681Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Log multiple variables at the same plot",
		"Question_link": "https://community.wandb.ai/t/log-multiple-variables-at-the-same-plot/2474",
		"Question_created_time": "2022-05-22T02:05:44.304Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 125,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello there, I would like to log two different variables to show up on the same chart. I use the following:</p>\n<pre><code class=\"lang-auto\">for I in range(100):\n    var1 = something\n    var2 = something_else\n\n    wandb.log({\"var1\":something, \"var2\":something_else})\n</code></pre>\n<p>but for some reason, the dashboard shows it as two separate plots. I went through the documentation I see this:<br>\nMultiple metrics on one chart: Log multiple metrics in the same call to wandb.log, like this:</p>\n<p><code>wandb.log({\"acc'\": 0.9, \"loss\": 0.1})</code></p>\n<p>and they will both be available to plot against in the UI.</p>\n<p>Can anyone help me on this? I tried many hacks like insertring a list in the place of the variable, or a dict of dicts, etc\u2026</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-23T10:54:25.875Z",
				"Answer_body": "<p>Hey there, you\u2019ll need to edit one of the charts to include the other metrics manually in the UI. I\u2019ll edit the documentation to make this more clear. Here is an example:<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/c0855646bcca0e8b6f621e2da9d9a2e57f80b7e9.gif\" alt=\"May-23-2022 14-53-44\" data-base62-sha1=\"rt7ly31TOAnaAoc2J0N9HA5UFJf\" width=\"690\" height=\"282\" class=\"animated\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-22T10:55:12.901Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Question on using ax.vspan when plotting",
		"Question_link": "https://community.wandb.ai/t/question-on-using-ax-vspan-when-plotting/2355",
		"Question_created_time": "2022-05-02T12:58:56.203Z",
		"Question_answer_count": 5,
		"Question_score_count": 1,
		"Question_view_count": 115,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi!</p>\n<p>Does wandb plotting support the use of matplotlib\u2019s <a href=\"https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.axvspan.html?highlight=axvspan#matplotlib.axes.Axes.axvspan\" rel=\"noopener nofollow ugc\">axvspan</a>? I\u2019m trying to shade an area and it works locally, but it doesn\u2019t pop up in my plot in wandb.</p>\n<pre><code class=\"lang-auto\">    fig, ax = plt.subplots()\n    ax.plot(x_train, y_train, 'ro', label='data')\n\n    if len(x_test) &gt; 0:\n        ax.plot(x_test, y_test, 'bo', label='unseen data')\n        ax.axvspan(np.min(x_test), np.max(x_test), alpha=0.3, color='blue')\n    wandb.log({\"plot\": plt})\n</code></pre>\n<p>Thanks,<br>\nAndrei</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-04T17:01:52.414Z",
				"Answer_body": "<p>HI <a class=\"mention\" href=\"/u/inwaves\">@inwaves</a> could you share a link to your workspace?</p>\n<p>This may be a bug. We should support it if it is part of the Matplotlib library. I\u2019ll try to reproduce as well.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-18T20:35:35.283Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/inwaves\">@inwaves</a> I was able to test and replicate this issue. I\u2019ll report this as a bug and follow up if we are able to create a solution.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-19T12:23:49.091Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/nathank\">@nathank</a>, thanks for replicating! Until the solution arrives, using Plotly directly seems to work just fine, something like:</p>\n<pre><code class=\"lang-auto\">fig.add_vrect(x0=np.min(x_test), x1=np.max(x_test), line_width=0, fillcolor=\"red\", opacity=0.2)\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-20T20:18:14.918Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/inwaves\">@inwaves</a>, I\u2019m glad that using Plotly directly is working.</p>\n<p>I was looking through our source code and we simply call Plotly\u2019s conversion tool <a href=\"https://github.com/wandb/client/blob/272ce0aed8610df9e012b4645d00bac96d90d188/wandb/util.py#L560\" rel=\"noopener nofollow ugc\">here</a>. I tested converting a Matplotlib plot to Plotly with this tool locally and saw that same behavior. Unfortunately, it looks  like the change would actually have to take place in the Plotly repo in order for this to work properly.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-19T20:18:47.497Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Workspace configuration gone",
		"Question_link": "https://community.wandb.ai/t/workspace-configuration-gone/2130",
		"Question_created_time": "2022-03-22T09:08:02.726Z",
		"Question_answer_count": 12,
		"Question_score_count": 0,
		"Question_view_count": 261,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I spent many hours designing the workspace I wanted (columns, graphs, \u2026). Worked nicely (beside a bug that I reported before). Now I run the first experiment on a more powerful machine and\u2026 ALL configuration is gone, I am presented with the initial/standard graphs. Please tell me that there is a way to get my designs back. This way I can\u2019t use it.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-22T16:25:47.700Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hogru\">@hogru</a>,<br>\nI\u2019m sorry you had this issue. Was the new run sent to the same project as the other runs where you setup this workspace?</p>\n<p>If so, you can change the workspace on the bottom left corner of the UI from default to the workspace you created.</p>\n<p>Workspaces currently only apply to a single project but if you need, we should be able to move that run into the original project if you would like?</p>\n<p>As a side note, this has been reported as a frustration before and we are currently working to allow workspaces to be used like templates that can be moved across projects. I can add your name to this feature request to help up the priority.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-22T16:49:34.691Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nathank\">@nathank</a>,</p>\n<p>I log the runs to the same project. And my issue is very basic. I don\u2019t need to copy workspace settings (although<br>\nthat might be convenient in the future).</p>\n<p>On machine A I implement/debug and log to wandb. On machine B (with a GPU) I run the experiment. I have setup a workspace on machine A. After running the experiment on machine B the workspace setting is gone. It does not matter if I am in the default or my personal workspace. It\u2019s as if it was never configured (but I can \u201cprove\u201d it since I did a couple of exports).</p>\n<p>I will present the results to a couple of dozens lecturers and master students at an ML institute. The presentation will also cover my experience with wandb and a recommendation. I would really like to recommend it, but if the settings are gone this is a no go.</p>\n<p>Even if I did something stupid it should give a warning about deleting/overwriting.</p>\n<p>If it makes a difference, I log via Pytorch Lightning. And I have reported a bug (presumably) in the wandb UI a couple of days ago which I have not received a response for. I think it does not relate to this one, but who knows. Just so that you are aware.</p>\n<p>Hope you can help.</p>\n<p>Best,<br>\nStephan</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-22T19:17:00.490Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/hogru\">@hogru</a> I see. The workspace should persist across different machines but it is tied to the username who is signed into the UI. Is there any chance that machine B is logged in as another user?</p>\n<p>Also, are you on a local deployment or using our public cloud? If it is public cloud, could you share a link to the project and I can take a look?</p>\n<p>Lastly, I apologize that you didn\u2019t get a response on your bug report. Could you possibly share a link to where you posted it and I can address it there?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-22T21:22:03.341Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nathank\">@nathank</a>,</p>\n<p>thank for your quick responses. As a context information: I am new to wandb, this is my first project with it. So it might be that I don\u2019t use the right wandb terms or do \u201cstupid\u201d things.</p>\n<p>ad user name: I am not in front of machine B but I am pretty sure it is the same user X. I can\u2019t remember having added a second user Y. I set up a team though, just to try it out (if that\u2019s relevant). If machine B would log with user Y I guess I would not see the runs on machine A with user X. I see all runs from both machines on both machines.</p>\n<p>ad cloud: I use your public cloud. The project is a bit of a mess right now (in terms of logging) but it does not contain any  sensitive information and I just made it public: <a href=\"https://wandb.ai/hogru/Retrosynthesis\">project</a></p>\n<p>ad bug report: mea culpa, I saw that there IS an answer, I was just expecting/used to getting an e-mail after a thread update, which I didn\u2019t. I will deal with my issue  in the other thread.</p>\n<p>Update: the bug (which was mine) is now resolved; just if you are curious: <a href=\"https://community.wandb.ai/t/logged-value-available-in-graph-panel-but-not-in-columns/2100/4\" class=\"inline-onebox\">Logged value available in graph panel, but not in columns - #4 by hogru</a></p>\n<p>Best,<br>\nStephan</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-23T13:34:28.774Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/hogru\">@hogru</a>, no problem! And we\u2019re glad you\u2019re trying out W&amp;B!</p>\n<p>In the runs table you can see that all of the runs in this project were created by \u201chogru\u201d but I just wanted to clarify a little about the usernames to make sure we\u2019re understanding each other. When you log a run and give an API key when logging, the API key is tied to a username and will affect who \u201cCreated\u201d the run. Regardless of who created the run, you should be able to access the UI from any computer and the workspace will be tied to the user name used to sign into the UI on that computer, not the username associated with the run.</p>\n<p>I can see a workspace created by \u201chogru\u201d that is different than the default. Here is what that looks like:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/e7d0c63bb086d96c52b44917ee382fb9213bcf70.jpeg\" data-download-href=\"/uploads/short-url/x4JAK9zyhF2wU8LIJKweFXJgOqI.jpeg?dl=1\" title=\"Screen Shot 2022-03-23 at 8.22.22 AM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e7d0c63bb086d96c52b44917ee382fb9213bcf70_2_690x319.jpeg\" alt=\"Screen Shot 2022-03-23 at 8.22.22 AM\" data-base62-sha1=\"x4JAK9zyhF2wU8LIJKweFXJgOqI\" width=\"690\" height=\"319\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e7d0c63bb086d96c52b44917ee382fb9213bcf70_2_690x319.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e7d0c63bb086d96c52b44917ee382fb9213bcf70_2_1035x478.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e7d0c63bb086d96c52b44917ee382fb9213bcf70_2_1380x638.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e7d0c63bb086d96c52b44917ee382fb9213bcf70_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-03-23 at 8.22.22 AM</span><span class=\"informations\">1920\u00d7890 100 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Is this the workspace you were looking for or is this different than the one you created?</p>\n<p>Also, I see that you\u2019ve created a report found <a href=\"https://wandb.ai/hogru/Retrosynthesis/reports/Retrosynthesis-Zwischenbericht--VmlldzoxNjQ0Mjkw\">here.</a> I just wanted to double check that this isn\u2019t what you are looking for.</p>\n<p>Glad we were able to resolve the other bug you were experiencing!</p>\n<p>Let me know if either of these were the workspace you wanted or if we have some more digging to do.<br>\nThank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-23T14:00:59.696Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nathank\">@nathank</a>,</p>\n<p>thank you for the clarification concerning the user names. Makes sense. At the moment it is just me (creating runs and designing the UI) but for future work this will be important to understand.</p>\n<p>The screenshot you showed is what I referred to as the \u201cdefault\u201d. Since my modifications are lost I was assuming that the UI was reset to the default. If this is not the default I can only assume it is a very early version of the UI when I started to experiment with it. My \u201clast known good\u201d UI shows additional sections starting with \u201c10\u201d, \u201c20\u201d, \u2026 (I refer to those in a presentation).</p>\n<p>I created the report as a short status report for my supervisor at the university. It\u2019s not what I am missing.</p>\n<p>I attach a sample graph that I had in the UI, just to \u201cprove\u201d that something is gone. I had those until Monday.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/0f37317c14cccf2361c7862e3b9365c3c66ba5cd.png\" data-download-href=\"/uploads/short-url/2aBpCazGZPZNDGTNxVmKF89F05f.png?dl=1\" title=\"Untitled\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0f37317c14cccf2361c7862e3b9365c3c66ba5cd_2_690x298.png\" alt=\"Untitled\" data-base62-sha1=\"2aBpCazGZPZNDGTNxVmKF89F05f\" width=\"690\" height=\"298\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0f37317c14cccf2361c7862e3b9365c3c66ba5cd_2_690x298.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0f37317c14cccf2361c7862e3b9365c3c66ba5cd_2_1035x447.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0f37317c14cccf2361c7862e3b9365c3c66ba5cd_2_1380x596.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0f37317c14cccf2361c7862e3b9365c3c66ba5cd_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Untitled</span><span class=\"informations\">4559\u00d71969 257 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>So, unfortunately for me this is still unresolved and I still hope to get my Monday configuration back.</p>\n<p>Best,<br>\nStephan</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-04T16:21:51.115Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hogru\">@hogru</a>, sorry for the delay on this. Looking at your workspace now, it looks like you have the custom charts back. Did you have to recreate these?</p>\n<p>The only way that the workspace should be able to be reset is by going to the workspace dialogue in the bottom left corner and clicking clear workspace. If you don\u2019t think this could have happened then let me know and we can see if anything happened on our end.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-05T11:08:15.491Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nathank\">@nathank</a>,</p>\n<p>first, a status update:</p>\n<ul>\n<li>I had to recreate (a subset of) the custom charts</li>\n<li>I finished all runs on machine B (Ubuntu) and only then recreated the workspace on machine A (macOS); sure, should not make a difference, but I do not trust the UI / web service at this point</li>\n<li>During the runs of machine B (a number of loops over the same experiment setup to get the std.dev. of the results) the wandb process crashed in 2 out of 5 runs\u2026 I did not bother to report it since I needed to finish it and could not parallelize the work (see point above)</li>\n<li>As a consequence, I could not recommend wandb for \u201cserious work\u201d during my presentation to our ML institute</li>\n<li>I experienced wandb with a nice feature set and I like the product, but as a pre-sales consultant (not in the AI field) I would not recommend wandb to paying customers</li>\n</ul>\n<p>That said, I like the feature set, I am glad to get it for free in the academic context and I need to decide if/how I will proceed with my usage of wandb from here on. My next and last step is the master thesis and as I said, I don\u2019t know if I can trust wandb with my config data and the stability it needs for experiments that last longer hours.</p>\n<p>I understand that \u201cClear workspace\u201d should be the (only) way to delete the configuration, but as described in my initial bug report, the configuration was gone without me clearing the workspace. I can \u201coffer\u201d an experiment to try to reproduce the situation, i.e. running experiments from machine B (I only touched the wandb UI on machine A since recreating the workspace). I consider it unlikely that we can simply reproduce it, but it might be worth a try. Let me know what you think.</p>\n<p>In the meantime, I have a bit more time until I am ready to log new experiments and still need to decide how I will track them.</p>\n<p>Best regards,<br>\nStephan</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-11T16:16:25.915Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hogru\">@hogru</a>,<br>\nI apologize for the delay in the response. I\u2019m not able to replicate the issue unfortunately. We\u2019ll make a note of this and watch for any other users experiencing a similar problem but I apologize that you lost time spent creating the original workspace.</p>\n<p>We do have many user that run long experiments on our platform without any issues but I understand your concerns given the experience you had. If you would like we can try to debug what happened that caused your runs to crash? Was there any particular error you encountered? Linux machines sometimes do not like that we start new processes so often setting the env variable <code>WANDB_START_METHOD=\"thread\"</code> can help resolve these problems.</p>\n<p>Again, I apologize for the bad experience you had but I would love to hear your feedback and see if we can resolve your issues.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-18T08:06:05.206Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nathank\">@nathank</a>,</p>\n<p>I am still finishing the final touches on the work/report that I used wandb for. Until then, (when I get my grade) I will not touch wandb on Ubuntu, I am still afraid to lose work. For my master thesis (already started) I plan to use it for experiment tracking. I will switch between machines, set the WANDB_START_METHOD as suggested and depending on the experience, even do some graphs/reports that I plan to use in the thesis.  I have also started to download the logged data as CSV files so that I can do the critical reporting with more conventional methods (matplotlib et al.). Let\u2019s see how this goes, I\u2019ll report back (in a couple of months).</p>\n<p>Best regards,<br>\nStephan</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-20T13:14:16.078Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hogru\">@hogru</a>,<br>\nI\u2019m excited to hear that you plan to continue with W&amp;B in your thesis work. Feel free to write us here or email us at <a href=\"mailto:support@wandb.com\">support@wandb.com</a> if you have any feedback along the way.</p>\n<p>Wish you the best with your projects and excited to see how you incorporate W&amp;B in your work!</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-19T13:14:27.875Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Save_code in Google Colab",
		"Question_link": "https://community.wandb.ai/t/save-code-in-google-colab/2439",
		"Question_created_time": "2022-05-18T08:08:04.020Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 101,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I tried saving code using <code>save_code=True</code> in wandb.init() running on Google Colab, but can\u2019t see any code files in the run dashboard (there is no code section).<br>\nTaking a look in the debug log, I see \"\u2026Unable to probe notebook: \u2018NoneType\u2019 object has no attribute \u2018get\u2019 \" - can I assume save_code doesn\u2019t work on Google colab?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-19T10:44:04.711Z",
				"Answer_body": "<p>Hey John, could you share the debug logs? Also which wandb version are you using?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-20T12:59:23.676Z",
				"Answer_body": "<p>I tried to re-create in a fresh notebook and it seems to mostly work. If I can find what it was about the previous test that triggered the error I\u2019ll share more but my question (does save_code) work on colab has been answered by this second test with a resounding yes, and you can consider this issue closed.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-23T13:27:14.262Z",
				"Answer_body": "<p>Thanks for the update!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-19T13:00:16.400Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Is prediction speed of YOLOv5 recorded somewhere as part of the integration?",
		"Question_link": "https://community.wandb.ai/t/is-prediction-speed-of-yolov5-recorded-somewhere-as-part-of-the-integration/2419",
		"Question_created_time": "2022-05-14T01:03:03.869Z",
		"Question_answer_count": 8,
		"Question_score_count": 2,
		"Question_view_count": 110,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello!<br>\nI\u2019ve been training YOLOv5 models using wandb, and I\u2019ve been amazed at how much is natively built in with just a few command-line arguments. One thing I\u2019m lacking - is there any recording of the speed at which it makes predictions? I don\u2019t particularly care if it\u2019s on the training or test sets, I\u2019m just looking for any record of the speed at which the model makes predictions.</p>\n<p>Thanks!<br>\nIan</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-14T08:01:46.000Z",
				"Answer_body": "<p>Hi,</p>\n<p>This is probably a YoloV5 specific question, but in general, in cases like these where you want an additional logged metric, you would just record it yourself and call <code>wandb.log({'speed': speed}, commit=false)</code>.<br>\nThat being said, I had a look at the yolov5 docs and it looks like you can pass \u2014profile to get it to profile the inference speed of your model. Hope this helps <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-14T20:17:14.304Z",
				"Answer_body": "<p>Hi Scott thanks for your reply! I\u2019ll try using <code>wandb.log({'speed': speed}, commit=false)</code></p>\n<p>I looked in the docs <a href=\"https://docs.wandb.ai/guides/integrations/yolov5\">here</a> and didn\u2019t see any reference to a <code>-profile</code> option, nor is it in the source code for <code>train.py</code> for YOLOv5. Where did you see it mentioned? Is it a different script to run other than <code>train.py</code>?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-14T20:25:31.674Z",
				"Answer_body": "<aside class=\"quote group-team quote-modified\" data-username=\"_scott\" data-post=\"2\" data-topic=\"2419\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://sea2.discourse-cdn.com/business7/user_avatar/community.wandb.ai/_scott/40/95_2.png\" class=\"avatar\"> _scott:</div>\n<blockquote>\n<p>wandb.log({\u2018speed\u2019: speed}, commit=false)</p>\n</blockquote>\n</aside>\n<p>It seems that speed is not an option? I tried it and received an error.</p>\n<p>----&gt; 6 wandb.log({\u2018speed\u2019: speed}, commit=false)</p>\n<p>NameError: name \u2018speed\u2019 is not defined</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-14T21:22:18.574Z",
				"Answer_body": "<p>I\u2019ll reach out to the author of YoloV5 and find the appropriate command to profile the inference speed.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-14T21:25:18.523Z",
				"Answer_body": "<p>In the meantime, this tutorial profiles some different configurations.<br>\n<a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb#scrollTo=zR9ZbuQCH7FX\">https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb#scrollTo=zR9ZbuQCH7FX</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-20T12:09:42.862Z",
				"Answer_body": "<p>It looks like you can call <code>yolo.py</code> directly with <code>--profile</code>, but not <code>train.py</code>.</p><aside class=\"onebox githubblob\" data-onebox-src=\"https://github.com/ultralytics/yolov5/blob/fb7fa5be8b98b1f5f8162f699a10b2ddde5143c0/models/yolo.py#L311\">\n  <header class=\"source\">\n\n      <a href=\"https://github.com/ultralytics/yolov5/blob/fb7fa5be8b98b1f5f8162f699a10b2ddde5143c0/models/yolo.py#L311\" target=\"_blank\" rel=\"noopener\">github.com</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <h4><a href=\"https://github.com/ultralytics/yolov5/blob/fb7fa5be8b98b1f5f8162f699a10b2ddde5143c0/models/yolo.py#L311\" target=\"_blank\" rel=\"noopener\">ultralytics/yolov5/blob/fb7fa5be8b98b1f5f8162f699a10b2ddde5143c0/models/yolo.py#L311</a></h4>\n\n\n\n    <pre class=\"onebox\">      <code class=\"lang-py\">\n        <ol class=\"start lines\" start=\"301\" style=\"counter-reset: li-counter 300 ;\">\n            <li>            ch = []</li>\n            <li>        ch.append(c2)</li>\n            <li>    return nn.Sequential(*layers), sorted(save)</li>\n            <li>\n            </li>\n<li>\n            </li>\n<li>if __name__ == '__main__':</li>\n            <li>    parser = argparse.ArgumentParser()</li>\n            <li>    parser.add_argument('--cfg', type=str, default='yolov5s.yaml', help='model.yaml')</li>\n            <li>    parser.add_argument('--batch-size', type=int, default=1, help='total batch size for all GPUs')</li>\n            <li>    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')</li>\n            <li class=\"selected\">    parser.add_argument('--profile', action='store_true', help='profile model speed')</li>\n            <li>    parser.add_argument('--line-profile', action='store_true', help='profile model speed layer by layer')</li>\n            <li>    parser.add_argument('--test', action='store_true', help='test all yolo*.yaml')</li>\n            <li>    opt = parser.parse_args()</li>\n            <li>    opt.cfg = check_yaml(opt.cfg)  # check YAML</li>\n            <li>    print_args(vars(opt))</li>\n            <li>    device = select_device(opt.device)</li>\n            <li>\n            </li>\n<li>    # Create model</li>\n            <li>    im = torch.rand(opt.batch_size, 3, 640, 640).to(device)</li>\n            <li>    model = Model(opt.cfg).to(device)</li>\n        </ol>\n      </code>\n    </pre>\n\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-26T13:13:06.011Z",
				"Answer_body": "<p>Hi Ian, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-19T12:10:10.635Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Acoount Deletion",
		"Question_link": "https://community.wandb.ai/t/acoount-deletion/2456",
		"Question_created_time": "2022-05-20T02:54:48.831Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 66,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I no more use W&amp;B. Could you delete my account please?<br>\nmy username is code4bw</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-20T11:42:16.694Z",
				"Answer_body": "<p>Hey there,</p>\n<p>The account has been deleted. Have a nice day!</p>\n<p>Best,<br>\nArman</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-19T11:43:11.667Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Want to log Inference Progress",
		"Question_link": "https://community.wandb.ai/t/want-to-log-inference-progress/2459",
		"Question_created_time": "2022-05-20T06:28:20.295Z",
		"Question_answer_count": 5,
		"Question_score_count": 2,
		"Question_view_count": 214,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi Wandb,<br>\nI am running an Inference script on a huge corpus for a wav2vec ASR model. I want to log the progress on wandb (% of files completed) either as a progress bar or a changing label so that I can peacefully close the sagemaker notebook window and make sure the notebook still runs fine. How can I log the percentage completion (maybe like tqdm)?<br>\nAny help is appreciated, thanks in advance!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-20T07:15:04.763Z",
				"Answer_body": "<p>For now, I\u2019ve logged the progress in the form of a linear graph (showing percentage and examples inference) manually updating them in each iteration. But wouldn\u2019t it be a good feature to have a tqdm like progress bar in the wandb dashboard?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-20T10:01:50.328Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/spranjal25\">@spranjal25</a>,</p>\n<p>This is a nice idea. All of the logs printed during your run will be displayed in the logs tab of your run.<br>\nThat\u2019ll show your progress bar from tqdm. I do agree however that it would be a nice feature for us to add to be able to display a custom progress bar on your workspace, alonside your other plots. I\u2019ll make a feature request ticket for this.</p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/ref/app/pages/run-page#logs-tab\">\n  <header class=\"source\">\n      \n\n      <a href=\"https://docs.wandb.ai/ref/app/pages/run-page#logs-tab\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://www.gitbook.com/cdn-cgi/image/height=640,width=1280,fit=contain,dpr=1,format=auto/https%3A%2F%2F1039519455-files.gitbook.io%2F~%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252F-Lqya5RvLedGEWPhtkjU%252Fsocialpreview%252Fue7fU3AWqmkPrLvIA1sg%252Flogo.png%3Falt%3Dmedia%26token%3Dc5fd7a6b-2501-4ee8-9a85-bcef4bb40fdc\" class=\"thumbnail onebox-avatar\" width=\"500\" height=\"500\">\n\n<h3><a href=\"https://docs.wandb.ai/ref/app/pages/run-page#logs-tab\" target=\"_blank\" rel=\"noopener\">Run Page</a></h3>\n\n  <p>Each training run of your model gets a dedicated page, organized within the larger project</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-20T10:24:30.657Z",
				"Answer_body": "<p>Great <a class=\"mention\" href=\"/u/_scott\">@_scott</a>! Thanks for the quick response. Also, thanks for the \u2018logs\u2019 part, not sure why I never noticed it. I am able to see my logs but I think the earlier logs are replaced, I\u2019m not able to see the TQDM progress bar. But I must say, you\u2019ve built a great product with WANDB. Kudos!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-23T18:30:59.230Z",
				"Answer_body": "<p>Hi, I\u2019m glad you like our product so far. We actually have a ticket out to fix tqdm with wandb. I have increased the priority on it for you and I\u2019ll keep you updated on it</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-19T10:25:00.389Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Permission Error",
		"Question_link": "https://community.wandb.ai/t/permission-error/2444",
		"Question_created_time": "2022-05-18T23:15:19.749Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 163,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi all,<br>\nI am totally new to wandb and when running my code I get the following error:<br>\nTraceback (most recent call last):<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\u201d, line 996, in init<br>\nwi.setup(kwargs)<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\u201d, line 237, in setup<br>\nwandb_login._login(<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/site-packages/wandb/sdk/wandb_login.py\u201d, line 297, in _login<br>\nwlogin.prompt_api_key()<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/site-packages/wandb/sdk/wandb_login.py\u201d, line 220, in prompt_api_key<br>\nkey, status = self._prompt_api_key()<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/site-packages/wandb/sdk/wandb_login.py\u201d, line 197, in _prompt_api_key<br>\napi = Api(self._settings)<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\u201d, line 74, in <strong>init</strong><br>\nself._settings = Settings(<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/site-packages/wandb/old/settings.py\u201d, line 23, in <strong>init</strong><br>\nself._global_settings.read([Settings._global_path()])<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/site-packages/wandb/old/settings.py\u201d, line 110, in _global_path<br>\nutil.mkdir_exists_ok(config_dir)<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/site-packages/wandb/util.py\u201d, line 854, in mkdir_exists_ok<br>\nos.makedirs(path)<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/os.py\u201d, line 213, in makedirs<br>\nmakedirs(head, exist_ok=exist_ok)<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/os.py\u201d, line 213, in makedirs<br>\nmakedirs(head, exist_ok=exist_ok)<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/os.py\u201d, line 223, in makedirs<br>\nmkdir(name, mode)<br>\nPermissionError: [Errno 13] Permission denied: \u2018/home/mahzad-khosh\u2019<br>\nwandb: ERROR Abnormal program exitTraceback (most recent call last):<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\u201d, line 996, in init<br>\nwi.setup(kwargs)<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/site-packages/wandb/sdk/wandb_init.py\u201d, line 237, in setup<br>\nwandb_login._login(<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/site-packages/wandb/sdk/wandb_login.py\u201d, line 297, in _login<br>\nwlogin.prompt_api_key()<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/site-packages/wandb/sdk/wandb_login.py\u201d, line 220, in prompt_api_key<br>\nkey, status = self._prompt_api_key()<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/site-packages/wandb/sdk/wandb_login.py\u201d, line 197, in _prompt_api_key<br>\napi = Api(self._settings)<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\u201d, line 74, in <strong>init</strong><br>\nself._settings = Settings(<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/site-packages/wandb/old/settings.py\u201d, line 23, in <strong>init</strong><br>\nself._global_settings.read([Settings._global_path()])<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/site-packages/wandb/old/settings.py\u201d, line 110, in _global_path<br>\nutil.mkdir_exists_ok(config_dir)<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/site-packages/wandb/util.py\u201d, line 854, in mkdir_exists_ok<br>\nos.makedirs(path)<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/os.py\u201d, line 213, in makedirs<br>\nmakedirs(head, exist_ok=exist_ok)<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/os.py\u201d, line 213, in makedirs<br>\nmakedirs(head, exist_ok=exist_ok)<br>\nFile \u201c/z/home/mahzad-khosh/env/romp2/lib/python3.8/os.py\u201d, line 223, in makedirs<br>\nmkdir(name, mode)<br>\nPermissionError: [Errno 13] Permission denied: \u2018/home/mahzad-khosh\u2019<br>\nwandb: ERROR Abnormal program exit</p>\n<p>When initializing wandb I set the dir to path = \u201c/z/home/mahzad-khosh/Human_object_transform/wandb\u201d which I am sure has permission to write.<br>\nAlso I do<br>\nexport WANDB_DIR=/z/home/mahzad-khosh/Human_object_transform/wandb<br>\nin my submit script.<br>\nAny tip on how I can avoid this error?</p>\n<p>Thanks,</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-19T21:26:16.275Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mkhoshle\">@mkhoshle</a>,</p>\n<p>Looks like the <code>makedirs</code> function is trying to create directories in the folder <code>/home/mahzad-khosh</code>, could you share the init command you ran  when you tried to initialize the dir?</p>\n<p>Additionally, what version of <code>wandb</code> are you currently running? This will let me know next steps on how to debug this for you.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-19T22:08:48.557Z",
				"Answer_body": "<p>Hi,</p>\n<p>I added these three lines to my submit script and it is working now!</p>\n<p>export WANDB_CONFIG_DIR=/z/home/mahzad-khosh/Human_object_transform/wandb<br>\nexport WANDB_DIR=/z/home/mahzad-khosh/Human_object_transform/wandb<br>\nexport WANDB_CACHE_DIR=/z/home/mahzad-khosh/Human_object_transform/wandb</p>\n<p>Thank you,</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-18T22:09:18.506Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb integration using class and sweep running twice under the same name",
		"Question_link": "https://community.wandb.ai/t/wandb-integration-using-class-and-sweep-running-twice-under-the-same-name/2433",
		"Question_created_time": "2022-05-16T16:44:47.380Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 308,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi all,</p>\n<p>I\u2019m implementing W&amp;B into an existing project in which Agent, Model creation and Environment are constructed in classes. The code structure in the Python file (<code>AIAgent.py</code>) looks like this:</p>\n<pre><code class=\"lang-auto\">import wandb\n\nconfig = {\n    'layer_sizes': [17, 16, 12, 4],\n    'batch_minsize': 32,\n    'max_memory': 100_000,\n    'episodes': 2,\n    'epsilon': 1.0,\n    'epsilon_decay': 0.998,\n    'epsilon_min': 0.01,\n    'gamma': 0.9,\n    'learning_rate': 0.001,\n    'weight_decay': 0,\n    'optimizer': 'sgd',\n    'activation': 'relu',\n    'loss_function': 'mse'\n}\n\nclass AIAgent:\n    def __init__(self):\n        self.config = config\n        self.pipeline(self.config)\n\n\n    def pipeline(self, config):\n        wandb.init()\n        config = wandb.config\n\n        model, criterion, optimizer = self.make(config)\n        self.train(model, criterion, optimizer, config) \n\n\n    def make(self, config):\n        model = LinearQNet(config).to(device)\n\n        if config['loss_function'] == 'mse':\n            criterion = nn.MSELoss()\n\n        if config['optimizer'] == 'adam':\n            optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], betas=(0.9, 0.999), eps=1e-08, weight_decay=config['weight_decay'], amsgrad=False)\n \n        wandb.watch(model, criterion, log='all', log_freq=1)\n        summary(model)\n\n        return model, criterion, optimizer\n\n\n    def train(self, model, criterion, optimizer, config):\n        for episode in range(1, config['episodes'] + 1):\n            while True:\n                # Where the training is performed\n\n                if done:\n                    if (episode % 1) == 0:\n                        wandb.log({'episode': episode, 'epsilon': epsilon, 'score': score, 'loss': loss_mean, 'reward': reward_mean, 'score_mean': score_mean, 'images': [wandb.Image(img) for img in env_images]}, step=episode})\n                    break\n\n            if episode &lt; config['episodes']:\n                game.game_reset()\n            else:\n                wandb.finish()\n                break\n\n\nclass LinearQNet(nn.Module):\n    def __init__(self, config):\n        super(LinearQNet, self).__init__()\n        self.config = config\n        # Where the NN is configured\n\n\nif __name__ == '__main__':\n    AIAgent.__init__(AIAgent())\n</code></pre>\n<p>I\u2019m currently initializing the sweep configuration via a .yaml file calling  <code>wandb sweep sweep.yaml</code>. The sweep.yaml file looks like this:</p>\n<pre><code class=\"lang-auto\">program: AIAgent.py\nproject: evaluation-sweep-1\nmethod: random\nmetric:\n  name: score_mean\n  goal: maximize\ncommand:\n  - ${env}\n  - python3\n  - ${program}\n  - ${args}\nparameters:\n  layer_sizes:\n    distribution: constant\n    value: [17, 16, 512, 4]\n  batch_minsize:\n    distribution: int_uniform\n    max: 1024\n    min: 32\n  max_memory:\n    distribution: constant\n    value: 100_000\n  episodes:\n    distribution: constant\n    value: 50\n  epsilon:\n    distribution: constant\n    value: 1.0\n  epsilon_decay:\n    distribution: constant\n    value: 0.995\n  epsilon_min:\n    distribution: constant\n    value: 0.01\n  gamma:\n    distribution: uniform\n    max: 0.99\n    min: 0.8\n  learning_rate:\n    distribution: uniform\n    max: 0.1\n    min: 0.0001  \n  weight_decay:\n    distribution: constant\n    value: 0\n  optimizer:\n    distribution: categorical\n    values: ['sgd', 'adam', 'adamw']\n  activation:\n    distribution: categorical\n    values: ['relu', 'sigmoid', 'tanh', 'leakyrelu']\n  loss_function:\n    distribution: constant\n    value: 'mse'\nearly_terminate:\n  type: hyperband\n  min_iter: 5\n</code></pre>\n<p>Besides general feedback on the implementation I\u2019m a bit dumbfounded with a current bug. The sweeps run fine and show up in the W&amp;B interface but every sweep is performed twice under the same name of which only the loffing of the first is displayed and the second runs \u2018silently\u2019 in the environment without update of wandb.log. Does anybody have an idea what the reason for this might be?</p>\n<p>Thanks,<br>\nTobias</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-18T14:52:27.134Z",
				"Answer_body": "<p>Hi Tobias,</p>\n<p>Looks like the source of this bug is this line: <code>AIAgent.__init__(AIAgent())</code> which is calling 2 constructors: 1 from <code>AIAgent.__init__()</code> and 1 from <code>AIAgent()</code>. This, in turn calls <code>pipeline</code> twice, which ends up meaning 2 calls to <code>wandb.init()</code> and therefore you see 2 runs.</p>\n<p>I would suggest changing that line to just <code>AIAgent</code> to prevent this error.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-05-19T08:22:06.618Z",
				"Answer_body": "<p>Oh mann. Thanks a lot Ramit.<br>\nMuch appreciated!</p>\n<p>Best regards,<br>\nTobias</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-18T08:22:24.480Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Copy instead of moving runs to team",
		"Question_link": "https://community.wandb.ai/t/copy-instead-of-moving-runs-to-team/2442",
		"Question_created_time": "2022-05-18T16:20:34.786Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 81,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>I know how to move runs to a team, but my problem is that the runs are then removed from my profile.</p>\n<p>Is there a way to copy the runs, keeping them in my profile and in the team ?</p>\n<p>A better solution would be to link them to a team project and if we add things to the run in the user project the changes should  also be  reported in the team project. Basically, both projects would point to the same unique run and if a user deletes a run in his project the run would still be present in team\u2019s project (only the link would be removed). If a run as no links attached to it, it should be erased.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-07-17T16:21:35.467Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Remove multiple runs at the same time",
		"Question_link": "https://community.wandb.ai/t/remove-multiple-runs-at-the-same-time/2435",
		"Question_created_time": "2022-05-17T08:39:36.526Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 234,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hello,</p>\n<p>I think it would be beneficial to select and delete several experiments at the same time.<br>\nNow I have to delete one by one and it is very time consuming.</p>\n<p>Thank you!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-18T11:54:10.582Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/lucasventura\">@lucasventura</a>, you can do it like <a href=\"https://docs.wandb.ai/ref/app/features/runs-table#filter-and-delete-unwanted-runs\">this</a>.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-05-18T13:20:23.382Z",
				"Answer_body": "<p>Thank you <a class=\"mention\" href=\"/u/armanharutyunyan\">@armanharutyunyan</a> !</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-17T13:20:50.378Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Comparing different artifact versions visually",
		"Question_link": "https://community.wandb.ai/t/comparing-different-artifact-versions-visually/2394",
		"Question_created_time": "2022-05-10T11:56:16.601Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 399,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am running an image generative model and logging the generated images at each step as a new version of the same artifact. I would like to compare the generated images over time. I was able to compare two versions of the same artifact using \u201ccompare\u201d in the artifact view (and doing an inner join between the tables containing the images). However I was not able to compare more than two versions. I have tried using weave in a reportbut it seems to be very buggy.<br>\nAny ideas how I can compare multiple versions of an artifact (to view the improvement in image generation over time).</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-11T08:56:51.110Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/mmabrouk_modelme\">@mmabrouk_modelme</a>. I am checking whether that\u2019s possible</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-18T08:52:19.194Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/mmabrouk_modelme\">@mmabrouk_modelme</a>, apologies about the delay. At the moment comparing more that two versions of an artifact is not possible.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-17T08:52:55.515Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Run best model off sweep?",
		"Question_link": "https://community.wandb.ai/t/run-best-model-off-sweep/2423",
		"Question_created_time": "2022-05-16T03:38:22.869Z",
		"Question_answer_count": 6,
		"Question_score_count": 2,
		"Question_view_count": 576,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi,<br>\nI am using Sweeps to run through different configuration models and I was told by the wandb chat support that to run the best model configuration off sweeps is to create a new sweep with the best performing parameter set and running off it.</p>\n<p>But this is lot of tedious work, is there any other elegant way of quering wandb project for the best model configuration and running off it?</p>\n<p>tldr: I run a sweep with different configuration, would like to run predictions off a specific set of parameters (or best performing set of parameters). How  to do it with the sweep API?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-16T10:11:09.278Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/cyrilw\">@cyrilw</a></p>\n<p>Thanks for persisting with this and posting it here, here is how you do it with the Api.</p>\n<pre><code class=\"lang-auto\">import wandb\n\napi = wandb.Api()\nsweep = api.sweep(f\"_scott/project-name/sweeps/qwbwbwbz\")\n\n# Get best run parameters\nbest_run = sweep.best_run(order='validation/accuracy')\nbest_parameters = best_run.config\nprint(best_parameters)\n</code></pre>\n<p>Hope this helps <img src=\"https://emoji.discourse-cdn.com/twitter/magic_wand.png?v=12\" title=\":magic_wand:\" class=\"emoji\" alt=\":magic_wand:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-05-16T14:52:40.371Z",
				"Answer_body": "<p>Thank you for the reply.</p>\n<p>in this,<br>\n<code>best_run = sweep.best_run(order='validation/accuracy')</code></p>\n<p>do I need to change the validation/accuracy based on my sweep columns?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-16T15:02:05.630Z",
				"Answer_body": "<p>Yes, sorry I should have said that. <code>order</code> is the metric you want it to order by.</p>\n<p>If you have set a goal in your Sweep config, it\u2019ll use that if <code>order</code> is not given.</p>\n<p>Here\u2019s the source if you\u2019re curious: <a href=\"https://wandb/client\">https://github.com/wandb/client/blob/a339333b3ee93864daf416f04c1501186dffac5c/wandb/apis/public.py#L2137</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-16T15:36:04.777Z",
				"Answer_body": "<p>I see. Just to confirm, my current sweep configuration is;</p>\n<pre><code class=\"lang-auto\">method: random\nmetric:\n  goal: minimize\n  name: KL\nparameters:\n  K:\n    distribution: int_uniform\n    max: 15\n    min: 3\n</code></pre>\n<p>since I do have the goal/metric set I don\u2019t need to worry about order, right? but if not I do collect KL (column name is <code>KL</code>) score (kl-divergence) so I\u2019d modify the code snipet as;</p>\n<p><code>best_run = sweep.best_run(order='KL')</code></p>\n<p>But in case of KL, the lower is better any recommendation on how to select best_run based on it?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-16T16:51:05.087Z",
				"Answer_body": "<p>Because your configuration has a goal, you can leave <code>order</code> out.<br>\nSo you can just do:</p>\n<pre><code class=\"lang-auto\">best_run = sweep.best_run() \n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-15T16:51:46.560Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Additional System Metrics From e.g., `dstat`",
		"Question_link": "https://community.wandb.ai/t/additional-system-metrics-from-e-g-dstat/2333",
		"Question_created_time": "2022-04-27T17:16:16.562Z",
		"Question_answer_count": 5,
		"Question_score_count": 1,
		"Question_view_count": 163,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi W&amp;B Community,</p>\n<p>Is there a possibility to get additional live system metrics like the network read/write rates, disk read/write rates, virtual memory major/minor page faults, filesystem inodes, and system context switches?</p>\n<p>Basically, most of the metrics that dstat provides with the following flags:</p>\n<ul>\n<li>\u2013disk</li>\n<li>\u2013mem (memory)</li>\n<li>\u2013net (network)</li>\n<li>\u2013sys (system)</li>\n<li>\u2013fs (filesystem)</li>\n<li>\u2013vm (virtual memory)</li>\n</ul>\n<p>I\u2019m deep into pipeline profiling and found that having these helps a lot when looking for performance tuning opportunities. Also, allowing to add to the system metric log might be helpful generally to have everything related to actual ML in one log, and everything related to system metrics in another.</p>\n<p>I saw that the <a href=\"https://docs.wandb.ai/ref/app/features/system-metrics\">current documentation</a> suggests that you use this script - github(.)com/nicolargo/nvidia-ml-py3/blob/master/pynvml.py - to get the GPU metrics, however, I did not find the system metrics there.</p>\n<p>The first workaround for me would be to run  <code>dstat</code> in parallel to the process, save the profiling log,<br>\ndownload your system metrics and join over the <code>_timestamp</code>. This, however, would negate your wonderful automatic visualization.</p>\n<p>The other solution would be to use some system monitoring library and add manually via <code>wandb.log({'my_metric': x})</code> to the \u201cML\u201d-log. This would show the metric in your visualization but not at the correct place and would not be easily compared to the other system metrics. I do not know how well this would work in practice as there would need to be additions to this log ideally every (few) seconds. This would be an asynchronous running thread that is not inside of the training loop. <a href=\"https://docs.wandb.ai/guides/track/log/logging-faqs#what-if-i-want-to-log-some-metrics-on-batches-and-some-metrics-only-on-epochs\">The solution proposed here</a>  seems like it could work if I use \u201ctimestamps\u201d as the X-axis? This still does not seem like a clean solution.</p>\n<p>What are your thoughts on this proposed feature? I\u2019m very much a novice regarding your service so I might not know the in\u2019s and out\u2019s, maybe I have overlooked some trivial solution.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-27T19:49:01.414Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/cirquit\">@cirquit</a>!</p>\n<p>Thank you for your feature request! I\u2019m curious about your use case here - I definitely understand how network read/writes and disk read/writes could help here, but I\u2019m curious about how you see page faults, inodes and context switches fit into your workflow.</p>\n<p>They sound a little too low level for a typical ML workflow and I would love to hear how you see these incorporate into your workflow. This will help us create a better feature that better fits your needs.</p>\n<p>Thanks!<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-27T21:36:38.045Z",
				"Answer_body": "<p>Hi Ramit,</p>\n<p>Thanks for the fast response! My use case is actually part of my research for my PhD, where I was lucky enough to publish <a href=\"https://arxiv.org/abs/2202.08679\" rel=\"noopener nofollow ugc\">a paper</a> about preprocessing pipeline optimizations at SIGMOD '22. You\u2019re very welcome to read it, but I will summarize some insights throughout this answer as well.</p>\n<p>I\u2019m generally focused on optimizing DL training pipelines, as we have seen multiple instances of underutilized hardware, be it due to inefficient user-level code, inefficient placement of jobs, or naive assumptions about performance that might often not hold (such as preprocessing being trivially parallelizable for example).</p>\n<p>To directly answer your question, page faults and inodes were helpful to me to double-check how application-level caching was implemented in TF and to be maximally sure where data is read from, as debugging remote storage performance is not always deterministic. It is basically just a helpful tool to be sure of the current status of the pipeline.</p>\n<p>Tracking context switches was the only way to get a glimpse as to why tiny sample sizes (&lt;0.01MB) were deserialized very slowly with the TFRecord format, and why the speedup going from 1 to 8 threads was missing entirely.</p>\n<p>The main reason why I think it might be helpful to include these system metrics is for debugging and performance tuning reasons. My first impression of W&amp;B was a one-stop solution for tracking experiments and iterating on their performance, be it an ML model accuracy or the training time. Due to the nature of many people renting accelerators to run ML experiments, I think it might be very nice to have a way to efficiently allocate them by knowing how well specific system resources are used, or what the current bottleneck is. (e.g., renting a better CPU node vs. one with a bigger memory if a deserialization bottleneck removes the effects of caching).</p>\n<p>The potential of adding these metrics would allow for a better comparison between heterogeneous hardware or even different DL software stacks, e.g., webdataset+Torch, datasets+Torch, DALI+TF, and their mixes. Right now it is not very easy to estimate if, for example, decoding JPEGs on the GPU is actually favorable for actual training throughput and accuracy as you reduce the GPU memory.</p>\n<p>With additional system metrics, this becomes an easier task, especially if you can hand off these logs from the ML \u201ctraining-person\u201d to the ML \u201csystems-optimizer-we-should-spend-less-money-on-resources-person\u201d <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"> Automatically analyzing these logs also seems to be like quite a good business opportunity <img src=\"https://emoji.discourse-cdn.com/twitter/innocent.png?v=12\" title=\":innocent:\" class=\"emoji\" alt=\":innocent:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<p>But I would also be very glad if you would add at least the disk/network read/writes for the time being.<br>\nCreating a system to add specific system metrics to your profiling runs is not an easy task to do, especially if somebody like me comes around and might demand even more esoteric things like TCP or UDP stats.</p>\n<p>I figure this might slightly change your platform\u2019s focus not only for ML practitioners, but also target ML-SysOps people, but I very much hope that you are interested in that as well!</p>\n<p>And sorry for this wall of text!</p>\n<p>Alex</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-03T23:23:48.352Z",
				"Answer_body": "<p>Hi Alex,</p>\n<p>Thank you for that very detailed and insightful response regarding your request! I definitely see why this could be useful for optimizing features now, I had never considered how the rate of context switches could have a performance impact on the performance of an ML pipeline.</p>\n<p>I\u2019ll definitely go ahead and make a feature request for this, and I\u2019ll keep you updated on the status of this request.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-05-16T14:32:44.005Z",
				"Answer_body": "<p>Thank you a lot, Ramit!</p>\n<p>Maybe a short follow-up from my side - I decided to implement the system metric tracking manually with <code>wandb.log()</code> for now, as the essential condition for my profiling is to use the system metrics in a sweep and optimize for different optimization (system-level) targets. The default frequency by which it is recorded right now is unfortunately not high enough to allow quick experiments that run &lt; 1min (e.g., an epoch on CIFAR, which encompasses data loading, data preprocessing, inference and backpropagation)</p>\n<p>One easy example would be having <code>batch_size</code> and <code>network_down_mb_s</code> and being able to compare the increase of the network bandwidth with the batch size.</p>\n<p>While my high-frequency needs might be too specific, having the system metrics available to pick in the hyperparameter parallel coordinates chart would be awesome in the long run.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-15T14:33:27.379Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Custom settings for wandb.Object3D",
		"Question_link": "https://community.wandb.ai/t/custom-settings-for-wandb-object3d/2351",
		"Question_created_time": "2022-05-02T02:39:24.070Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 236,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I wonder if <a class=\"mention-group notify\" href=\"/groups/team\">@team</a> can add some custom seetings for wandb.Object3D.<br>\nAf first I tried to use Plotly to achieve custom 3D point cloud visualization, but I saw team says Plotly is not supported now in github issue.<br>\nFor example, point size, backgorund color, etc.<br>\nIt would be really nice for 3D task.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-04T13:52:37.046Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/justice\">@justice</a>, I can put in a feature request for this. Could you elaborate a little more about the specific controls you were hoping for so I can better communicate with the engineering team all of the controls you were hoping to have?</p>\n<p>Also, is the issue with Plotly specificly related to 3D objects or Plotly in general? We do support adding Plotly charts but if there is an issue with uploading 3D Plotly objects I can see if this is intended behavior or a bug.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-05T03:44:58.715Z",
				"Answer_body": "<blockquote>\n<p>Also, is the issue with Plotly specificly related to 3D objects or Plotly in general?</p>\n</blockquote>\n<p>I\u2019m not sure about other Plotly function is function properly or not, but at least I\u2019m sure about Plotly 3D object isn\u2019t function properly in wandb\u2019s table. Here\u2019s  the realted  <a href=\"https://github.com/wandb/client/issues/2191#issuecomment-841452278\" rel=\"noopener nofollow ugc\">github issue</a> I found.</p>\n<blockquote>\n<p>Could you elaborate a little more about the specific controls you were hoping for so I can better communicate with the engineering team all of the controls you were hoping to have?</p>\n</blockquote>\n<ol>\n<li>point size control</li>\n<li>background color control</li>\n<li>relative coordinates on the side of the charts to get an idea of the 3d object\u2019s size</li>\n<li>customizable default view angle (in the thumbnail)</li>\n<li>mesh support</li>\n<li>voxel support</li>\n<li>separate color arrays, rather then tied with point sets defaultly. (Optional, since users can still do some array operations to change that in current wandb.Object3D.</li>\n</ol>\n<p>Thanks in advanced!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-05T03:56:08.729Z",
				"Answer_body": "<p>Also, I think it would be great if wandb can support a time lapse video/gif demonstrating how the prediction deformed/changed along with epochs without doing a lot of coding.</p>\n<p>I know users can do it in various ways, but it would be a nice  feature to have if wandb can support it natively and effortlessly, no matter it\u2019s an image or a 3D object.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-09T15:59:23.756Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/justice\">@justice</a> thank you for the details! I\u2019ll capture this and pass it on to our engineering team and will follow up with you here if we are able implement any of these features.</p>\n<p>Does the workaround of converting the Plotly figure to html and wrapping it in a <code>wandb.Html()</code> object work for some of these features in the meantime?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-09T16:20:23.526Z",
				"Answer_body": "<p>I\u2019m not sure about if <code>wandb.Html()</code> will work or not.<br>\nI\u2019m not so familiar with html, but I don\u2019t think html can do something like rotating the 3d object as in <strong>Plotly</strong>? I didn\u2019t really give it a try through.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-13T23:54:55.254Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/justice\">@justice</a>, I wanted to check in and see if you had gotten the chance to try out the HTML method. I\u2019ve went ahead and put in a feature request but wanted to see if this was working as a temporary workaround?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-12T23:55:50.417Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "[Solved] How to create model comparison table",
		"Question_link": "https://community.wandb.ai/t/solved-how-to-create-model-comparison-table/2416",
		"Question_created_time": "2022-05-13T14:04:44.607Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 310,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi all! In the YOLOv5 tutorial there is an excellent table comparing the model runs side by side. I\u2019m not sure how to create it - can anyone give any advice? The tutorial is located here:  <a href=\"https://wandb.ai/glenn-jocher/yolov5_tutorial/reports/YOLOv5-COCO128-Tutorial-Results--VmlldzozMDI5OTY\" class=\"inline-onebox\">Weights &amp; Biases</a></p>\n<p>and the table I\u2019m looking to recreate is this:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/0b8e2068bea1ab2b410430e5668fa688a2201fda.jpeg\" data-download-href=\"/uploads/short-url/1EdKVW3ukTzAAcyxW6wBQuGijvY.jpeg?dl=1\" title=\"demo-model-comparison\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0b8e2068bea1ab2b410430e5668fa688a2201fda_2_690x365.jpeg\" alt=\"demo-model-comparison\" data-base62-sha1=\"1EdKVW3ukTzAAcyxW6wBQuGijvY\" width=\"690\" height=\"365\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0b8e2068bea1ab2b410430e5668fa688a2201fda_2_690x365.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0b8e2068bea1ab2b410430e5668fa688a2201fda_2_1035x547.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0b8e2068bea1ab2b410430e5668fa688a2201fda_2_1380x730.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0b8e2068bea1ab2b410430e5668fa688a2201fda_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">demo-model-comparison</span><span class=\"informations\">3062\u00d71624 365 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Thanks for the help!!</p>\n<p>EDIT: Figured it out by searching for the term \u201cdiff only\u201d that appears in the top left. If anyone is wondering, you create a new panel and select \u201cRun Comparer\u201d. Leaving this up in case anyone has the same question <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-13T14:11:28.454Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/iankelk\">@iankelk</a>!</p>\n<p>That\u2019s called a Run Comparer panel, and you can created it by clicking <code>+ Add Panel</code> in the top right of your workspace, and choosing Run Comparer.</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/ref/app/features/panels/run-comparer\">\n  <header class=\"source\">\n      \n\n      <a href=\"https://docs.wandb.ai/ref/app/features/panels/run-comparer\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://www.gitbook.com/cdn-cgi/image/height=640,width=1280,fit=contain,dpr=1,format=auto/https%3A%2F%2F1039519455-files.gitbook.io%2F~%2Ffiles%2Fv0%2Fb%2Fgitbook-x-prod.appspot.com%2Fo%2Fspaces%252F-Lqya5RvLedGEWPhtkjU%252Fsocialpreview%252Fue7fU3AWqmkPrLvIA1sg%252Flogo.png%3Falt%3Dmedia%26token%3Dc5fd7a6b-2501-4ee8-9a85-bcef4bb40fdc\" class=\"thumbnail onebox-avatar\" width=\"500\" height=\"500\">\n\n<h3><a href=\"https://docs.wandb.ai/ref/app/features/panels/run-comparer\" target=\"_blank\" rel=\"noopener\">Run Comparer</a></h3>\n\n  <p>Compare metrics across multiple runs</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-13T14:12:24.243Z",
				"Answer_body": "<p>Thanks Scott! I found it almost immediately after posting by googling \u201cweights and biases diff only\u201d. Thanks for such an amazingly fast response!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-12T14:13:17.412Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to draw many images with a bar",
		"Question_link": "https://community.wandb.ai/t/how-to-draw-many-images-with-a-bar/2391",
		"Question_created_time": "2022-05-10T09:42:20.664Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 180,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I can only draw image with [wandb.Image(Numpy.array()),] like this</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://discourse.aicrowd.com/t/maskrcnn-integrated-with-wandb-and-direct-submit-from-colab/3961\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b48aa9bfc94603e638f56ff8452ed88b900f00db.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https://discourse.aicrowd.com/t/maskrcnn-integrated-with-wandb-and-direct-submit-from-colab/3961\" target=\"_blank\" rel=\"noopener nofollow ugc\" title=\"11:54AM - 20 November 2020\">AIcrowd Forum \u2013 20 Nov 20</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:600/325;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/e05a631c976b165047261523c356b3fa7e5eab41.gif\" class=\"thumbnail animated\" width=\"600\" height=\"325\"></div>\n\n<h3><a href=\"https://discourse.aicrowd.com/t/maskrcnn-integrated-with-wandb-and-direct-submit-from-colab/3961\" target=\"_blank\" rel=\"noopener nofollow ugc\">MaskRCNN integrated with WandB and DIRECT SUBMIT FROM COLAB!</a></h3>\n\n  <p>Hi everyone!    @rohitmidha23 and me have been following this challenge for quite a while. We have written a starter notebook using MaskRCNN. We further integrate MaskRCNN with WandB which really helps to keep track of the various experiments that...</p>\n\n  <p>\n    <span class=\"label1\">Reading time: 1 mins \ud83d\udd51</span>\n      <span class=\"label2\">Likes: 17 \u2764</span>\n  </p>\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n<p>\nBut how can I draw many images with a bar like this<br>\n<a href=\"https://sooftware.io/static/fd6ffa741fe53de299a57e6a8852f68d/f312c/wandb_image.webp\" class=\"onebox\" target=\"_blank\" rel=\"noopener nofollow ugc\">https://sooftware.io/static/fd6ffa741fe53de299a57e6a8852f68d/f312c/wandb_image.webp</a></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-11T08:41:46.823Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/langelo\">@langelo</a>, by bar do you mean the step slider?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-13T09:03:54.120Z",
				"Answer_body": "<p>Oh\uff0cyes! I got it ,the step slider.<br>\nIt\u2019s on the left top of my panel. Thanks!<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/7477d027660f227b355c1b7090095a0ca0e72264.png\" alt=\"FireShot Capture 043 - warm-sea-50 - deepfillv2_512x512_dv5_0pv8_1 \u2013 Weights &amp; Biases_ - 192.168.23.40\" data-base62-sha1=\"gCk5gzKgcCCqUAxrDVgTMn9CtF2\" width=\"274\" height=\"249\"></p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-07-12T09:04:26.645Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Mean of two different groups on the same plot",
		"Question_link": "https://community.wandb.ai/t/mean-of-two-different-groups-on-the-same-plot/2407",
		"Question_created_time": "2022-05-11T21:16:21.483Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 90,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I have multiple replicates of two algorithms running. I\u2019d like to group by the algorithm and then plot the resulting mean accuracy over time. This should lead to two lines for the two different groups. What\u2019s the best way to do this? I played around with the group variables without too much success.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-11T23:40:40.040Z",
				"Answer_body": "<p>Hi Lalit,</p>\n<p>I will look into this for you. Can you please provide me a code snippet of what you are attempting to do and also a link to your work space so I could reference your work.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-10T21:17:20.365Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to log absolutely everything on the console?",
		"Question_link": "https://community.wandb.ai/t/how-to-log-absolutely-everything-on-the-console/1896",
		"Question_created_time": "2022-02-10T21:02:27.078Z",
		"Question_answer_count": 4,
		"Question_score_count": 3,
		"Question_view_count": 325,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019ve had a few jobs die without any information on my wandb log of what happened. I wonder if there is some logging level that is implicitly set that doesn\u2019t allow me to see why it ended at X epochs randomly rather than the end.</p>\n<p>Is there a way to set it to print everything?</p>\n<ul>\n<li>perhaps there is a way to debug this with the extra system stuff wandb already logs?</li>\n</ul>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-20T11:53:38.039Z",
				"Answer_body": "<p>Sorry this didn\u2019t get a reply, I\u2019ve forwarded this to Support.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-21T11:39:06.729Z",
				"Answer_body": "<p>Hey Brando, checking on this for you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-11T16:33:02.951Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/brando\">@brando</a>, apologies about the lack of updates on this. At the moment there is no logging level that does what you want. I have filed a ticket for the engineering team to consider adding the functionality.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-10T16:33:30.826Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Weird login error with wandb?",
		"Question_link": "https://community.wandb.ai/t/weird-login-error-with-wandb/2379",
		"Question_created_time": "2022-05-07T17:17:43.759Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 166,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Error</p>\n<pre><code class=\"lang-auto\">---- Running your python main ----\nwandb=&lt;module 'wandb' from '/home/miranda9/miniconda3/envs/meta_learning_a100/lib/python3.9/site-packages/wandb/__init__.py'&gt;\nwandb: W&amp;B API key is configured. Use `wandb login --relogin` to force relogin\nwandb: Network error (ReadTimeout), entering retry loop.\nwandb: Network error (ReadTimeout), entering retry loop.\nProblem at: /home/miranda9/ultimate-utils/ultimate-utils-proj-src/uutils/logging_uu/wandb_logging/common.py 25 setup_wand\nwandb: ERROR Error communicating with wandb process\nwandb: ERROR try: wandb.init(settings=wandb.Settings(start_method='fork'))\nwandb: ERROR or:  wandb.init(settings=wandb.Settings(start_method='thread'))\nwandb: ERROR For more info see: https://docs.wandb.ai/library/init#init-start-error\nTraceback (most recent call last):\n  File \"/home/miranda9/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/experiment_mains/main_diversity_with_task2vec.py\", line 323, in &lt;module&gt;\n    main()\n  File \"/home/miranda9/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/experiment_mains/main_diversity_with_task2vec.py\", line 254, in main\n    args: Namespace = load_args()\n  File \"/home/miranda9/diversity-for-predictive-success-of-meta-learning/div_src/diversity_src/experiment_mains/main_diversity_with_task2vec.py\", line 247, in load_args\n    setup_wand(args)\n  File \"/home/miranda9/ultimate-utils/ultimate-utils-proj-src/uutils/logging_uu/wandb_logging/common.py\", line 25, in setup_wand\n    wandb.init(project=args.wandb_project,\n  File \"/home/miranda9/miniconda3/envs/meta_learning_a100/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 999, in init\n    run = wi.init()\n  File \"/home/miranda9/miniconda3/envs/meta_learning_a100/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 653, in init\n    raise UsageError(error_message)\nwandb.errors.UsageError: Error communicating with wandb process\ntry: wandb.init(settings=wandb.Settings(start_method='fork'))\nor:  wandb.init(settings=wandb.Settings(start_method='thread'))\nFor more info see: https://docs.wandb.ai/library/init#init-start-error\n</code></pre>\n<p>Why is this happening and what is the solution?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-10T22:19:23.551Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/brando\">@brando</a>,</p>\n<p>I\u2019m sorry to hear you are facing this. This error usually occurs due to multiprocessing and issues with the OS. I\u2019m curious if you have tried the 2 suggestions in the error message:</p>\n<pre><code class=\"lang-auto\">wandb.init(settings=wandb.Settings(start_method='fork'))\nwandb.init(settings=wandb.Settings(start_method='thread'))\n</code></pre>\n<p>and if either of them worked for you. Additionally, could you share what operating system you are running your code on?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-16T20:00:53.705Z",
				"Answer_body": "<p>Hi Brando,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-09T22:19:42.435Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Recreating wandb plots with matplotlib/seaborn",
		"Question_link": "https://community.wandb.ai/t/recreating-wandb-plots-with-matplotlib-seaborn/2303",
		"Question_created_time": "2022-04-22T11:08:05.152Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 876,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have been using w&amp;b for a few months and have had a great experience with it. However, I have had some trouble with including the diagram in my report. Under *more actions &gt; export panel \u2026 * there exist options for exporting the panel to PNG, SVG, PDF, and CSV. I want to export the panel to PDF with vectorized graphics and text but the PDF export seems to simply render the panel to PNG.</p>\n<p>What I have tried:</p>\n<ul>\n<li>exporting to SVG, but I was not able to convert this format to pdf or any other format suitable for my LaTeX report. I have been unable to use SVG files in my LaTeX report directly.</li>\n<li>creating a report of the panel and downloading the report as LaTeX, but again it renders the plots as PNG which is not desired in my case.</li>\n</ul>\n<p>Perhaps I am missing something, but as a final resort I have tried recreating the plots in wandb with the Export API in the following code snippet:</p>\n<pre><code class=\"lang-python\">import wandb\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\napi = wandb.Api()\n\n# Project is specified by &lt;entity/project-name&gt;\nruns = api.runs(\"&lt;wandb-id&gt;/&lt;entity-project-name&gt;\")\nhist_list = [] \nfor run in runs: \n    if not 'val/loss' in run.summary:\n        continue\n\n    name = run.config['model']['_target_'].split('.')[-1]\n    hist = run.history(keys=['epoch', 'val/loss'])\n    hist['name'] = name\n    hist_list.append(hist)\n\ndf = pd.concat(hist_list, ignore_index=True)\ndf = df.query(\"`val/loss` != 'NaN'\")\n\nsns.lineplot(x=\"epoch\", y=\"val/loss\", hue=\"name\", data=df)\nplt.show()\n</code></pre>\n<p>The script takes a long time to run (10 seconds) and comparing the output with the panel in the w&amp;b dashboard we have the following two plots</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/96ee4d13b86074c85b617696f6eb1306b1fde22a.png\" data-download-href=\"/uploads/short-url/lxcb3jp5qj9Tu3wiJDqNxbIHY1Q.png?dl=1\" title=\"my fig\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/96ee4d13b86074c85b617696f6eb1306b1fde22a_2_690x343.png\" alt=\"my fig\" data-base62-sha1=\"lxcb3jp5qj9Tu3wiJDqNxbIHY1Q\" width=\"690\" height=\"343\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/96ee4d13b86074c85b617696f6eb1306b1fde22a_2_690x343.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/96ee4d13b86074c85b617696f6eb1306b1fde22a.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/96ee4d13b86074c85b617696f6eb1306b1fde22a.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/96ee4d13b86074c85b617696f6eb1306b1fde22a_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">my fig</span><span class=\"informations\">964\u00d7480 40.8 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/50ee331e0f5890b1feed33198e4e7e4b3e04f3aa.png\" data-download-href=\"/uploads/short-url/bxWxmqbCJuvxst6H9WgGcA170lY.png?dl=1\" title=\"wandb fig\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/50ee331e0f5890b1feed33198e4e7e4b3e04f3aa_2_690x263.png\" alt=\"wandb fig\" data-base62-sha1=\"bxWxmqbCJuvxst6H9WgGcA170lY\" width=\"690\" height=\"263\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/50ee331e0f5890b1feed33198e4e7e4b3e04f3aa_2_690x263.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/50ee331e0f5890b1feed33198e4e7e4b3e04f3aa_2_1035x394.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/50ee331e0f5890b1feed33198e4e7e4b3e04f3aa_2_1380x526.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/50ee331e0f5890b1feed33198e4e7e4b3e04f3aa_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">wandb fig</span><span class=\"informations\">1516\u00d7580 69 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>The two plots have a noticeable difference. So I have two questions:</p>\n<ul>\n<li>Is it possible to export a panel to pdf with selectable text?</li>\n<li>If not, is there any reference for recreating the plots in wandb?</li>\n</ul>\n<p>Any help is appreciated <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<p><strong>EDIT</strong></p>\n<p>I found a github thread that explains my problem a bit better: <a href=\"https://github.com/wandb/client/issues/1446#issuecomment-1029293004\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Custom Charts: Export Panel Feature \u00b7 Issue #1446 \u00b7 wandb/client \u00b7 GitHub</a></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-26T17:21:03.919Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevjn\">@kevjn</a>, thank you for writing in and I\u2019m glad you\u2019re enjoying our product!</p>\n<p>Currently there isn\u2019t a way to export the panel with selectable text but I can put in a feature request around this if you would like? It sounds like this would solve most of your issues. I believe the issue here was the way that Vega wants to render charts but I can talk to our engineering team and see if there is a way around this.</p>\n<p>I don\u2019t have any specific references for recreating plots in Python but are you using custom charts? If so, you can access the Vega code that was used to create the chart in the UI and use that locally to recreate the chart.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-27T09:39:52.203Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nathank\">@nathank</a>, I am not using custom charts - the charts are rendered by default in the dashboard. Where can I access the Vega code and data used to populate the charts?</p>\n<p>I did get around my issue by exporting to CSV and doing some acrobatics with pandas and matplotlib, but I would prefer an easier way of doing it.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-10T14:37:39.885Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/kevjn\">@kevjn</a> Unfortunately, only the custom charts are created with Vega and our standard charts are actually written in Javascript.</p>\n<p>I think using your acrobatics to make Matplotlib work will be the best workaround for now. I\u2019ve put in the feature request for exporting text- selectable PDF and can follow up with you if we are able to implement this feature.</p>\n<p>I apologize that I don\u2019t have a better workaround for you in the meantime.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-09T14:38:03.434Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Account deletion",
		"Question_link": "https://community.wandb.ai/t/account-deletion/2386",
		"Question_created_time": "2022-05-10T07:31:42.800Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 250,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\nI created two accounts by accident. Would you please delete this account (kaminski)?<br>\nIs there a cool-down to use the email address bound to this account again? Because I would like to add it, my academic address, as the primary address to my main account (jkaminski).</p>\n<p>Cheers</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-10T08:11:10.638Z",
				"Answer_body": "<p>Hey Johannes, I\u2019ve deleted your account. You should be able to add it as the primary address for the other account</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-09T08:11:51.319Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How does one save a plot in wandb with wandb.log?",
		"Question_link": "https://community.wandb.ai/t/how-does-one-save-a-plot-in-wandb-with-wandb-log/2373",
		"Question_created_time": "2022-05-05T22:15:27.254Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 251,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m trying to save a plot with wandb.log. Their <a href=\"https://docs.wandb.ai/guides/track/log/plots\">docs</a> say to do:</p>\n<pre><code class=\"lang-auto\">    wandb.log({\"chart\": plt})\n</code></pre>\n<p>but this fails for me.</p>\n<p>I get two errors, 1st error (when I do NOT do <code>plt.show()</code> before trying to do wand.log):</p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_exec2.py\", line 3, in Exec\n    exec(exp, global_vars, local_vars)\n  File \"&lt;input&gt;\", line 1, in &lt;module&gt;\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 256, in wrapper\n    return func(self, *args, **kwargs)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 222, in wrapper\n    return func(self, *args, **kwargs)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1548, in log\n    self._log(data=data, step=step, commit=commit)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1339, in _log\n    self._partial_history_callback(data, step, commit)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1228, in _partial_history_callback\n    self._backend.interface.publish_partial_history(\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/wandb/sdk/interface/interface.py\", line 541, in publish_partial_history\n    data = history_dict_to_json(run, data, step=user_step, ignore_copy_err=True)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/wandb/sdk/data_types/utils.py\", line 54, in history_dict_to_json\n    payload[key] = val_to_json(\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/wandb/sdk/data_types/utils.py\", line 82, in val_to_json\n    val = Plotly.make_plot_media(val)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/wandb/sdk/data_types/plotly.py\", line 48, in make_plot_media\n    val = util.matplotlib_to_plotly(val)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/wandb/util.py\", line 560, in matplotlib_to_plotly\n    return tools.mpl_to_plotly(obj)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/plotly/tools.py\", line 112, in mpl_to_plotly\n    matplotlylib.Exporter(renderer).run(fig)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/plotly/matplotlylib/mplexporter/exporter.py\", line 53, in run\n    self.crawl_fig(fig)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/plotly/matplotlylib/mplexporter/exporter.py\", line 124, in crawl_fig\n    self.crawl_ax(ax)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/plotly/matplotlylib/mplexporter/exporter.py\", line 146, in crawl_ax\n    self.draw_collection(ax, collection)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/plotly/matplotlylib/mplexporter/exporter.py\", line 289, in draw_collection\n    offset_order = offset_dict[collection.get_offset_position()]\nAttributeError: 'LineCollection' object has no attribute 'get_offset_position'\n</code></pre>\n<p>I get two errors, 2nd error (when I DO <code>plt.show()</code> before trying to do wand.log):</p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_exec2.py\", line 3, in Exec\n    exec(exp, global_vars, local_vars)\n  File \"&lt;input&gt;\", line 1, in &lt;module&gt;\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 256, in wrapper\n    return func(self, *args, **kwargs)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 222, in wrapper\n    return func(self, *args, **kwargs)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1548, in log\n    self._log(data=data, step=step, commit=commit)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1339, in _log\n    self._partial_history_callback(data, step, commit)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1228, in _partial_history_callback\n    self._backend.interface.publish_partial_history(\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/wandb/sdk/interface/interface.py\", line 541, in publish_partial_history\n    data = history_dict_to_json(run, data, step=user_step, ignore_copy_err=True)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/wandb/sdk/data_types/utils.py\", line 54, in history_dict_to_json\n    payload[key] = val_to_json(\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/wandb/sdk/data_types/utils.py\", line 82, in val_to_json\n    val = Plotly.make_plot_media(val)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/wandb/sdk/data_types/plotly.py\", line 48, in make_plot_media\n    val = util.matplotlib_to_plotly(val)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/wandb/util.py\", line 560, in matplotlib_to_plotly\n    return tools.mpl_to_plotly(obj)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/plotly/tools.py\", line 112, in mpl_to_plotly\n    matplotlylib.Exporter(renderer).run(fig)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/plotly/matplotlylib/mplexporter/exporter.py\", line 53, in run\n    self.crawl_fig(fig)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/plotly/matplotlylib/mplexporter/exporter.py\", line 122, in crawl_fig\n    with self.renderer.draw_figure(fig=fig, props=utils.get_figure_properties(fig)):\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/contextlib.py\", line 119, in __enter__\n    return next(self.gen)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/plotly/matplotlylib/mplexporter/renderers/base.py\", line 45, in draw_figure\n    self.open_figure(fig=fig, props=props)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/plotly/matplotlylib/renderer.py\", line 90, in open_figure\n    self.mpl_x_bounds, self.mpl_y_bounds = mpltools.get_axes_bounds(fig)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/site-packages/plotly/matplotlylib/mpltools.py\", line 265, in get_axes_bounds\n    x_min, y_min, x_max, y_max = min(x_min), min(y_min), max(x_max), max(y_max)\nValueError: min() arg is an empty sequence\n</code></pre>\n<p>Note that their trivial example DOES work:</p>\n<pre><code class=\"lang-auto\">import matplotlib.pyplot as plt\n\nplt.plot([1, 2, 3, 4])\nplt.ylabel(\"some interesting numbers\")\nwandb.log({\"chart\": plt})\n</code></pre>\n<p>for me.</p>\n<hr>\n<p>cross posted: <a href=\"https://stackoverflow.com/questions/72134168/how-does-one-save-a-plot-in-wandb-with-wandb-log\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">python - How does one save a plot in wandb with wandb.log? - Stack Overflow</a></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-09T21:30:52.813Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/brando\">@brando</a>,</p>\n<p>I\u2019m sorry you are facing this. Could you share the code snippet you were using to generate this chart? I\u2019ll test this on my end and see how this can be resolved.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-12T22:18:46.528Z",
				"Answer_body": "<p>Hi Brando,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-08T21:31:40.625Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Accessing a run that was saved offline",
		"Question_link": "https://community.wandb.ai/t/accessing-a-run-that-was-saved-offline/2372",
		"Question_created_time": "2022-05-05T18:33:56.353Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 436,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m running experiments on an environment with no internet connection, and I have some issues running wand locally. I can save the run in offline mode.</p>\n<p>I\u2019d like to access the logs/artifacts/tables using the public API (I have that already implemented), but by giving a path to the relevant experiment\u2019s wandb directory (and not with the <code>entity/project/run_id</code> run_id format)?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-09T17:25:01.658Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/shlomihod\">@shlomihod</a>,</p>\n<p>If you would like to use the API to fetch data, unfortunately the only way right now is to log the files in the directory to a W&amp;B instance (local or our cloud). Seeing as you do not have access to the internet, the only solution in this case would be to set up a local instance.</p>\n<p>Could you share what issues you are seeing with trying to set up your local instance? We can help get it going for you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-12T21:08:42.181Z",
				"Answer_body": "<p>Hi Shlomi,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-08T17:25:08.459Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Azure Artifact Referencing",
		"Question_link": "https://community.wandb.ai/t/azure-artifact-referencing/2376",
		"Question_created_time": "2022-05-06T19:10:51.629Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 99,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Following doesn\u2019t work for us. Is their any way to solve the following problems for Artifact reference with  <strong>Azure Blob Storage</strong>:</p>\n<ol>\n<li>\n<p>How should we pass credentials to wandb ? As for Amazon S3 and GCS the priority and env variables are mentioned in docs.</p>\n</li>\n<li>\n<p>It was recommended that by passing <strong>az://</strong> as prefix will work similar to whats done s3 bucket and gcs.  However I didn\u2019t see any storage handler in wandb code for azure. I wonder how would it work just by passing a prefix ? Furthermore, unlike boto for s3 and google-cloud-storage sdk for gcs. I don\u2019t see any requirement of azure-storage in requirements.txt. Is their any Microsoft Azure Storage SDK for Python somewhere in code that I can not find ??</p>\n</li>\n<li>\n<p>Although it doesn\u2019t make any sense still I gave it a try, and as expected. Following are the results.</p>\n</li>\n</ol>\n<pre><code class=\"lang-auto\">run = wandb.init(project=\"Dummy_Training\", job_type=\"upload\")\nbucket = 'az://azurestorage.blob.core.windows.net/container_name'\ndataset_at = wandb.Artifact('sample',type=\"raw_data\")\n\ndataset_at.add_reference(bucket)\nrun.log_artifact(dataset_at)\nrun.finish()\n</code></pre>\n<p>And I get the following Error</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d74321689bbd477953afb77691a5b5ee70505085.jpeg\" data-download-href=\"/uploads/short-url/uIitV3rWGuO3hAvgAkyuvwPTnF3.jpeg?dl=1\" title=\"6853D58492F2404D8EAC586087E55373\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d74321689bbd477953afb77691a5b5ee70505085_2_682x500.jpeg\" alt=\"6853D58492F2404D8EAC586087E55373\" data-base62-sha1=\"uIitV3rWGuO3hAvgAkyuvwPTnF3\" width=\"682\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d74321689bbd477953afb77691a5b5ee70505085_2_682x500.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d74321689bbd477953afb77691a5b5ee70505085_2_1023x750.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d74321689bbd477953afb77691a5b5ee70505085.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d74321689bbd477953afb77691a5b5ee70505085_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">6853D58492F2404D8EAC586087E55373</span><span class=\"informations\">1202\u00d7881 264 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<ol start=\"4\">\n<li>Do I need to pass something in name parameter? What would be the entry name for azure?<br>\nSeems like az:// is defiantly not in your known handlers</li>\n</ol>\n<p><strong>Is their any way for Azure Artifact Referencing (azure blob storage) to work. And please let me know if their is any thing that I am missing. Any example for the resolution of this problem will be much appreciated.</strong></p>\n<p>Thanks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-06T19:13:39.199Z",
				"Answer_body": "<p>And I also didn\u2019t see any storage handler in wandb code for azure.<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/518cfc9b6ac1a236c9bf6f8214201bfb3c9ea0ce.png\" alt=\"C1BCD638F8B84BF0A7F85024A39F405A\" data-base62-sha1=\"bDqJKaAKdDJiE6LewUjkZ94mvaS\" width=\"620\" height=\"407\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-06T19:14:39.070Z",
				"Answer_body": "<p>And I also didnt see a way to pass azure credential to wandb in the artifact referencing document.<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9418fe0d93a9475617d384530096373e8e15cfa9.png\" alt=\"F9B220A31E5648CCA496FEE206CDCF27\" data-base62-sha1=\"l88d7kEe3th26ci9aH7qXvyQa8N\" width=\"642\" height=\"232\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-09T17:02:44.792Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hassanw65\">@hassanw65</a>. Unfortunately Azure reference artifacts aren\u2019t supported currently. We have a ticket created with our engineering team and increased the priority for it. I will let you know when there are updates.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-08T17:03:14.598Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "About hyperparameters sweeping for DDP program",
		"Question_link": "https://community.wandb.ai/t/about-hyperparameters-sweeping-for-ddp-program/2384",
		"Question_created_time": "2022-05-09T15:16:25.291Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 159,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I have a program which needs multiple GPUs to run at the same time, currently I use DDP to launch the program. I wonder how can I do the sweeping , the program will still be launched  in DDP mode (using all GPUs) at each trial. Thanks!</p>\n<p>Best</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-10T23:06:21.538Z",
				"Answer_body": "<p>Hi Weipeng,</p>\n<p>I am happy to help you with this. Are you using PyTorch or PyTorch lightning?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-16T17:05:49.053Z",
				"Answer_body": "<p>Hi Weipeng,</p>\n<p>I am following up on your recent issue with DDP. If you require further assistance please let do reach out again.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-19T20:19:22.507Z",
				"Answer_body": "<p>Hi Weipeng,</p>\n<p>As we have not heard back from you, I\u2019ll be closing this ticket. But please do reach out again at anytime if you need any assistance.</p>\n<p>Regards,</p>\n<p>Mohammad</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-08T15:17:18.395Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Logging Date Objects",
		"Question_link": "https://community.wandb.ai/t/logging-date-objects/2263",
		"Question_created_time": "2022-04-19T17:00:30.533Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 456,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey everyone!</p>\n<p>I\u2019m looking for a way to log Dates. I want to show the evolution of our labeled data over time over non-uniform time steps. To make it more clear, let\u2019s say I want to display the amount of data on arbitrary days. If I ran my W&amp;B run on those days, I could distinguish them by <code>run:createdAt</code>. The plots could display them as dates as one would expect and everything is fine.  Now, this fails as soon as I want to have a starting date AND an end date. Therefore I\u2019m looking to log date data.</p>\n<p>The functionality should be there, as it is for <code>createdAt</code>,  but I can\u2019t figure out how to log my own. I couldn\u2019t find a suitable object in the docs and neither POSIX timestamp nor iso format/datetime objects work out of the box.</p>\n<p>Is there no way to do this, or did I overlook something?</p>\n<p>As a workaround I could just use the POSIX timestamp as scale, but I guess we all agree that\u2019s a little unwieldy.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-19T22:41:18.450Z",
				"Answer_body": "<p>Hi Thomas,</p>\n<p>I looked into this and it looks like there is no good way to upload date data currently. I agree that this is definitely something we want to support, I\u2019ll create a feature request for this and keep you updated on the progress of this feature.</p>\n<p>For now, a POSIX timestamp is the only way to upload this data.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-06T19:39:38.767Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tsteffek\">@tsteffek</a>,</p>\n<p>Here is one way to do what you want to acheive, through our Tables:</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/7204b693004bf73705dcc6bae6452a1dc1a9312f.gif\" alt=\"Timeseries\" data-base62-sha1=\"ggEwPGiUOZrkxn985dV6lRnr4AL\" width=\"690\" height=\"401\" class=\"animated\"></p>\n<p>Let me know if this helps with what you are looking for.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-10T18:37:41.399Z",
				"Answer_body": "<p>Hi Thomas,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-05T19:40:35.412Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How do I query whether a run object is disabled (`RunDisabled`)?",
		"Question_link": "https://community.wandb.ai/t/how-do-i-query-whether-a-run-object-is-disabled-rundisabled/2256",
		"Question_created_time": "2022-04-17T19:14:57.307Z",
		"Question_answer_count": 9,
		"Question_score_count": 2,
		"Question_view_count": 206,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Given a <code>run</code> object (such as the one retuned by <code>wandb.init()</code>, what\u2019s the right way to query its status?<br>\nE.g. `run.status == \u2018RunDisabled\u2019?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-18T07:54:47.591Z",
				"Answer_body": "<p>Hey there,</p>\n<p>The run object returned by wandb.init() doesn\u2019t have a state attribute but the run object that is returned by our Public API does.</p>\n<p>Here is an example you can use:</p>\n<p>api = wandb.Api()<br>\nrun = api.run(\u2018entity/project/run_id\u2019)<br>\nrun.state</p>\n<p>Best,<br>\nArman</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-19T16:31:43.776Z",
				"Answer_body": "<pre><code class=\"lang-auto\">wandb_run = wandb.init(\n  entity=\"my_entity\",\n  project=\"my_project\",\n  job_type=\"my_cool_job\",\n  mode=\"disabled\"\n)\n\napi = wandb.Api()\nrun = api.run(f\"my_entity/my_project/{wandb_run.id}\")\n</code></pre>\n<p>Returns an error: <code>wandb.errors.CommError: Could not find run &lt;Run ...  (not found)&gt;</code></p>\n<p>Please advise - am I doing something wrong?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-21T11:14:18.444Z",
				"Answer_body": "<p>Yes, you are initializing the experiment in disabled mode which will just mock out all the wandb method calls. So the run doesn\u2019t really exist.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-22T15:25:34.249Z",
				"Answer_body": "<p>Hi Arman,</p>\n<p>Sorry, I\u2019m not feeling I\u2019m getting a clear answer here. Let me rephrase my question: Given a <code>run</code> object as returned by <code>wand.init()</code> (or a <code>run id</code>), how do I find out if it\u2019s a valid run (i.e. not <code>disabled</code>)?<br>\nCan you provide a short and concise code to implement this check?</p>\n<p>Thanks,<br>\nRan</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-03T03:42:42.164Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/ranshadmi-nexite\">@ranshadmi-nexite</a>, apologies about the delay on this. I found a workaround for this. You can use this code snippet to check if the run is disabled:</p>\n<pre><code class=\"lang-auto\">run = wandb.init()\nisinstance(run.mode, wandb.sdk.lib.disabled.RunDisabled)\n</code></pre>\n<p>If the run is not disable, run.mode type will be string, if it is disabled, the isinstance call will return True.</p>\n<p>Please let me know if this works for you.</p>\n<p>Best,<br>\nArman</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-03T11:27:16.886Z",
				"Answer_body": "<p>What you suggest would work. I also found another workaround which doesn\u2019t require the <code>run</code> variable to be supplied (and is slightly prettier I think):</p>\n<pre><code class=\"lang-auto\">import wandb\nprint(\"active\" if isinstance(wandb.run, wandb.sdk.wandb_run.Run) else \"inactive\")\n</code></pre>\n<p>What do you think?</p>\n<p>Anyway I think you guys in W&amp;B need to provide a simpler and more concise API call to get the current run status. Just my thought.</p>\n<p>Thanks,<br>\nRan</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-05T15:27:05.981Z",
				"Answer_body": "<p>Yeah that should work as well. Thanks for the feedback <a class=\"mention\" href=\"/u/ranshadmi-nexite\">@ranshadmi-nexite</a>. I\u2019ll share it with the team. In the meantime i just want to make sure that you don\u2019t have any other questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-05T16:47:51.792Z",
				"Answer_body": "<p>No further questions regarding this topic, thank you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-04T16:47:54.525Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to build a sweeps model for different numbers of hidden layers?",
		"Question_link": "https://community.wandb.ai/t/how-to-build-a-sweeps-model-for-different-numbers-of-hidden-layers/2363",
		"Question_created_time": "2022-05-03T12:11:09.475Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 153,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am making a simple network in PyTorch with linear units as a practise project. I\u2019d like to use sweeps to find the best hyper parameters for the network. Some of these hyperparameters include batch_norm, dropout value, number of hidden layers, number of units in each hidden layer.</p>\n<p>I can\u2019t figure out how to set up the model and sweep config so that two different model structures can be swept without being confusing. For example, I want to use batch_norm OR have dropout values of <code>[0, 0.2, 0.4, 0.5]</code>. I never want <code>batch_norm</code> AND <code>dropout</code> to be used. If I use random search with wandb, it may choose both <code>0.4</code> dropout AND <code>batch_norm</code> which I don\u2019t want.</p>\n<p>I know how to set up the network class with simple if statements so it adds either <code>batch_norm</code> or <code>dropout</code>, but the <code>wandb.config</code> would still select a value for <code>dropout</code> and a boolean for <code>batch_norm</code>, and I don\u2019t want the sweep report to show both these parameters if the network only uses one.</p>\n<p>Another example is, I\u2019d like 2, 3, 4 or 5 hidden layers. I\u2019d also like each layer to have a randomly selected  number of neurons from the range <code>[64, 128, 256, 512]</code>.</p>\n<p>I can forsee a problem where wandb will select the model to have 3 hidden layers but also pick say, 256 neurons for the 4th or 5th layer which will be misleading on the sweep parameter graph.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-04T11:53:14.056Z",
				"Answer_body": "<p>Hey Gary, at the moment this is not possible unfortunately. But we are planning to add conditional sweeps in the near future which will address your use-case.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-03T11:53:14.663Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb upload limit / request limit should not stop execution of script",
		"Question_link": "https://community.wandb.ai/t/wandb-upload-limit-request-limit-should-not-stop-execution-of-script/2311",
		"Question_created_time": "2022-04-24T10:29:55.742Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 220,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>my scripts regularly slow down significantly because I run into the wandb upload limit/ request limit.<br>\nE.g. getting <code>429 encountered (Filestream rate limit exceeded, retrying in 4.902817452929678 seconds), retrying request</code></p>\n<p>Is there a way to set wandb to \u201csoft uploads\u201d, i.e. uploading data whenever possible but never stopping/pausing the execution of the main script?</p>\n<p>Thanks so much!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-26T11:56:19.310Z",
				"Answer_body": "<p>Hey Tim, I\u2019ll double-check with the team on this and get back to you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-28T23:07:08.226Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/frtim\">@frtim</a>,</p>\n<p>From the error you can see that we will retry writing to wandb once the rate limit retry is hit. Can you let me know how often you are logging your code as you can adjust how often your model writes to wandb as noted in here in the docs: <a href=\"https://docs.wandb.ai/ref/python/run#log\" class=\"inline-onebox\">wandb.Run - Documentation</a> under <code>log</code>,</p>\n<p>Thank you,<br>\nAnish</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-02T14:12:48.120Z",
				"Answer_body": "<p>\u200bHi <a class=\"mention\" href=\"/u/frtim\">@frtim</a> ,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nAnish</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-05T18:01:29.111Z",
				"Answer_body": "<p>Hi Tim, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-01T14:13:44.156Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "(unsolved) How to set spacing between monitoring points(default 30s)?",
		"Question_link": "https://community.wandb.ai/t/unsolved-how-to-set-spacing-between-monitoring-points-default-30s/1780",
		"Question_created_time": "2022-01-18T01:32:40.749Z",
		"Question_answer_count": 9,
		"Question_score_count": 0,
		"Question_view_count": 247,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>The default interval of monitoring points for GPU utilization is the 30s. How can I set this time?</p>\n<p>In my model, the latency of one batch is shorter than the 30s. So I don\u2019t think this interval is suitable.<br>\nCan I modify it by setting any variable?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-18T04:08:20.421Z",
				"Answer_body": "<p>I modify the two function <code>sample_rate_seconds(self)</code> and <code>sample_rate_average(self)</code> in <code>stats.py</code>. The path of <code>stats.py</code> is <code>&lt;Python_Path&gt;\\Lib\\site-packages\\wandb\\sdk\\internal\\stats.py</code>.</p>\n<p>And the default value is 2 and 15. I don\u2019t know how it works, so I set it as small as possible.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-18T05:26:57.685Z",
				"Answer_body": "<p>There are some notes in code,</p>\n<blockquote>\n<p>\u201c\u201d\u201cSample system stats every this many seconds, defaults to 2, min is 0.5\"\u201d\"<br>\n\u201c\u201d\u201cThe number of samples to average before pushing, defaults to 15 valid range (2:30)\u201d\"\"</p>\n</blockquote>\n<p>Finally, the interval is 1s. Have any other way to make the interval shorter? Like 0.5s?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T12:01:14.369Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-22T15:14:20.158Z",
				"Answer_body": "<p>Hi Boqian, according to lines 85-87 in this code (<a href=\"https://github.com/wandb/client-ng/blob/fa51b2fbaf12a22a3e48f8c9c2c157642986946b/wandb/internal/stats.py#L85\" class=\"inline-onebox-loading\" rel=\"noopener nofollow ugc\">https://github.com/wandb/client-ng/blob/fa51b2fbaf12a22a3e48f8c9c2c157642986946b/wandb/internal/stats.py#L85</a>) we can\u2019t return anything faster than one second. However, if you\u2019re willing to edit the client code on your instance to where you make the interval shorter on your machine you can.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-22T16:43:44.280Z",
				"Answer_body": "",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-25T16:45:53.277Z",
				"Answer_body": "<p>Hi Boqian,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-28T18:07:46.648Z",
				"Answer_body": "<p>Hi Boqian, I\u2019m going to close this request because we haven\u2019t heard back from you but let me know if you need any further help!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-02T11:50:58.796Z",
				"Answer_body": "<p>Thanks a lot!</p>\n<p>I see, but I am still confused about why the min value is 0.5. Why not set it shorter? like 0.1?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-02T11:56:35.323Z",
				"Answer_body": "<p>Do you have any idea about how to show the GPU utilization per 0.1 seconds?<br>\nI think it is hard to continuously modify the client code to achieve that.<br>\nThanks!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Custom HTML with three.js for interactive 3D asset visualization",
		"Question_link": "https://community.wandb.ai/t/custom-html-with-three-js-for-interactive-3d-asset-visualization/2258",
		"Question_created_time": "2022-04-18T14:18:11.993Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 321,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I am working on a 3D reconstruction task that returns multiple 3D meshes in my visualization. The custom W&amp;B 3D visualization is too bright and it is not helpful for tasks that require to visualize texture; also, it seems to reduce the triangle counts, but triangle counts are important for 3D vision.</p>\n<p>It seems that W&amp;B supports uploading custom HTML.  I am wondering if it is possible to:</p>\n<ol>\n<li>Upload my predicted 3D meshes for each step.</li>\n<li>Display my 3D meshes using a custom HTML that using <a href=\"https://threejs.org/examples/#webgl_animation_keyframes\" rel=\"noopener nofollow ugc\">three.js</a> to allow me interact with it.</li>\n</ol>\n<p>Potential blockers:</p>\n<ul>\n<li>I assume <code>wandb.Object3D</code> is used with <code>wandb.log</code> to upload my 3D prediction. In my HTML, how do I get access to the uploaded meshes?</li>\n<li>Similarly, how do I upload and get access to a js library in the HTML? (the paths)</li>\n</ul>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-05-01T14:29:04.480Z",
				"Answer_body": "<p>Alosm curious about this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-30T14:29:55.774Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How can I add a table to a run after it has completed via the API?",
		"Question_link": "https://community.wandb.ai/t/how-can-i-add-a-table-to-a-run-after-it-has-completed-via-the-api/2334",
		"Question_created_time": "2022-04-27T19:47:44.988Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 148,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I would like to log a table to a wandb run, like shown here: <a href=\"https://docs.wandb.ai/guides/data-vis/tables-quickstart\">https://docs.wandb.ai/guides/data-vis/tables-quickstart</a></p>\n<p>The table will contain information about the performance of an RL agent in environments which differ from its training environment. I want to add the table to the wandb created during the training of the RL agent. Is this possible?</p>\n<p>Thanks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-29T19:42:20.636Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/jcoholich\">@jcoholich</a>,</p>\n<p>You can <a href=\"https://docs.wandb.ai/guides/track/advanced/resuming?q=resume\">resume</a> a run and log your table through that way.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-04T04:36:06.496Z",
				"Answer_body": "<p>Hi <strong><a class=\"mention\" href=\"/u/jcoholich\">@jcoholich</a></strong>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-10T19:13:04.965Z",
				"Answer_body": "<p>Hi Jeremiah, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-28T19:42:42.352Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Local runs are not being updated to server",
		"Question_link": "https://community.wandb.ai/t/local-runs-are-not-being-updated-to-server/2328",
		"Question_created_time": "2022-04-27T07:36:04.042Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 132,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Nothing is being logged on <a href=\"http://wandb.ai\">wandb.ai</a><br>\nSessions are being created but no graphs are being made and no codes are being saved.</p>\n<p>Are there issues with the server?<br>\nThis has been happening since yesterday and it\u2019s very frustrating since i can\u2019t see the graphs <img src=\"https://emoji.discourse-cdn.com/twitter/confused.png?v=12\" title=\":confused:\" class=\"emoji\" alt=\":confused:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-28T19:33:46.511Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ab3yang\">@ab3yang</a>,</p>\n<p>I\u2019m sorry you are not able to see the charts in your project. Do you have a link through which I can look into this? I\u2019m not sure I completely understand the exact behavior you are seeing, a link would be really helpful in understand this issue.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-02T16:47:43.956Z",
				"Answer_body": "<p>Hi Abe,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-05T19:20:15.808Z",
				"Answer_body": "<p>Hi Abe, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-27T19:34:14.500Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Adding values manually to run",
		"Question_link": "https://community.wandb.ai/t/adding-values-manually-to-run/2146",
		"Question_created_time": "2022-03-23T16:26:50.276Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 500,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey!</p>\n<p>I have some metrics which I cannot log during a run, but would like to attach to afterwards to also plot it. Is there a ways through the website or the CLI to manually attach a new value or metric?</p>\n<p>Greetings,<br>\nPatrick</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-21T19:49:45.340Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hallerpatrick\">@hallerpatrick</a>,</p>\n<p>Apologies about the delay here. You can not add metrics to a run\u2019s history, just the final value of a metric. As such, I don\u2019t believe metrics can be plotted this way.</p>\n<p>Please let me know how your metrics are logged, and we can try to find a solution for how this can be done.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-27T18:36:00.181Z",
				"Answer_body": "<p>\u200bHi <a class=\"mention\" href=\"/u/hallerpatrick\">@hallerpatrick</a>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,</p>\n<p>Weights &amp; Biases</p>\n<p>\u200b</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-27T20:13:01.215Z",
				"Answer_body": "<p>Hi,</p>\n<p>You can do something like this using the API.</p>\n<pre><code class=\"lang-auto\">import wandb\napi = wandb.Api()\n\nrun = api.run(\"ayut/petfinder-train/ejcxhnb3\")\nrun.summary[\"LB Score\"] = 18.70218\nrun.summary.update()\n</code></pre>\n<p>Here ayut/petfinder-train/ejcxhnb3 is the run path</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-26T20:13:56.458Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Account deletion request",
		"Question_link": "https://community.wandb.ai/t/account-deletion-request/2322",
		"Question_created_time": "2022-04-26T14:28:16.869Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 92,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Can you delete my account please? username realdionysus</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-26T15:09:30.206Z",
				"Answer_body": "<p>Hey Ramzi, the account is deleted. Best, Arman</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-25T15:10:32.733Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Suboptimal subsampling behavior",
		"Question_link": "https://community.wandb.ai/t/suboptimal-subsampling-behavior/2320",
		"Question_created_time": "2022-04-26T12:57:37.791Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 168,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am trying to build a plot of \u201closs/eval\u201d vs \u201ccompleted_steps\u201d. \u201closs/eval\u201d is the validation loss and it is logged once in a while. \u201ccompleted_steps\u201d is logged at every step. I would like to see all datapoints where \u201closs/eval\u201d is logged to be displayed in the plot, because there is not many of them (about 30 for each run). Instead I only see random ones because apparently the downsampling procedure is based on frequency of \u201ccompleted_steps\u201d logging. As a result the plots are not very informative;</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/bf980db958e2b3207bbe7973f8a99a123bb9cb84.png\" alt=\"image\" data-base62-sha1=\"rkUY9uzfHFfCzy1pCZMz1zVMVSs\" width=\"649\" height=\"305\"></p>\n<p>I think a better behavior when plotting a metric X against metric Y would be to fetch all (X, Y) pairs first and then downsample if there is too many such pairs.</p>\n<p>Can I hope to see improvements in downsampling logic at some point?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-28T15:21:47.615Z",
				"Answer_body": "<p>This discussion was followed up via email, but I\u2019ll follow up here once it\u2019s resolved</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-25T12:58:16.765Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Tracked hours difference in personal account vs team usage?",
		"Question_link": "https://community.wandb.ai/t/tracked-hours-difference-in-personal-account-vs-team-usage/2288",
		"Question_created_time": "2022-04-21T01:47:08.301Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 143,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Thanks for a great resource. I have a quick question on pricing. I\u2019m on the personal (free) account and <a href=\"https://wandb.ai/site/pricing\">I see here</a> that I have unlimited tracking hours:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9c83666d152fcb77e5641a77a84886c46f328d26.png\" data-download-href=\"/uploads/short-url/mkA0xRHM7AOXolpoKtYl3ViLpNs.png?dl=1\" title=\"Screenshot from 2022-04-20 21-31-22\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9c83666d152fcb77e5641a77a84886c46f328d26_2_208x500.png\" alt=\"Screenshot from 2022-04-20 21-31-22\" data-base62-sha1=\"mkA0xRHM7AOXolpoKtYl3ViLpNs\" width=\"208\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9c83666d152fcb77e5641a77a84886c46f328d26_2_208x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9c83666d152fcb77e5641a77a84886c46f328d26_2_312x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9c83666d152fcb77e5641a77a84886c46f328d26.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9c83666d152fcb77e5641a77a84886c46f328d26_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot from 2022-04-20 21-31-22</span><span class=\"informations\">351\u00d7841 24.4 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>On the same page, it says for team management, a personal account has 250 tracked hours.</p>\n<p>To clarify, does this mean that if I am running wandb for a team, and hit my 250 tracked hours, if I want to remain in the free tier while using the team, I will need to move the experiments to my personal account? Will this \u201cremove\u201d the tracked hours or will the tracked hours continue to count against the 250?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-25T17:26:00.956Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/danieltakeshi\">@danieltakeshi</a>,<br>\nI\u2019m glad you are enjoying our product! Are you looking to use W&amp;B as a team or as an individual user?</p>\n<p>If you do end up using a team to collaborate with others, then the 250 hour limit would be imposed on any runs created to the team.</p>\n<p>If you would like though, we can remove you from a team so that you can go back to creating runs to your personal account and not have the limit imposed?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-24T17:26:57.552Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "[Feature Request] W&B badge or shield for GitHub repositories",
		"Question_link": "https://community.wandb.ai/t/feature-request-w-b-badge-or-shield-for-github-repositories/2181",
		"Question_created_time": "2022-04-02T15:50:23.994Z",
		"Question_answer_count": 4,
		"Question_score_count": 4,
		"Question_view_count": 273,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I was wondering if it would be possible to have a simple W&amp;B/wandb badge to display on GitHub repositories, meaning: \u201cThis repository supports experiment tracking with wandb\u201d.</p>\n<p>By badge, I mean like below. The official wandb client repository for example uses pypi, codecov and circleci badges.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/2a8eb240dfb428a627280e4311324e7c0ec92188.png\" data-download-href=\"/uploads/short-url/64tMj9Dw36m9P2OBKPlPRcyIuBq.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2a8eb240dfb428a627280e4311324e7c0ec92188_2_690x151.png\" alt=\"image\" data-base62-sha1=\"64tMj9Dw36m9P2OBKPlPRcyIuBq\" width=\"690\" height=\"151\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2a8eb240dfb428a627280e4311324e7c0ec92188_2_690x151.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/2a8eb240dfb428a627280e4311324e7c0ec92188.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/2a8eb240dfb428a627280e4311324e7c0ec92188.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2a8eb240dfb428a627280e4311324e7c0ec92188_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">775\u00d7170 36 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-03T11:48:41.111Z",
				"Answer_body": "<p>this would be a nice idea!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-04T23:29:33.870Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dealer56\">@dealer56</a>!</p>\n<p>This is a great idea! I\u2019ll pass it on to our team to have this reviewed.</p>\n<p>Thanks,<br>\nRamit<br>\nWeights and Biases Support</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-22T21:46:15.454Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dealer56\">@dealer56</a>,</p>\n<p>I discussed this with some folks, and looks like we already have a <a href=\"https://img.shields.io/badge/Weights_&amp;_Biases-FFCC33?style=for-the-badge&amp;logo=WeightsAndBiases&amp;logoColor=black\" rel=\"noopener nofollow ugc\">badge</a> for something like this. You should also be able to generate such badges through <a href=\"http://shields.io\" rel=\"noopener nofollow ugc\">shields.io</a>, and we plan to have a tutorial in the future on how to use badges to present a metric on your repo.</p>\n<p>I\u2019ll link the tutorial once it is out.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-06-21T21:46:43.358Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "On premises W&B and inviting users to teams without email",
		"Question_link": "https://community.wandb.ai/t/on-premises-w-b-and-inviting-users-to-teams-without-email/2191",
		"Question_created_time": "2022-04-06T16:34:08.750Z",
		"Question_answer_count": 13,
		"Question_score_count": 1,
		"Question_view_count": 188,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m using an on-premises version of W&amp;B behind a corporate proxy. We\u2019re trying to create a team within our instance to collaborate on data. To do so, I go to the team settings (as the owner), and type in the username of the person I\u2019m trying to add. W&amp;B tries to send an email to the person. Because we\u2019re behind a SSL proxy, we get this error:</p>\n<pre><code class=\"lang-auto\">Something went wrong while trying to add the user &lt;USERNAME&gt;: Post \"https://api.sendgrid.com/v3/mail/send\": x509: certificate signed by unknown authority\n</code></pre>\n<p>Is there an option (like with signing up new users) to just copy an invite link to the clipboard to send ourselves? There doesn\u2019t seem to be a \u2018backdoor\u2019 way to add a user to a team, like through python code or an API. Am I missing something?</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-07T15:16:40.018Z",
				"Answer_body": "<p>Are you using a self-signed certificate for the HTTPS load balancer in front of your container? The simplest fix would be to use a trusted cert from <a href=\"https://letsencrypt.org\" rel=\"noopener nofollow ugc\">https://letsencrypt.org</a> or a trusted vendor like <a href=\"https://www.verisign.com\" rel=\"noopener nofollow ugc\">https://www.verisign.com</a>. You may be able to add the authority to the instance itself, but it\u2019s not officially supported today. If you did go this route you would need to run <code>sv restart gorilla</code> after updating the ca certificates.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-08T14:58:28.850Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/lesliewandb\">@lesliewandb</a> \u2013 I have, unfortunately, no control over the corporate proxy, and there is no additional HTTPS load balancer in front of the container either. Even if I added a nginx/traefik https reverse proxy, I would still be faced with getting out through the corporate firewall and errors on that end.</p>\n<p>On the user creation page, W&amp;B provides a \u201ccopy link\u201d rather than \u201cemail link\u201d button. Is the same capability available for the team invites? We can make the team/project completely public, which makes is \u2018public within the intranet\u2019 \u2013 that might be a viable solution but I would prefer not to rely on it.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-12T23:44:03.299Z",
				"Answer_body": "<p>Is there somebody that you can contact to do this? The CA certificate needs to be updated to get around this error</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-13T04:36:39.254Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tkott\">@tkott</a> , you can use our <a href=\"https://docs.wandb.ai/ref/python/public-api\">public API</a> to <a href=\"https://github.com/wandb/client/blob/1818b0395ffdbbadaae4353bc3b64ed343b0ffda/wandb/apis/public.py#L1137\" rel=\"noopener nofollow ugc\">invite users</a> to your team. The code snippet below should be able to guide you well.</p>\n<pre><code class=\"lang-auto\">api = wandb.Api()\nteam = api.team('your_team_name')\nteam.invite('user_email_id')\n</code></pre>\n<p>Please let us know in case of any further queries.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-13T17:51:46.907Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/anmolmann\">@anmolmann</a> unfortunately that (I believe) still tries to send an email using the same service that is unavailable through the UI. So the problem is still the need to \u201cinvite\u201d someone, rather than (as an admin, at least) being able to direclty \u201cadd\u201d someone without an invite.</p>\n<p>This is the error I get, which is unhelpful:</p>\n<pre><code class=\"lang-bash\">requests.exceptions.HTTPError: 500 Server Error: Internal Server Error for url: http://&lt;SERVER_URL&gt;/graphql\nwandb: Network error (HTTPError), entering retry loop.\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-13T17:58:55.427Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/lesliewandb\">@lesliewandb</a> : Short answer: no.</p>\n<p>Long answer: yes, but the answer to a request to avoid this problem will be no, or will come with so many caveats and gotchas and ruin the simplicity of the workflow that it would be irrelevant. This is a non-negotiable part of the job, unfortunately.</p>\n<p>I sincerely hope that W&amp;B will consider an option for site admins to be able to just add users to a team without invites, OR to allow team admins to copy / paste an invite link.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-19T16:47:08.086Z",
				"Answer_body": "<p>I see, thanks for the update <a class=\"mention\" href=\"/u/tkott\">@tkott</a>. You should be able to solve this by setting the following environment variable: <code>GORILLA_EMAIL_SINK=dummy://</code>.<br>\nIf you started the docker container using <code>wandb local</code>, you can restart the container with this env variable by running:</p>\n<pre><code class=\"lang-auto\">docker stop wandb-local \nwandb local -e GORILLA_EMAIL_SINK=dummy://\n</code></pre>\n<p>Or,<br>\nyou can also add <code>- \"GORILLA_EMAIL_SINK=dummy://\"</code> line in your <code>wandb</code> container in my docker-compose file.</p>\n<p>Please let me know if this helps resolving your issue.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-19T17:05:54.000Z",
				"Answer_body": "<p>Thanks for that ENV variable. What will that do in terms of the invite though? When faced with not being able to send an email, will it just print out the invite to the console? Or add them as originally envisioned?</p>\n<p>Thanks!</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/c068a531a4cb060559186c287c0508c8c7321469.jpeg\" alt=\"image001.jpg\" data-base62-sha1=\"rs7SiFek7tnQtx4wt2yshERms0p\" width=\"79\" height=\"79\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-19T17:21:52.863Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tkott\">@tkott</a> , this would make sure that you can add users to any teams without them needing to click on any invites as it\u2019ll turn off email sending and directly add them to teams. So, the the env var I just posted disables email sending.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-22T17:35:42.296Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tkott\">@tkott</a> , I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-22T17:59:04.000Z",
				"Answer_body": "<p>Hi, yes! This worked and we can now automatically add folks to a team. Thank you!</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/c068a531a4cb060559186c287c0508c8c7321469.jpeg\" alt=\"image001.jpg\" data-base62-sha1=\"rs7SiFek7tnQtx4wt2yshERms0p\" width=\"79\" height=\"79\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-22T18:35:12.249Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/tkott\">@tkott</a> , Happy to help!!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-21T18:35:35.726Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to use panels/sections configured for one run for all runs",
		"Question_link": "https://community.wandb.ai/t/how-to-use-panels-sections-configured-for-one-run-for-all-runs/2060",
		"Question_created_time": "2022-03-11T11:41:27.418Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 142,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>A couple of weeks ago I \u201clost\u201d the logged gradients in my wandb UI. Today I wanted to research why this might be the case (updated wandb to 0.12.11, changed <code>log-freq</code>, \u2026) but as it turns out (by chance) it is a visualisation issue. This is either a bug or a feature/setting that I miss. It might also be related to a bug/misunderstanding on my behalf that I have \u201clost\u201d sections/panels configurations in the wandb UI.</p>\n<p>When I list a couple of (toy) runs with one run visible (\u201ceye open\u201d) I see a certain layout of sections/panels. I have no gradients logged (see screenshot, section \u201cGradients\u201d. I have renamed it to uppercase and selected the option to also \u201cshow empty sections\u201d). That\u2019s what led me to believe that I have \u201clost\u201d the gradients.</p>\n<p>But when I select the run from above I can see both the run\u2019s gradient and the layout that I had changed.</p>\n<p>Can I somehow make the section/panel configuration of this run the default for all runs? I already applied \u201cCopy to default workspace\u201d (which has a different intention I think, but it was worth a try).</p>\n<p>Do I miss a setting or behaviour?</p>\n<p>See the 2 screenshots in the PNG (had to combine them, only 1 upload allowed).<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/1536b9c8180282ae0182c8834f883bea30622414.png\" data-download-href=\"/uploads/short-url/31Fh7BjMnQAFkMRbuNmt9Zl6feQ.png?dl=1\" title=\"Screenshots\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1536b9c8180282ae0182c8834f883bea30622414_2_594x500.png\" alt=\"Screenshots\" data-base62-sha1=\"31Fh7BjMnQAFkMRbuNmt9Zl6feQ\" width=\"594\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1536b9c8180282ae0182c8834f883bea30622414_2_594x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1536b9c8180282ae0182c8834f883bea30622414_2_891x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1536b9c8180282ae0182c8834f883bea30622414_2_1188x1000.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1536b9c8180282ae0182c8834f883bea30622414_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshots</span><span class=\"informations\">1894\u00d71592 232 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Thank you in advance!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-22T17:27:54.748Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hogru\">@hogru</a>,</p>\n<p>Apologies for the delay here. Currently, we do not support Predefined Layouts for workspaces, though this is already a planned feature. This has been becoming an increasingly common feature request recently, I\u2019ll make sure to increase the priority on this.</p>\n<p>I\u2019ll let you know when I hear back / there is some progress on this feature.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-21T17:28:39.585Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Table artifact to pandas dataframe",
		"Question_link": "https://community.wandb.ai/t/table-artifact-to-pandas-dataframe/2059",
		"Question_created_time": "2022-03-11T10:15:27.467Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 789,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I logged a table artifact.<br>\nNow I want to analyze it using pd.DataFrame.</p>\n<p>I\u2019ve downloaded the artifact.<br>\nHowever, I don\u2019t mange to convert the json into dataframe.<br>\nIs there a method for doing so?<br>\nThanks</p>\n<pre><code class=\"lang-auto\">import wandb\nimport pandas as pd\nimport os.path as osp\n\nrun = wandb.init()\nartifact = run.use_artifact('PATH/run-1n4emfxy-test_table:v19', type='run_table')\nartifact_dir = artifact.download()\npath_to_json = osp.join( next(iter(artifact._download_roots)), 'test_table.table.json')\npd.read_json(path_to_json)\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-22T11:44:32.650Z",
				"Answer_body": "<p>Hey Koby, sorry about the delay on this. At the moment the workaround is the following:</p>\n<pre><code class=\"lang-auto\">table = run.use_artifact(\"run-&lt;run-id&gt;-&lt;table-name&gt;:&lt;tag&gt;\").get(\"&lt;table-name&gt;\")\ndf = pd.DataFrame(data=table.data, columns=table.columns)\n</code></pre>\n<p>Best,<br>\nArman</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-26T03:09:24.908Z",
				"Answer_body": "<p>Hi Koby,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-21T11:44:49.790Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Adding tfRecords files to artifacts doesn't work?",
		"Question_link": "https://community.wandb.ai/t/adding-tfrecords-files-to-artifacts-doesnt-work/1948",
		"Question_created_time": "2022-02-18T16:05:59.797Z",
		"Question_answer_count": 9,
		"Question_score_count": 0,
		"Question_view_count": 225,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>I am trying logging my tfRecords files to artefact, but it seems to not be working (I get an error: \u201cwandb: Network error (TransientError), entering retry loop.\u201d).</p>\n<p>I am providing the code I use below. I am pretty sure it is something regarding the tfRecords file since I tried changing the contents of my folders to contain only .csv and .paqruet and it worked nicely. Do you have any ideas what could be happening here?</p>\n<pre><code class=\"lang-auto\">with wandb.init(project=\"----\", entity='----', job_type='saving_processed_files') as run:\n    train_data_art = wandb.Artifact(\n        name='train_data',\n        type='train_data'  \n    )\n\n    files_train = os.listdir(final_path_train)\n    files_train=[x  for x in files_train if x[0]!='.']\n\n    for file in files_train:\n        file_path = os.path.join(final_path_train, file)\n        train_data_art.add_file(file_path, name=file)\n\n    run.log_artifact(train_data_art)\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-02-18T23:21:12.490Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/drlje\">@drlje</a>,</p>\n<p>Is this error still popping up with TF Record files? Usually TransientErrors are minor network issues that automatically get resolved after a while.</p>\n<p>Please let me know if this error still persists and I will dig in further into what might be happening here in that case.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-22T18:02:59.790Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/drlje\">@drlje</a>,</p>\n<p>We wanted to follow up with you regarding this issue as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-25T20:23:30.807Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/drlje\">@drlje</a>,</p>\n<p>Since we have not heard back from you, I am closing out this request. If you would like to re-open this conversation, please let us know!</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-26T14:09:58.492Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a> ,</p>\n<p>Sorry for not being prompt. I tried again and I got the same error. However, I also tries doing this on a small fraction of data (also saved as a TFRecords) and it went through. So I am guessing this has something to do with the size - the total size of my files is around 10gb. Do you think that could be the issue?</p>\n<p>Thanks a lot!</p>\n<p>Marin</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-22T09:00:11.736Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a>,</p>\n<p>Do you have a feedback regarding the limit size of the files being uploaded? We are thinking to upgrade our account and this issue is really important for us.</p>\n<p>Thanks!</p>\n<p>Marin</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-13T14:29:02.000Z",
				"Answer_body": "<p>Hi,</p>\n<p>Could you please re-look at this issue - I have left additional comment a while ago, and in a couple of days we will face this issue again, so I would love to get to the bottom of it.</p>\n<p><a href=\"https://community.wandb.ai/t/adding-tfrecords-files-to-artifacts-doesnt-work/1948/6\">https://community.wandb.ai/t/adding-tfrecords-files-to-artifacts-doesnt-work/1948/6</a></p>\n<p>Thanks!</p>\n<p>Marin</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-14T17:33:53.146Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/drlje\">@drlje</a>,</p>\n<p>I\u2019m sorry about not responding here sooner. I\u2019m sorry to hear you are still facing this issue, and I will definitely assist you here. You said you are seeing an error with a lot of data : Could you share a little bit more  information about the structure of this data and the behavior you see? More specifically:</p>\n<ul>\n<li>How many files do you have?</li>\n<li>Are you seeing a lot of time delay before these errors show up?</li>\n<li>Could you try uploading this same scale of information but using some other file format? (like a set of <code>.txt</code> files)</li>\n</ul>\n<p>Additionally, the <code>debug.log</code> and <code>debug-internal.log</code> files associated with the run where you are facing this issue would be highly appreciated since it would give us some more visibility into this issue.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-22T06:54:30.577Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a>,</p>\n<p>In reproducing the issue today, the artifact was saved without any problems; so I guess the issue can be closed. If we experience the same problematic again, I will follow the steps above and supply you with the log files.</p>\n<p>Many thanks!</p>\n<p>Best,</p>\n<p>Marin</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-21T06:55:17.151Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb Project table value select algorithm",
		"Question_link": "https://community.wandb.ai/t/wandb-project-table-value-select-algorithm/2300",
		"Question_created_time": "2022-04-22T03:56:51.340Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 504,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have a wondering how to select value in project table.<br>\nWhat is algorithm in wandb project table to select values? In images, these values is not minimum in each models.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/5238ecb4f4a97cf42692282562cfbd48f3bb95da.png\" data-download-href=\"/uploads/short-url/bJn70ylkOmBrf45BJzAwLO3FLIe.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_690x99.png\" alt=\"image\" data-base62-sha1=\"bJn70ylkOmBrf45BJzAwLO3FLIe\" width=\"690\" height=\"99\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_690x99.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_1035x148.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_1380x198.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/5238ecb4f4a97cf42692282562cfbd48f3bb95da_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">2478\u00d7358 42.7 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-26T11:38:15.026Z",
				"Answer_body": "<p>Hey Byeongjun, I am not sure I fully understand the question. Could you please elaborate?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-29T14:12:11.733Z",
				"Answer_body": "<p>Hi Byeongjun,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-21T03:57:11.366Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to distinguish resumed runs during sweeps?",
		"Question_link": "https://community.wandb.ai/t/how-to-distinguish-resumed-runs-during-sweeps/2091",
		"Question_created_time": "2022-03-16T09:10:01.021Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 234,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m looking into WandB\u2019s Sweep feature for my next project and am currently trying to implement the resume-mechanism.</p>\n<p>I use the following code to restore my model:</p>\n<pre><code class=\"lang-python\">wandb.init(resume=True)\n\nif wandb.run.resumed:\n    model = wandb.restore(\"last.ckpt\")\nelse:\n    model = ... # instantiate new model\n</code></pre>\n<p>However,  <code>wandb.run.resumed</code> is apparently always <code>True</code>, since the wandb agent sets the <code>WANDB_RUN_ID</code>-environment variable, so restore fails for new runs. What is a good way to handle this?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-20T11:44:42.525Z",
				"Answer_body": "<p>Hi,<br>\nSorry this was missed, I have forwarded this to support.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-21T22:15:29.441Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/cschell\">@cschell</a>,</p>\n<p>I just tested this on my end <code>wandb.run.resumed</code> is only <code>True</code> when the last run which had been run in the directory had exits with a nonzero exit code. When the previous run exits with a zero exit code, <code>wandb.run.resumed</code> is <code>False</code>.</p>\n<p>I suspect you might always be getting <code>True</code> because the previous run crashes on <code>wandb.restore</code>. Could you try instantiating a new run which creates \u201clast.ckpt\u201d and then try resuming?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-27T19:16:27.069Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/cschell\">@cschell</a>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-02T16:22:59.620Z",
				"Answer_body": "<p>Hi Christian, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-20T22:16:11.593Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb for Huggingface Trainer saves only first model",
		"Question_link": "https://community.wandb.ai/t/wandb-for-huggingface-trainer-saves-only-first-model/2270",
		"Question_created_time": "2022-04-20T07:18:31.790Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 199,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I am finetuning multiple models using for loop as follows.</p>\n<pre><code class=\"lang-auto\">for file in os.listdir(args.data_dir):\n    finetune(args, file)\n</code></pre>\n<p>BUT <code>wandb</code> shows logs only for the first file in <code>data_dir</code> although it is training and saving models for other files. It feels very strange behavior.</p>\n<pre><code class=\"lang-auto\">wandb: Synced bertweet-base-finetuned-file1: https://wandb.ai/***/huggingface/runs/***\n</code></pre>\n<p>This is a small snippet of <strong>finetuning</strong> code with Huggingface:</p>\n<pre><code class=\"lang-auto\">def finetune(args, file):\n    training_args = TrainingArguments(\n        output_dir=f'{model_name}-finetuned-{file}',\n        overwrite_output_dir=True,\n        evaluation_strategy='no',\n        num_train_epochs=args.epochs,\n        learning_rate=args.lr,\n        weight_decay=args.decay,\n        per_device_train_batch_size=args.batch_size,\n        per_device_eval_batch_size=args.batch_size,\n        fp16=True, # mixed-precision training to boost speed\n        save_strategy='no',\n        seed=args.seed,\n        dataloader_num_workers=4,\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=tokenized_dataset['train'],\n        eval_dataset=None,\n        data_collator=data_collator,\n    )\n    trainer.train()\n    trainer.save_model()\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-20T19:56:12.331Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/kgarg8\">@kgarg8</a> , you\u2019ve set <code>save_strategy</code> to NO in your code to avoid saving anything. This would only save the final model once training is done with <code>trainer.save_model()</code> . You can update it to <code>save_strategy=\"epoch\"</code> and it will save the model with every epoch.</p>\n<p>Or, in order <a href=\"https://docs.wandb.ai/guides/integrations/huggingface#turn-on-model-versioning\">to log models</a>, you could also set the env var <code>WANDB_LOG_MODEL</code> as <a href=\"https://docs.wandb.ai/guides/integrations/huggingface#additional-w-and-b-settings\">specified in our docs here</a>. Once you set this env var, any Trainer you initialize from now on will upload models to your W&amp;B project. Note that your model will be saved to W&amp;B Artifacts as <code>run-{run_name}</code> .</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-21T14:50:51.674Z",
				"Answer_body": "<p><code>wandb.init(reinit=True)</code> and <code>run.finish()</code> helped me to log the models <strong>separately</strong> on wandb website.</p>\n<p>The working code looks like below:</p>\n<pre><code class=\"lang-auto\">\nfor file in os.listdir(args.data_dir):\n    finetune(args, file)\n\nimport wandb\ndef finetune(args, file):\n    run = wandb.init(reinit=True)\n    ...\n    run.finish()\n</code></pre>\n<p>Reference: <a href=\"https://docs.wandb.ai/guides/track/launch#how-do-i-launch-multiple-runs-from-one-script\" class=\"inline-onebox\">Launch Experiments with wandb.init - Documentation</a></p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-06-20T14:51:40.355Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Visualizations, metrics, etc. keep randomly appearing and disappearing",
		"Question_link": "https://community.wandb.ai/t/visualizations-metrics-etc-keep-randomly-appearing-and-disappearing/2283",
		"Question_created_time": "2022-04-20T19:34:11.598Z",
		"Question_answer_count": 9,
		"Question_score_count": 4,
		"Question_view_count": 175,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>This morning we were looking at the visualizations and charts on an active training run and everything was fine. After about 11am PDT, all of the visualizations started randomly disappearing. Sometimes only the loss charts would be visible, other times the losses and metrics and statistics would all be visible.</p>\n<p>The best I can tell is that the site is only showing charts for whatever things were in the most recent step. If you send some things less frequently, then their charts/visualizations disappear until they\u2019re in the step data again.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-20T19:39:58.684Z",
				"Answer_body": "<p>Exactly the same issue is happening on my side. Roughly about 11 am (PDT) some of the training and validation visualizations started to disappear for finished runs. In some cases only the last epoch metrics were visible but in some cases only one metric was visible.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T19:46:43.109Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/cogwheel\">@cogwheel</a> and <a class=\"mention\" href=\"/u/mehraveh\">@mehraveh</a>,<br>\nThank you for reporting and sorry for the issue. This is a current issue with our backend that is being fixed now. I\u2019ll update here shortly once this has been resolved.<br>\nThank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T21:06:35.626Z",
				"Answer_body": "<p>Just wanted to let you all know that the issue seems to be resolved on my end now. Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T21:59:37.541Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/nathank\">@nathank</a>  has this been fixed globally? I seem to be running into a similar issue.</p>\n<p>I log a metric after every epoch in the validation loop (and these 25hour epochs). I see the metric I logged in my summary section on the info page, but I don\u2019t see the chart with that metric on the charts page. And, I can\u2019t seem re-add it.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T22:28:14.644Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/fishbotics\">@fishbotics</a> the database is currently backfilling any metric information that was uploaded during the issue. Our engineering team said this may take a few hours for this process but your data should show up in the UI shortly. Feel free to ping me here if you notice after a couple of hours that you still are having issues.</p>\n<p>Thank you all for reporting this so we could get this resolved as quickly as possible</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T22:28:40.384Z",
				"Answer_body": "<p>Yeah, I\u2019m actually still seeing this problem on old runs. All of the images etc are there under files, but they\u2019re missing from the charts.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T22:33:58.572Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/cogwheel\">@cogwheel</a> Could you possibly send me a link to your workspace?  If you don\u2019t want to share here you can also email <a href=\"mailto:support@wandb.com\">support@wandb.com</a> and explain the issue and I can respond via email.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-04-20T23:05:39.144Z",
				"Answer_body": "<p>Sent</p>\n<p>Too short\u2026 Adding letters</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-19T23:05:41.654Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sweep over pre-training, then sweep over finetuning",
		"Question_link": "https://community.wandb.ai/t/sweep-over-pre-training-then-sweep-over-finetuning/2015",
		"Question_created_time": "2022-03-04T13:11:45.042Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 195,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019d like to pre-train a model under several different conditions, then finetune each of those resulting models. The simple way to do this would be two separate sweeps. But then I need to manually start the second one. Is there a way to combine these into one single sweep?</p>\n<p>With a bash script, I can simply call pre-train and finetune in sequence, passing the respective arguments via a config file. Is it somehow possible to tell the respective scripts that they are part of the same sweep and should therefore use certain parameters?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-20T20:53:36.012Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sgerard\">@sgerard</a>,</p>\n<p>I don\u2019t believe so. A sweep is inherently tied to its config, so there is no way to have 2 different configs - one for pre-training and one for fine-tuning.</p>\n<p>The only good way to do this currently is to have 2 sweeps to do this.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-27T19:16:58.009Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sgerard\">@sgerard</a>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-02T16:27:18.273Z",
				"Answer_body": "<p>Hi Sebastian, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-19T20:53:49.540Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Prevent wandb from eating output in distributed mode",
		"Question_link": "https://community.wandb.ai/t/prevent-wandb-from-eating-output-in-distributed-mode/1931",
		"Question_created_time": "2022-02-15T16:45:50.264Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 133,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Is there any way to stop wandb from gobbling up all the std out / logging output?<br>\nI\u2019m running wandb in distributed mode on rank=0 process, and wandb gobbles up all the output there.<br>\nHowever, rank=1 process still outputs stuff to stdout. So now if I want to see an error I have to look at both wandb logs and the server logs.</p>\n<p>I would like wandb to log its thing - but also leave the standard out where it was.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-20T12:00:14.389Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb login issue on git bash",
		"Question_link": "https://community.wandb.ai/t/wandb-login-issue-on-git-bash/2000",
		"Question_created_time": "2022-03-02T06:51:27.453Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 466,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>In the login process, this error occurs. It  says install \u201cMkl-service\u201d but the service has already installed and I had tried to fix this error but I was unable to do so</p>\n<p>$ wandb login<br>\nc:\\users\\great\\anaconda3\\lib\\site-packages\\numpy_<em>init</em>_.py:143: UserWarning: mkl-service package failed to import, therefore Intel(R) MKL initialization ensuring its correct out-of-the box operation under condition when Gnu OpenMP had already been loaded by Python process is not assured. Please install mkl-service package, see <a href=\"http://github.com/IntelPython/mkl-service\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">GitHub - IntelPython/mkl-service: Python hooks for Intel(R) Math Kernel Library runtime control settings.</a><br>\nfrom . import _distributor_init<br>\nwandb: Appending key for <a href=\"http://api.wandb.ai\">api.wandb.ai</a> to your netrc file: C:\\Users\\great/.netrc</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-22T16:17:17.405Z",
				"Answer_body": "<p>Hi Kushagra,</p>\n<p>Thank you for writing in! Can you double check for me that mkl-service  is properly installed? You can verify whether packages are installed by using <code>pip list</code> in the terminal</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-25T17:54:59.839Z",
				"Answer_body": "<p>Hi Kushagra,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-28T18:08:11.610Z",
				"Answer_body": "<p>Hi Kushagra, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-01T06:52:05.618Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Cumulative max (highwater mark) for distributed training and sweep",
		"Question_link": "https://community.wandb.ai/t/cumulative-max-highwater-mark-for-distributed-training-and-sweep/2072",
		"Question_created_time": "2022-03-14T14:29:30.761Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 207,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello everybody!<br>\nhave an algorithm that I run 10 times, and return the best run by a cumulative maximum - So for each run, I log the highest(cumulative) validation score of the entire run.</p>\n<p>I ran 7 of these, and grouped them together aggregating with maximum. However, since each experiment validates at different timestep, the resulting graph is not a cumulative maximum of the entire 7 runs. That happens because at each validation point, not all runs are present. What I got, with what I want to achieve marked in red:</p>\n<p><a href=\"https://i.stack.imgur.com/wrlxx.png\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/60ed9165396ec6c81826b4ec1203340a9f898494.png\" alt=\"enter image description here\" data-base62-sha1=\"dPsP625Jbrr920C7eeCL3YtRJVG\" width=\"690\" height=\"368\"></a></p>\n<ol>\n<li>Is this achievable?</li>\n<li>How can I set a sweep that uses the cumulative validation of the entire experiment (the red line,  not a single trial)?</li>\n</ol>\n<p>Thanks in advance!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-22T16:01:50.158Z",
				"Answer_body": "<p>Hi Eyal,</p>\n<p>This is possible! You can do this by clicking on the edit icon on the top right of the plot (it looks like a pencil) From there, go to the grouping tab and turn the runs toggle on. Afterwards, you can aggregate by max and see the graph that you wanted</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-25T18:32:13.870Z",
				"Answer_body": "<p>Hi Eyal,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-28T19:47:57.389Z",
				"Answer_body": "<p>Hi Eyal, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-13T14:30:04.443Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "I dont understand why my wandb_metadata.json file is showing this",
		"Question_link": "https://community.wandb.ai/t/i-dont-understand-why-my-wandb-metadata-json-file-is-showing-this/2199",
		"Question_created_time": "2022-04-07T20:33:19.905Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 189,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello, i am pretty new to this wandb function. I have been trying to run a program with it, but it shows an error of like this:<br>\nTraceback (most recent call last):<br>\nFile \u201cmain.py\u201d, line 105, in <br>\nmain()<br>\nFile \u201cmain.py\u201d, line 99, in main<br>\ntrainer.train(start_iteration=epoch)<br>\nFile \u201c/home/cs2212/Desktop/voxel2mesh-master/train.py\u201d, line 58, in train<br>\nloss = self.training_step(data, start_iteration)<br>\nFile \u201c/home/cs2212/Desktop/voxel2mesh-master/train.py\u201d, line 22, in training_step<br>\nloss, log = self.net.loss(data, epoch)<br>\nFile \u201c/home/cs2212/Desktop/voxel2mesh-master/model/voxel2mesh.py\u201d, line 214, in loss<br>\npred_points = sample_points_from_meshes(pred_mesh, 3000)<br>\nFile \u201c/home/cs2212/.local/lib/python3.8/site-packages/pytorch3d/ops/sample_points_from_meshes.py\u201d, line 55, in sample_points_from_meshes<br>\nareas, _ = mesh_face_areas_normals(<br>\nFile \u201c/home/cs2212/.local/lib/python3.8/site-packages/pytorch3d/ops/mesh_face_areas_normals.py\u201d, line 44, in forward<br>\nareas, normals = _C.face_areas_normals_forward(verts, faces)<br>\nRuntimeError: Not compiled with GPU support. (FaceAreasNormalsForward at /root/project/pytorch3d/csrc/face_areas_normals/face_areas_normals.h:51)</p>\n<p>The preprocessing data job was done fine, but as I try to run the program with the preprocessed data, the upper error happens</p>\n<p>I checked the metadata.json file and realized the cuda was set as null even though i checked the cuda was there with nvcc --version. I am guessing the wandb not realizing the cuda is there seems to be an issue. Are there any methods of how i could solve this? Any advice is appreciated Thank you</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-07T21:26:49.968Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/harrykwon97\">@harrykwon97</a>,</p>\n<p>Looking at the traceback of this error, this issue does not seem to be originating from wandb. The wandb library does not communicate with CUDA directly, nor is CUDA nessecary for wandb to operate, so I would not expect it to break because of wandb.</p>\n<p>It seems like the error actually originates from PyTorch3D, which would make sense since it would need to communicate to CUDA directly. I would suggest checking compatibility of your CUDA version with PyTorch 3D as a first step.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-14T19:58:00.804Z",
				"Answer_body": "<p>\u200bHi <a class=\"mention\" href=\"/u/harrykwon97\">@harrykwon97</a>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,</p>\n<p>Weights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-19T19:27:44.968Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/harrykwon97\">@harrykwon97</a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>\n<p>\u200b</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-18T19:28:07.692Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Export panel between sweeps",
		"Question_link": "https://community.wandb.ai/t/export-panel-between-sweeps/2186",
		"Question_created_time": "2022-04-04T08:13:33.695Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 344,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>Is there a way to export custom plots I created in one sweep to the dashboard of another?<br>\nSpecifically, I used the \u201cadd section\u201d button to create a new section, and added custom plots to it. I would like to move this section \\ panel as a whole to another sweep.</p>\n<p>Is it possible somehow? It could save me a lot of time instead of setting it again and again for every sweep.</p>\n<p>Thanks,<br>\nTom</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-04T20:53:39.698Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tomjur\">@tomjur</a>,</p>\n<p>Are you talking about our custom charts feature? If you are, we do allow for saving <a href=\"https://docs.wandb.ai/ref/app/features/custom-charts#saving-chart-presets\">chart presets</a>.</p>\n<p>Please let me know if this was not what you were looking for.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-05T07:56:53.509Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a> ,</p>\n<p>My use-case is that I have 3 metrics that I want to show on the same plot. For that I open a line plot and add the 3 metrics to the Y field. Each of those metrics is recorded and automatically displayed elsewhere, but I would like to see the combined plot automatically in new sweeps. I searched the UI according to the ref you sent, but I didn\u2019t see any option to save the plot.</p>\n<p>Thanks,<br>\nTom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-19T19:21:26.290Z",
				"Answer_body": "<p>Ah, I see what you are talking about. We have a planned feature that accomplishes this, but unfortunately it has not been implemented yet.</p>\n<p>I\u2019ll increase the priority on the feature, and I\u2019ll let you know as soon as I hear back about the progress of the feature.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-18T19:22:06.857Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Artifacts (local) caching - how does it really work?",
		"Question_link": "https://community.wandb.ai/t/artifacts-local-caching-how-does-it-really-work/2255",
		"Question_created_time": "2022-04-17T13:50:52.610Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 845,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi all,</p>\n<p>I\u2019m trying to figure out how does the caching  of artifacts work. Let\u2019s say I want to download a model artifact to run some evaluation on. I don\u2019t need the file on disk to persist rather I just want to load it into memory. What I do right now in my evaluation script is:</p>\n<pre><code class=\"lang-auto\">import tempfile\nimport wandb\n\nartifact = wandb.use_artifact(model_weights_uri)\nwith tempfile.TemporaryDirectory() as tmpdirname:\n    artifact.download(tmpdirname)\n    model_weights = load_pickle(os.path.join(tmpdirname, \"model_weights.pickle\"))\n</code></pre>\n<p>And from that point on I use the <code>model_weights</code> as it was loaded into memory.</p>\n<p>My first question is: if I run the code twice (on the same machine), <strong>will the model-weights be downloaded again</strong> or are they cached somewhere? assuming the logged artifact wasn\u2019t changed of course. And if they are cached, where are they cached?<br>\nI\u2019m also not clear about the <code>artifact</code> directory (which is used if I run <code>artifact.download()</code> without any argument). Does that directory serve as cache? if so, what does the <code>.cache</code> directory used for?</p>\n<p>I would appreciate answers to my questions and perhaps a  general explanation of the artifact caching mechanism &amp; best practices.</p>\n<p>Thanks!<br>\nRan</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-18T20:15:55.393Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ranshadmi-nexite\">@ranshadmi-nexite</a>,</p>\n<p>Thank you for your question. You are right, all Artifacts are cached on your system under <code>~/.cache/wandb/artifacts</code> and organized by their checksum. So if you try to download a file with checksum <code>x</code> and that file has been logged in an Artifact from your machine or downloaded to your machine as part of an artifact before, we just pull it from the cache by checking if there is a cached Artifact file with checksum <code>x</code>.</p>\n<p>So, if you run the same code twice, assuming the version of the artifact you are trying to download has not changed, the artifact can simply be pickked up from your cache directory.</p>\n<p>Also, when calling <code>artifact.download()</code> without any arguments, the artifact is saved in the directory in which the code is running. This, however,  is not the directory that serves as a cache, that still remains <code>.cache</code> which acts as a central location to look for artifacts before fetching it.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-04-18T20:16:02.526Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ranshadmi-nexite\">@ranshadmi-nexite</a>,</p>\n<p>Thank you for your question. You are right, all Artifacts are cached on your system under <code>~/.cache/wandb/artifacts</code> and organized by their checksum. So if you try to download a file with checksum <code>x</code> and that file has been logged in an Artifact from your machine or downloaded to your machine as part of an artifact before, we just pull it from the cache by checking if there is a cached Artifact file with checksum <code>x</code>.</p>\n<p>So, if you run the same code twice, assuming the version of the artifact you are trying to download has not changed, the artifact can simply be pickked up from your cache directory.</p>\n<p>Also, when calling <code>artifact.download()</code> without any arguments, the artifact is saved in the directory in which the code is running. This, however, is not the directory that serves as a cache, that still remains <code>.cache</code> which acts as a central location to look for artifacts before fetching it.</p>\n<p>Thanks,<br>\nRamit</p>\n<p>[Discourse post]</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-17T20:16:30.337Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Is there a way to change job_type?",
		"Question_link": "https://community.wandb.ai/t/is-there-a-way-to-change-job-type/2253",
		"Question_created_time": "2022-04-17T10:40:14.093Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 215,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hiya!</p>\n<p>Last night I ran an experiment and didn\u2019t bother to check the inputs to <code>wandb.init</code>. It turned out later that I mixed some things up and there was a mistake in <code>job_type</code> kwarg.  Now I am wondering is there a way to change this parameter (I really need it for grouping) through API or UI?</p>\n<p>Thanx</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-18T07:35:43.235Z",
				"Answer_body": "<p>Hey Ilya,</p>\n<p>At the moment, changing the job type is not possible. I\u2019ll file a ticket for this. As a workaround I\u2019d suggest tagging the runs using our Public API.</p>\n<p>Let me know if you have any questions.</p>\n<p>Best,<br>\nArman</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-04-21T11:17:01.342Z",
				"Answer_body": "<p>Hi Ilya,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-16T10:41:08.331Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Show single lines in groups",
		"Question_link": "https://community.wandb.ai/t/show-single-lines-in-groups/2245",
		"Question_created_time": "2022-04-14T20:29:45.659Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 80,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,<br>\nI want to have a way to organise my runs so that I can know some parameters of the runs already by the name. I can do that by using group_by and then I can see the different parameter for each run</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/7aefbd3b28fbf0ac496352f40ceb75e0975e1f00.png\" alt=\"image\" data-base62-sha1=\"hxxTc29jObSNMn9oZg3e64ZOA4U\" width=\"269\" height=\"195\"></p>\n<p>But this also means all the runs inside a group, is it possible to group but still see the different runs (optionally all runs in a group with the same color?)<br>\nThanks,</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-15T10:48:05.606Z",
				"Answer_body": "<p>Hey Oren, this is not possible with grouping. I\u2019d suggest to pass the <a href=\"https://docs.wandb.ai/ref/python/init\">name</a> argument when invoking wandb.init(). You can format the string with the values of the wandb.config dict.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-16T17:47:21.269Z",
				"Answer_body": "<p>Thanks,<br>\nThis is a shame, is it possible to add it as a feature request?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-27T15:31:01.255Z",
				"Answer_body": "<p>Hey Oren, sorry about the late reply. I\u2019ve shared your request with the team. Will notify you once there are updates on this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-26T20:26:52.905Z",
				"Answer_body": "<p>Hey Oren, another workaround I\u2019d suggest is to pin columns to achieve what you want.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-15T17:48:07.417Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Can you edit config of a run after it finishes?",
		"Question_link": "https://community.wandb.ai/t/can-you-edit-config-of-a-run-after-it-finishes/2247",
		"Question_created_time": "2022-04-15T20:22:38.436Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 148,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>A very bad practice, I know. But for a part of my experiment, the main file wasn\u2019t updated so it ignored some configs. Is it possible to manually add them into the runs, now that the runs are finished?</p>\n<p>If it helps, I don\u2019t need to add new entries to the config. I just need to add to an existing string in the config.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-15T22:00:23.990Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/aceticia\">@aceticia</a>,</p>\n<p>This is absolutely possible! Here is an example in our docs on how to do this : <a href=\"https://docs.wandb.ai/guides/track/public-api-guide#update-config-for-an-existing-run\">https://docs.wandb.ai/guides/track/public-api-guide#update-config-for-an-existing-run</a></p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-04-16T00:30:19.695Z",
				"Answer_body": "<p>Thank you so much! I haven\u2019t discovered this section of the doc before. Now it looks like a whole new world has opened.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-15T00:30:59.341Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Configuration for the Replication for sweep",
		"Question_link": "https://community.wandb.ai/t/configuration-for-the-replication-for-sweep/2246",
		"Question_created_time": "2022-04-15T04:27:35.854Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 132,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Is there a replication option for the sweep config?<br>\nI want to compare the average performance of my experiments more than one time due to variance in my experiments.</p>\n<p>Thaks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-15T10:38:31.858Z",
				"Answer_body": "<p>Hey there, we don\u2019t have that option at the moment but if you are using grid search one workaround that comes to mind is to add dummy parameter to your config like dummy: [1,2,3,4,5]. That way the  other hyperparameters will be tried 5 times.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-15T10:50:30.000Z",
				"Answer_body": "<p>Thanks!!</p>\n<p>2022\ub144 4\uc6d4 15\uc77c (\uae08) 19:48, Arman Harutyunyan via W&amp;B Community &lt;<a href=\"mailto:notifications@wandb.discoursemail.com\">notifications@wandb.discoursemail.com</a>&gt;\ub2d8\uc774 \uc791\uc131:</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-14T10:51:23.641Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Plot train and validation loss together by default?",
		"Question_link": "https://community.wandb.ai/t/plot-train-and-validation-loss-together-by-default/2235",
		"Question_created_time": "2022-04-13T14:54:32.467Z",
		"Question_answer_count": 2,
		"Question_score_count": 1,
		"Question_view_count": 115,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>By default wandb plots the loss and the validation loss in separate plots. I know it is possible to add plots and modify those existing plots, but for each new run it will appear like the default again. Is there a way to change this default on a project or acount basis?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-13T20:47:05.018Z",
				"Answer_body": "<p>Hi <span class=\"mention\">@apjensen</span>,</p>\n<p>Unfortunately it is not possible to do this by default in our UI yet. This is a planned feature however, I\u2019ll increase the priority on it and let you know as soon as we make some progress on this.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-12T20:47:58.388Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Passing arguments based on search parameters in sweep",
		"Question_link": "https://community.wandb.ai/t/passing-arguments-based-on-search-parameters-in-sweep/2221",
		"Question_created_time": "2022-04-12T08:53:36.910Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 185,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m running a grid-search sweep with a custom command of this sort:</p>\n<pre><code class=\"lang-auto\">project: my_project\nprogram: main.py\nname: grid_search\nmethod: grid\nmetric:\n  goal: maximize\n  name: eval_accuracy\nparameters:\n  learning_rate:\n    values: [1e-5, 5e-5, 1e-4]\n  batch_size:\n    values: [4, 8, 16]\ncommand:\n  - ${env}\n  - ${interpreter}\n  - ${program}\n  - \"--run_name\"\n  - \"${batch_size}_${learning_rate}\"\n  - ${args}\n</code></pre>\n<p>Note that when passing the <code>--run_name</code> argument I would like to condition it on the values of the search parameters <code>batch_size</code> &amp; <code>learning_rate</code>. I do not want to do this inside my code because the format might change between sweeps and I want my code to be generic.</p>\n<p>Is there a way to use the search parameters in other arguments? I tried using <code>${args_no_hyphens}</code> before my command so the variables would be defined but it didn\u2019t seem to work.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-13T14:49:20.967Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/navehp\">@navehp</a>, can you show me how you tried to use <code>${args_no_hyphens}</code>? I think this should work for your use case but maybe I\u2019m misunderstanding how it was used.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-12T14:49:21.338Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Hide Command from Overview Run Page",
		"Question_link": "https://community.wandb.ai/t/hide-command-from-overview-run-page/2231",
		"Question_created_time": "2022-04-13T00:53:59.532Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 264,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>On the Run Page (<a href=\"https://docs.wandb.ai/ref/app/pages/run-page\">https://docs.wandb.ai/ref/app/pages/run-page</a>) it shows on the left incognito that it shouldn\u2019t show your command when the public is viewing your page.</p>\n<p>However, on my page, when public and I view as not-me, it still shows the command that launched it, and that includes my Windows username, which I\u2019d rather not. I can\u2019t find anything to override or hide this. What am I missing?</p>\n<p>Thanks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-13T05:36:51.412Z",
				"Answer_body": "<p>Hey there, this seems to be a bug on our end. I am sharing this with the team so we can address this asap.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-12T05:37:39.375Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Information in tables disappearing",
		"Question_link": "https://community.wandb.ai/t/information-in-tables-disappearing/2215",
		"Question_created_time": "2022-04-11T05:26:21.916Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 280,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello!</p>\n<p>I have 39 runs in an experiment, all correctly finished with the corresponding tables per run correctly uploaded and available (when clicking on the specific run).</p>\n<p>I have 4 different tables, and combine the runs depending on the table ID (runs .summary[\u201ca\u201d], runs .summary[\u201cb\u201d], \u2026).</p>\n<p>2 of the combined tables are correctly outputted, but in 1 of the tables there is half the data available, and in the other a message of \u201cno rows to display\u201d is shown. If I re-upload the data of the \u201cno rows to display\u201d table, it is shown properly, but another table becomes empty, with the \u201cno rows to display\u201d message.</p>\n<p>Probably is due to the amount of rows can be processed at the same time? The total number of rows per run is 42, so 39x42 = 1638, which shouldn\u2019t be that much?</p>\n<p>Thank you!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-12T13:43:39.133Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/agirbau\">@agirbau</a>,<br>\nWould you mind sharing a link to the workspace so I can see what is going on?</p>\n<p>If you would rather not share here you can email me at <a href=\"mailto:support@wandb.com\">support@wandb.com</a></p>\n<p>I don\u2019t think this should be an issue with the number of rows since we support up to 200k rows so I would be interested to see what is going on here.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-13T04:29:36.661Z",
				"Answer_body": "<p>Hello Nate,</p>\n<p>I will send you an email with the link. Thanks!</p>\n<p>Andreu</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-26T22:46:20.173Z",
				"Answer_body": "<p>Hi Andreu,<br>\nI apologize for the delay on this. Are the panels working how you would expect now or is this still an issue? I see that there is data in all of the panels now.</p>\n<p>If not, let me know and I will look into this further.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-02T13:23:10.438Z",
				"Answer_body": "<p>Hi Andreu, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-12T04:29:47.510Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to continue a specific run after stopping?",
		"Question_link": "https://community.wandb.ai/t/how-to-continue-a-specific-run-after-stopping/2074",
		"Question_created_time": "2022-03-14T15:59:44.759Z",
		"Question_answer_count": 7,
		"Question_score_count": 1,
		"Question_view_count": 2707,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello, I am new to using wandb and I cant seem to wrap my head around how to continue a run after i stop it. I tried the wandb.restore and loading the weights from the \u201cwandb\\run-20220313_020710-18ws9vua\\files\u201d , but i seem to get the following error : \u201cwandb.errors.CommError: Could not find run\u201d .<br>\nIt seems that the run isn\u2019t unique? Do i need to set up something in the init ? Or am I just going about it all wrong?<br>\nThank you very much for your time !</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-14T21:57:06.406Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/frem\">@frem</a>,</p>\n<p>I\u2019m sorry you are facing this issue. Could you have a look at our <a href=\"https://docs.wandb.ai/guides/track/advanced/resuming#resuming-guidance\">Resuming Guide</a> to see if this resolves your issue?</p>\n<p>If not, I would really appreciate it if you could send a whole stack trace over, I\u2019ll help you debug this further.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-17T14:27:32.380Z",
				"Answer_body": "<p>Hello, it seems resume is the way to go. I tried to implement it but it doesn\u2019t seem to be working right.</p>\n<p>this is my code, I have removed everything that has to do with the training and pre-processing, when I first start training I have resume = False, and after I interrupt the run I change it to resume = True and run it again, but a new run starts, also the checkpoints folder I created is empty so no files have been saved .</p>\n<p>thank you very much for your time again !</p>\n<pre><code>def main():\n  #Weight and Biases\n  torch.manual_seed(0) # to fix the split result\n\n  CHECKPOINT_PATH = r'C:\\Users\\wandb\\checkpoints'\n\n  run = wandb.init(project=\"my-test-project\", entity=\"frem\",save_code=True, resume= True)\n  if wandb.run.resumed:\n    checkpoint = torch.load(wandb.restore(CHECKPOINT_PATH))\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    epoch = checkpoint['epoch']\n    train_batch_loss = checkpoint['train_batch_loss']\n    train_batch_acc = checkpoint['train_batch_acc']\n    epoch_train_loss = checkpoint['epoch_train_loss']\n    epoch_train_acc = checkpoint['epoch_train_acc']\n    epoch_val_loss = checkpoint['epoch_val_loss']\n    epoch_val_acc = checkpoint['epoch_val_acc']\n    best_loss = checkpoint['best_loss']\n    counter = checkpoint['counter']\n    early_stop = checkpoint['early_stop']\n\n   CONFIG =  dict(\n    model_conf= \"resnet50\",\n    lr_conf= 0.001,\n    max_epochs= 100,\n    batch_size= 32,\n    optimizer= \"Adam\",\n    loss_conf= \"CrossEntropyLoss\"\n   )\n   wandb.config = CONFIG\n   print(\"\\tWANDB SET UP DONE\")\n\n   # TRANSFORMS\n\n   # DATA SET UP\n\n   # MODEL SET UP\n\n    # Training and Validation\n\n    #after training 1 epoch I log these\n     wandb.log({\n            \"train_batch_loss\": train_batch_loss,\n            \"train_batch_acc\": train_batch_acc\n        })\n    \n      wandb.log({\n        \"epoch_train_loss\": torch.tensor(train_losses).mean(),\n        \"epoch_train_acc\": torch.tensor(train_accuracies).mean()\n      })\n\n      #after validation I log\n       \n       wandb.log({\n          \"epoch_val_loss\": torch.tensor(val_losses).mean(),\n          \"epoch_val_acc\": torch.tensor(val_accuracies).mean()\n       })\n \n     #and in in the end of the each epoch\n\n      torch.save({ # Save our checkpoint loc\n           'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'train_batch_loss': train_batch_loss,\n            'train_batch_acc': train_batch_acc,\n            'epoch_train_loss': torch.tensor(train_losses).mean(),\n            'epoch_train_acc': torch.tensor(train_accuracies).mean(),\n            'epoch_val_loss': torch.tensor(val_losses).mean(),\n            'epoch_val_acc': torch.tensor(val_accuracies).mean(),\n            'best_loss': best_loss,\n            'counter': counter,\n            'early_stop': early_stop,\n            }, CHECKPOINT_PATH)\n       wandb.save(CHECKPOINT_PATH) # saves checkpoint to wandb\n    \n    \n       torch.save(model.state_dict(), os.path.join('D:\\Art DataBase\\models',f\"{CONFIG['model_conf']}_{epoch}.pth\"))\n       wandb.save(os.path.join('D:\\Art DataBase\\models', f\"{CONFIG['model_conf']}_{epoch}.pth\"))</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-30T16:50:39.670Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/frem\">@frem</a>,</p>\n<p>Are you passing in the <code>id</code> of the previous run you are trying to resume? The SDK needs to know the ID in order to pick up the run where it left off. Odds are that <code>wandb.init()</code> is creating a new run ID and looking for that ID in your previous runs, which would explain the \u201cCould not find run\u201d error message you are recieving.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-04T16:07:55.674Z",
				"Answer_body": "<p>\u200bHi <a class=\"mention\" href=\"/u/frem\">@frem</a> ,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>\u200b</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-07T17:39:54.405Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/frem\">@frem</a> , since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-13T03:30:57.497Z",
				"Answer_body": "<p>Hi, I am a bit confused with how ids work, do I need to use WANDB_RESUME and WANDB_RUN_ID in order to set the id for the run, or  altering the way that I use wand.init to provide it with an existing id would solve the fact that it generates a new id each time.</p>\n<p>Also another problem is that in the specified path for the checkpoints there doesn\u2019t seem to be any files saved. I get an \u201cPermissionError: [Errno 13] Permission denied:\u201d when trying to save the checkpoint in a folder even though it saves all other information in the same script with no issue, I also tried running the script as admin and it gave me a \u201cwandb: Network error (ReadTimeout), entering retry loop.\u201d error and then the PermissionError again.</p>\n<p>Thanks again for your time !</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-12T03:31:48.423Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Invalid apollo response An application error occurred",
		"Question_link": "https://community.wandb.ai/t/invalid-apollo-response-an-application-error-occurred/2228",
		"Question_created_time": "2022-04-12T19:42:36.780Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 155,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am getting \u201cinvalid apollo response An application error occurred.\u201d when accessing the any sweep via the UI. The rest seems to work, e.g. I can access all my runs in the UI. What is going on here, how can i fix this?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-12T20:01:22.461Z",
				"Answer_body": "<p>Hi Manuel,<br>\nThis is an issue on our end. Our engineering team is aware of this and we\u2019re trying to fix this ASAP.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-12T20:46:32.366Z",
				"Answer_body": "<p>Hi again! Our engineers have fixed this issue. Please let me know if you still run into this</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-18T12:27:20.385Z",
				"Answer_body": "<p>Hi Manuel, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-11T19:42:53.391Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb not logging git commit/hash",
		"Question_link": "https://community.wandb.ai/t/wandb-not-logging-git-commit-hash/2197",
		"Question_created_time": "2022-04-07T18:47:49.284Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 345,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>When I first used wandb, I did find that wandb automatically logs the git commit hash when I ran experiments. However, recently, I found that it stops doing so. Namely, I cannot find any git information on the \u201coverview\u201d page of each experiment. Does anyone have some guesses on what might be the cause? Thanks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-07T20:08:18.500Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/taochen\">@taochen</a>,</p>\n<p>Could you share a little more information about your setup here? It will help me understand the root cause of this issue. More specifically:</p>\n<ul>\n<li>Are you running a normal run or a sweep? If it is a sweep, are you running it as <code>wandb.agent()</code> or <code>wandb agent</code>?</li>\n<li>What operating system are you on?</li>\n<li>What version of <code>wandb</code> are you currently using?</li>\n</ul>\n<p>It would also really help to have the link of the runs where you do not see the git hash.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-11T19:06:19.168Z",
				"Answer_body": "<p>\u200bHi <a class=\"mention\" href=\"/u/taochen\">@taochen</a> ,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,</p>\n<p>Weights &amp; Biases</p>\n<p>\u200b</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-11T20:26:48.940Z",
				"Answer_body": "<p>Hi Ramit,</p>\n<p>thanks for the help. I found out that it only occurs in one of the specific conda environments I have. I am not sure why this is the case. I will close the issue for now.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-10T20:26:50.513Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Exporting GPU utilization, power usage data",
		"Question_link": "https://community.wandb.ai/t/exporting-gpu-utilization-power-usage-data/2194",
		"Question_created_time": "2022-04-07T08:59:03.188Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 630,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I\u2019ve been wanting to export the data on GPU usage for my algorithm, but when I export the CSV file there is a single line which does not contain all the data.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b17a445f7fc35f370a78c8a4d9ea242ef5797b42.png\" data-download-href=\"/uploads/short-url/pk2t25q25HlYQzj2LOJ1W7xb1e2.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b17a445f7fc35f370a78c8a4d9ea242ef5797b42.png\" alt=\"image\" data-base62-sha1=\"pk2t25q25HlYQzj2LOJ1W7xb1e2\" width=\"690\" height=\"35\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b17a445f7fc35f370a78c8a4d9ea242ef5797b42_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1893\u00d797 7.21 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>For some reason all other data exports work, but any data which has to do with the GPU does not. I have 4 GPUs. The plot shows the right data:</p>\n<p>I could also not find the complete data using the API. Is this a bug?</p>\n<p>Best,</p>\n<p>Mario</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-07T20:15:51.468Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/meerio\">@meerio</a>,</p>\n<p>You should be able to retrieve your System Metrics history from the run using the following line of code:</p>\n<pre><code class=\"lang-python\">metrics = run.history(stream='events')\n</code></pre>\n<p>where <code>run</code> is a <code>Run</code> object accessed through the API. This should allow you to access all your system metrics data. Please let me know if this does not work for you or if you need any further assistance.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-04-11T09:58:23.756Z",
				"Answer_body": "<p>Awesome, that works :)!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-10T09:58:33.616Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to remove myself from a team?",
		"Question_link": "https://community.wandb.ai/t/how-to-remove-myself-from-a-team/2201",
		"Question_created_time": "2022-04-08T12:50:46.846Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 110,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I don\u2019t have admin access to a team and want to remove myself from the said team. There are other admin users, but say I can\u2019t communicate with them, how to remove myself?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-08T13:20:30.195Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/sai_prasanna\">@sai_prasanna</a>, an admin would have to remove you but if you would like I can remove you from a team? I see that you are a part of two teams, which one would you like to be removed from?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-08T13:23:38.124Z",
				"Answer_body": "<p>Hi Nate, Please remove me from the team \u201cagara\u201d. Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-08T13:28:00.723Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/sai_prasanna\">@sai_prasanna</a> no problem! You\u2019ve been removed from \u201cagara\u201d. Is there anything else I can help with?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-06-07T13:28:31.387Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb Comm Error",
		"Question_link": "https://community.wandb.ai/t/wandb-comm-error/2093",
		"Question_created_time": "2022-03-16T10:03:29.705Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 244,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi I am facing below problem while trying to run sweeps using wandb.</p>\n<p>wandb: Program failed with code 1.  Press ctrl-c to abort syncing.<br>\nwandb: ERROR Error uploading \u201ccode/wandb_hyperparameter.py\u201d: CommError, &lt;Response [400]&gt;<br>\nwandb: ERROR Error uploading \u201cwandb-metadata.json\u201d: CommError, &lt;Response [400]&gt;<br>\nwandb: ERROR Error uploading \u201cwandb-summary.json\u201d: CommError, &lt;Response [400]&gt;<br>\nwandb: ERROR Error uploading \u201cconfig.yaml\u201d: CommError, &lt;Response [400]&gt;<br>\nwandb: ERROR Error uploading \u201crequirements.txt\u201d: CommError, &lt;Response [400]&gt;</p>\n<p>Please help.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-16T23:04:39.523Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mithileshia\">@mithileshia</a>,</p>\n<p>I\u2019m sorry you are facing this issue. Could you share the <code>debug.log</code> and <code>debug-internal.log</code> files associated with one of the runs which displays this error? It would be very helpful in order to gain more visibility into this error and understand why you are seeing CommErrors here.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-18T06:09:07.484Z",
				"Answer_body": "<p>Hi Ramit sharing the debug.log and debug-internal.log files with you.</p>\n<p><strong>debug.log</strong></p>\n<p>2022-03-16 10:23:25,658 INFO    Thread-11 :28804 [wandb_init.py:_log_setup():293] Logging user logs to /home/demo_user2/Mithilesh/BayesianLSTM_W&amp;B/wandb/run-20220316_102325-g3s746w2/logs/debug.log<br>\n2022-03-16 10:23:25,658 INFO    Thread-11 :28804 [wandb_init.py:_log_setup():294] Logging internal logs to /home/demo_user2/Mithilesh/BayesianLSTM_W&amp;B/wandb/run-20220316_102325-g3s746w2/logs/debug-internal.log<br>\n2022-03-16 10:23:25,658 INFO    Thread-11 :28804 [wandb_setup.py:_flush():69] setting env: {\u2018api_key\u2019: \u2018xxxxxxxxxxxxxxxxx\u2019, \u2018project\u2019: \u2018blstm\u2019, \u2018entity\u2019: \u2018mithileshia\u2019, \u2018root_dir\u2019: \u2018/home/demo_user2/Mithilesh/BayesianLSTM_W&amp;B\u2019, \u2018sweep_id\u2019: \u2018lndyf4e1\u2019, \u2018run_id\u2019: \u2018g3s746w2\u2019, \u2018config_paths\u2019: \u2018/home/demo_user2/Mithilesh/BayesianLSTM_W&amp;B/wandb/sweep-lndyf4e1/config-g3s746w2.yaml\u2019}<br>\n2022-03-16 10:23:25,658 INFO    Thread-11 :28804 [wandb_setup.py:_flush():69] setting user settings: {\u2018save_code\u2019: True, \u2018email\u2019: \u2018xxxxxxxxxx@gmail.co\u2019}<br>\n2022-03-16 10:23:25,658 INFO    Thread-11 :28804 [wandb_setup.py:_flush():69] multiprocessing start_methods=fork,spawn,forkserver<br>\n2022-03-16 10:23:26,598 INFO    Thread-11 :28804 [wandb_run.py:_console_start():1290] atexit reg<br>\n2022-03-16 10:23:26,599 INFO    Thread-11 :28804 [wandb_run.py:_redirect():1160] redirect: SettingsConsole.REDIRECT<br>\n2022-03-16 10:23:26,600 INFO    Thread-11 :28804 [wandb_run.py:_redirect():1163] Redirecting console.<br>\n2022-03-16 10:23:26,600 INFO    Thread-11 :28804 [redirect.py:install():196] install start<br>\n2022-03-16 10:23:26,600 INFO    Thread-11 :28804 [redirect.py:install():211] install stop<br>\n2022-03-16 10:23:26,600 INFO    Thread-11 :28804 [redirect.py:install():196] install start<br>\n2022-03-16 10:23:26,602 INFO    Thread-11 :28804 [redirect.py:install():211] install stop<br>\n2022-03-16 10:23:26,602 INFO    Thread-11 :28804 [wandb_run.py:_redirect():1207] Redirects installed.<br>\n2022-03-16 10:23:26,614 INFO    Thread-11 :28804 [wandb_run.py:finish():988] finishing run mithileshia/blstm/g3s746w2</p>\n<p><strong>debug-internal.log</strong></p>\n<p>2022-03-16 10:23:26,477 INFO    MainThread:28972 [internal.py:wandb_internal():62] W&amp;B internal server running at pid: 28972<br>\n2022-03-16 10:23:26,480 DEBUG   HandlerThread:28972 [handler.py:handle_request():54] handle_request: check_version<br>\n2022-03-16 10:23:26,480 INFO    WriterThread:28972 [datastore.py:open_for_write():76] open: /home/demo_user2/Mithilesh/BayesianLSTM_W&amp;B/wandb/run-20220316_102325-g3s746w2/run-g3s746w2.wandb<br>\n2022-03-16 10:23:26,481 DEBUG   SenderThread:28972 [sender.py:send():89] send: header<br>\n2022-03-16 10:23:26,481 DEBUG   SenderThread:28972 [sender.py:send():89] send: request<br>\n2022-03-16 10:23:26,481 DEBUG   SenderThread:28972 [sender.py:send_request():98] send_request: check_version<br>\n2022-03-16 10:23:26,483 DEBUG   Thread-4  :28972 [connectionpool.py:_new_conn():939] Starting new HTTPS connection (1):2022-03-16 10:23:26,529 DEBUG   Thread-4  :28972 [connectionpool.py:_make_request():433]  \u201cGET /pypi/wandb/json HTTP/1.1\u201d 200 62723<br>\n2022-03-16 10:23:26,550 DEBUG   SenderThread:28972 [sender.py:send():89] send: run<br>\n2022-03-16 10:23:26,554 DEBUG   SenderThread:28972 [git.py:repo():30] git repository is invalid</p>\n<p>2022-03-16 10:23:26,611 DEBUG   Thread-11 :28972 [connectionpool.py:_new_conn():226] Starting new HTTP connection (1): localhost:  8080<br>\n2022-03-16 10:23:26,613 DEBUG   Thread-11 :28972 [connectionpool.py:_make_request():433] http:  //     localhost :  8080 \u201cPUT //local-files/mithileshia/blstm/g3s746w2/wandb-metadata.json?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=0IGHhIFOZrr9%2BXoTgbQ%2Blg%3D%3D%2F20220316%2Fwandb-local%2Fs3%2Faws4_request&amp;X-Amz-Date=20220316T102326Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=11545c50288dbb6a0b2ec1f09c833776f78f73ec3a4b5742d55d589d6c41713e HTTP/1.1\u201d 400 406<br>\n2022-03-16 10:23:26,614 ERROR   Thread-11 :28972 [internal_api.py:upload_file():1210] upload_file exception http: // localhost :8080 //local-files/mithileshia/blstm/g3s746w2/wandb-metadata.json?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=0IGHhIFOZrr9%2BXoTgbQ%2Blg%3D%3D%2F20220316%2Fwandb-local%2Fs3%2Faws4_request&amp;X-Amz-Date=20220316T102326Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=11545c50288dbb6a0b2ec1f09c833776f78f73ec3a4b5742d55d589d6c41713e 400 Client Error: Bad Request for url: http:// localhost:8080//local-files/mithileshia/blstm/g3s746w2/wandb-metadata.json?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=0IGHhIFOZrr9%2BXoTgbQ%2Blg%3D%3D%2F20220316%2Fwandb-local%2Fs3%2Faws4_request&amp;X-Amz-Date=20220316T102326Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=11545c50288dbb6a0b2ec1f09c833776f78f73ec3a4b5742d55d589d6c41713e<br>\n2022-03-16 10:23:26,615 DEBUG   SenderThread:28972 [connectionpool.py:_make_request():433] http : //l ocalhost:8080 \u201cPOST /graphql HTTP/1.1\u201d 200 65<br>\n2022-03-16 10:23:26,615 DEBUG   Thread-12 :28972 [connectionpool.py:_make_request():433] localhost:8080 \u201cPOST /graphql HTTP/1.1\u201d 200 431<br>\n2022-03-16 10:23:26,617 DEBUG   SenderThread:28972 [sender.py:send():89] send: run<br>\n2022-03-16 10:23:26,623 DEBUG   Thread-12 :28972 [connectionpool.py:_new_conn():226] Starting new HTTP connection (1): localhost:8080<br>\n2022-03-16 10:23:26,626 DEBUG   HandlerThread:28972 [handler.py:handle_request():54] handle_request: poll_exit<br>\n2022-03-16 10:23:26,626 DEBUG   Thread-12 :28972 [connectionpool.py:_make_request():433] // localhost:8080 \u201cPUT //local-files/mithileshia/blstm/g3s746w2/code/wandb_hyperparameter.py?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=0IGHhIFOZrr9%2BXoTgbQ%2Blg%3D%3D%2F20220316%2Fwandb-local%2Fs3%2Faws4_request&amp;X-Amz-Date=20220316T102326Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=ba1e408c529f3e8f79ad2150ee5468f05c21064c63b7e20e1a5e3a97b0bf9bd6 HTTP/1.1\u201d 400 424<br>\n2022-03-16 10:23:26,627 ERROR   Thread-12 :28972 [internal_api.py:upload_file():1210] upload_file exception http:// localhost:8080//local-files/mithileshia/blstm/g3s746w2/code/wandb_hyperparameter.py?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=0IGHhIFOZrr9%2BXoTgbQ%2Blg%3D%3D%2F20220316%2Fwandb-local%2Fs3%2Faws4_request&amp;X-Amz-Date=20220316T102326Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=ba1e408c529f3e8f79ad2150ee5468f05c21064c63b7e20e1a5e3a97b0bf9bd6 400 Client Error: Bad Request for url: http: // localhost: 8080//local-files/mithileshia/blstm/g3s746w2/code/wandb_hyperparameter.py?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=0IGHhIFOZrr9%2BXoTgbQ%2Blg%3D%3D%2F20220316%2Fwandb-local%2Fs3%2Faws4_request&amp;X-Amz-Date=20220316T102326Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=ba1e408c529f3e8f79ad2150ee5468f05c21064c63b7e20e1a5e3a97b0bf9bd6<br>\n2022-03-16 10:23:26,627 ERROR   Thread-11 :28972 [upload_job.py:push():115] Failed to upload file: /tmp/tmpc_2asjh8wandb/gc64ldxd-wandb-metadata.json<br>\nTraceback (most recent call last):<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u201d, line 24, in wrapper<br>\nreturn func(*args, **kwargs)<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u201d, line 132, in wrapped_fn<br>\nreturn retrier(*args, **kargs)<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u201d, line 96, in <strong>call</strong><br>\nresult = self._call_fn(*args, **kwargs)<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u201d, line 1220, in upload_file<br>\nutil.sentry_reraise(e)<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/util.py\u201d, line 95, in sentry_reraise<br>\nsix.reraise(type(exc), exc, sys.exc_info()[2])<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/six.py\u201d, line 703, in reraise<br>\nraise value<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u201d, line 1208, in upload_file<br>\nresponse.raise_for_status()<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/requests/models.py\u201d, line 941, in raise_for_status<br>\nraise HTTPError(http_error_msg, response=self)<br>\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: http: // localhost:8080//local-files/mithileshia/blstm/g3s746w2/wandb-metadata.json?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=0IGHhIFOZrr9%2BXoTgbQ%2Blg%3D%3D%2F20220316%2Fwandb-local%2Fs3%2Faws4_request&amp;X-Amz-Date=20220316T102326Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=11545c50288dbb6a0b2ec1f09c833776f78f73ec3a4b5742d55d589d6c41713e</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>Traceback (most recent call last):<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/filesync/upload_job.py\u201d, line 107, in push<br>\nself._api.upload_file_retry(<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u201d, line 26, in wrapper<br>\nraise CommError(err.response, err)<br>\nwandb.errors.error.CommError: &lt;Response [400]&gt;<br>\n2022-03-16 10:23:26,629 DEBUG   raven-sentry.BackgroundWorker:28972 [connectionpool.py:_new_conn():939] Starting new HTTPS connection (1): <a href=\"http://o151352.ingest.sentry.io:443\" rel=\"noopener nofollow ugc\">o151352.ingest.sentry.io:443</a><br>\n2022-03-16 10:23:26,631 ERROR   Thread-12 :28972 [upload_job.py:push():115] Failed to upload file: /tmp/tmpc_2asjh8wandb/brxvnwm4-code/wandb_hyperparameter.py<br>\nTraceback (most recent call last):<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u201d, line 24, in wrapper<br>\nreturn func(*args, **kwargs)<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u201d, line 132, in wrapped_fn<br>\nreturn retrier(*args, **kargs)<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u201d, line 96, in <strong>call</strong><br>\nresult = self._call_fn(*args, **kwargs)<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u201d, line 1220, in upload_file<br>\nutil.sentry_reraise(e)<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/util.py\u201d, line 95, in sentry_reraise<br>\nsix.reraise(type(exc), exc, sys.exc_info()[2])<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/six.py\u201d, line 703, in reraise<br>\nraise value<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u201d, line 1208, in upload_file<br>\nresponse.raise_for_status()<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/requests/models.py\u201d, line 941, in raise_for_status<br>\nraise HTTPError(http_error_msg, response=self)<br>\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: http: // localhost: 8080//local-files/mithileshia/blstm/g3s746w2/code/wandb_hyperparameter.py?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=0IGHhIFOZrr9%2BXoTgbQ%2Blg%3D%3D%2F20220316%2Fwandb-local%2Fs3%2Faws4_request&amp;X-Amz-Date=20220316T102326Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=ba1e408c529f3e8f79ad2150ee5468f05c21064c63b7e20e1a5e3a97b0bf9bd6</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>Traceback (most recent call last):<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/filesync/upload_job.py\u201d, line 107, in push<br>\nself._api.upload_file_retry(<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u201d, line 26, in wrapper<br>\nraise CommError(err.response, err)<br>\nwandb.errors.error.CommError: &lt;Response [400]&gt;<br>\n2022-03-16 10:23:26,631 DEBUG   SenderThread:28972 [git.py:repo():30] git repository is invalid<br>\n2022-03-16 10:23:26,638 DEBUG   SenderThread:28972 [connectionpool.py:_new_conn():226] Starting new HTTP connection (1): localhost:8080<br>\n2022-03-16 10:23:26,650 DEBUG   SenderThread:28972 [connectionpool.py:_make_request():433] localhost:8080 \u201cPOST /graphql HTTP/1.1\u201d 200 591<br>\n2022-03-16 10:23:26,652 INFO    SenderThread:28972 [sender.py:send_run():392] updated run: g3s746w2<br>\n2022-03-16 10:23:26,652 DEBUG   SenderThread:28972 [sender.py:send():89] send: exit<br>\n2022-03-16 10:23:26,652 INFO    SenderThread:28972 [sender.py:send_exit():167] handling exit code: 1<br>\n2022-03-16 10:23:26,652 INFO    SenderThread:28972 [sender.py:send_exit():175] send defer<br>\n2022-03-16 10:23:26,652 DEBUG   SenderThread:28972 [sender.py:send():89] send: request<br>\n2022-03-16 10:23:26,652 DEBUG   SenderThread:28972 [sender.py:send_request():98] send_request: poll_exit<br>\n2022-03-16 10:23:26,652 DEBUG   HandlerThread:28972 [handler.py:handle_request():54] handle_request: defer<br>\n2022-03-16 10:23:26,653 INFO    HandlerThread:28972 [handler.py:handle_request_defer():68] handle defer: 0<br>\n2022-03-16 10:23:26,653 DEBUG   SenderThread:28972 [sender.py:send():89] send: request<br>\n2022-03-16 10:23:26,653 DEBUG   SenderThread:28972 [sender.py:send_request():98] send_request: defer<br>\n2022-03-16 10:23:26,653 INFO    SenderThread:28972 [sender.py:send_request_defer():184] handle sender defer: 0<br>\n2022-03-16 10:23:26,653 INFO    SenderThread:28972 [sender.py:send_request_defer():220] send defer: 1<br>\n2022-03-16 10:23:26,653 DEBUG   HandlerThread:28972 [handler.py:handle_request():54] handle_request: defer<br>\n2022-03-16 10:23:26,654 INFO    HandlerThread:28972 [handler.py:handle_request_defer():68] handle defer: 1<br>\n2022-03-16 10:23:26,657 DEBUG   raven-sentry.BackgroundWorker:28972 [connectionpool.py:_make_request():433] \"https:// o151352.ingest. sentry. io:443  \u201cPOST /api/5288891/store/ HTTP/1.1\u201d 200 41<br>\n2022-03-16 10:23:26,661 DEBUG   raven-sentry.BackgroundWorker:28972 [connectionpool.py:_make_request():433] https:// o151352.i ngest. sentry. io :443 \u201cPOST /api/5288891/store/ HTTP/1.1\u201d 200 41<br>\n2022-03-16 10:23:26,665 DEBUG   raven-sentry.BackgroundWorker:28972 [connectionpool.py:_make_request():433] https:// o151352. ingest.sentry. io:443 \u201cPOST /api/5288891/store/ HTTP/1.1\u201d 200 41<br>\n2022-03-16 10:23:26,670 DEBUG   raven-sentry.BackgroundWorker:28972 [connectionpool.py:_make_request():433] https:// o151352. ingest. sentry. io:443 \u201cPOST /api/5288891/store/ HTTP/1.1\u201d 200 41<br>\n2022-03-16 10:23:26,691 DEBUG   SenderThread:28972 [sender.py:send():89] send: request<br>\n2022-03-16 10:23:26,691 DEBUG   SenderThread:28972 [sender.py:send_request():98] send_request: defer<br>\n2022-03-16 10:23:26,691 INFO    SenderThread:28972 [sender.py:send_request_defer():184] handle sender defer: 1<br>\n2022-03-16 10:23:26,691 INFO    SenderThread:28972 [sender.py:send_request_defer():220] send defer: 2<br>\n2022-03-16 10:23:26,692 DEBUG   SenderThread:28972 [sender.py:send():89] send: stats<br>\n2022-03-16 10:23:26,692 DEBUG   HandlerThread:28972 [handler.py:handle_request():54] handle_request: defer<br>\n2022-03-16 10:23:26,692 INFO    HandlerThread:28972 [handler.py:handle_request_defer():68] handle defer: 2<br>\n2022-03-16 10:23:26,692 DEBUG   SenderThread:28972 [sender.py:send():89] send: request<br>\n2022-03-16 10:23:26,692 DEBUG   SenderThread:28972 [sender.py:send_request():98] send_request: defer<br>\n2022-03-16 10:23:26,692 INFO    SenderThread:28972 [sender.py:send_request_defer():184] handle sender defer: 2<br>\n2022-03-16 10:23:26,692 INFO    SenderThread:28972 [sender.py:send_request_defer():220] send defer: 3<br>\n2022-03-16 10:23:26,693 DEBUG   HandlerThread:28972 [handler.py:handle_request():54] handle_request: defer<br>\n2022-03-16 10:23:26,693 INFO    HandlerThread:28972 [handler.py:handle_request_defer():68] handle defer: 3<br>\n2022-03-16 10:23:26,693 DEBUG   SenderThread:28972 [sender.py:send():89] send: summary<br>\n2022-03-16 10:23:26,693 INFO    SenderThread:28972 [sender.py:_save_file():567] saving file wandb-summary.json with policy end<br>\n2022-03-16 10:23:26,693 DEBUG   SenderThread:28972 [sender.py:send():89] send: request<br>\n2022-03-16 10:23:26,693 DEBUG   SenderThread:28972 [sender.py:send_request():98] send_request: defer<br>\n2022-03-16 10:23:26,694 INFO    SenderThread:28972 [sender.py:send_request_defer():184] handle sender defer: 3<br>\n2022-03-16 10:23:26,694 INFO    SenderThread:28972 [sender.py:send_request_defer():220] send defer: 4<br>\n2022-03-16 10:23:26,694 DEBUG   HandlerThread:28972 [handler.py:handle_request():54] handle_request: defer<br>\n2022-03-16 10:23:26,694 INFO    HandlerThread:28972 [handler.py:handle_request_defer():68] handle defer: 4<br>\n2022-03-16 10:23:26,694 DEBUG   SenderThread:28972 [sender.py:send():89] send: request<br>\n2022-03-16 10:23:26,694 DEBUG   SenderThread:28972 [sender.py:send_request():98] send_request: defer<br>\n2022-03-16 10:23:26,694 INFO    SenderThread:28972 [sender.py:send_request_defer():184] handle sender defer: 4<br>\n2022-03-16 10:23:26,694 INFO    SenderThread:28972 [dir_watcher.py:finish():280] shutting down directory watcher<br>\n2022-03-16 10:23:27,577 INFO    Thread-8  :28972 [dir_watcher.py:_on_file_modified():228] file/dir modified: /home/demo_user2/Mithilesh/BayesianLSTM_W&amp;B/wandb/run-20220316_102325-g3s746w2/files/config.yaml<br>\n2022-03-16 10:23:27,578 INFO    SenderThread:28972 [dir_watcher.py:_on_file_created():215] file/dir created: /home/demo_user2/Mithilesh/BayesianLSTM_W&amp;B/wandb/run-20220316_102325-g3s746w2/files/wandb-metadata.json<br>\n2022-03-16 10:23:27,578 INFO    SenderThread:28972 [dir_watcher.py:_on_file_created():215] file/dir created: /home/demo_user2/Mithilesh/BayesianLSTM_W&amp;B/wandb/run-20220316_102325-g3s746w2/files/output.log<br>\n2022-03-16 10:23:27,578 INFO    SenderThread:28972 [dir_watcher.py:_on_file_created():215] file/dir created: /home/demo_user2/Mithilesh/BayesianLSTM_W&amp;B/wandb/run-20220316_102325-g3s746w2/files/requirements.txt<br>\n2022-03-16 10:23:27,579 INFO    SenderThread:28972 [dir_watcher.py:_on_file_created():215] file/dir created: /home/demo_user2/Mithilesh/BayesianLSTM_W&amp;B/wandb/run-20220316_102325-g3s746w2/files/code<br>\n2022-03-16 10:23:27,579 INFO    SenderThread:28972 [dir_watcher.py:finish():309] scan:</p>\n<p>2022-03-16 10:23:27,602 DEBUG   Thread-13 :28972 [connectionpool.py:_new_conn():226] Starting new HTTP connection (1): localhost:8080<br>\n2022-03-16 10:23:27,605 DEBUG   Thread-15 :28972 [connectionpool.py:_new_conn():226] Starting new HTTP connection (1): localhost:8080<br>\n2022-03-16 10:23:27,605 DEBUG   Thread-14 :28972 [connectionpool.py:_make_request():433] http: // localhost: 8080 \u201cPOST /graphql HTTP/1.1\u201d 200 417<br>\n2022-03-16 10:23:27,606 DEBUG   Thread-13 :28972 [connectionpool.py:_make_request():433] http: // localhost: 8080 \u201cPUT //local-files/mithileshia/blstm/g3s746w2/wandb-summary.json?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=0IGHhIFOZrr9%2BXoTgbQ%2Blg%3D%3D%2F20220316%2Fwandb-local%2Fs3%2Faws4_request&amp;X-Amz-Date=20220316T102327Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=71b63953009d547f05162851b5762e9f28fe65117cc7a293ba71138648f76525 HTTP/1.1\u201d 400 404<br>\n2022-03-16 10:23:27,608 ERROR   Thread-13 :28972 [internal_api.py:upload_file():1210] upload_file exception http: // localhost: 8080//local-files/mithileshia/blstm/g3s746w2/wandb-summary.json?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=0IGHhIFOZrr9%2BXoTgbQ%2Blg%3D%3D%2F20220316%2Fwandb-local%2Fs3%2Faws4_request&amp;X-Amz-Date=20220316T102327Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=71b63953009d547f05162851b5762e9f28fe65117cc7a293ba71138648f76525 400 Client Error: Bad Request for url: http: // localhost:8080// local-files/mithileshia/blstm/g3s746w2/wandb-summary.json?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=0IGHhIFOZrr9%2BXoTgbQ%2Blg%3D%3D%2F20220316%2Fwandb-local%2Fs3%2Faws4_request&amp;X-Amz-Date=20220316T102327Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-<br>\nTraceback (most recent call last):<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u201d, line 24, in wrapper<br>\nreturn func(*args, **kwargs)<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u201d, line 132, in wrapped_fn<br>\nreturn retrier(*args, **kargs)<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u201d, line 96, in <strong>call</strong><br>\nresult = self._call_fn(*args, **kwargs)<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u201d, line 1220, in upload_file<br>\nutil.sentry_reraise(e)<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/util.py\u201d, line 95, in sentry_reraise<br>\nsix.reraise(type(exc), exc, sys.exc_info()[2])<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/six.py\u201d, line 703, in reraise<br>\nraise value<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u201d, line 1208, in upload_file<br>\nresponse.raise_for_status()<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/requests/models.py\u201d, line 941, in raise_for_status<br>\nraise HTTPError(http_error_msg, response=self)<br>\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: http: // localhost:8080// local-files/mithileshia/blstm/g3s746w2/wandb-summary.json?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=0IGHhIFOZrr9%2BXoTgbQ%2Blg%3D%3D%2F20220316%2Fwandb-local%2Fs3%2Faws4_request&amp;X-Amz-Date=20220316T102327Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=71b63953009d547f05162851b5762e9f28fe65117cc7a293ba71138648f76525</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>Traceback (most recent call last):<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/filesync/upload_job.py\u201d, line 107, in push<br>\nself._api.upload_file_retry(<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u201d, line 26, in wrapper<br>\nraise CommError(err.response, err)<br>\nwandb.errors.error.CommError: &lt;Response [400]&gt;<br>\n2022-03-16 10:23:27,618 DEBUG   Thread-14 :28972 [connectionpool.py:_make_request():433] http: // localhost:8080 \u201cPUT //local-files/mithileshia/blstm/g3s746w2/config.yaml?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=0IGHhIFOZrr9%2BXoTgbQ%2Blg%3D%3D%2F20220316%2Fwandb-local%2Fs3%2Faws4_request&amp;X-Amz-Date=20220316T102327Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=a22fd49e13ede15a3b6ea19c938b6e0c79b4219d3534c0bd1f6bc246770bd085 HTTP/1.1\u201d 400 390<br>\n2022-03-16 10:23:27,621 ERROR   Thread-15 :28972 [upload_job.py:push():115] Failed to upload file: /home/demo_user2/Mithilesh/BayesianLSTM_W&amp;B/wandb/run-20220316_102325-g3s746w2/files/requirements.txt<br>\nTraceback (most recent call last):<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u201d, line 24, in wrapper<br>\nreturn func(*args, **kwargs)<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u201d, line 132, in wrapped_fn<br>\nreturn retrier(*args, **kargs)<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u201d, line 96, in <strong>call</strong><br>\nresult = self._call_fn(*args, **kwargs)<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u201d, line 1220, in upload_file<br>\nutil.sentry_reraise(e)<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/util.py\u201d, line 95, in sentry_reraise<br>\nsix.reraise(type(exc), exc, sys.exc_info()[2])<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/six.py\u201d, line 703, in reraise<br>\nraise value<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u201d, line 1208, in upload_file<br>\nresponse.raise_for_status()<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/requests/models.py\u201d, line 941, in raise_for_status<br>\nraise HTTPError(http_error_msg, response=self)<br>\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: http:// localhost:8080//local-files/mithileshia/blstm/g3s746w2/requirements.txt?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=0IGHhIFOZrr9%2BXoTgbQ%2Blg%3D%3D%2F20220316%2Fwandb-local%2Fs3%2Faws4_request&amp;X-Amz-Date=20220316T102327Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=00bd693017e41aa2739f274a3e398cb45c70d4f075eb44662473dfd17b821a7a</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>Traceback (most recent call last):<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/filesync/upload_job.py\u201d, line 107, in push<br>\nself._api.upload_file_retry(<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u201d, line 26, in wrapper<br>\nraise CommError(err.response, err)<br>\nwandb.errors.error.CommError: &lt;Response [400]&gt;<br>\n2022-03-16 10:23:27,622 ERROR   Thread-14 :28972 [internal_api.py:upload_file():1210] upload_file exception http: // localhost: 8080//local-files/mithileshia/blstm/g3s746w2/config.yaml?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=0IGHhIFOZrr9%2BXoTgbQ%2Blg%3D%3D%2F20220316%2Fwandb-local%2Fs3%2Faws4_request&amp;X-Amz-Date=20220316T102327Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=a22fd49e13ede15a3b6ea19c938b6e0c79b4219d3534c0bd1f6bc246770bd085 400 Client Error: Bad Request for url: http: // localhost:8080//local-files/mithileshia/blstm/g3s746w2/config.yaml?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=0IGHhIFOZrr9%2BXoTgbQ%2Blg%3D%3D%2F20220316%2Fwandb-<br>\n2022-03-16 10:23:27,631 DEBUG   SenderThread:28972 [sender.py:send():89] send: final<br>\n2022-03-16 10:23:27,631 ERROR   Thread-14 :28972 [upload_job.py:push():115] Failed to upload file: /home/demo_user2/Mithilesh/BayesianLSTM_W&amp;B/wandb/run-20220316_102325-g3s746w2/files/config.yaml<br>\nTraceback (most recent call last):<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u201d, line 24, in wrapper<br>\nreturn func(*args, **kwargs)<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u201d, line 132, in wrapped_fn<br>\nreturn retrier(*args, **kargs)<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u201d, line 96, in <strong>call</strong><br>\nresult = self._call_fn(*args, **kwargs)<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u201d, line 1220, in upload_file<br>\nutil.sentry_reraise(e)<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/util.py\u201d, line 95, in sentry_reraise<br>\nsix.reraise(type(exc), exc, sys.exc_info()[2])<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/six.py\u201d, line 703, in reraise<br>\nraise value<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u201d, line 1208, in upload_file<br>\nresponse.raise_for_status()<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/requests/models.py\u201d, line 941, in raise_for_status<br>\nraise HTTPError(http_error_msg, response=self)<br>\nrequests.exceptions.HTTPError: 400 Client Error: Bad Request for url: http: // localhost: 8080//local-files/mithileshia/blstm/g3s746w2/config.yaml?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=0IGHhIFOZrr9%2BXoTgbQ%2Blg%3D%3D%2F20220316%2Fwandb-local%2Fs3%2Faws4_request&amp;X-Amz-Date=20220316T102327Z&amp;X-Amz-Expires=86400&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Signature=a22fd49e13ede15a3b6ea19c938b6e0c79b4219d3534c0bd1f6bc246770bd085</p>\n<p>During handling of the above exception, another exception occurred:</p>\n<p>Traceback (most recent call last):<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/filesync/upload_job.py\u201d, line 107, in push<br>\nself._api.upload_file_retry(<br>\nFile \u201c/home/demo_user2/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u201d, line 26, in wrapper<br>\nraise CommError(err.response, err)<br>\nwandb.errors.error.CommError: &lt;Response [400]&gt;</p>\n<p>2022-03-16 10:23:29,658 INFO    SenderThread:28972 [file_pusher.py:finish():169] shutting down file pusher<br>\n2022-03-16 10:23:29,658 INFO    SenderThread:28972 [file_pusher.py:join():174] waiting for file pusher<br>\n2022-03-16 10:23:29,659 INFO    MainThread:28972 [internal.py:handle_exit():137] Internal process exited</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-30T21:06:11.322Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mithileshia\">@mithileshia</a>,</p>\n<p>I apologize about the delay here. From the looks of it it seems like the URL <code>http: // localhost:8080// local-files/mithileshia/blstm/g3s746w2/wandb-summary.json</code>  is malformed, though I can not see the line creating from your source code in the debug logs. Could you share the line from the code causing this error?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-04T16:32:14.392Z",
				"Answer_body": "<p>\u200bHi <a class=\"mention\" href=\"/u/mithileshia\">@mithileshia</a>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-07T19:09:15.596Z",
				"Answer_body": "<p>\u200bHi <a class=\"mention\" href=\"/u/mithileshia\">@mithileshia</a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>\n<p>\u200b</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-06T19:10:06.127Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Error in callback",
		"Question_link": "https://community.wandb.ai/t/error-in-callback/2175",
		"Question_created_time": "2022-03-31T18:04:40.180Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 205,
		"Question_has_accepted_answer": false,
		"Question_body": "<pre><code class=\"lang-auto\">Error in callback &lt;function _WandbInit._resume_backend at 0x7f84f11b49d0&gt; (for pre_run_cell):\n</code></pre>\n<p>If I stop a run in a Paperspace Gradient jupyter notebook and then try to execute any cell I receive the above error.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-01T17:39:54.287Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/georgepearsebehold\">@georgepearsebehold</a>,</p>\n<p>I\u2019m sorry you are facing this issue. Could you share a full traceback to the error you see here, and some steps to reproduce this error? I will try to reproduce this issue on my end.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-01T17:40:12.522Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/georgepearsebehold\">@georgepearsebehold</a>,</p>\n<p>I\u2019m sorry you are facing this issue. Could you share a full traceback to the error you see here, and some steps to reproduce this error? I will try to reproduce this issue on my end.</p>\n<p>Thanks,<br>\nRamit</p>\n<p>[Discourse post]</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-05T19:07:28.185Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/georgepearsebehold\">@georgepearsebehold</a></p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>\n<p>\u200b</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-04T19:08:11.313Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Will multiple runs in the same folder <del>sync</del>resume properly?",
		"Question_link": "https://community.wandb.ai/t/will-multiple-runs-in-the-same-folder-del-sync-del-resume-properly/2180",
		"Question_created_time": "2022-04-02T07:21:29.352Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 313,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Edit: I think I did not express my problem correctly, I was concerned that if there are multiple runs in the same directory and some runs crashed, could wandb resume automatically if I pass the <code>resume=True</code> parameter to <code>wandb.init</code>.</p>\n<p>The answer is no, apparently.  I think either <a href=\"https://docs.wandb.ai/guides/track/advanced/resuming#automatic-and-controlled-resuming\">controlled resuming</a> or running from different working directories is mandatory in this case.</p>\n<hr>\n<p><del>Hi, I wonder if wandb can sync properly if I start multiple runs simultaneously in the same project root?</del></p>\n<p><del>I was using wandb with only 1 GPU and it worked splendidly, now I want to use the same codebase on a machine with 2 GPUs.  I have already started a run with <code>CUDA_VISIBLE_DEVICES=0</code>, now I want to start another run with <code>CUDA_VISIBLE_DEVICES=1</code> in a new shell session, but in the same directory as the first run.  I noticed that the <code>wandb/</code> directory in the project root seems to track only the latest run (there is a symlink called <code>latest-run</code>), my question is, <strong>if I start another run in the same directory while the first one is running, will <code>wandb</code> mess it up</strong>?  If it does mess up, is cloning the codebase to another path and run there my best option?  Or if wandb can properly handle the situation mentioned above, is there any caveats I should be aware of?</del></p>\n<p>Thanks for reading through, any help would be greatly appreciated.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-04T23:18:54.762Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/blurgy\">@blurgy</a>,</p>\n<p>If you have multiple runs and some of them crashed, <code>wandb</code> can not automatically resume them if the <code>resume=True</code> parameter is passed. The second mandatory parameter to resume a run is <code>id</code>, which is the 8 character alphanumeric ID given to every run. This needs to be specified in order to know which run has to be resumed.</p>\n<p>As a result, you will not be able to automatically resume runs by setting <code>resume=True</code>.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-03T23:19:48.447Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Has anyone used wandb sweeps and torch.distributed before?",
		"Question_link": "https://community.wandb.ai/t/has-anyone-used-wandb-sweeps-and-torch-distributed-before/2184",
		"Question_created_time": "2022-04-04T01:04:36.622Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 135,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi! My first time posting here. One of my code bases uses torch.distributed for distributed training over different GPUs. Currently, I am writing .sh scripts to deal with hyperparameter sweeping. I was wondering if anyone had experience with using wandb sweep functionality to launch sweeps for torch.distributed training scripts.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-04T22:12:03.110Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevin-miao\">@kevin-miao</a>,</p>\n<p>We do not have an example for torch.distributed with Sweeps, but an example for integrating <code>wandb</code> with torch.distributed can be found <a href=\"https://github.com/wandb/examples/tree/master/examples/pytorch/pytorch-ddp\" rel=\"noopener nofollow ugc\">here</a>. It should be fairly straightforward to extend this example to a sweep.</p>\n<p>Please let me know if you face issues with this.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-03T22:12:59.386Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to live log arbitrary line graph",
		"Question_link": "https://community.wandb.ai/t/how-to-live-log-arbitrary-line-graph/2168",
		"Question_created_time": "2022-03-29T20:39:20.998Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 174,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m running active learning experiments where the result is some model performance metric against dataset size.  I\u2019ve seen the below code example:</p>\n<pre><code class=\"lang-auto\">data = [\ufeff[x, y] for (x, y) in zip\ufeff(x_values, y_values)\ufeff]\ntable = wandb.Table(data=data, columns = [\ufeff\"x\"\ufeff, \"y\"\ufeff]\ufeff)\nwandb.log(\ufeff{\ufeff\"my_custom_plot_id\" : wandb.plot.line(table,\n                                 \"x\"\ufeff, \"y\"\ufeff, title=\ufeff\"Custom Y vs X Line Plot\"\ufeff)\ufeff}\ufeff)\n</code></pre>\n<p>but this seems to be for static graph generation once you have access to all the data.</p>\n<p>How do I generate a live updating graph of model performance against dataset size?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-30T21:43:45.849Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/georgepearsebehold\">@georgepearsebehold</a>,</p>\n<p>Just to make sure I understand you correctly, are you trying to log a line of values at each timestep and want to see the progression of this line over time?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-31T18:02:58.165Z",
				"Answer_body": "<p>I wanted to log a line of values against a self defined x axis.</p>\n<p>I\u2019ve since resolved with :</p>\n<pre><code class=\"lang-auto\">wandb.define_metric(\"dataset_size\")\nwandb.define_metric(\"val/ AUC SLC (max)\", step_metric=\"dataset_size\")\nlog_dict = {\n    'dataset_size': len(baal_data_module.active_set),\n    'val/ AUC SLC (max)': max_val_auc\n}\nwandb.log(log_dict)\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-04T19:04:58.171Z",
				"Answer_body": "<p>Ah, understood. <code>define_metric</code> is definitely the right way to go about this. Glad you were able to resolve this by yourself!</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-03T19:05:44.909Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Best practice to efficiently log GPU PyTorch tensors to wandb?",
		"Question_link": "https://community.wandb.ai/t/best-practice-to-efficiently-log-gpu-pytorch-tensors-to-wandb/2037",
		"Question_created_time": "2022-03-08T02:43:59.218Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 196,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi there,</p>\n<p>I am using reinforcement learning and have quite a complicated training procedure. To make sure everything is working properly it is important to me to log as much as I can to my wandb dashboard. However most of these quantities are PyTorch tensors on GPU and the way I am logging seems quite inefficient.</p>\n<p>My current logging setup looks something like this</p>\n<pre><code class=\"lang-auto\">batch_d = dict()\nbatch_d['logp']        =           logp.detach().cpu().tolist()\nbatch_d['loss']        =           loss.detach().cpu().tolist()\nbatch_d['loss_sum']    =       loss_sum.detach().cpu().tolist()\nbatch_d['loss_batch']   =    loss_batch.detach().cpu().tolist()\n# ... ~10 other similar things tracked here too\n# ...convert quantities to wandb Histograms and similar\nwandb.log(batch_d)\n</code></pre>\n<p>However all this detaching and moving to cpu slows down performance (e.g. as mentioned by this <a href=\"https://towardsdatascience.com/7-tips-for-squeezing-maximum-performance-from-pytorch-ca4a40951259\" rel=\"noopener nofollow ugc\">article</a> on PyTorch efficiency). Hence I was wondering if there was a better way I can log all these quantities.</p>\n<p>Thanks,</p>\n<p>Tom</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-20T23:35:47.648Z",
				"Answer_body": "<p>Any ideas are very appreciated.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-22T20:21:43.633Z",
				"Answer_body": "<p>To be honest, I\u2019ve found that real-time batch training metrics are a bit overrated and sometimes it\u2019s better to just train faster, what I personally do is create an entirely separate \u201ctraining_eval\u201d workflow (identical to running validation with no gradients, but executed on the training dataset).  This might get you the speedups you need depending on what your bottleneck is, and you can also always set this workflow to run e.g. every 5 epochs for a guaranteed speedup.</p>\n<p>Of course you also lose a bit of logging, but from my view training metrics are only a supplemental thing to compare to validation metrics, sometimes it\u2019s better just to train something faster rather than to log everything.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-02T16:02:30.712Z",
				"Answer_body": "<p>Even something as simple as <code>print(some_tensor_on_gpu)</code> needs to move the tensor from GPU to CPU, so that overhead is an unavoidable action when logging.</p>\n<p>Off the top of my head, the only thing I can think of at the moment is perhaps if you could dump all the <code>detach() cpu() numpy() tolist()</code> etc. operations followed by <code>wandb.log</code> to a thread that asynchronously runs in the background and thus does not block your main training code.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-04T05:45:43.989Z",
				"Answer_body": "<p>Thanks guys for your replies.</p>\n<p><a class=\"mention\" href=\"/u/dealer56\">@dealer56</a> I like the idea with the async thread, but I\u2019ve never done anything like this. Any ideas for a good starting place? Wondering if it\u2019s something that Pytorch supports easily.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-03T05:46:35.621Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Download Report as LaTeX not working",
		"Question_link": "https://community.wandb.ai/t/download-report-as-latex-not-working/2182",
		"Question_created_time": "2022-04-03T20:19:23.494Z",
		"Question_answer_count": 2,
		"Question_score_count": 1,
		"Question_view_count": 121,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey,</p>\n<p>I\u2019m trying to download a <a href=\"https://wandb.ai/dezzardhd/eval_finals/reports/P1850-dim16--VmlldzoxNzc0NzA3?accessToken=7f0xyvcyq6j27xipyvuwhgbm9237uf2uft18zxt0kyhlutbg5b1ynodog330pqpa\">report</a> as LaTeX.<br>\nThe images and tables are not being downloaded. The folders contained in the zip archive are empty.</p>\n<p>That\u2019s a bug I guess.</p>\n<p>DezzardHD</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-04T11:37:32.088Z",
				"Answer_body": "<p>Hey Moritz,</p>\n<p>Thanks for reporting this. I\u2019ll file a ticket so that our team can look into this.</p>\n<p>Best,<br>\nArman</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-06-02T20:19:49.405Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Agent bug? File not found error",
		"Question_link": "https://community.wandb.ai/t/agent-bug-file-not-found-error/2109",
		"Question_created_time": "2022-03-18T09:03:02.106Z",
		"Question_answer_count": 11,
		"Question_score_count": 2,
		"Question_view_count": 3734,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi I\u2019m using kaggle with Pytorch and W&amp;B</p>\n<ul>\n<li>Weights and Biases version: 0.12.11</li>\n<li>Python version: 3.7.12<br>\n<strong>Description:</strong><br>\nWhen using the attached notebook I get the following error:<br>\n[<a href=\"https://www.kaggle.com/code/wojtekddl/license-plate-w-b\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">License-plate-w&amp;b | Kaggle</a>]</li>\n</ul>\n<pre><code class=\"lang-auto\">wandb: Agent Starting Run: 9uvr1lj3 with config:\nwandb: \tbatch_size: 64\nwandb: \tdropout: 0.2\nwandb: \tdropout_lstm: 0.1\nwandb: \tepochs: 8\nwandb: \thidden_size: 32\nwandb: \tlinear_output: 64\nwandb: \tmodels: PlateLUX_2GRU\nwandb: \toptimizer: RMSprop\nwandb: \tscheduler: ReduceLROnPlateau\nwandb: Currently logged in as: wualas (use `wandb login --relogin` to force relogin)\nTracking run with wandb version 0.12.11\nRun data is saved locally in /kaggle/working/wandb/run-20220318_082708-9uvr1lj3\nSyncing run winter-sweep-1 to Weights &amp; Biases (docs)\nSweep page: https://wandb.ai/wualas/pytorch-sweeps-rejestracje_last/sweeps/7ioy5yu1\n\nWaiting for W&amp;B process to finish... (failed 1). Press Control-C to abort syncing.\nSynced winter-sweep-1: https://wandb.ai/wualas/pytorch-sweeps-rejestracje_last/runs/9uvr1lj3\nSynced 4 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nFind logs at: ./wandb/run-20220318_082708-9uvr1lj3/logs\nRun 9uvr1lj3 errored: FileNotFoundError(2, 'No such file or directory')\nwandb: ERROR Run 9uvr1lj3 errored: FileNotFoundError(2, 'No such file or directory')\n</code></pre>\n<p>train_function:</p>\n<pre><code class=\"lang-auto\">def train(config=None):\n    with wandb.init(config=config):\n        config = wandb.config\n        df = pd.read_csv('/content/OCRdataset/annotations_CRNN.csv')\n        df['filename'] = '/content/OCRdataset/images/' + df['filename'].astype(str)\n        image_files = df['filename'].tolist()\n        targets_orig = df['label'].tolist()\n        targets = [[c for c in x] for x in targets_orig]\n        targets_flat = [c for clist in targets for c in clist]\n\n        lbl_enc = preprocessing.LabelEncoder()\n        lbl_enc.fit(targets_flat)\n        targets_enc = [lbl_enc.transform(x) for x in targets]\n        targets_enc = np.array(targets_enc)\n        targets_enc = targets_enc + 1\n\n        (\n        train_imgs,\n        test_imgs,\n        train_targets,\n        test_targets,\n        _,\n        test_targets_orig,\n        ) = model_selection.train_test_split(\n        image_files, targets_enc, targets_orig, test_size=0.1, random_state=42\n        )\n        num_chars=len(lbl_enc.classes_)\n        train_loader, test_loader = build_loader(train_imgs, train_targets, test_imgs, test_targets, config.batch_size)\n        model = build_network(config.models, num_chars, config.linear_output, config.hidden_size, config.dropout, config.dropout_lstm)\n        optimizer = build_optimizer(model, config.optimizer)\n        scheduler = build_scheduler(optimizer, config.scheduler)\n\n        train_loss_tab = []\n        test_loss_tab = []\n        accuracy_tab = []\n        best_test_loss = 100000000000000\n        for epoch in range(config.epochs):\n            train_loss = train_fn(model, train_loader, optimizer)\n            valid_preds, test_loss = eval_fn(model, test_loader)\n            valid_captcha_preds = []\n            for vp in valid_preds:\n                current_preds = decode_predictions(vp, lbl_enc)\n                valid_captcha_preds.extend(current_preds)\n            combined = list(zip(test_targets_orig, valid_captcha_preds))\n            print(combined)\n            test_dup_rem = [remove_duplicates(c) for c in test_targets_orig]\n            accuracy = metrics.accuracy_score(test_dup_rem, valid_captcha_preds)\n            print(\n              f\"Epoch={epoch}, Train Loss={train_loss}, Test Loss={test_loss} Accuracy={accuracy}\"\n            )\n            exloss = calculate_EXACTloss(combined)\n            scheduler.step(test_loss)\n            #torch.save(model.state_dict(), \"/content/epoch_save/EPOCH_SAVER_CRNN_state_dict3{}.pt\".format(epoch))\n            # dopisac zapisywanie kazdego modelu\n            train_loss_tab.append(train_loss)\n            test_loss_tab.append(test_loss)\n            accuracy_tab.append(accuracy)\n            print(\"zapisuje\")\n            wandb.log({'epoch': epoch, 'loss_test': test_loss, 'loss_train': train_loss, 'accuracy': accuracy, 'EXACTacc' : exloss})\n</code></pre>\n<p>Is there an error how I\u2019m using wandb or is this a bug?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-18T14:28:19.118Z",
				"Answer_body": "<p>Hi Wojtek,</p>\n<p>The error you are getting <code>'No such file or directory'</code> is appearing because <code>Run 9uvr1lj3</code> is not available. The only sweep available in your dashboard is <code>7ioy5yu1</code> . If you look at blocks 41 and 42 within your notebook the values for what you put into you wandb.agent and your sweep_id don\u2019t align properly. This is because when you\u2019re calling wandb.agent(), a new agent is being created compared to using the previously generated sweep id from line 41. Can you explicitly state your variables in your wandb.agent function: <code>wandb.agent(sweep_id, function = train), count = 1)</code> and see if this helps? If not, can you hard code  <code>7ioy5yu1</code> as your sweep id?</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-18T15:43:31.145Z",
				"Answer_body": "<p>Hi Leslie!<br>\nThanks for your response ,<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/3673d21c8733d42076785121e7d73b1f481c1577.jpeg\" data-download-href=\"/uploads/short-url/7LHVy2UedrzXBdWLrinLGsabolV.jpeg?dl=1\" title=\"sweep\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3673d21c8733d42076785121e7d73b1f481c1577_2_690x446.jpeg\" alt=\"sweep\" data-base62-sha1=\"7LHVy2UedrzXBdWLrinLGsabolV\" width=\"690\" height=\"446\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3673d21c8733d42076785121e7d73b1f481c1577_2_690x446.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/3673d21c8733d42076785121e7d73b1f481c1577.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/3673d21c8733d42076785121e7d73b1f481c1577.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3673d21c8733d42076785121e7d73b1f481c1577_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">sweep</span><span class=\"informations\">925\u00d7598 108 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nIt seems that it doesn\u2019t  work.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-25T15:13:14.416Z",
				"Answer_body": "<p>Hi again, I tried going to the project page you have on your image and it looks like you deleted it, so I wasn\u2019t able to get any information from there. However, I still can get some information from your image. It looks like your sweep page is getting created from the image that you had sent and I have a few questions.</p>\n<ul>\n<li>Is the sweep id show up on personal cloud?</li>\n<li>If so, can you provide debug logs from your wandb run directory (debug.log and debug-internal.log) so we can see if the config is populating properly?</li>\n<li>If you remove wandb, does your code run properly?</li>\n</ul>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-28T18:24:43.455Z",
				"Answer_body": "<p>Hi Wojtek,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-29T21:31:39.577Z",
				"Answer_body": "<p>Hi, thanks for response again</p>\n<ol>\n<li>\n<p>Yes, i can see it<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/048f0ae88f0abf6711f2383d2f16485d3d40731e.jpeg\" data-download-href=\"/uploads/short-url/EknoceNzDprKu1ncYnubhs3JxA.jpeg?dl=1\" title=\"222\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/048f0ae88f0abf6711f2383d2f16485d3d40731e_2_690x375.jpeg\" alt=\"222\" data-base62-sha1=\"EknoceNzDprKu1ncYnubhs3JxA\" width=\"690\" height=\"375\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/048f0ae88f0abf6711f2383d2f16485d3d40731e_2_690x375.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/048f0ae88f0abf6711f2383d2f16485d3d40731e_2_1035x562.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/048f0ae88f0abf6711f2383d2f16485d3d40731e_2_1380x750.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/048f0ae88f0abf6711f2383d2f16485d3d40731e_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">222</span><span class=\"informations\">1660\u00d7903 118 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n</li>\n<li>\n</li>\n</ol>\n<p>Debug log</p>\n<pre><code class=\"lang-auto\">2022-03-29 21:20:04,247 INFO    Thread-51 :73 [wandb_setup.py:_flush():75] Loading settings from /root/.config/wandb/settings\n2022-03-29 21:20:04,247 INFO    Thread-51 :73 [wandb_setup.py:_flush():75] Loading settings from wandb/settings\n2022-03-29 21:20:04,248 INFO    Thread-51 :73 [wandb_setup.py:_flush():75] Loading settings from environment variables: {'project': 'pytorch-sweeps-License-Plate-last-gpu', 'entity': 'wualas', 'root_dir': '/content', 'run_id': '1a183de4', 'sweep_param_path': '/content/wandb/sweep-mhru0h2m/config-1a183de4.yaml', 'sweep_id': 'mhru0h2m'}\n2022-03-29 21:20:04,248 INFO    Thread-51 :73 [wandb_setup.py:_flush():75] Inferring run settings from compute environment: {'program': '&lt;python with no main file&gt;'}\n2022-03-29 21:20:04,248 INFO    Thread-51 :73 [wandb_init.py:_log_setup():405] Logging user logs to /content/wandb/run-20220329_212004-1a183de4/logs/debug.log\n2022-03-29 21:20:04,248 INFO    Thread-51 :73 [wandb_init.py:_log_setup():406] Logging internal logs to /content/wandb/run-20220329_212004-1a183de4/logs/debug-internal.log\n2022-03-29 21:20:04,248 INFO    Thread-51 :73 [wandb_init.py:_jupyter_setup():355] configuring jupyter hooks &lt;wandb.sdk.wandb_init._WandbInit object at 0x7fdd03d848d0&gt;\n2022-03-29 21:20:04,248 INFO    Thread-51 :73 [wandb_init.py:init():439] calling init triggers\n2022-03-29 21:20:04,248 INFO    Thread-51 :73 [wandb_init.py:init():443] wandb.init called with sweep_config: {'batch_size': 16, 'dropout': 0.2, 'dropout_lstm': 0.25, 'epochs': 5, 'hidden_size': 64, 'linear_output': 128, 'models': 'PlateLUX_2GRU', 'optimizer': 'adam', 'scheduler': 'ExponentialLR'}\nconfig: {}\n2022-03-29 21:20:04,248 INFO    Thread-51 :73 [wandb_init.py:init():492] starting backend\n2022-03-29 21:20:04,248 INFO    Thread-51 :73 [backend.py:_multiprocessing_setup():101] multiprocessing start_methods=fork,spawn,forkserver, using: spawn\n2022-03-29 21:20:04,253 INFO    Thread-51 :73 [backend.py:ensure_launched():219] starting backend process...\n2022-03-29 21:20:04,276 INFO    Thread-51 :73 [backend.py:ensure_launched():225] started backend process with pid: 636\n2022-03-29 21:20:04,278 INFO    Thread-51 :73 [wandb_init.py:init():501] backend started and connected\n2022-03-29 21:20:04,347 INFO    Thread-51 :73 [wandb_run.py:_config_callback():992] config_cb None None {'batch_size': 16, 'dropout': 0.2, 'dropout_lstm': 0.25, 'epochs': 5, 'hidden_size': 64, 'linear_output': 128, 'models': 'PlateLUX_2GRU', 'optimizer': 'adam', 'scheduler': 'ExponentialLR'}\n2022-03-29 21:20:04,350 INFO    Thread-51 :73 [wandb_run.py:_label_probe_notebook():947] probe notebook\n2022-03-29 21:20:09,374 INFO    Thread-51 :73 [wandb_run.py:_label_probe_notebook():957] Unable to probe notebook: 'NoneType' object has no attribute 'get'\n2022-03-29 21:20:09,374 INFO    Thread-51 :73 [wandb_init.py:init():565] updated telemetry\n2022-03-29 21:20:09,378 INFO    Thread-51 :73 [wandb_init.py:init():596] communicating run to backend with 30 second timeout\n2022-03-29 21:20:09,475 INFO    Thread-51 :73 [wandb_run.py:_on_init():1759] communicating current version\n2022-03-29 21:20:09,542 INFO    Thread-51 :73 [wandb_run.py:_on_init():1763] got version response \n2022-03-29 21:20:09,542 INFO    Thread-51 :73 [wandb_init.py:init():625] starting run threads in backend\n2022-03-29 21:20:12,495 INFO    Thread-51 :73 [wandb_run.py:_console_start():1733] atexit reg\n2022-03-29 21:20:12,495 INFO    Thread-51 :73 [wandb_run.py:_redirect():1606] redirect: SettingsConsole.WRAP\n2022-03-29 21:20:12,495 INFO    Thread-51 :73 [wandb_run.py:_redirect():1643] Wrapping output streams.\n2022-03-29 21:20:12,497 INFO    Thread-51 :73 [wandb_run.py:_redirect():1667] Redirects installed.\n2022-03-29 21:20:12,497 INFO    Thread-51 :73 [wandb_init.py:init():664] run started, returning control to user process\n2022-03-29 21:22:09,715 INFO    Thread-51 :73 [wandb_run.py:finish():1539] finishing run wualas/pytorch-sweeps-License-Plate-last-gpu/1a183de4\n2022-03-29 21:22:09,715 INFO    Thread-51 :73 [jupyter.py:save_history():429] not saving jupyter history\n2022-03-29 21:22:09,716 INFO    Thread-51 :73 [jupyter.py:save_ipynb():374] not saving jupyter notebook\n2022-03-29 21:22:09,716 INFO    Thread-51 :73 [wandb_init.py:_jupyter_teardown():337] cleaning up jupyter logic\n2022-03-29 21:22:09,716 INFO    Thread-51 :73 [wandb_run.py:_atexit_cleanup():1702] got exitcode: 1\n2022-03-29 21:22:09,718 INFO    Thread-51 :73 [wandb_run.py:_restore():1674] restore\n2022-03-29 21:22:10,710 INFO    Thread-51 :73 [wandb_run.py:_on_finish():1831] got exit ret: file_counts {\n  wandb_count: 1\n}\npusher_stats {\n  uploaded_bytes: 664\n  total_bytes: 664\n}\n\n2022-03-29 21:22:11,553 INFO    Thread-51 :73 [wandb_run.py:_on_finish():1831] got exit ret: file_counts {\n  wandb_count: 4\n}\npusher_stats {\n  uploaded_bytes: 664\n  total_bytes: 8575\n}\n\n2022-03-29 21:22:11,657 INFO    Thread-51 :73 [wandb_run.py:_on_finish():1831] got exit ret: file_counts {\n  wandb_count: 5\n}\npusher_stats {\n  uploaded_bytes: 664\n  total_bytes: 30246\n}\n\n2022-03-29 21:22:11,760 INFO    Thread-51 :73 [wandb_run.py:_on_finish():1831] got exit ret: file_counts {\n  wandb_count: 5\n}\npusher_stats {\n  uploaded_bytes: 30246\n  total_bytes: 30246\n}\n\n2022-03-29 21:22:11,863 INFO    Thread-51 :73 [wandb_run.py:_on_finish():1831] got exit ret: file_counts {\n  wandb_count: 5\n}\npusher_stats {\n  uploaded_bytes: 30246\n  total_bytes: 30246\n}\n\n2022-03-29 21:22:11,965 INFO    Thread-51 :73 [wandb_run.py:_on_finish():1831] got exit ret: file_counts {\n  wandb_count: 5\n}\npusher_stats {\n  uploaded_bytes: 30246\n  total_bytes: 30246\n}\n\n2022-03-29 21:22:12,066 INFO    Thread-51 :73 [wandb_run.py:_on_finish():1831] got exit ret: file_counts {\n  wandb_count: 5\n}\npusher_stats {\n  uploaded_bytes: 30246\n  total_bytes: 30246\n}\n\n2022-03-29 21:22:12,214 INFO    Thread-51 :73 [wandb_run.py:_on_finish():1831] got exit ret: file_counts {\n  wandb_count: 5\n}\npusher_stats {\n  uploaded_bytes: 30246\n  total_bytes: 30246\n}\n\n2022-03-29 21:22:12,364 INFO    Thread-51 :73 [wandb_run.py:_on_finish():1831] got exit ret: done: true\nexit_result {\n}\nfile_counts {\n  wandb_count: 5\n}\npusher_stats {\n  uploaded_bytes: 30246\n  total_bytes: 30246\n}\nlocal_info {\n}\n\n2022-03-29 21:22:13,802 INFO    Thread-51 :73 [wandb_run.py:_footer_history_summary_info():2865] rendering history\n2022-03-29 21:22:13,803 INFO    Thread-51 :73 [wandb_run.py:_footer_history_summary_info():2894] rendering summary\n2022-03-29 21:22:13,805 INFO    Thread-51 :73 [wandb_run.py:_footer_sync_info():2822] logging synced files\n\n</code></pre>\n<p>Debug internal log</p>\n<pre><code class=\"lang-auto\">2022-03-29 21:20:05,321 INFO    MainThread:636 [internal.py:wandb_internal():95] W&amp;B internal server running at pid: 636, started at: 2022-03-29 21:20:05.321477\n2022-03-29 21:20:09,376 INFO    WriterThread:636 [datastore.py:open_for_write():77] open: /content/wandb/run-20220329_212004-1a183de4/run-1a183de4.wandb\n2022-03-29 21:20:09,377 DEBUG   SenderThread:636 [sender.py:send():235] send: header\n2022-03-29 21:20:09,379 DEBUG   SenderThread:636 [sender.py:send():235] send: run\n2022-03-29 21:20:09,476 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: check_version\n2022-03-29 21:20:09,477 INFO    SenderThread:636 [dir_watcher.py:__init__():169] watching files in: /content/wandb/run-20220329_212004-1a183de4/files\n2022-03-29 21:20:09,477 INFO    SenderThread:636 [sender.py:_start_run_threads():815] run started: 1a183de4 with start time 1648588804\n2022-03-29 21:20:09,477 DEBUG   SenderThread:636 [sender.py:send():235] send: summary\n2022-03-29 21:20:09,478 INFO    SenderThread:636 [sender.py:_save_file():947] saving file wandb-summary.json with policy end\n2022-03-29 21:20:09,478 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: check_version\n2022-03-29 21:20:09,543 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: run_start\n2022-03-29 21:20:10,481 INFO    Thread-7  :636 [dir_watcher.py:_on_file_created():217] file/dir created: /content/wandb/run-20220329_212004-1a183de4/files/wandb-summary.json\n2022-03-29 21:20:12,462 DEBUG   HandlerThread:636 [meta.py:__init__():37] meta init\n2022-03-29 21:20:12,462 DEBUG   HandlerThread:636 [meta.py:__init__():51] meta init done\n2022-03-29 21:20:12,463 DEBUG   HandlerThread:636 [meta.py:probe():211] probe\n2022-03-29 21:20:12,469 DEBUG   HandlerThread:636 [git.py:repo():33] git repository is invalid\n2022-03-29 21:20:12,469 DEBUG   HandlerThread:636 [meta.py:_save_pip():55] save pip\n2022-03-29 21:20:12,470 DEBUG   HandlerThread:636 [meta.py:_save_pip():69] save pip done\n2022-03-29 21:20:12,470 DEBUG   HandlerThread:636 [meta.py:probe():249] probe done\n2022-03-29 21:20:12,476 DEBUG   SenderThread:636 [sender.py:send():235] send: files\n2022-03-29 21:20:12,477 INFO    SenderThread:636 [sender.py:_save_file():947] saving file wandb-metadata.json with policy now\n2022-03-29 21:20:12,489 INFO    Thread-7  :636 [dir_watcher.py:_on_file_created():217] file/dir created: /content/wandb/run-20220329_212004-1a183de4/files/wandb-metadata.json\n2022-03-29 21:20:12,490 INFO    Thread-7  :636 [dir_watcher.py:_on_file_created():217] file/dir created: /content/wandb/run-20220329_212004-1a183de4/files/requirements.txt\n2022-03-29 21:20:12,499 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: stop_status\n2022-03-29 21:20:12,500 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: stop_status\n2022-03-29 21:20:12,565 DEBUG   SenderThread:636 [sender.py:send():235] send: telemetry\n2022-03-29 21:20:13,187 INFO    Thread-11 :636 [upload_job.py:push():137] Uploaded file /tmp/tmpb74a7agqwandb/16hbjkye-wandb-metadata.json\n2022-03-29 21:20:13,490 INFO    Thread-7  :636 [dir_watcher.py:_on_file_created():217] file/dir created: /content/wandb/run-20220329_212004-1a183de4/files/output.log\n2022-03-29 21:20:27,567 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: stop_status\n2022-03-29 21:20:27,568 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: stop_status\n2022-03-29 21:20:36,500 INFO    Thread-7  :636 [dir_watcher.py:_on_file_modified():230] file/dir modified: /content/wandb/run-20220329_212004-1a183de4/files/config.yaml\n2022-03-29 21:20:40,609 DEBUG   SenderThread:636 [sender.py:send():235] send: stats\n2022-03-29 21:20:42,637 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: stop_status\n2022-03-29 21:20:42,637 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: stop_status\n2022-03-29 21:20:58,606 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: stop_status\n2022-03-29 21:20:58,607 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: stop_status\n2022-03-29 21:21:10,767 DEBUG   SenderThread:636 [sender.py:send():235] send: stats\n2022-03-29 21:21:13,656 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: stop_status\n2022-03-29 21:21:13,656 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: stop_status\n2022-03-29 21:21:28,721 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: stop_status\n2022-03-29 21:21:28,721 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: stop_status\n2022-03-29 21:21:40,894 DEBUG   SenderThread:636 [sender.py:send():235] send: stats\n2022-03-29 21:21:43,774 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: stop_status\n2022-03-29 21:21:43,775 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: stop_status\n2022-03-29 21:21:58,823 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: stop_status\n2022-03-29 21:21:58,823 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: stop_status\n2022-03-29 21:22:09,716 DEBUG   SenderThread:636 [sender.py:send():235] send: telemetry\n2022-03-29 21:22:09,719 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: partial_history\n2022-03-29 21:22:09,719 DEBUG   SenderThread:636 [sender.py:send():235] send: telemetry\n2022-03-29 21:22:10,541 INFO    Thread-7  :636 [dir_watcher.py:_on_file_modified():230] file/dir modified: /content/wandb/run-20220329_212004-1a183de4/files/output.log\n2022-03-29 21:22:10,624 DEBUG   SenderThread:636 [sender.py:send():235] send: exit\n2022-03-29 21:22:10,624 INFO    SenderThread:636 [sender.py:send_exit():371] handling exit code: 1\n2022-03-29 21:22:10,625 INFO    SenderThread:636 [sender.py:send_exit():373] handling runtime: 121\n2022-03-29 21:22:10,625 INFO    SenderThread:636 [sender.py:_save_file():947] saving file wandb-summary.json with policy end\n2022-03-29 21:22:10,625 INFO    SenderThread:636 [sender.py:send_exit():379] send defer\n2022-03-29 21:22:10,626 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: defer\n2022-03-29 21:22:10,626 INFO    HandlerThread:636 [handler.py:handle_request_defer():164] handle defer: 0\n2022-03-29 21:22:10,626 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: defer\n2022-03-29 21:22:10,626 INFO    SenderThread:636 [sender.py:send_request_defer():388] handle sender defer: 0\n2022-03-29 21:22:10,626 INFO    SenderThread:636 [sender.py:transition_state():392] send defer: 1\n2022-03-29 21:22:10,627 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: defer\n2022-03-29 21:22:10,627 INFO    HandlerThread:636 [handler.py:handle_request_defer():164] handle defer: 1\n2022-03-29 21:22:10,708 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: poll_exit\n2022-03-29 21:22:10,708 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: defer\n2022-03-29 21:22:10,708 INFO    SenderThread:636 [sender.py:send_request_defer():388] handle sender defer: 1\n2022-03-29 21:22:10,708 INFO    SenderThread:636 [sender.py:transition_state():392] send defer: 2\n2022-03-29 21:22:10,709 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: poll_exit\n2022-03-29 21:22:10,709 DEBUG   SenderThread:636 [sender.py:send():235] send: stats\n2022-03-29 21:22:10,710 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: defer\n2022-03-29 21:22:10,710 INFO    HandlerThread:636 [handler.py:handle_request_defer():164] handle defer: 2\n2022-03-29 21:22:10,710 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: defer\n2022-03-29 21:22:10,710 INFO    SenderThread:636 [sender.py:send_request_defer():388] handle sender defer: 2\n2022-03-29 21:22:10,710 INFO    SenderThread:636 [sender.py:transition_state():392] send defer: 3\n2022-03-29 21:22:10,710 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: defer\n2022-03-29 21:22:10,711 INFO    HandlerThread:636 [handler.py:handle_request_defer():164] handle defer: 3\n2022-03-29 21:22:10,711 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: defer\n2022-03-29 21:22:10,711 INFO    SenderThread:636 [sender.py:send_request_defer():388] handle sender defer: 3\n2022-03-29 21:22:10,711 INFO    SenderThread:636 [sender.py:transition_state():392] send defer: 4\n2022-03-29 21:22:10,711 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: defer\n2022-03-29 21:22:10,711 INFO    HandlerThread:636 [handler.py:handle_request_defer():164] handle defer: 4\n2022-03-29 21:22:10,712 DEBUG   SenderThread:636 [sender.py:send():235] send: summary\n2022-03-29 21:22:10,712 INFO    SenderThread:636 [sender.py:_save_file():947] saving file wandb-summary.json with policy end\n2022-03-29 21:22:10,712 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: defer\n2022-03-29 21:22:10,713 INFO    SenderThread:636 [sender.py:send_request_defer():388] handle sender defer: 4\n2022-03-29 21:22:10,713 INFO    SenderThread:636 [sender.py:transition_state():392] send defer: 5\n2022-03-29 21:22:10,713 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: defer\n2022-03-29 21:22:10,713 INFO    HandlerThread:636 [handler.py:handle_request_defer():164] handle defer: 5\n2022-03-29 21:22:10,713 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: defer\n2022-03-29 21:22:10,713 INFO    SenderThread:636 [sender.py:send_request_defer():388] handle sender defer: 5\n2022-03-29 21:22:10,796 INFO    SenderThread:636 [sender.py:transition_state():392] send defer: 6\n2022-03-29 21:22:10,796 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: defer\n2022-03-29 21:22:10,796 INFO    HandlerThread:636 [handler.py:handle_request_defer():164] handle defer: 6\n2022-03-29 21:22:10,797 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: defer\n2022-03-29 21:22:10,797 INFO    SenderThread:636 [sender.py:send_request_defer():388] handle sender defer: 6\n2022-03-29 21:22:10,797 INFO    SenderThread:636 [dir_watcher.py:finish():283] shutting down directory watcher\n2022-03-29 21:22:10,838 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: poll_exit\n2022-03-29 21:22:11,542 INFO    Thread-7  :636 [dir_watcher.py:_on_file_modified():230] file/dir modified: /content/wandb/run-20220329_212004-1a183de4/files/output.log\n2022-03-29 21:22:11,542 INFO    SenderThread:636 [dir_watcher.py:_on_file_modified():230] file/dir modified: /content/wandb/run-20220329_212004-1a183de4/files/wandb-summary.json\n2022-03-29 21:22:11,543 INFO    SenderThread:636 [dir_watcher.py:_on_file_modified():230] file/dir modified: /content/wandb/run-20220329_212004-1a183de4/files/config.yaml\n2022-03-29 21:22:11,543 INFO    SenderThread:636 [dir_watcher.py:finish():313] scan: /content/wandb/run-20220329_212004-1a183de4/files\n2022-03-29 21:22:11,543 INFO    SenderThread:636 [dir_watcher.py:finish():327] scan save: /content/wandb/run-20220329_212004-1a183de4/files/wandb-metadata.json wandb-metadata.json\n2022-03-29 21:22:11,543 INFO    SenderThread:636 [dir_watcher.py:finish():327] scan save: /content/wandb/run-20220329_212004-1a183de4/files/requirements.txt requirements.txt\n2022-03-29 21:22:11,543 INFO    SenderThread:636 [dir_watcher.py:finish():327] scan save: /content/wandb/run-20220329_212004-1a183de4/files/wandb-summary.json wandb-summary.json\n2022-03-29 21:22:11,547 INFO    SenderThread:636 [dir_watcher.py:finish():327] scan save: /content/wandb/run-20220329_212004-1a183de4/files/config.yaml config.yaml\n2022-03-29 21:22:11,547 INFO    SenderThread:636 [dir_watcher.py:finish():327] scan save: /content/wandb/run-20220329_212004-1a183de4/files/output.log output.log\n2022-03-29 21:22:11,551 INFO    SenderThread:636 [sender.py:transition_state():392] send defer: 7\n2022-03-29 21:22:11,552 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: poll_exit\n2022-03-29 21:22:11,553 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: defer\n2022-03-29 21:22:11,555 INFO    HandlerThread:636 [handler.py:handle_request_defer():164] handle defer: 7\n2022-03-29 21:22:11,555 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: defer\n2022-03-29 21:22:11,555 INFO    SenderThread:636 [sender.py:send_request_defer():388] handle sender defer: 7\n2022-03-29 21:22:11,555 INFO    SenderThread:636 [file_pusher.py:finish():145] shutting down file pusher\n2022-03-29 21:22:11,655 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: poll_exit\n2022-03-29 21:22:11,656 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: poll_exit\n2022-03-29 21:22:11,759 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: poll_exit\n2022-03-29 21:22:11,760 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: poll_exit\n2022-03-29 21:22:11,863 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: poll_exit\n2022-03-29 21:22:11,863 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: poll_exit\n2022-03-29 21:22:11,879 INFO    Thread-14 :636 [upload_job.py:push():137] Uploaded file /content/wandb/run-20220329_212004-1a183de4/files/config.yaml\n2022-03-29 21:22:11,880 INFO    Thread-13 :636 [upload_job.py:push():137] Uploaded file /content/wandb/run-20220329_212004-1a183de4/files/wandb-summary.json\n2022-03-29 21:22:11,895 INFO    Thread-15 :636 [upload_job.py:push():137] Uploaded file /content/wandb/run-20220329_212004-1a183de4/files/output.log\n2022-03-29 21:22:11,902 INFO    Thread-12 :636 [upload_job.py:push():137] Uploaded file /content/wandb/run-20220329_212004-1a183de4/files/requirements.txt\n2022-03-29 21:22:11,964 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: poll_exit\n2022-03-29 21:22:11,964 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: poll_exit\n2022-03-29 21:22:12,066 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: poll_exit\n2022-03-29 21:22:12,066 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: poll_exit\n2022-03-29 21:22:12,102 INFO    Thread-6  :636 [sender.py:transition_state():392] send defer: 8\n2022-03-29 21:22:12,103 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: defer\n2022-03-29 21:22:12,103 INFO    HandlerThread:636 [handler.py:handle_request_defer():164] handle defer: 8\n2022-03-29 21:22:12,103 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: defer\n2022-03-29 21:22:12,103 INFO    SenderThread:636 [sender.py:send_request_defer():388] handle sender defer: 8\n2022-03-29 21:22:12,167 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: poll_exit\n2022-03-29 21:22:12,213 INFO    SenderThread:636 [sender.py:transition_state():392] send defer: 9\n2022-03-29 21:22:12,213 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: poll_exit\n2022-03-29 21:22:12,214 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: defer\n2022-03-29 21:22:12,214 INFO    HandlerThread:636 [handler.py:handle_request_defer():164] handle defer: 9\n2022-03-29 21:22:12,214 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: defer\n2022-03-29 21:22:12,214 INFO    SenderThread:636 [sender.py:send_request_defer():388] handle sender defer: 9\n2022-03-29 21:22:12,214 INFO    SenderThread:636 [sender.py:transition_state():392] send defer: 10\n2022-03-29 21:22:12,215 DEBUG   SenderThread:636 [sender.py:send():235] send: final\n2022-03-29 21:22:12,215 DEBUG   SenderThread:636 [sender.py:send():235] send: footer\n2022-03-29 21:22:12,216 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: defer\n2022-03-29 21:22:12,216 INFO    HandlerThread:636 [handler.py:handle_request_defer():164] handle defer: 10\n2022-03-29 21:22:12,216 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: defer\n2022-03-29 21:22:12,216 INFO    SenderThread:636 [sender.py:send_request_defer():388] handle sender defer: 10\n2022-03-29 21:22:12,314 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: poll_exit\n2022-03-29 21:22:12,315 DEBUG   SenderThread:636 [sender.py:send_request():249] send_request: poll_exit\n2022-03-29 21:22:12,315 INFO    SenderThread:636 [file_pusher.py:join():150] waiting for file pusher\n2022-03-29 21:22:12,466 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: sampled_history\n2022-03-29 21:22:12,467 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: get_summary\n2022-03-29 21:22:12,468 DEBUG   HandlerThread:636 [handler.py:handle_request():141] handle_request: shutdown\n2022-03-29 21:22:12,468 INFO    HandlerThread:636 [handler.py:finish():778] shutting down handler\n2022-03-29 21:22:13,216 INFO    WriterThread:636 [datastore.py:close():281] close: /content/wandb/run-20220329_212004-1a183de4/run-1a183de4.wandb\n2022-03-29 21:22:13,364 INFO    SenderThread:636 [sender.py:finish():1078] shutting down sender\n2022-03-29 21:22:13,364 INFO    SenderThread:636 [file_pusher.py:finish():145] shutting down file pusher\n2022-03-29 21:22:13,364 INFO    SenderThread:636 [file_pusher.py:join():150] waiting for file pusher\n2022-03-29 21:22:13,367 INFO    MainThread:636 [internal.py:handle_exit():82] Internal process exited\n</code></pre>\n<ol start=\"3\">\n<li>\n<p>When I dont use wandb model train properly</p>\n</li>\n<li>\n<p>Intresting thing is that when i run it on colab model train 1 epoch and after it crash but when is trained on kaggle it crashes before even start training</p>\n</li>\n</ol>\n<p><a href=\"https://colab.research.google.com/drive/1o_LYw1Men-1s0KPDMMaMci1O_YxCOS3u#scrollTo=Zd-ONNoxI0MV\" rel=\"noopener nofollow ugc\">colab notebook</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-31T18:20:54.250Z",
				"Answer_body": "<p>Hi Wojtek, can you give us your workspace link so we can make sure that all the files for your sweep are there?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-01T11:09:10.128Z",
				"Answer_body": "<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://wandb.ai/wualas/pytorch-sweeps-License-Plate-last-gpu/sweeps/mhru0h2m?workspace=user-wualas\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/18b592222b97bc09df3743831bb4929dec23611c.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https://wandb.ai/wualas/pytorch-sweeps-License-Plate-last-gpu/sweeps/mhru0h2m?workspace=user-wualas\" target=\"_blank\" rel=\"noopener\">W&amp;B</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/8aebbd5b65e6324b342a2c136685b4f564002b10.png\" class=\"thumbnail onebox-avatar\" width=\"96\" height=\"96\">\n\n<h3><a href=\"https://wandb.ai/wualas/pytorch-sweeps-License-Plate-last-gpu/sweeps/mhru0h2m?workspace=user-wualas\" target=\"_blank\" rel=\"noopener\">wualas</a></h3>\n\n  <p>Weights &amp; Biases, developer tools for machine learning</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://colab.research.google.com/drive/1o_LYw1Men-1s0KPDMMaMci1O_YxCOS3u#scrollTo=VZ85Q2OA7Tr4\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/df9d8a0977a9a2bfca938e36c01cbe9feb49739a.png\" class=\"site-icon\" width=\"16\" height=\"16\">\n\n      <a href=\"https://colab.research.google.com/drive/1o_LYw1Men-1s0KPDMMaMci1O_YxCOS3u#scrollTo=VZ85Q2OA7Tr4\" target=\"_blank\" rel=\"noopener nofollow ugc\">colab.research.google.com</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/e2eb089e1834a0581da1d893b1624f376f01ad6a.png\" class=\"thumbnail onebox-avatar\" width=\"260\" height=\"260\">\n\n<h3><a href=\"https://colab.research.google.com/drive/1o_LYw1Men-1s0KPDMMaMci1O_YxCOS3u#scrollTo=VZ85Q2OA7Tr4\" target=\"_blank\" rel=\"noopener nofollow ugc\">Google Colaboratory</a></h3>\n\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-07T02:20:14.716Z",
				"Answer_body": "<p>While going through your sweeps, runs 1-4 are working properly, but since 5 is still in the process of running, it\u2019s not populated yet. It\u2019s good that you got everything up and running now! Do you still need help with this issue since the sweeps are now able to find the file?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-11T15:36:04.987Z",
				"Answer_body": "<p>Hi Wojtek,</p>\n<p>I\u2019m just checking in again to see whether you still need help with this issue?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-14T17:19:32.023Z",
				"Answer_body": "<p>Hi Wojtek, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-31T11:09:30.292Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Pytorch sync_tensorboard help",
		"Question_link": "https://community.wandb.ai/t/pytorch-sync-tensorboard-help/1017",
		"Question_created_time": "2021-10-17T19:51:24.534Z",
		"Question_answer_count": 8,
		"Question_score_count": 1,
		"Question_view_count": 787,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m having some issues getting W&amp;B to sync with Tensorboard in PyTorch. According to this <a href=\"https://github.com/wandb/client/issues/493\" rel=\"noopener nofollow ugc\">issue</a> and the docs, I should initializing <code>SummaryWriter</code> after W&amp;B  <code>init</code> possibly using <code>wandb.tensorboard.patch</code>. So far I haven\u2019t been able to get this to work with either <code>torch.utils.tensorboard</code> or <code>tensorboardX</code> and with or without the patch. Not sure if this is a bug or I\u2019m missing something. Thanks.</p>\n<p>Windows 11<br>\nPython 3.8.8<br>\nwandb 0.12.4<br>\ntorch 1.9.1</p>\n<pre><code class=\"lang-auto\"> wandb.tensorboard.patch(root_logdir=\"logs\")\n wandb.init(config=hyperparameter_defaults, project=f\"ppo_{env_name}_torch\", sync_tensorboard=True, save_code=True, name=run_name)\n config = wandb.config\n writer = SummaryWriter(f\"logs\")\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-19T15:30:08.699Z",
				"Answer_body": "<p>Hey there, taking a look!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-26T12:59:29.832Z",
				"Answer_body": "<p>Hey there, are you getting an error? If so could you send the stack trace?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-26T14:02:42.372Z",
				"Answer_body": "<p>I don\u2019t get any errors. The code runs and logs to Tensorboard, but nothing gets logged to W&amp;B. Here\u2019s an example run:</p>\n<p>dazzling-microwave-39: <a href=\"https://wandb.ai/tims457/mbrl/runs/8x3u2qoi\" class=\"inline-onebox\">Weights &amp; Biases</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-28T17:17:55.706Z",
				"Answer_body": "<p>Could you share the debug logs for this run? They are in the run directory relative to your script.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-29T23:55:11.620Z",
				"Answer_body": "<p>debug.log</p>\n<pre><code class=\"lang-auto\">2021-10-26 07:58:59,137 INFO    MainThread:33572 [wandb_setup.py:_flush():71] setting env: {}\n2021-10-26 07:58:59,137 INFO    MainThread:33572 [wandb_setup.py:_flush():71] setting login settings: {}\n2021-10-26 07:58:59,138 INFO    MainThread:33572 [wandb_init.py:_log_setup():357] Logging user logs to C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\logs\\debug.log\n2021-10-26 07:58:59,138 INFO    MainThread:33572 [wandb_init.py:_log_setup():358] Logging internal logs to C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\logs\\debug-internal.log\n2021-10-26 07:58:59,139 INFO    MainThread:33572 [wandb_init.py:init():390] calling init triggers\n2021-10-26 07:58:59,139 INFO    MainThread:33572 [wandb_init.py:init():395] wandb.init called with sweep_config: {}\nconfig: {'gamma': 0.99, 'gae_lambda': 0.95, 'eps': 0.2, 'batch_size': 128, 'timesteps': 2000, 'n_epochs': 40, 'c1': 0.5, 'c2': 0.001, 'actor_lr': 0.0003, 'critic_lr': 0.001, 'decay_lr': True, 'lr_decay': 1, 'epochs': 150, 'test_freq': 20, 'reward_threshold': 150}\n2021-10-26 07:58:59,139 INFO    MainThread:33572 [wandb_init.py:init():435] starting backend\n2021-10-26 07:58:59,139 INFO    MainThread:33572 [backend.py:_multiprocessing_setup():94] multiprocessing start_methods=spawn, using: spawn\n2021-10-26 07:58:59,151 INFO    MainThread:33572 [backend.py:ensure_launched():198] starting backend process...\n2021-10-26 07:58:59,266 INFO    MainThread:33572 [backend.py:ensure_launched():203] started backend process with pid: 16652\n2021-10-26 07:58:59,267 INFO    MainThread:33572 [wandb_init.py:init():444] backend started and connected\n2021-10-26 07:58:59,267 INFO    MainThread:33572 [wandb_init.py:init():503] updated telemetry\n2021-10-26 07:58:59,346 INFO    MainThread:33572 [wandb_init.py:init():533] communicating current version\n2021-10-26 07:59:01,269 INFO    MainThread:33572 [wandb_init.py:init():538] got version response \n2021-10-26 07:59:01,269 INFO    MainThread:33572 [wandb_init.py:init():548] communicating run to backend with 30 second timeout\n2021-10-26 07:59:01,362 INFO    MainThread:33572 [wandb_init.py:init():576] starting run threads in backend\n2021-10-26 07:59:06,373 INFO    MainThread:33572 [wandb_run.py:_console_start():1693] atexit reg\n2021-10-26 07:59:06,374 INFO    MainThread:33572 [wandb_run.py:_redirect():1567] redirect: SettingsConsole.WRAP\n2021-10-26 07:59:06,374 INFO    MainThread:33572 [wandb_run.py:_redirect():1604] Wrapping output streams.\n2021-10-26 07:59:06,377 INFO    MainThread:33572 [wandb_run.py:_redirect():1628] Redirects installed.\n2021-10-26 07:59:06,377 INFO    MainThread:33572 [wandb_init.py:init():603] run started, returning control to user process\n2021-10-26 07:59:06,377 INFO    MainThread:33572 [wandb_watch.py:watch():43] Watching\n2021-10-26 07:59:06,378 INFO    MainThread:33572 [wandb_run.py:_tensorboard_callback():984] tensorboard callback: logs, None\n2021-10-26 08:01:02,573 INFO    MainThread:33572 [wandb_run.py:_atexit_cleanup():1663] got exitcode: 255\n2021-10-26 08:01:02,575 INFO    MainThread:33572 [wandb_run.py:_restore():1635] restore\n2021-10-26 08:01:02,833 INFO    MainThread:33572 [wandb_run.py:_wait_for_finish():1793] got exit ret: file_counts {\n  wandb_count: 2\n  other_count: 1\n}\npusher_stats {\n  uploaded_bytes: 41021\n  total_bytes: 41021\n}\n\n2021-10-26 08:01:07,935 INFO    MainThread:33572 [wandb_run.py:_wait_for_finish():1793] got exit ret: None\n2021-10-26 08:01:09,929 INFO    MainThread:33572 [wandb_run.py:_wait_for_finish():1793] got exit ret: file_counts {\n  wandb_count: 2\n  other_count: 1\n}\npusher_stats {\n  uploaded_bytes: 41021\n  total_bytes: 41021\n}\n\n2021-10-26 08:01:10,043 INFO    MainThread:33572 [wandb_run.py:_wait_for_finish():1793] got exit ret: file_counts {\n  wandb_count: 2\n  other_count: 1\n}\npusher_stats {\n  uploaded_bytes: 41021\n  total_bytes: 41021\n}\n\n2021-10-26 08:01:10,560 INFO    MainThread:33572 [wandb_run.py:_wait_for_finish():1793] got exit ret: file_counts {\n  wandb_count: 6\n  other_count: 1\n}\npusher_stats {\n  uploaded_bytes: 41021\n  total_bytes: 66539\n}\n\n2021-10-26 08:01:10,667 INFO    MainThread:33572 [wandb_run.py:_wait_for_finish():1793] got exit ret: file_counts {\n  wandb_count: 7\n  other_count: 1\n}\npusher_stats {\n  uploaded_bytes: 41021\n  total_bytes: 88164\n}\n\n2021-10-26 08:01:10,769 INFO    MainThread:33572 [wandb_run.py:_wait_for_finish():1793] got exit ret: file_counts {\n  wandb_count: 7\n  other_count: 1\n}\npusher_stats {\n  uploaded_bytes: 88164\n  total_bytes: 88164\n}\n\n2021-10-26 08:01:10,871 INFO    MainThread:33572 [wandb_run.py:_wait_for_finish():1793] got exit ret: file_counts {\n  wandb_count: 7\n  other_count: 1\n}\npusher_stats {\n  uploaded_bytes: 88164\n  total_bytes: 88164\n}\n\n2021-10-26 08:01:10,972 INFO    MainThread:33572 [wandb_run.py:_wait_for_finish():1793] got exit ret: file_counts {\n  wandb_count: 7\n  other_count: 1\n}\npusher_stats {\n  uploaded_bytes: 88164\n  total_bytes: 88164\n}\n\n2021-10-26 08:01:11,104 INFO    MainThread:33572 [wandb_run.py:_wait_for_finish():1793] got exit ret: file_counts {\n  wandb_count: 7\n  other_count: 1\n}\npusher_stats {\n  uploaded_bytes: 88164\n  total_bytes: 88164\n}\n\n2021-10-26 08:01:11,319 INFO    MainThread:33572 [wandb_run.py:_wait_for_finish():1793] got exit ret: done: true\nexit_result {\n}\nfile_counts {\n  wandb_count: 7\n  other_count: 1\n}\npusher_stats {\n  uploaded_bytes: 88164\n  total_bytes: 88164\n}\nlocal_info {\n}\n\n2021-10-26 08:01:12,789 INFO    MainThread:33572 [wandb_run.py:_append_history():2011] rendering history\n2021-10-26 08:01:12,789 INFO    MainThread:33572 [wandb_run.py:_append_summary():1966] rendering summary\n2021-10-26 08:01:12,789 INFO    MainThread:33572 [wandb_run.py:_append_files():2061] logging synced files\n\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-29T23:55:44.926Z",
				"Answer_body": "<p>debug-internal.log</p>\n<pre><code class=\"lang-auto\">2021-10-26 07:59:01,207 INFO    MainThread:16652 [internal.py:wandb_internal():88] W&amp;B internal server running at pid: 16652, started at: 2021-10-26 07:59:01.207113\n2021-10-26 07:59:01,209 INFO    WriterThread:16652 [datastore.py:open_for_write():77] open: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\run-8x3u2qoi.wandb\n2021-10-26 07:59:01,209 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: check_version\n2021-10-26 07:59:01,213 DEBUG   SenderThread:16652 [sender.py:send():185] send: header\n2021-10-26 07:59:01,213 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: check_version\n2021-10-26 07:59:01,270 DEBUG   SenderThread:16652 [sender.py:send():185] send: run\n2021-10-26 07:59:01,362 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: run_start\n2021-10-26 07:59:01,364 INFO    SenderThread:16652 [dir_watcher.py:__init__():169] watching files in: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\n2021-10-26 07:59:01,364 INFO    SenderThread:16652 [sender.py:_start_run_threads():768] run started: 8x3u2qoi with start time 1635256739\n2021-10-26 07:59:01,364 DEBUG   SenderThread:16652 [sender.py:send():185] send: summary\n2021-10-26 07:59:01,364 INFO    SenderThread:16652 [sender.py:_save_file():901] saving file wandb-summary.json with policy end\n2021-10-26 07:59:02,365 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_created():217] file/dir created: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\wandb-summary.json\n2021-10-26 07:59:03,592 DEBUG   HandlerThread:16652 [meta.py:__init__():40] meta init\n2021-10-26 07:59:03,593 DEBUG   HandlerThread:16652 [meta.py:__init__():54] meta init done\n2021-10-26 07:59:03,593 DEBUG   HandlerThread:16652 [meta.py:probe():212] probe\n2021-10-26 07:59:03,645 DEBUG   HandlerThread:16652 [meta.py:_setup_git():202] setup git\n2021-10-26 07:59:03,796 DEBUG   HandlerThread:16652 [meta.py:_setup_git():209] setup git done\n2021-10-26 07:59:03,796 DEBUG   HandlerThread:16652 [meta.py:_save_code():90] save code\n2021-10-26 07:59:03,873 DEBUG   HandlerThread:16652 [meta.py:_save_code():111] save code done\n2021-10-26 07:59:03,873 DEBUG   HandlerThread:16652 [meta.py:_save_patches():128] save patches\n2021-10-26 07:59:04,310 DEBUG   HandlerThread:16652 [meta.py:_save_patches():170] save patches done\n2021-10-26 07:59:04,310 DEBUG   HandlerThread:16652 [meta.py:_save_pip():58] save pip\n2021-10-26 07:59:04,311 DEBUG   HandlerThread:16652 [meta.py:_save_pip():72] save pip done\n2021-10-26 07:59:04,312 DEBUG   HandlerThread:16652 [meta.py:_save_conda():79] save conda\n2021-10-26 07:59:04,364 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_created():217] file/dir created: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\conda-environment.yaml\n2021-10-26 07:59:04,365 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_created():217] file/dir created: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\code\\ppo_torch.py\n2021-10-26 07:59:04,365 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_created():217] file/dir created: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\requirements.txt\n2021-10-26 07:59:04,365 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_created():217] file/dir created: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\diff.patch\n2021-10-26 07:59:04,365 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_created():217] file/dir created: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\code\n2021-10-26 07:59:07,367 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_created():217] file/dir created: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 07:59:11,371 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 07:59:15,374 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 07:59:18,406 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\conda-environment.yaml\n2021-10-26 07:59:18,407 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 07:59:18,630 DEBUG   HandlerThread:16652 [meta.py:_save_conda():87] save conda done\n2021-10-26 07:59:18,631 DEBUG   HandlerThread:16652 [meta.py:probe():250] probe done\n2021-10-26 07:59:18,636 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: stop_status\n2021-10-26 07:59:18,636 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: stop_status\n2021-10-26 07:59:18,638 INFO    HandlerThread:16652 [handler.py:handle_tbrecord():640] handling tbrecord: tbrecord {\n  log_dir: \"logs\"\n  save: true\n}\n\n2021-10-26 07:59:18,639 DEBUG   HandlerThread:16652 [config_util.py:dict_from_config_file():101] no default config file found in config-defaults.yaml\n2021-10-26 07:59:18,667 DEBUG   Thread-30 :16652 [tb_watcher.py:_process_events():269] Encountered tensorboard directory watcher error: [WinError 1314] A required privilege is not held by the client: 'C:\\\\Users\\\\tim\\\\GitHub\\\\rl_agents\\\\logs\\\\events.out.tfevents.1635256746.DESKTOP-7MG5U16.33572.0' -&gt; 'C:\\\\Users\\\\tim\\\\GitHub\\\\rl_agents\\\\wandb\\\\run-20211026_075859-8x3u2qoi\\\\files\\\\events.out.tfevents.1635256746.DESKTOP-7MG5U16.33572.0'\n2021-10-26 07:59:18,695 DEBUG   SenderThread:16652 [sender.py:send():185] send: tbrecord\n2021-10-26 07:59:18,696 DEBUG   SenderThread:16652 [sender.py:send():185] send: files\n2021-10-26 07:59:18,696 INFO    SenderThread:16652 [sender.py:_save_file():901] saving file wandb-metadata.json with policy now\n2021-10-26 07:59:18,697 INFO    SenderThread:16652 [sender.py:_save_file():901] saving file code\\ppo_torch.py with policy now\n2021-10-26 07:59:18,699 INFO    SenderThread:16652 [sender.py:_save_file():901] saving file diff.patch with policy now\n2021-10-26 07:59:18,987 INFO    Thread-31 :16652 [upload_job.py:push():137] Uploaded file C:\\Users\\tim\\AppData\\Local\\Temp\\tmp70meo4ibwandb\\1turuybf-wandb-metadata.json\n2021-10-26 07:59:18,999 INFO    Thread-33 :16652 [upload_job.py:push():137] Uploaded file C:\\Users\\tim\\AppData\\Local\\Temp\\tmp70meo4ibwandb\\2dtlm77i-diff.patch\n2021-10-26 07:59:19,045 INFO    Thread-32 :16652 [upload_job.py:push():137] Uploaded file C:\\Users\\tim\\AppData\\Local\\Temp\\tmp70meo4ibwandb\\1pyzaeuj-code/ppo_torch.py\n2021-10-26 07:59:19,409 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_created():217] file/dir created: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\wandb-metadata.json\n2021-10-26 07:59:22,410 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 07:59:24,411 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 07:59:26,373 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: stop_status\n2021-10-26 07:59:26,373 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: stop_status\n2021-10-26 07:59:28,416 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 07:59:32,419 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 07:59:32,654 DEBUG   SenderThread:16652 [sender.py:send():185] send: stats\n2021-10-26 07:59:36,420 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 07:59:38,423 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 07:59:41,439 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: stop_status\n2021-10-26 07:59:41,439 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: stop_status\n2021-10-26 07:59:42,425 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 07:59:44,427 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 07:59:48,431 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 07:59:52,435 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 07:59:54,441 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 07:59:56,493 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: stop_status\n2021-10-26 07:59:56,493 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: stop_status\n2021-10-26 07:59:58,444 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:00:02,453 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:00:03,625 DEBUG   SenderThread:16652 [sender.py:send():185] send: stats\n2021-10-26 08:00:06,457 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:00:10,458 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:00:11,551 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: stop_status\n2021-10-26 08:00:11,551 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: stop_status\n2021-10-26 08:00:12,460 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:00:16,463 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:00:18,464 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:00:22,468 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:00:24,470 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:00:26,622 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: stop_status\n2021-10-26 08:00:26,622 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: stop_status\n2021-10-26 08:00:28,472 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:00:30,475 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:00:34,478 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:00:34,490 DEBUG   SenderThread:16652 [sender.py:send():185] send: stats\n2021-10-26 08:00:38,481 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:00:40,481 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:00:41,679 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: stop_status\n2021-10-26 08:00:41,679 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: stop_status\n2021-10-26 08:00:44,485 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:00:46,489 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:00:50,492 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:00:52,493 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:00:56,496 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:00:56,755 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: stop_status\n2021-10-26 08:00:56,755 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: stop_status\n2021-10-26 08:01:00,500 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:01:02,500 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:01:02,569 WARNING MainThread:16652 [internal.py:wandb_internal():147] Internal process interrupt: 1\n2021-10-26 08:01:02,578 DEBUG   SenderThread:16652 [sender.py:send():185] send: history\n2021-10-26 08:01:02,579 DEBUG   SenderThread:16652 [sender.py:send():185] send: summary\n2021-10-26 08:01:02,582 INFO    SenderThread:16652 [sender.py:_save_file():901] saving file wandb-summary.json with policy end\n2021-10-26 08:01:02,828 DEBUG   SenderThread:16652 [sender.py:send():185] send: telemetry\n2021-10-26 08:01:02,829 DEBUG   SenderThread:16652 [sender.py:send():185] send: exit\n2021-10-26 08:01:02,829 INFO    SenderThread:16652 [sender.py:send_exit():317] handling exit code: 255\n2021-10-26 08:01:02,829 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: poll_exit\n2021-10-26 08:01:02,829 INFO    SenderThread:16652 [sender.py:send_exit():319] handling runtime: 121\n2021-10-26 08:01:02,831 INFO    SenderThread:16652 [sender.py:_save_file():901] saving file wandb-summary.json with policy end\n2021-10-26 08:01:02,832 INFO    SenderThread:16652 [sender.py:send_exit():329] send defer\n2021-10-26 08:01:02,832 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: poll_exit\n2021-10-26 08:01:02,832 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: defer\n2021-10-26 08:01:02,833 INFO    HandlerThread:16652 [handler.py:handle_request_defer():147] handle defer: 0\n2021-10-26 08:01:02,833 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: defer\n2021-10-26 08:01:02,833 INFO    SenderThread:16652 [sender.py:send_request_defer():338] handle sender defer: 0\n2021-10-26 08:01:02,833 INFO    SenderThread:16652 [sender.py:transition_state():342] send defer: 1\n2021-10-26 08:01:02,833 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: defer\n2021-10-26 08:01:02,833 INFO    HandlerThread:16652 [handler.py:handle_request_defer():147] handle defer: 1\n2021-10-26 08:01:02,923 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: defer\n2021-10-26 08:01:02,923 INFO    SenderThread:16652 [sender.py:send_request_defer():338] handle sender defer: 1\n2021-10-26 08:01:02,923 INFO    SenderThread:16652 [sender.py:transition_state():342] send defer: 2\n2021-10-26 08:01:02,924 DEBUG   SenderThread:16652 [sender.py:send():185] send: stats\n2021-10-26 08:01:02,924 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: defer\n2021-10-26 08:01:02,925 INFO    HandlerThread:16652 [handler.py:handle_request_defer():147] handle defer: 2\n2021-10-26 08:01:03,502 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\wandb-summary.json\n2021-10-26 08:01:03,503 INFO    Thread-12 :16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:01:09,927 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: defer\n2021-10-26 08:01:09,927 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: poll_exit\n2021-10-26 08:01:09,927 INFO    SenderThread:16652 [sender.py:send_request_defer():338] handle sender defer: 2\n2021-10-26 08:01:09,927 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: poll_exit\n2021-10-26 08:01:09,928 INFO    SenderThread:16652 [sender.py:transition_state():342] send defer: 3\n2021-10-26 08:01:09,928 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: poll_exit\n2021-10-26 08:01:09,928 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: poll_exit\n2021-10-26 08:01:09,928 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: defer\n2021-10-26 08:01:09,929 INFO    HandlerThread:16652 [handler.py:handle_request_defer():147] handle defer: 3\n2021-10-26 08:01:09,930 DEBUG   SenderThread:16652 [sender.py:send():185] send: summary\n2021-10-26 08:01:09,934 INFO    SenderThread:16652 [sender.py:_save_file():901] saving file wandb-summary.json with policy end\n2021-10-26 08:01:09,934 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: defer\n2021-10-26 08:01:09,934 INFO    SenderThread:16652 [sender.py:send_request_defer():338] handle sender defer: 3\n2021-10-26 08:01:09,934 INFO    SenderThread:16652 [sender.py:transition_state():342] send defer: 4\n2021-10-26 08:01:09,935 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: defer\n2021-10-26 08:01:09,936 INFO    HandlerThread:16652 [handler.py:handle_request_defer():147] handle defer: 4\n2021-10-26 08:01:09,936 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: defer\n2021-10-26 08:01:09,936 INFO    SenderThread:16652 [sender.py:send_request_defer():338] handle sender defer: 4\n2021-10-26 08:01:10,030 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: poll_exit\n2021-10-26 08:01:10,042 INFO    SenderThread:16652 [sender.py:transition_state():342] send defer: 5\n2021-10-26 08:01:10,043 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: poll_exit\n2021-10-26 08:01:10,043 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: defer\n2021-10-26 08:01:10,043 INFO    HandlerThread:16652 [handler.py:handle_request_defer():147] handle defer: 5\n2021-10-26 08:01:10,044 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: defer\n2021-10-26 08:01:10,044 INFO    SenderThread:16652 [sender.py:send_request_defer():338] handle sender defer: 5\n2021-10-26 08:01:10,044 INFO    SenderThread:16652 [dir_watcher.py:finish():283] shutting down directory watcher\n2021-10-26 08:01:10,145 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: poll_exit\n2021-10-26 08:01:10,509 INFO    SenderThread:16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\wandb-summary.json\n2021-10-26 08:01:10,510 INFO    SenderThread:16652 [dir_watcher.py:_on_file_modified():230] file/dir modified: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\config.yaml\n2021-10-26 08:01:10,512 INFO    SenderThread:16652 [dir_watcher.py:finish():313] scan: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\n2021-10-26 08:01:10,513 INFO    SenderThread:16652 [dir_watcher.py:finish():327] scan save: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\conda-environment.yaml conda-environment.yaml\n2021-10-26 08:01:10,515 INFO    SenderThread:16652 [dir_watcher.py:finish():327] scan save: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\config.yaml config.yaml\n2021-10-26 08:01:10,517 INFO    SenderThread:16652 [dir_watcher.py:finish():327] scan save: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\diff.patch diff.patch\n2021-10-26 08:01:10,518 INFO    SenderThread:16652 [dir_watcher.py:finish():327] scan save: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log output.log\n2021-10-26 08:01:10,535 INFO    SenderThread:16652 [dir_watcher.py:finish():327] scan save: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\requirements.txt requirements.txt\n2021-10-26 08:01:10,537 INFO    SenderThread:16652 [dir_watcher.py:finish():327] scan save: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\wandb-metadata.json wandb-metadata.json\n2021-10-26 08:01:10,537 INFO    SenderThread:16652 [dir_watcher.py:finish():327] scan save: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\wandb-summary.json wandb-summary.json\n2021-10-26 08:01:10,553 INFO    SenderThread:16652 [dir_watcher.py:finish():327] scan save: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\code\\ppo_torch.py code\\ppo_torch.py\n2021-10-26 08:01:10,553 INFO    SenderThread:16652 [sender.py:transition_state():342] send defer: 6\n2021-10-26 08:01:10,554 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: poll_exit\n2021-10-26 08:01:10,556 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: defer\n2021-10-26 08:01:10,557 INFO    HandlerThread:16652 [handler.py:handle_request_defer():147] handle defer: 6\n2021-10-26 08:01:10,559 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: defer\n2021-10-26 08:01:10,559 INFO    SenderThread:16652 [sender.py:send_request_defer():338] handle sender defer: 6\n2021-10-26 08:01:10,559 INFO    SenderThread:16652 [file_pusher.py:finish():177] shutting down file pusher\n2021-10-26 08:01:10,666 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: poll_exit\n2021-10-26 08:01:10,666 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: poll_exit\n2021-10-26 08:01:10,768 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: poll_exit\n2021-10-26 08:01:10,768 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: poll_exit\n2021-10-26 08:01:10,804 INFO    Thread-37 :16652 [upload_job.py:push():137] Uploaded file C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\requirements.txt\n2021-10-26 08:01:10,842 INFO    Thread-34 :16652 [upload_job.py:push():137] Uploaded file C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\conda-environment.yaml\n2021-10-26 08:01:10,856 INFO    Thread-36 :16652 [upload_job.py:push():137] Uploaded file C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\output.log\n2021-10-26 08:01:10,856 INFO    Thread-35 :16652 [upload_job.py:push():137] Uploaded file C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\config.yaml\n2021-10-26 08:01:10,856 INFO    Thread-38 :16652 [upload_job.py:push():137] Uploaded file C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\files\\wandb-summary.json\n2021-10-26 08:01:10,870 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: poll_exit\n2021-10-26 08:01:10,870 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: poll_exit\n2021-10-26 08:01:10,971 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: poll_exit\n2021-10-26 08:01:10,971 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: poll_exit\n2021-10-26 08:01:11,057 INFO    Thread-11 :16652 [sender.py:transition_state():342] send defer: 7\n2021-10-26 08:01:11,057 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: defer\n2021-10-26 08:01:11,057 INFO    HandlerThread:16652 [handler.py:handle_request_defer():147] handle defer: 7\n2021-10-26 08:01:11,057 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: defer\n2021-10-26 08:01:11,058 INFO    SenderThread:16652 [sender.py:send_request_defer():338] handle sender defer: 7\n2021-10-26 08:01:11,073 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: poll_exit\n2021-10-26 08:01:11,103 INFO    SenderThread:16652 [sender.py:transition_state():342] send defer: 8\n2021-10-26 08:01:11,103 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: poll_exit\n2021-10-26 08:01:11,104 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: defer\n2021-10-26 08:01:11,104 INFO    HandlerThread:16652 [handler.py:handle_request_defer():147] handle defer: 8\n2021-10-26 08:01:11,104 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: defer\n2021-10-26 08:01:11,104 INFO    SenderThread:16652 [sender.py:send_request_defer():338] handle sender defer: 8\n2021-10-26 08:01:11,104 INFO    SenderThread:16652 [sender.py:transition_state():342] send defer: 9\n2021-10-26 08:01:11,105 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: defer\n2021-10-26 08:01:11,105 INFO    HandlerThread:16652 [handler.py:handle_request_defer():147] handle defer: 9\n2021-10-26 08:01:11,105 DEBUG   SenderThread:16652 [sender.py:send():185] send: final\n2021-10-26 08:01:11,106 DEBUG   SenderThread:16652 [sender.py:send():185] send: footer\n2021-10-26 08:01:11,106 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: defer\n2021-10-26 08:01:11,106 INFO    SenderThread:16652 [sender.py:send_request_defer():338] handle sender defer: 9\n2021-10-26 08:01:11,205 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: poll_exit\n2021-10-26 08:01:11,205 DEBUG   SenderThread:16652 [sender.py:send_request():199] send_request: poll_exit\n2021-10-26 08:01:11,205 INFO    SenderThread:16652 [file_pusher.py:join():182] waiting for file pusher\n2021-10-26 08:01:11,321 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: get_summary\n2021-10-26 08:01:11,324 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: sampled_history\n2021-10-26 08:01:11,324 DEBUG   HandlerThread:16652 [handler.py:handle_request():130] handle_request: shutdown\n2021-10-26 08:01:11,325 INFO    HandlerThread:16652 [handler.py:finish():731] shutting down handler\n2021-10-26 08:01:12,106 INFO    WriterThread:16652 [datastore.py:close():281] close: C:\\Users\\tim\\GitHub\\rl_agents\\wandb\\run-20211026_075859-8x3u2qoi\\run-8x3u2qoi.wandb\n2021-10-26 08:01:12,320 INFO    SenderThread:16652 [sender.py:finish():1029] shutting down sender\n2021-10-26 08:01:12,320 INFO    SenderThread:16652 [file_pusher.py:finish():177] shutting down file pusher\n2021-10-26 08:01:12,320 INFO    SenderThread:16652 [file_pusher.py:join():182] waiting for file pusher\n2021-10-26 08:01:12,322 INFO    MainThread:16652 [internal.py:handle_exit():78] Internal process exited\n\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-07T18:22:11.404Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/tims457\">@tims457</a> I am terribly sorry for the delay. Removing the <code>sync_tensorboard=True</code> argument from <code>wandb.init()</code>. If you want more information on using <code>wandb.tensorboard.patch()</code> check out this <a href=\"https://community.wandb.ai/t/pytorch-sync-tensorboard-help/1017/3\">FAQ</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-30T11:59:40.291Z",
				"Answer_body": "<p>Not sure if you\u2019ve solved this by now. I\u2019ve expereinced something similar. It turned out that wandb wants to create a symbolic link which it can\u2019t simply do on Windows. When I run my script as admin everything worls fine.  You could try that as well.<br>\nIt\u2019s not very convenient but works for now.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Accidentally deleted user account in local - is there any way to recover user or projects?",
		"Question_link": "https://community.wandb.ai/t/accidentally-deleted-user-account-in-local-is-there-any-way-to-recover-user-or-projects/2163",
		"Question_created_time": "2022-03-28T13:37:08.027Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 116,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>While investigating an unrelated issue I incorrectly thought there was something wrong with the user as the local instance was having issues in the GUI. I tried a lot of troubleshooting steps, one of which I think included an attempt to recreate the account.</p>\n<p>Is there a way to recover the data associated with the old account or to recover the account itself? I tried to dig around myself and found entries relating to the old user in the mysql database and was hopeful there was a way I could recreate the account or recover the data to a new user in our local instance.  Is this at all possible?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-28T20:02:46.441Z",
				"Answer_body": "<p>A shot in the dark but If I deleted the old user_id and entity_id from the users and entities table and updated the new account to have the old user_id / entity_id would that potentially work?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-29T11:36:37.444Z",
				"Answer_body": "<p>Hey Andrew,</p>\n<p>I\u2019ll double-check with the team to see if there is a way to recover the account and get back to you.</p>\n<p>Best,<br>\nArman</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-27T20:03:39.316Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Image plotting tells lies(samples are not from the same iteration when not trained)!",
		"Question_link": "https://community.wandb.ai/t/image-plotting-tells-lies-samples-are-not-from-the-same-iteration-when-not-trained/2047",
		"Question_created_time": "2022-03-08T23:42:45.898Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 191,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>As you can see, when I push the image slider to 13500, while the red model is not trained yet to that iteration, the wandb shows a sample for it. I guess it is the last sample of the model, but wandb I guess at least show exactly from which iteration this image is coming from because I think this way is misleading. I mean, if someone does not pay attention they may think they are comparing the quality of the samples at the same number of iterations.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/f47d3c9714bbc13b8a32401fc97695379b5f804d.jpeg\" data-download-href=\"/uploads/short-url/ySQOUszDVHpVqz8QnJLmnU2HItf.jpeg?dl=1\" title=\"Screen Shot 2022-03-08 at 6.27.10 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f47d3c9714bbc13b8a32401fc97695379b5f804d_2_690x447.jpeg\" alt=\"Screen Shot 2022-03-08 at 6.27.10 PM\" data-base62-sha1=\"ySQOUszDVHpVqz8QnJLmnU2HItf\" width=\"690\" height=\"447\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f47d3c9714bbc13b8a32401fc97695379b5f804d_2_690x447.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f47d3c9714bbc13b8a32401fc97695379b5f804d_2_1035x670.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f47d3c9714bbc13b8a32401fc97695379b5f804d_2_1380x894.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f47d3c9714bbc13b8a32401fc97695379b5f804d_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-03-08 at 6.27.10 PM</span><span class=\"informations\">2332\u00d71512 177 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-09T23:38:38.546Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/miladink\">@miladink</a>,</p>\n<p>Thank you for reporting this. Would it be possible for you to share a link to the page where you are seeing this behaviour? I\u2019ll report it to our engineering team to have this issue resolved.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-15T19:49:48.775Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/miladink\">@miladink</a>,</p>\n<p>I wanted to follow up here with you. Would it be possible to share a link where you see this behavior? It will be very helpful for us to debug this issue.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-25T20:00:21.627Z",
				"Answer_body": "<p>Hi  <a class=\"mention\" href=\"/u/miladink\">@miladink</a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-24T20:00:31.091Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Homogenizing x-axis among plots",
		"Question_link": "https://community.wandb.ai/t/homogenizing-x-axis-among-plots/2132",
		"Question_created_time": "2022-03-22T12:47:39.189Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 189,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello WandB community,</p>\n<p>I am having trouble doing something that I believe should be pretty straightforward. <a href=\"https://wandb.ai/catai/MIDL%2010%20splits?workspace=user-carloshernandezp\">Here is the link to the Dashboard</a></p>\n<p>I am training ten different splits on some data and I am logging some metrics, pretty standard stuff. Specifically I am logging some training and validation. Whenever the Validation Area Under Curve (<code>Val AUC</code>) surpasses the previous highest, I compute some metrics for the Test Set.  After the training script is done, I download all the information in <code>.csv</code> files</p>\n<p>The problem arises when comparing plots as the <code>X-axis</code> or <code>Step</code> is different for each one. For example: if we take a look at the run <code>Pleasant-elevator-24</code> the highest <code>Val AUC</code> happens at <code>Step</code> 530. But the logged value of  <code>Test auc</code> is at 530.</p>\n<p>What I would like to have the <code>X Steps</code> of all the plots synced.</p>\n<p>My code to plot this is the following:</p>\n<pre><code class=\"lang-auto\">if max_auc&lt;metrics[0] and epoch &gt;5:\n          max_auc = metrics[0]\n          torch.save(model.state_dict(), os.path.join(args.results_dir, \"s_{}_{}_checkpoint.pt\".format(round(metrics[0],3), cur)))\n          wandb.log({\"P-R curve\" : wandb.plot.pr_curve(metrics[1], metrics[2], labels=['Negative', 'Positive'])})     \n    \n          results_dict, test_error, test_auc, acc_logger, metrics_test = summary(model, test_loader, args.n_classes)    \n    \n          wandb.log({\"P-R curve test\" : wandb.plot.pr_curve(metrics_test[1], metrics_test[2], labels=['Negative', 'Positive'])})   \n          wandb.log({'Test auc' : metrics_test[0], \n                  'Test bal acc' : metrics_test[3],\n                  'Test sensitivity': metrics_test[4],\n                          'Test specificity': metrics_test[5]})\n</code></pre>\n<p>Is there a way in which I can solve this issue without having to re-run the experiments again?</p>\n<p>Maybe I am getting something wrong here, I appreciate all the help!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-22T20:26:27.093Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/carloshernandezp\">@carloshernandezp</a>,</p>\n<p>If not set manually, <code>step</code> automatically increments every time <code>.log</code> is called. There are 2 ways you can synchronize your step value, though both of them require the experiment to be re-run:</p>\n<ol>\n<li>Any metrics logged in a single call to log will be considered part of that <code>step</code>.</li>\n<li>You can also set the step metric manually as <code>wandb.log(..., step=step)</code>. Please note that in this case, you are controlling step manually and must make sure that <code>step</code> increases monotonically. Any decreases in the value of <code>step</code> will cause the value of <code>.log</code> to be ignored.</li>\n</ol>\n<p>Unfortunately, this also means that there is no way to adjust the axes of your chart, and you will have to create new experiments.</p>\n<p>You can read a more comprehensive explanation <a href=\"https://docs.wandb.ai/guides/track/log/logging-faqs#why-am-i-seeing-fewer-data-points-than-i-logged\">here</a>.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-23T10:30:23.161Z",
				"Answer_body": "<p>Thank you very much for your answer.</p>\n<p>As I was logging the test metrics 3 <code>wandb.log(...)</code> later I found a workaround by simply adding 3 units on the downloaded <code>.csv</code> files. Which for all intended purposes, worked just fine.</p>\n<p>I will be extra careful next time.</p>\n<p>Thank you once again.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-22T10:30:37.590Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Logged value available in graph panel, but not in columns",
		"Question_link": "https://community.wandb.ai/t/logged-value-available-in-graph-panel-but-not-in-columns/2100",
		"Question_created_time": "2022-03-17T09:28:30.562Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 629,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I log values which have names in the form of <code>test/temp_top-k.---1</code> (I want the dashes for sorting reasons). I can create graph panels with these values, but they do not show up in the column view. When I <code>Manage Columns</code> they are not listed in the <code>Hidden Columns</code>. When I search for them, it gives me no (an empty) result. Even when I select <code>Show All</code> they don\u2019t show up in the column view. A bug?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-17T16:15:26.271Z",
				"Answer_body": "<p>Hi Stephan,</p>\n<p>I wasn\u2019t able to reproduce this bug on my end when using the code:<br>\n<code>wandb.log({``\"test/temp_top-k.---1\"``:metric})</code></p>\n<p>Can you tell me how you are logging this data? I was also able to find the column <code>train/temp_top-k_mean</code> within your run table from your most recent project. When you created the column, was the quotations properly around the <code>---1</code>?</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-21T12:53:08.798Z",
				"Answer_body": "<p>Hi Stephan,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-22T21:38:19.859Z",
				"Answer_body": "<p>Hi Leslie,</p>\n<p>I apologize for not responding earlier. I assumed to be notified by e-mail when this thread is updated. Probably I need to check my settings, or \u201cwatch\u201d this thread.</p>\n<p>I log via Pytorch Lightning:</p>\n<pre><code class=\"lang-auto\">wandb_logger = WandbLogger(project=settings.project_name, log_model=True)\nwandb_logger.watch(model, log='gradients', log_freq=50, log_graph=True)\n</code></pre>\n<p>The actual code for the logging is this:</p>\n<pre><code class=\"lang-auto\">temp_accs_top_k = {f'{k:-&gt;4d}': v for k, v in zip(settings.ks, temp_accs)}\nlightning_module.log(f'{split}/temp_top-k', temp_accs_top_k, batch_size=lightning_module.batch_size)\n</code></pre>\n<p>That looks a bit odd I suppose. The code is in a function that I call from several different <code>pl.LightningModule</code>s. The variable <code>lightning_module</code> refers to that module. The parameter <code>temp_accs_top_k</code> evaluates to (straight from the debugger):</p>\n<p><code>{'---1': 0.00019996000628452748, '---2': 0.00019996000628452748, '---3': 0.00039992001256905496, '---5': 0.0005998800043016672, '--10': 0.0005998800043016672, '--20': 0.001399720087647438, '--50': 0.004199160262942314, '-100': 0.007598480209708214, '1000': 0.08318336308002472}</code></p>\n<p>Which is wrong. But I am seeing the values in the graph panels (see attached screenshot).<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/3ae06dc0b1399ce16eb917dfb94b60a5e0f77acd.png\" alt=\"Screen Shot 2022-03-22 at 21.52.37\" data-base62-sha1=\"8oQwPNwBrsRhQBp0p6SuZ6ht6NL\" width=\"412\" height=\"275\"></p>\n<p>I changed the code so that <code>temp_accs_top_k</code>now contains <code>{'test/temp_top-k.---1': 0.2963850498199463, 'test/temp_top-k.---2': 0.3962452709674835, 'test/temp_top-k.---3': 0.44557619094848633, 'test/temp_top-k.---5': 0.5052925944328308, 'test/temp_top-k.--10': 0.5733972191810608, 'test/temp_top-k.--20': 0.6277211904525757, 'test/temp_top-k.--50': 0.6810465455055237, 'test/temp_top-k.-100': 0.716596782207489, 'test/temp_top-k.1000': 0.802676260471344}</code>.</p>\n<p>I log in a loop since Pytorch Lightning can\u2019t log a dict (I believe). I know that wandb does it, but I need the batch_size parameter (I have two dataloaders with different sizes/lenghts and need to make sure that Pytorch Lightning does not get confused with steps/epochs).</p>\n<pre><code class=\"lang-auto\">for k, v in temp_accs_top_k.items():\n    lightning_module.log(k, v, batch_size=lightning_module.batch_size)\n</code></pre>\n<p>Update: just realized that Pytorch Lightning has a <code>log_dict</code> function which lets me get rid of the awkward for loop.</p>\n<p>So the \u201cbug\u201d is more like \u201cwhy did it work in the first place (in the graph panels)?\u201d</p>\n<p>Hope that\u2019s not too much to digest and it is traceable.</p>\n<p>Best,<br>\nStephan</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-03-30T14:58:13.781Z",
				"Answer_body": "<p>Hi Stephan, the values that you first pointed to that you had mentioned were wrong are not the values that are shown on the graph. You can find the values that are logged there by creating a weave Table. This is done by clicking on \u2018+ Add Panel\u2019 then navigating to Weave. From there type on the top of the navigation bar <code>runs.history.concat[\"train/temp_top-k\\.---1\"]</code> and then clicking on the gear icon on the right and changing \u2018Render As\u2019 to \u2018Table\u2019 as shown in the image attached. Let me know if you have any problems pulling up this table!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-04T12:31:27.222Z",
				"Answer_body": "<p>Hi Stephan, I\u2019m just checking in to see if you were able to get everything working properly?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-07T16:20:50.157Z",
				"Answer_body": "<p>Hi Stephan, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-21T21:39:14.291Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sweep - starting with a small project",
		"Question_link": "https://community.wandb.ai/t/sweep-starting-with-a-small-project/2075",
		"Question_created_time": "2022-03-14T16:04:43.323Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 141,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi there,<br>\nI\u2019m new to W&amp;B and try to use sweep to find best parameters for MNIST with tf2.</p>\n<p>First, I ran sweep agent and I\u2019ve got this issue  that I don\u2019t understand where it comes from\u2026<br>\nAttributeError: module \u2018wandb\u2019 has no attribute \u2018init\u2019<br>\nIt doesn\u2019t appear when I 'm not using any agent.</p>\n<p>Second it\u2019s not clear to me if it\u2019s mandatory to put the hyperparameters as command line arguments. I\u2019m using a json file to fill the default values. I thought I would use this kind of file to configure the sweep.</p>\n<p>Where exactly do we have to run the agent? My script train.py is in a folder, source code in another, and my experiment in a third one. I would have like to put the sweep.yaml with my experiments.  Is there a way to put the script and the yaml file in a different folder?</p>\n<p>Thanks for your help</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-14T19:25:20.569Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/xllcrn\">@xllcrn</a>,</p>\n<p>I\u2019m sorry you are facing this issue. Can you test where wandb is getting imported from? You should be able to do this by running</p>\n<pre><code class=\"lang-auto\">print(wandb.__path__)\n</code></pre>\n<p>Chances are, it is importing the <code>wandb</code> directory generated instead of the actual library. Since this is happening with <code>agent</code> and not normal runs, one possibility of why this is happening is  if you are using <code>wandb agent</code> instead of <code>wandb.agent()</code> and the interpreter used by <code>wandb agent</code> might not have <code>wandb</code> installed, causing the generated folder to get imported as a module.</p>\n<p>I would recommend trying one of the following solutions:</p>\n<ol>\n<li>Change the <code>${interpreter}</code> in your config.yaml to a Python interpreter which has wandb installed. Check out our docs on Sweep Configuration <a href=\"https://docs.wandb.ai/guides/sweeps/configuration\">here</a>.</li>\n<li>Alternatively, try using <code>wandb.agent()</code> instead of <code>wandb agent</code>.</li>\n</ol>\n<p>Please let me know if I can assist you any further.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-17T21:17:05.388Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/xllcrn\">@xllcrn</a> ,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Thanks,<br>\nWeights and Biases Support</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-21T18:42:33.654Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/xllcrn\">@xllcrn</a>, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-20T18:42:47.837Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Re run a previous config",
		"Question_link": "https://community.wandb.ai/t/re-run-a-previous-config/2068",
		"Question_created_time": "2022-03-14T10:27:35.310Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 193,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>In my project lifetime I have many similar sweeps, such that each one is slightly different or even exactly like a previous sweep (for instance after a bug fix). In order to execute the same sweep again, I navigate to the previous sweep, copy the configuration, and paste that configuration in the new sweep. Is there a way to name and save a previous config and load it?</p>\n<p>Thanks,<br>\nTom</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-14T18:48:23.503Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tomjur\">@tomjur</a> ,<br>\nAre you currently configuring your sweep inline in Python?</p>\n<p>You can also create a .yaml file to define the sweep as well. <a href=\"https://docs.wandb.ai/guides/sweeps/quickstart#2.-configure-your-sweep\">Here</a> is the documentation on how to do so. Also <a href=\"https://github.com/wandb/examples/tree/master/examples/keras/keras-cnn-fashion\" rel=\"noopener nofollow ugc\">here</a> is an example repo of different YAML files along with instructions for how to use them.</p>\n<p>Let me know if this is what you were looking for or if there is another way I can help.<br>\nThank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-15T06:27:30.425Z",
				"Answer_body": "<p>Hi,</p>\n<p>No I am using the project website to run sweeps.</p>\n<p>I think it would be a real timesaver to have a drop-down of previous saved configurations instead of manually open the correct previous sweep, copy the entire config and paste it in the new sweep page.</p>\n<p>Thanks,<br>\nTom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-15T06:27:49.977Z",
				"Answer_body": "<p>Hi,</p>\n<p>No I am using the project website to run sweeps.</p>\n<p>I think it would be a real timesaver to have a drop-down of previous saved configurations instead of manually open the correct previous sweep, copy the entire config and paste it in the new sweep page.</p>\n<p>Thanks,<br>\nTom</p>\n<p>[Discourse post]</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-17T20:30:35.149Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/tomjur\">@tomjur</a> I\u2019ll go ahead and put in a feature request here. I imagine you are looking for something like the following?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b51e2ff4b4a6ad61c9482fa6b1a766eadd2960d3.png\" data-download-href=\"/uploads/short-url/pQf65upjsfNR8noMyUpgjuYCXhV.png?dl=1\" title=\"Screen Shot 2022-03-17 at 2.13.44 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b51e2ff4b4a6ad61c9482fa6b1a766eadd2960d3_2_498x499.png\" alt=\"Screen Shot 2022-03-17 at 2.13.44 PM\" data-base62-sha1=\"pQf65upjsfNR8noMyUpgjuYCXhV\" width=\"498\" height=\"499\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b51e2ff4b4a6ad61c9482fa6b1a766eadd2960d3_2_498x499.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b51e2ff4b4a6ad61c9482fa6b1a766eadd2960d3_2_747x748.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b51e2ff4b4a6ad61c9482fa6b1a766eadd2960d3.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b51e2ff4b4a6ad61c9482fa6b1a766eadd2960d3_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-03-17 at 2.13.44 PM</span><span class=\"informations\">962\u00d7965 57.8 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-18T07:02:02.940Z",
				"Answer_body": "<p>Yes, looks great! thank you!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-21T12:40:43.489Z",
				"Answer_body": "<p>No problem! I\u2019ll watch the ticket and let you know if progress is made towards this. Thank you <a class=\"mention\" href=\"/u/tomjur\">@tomjur</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-20T12:41:37.469Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Delete my account",
		"Question_link": "https://community.wandb.ai/t/delete-my-account/2116",
		"Question_created_time": "2022-03-19T08:35:14.265Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 138,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Can you delete my account please? Username is cengizk</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-21T07:55:01.014Z",
				"Answer_body": "<p>Hey there, the account has been deleted.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-20T07:55:50.457Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Averaging over runs with the same seed in a sweep",
		"Question_link": "https://community.wandb.ai/t/averaging-over-runs-with-the-same-seed-in-a-sweep/2110",
		"Question_created_time": "2022-03-18T09:49:35.964Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 175,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi everyone,</p>\n<p>I am currently running a sweep to do hyperparameter search on a set of parameters and a seed. What I would like to do is have the results averaged over the different seeds, so that for each group of runs sharing the same hyperparameters but different seeds I only have one value.<br>\nI already tried grouping them by all the parameters except the seed in the GUI, but I obtain a hierarchical grouping (split over each hyparaparameter) which is not what I would expect.<br>\nI think that I will have to go through the API and add a new group to the runs with the same hyperparameters and then group by that group. Is there anything else I can do?</p>\n<p>Thank you in advance for your help!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-18T23:07:11.993Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/crisostomi\">@crisostomi</a>,</p>\n<p>You have the right idea. Grouping on the parallel coordinates chart shows the highest level of grouping currently. You will need to create a new parameter to group these by to get the desired result.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-20T09:13:25.276Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a>,</p>\n<p>Alright, I will try this way!</p>\n<p>Thank you for your help.<br>\nDonato.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-19T09:13:56.431Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb.watch with pytorch not logging anything",
		"Question_link": "https://community.wandb.ai/t/wandb-watch-with-pytorch-not-logging-anything/2096",
		"Question_created_time": "2022-03-16T17:08:21.888Z",
		"Question_answer_count": 4,
		"Question_score_count": 2,
		"Question_view_count": 1522,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi,</p>\n<p>I am trying to use <code>wandb.watch</code> for a pytorch model, unfortunately without success. I checked the documentation and these two threads:</p>\n<ul>\n<li>Wandb.watch not logging parameters</li>\n<li>When is one supposed to run wandb.watch so that weights and biases tracks params and gradients?</li>\n</ul>\n<p>But none of the suggested solutions solves my problem. I run in my environment the code from the colab notebook linked in <a href=\"https://community.wandb.ai/t/when-is-one-supposed-to-run-wandb-watch-so-that-weights-and-biases-tracks-params-and-gradients/518/3\">this post</a> (with <code>N, log_freq = 50, 2</code>) and still nothing is logged.</p>\n<p>Interestingly, if I set the <code>log_graph=True</code> there is a JSON file logged as a file, under <code>root / media / graph</code> in the files section. But I was expecting to get a result similar to <a href=\"https://wandb.ai/ayush-thakur/debug-neural-nets/runs/jh061uaf/model\">this</a>.</p>\n<p>I am using wandb version 0.12.10.</p>\n<p>Kind regards,<br>\nMaciej</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-17T15:45:11.862Z",
				"Answer_body": "<p>Hi Maciej,</p>\n<p>Thank you for writing in and for doing as much research on your own as you can for this issue.</p>\n<p>In the colab that you had mentioned with the changed parameters that you used, I as able to log parameters properly. Here\u2019s the run that I used with <code>N, log_freq = 50, 2</code>. Can you send me a link of the run page where you are experiencing this issue? Also, can you try rerunning this using CLI-0.12.11 and see if that is able to help?</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-18T08:58:43.663Z",
				"Answer_body": "<p>Hi,</p>\n<p>Eureka! Everything was working correctly, but I always use <a href=\"http://wandb.ai\">wandb.ai</a> with project view or run groups view. When I opened the run view both the graph and gradient were there <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<p>However, there is one problem remaining: <code>parameters</code>. When running the colab notebook code with <code>wandb.watch(d, log_freq=log_freq, log=\"all\")</code> I still can see only gradients in the run view.</p>\n<p><a href=\"https://wandb.ai/dmml-heg/uncategorized/runs/2qovzwq9\">Link to run page</a>  executed with wandb version 0.12.11 in Google Colab.</p>\n<p>EDIT: I found it <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"> Code in the notebook was using <code>forward()</code> instead of <code>__call__()</code>. Forward hooks were not executed.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-03-21T15:20:24.555Z",
				"Answer_body": "<p>Yay! That\u2019s great! I\u2019m glad you were able to find out what was wrong with your script <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"> I hope you have a beautiful week</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-17T08:58:44.618Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "No history data in custom charts",
		"Question_link": "https://community.wandb.ai/t/no-history-data-in-custom-charts/2087",
		"Question_created_time": "2022-03-15T14:03:29.602Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 357,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi everyone,<br>\nI have been running a sweep with wandb and logged data (loss, accuracy, val_loss, val_accuracy) via wandb.keras.WandbCallback(). All plots over all epochs are plotted nicely in the main panel, but now I would like to create some custom charts. To be able to do that, I have tried to use the <code>history</code> field in the query but seems like it\u2019s empty. On the other hand, <code>summary</code> field seems okay (as can be seen in the screenshot).<br>\nHow do I get access to all these metrics logged in each epoch?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/12ecb1489c44995a08fbc00d8f1a7ff46357ec8e.png\" data-download-href=\"/uploads/short-url/2HpHLfFrQu2aAy7Cy1j9wzzaZQ2.png?dl=1\" title=\"Screenshot 2022-03-15 at 15.01.54\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/12ecb1489c44995a08fbc00d8f1a7ff46357ec8e_2_690x384.png\" alt=\"Screenshot 2022-03-15 at 15.01.54\" data-base62-sha1=\"2HpHLfFrQu2aAy7Cy1j9wzzaZQ2\" width=\"690\" height=\"384\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/12ecb1489c44995a08fbc00d8f1a7ff46357ec8e_2_690x384.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/12ecb1489c44995a08fbc00d8f1a7ff46357ec8e.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/12ecb1489c44995a08fbc00d8f1a7ff46357ec8e.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/12ecb1489c44995a08fbc00d8f1a7ff46357ec8e_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2022-03-15 at 15.01.54</span><span class=\"informations\">890\u00d7496 35.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-15T17:58:48.819Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/eldarkurtic\">@eldarkurtic</a>,</p>\n<p>I\u2019m sorry you are facing this issue. I tested this on my end seems like this is something that will have to be reported to our engineering team to be resolved. I found a workaround for you however:</p>\n<ol>\n<li>\n<p>Select <code>summary</code> and place keys in there<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/ae817ecd4692c2a3c23559f0897cd48f982df01d.png\" data-download-href=\"/uploads/short-url/oTKwnIZwLzWBqMf5DTmmNVRepE9.png?dl=1\" title=\"Screen Shot 2022-03-15 at 11.27.16 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ae817ecd4692c2a3c23559f0897cd48f982df01d_2_690x302.png\" alt=\"Screen Shot 2022-03-15 at 11.27.16 PM\" data-base62-sha1=\"oTKwnIZwLzWBqMf5DTmmNVRepE9\" width=\"690\" height=\"302\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ae817ecd4692c2a3c23559f0897cd48f982df01d_2_690x302.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ae817ecd4692c2a3c23559f0897cd48f982df01d_2_1035x453.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/ae817ecd4692c2a3c23559f0897cd48f982df01d.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ae817ecd4692c2a3c23559f0897cd48f982df01d_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-03-15 at 11.27.16 PM</span><span class=\"informations\">1050\u00d7460 57.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n</li>\n<li>\n<p>Change <code>summary</code> to <code>history</code> through the dropdown menu<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d609123fb6e92b24600a3985cf574d38b5f77a27.png\" data-download-href=\"/uploads/short-url/uxrC3v36MlzNsn6wu4UraytX29V.png?dl=1\" title=\"Screen Shot 2022-03-15 at 11.27.26 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d609123fb6e92b24600a3985cf574d38b5f77a27_2_690x288.png\" alt=\"Screen Shot 2022-03-15 at 11.27.26 PM\" data-base62-sha1=\"uxrC3v36MlzNsn6wu4UraytX29V\" width=\"690\" height=\"288\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d609123fb6e92b24600a3985cf574d38b5f77a27_2_690x288.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d609123fb6e92b24600a3985cf574d38b5f77a27_2_1035x432.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d609123fb6e92b24600a3985cf574d38b5f77a27.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d609123fb6e92b24600a3985cf574d38b5f77a27_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-03-15 at 11.27.26 PM</span><span class=\"informations\">1062\u00d7444 57.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n</li>\n</ol>\n<p>and you should have your keys present in <code>history</code> and can be used as such.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-14T17:59:38.384Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Could wandb be used in the inference?",
		"Question_link": "https://community.wandb.ai/t/could-wandb-be-used-in-the-inference/2077",
		"Question_created_time": "2022-03-14T21:16:47.497Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 162,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Could wandb be used in the inference stage? I\u2019m specifically interested in collecting system metrics during inference.  I\u2019m working with DeepSpeed and torch profile and would to know if wandb could be useful in the inference as well.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-14T22:18:07.748Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/eneas-jr\">@eneas-jr</a>,</p>\n<p>Yes, wandb can definitely be used at inference time as well to record system metrics. <code>wandb</code> will record system metrics in between the calls to <code>wandb.init()</code> and <code>wandb.finish()</code>.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-03-15T15:21:32.272Z",
				"Answer_body": "<p>Thanks a lot, <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-14T15:22:21.359Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to access the data of specific step in the dashboard of wandb.ai?",
		"Question_link": "https://community.wandb.ai/t/how-to-access-the-data-of-specific-step-in-the-dashboard-of-wandb-ai/2017",
		"Question_created_time": "2022-03-04T14:20:51.386Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 204,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am using the dashboard of wandb and want to access the specific step data. However, I can only obtain the metric throughout the whole training step. For example, I wanna get the best mAP in COCO evaluation, and corresponding AP50, AP70 and other evaluation metrics.</p>\n<p>Need help. Thanks for your help!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-09T00:51:13.714Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/djh\">@djh</a>,</p>\n<p>Could you share the workspace for which you are looking to compute these metrics? The context of the workspace would help me understand your request better.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-09T01:21:03.575Z",
				"Answer_body": "<p>The request is simple, I just cannot find how to access the entire record of one specific step in the dashboard. For example, I have recorded the log metric (loss, acc, .etc.) at each step, but in the dashboard, I can only see the line chart for loss or acc varying from step. My real demand is to access the log information at a certain step. Thanks for your reply!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-10T21:45:39.535Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/djh\">@djh</a>,</p>\n<p>This should be possible through our <a href=\"https://docs.wandb.ai/ref/app/features/panels/weave#introduction\">Weave Tables</a>. The <code>runs.history</code> metric holds all the step information and the weave table will let you hold it in a Tabular Format.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-14T21:39:10.199Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/djh\">@djh</a>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,</p>\n<p>Weights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-15T02:44:21.815Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a> , thanks for your instructions, Weave Tables meets my expectation.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-14T02:44:29.536Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Logging all summary metrics based on the max of one",
		"Question_link": "https://community.wandb.ai/t/logging-all-summary-metrics-based-on-the-max-of-one/1836",
		"Question_created_time": "2022-01-28T23:16:27.613Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 181,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>If you\u2019re doing something like early stopping, you might simply save the model with the best loss and let it run for 10 more epochs, but discard those model weights.  I see that for individual metrics I can tell it to store the \u201cmax\u201d or \u201cmin\u201d, but what if I want the entire summary to happen based on a single metric\u2019s max/min?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-31T07:24:45.969Z",
				"Answer_body": "<p>Hey Darrick, I am not sure I fully understand your use-case. Could you give me an example?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-01T20:39:13.293Z",
				"Answer_body": "<p>Sure, let\u2019s say I\u2019m training a model, but during training I save only the <em>best performing model</em>, for example, when the model has the best validation accuracy I save the weights.  Let\u2019s say I train for 50 epochs, but at epoch 40, the model has its peak accuracy.  Therefore, the weights I have saved for this model reflect the state of the model at epoch 40.  However, the weights and biases <em>summary metrics</em> reflect the state of the model at epoch 50.</p>\n<p>Ideally, I\u2019d like to change some simple setting which allows me to do this.  I realize that I could probably put code in the training workflow to manually check accuracy and set the summary metrics, but it would be nice if there was more a setting for this purpose.  I can already tell wandb to log the best accuracy (at epoch 40) instead of the final accuracy (at epoch 50), but I would like to tell wandb to give me <em>all of the metrics</em> at epoch 40 where the best accuracy was achieved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-09T05:59:36.161Z",
				"Answer_body": "<p>Hey Darrick,</p>\n<p>Apologies about the delay on this one. You should be able to set all the summary metrics in your code. Here is an example. Doesn\u2019t this cover your use-case?</p>\n<p>Best,<br>\nArman</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-10T08:08:14.014Z",
				"Answer_body": "<p>Hi Darrick,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-12T09:22:13.098Z",
				"Answer_body": "<p>Hey Darrick, since we have not heard back from you, I\u2019ll be closing this ticket. But please let me know if you have further questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-15T02:17:10.051Z",
				"Answer_body": "<p>I don\u2019t see any example along with your reply</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-14T02:17:31.307Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Grouping custom metrics by configuration",
		"Question_link": "https://community.wandb.ai/t/grouping-custom-metrics-by-configuration/1995",
		"Question_created_time": "2022-03-01T13:09:53.637Z",
		"Question_answer_count": 9,
		"Question_score_count": 1,
		"Question_view_count": 381,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I started using WandB today together with PyTorch Lightning.</p>\n<p>I am using a <code>LightningModule</code> which retrieves the input data and labels. I have also associated each input/output pair with json configuration file which describes the capture environment (e.g., if it is multi host or single host, bandwidth, delay, BDP factor). I know how to log values such as F1 score and accuracy for each sample but I am confused how to associate each value with a configuration. Is there any guides available that addresses this or something similar?</p>\n<p>For instance, in <code>test_step</code> from the LightningModule I have</p>\n<pre><code class=\"lang-auto\">def test_step(self, batch, batch_idx):\n  x, y, config_file =  batch\n  y_pred = self.forward(x)\n  loss = self.loss(y_pred, y)\n  self.log(\"test/loss\", loss)\n  return loss\n</code></pre>\n<p>I would like to do something like this:</p>\n<pre><code class=\"lang-auto\">def test_step(self, batch, batch_idx):\n  x, y, config_file =  batch\n  y_pred = self.forward(x)\n  loss = self.loss(y_pred, y)\n  self.log(\n    \"test/loss\", \n    loss, \n    configuration = {\n      \"delay\": \"10ms\",\n      \"BDP\": 3,\n       # etc ...\n    }\n  )\n  return loss\n</code></pre>\n<p>The <code>config_file</code> is a json file with <code>configuration</code>.</p>\n<p>My guess is that I could probably change <code>\"test/loss\"</code> to  <code>\"test/loss/10ms/3\"</code>, but I am not sure if this is the best way to go about it, how would the charts look in the w&amp;b dashboard? I want to be able to compare different environment settings somehow.</p>\n<p>Thanks in advance!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-02T16:12:55.807Z",
				"Answer_body": "<p>Hi Kevin,<br>\nThis is an interesting use case. Just so that I can confirm what you are trying to do let me try to sum this up.</p>\n<p>You would like to capture the exact environment at the time that the test/loss is logged correct?</p>\n<p>Does the environment changes dynamically or is it something you are setting at the beginning of the run?</p>\n<p>Also, test/loss is logged multiple times within the same run correct?</p>\n<p>If this is the case I don\u2019t know that logging it as \u201ctest/loss/10ms/3\u201d would be the best way to do this as you will then have a plot for each different environment with only one point on it in the dashboard. What would you like a plot to look like on the dashboard after you log this?</p>\n<p>Sorry for all of the questions. I just want to make sure I understand your goal before I try to come up with a solution.<br>\nThank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-03T18:11:56.973Z",
				"Answer_body": "<p>Hi Nathan,<br>\nThanks for the answer. The environment (i.e. <code>config</code>) comes from the test data, so you could say that these environment variables are set at the beginning of the run.</p>\n<p>Ultimately, I would like to plot some metric over grouped configuration values such as delay. So one plot might have F1 score on the y axis and ms on x axis.</p>\n<p>I think i solved this by aggregating everything into a huge matrix and use the <code>log_table</code> syntax.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-03T18:58:22.043Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/kevjn\">@kevjn</a>, I\u2019m glad you found a way to make this work! If I\u2019m understanding your use case correctly there may be a way to simplify this a little bit.</p>\n<p>If you set the <code>wandb.config</code> using the following at the beginning of the run, you can later group by certain config parameters in the UI to show just runs with a certain config.</p>\n<pre><code class=\"lang-auto\">environment = {\"delay\":&lt;delay_variable_from_data&gt;, \"BDP\": &lt;BDP_value&gt;}\nrun = wandb.init(config=environment) \n</code></pre>\n<p>All of the <code>wandb.config</code> is stored with that run on the UI and be used to filter or group runs together.</p>\n<p><a href=\"https://docs.wandb.ai/guides/track/config\">Here</a> is a quick guide on <code>wandb.config</code></p>\n<p>Let me know if this helps!<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-03T19:23:41.426Z",
				"Answer_body": "<p>Thank you for the suggestion. However, the problem I have with this approach is that I need to create a new dataset for each configuration, or at-least only select samples that are equal to the current <code>enviroment</code>. I have only 1 test dataset and the config values such as delay and BDP are tied to each sample in the dataset. This means that the values such as BDP and delay are <em>different</em> for each sample often times.</p>\n<p>So while your approach is feasible if a structure my data better, I would prefer to do everything in one swoop and filter/group the values in retrospect.</p>\n<p>I hope this makes sense, please let me know otherwise and I can try to clarify my intention better.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-03T19:34:51.231Z",
				"Answer_body": "<p>On second thought, It might be worth the effort to create a dataset for each <code>enviroment</code> and run the test mutliple times on the same trained model. I am not sure how this would look in the end though, What if i had 10 different values of delay and I wanted to plot it against the model accuracy for each respective value?</p>\n<p>I tried illustrating it below <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<pre data-code-wrap=\"none\"><code class=\"lang-nohighlight\">Accuracy\n   ^\n   |\n   |\n   |\n   |\n   + ---- --- --- --- --- &gt;\n          Delay [ms]\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-09T16:58:25.693Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/kevjn\">@kevjn</a> I love the illustration!</p>\n<p>Ok, I see how this would be pretty hard to do without restructuring the data. I agree that using tables to create something like this is the probably the best solution:</p>\n<pre><code class=\"lang-auto\">Delay | BDP | Accuracy |\n10    |  3  |  .89     |\n15    |  4  |  .90     |\n</code></pre>\n<p>Then you should be able to use that Table to generate a chart with delay on the X-axis and accuracy on the Y-axis.</p>\n<p>Is this what you are doing now?</p>\n<p>Also it sounds like your end goal is not training a model but rather to compare different environments on the same model correct?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-09T18:58:52.906Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/nathank\">@nathank</a> , I did log everything in a table at first, but I notice it was a bit  slow and required some manual labor to make the data presentable. There are about 30 000 rows and I figured that the best way is to create the plots myself in something like matplotlib and log the figures using wandb images.</p>\n<p>Regarding question 2)<br>\nExactly, I have training and testing pipeline and in the testing pipeline i want to compare the models accuracy in many different environments. The number of unique configurations explodes in value so i it is not really feasible to start a new run for each configuration.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-14T15:37:43.895Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/kevjn\">@kevjn</a> sorry that going with Tables wasn\u2019t working as a great solution for you. Currently we are working on restructuring Tables with the hopes of speeding up logging times.</p>\n<p>I\u2019m glad you found a working solution using Matplotlib but if you have any feedback on how Tables could better support this use case feel free to let me know and I can put in a feature request.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-13T15:37:57.385Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Loading a saved table to pandas dataframe",
		"Question_link": "https://community.wandb.ai/t/loading-a-saved-table-to-pandas-dataframe/2063",
		"Question_created_time": "2022-03-11T22:29:56.200Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 437,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I have been recently using wandb a lot in my projects and it is really helpful.</p>\n<p>my issue is that I an trying access the logged tables as a pandas dataframe in a program. I check the documentation and tried the solution mentioned in the <a href=\"https://docs.wandb.ai/guides/data-vis/log-tables#access-tables-programmatically\">documentation here</a>.  Once I run this instead of getting the table it returns a dictionary like this</p>\n<pre><code class=\"lang-auto\">{'artifact_path': 'wandb-client-artifact://sx4urflmwtczzq7zf71hsfxkill8hqrnd8o4uirjbcswuuc29f0xxrq6nra7uo2kzsp8jmu4s2g53e7xl3xuyu4lfjiowz9v63r9fbn7d3r8ckmlz5lrkhncuyhr0e46:latest/metrics.table.json', '_latest_artifact_path': 'wandb-client-artifact://sx4urflmwtczzq7zf71hsfxkill8hqrnd8o4uirjbcswuuc29f0xxrq6nra7uo2kzsp8jmu4s2g53e7xl3xuyu4lfjiowz9v63r9fbn7d3r8ckmlz5lrkhncuyhr0e46:latest/metrics.table.json', 'path': 'media/table/metrics_2_491a3e34c6fcf4271cb2.table.json', 'size': 413, '_type': 'table-file', 'ncols': 9, 'nrows': 3, 'sha256': '491a3e34c6fcf4271cb2378f9a33ff5dc8c9cdb8268299b4f96b88151730ecad'}\n</code></pre>\n<p>It would be great if someone can help me to convert this to a table so that I can perform aggregations on the results.</p>\n<p>Thanks<br>\nPrateek</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-13T15:00:33.126Z",
				"Answer_body": "<p>Hey Prateek,</p>\n<p>you can use this function (its a modified version of a function from the wandb repo).</p>\n<pre><code class=\"lang-auto\">def get_table_data_from_url(source_url: str, api_key: Optional[str] = None) -&gt; None:\n    response = requests.get(source_url, auth=(\"api\", api_key), stream=True, timeout=5)\n    response.raise_for_status()\n    bytes_list = []\n    for data in response.iter_content(chunk_size=1024):\n        bytes_list.append(data)\n    final_byte_data = b\"\".join(bytes_list)\n    data_dict = json.loads(final_byte_data.decode(\"utf-8\"))\n    table_df = pd.DataFrame(data=data_dict[\"data\"], columns=data_dict[\"columns\"])\n    return table_df\n</code></pre>\n<p>To get the specific url of the artifact, you can just iterate over run.files() and save the url attribute of the returned files. By checking out the file names you should be able to see which files are relevant for you.</p>\n<p>Best<br>\nDarius</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-12T15:01:00.509Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Forgot password in local",
		"Question_link": "https://community.wandb.ai/t/forgot-password-in-local/1959",
		"Question_created_time": "2022-02-21T12:53:45.579Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 271,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>What can I do when I forget my password in the local wandb?<br>\nIt seems that deleting or uninstalling  doesn\u2019t work.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-09T00:10:28.353Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nightmare4214\">@nightmare4214</a> ,</p>\n<p>Could you try the following steps?</p>\n<ul>\n<li>Log into the docker container using <code>docker exec -it wandb-local bash</code>\n</li>\n<li>Type <code>/usr/local/bin/local password EMAIL@ADDRESS.com</code> (where <code>EMAIL@ADDRESS.com</code> is your email)</li>\n</ul>\n<p>This should let you manually reset your password for the local instance and you should be able to log in through this. Please let me know if this does not work for you.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-05-12T09:04:51.654Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Can I plot the value of a metric at a single step?",
		"Question_link": "https://community.wandb.ai/t/can-i-plot-the-value-of-a-metric-at-a-single-step/1971",
		"Question_created_time": "2022-02-23T06:10:38.027Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 198,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Typically, we can go to the table view to sort runs by their summary metrics. The summary metrics can simply be the last value logged, or it can be min/max/mean/etc.</p>\n<p>However, say I have an evaluation process that runs over a number of steps\u2014say 600 steps. I\u2019d like to be able to figure out which run was the best after 10 steps, which was best after 100 steps, and so on. I can obviously log each of these as separate summary metrics. But is there a way to access these without knowing which steps I want ahead of time? Can I show them in either a table or a bar chart?</p>\n<p>Ideally, I\u2019d love to be able to slice into any line plot at a single point on the x-axis, and then just plot those points as a bar chart or table. Thanks for your help!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-02-24T20:07:48.533Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ntraft\">@ntraft</a> , this is actually very easy to do graphically! Click on the little edit button on the top right of your plot and you should get something like this. From here it\u2019s easy to select the min and max X axis values so you can see which run performed the best after a certain step.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/457680759bc3aeb8944bf16f730aa2cb9f840e7a.jpeg\" data-download-href=\"/uploads/short-url/9UuPJnhOhUbtdEEhgm6i514pOtk.jpeg?dl=1\" title=\"Screen Shot 2022-02-24 at 12.06.15 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/457680759bc3aeb8944bf16f730aa2cb9f840e7a_2_690x275.jpeg\" alt=\"Screen Shot 2022-02-24 at 12.06.15 PM\" data-base62-sha1=\"9UuPJnhOhUbtdEEhgm6i514pOtk\" width=\"690\" height=\"275\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/457680759bc3aeb8944bf16f730aa2cb9f840e7a_2_690x275.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/457680759bc3aeb8944bf16f730aa2cb9f840e7a_2_1035x412.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/457680759bc3aeb8944bf16f730aa2cb9f840e7a_2_1380x550.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/457680759bc3aeb8944bf16f730aa2cb9f840e7a_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-02-24 at 12.06.15 PM</span><span class=\"informations\">1525\u00d7609 85.8 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-24T21:17:38.324Z",
				"Answer_body": "<p>Thanks, <a class=\"mention\" href=\"/u/aidanjd\">@aidanjd</a>. Ultimately I was hoping to sort the Runs Table by best performing model, or have a bar chart where the highest bar clearly showed the winner, but I think you\u2019re right that I will have to do it visually by hovering over the line plot, or maybe download the raw data from the table and handle it in a notebook.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-10T12:31:44.019Z",
				"Answer_body": "<p>Hi , I have a similar problem that I would like to have all my metrics in the table come from a certain time step. For example, I am comparing hyperparameters but all my runs have different number of steps:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/a553815ba4167f35479a9dbf429eb1e01c6b980f.jpeg\" data-download-href=\"/uploads/short-url/nAxGTIuhjN4GM8LbLo6xymttIOr.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a553815ba4167f35479a9dbf429eb1e01c6b980f_2_690x299.jpeg\" alt=\"image\" data-base62-sha1=\"nAxGTIuhjN4GM8LbLo6xymttIOr\" width=\"690\" height=\"299\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a553815ba4167f35479a9dbf429eb1e01c6b980f_2_690x299.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a553815ba4167f35479a9dbf429eb1e01c6b980f_2_1035x448.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a553815ba4167f35479a9dbf429eb1e01c6b980f_2_1380x598.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a553815ba4167f35479a9dbf429eb1e01c6b980f_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1693\u00d7735 175 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Ideally, I would love to have a slider there that I can search through the steps and compare hyperparameters at different points in training. Isn\u2019t there some kind of functionality to get every metric at step N in the Table overview at a Project?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-09T12:32:09.294Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb not compatible with Torch Script",
		"Question_link": "https://community.wandb.ai/t/wandb-not-compatible-with-torch-script/1997",
		"Question_created_time": "2022-03-01T20:56:27.010Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 149,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m using wandb logging in conjunction with pytorch + pytorch lightning, and it seems like some of the code in wandb makes it so I cannot JIT my model into torchscript. Here\u2019s the error</p>\n<pre><code class=\"lang-auto\">torch.jit.frontend.UnsupportedNodeError: Set aren't supported:\n  File \"/home/peter/catkin_ws/src/venv/lib/python3.8/site-packages/wandb/wandb_torch.py\", line 355\n        \n            # hook has been processed\n            self._graph_hooks -= {id(module)}\n                                 ~ &lt;--- HERE\n        \n            if not self._graph_hooks:\n</code></pre>\n<p>is there a workaround for this?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-02T20:33:21.182Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/petermitrano\">@petermitrano</a>,</p>\n<p>I\u2019m sorry you are facing this issue. Would it be possible for you to share a minimal reproduction of this issue? It will help us debug this for you.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-02T22:41:06.790Z",
				"Answer_body": "<p>This demonstrates the problem:</p>\n<pre><code class=\"lang-auto\">#!/usr/bin/env python\n\nimport torch\nfrom torch import nn\n\nimport pytorch_lightning as pl\n\nfrom pytorch_lightning.loggers import WandbLogger\n\nclass LitMLP(pl.LightningModule):\n\n    def __init__(self):\n        super().__init__()\n        self.layer_1 = nn.Linear(10, 10)\n\n    def forward(self, x):\n        return self.layer_1(x)\n\n\nwandb_logger = WandbLogger(project=\"torchscript_debugging\")\n\ntrainer = pl.Trainer(logger=wandb_logger)\n\nmodel = LitMLP()\n\n# comment in the line below and the model will fail to compile\n# wandb_logger.watch(model)\n\nscript = model.to_torchscript()\n\nprint(script(torch.ones(10)))\n\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-08T21:48:05.926Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/petermitrano\">@petermitrano</a>,</p>\n<p>Thanks for the reproduction! This is a known issue and there is already an internal ticket tracking this bug - I\u2019m going to bump the priority of this issue for you and will let you know as soon as I have some news on the progress of this issue.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-07T21:48:09.312Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-08-18T06:01:03.378Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/petermitrano\">@petermitrano</a>,</p>\n<p>This feature has been implemented and should be released in the next version of <code>wandb</code> CLI!</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How do I get the version of an artifact?",
		"Question_link": "https://community.wandb.ai/t/how-do-i-get-the-version-of-an-artifact/2035",
		"Question_created_time": "2022-03-07T21:55:11.212Z",
		"Question_answer_count": 3,
		"Question_score_count": 2,
		"Question_view_count": 398,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hey,<br>\nI\u2019m trying to get the version of an artifact directly after logging my model (encoder) as an artifact to WandB.</p>\n<p><strong>Code:</strong></p>\n<pre><code class=\"lang-auto\">artifact = wandb.Artifact('my_artifact_name', type='model')\nartifact.add_file('/home/dezzardhd/encoder.pth')\nwandb.log_artifact(artifact)\nversion = artifact.version\n</code></pre>\n<p>Logging works so far, but\u2026<br>\nwhen trying to access the version of the artifact I get an error.<br>\n<strong>Error:</strong></p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"/home/moritz/PycharmProjects/bachelorarbeit/main.py\", line 48, in &lt;module&gt;\n    train_setups.start_training_sessions(project=project)\n  File \"/home/moritz/PycharmProjects/bachelorarbeit/train_setups.py\", line 18, in start_training_sessions\n    model_pipeline(config, project=project)\n  File \"/home/moritz/PycharmProjects/bachelorarbeit/learning.py\", line 84, in model_pipeline\n    save_model(model_ae=model, model_encoder=model_encoder, model_decoder=model_decoder)\n  File \"/home/moritz/PycharmProjects/bachelorarbeit/learning.py\", line 124, in save_model\n    version = artifact_enc.version\n  File \"/home/moritz/anaconda3/envs/bachelorarbeit/lib/python3.9/site-packages/wandb/sdk/wandb_artifacts.py\", line 191, in version\n    return self._logged_artifact.version\n  File \"/home/moritz/anaconda3/envs/bachelorarbeit/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2899, in version\n    return self._assert_instance().version\n  File \"/home/moritz/anaconda3/envs/bachelorarbeit/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2871, in _assert_instance\n    raise ValueError(\nValueError: Must call wait() before accessing logged artifact properties\n</code></pre>\n<p>What should I do now?</p>\n<p>For context:<br>\nI want to print out the version number with some other parameters so that I can easier start my evaluation process for certain runs.</p>\n<p>Best regards<br>\nDezzardHD</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-07T23:48:08.233Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dezzardhd\">@dezzardhd</a>,</p>\n<p>Could you try running your code as the following?</p>\n<pre><code class=\"lang-python\">artifact = wandb.Artifact('my_artifact_name', type='model')\nartifact.add_file('/home/dezzardhd/encoder.pth')\nwandb.log_artifact(artifact).wait()\nversion = artifact.version\n</code></pre>\n<p>Calling <code>wait()</code> after <code>log_artifact()</code> should resolve this for you.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-03-08T13:03:55.518Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a>,</p>\n<p>this resolved the problem. Thanks!</p>\n<p>DezzardHD</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-07T13:04:12.391Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Problems accessing web interface: \"rate limit exceeded\"",
		"Question_link": "https://community.wandb.ai/t/problems-accessing-web-interface-rate-limit-exceeded/2041",
		"Question_created_time": "2022-03-08T10:59:29.636Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 118,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I am having trouble accessing the <a href=\"http://wandb.ai\">wandb.ai</a> web interface. I very often, yet not always, get error messages like \u201crate limit exceeded\u201d or \u201cThere was a problem rendering these panels\u201d.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b365941060b6ae0dc38310d95e97379e66323316.png\" data-download-href=\"/uploads/short-url/pB164ekBeFRf2vXOzJZpRNGSnBQ.png?dl=1\" title=\"Screenshot_google-chrome_20220308104954_crop\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b365941060b6ae0dc38310d95e97379e66323316_2_690x254.png\" alt=\"Screenshot_google-chrome_20220308104954_crop\" data-base62-sha1=\"pB164ekBeFRf2vXOzJZpRNGSnBQ\" width=\"690\" height=\"254\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b365941060b6ae0dc38310d95e97379e66323316_2_690x254.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b365941060b6ae0dc38310d95e97379e66323316.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b365941060b6ae0dc38310d95e97379e66323316.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b365941060b6ae0dc38310d95e97379e66323316_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot_google-chrome_20220308104954_crop</span><span class=\"informations\">790\u00d7291 10.6 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Yesterday I had no problems at all. What\u2019s the issue?</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-08T20:03:14.936Z",
				"Answer_body": "<p>Hi Florian, can you tell me how many parallel processes you are doing? Has it increased from yesterday? I will increase your rate limit from my end.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-14T12:36:17.028Z",
				"Answer_body": "<p>Hi Florian,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-17T14:06:51.529Z",
				"Answer_body": "<p>Hi Florian, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-07T11:00:10.508Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Loading config values of a previous run to reproduce it",
		"Question_link": "https://community.wandb.ai/t/loading-config-values-of-a-previous-run-to-reproduce-it/1955",
		"Question_created_time": "2022-02-20T18:25:22.160Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 145,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi all,</p>\n<p>Say I have a run that had a good result, and I want to re-run it. What would be the recommended way to do this? How can I download a previous run\u2019s config values to create a new run with the same config?</p>\n<p>Thanks, Carlos</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-02-22T14:39:05.458Z",
				"Answer_body": "<p>Hey Carlos, you can get the config by using our Public API. Here is a code snippet you can use:</p>\n<p>import wandb<br>\napi = wandb.Api()</p>\n<p>run = api.run(\"//&lt;run_id&gt;\")<br>\nrun.file(\u201cconfig.yaml\u201d).download()</p>\n<p>You can also use the W&amp;B Launch feature which is in beta at the moment. Here is a <a href=\"https://docs.wandb.ai/guides/launch\">link</a> to the documentation.</p>\n<p>Best,<br>\nArman</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-03-04T21:59:34.381Z",
				"Answer_body": "<p>Great, that helps.</p>\n<p>Thanks Arman</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-03T21:59:58.370Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How does one \"migrate\" move a wandb repo from personal projects to school?",
		"Question_link": "https://community.wandb.ai/t/how-does-one-migrate-move-a-wandb-repo-from-personal-projects-to-school/1990",
		"Question_created_time": "2022-02-28T21:01:58.836Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 147,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019ve been doing my experiments on my personal one by accident and wanted to move it\u2026to have everything centralized. How does one do it? What changes would I have to make to my script to push to the right places in wanbd? Other unexpected things I have to do?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-01T13:51:21.424Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/brando\">@brando</a>, currently we have to move the projects for you.</p>\n<p>Could you let me know what entity you would like your projects moved to?</p>\n<p>Do you use the same username for your other entity?</p>\n<p>Would you like all of your projects to be moved?</p>\n<p>You are able to set the default entity that projects will get saved to by clicking on your profile in the top right corner and going to settings. On the User Settings page there is an option to set \u201cDefault location to create new projects\u201d. You can also specify <code>wandb.init(entity=\"&lt;your_entity&gt;\"</code>in your script if you would like the run to be logged to a specific entity.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-04T15:04:58.743Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/brando\">@brando</a> I just wanted to follow up and see if you were still interested in having me move your projects for you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-03T15:05:29.430Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Fail to show images when logging images in a project created in teams mode",
		"Question_link": "https://community.wandb.ai/t/fail-to-show-images-when-logging-images-in-a-project-created-in-teams-mode/1936",
		"Question_created_time": "2022-02-16T09:50:03.760Z",
		"Question_answer_count": 8,
		"Question_score_count": 0,
		"Question_view_count": 163,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>We created a team and then added a project. while everything works when working with our personal space separately, in the project we created in the team space, images are not shown. Any ideas on how to fix it?</p>\n<p>please let me know what type of information I should provide here.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-02-16T22:52:21.656Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mfazampour\">@mfazampour</a>, could you please share a link to your project page so I can take a look? I\u2019m an admin so it can be a private project link.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-17T06:29:57.739Z",
				"Answer_body": "<p>Hi, thanks for replying. This is the link for the team one: <a href=\"https://wandb.ai/ebm/learsim-ebm/runs/2fidzop5?workspace=user-mfazampour\" class=\"inline-onebox\">Weights &amp; Biases</a></p>\n<p>and this one is the logs I have in my personal space: <a href=\"https://wandb.ai/mfazampour/learsim-ebm?workspace=user-mfazampour\" class=\"inline-onebox\">Weights &amp; Biases</a></p>\n<p><code>pretrain_model.transformation</code>, <code>pretrain_model.moving</code> and <code>pretrain_model.moving_warped</code> should be images. in the wandb page these are shown in a line plot and named <code>image-file</code></p>\n<p>I also realized that for one of the experiments, the images are actually shown. I don\u2019t know what\u2019s the reason and when it actually fails.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-02T22:26:25.358Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/mfazampour\">@mfazampour</a> , it looks like that run was killed after 33s. It\u2019s possible the run didn\u2019t log any images before that happened. Can you try logging an image in a new run to see if that was the issue?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-03T13:22:04.067Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/aidanjd\">@aidanjd</a> , This is another one: <a href=\"https://wandb.ai/ebm/learsim-ebm/runs/1nrd8saq?workspace=user-mfazampour\" class=\"inline-onebox\">Weights &amp; Biases</a></p>\n<p>This is how the image data is shown which is super weird considering the same code works in the personal space.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d6d818201326e4319212e79dacb57053f16932fc.png\" data-download-href=\"/uploads/short-url/uEB9P4N0YhyuLpA9yxgYsshSr2Q.png?dl=1\" title=\"Screen Shot 2022-03-03 at 2.21.09 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d6d818201326e4319212e79dacb57053f16932fc_2_690x274.png\" alt=\"Screen Shot 2022-03-03 at 2.21.09 PM\" data-base62-sha1=\"uEB9P4N0YhyuLpA9yxgYsshSr2Q\" width=\"690\" height=\"274\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d6d818201326e4319212e79dacb57053f16932fc_2_690x274.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d6d818201326e4319212e79dacb57053f16932fc.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d6d818201326e4319212e79dacb57053f16932fc.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d6d818201326e4319212e79dacb57053f16932fc_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-03-03 at 2.21.09 PM</span><span class=\"informations\">827\u00d7329 18 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-07T16:38:02.294Z",
				"Answer_body": "<p>Hi Mohammad, I\u2019ll be taking over this ticket. Can you tell me how you are logging your images?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-10T17:37:07.016Z",
				"Answer_body": "<p>Hi Mohammad, are you still experiencing this issue?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-14T12:53:46.464Z",
				"Answer_body": "<p>Hi Mohammad, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-05-02T13:23:00.427Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "AttributeError: 'EnumTypeWrapper' object has no attribute 'NOW'",
		"Question_link": "https://community.wandb.ai/t/attributeerror-enumtypewrapper-object-has-no-attribute-now/1993",
		"Question_created_time": "2022-03-01T00:38:49.098Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 186,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>what I do can reslove this problem?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-03-02T13:37:48.425Z",
				"Answer_body": "<p>Hi, can you elaborate on how this error is occurring by sending us a code snippet?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-07T13:16:12.011Z",
				"Answer_body": "<p>Hello, can you let us know how you are running into this error?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-10T14:08:59.144Z",
				"Answer_body": "<p>Hi \u9b4f\u5b50\u7fd4, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-30T00:39:26.596Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wanbd records wrong number of gpus and cpus when using a scheduler slurm or condor",
		"Question_link": "https://community.wandb.ai/t/wanbd-records-wrong-number-of-gpus-and-cpus-when-using-a-scheduler-slurm-or-condor/1982",
		"Question_created_time": "2022-02-25T19:20:25.884Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 140,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I noticed it says there are 8 gpus and 24 cpus in the run but I scheduled a job with 1 gpu and 4 cpus. So I thought it would be good to report this since that seems like a bug. It should report/record the actual amount is being used by my job. I assume the other plots graphs are wrong too\u2026if it says Iam not utilizing all the stuff is cuz I didn\u2019t ask for it\u2026</p>\n<p>Thought it would help to fix this eventually!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-02-28T17:57:25.580Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/brando\">@Brando</a>, thanks for reporting this. Do you know which version of weights and biases you are using?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-04T19:00:00.762Z",
				"Answer_body": "<p>Hi Brando, just following up on the question above.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-29T17:58:05.283Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Constant Liar algorithm for sweeps?",
		"Question_link": "https://community.wandb.ai/t/constant-liar-algorithm-for-sweeps/1961",
		"Question_created_time": "2022-02-22T06:22:55.954Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 217,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>Just wondering if you have constant liar algorithm implemented internally for hyper-parameter suggestions in parallel. If I understand wandb API correctly, it is geared more for sequential suggestions, and considering our company can run pods in parallel, would be amazing if you guys can implement this on your end, rather than us hacking it on our end.</p>\n<p>The basic idea is that for the first pod (in a parllel set) it will suggest the hyper-parameters as usual, but for the 2nd and other pods starting now in parallel, it will send back the worst loss it has currently seen. The logic being that the next suggested hyper-parameters will be far away from ones suggested to first one. You could probably be smarter here since wandb has access to loss metrics as it trains, but that would be a side project.</p>\n<p>Here is a link with more depth: <a href=\"https://github.com/microsoft/nni/blob/98f66f76d310b0e0679823d966fdaa6adafb66c2/docs/en_US/CommunitySharings/ParallelizingTpeSearch.md\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">nni/ParallelizingTpeSearch.md at 98f66f76d310b0e0679823d966fdaa6adafb66c2 \u00b7 microsoft/nni \u00b7 GitHub</a></p>\n<p>Edit 1: follow up question, do you use anything more advanced than sklearn GPs for bayes search (basing my question on <a href=\"https://github.com/wandb/client/blob/master/wandb/sweeps/bayes_search.py#L85\" rel=\"noopener nofollow ugc\">this</a>).</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-02-23T14:23:44.845Z",
				"Answer_body": "<p>Hi Sachin, we currently use the Baye\u2019s implementation (<a href=\"https://github.com/wandb/sweeps/blob/master/src/sweeps/bayes_search.py\" class=\"inline-onebox-loading\" rel=\"noopener nofollow ugc\">https://github.com/wandb/sweeps/blob/master/src/sweeps/bayes_search.py</a>) for running parallel sweeps. I can put a ticket for this request, but can you tell me why your company prefers the Constant Liar algorithm?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-27T23:46:58.599Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/lesliewandb\">@lesliewandb</a>, Thanks for getting back to me. I feel like the CL algorithm is independent of whether it is Bayes Search or TPE.</p>\n<p>Consider this example. Suppose we have conducted 1000 sweeps already, so the sampler is more or less confident about the parameter space. The problem with the current implementation is that if I were to spin up the next 5 sweeps in parallel, wandb ignores the fact they are happening in parallel and would independently suggest 5 hyper-parameters. There is a good chance that all these 5 parameters are extremely similar. However, if each sample \u201clies\u201d and says that it was a bad location, it would force the sampler to look at a different location and makes sure we can \u201cexplore\u201d the hyper-parameter space better.</p>\n<p>So basically what I\u2019m asking for is for the constant liar algorithm on top of bayes search. I do however, think that TPE algorithm is better than sklearn\u2019s GP\u2019s but that can be another discussion.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-01T15:08:23.685Z",
				"Answer_body": "<p>I see, thank you for the clarification! I\u2019ll create a ticket for this and I\u2019ll let you know if there\u2019s any updates</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-28T23:47:35.395Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Error on torch.load for a run's saved file",
		"Question_link": "https://community.wandb.ai/t/error-on-torch-load-for-a-runs-saved-file/1979",
		"Question_created_time": "2022-02-24T23:48:58.986Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 187,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\nI want to load a pt file of a run which is downloaded using  WandB api. but this error is raised:<br>\n<code>'utf-8' codec can't decode byte 0xaa in position 4: invalid start byte</code></p>\n<p>My code is:</p>\n<pre><code class=\"lang-python\">api = wandb.Api()\nruns = api.runs('USERNAME/PROJ')\nmodel_path = list(list(runs)[0].files())[1].download()\nmodel = torch.load(model_path)\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-02-25T00:51:02.561Z",
				"Answer_body": "<aside class=\"quote no-group quote-modified\" data-username=\"sadra-barikbin\" data-post=\"1\" data-topic=\"1979\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img loading=\"lazy\" alt=\"\" width=\"20\" height=\"20\" src=\"https://sea2.discourse-cdn.com/business7/user_avatar/community.wandb.ai/sadra-barikbin/40/679_2.png\" class=\"avatar\"> sadra-barikbin:</div>\n<blockquote>\n<p>\u2018utf-8\u2019 codec can\u2019t decode byte 0xaa in position 4: invalid start byte</p>\n</blockquote>\n</aside>\n<p>HI <a class=\"mention\" href=\"/u/sadra-barikbin\">@sadra-barikbin</a> , it sounds like an encoding/decoding issue to me. Can you try decoding in the following way</p>\n<pre><code class=\"lang-auto\">import io\nwith open(model_path, 'rb') as f:\n    buffer = io.BytesIO(f.read())\nmodel = torch.load(model_path)\n</code></pre>\n<p>If that doesn\u2019t work, check out the <a href=\"https://pytorch.org/docs/master/generated/torch.load.html#torch.load\" rel=\"noopener nofollow ugc\">PyTorch docs</a> for <code>torch.load</code> to see some other possible fixes.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-26T00:51:10.709Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Does wandb have a limit on how long it can be run and deadlocks?",
		"Question_link": "https://community.wandb.ai/t/does-wandb-have-a-limit-on-how-long-it-can-be-run-and-deadlocks/1933",
		"Question_created_time": "2022-02-15T19:50:41.495Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 149,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I find that my scripts seem to halt on their own but they seem to deadlock or don\u2019t throw an error e.g. I was running a training script on my laptop but cuz it was on debug mode I was able to pause and it seemed to be stuck with some multiprocessing things and it seemed it was related to wandb\u2026</p>\n<pre><code class=\"lang-auto\">epoch_num=95: train_loss=1.861583555999555, train_acc=0.4987407624721527\nepoch_num=95: val_loss=tensor(7.3504), val_acc=tensor(0.)\n 16% (96 of 600) | | Elapsed Time: 7:47:13 | ETA:  1 day, 16:52:54 | 175.7 s/it\nepoch_num=96: train_loss=1.8501708821246499, train_acc=0.5018503069877625\nepoch_num=96: val_loss=tensor(6.9187), val_acc=tensor(0.)\nException ignored in: &lt;Finalize object, dead&gt;\nTraceback (most recent call last):\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/multiprocessing/util.py\", line 224, in __call__\n    res = self._callback(*self._args, **self._kwargs)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/multiprocessing/synchronize.py\", line 88, in _cleanup\n    unregister(name, \"semaphore\")\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/multiprocessing/resource_tracker.py\", line 151, in unregister\n    self._send('UNREGISTER', name, rtype)\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/multiprocessing/resource_tracker.py\", line 154, in _send\n    self.ensure_running()\n  File \"/Users/brandomiranda/opt/anaconda3/envs/meta_learning/lib/python3.9/multiprocessing/resource_tracker.py\", line 75, in ensure_running\n    with self._lock:\nKeyboardInterrupt: \n</code></pre>\n<p>does wandb have some deadlock bug if it is ran for too long for a reallllyyyyyy long experiment?</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/7d5f38d6a7cf69ebb63dc36b3191889903bf273a.jpeg\" data-download-href=\"/uploads/short-url/hT5H9DiWLr9feqG3ZUqUHMsO3lE.jpeg?dl=1\" title=\"Screen Shot 2022-02-15 at 1.51.43 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7d5f38d6a7cf69ebb63dc36b3191889903bf273a_2_387x500.jpeg\" alt=\"Screen Shot 2022-02-15 at 1.51.43 PM\" data-base62-sha1=\"hT5H9DiWLr9feqG3ZUqUHMsO3lE\" width=\"387\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7d5f38d6a7cf69ebb63dc36b3191889903bf273a_2_387x500.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7d5f38d6a7cf69ebb63dc36b3191889903bf273a_2_580x750.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7d5f38d6a7cf69ebb63dc36b3191889903bf273a_2_774x1000.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7d5f38d6a7cf69ebb63dc36b3191889903bf273a_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2022-02-15 at 1.51.43 PM</span><span class=\"informations\">1032\u00d71333 251 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-02-15T23:15:59.420Z",
				"Answer_body": "<p>Hey Brando,</p>\n<p>There are no known deadlocks in our code as of now. Could you share the <code>debug.log</code> and <code>debug-internal.log</code> associated to this run? It can be found in the <code>wandb</code> folder relative to your project folder.</p>\n<p>Additionally, could you share the version of wandb that you are using and the duration of time for which you were running the experiment?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-22T17:56:31.194Z",
				"Answer_body": "<p>Hey Brando,</p>\n<p>I wanted to follow up here since we haven\u2019t heard back from you. Is this still an issue you are having trouble with? Please let us know if we can be of further assistance.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-25T20:29:28.983Z",
				"Answer_body": "<p>Hi Brando, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-23T17:56:56.499Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Add custom column in table reports the variance of a metric per group",
		"Question_link": "https://community.wandb.ai/t/add-custom-column-in-table-reports-the-variance-of-a-metric-per-group/1938",
		"Question_created_time": "2022-02-16T11:07:25.094Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 135,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello everyone,</p>\n<p>I\u2019 am using table view of wandb to compare different groups of multiple runs. Even thought table reports the mean of each group (e.x. training accuracy), do not reports the variance (std dev) of group\u2019s accuracies . Is there any way to add this per-group metric in my table view?</p>\n<p>Thank you in advance!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-02-16T23:35:11.580Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/eakirtas\">@eakirtas</a>,<br>\nThank you for the question! Unfortunately there is no easy way to do this currently. Accessing the runs via the API and programmatically calculating the standard deviation by group is possible but not an efficient solution.</p>\n<p>If you\u2019d like I can put in a feature request to try to make this available in the UI? If so, what statistics would you like to see available? Just standard deviation or anything else?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-22T15:51:56.614Z",
				"Answer_body": "<p>Hi, <a class=\"mention\" href=\"/u/eakirtas\">@eakirtas</a>,<br>\nI just wanted to follow up and see if this answered your question or if there is anything I can help with?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-23T15:52:13.317Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How can I check whether an artifact is available?",
		"Question_link": "https://community.wandb.ai/t/how-can-i-check-whether-an-artifact-is-available/1826",
		"Question_created_time": "2022-01-27T16:18:12.817Z",
		"Question_answer_count": 8,
		"Question_score_count": 0,
		"Question_view_count": 213,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi, just started to use W&amp;B and managed to refactor some code to use artifact versioning today. What I could not find is (and sorry if this is very basic): during the first run of the program I would like to check if there is already some artifact (raw data) f\u00fcr that project / artifact name / type available: If yes, use it. If no, prepare it (might take a while). I am looking for the equivalent of <code>&lt;filename&gt;.is_file()</code> but for artifacts. I could use/download the artifact in a <code>try, except</code> clause but that\u2019s not very pretty (throwing errors on the console, not sure what the correct Exception is). The API does not seem to provide such a functionality?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-27T17:06:02.937Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hogru\">@hogru</a>,</p>\n<p>You should be able to access the artifacts for a run through <code>run.logged_artifacts()</code> in our API. Here is the link to our <a href=\"https://docs.wandb.ai/ref/python/public-api/run#logged_artifacts\">docs</a> for this.</p>\n<p>Please let me know if this is what you were looking for.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-28T10:11:44.470Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a> ,</p>\n<p>thank you very much for the quick response. Unfortunately this does not do what I need (or I don\u2019t get it yet).</p>\n<p>I have 2 issues with that:</p>\n<p>(1) It does not do what (I understand) it should do:</p>\n<ul>\n<li>In the wandb UI (the website) I see an artifact, e.g. <code>iris-raw:v2</code> (toy example)</li>\n<li>This artifact is \u201cUsed by\u201d a run, e.g. <code>ancient-waterfall-39</code>\n</li>\n<li>This run has a \u201cRun path\u201d in its overview page</li>\n<li>I then use this \u201cRun path\u201d in <code>run = api.run(\"Run Path\")</code> (OK) and call <code>artifacts = run.logged_artifacts() </code> (OK)</li>\n<li>I can\u2019t find the artifact <code>iris-raw:v2</code> (should I?). From inspecting the variable I see a <code>length</code> of 0 and and empty <code>objects</code> list</li>\n</ul>\n<p>(2) I need to know the \u201cRun path\u201d</p>\n<ul>\n<li>I would like to check, which (if any) artifacts already exist and have been created for a given <code>entity/project/</code>\n</li>\n<li>In this situation (the program starts up and wants to see what\u2019s already there) I don\u2019t know neither the name nor the run path of the (previous) run(s)</li>\n</ul>\n<p>I could of course check for local copies but I am trying to switch that logic to wandb.</p>\n<p>Any more hints, APIs, clarifications? It\u2019s totally possible that I overlook something.</p>\n<p>Best,<br>\nStephan</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-31T23:18:14.554Z",
				"Answer_body": "<p>Hi Stephan,</p>\n<ol>\n<li>\n<p>Used artifacts and Logged artifacts are separate and serve different purposes. For example, when you train a model and log it as an artifact, but now you want to fine tune this pretrained model, a new run \u201cuses\u201d the artifact and then \u201clogs\u201d a new version (assuming it is being logged into the same artifact).</p>\n<p>We allow for you to check both through <code>run.used_artifacts()</code> and <code>run.logged_artifacts()</code> respectively.</p>\n</li>\n<li>\n<p>An artifact does not need an exact Run ID to be referred, it can be referred as:</p>\n</li>\n</ol>\n<pre><code class=\"lang-auto\">artifact = api.Artifact('&lt;project&gt;/&lt;artifact&gt;:&lt;alias&gt;')\n</code></pre>\n<p>where <code>alias</code> will mostly refer to the version of the artifact (or \u201clatest\u201d). However, if you want the artifacts associated to a run (as in the artifacts used or logged by a run), you would need to call <code>used_artifact</code> or <code>logged_artifact</code>.</p>\n<p>I hope this clarifies your doubts for you. Please let me know if you have any further questions.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-04T18:19:46.703Z",
				"Answer_body": "<p>Hi Stephan,</p>\n<p>I wanted to follow up on this request as we have not heard back from you. Please let us know if we can be of further assistance or if this issue has been resolved.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-06T20:33:25.626Z",
				"Answer_body": "<p>Hi Ramit,</p>\n<p>thank you for asking. The answer is both yes and no <img src=\"https://emoji.discourse-cdn.com/twitter/wink.png?v=12\" title=\":wink:\" class=\"emoji\" alt=\":wink:\"> Yes in the sense that I have learned a lot about wandb because of your answers and no in the sense that my initial question is still open (but I have a \u201cworkaround\u201d). The current code snippet looks like that:</p>\n<pre><code class=\"lang-auto\">with wandb.init(project=settings.project_name,\n                    job_type='load_data',\n                    dir=wb_dir,\n                    tags=[settings['ENV_FOR_DYNACONF']]) as run:\n\ntry:\n    wb_data_prep = run.use_artifact(f'{wb_prep_name}:latest')\n    wb_data_prep.download(root=data_prep_dir)\n    prep_data = False\n\nexcept wandb.CommError as exception:\n    log.debug(f'wandb raised exception: {exception}')\n    log.debug('Preprocessed data not available from wandb, create anew from raw data')\n    prep_data = True\n</code></pre>\n<p>The context is that I want to check if wandb has the data available (it\u2019s created in another script/run) and I was looking for an if statement to check whether the file exists in order to avoid the try/except. But the run I am in does not have any used or logged artifacts at that time (in fact it even doesn\u2019t offer the methods in this context). But this bit of code works so for the moment I (think I) can leave it as is.</p>\n<p>If you feel I am missing something I am happy to learn.</p>\n<p>Best,<br>\nStephan</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-09T18:16:35.263Z",
				"Answer_body": "<p>Hey Stephan,</p>\n<p>Thanks for your response. I think the code you have written is the best way to check if an artifact exists if you do not know a priori if it really exists.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-02-22T07:58:33.625Z",
				"Answer_body": "<p>Is it possible to get an artifact from multiple runs in a project just using the alias and artifact type?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-23T07:58:41.020Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Delete my user account",
		"Question_link": "https://community.wandb.ai/t/delete-my-user-account/1946",
		"Question_created_time": "2022-02-18T10:36:04.061Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 167,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I would like to delete my account, please.</p>\n<p>My user name is yvanthiel</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-02-18T17:10:20.135Z",
				"Answer_body": "<p>Hi!</p>\n<p>Your account has been successfully deleted. Please let us know if we can help you with anything else.</p>\n<p>Thanks,<br>\nRamit<br>\nWeights and Biases Support</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-19T17:11:06.410Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to plot performance metrics against non-summary stats?",
		"Question_link": "https://community.wandb.ai/t/how-to-plot-performance-metrics-against-non-summary-stats/1891",
		"Question_created_time": "2022-02-10T18:57:27.197Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 225,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>How to plot performance metrics against non-summary stats?</p>\n<p>I am running sweeps over a few different datasets within the same job (each for a different location, it\u2019s a multi-task learning problem) and I am making wandb logging calls such as:</p>\n<pre><code class=\"lang-auto\">  wandb.log({\n    \"false_negative_rate\" : 0.043,\n    \"false_positive_rate\" : 0.261,\n    \"location\": \"Boston\",\n    \"number_training_instances\": 50\n  })\n\n  ...\n\n  wandb.log({\n    \"false_negative_rate\" : 0.017,\n    \"false_positive_rate\" : 0.145,\n    \"location\": \"Boston\",\n    \"number_training_instances\": 100\n  })\n\n  ...\n\n  wandb.log({\n    \"false_negative_rate\" : 0.076,\n    \"false_positive_rate\" : 0.334,\n    \"location\": \"Miami\",\n    \"number_training_instances\": 50\n  })\n\n  ...\n\n  wandb.log({\n    \"false_negative_rate\" : 0.048,\n    \"false_positive_rate\" : 0.172,\n    \"location\": \"Miami\",\n    \"number_training_instances\": 100\n  })\n</code></pre>\n<p>After logging, I\u2019d like to be able to use the dashboard to create various scatter plots such as</p>\n<pre><code class=\"lang-auto\">Plot false_negative_rate versus false_positive_rate\n  where location == \"Boston\"\n    and number_training_instances == 50\n\nPlot false_negative_rate versus number_training_instances\n  where location == \"Washington\"\n\nPlot false_negative_positve_rate versus location\n  where number_training_instances == 100\n</code></pre>\n<p>However, the filters in the dashboard only provide me the ability to filter/plot the last values logged (as opposed to any of the values logged). E.g., I can only filter on</p>\n<pre><code class=\"lang-auto\"> - number_training_instances == 100\n - location == \"Miami\"\n</code></pre>\n<p>because these were the last values logged for these attributes in each sweep.</p>\n<p>Is there a way to get the plotting flexibility I want using wandb\u2019s existing features?<br>\nCheers</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-02-16T18:51:37.957Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/ted-positronix\">@ted-positronix</a>,</p>\n<p><code>wandb</code> offers flexible plotting capabilities via the usage of the <code>Custom Chart</code> panel. <a href=\"https://docs.wandb.ai/ref/app/features/custom-charts#custom-visualizations\">You can access all logs of your metrics via the <code>history</code> or <code>historyTable</code> tab. This can then be passed to something like the custom <code>scatter plot</code> chart we offer.</a>. At this point your filtering should adjust the custom chart as you\u2019ve seen with the summary plots you tried.</p>\n<p>Let me know if I\u2019m misinterpreting your use case!</p>\n<p>Regards,<br>\nAnish Shah</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-17T00:50:52.218Z",
				"Answer_body": "<p>Many thanks Ashish! I will need to do some reading to see how to use this functionality. I don\u2019t know Vega, etc.</p>\n<p>I will post further questions here if I run into trouble.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:07.290Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Example code for how to set up logging processes (cross validation folds) and grouping them?",
		"Question_link": "https://community.wandb.ai/t/example-code-for-how-to-set-up-logging-processes-cross-validation-folds-and-grouping-them/1908",
		"Question_created_time": "2022-02-12T15:37:40.014Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 191,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I am new to wandb and I am trying to figure out how to set up logging processes (based on cross validation folds) and to group them. What I would like to do is to plot/visualise performances for each fold in a cross validation scheme.</p>\n<p>In this Colab example notebook</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/scikit/Simple_Scikit_Integration.ipynb\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9d23677f636eedb4d570ae645da788122519566f.png\" class=\"site-icon\" width=\"16\" height=\"16\">\n\n      <a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/scikit/Simple_Scikit_Integration.ipynb\" target=\"_blank\" rel=\"noopener nofollow ugc\">colab.research.google.com</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/e2eb089e1834a0581da1d893b1624f376f01ad6a.png\" class=\"thumbnail onebox-avatar\" width=\"260\" height=\"260\">\n\n<h3><a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/scikit/Simple_Scikit_Integration.ipynb\" target=\"_blank\" rel=\"noopener nofollow ugc\">Google Colaboratory</a></h3>\n\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>at the very bottom the section \u201cBasic Setup\u201d says in point 2: \"Groups: For multiple processes or cross validation folds, log each process as a runs and group them together. <code>wandb.init(group='experiment-1')</code>\". I am not quite sure how to do this. I searched the documentation, but I was not successful. Can anyone point me to some example code how to do this?</p>\n<p>Basically, what I am interested in is to visualise ROC, etc. for each fold and compare how much they differ.</p>\n<p>Thanks in advance!<br>\nOliver</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-02-15T15:24:51.082Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/olto\">@olto</a>,<br>\nThank you for trying out Weights and Biases! If you call</p>\n<p><code>run = wandb.init(project='my_project', group='my_group')</code></p>\n<p>from within a KFold <code>for</code> loop to start a new run for each fold and then</p>\n<p><code>wandb.log(\ufeff{\ufeff\"roc\" : wandb.plot.roc_curve(ground_truth, predictions)\ufeff}\ufeff) </code></p>\n<p>to log the ROC curves to that run</p>\n<p>Here is what that may look like:</p>\n<pre><code class=\"lang-auto\">k_fold = KFold(n_splits=5)\n\nfor train_idx, test_idx in k_fold.split(X,y):\n    X_train, X_test= X[train_idx], X[test_idx] \n    y_train, y_test= y[train_idx], y[test_idx]\n    run = wandb.init(project='my_project', group='my_group')\n    model = # build model\n    model = model.fit(X_train,y_train)\n    y_hat = model.predict_proba(X_test)\n\n    wandb.log(\ufeff{\ufeff\"roc\" : wandb.plot.roc_curve(y, y_hat\ufeff)\ufeff}\ufeff)\n\n    wandb.finish()\n</code></pre>\n<p>Also <a href=\"https://github.com/wandb/examples/blob/master/examples/wandb-sweeps/sweeps-cross-validation/train-cross-validation.py\" rel=\"noopener nofollow ugc\">here</a> is a more advanced example using sweeps. Let me know if this helps to clarify or if you have any more questions about this.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-15T15:25:10.796Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/olto\">@olto</a>,<br>\nThank you for trying out Weights and Biases! If you call<br>\n<code>run = wandb.init(project='my_project', group='my_group')</code></p>\n<p>from within a KFold <code>for</code> loop to start a new run for each fold and then</p>\n<p><code>wandb.log(\ufeff{\ufeff\"roc\" : wandb.plot.roc_curve( ground_truth, predictions, labels=\ufefflabels\ufeff)\ufeff}\ufeff) </code></p>\n<p>to log the ROC curves to that run</p>\n<p>Here is what that may look like:</p>\n<pre><code>k_fold = KFold(n_splits=5)\n\nfor train_idx, test_idx in k_fold.split(X,y):\n    X_train, X_test= X[train_idx], X[test_idx]\n    y_train, y_test= y[train_idx], y[test_idx]\n    run = wandb.init(project='my_project', group='my_group')\n    model = # build model\n    model = model.fit(X_train,y_train)\n    y_hat = model.predict_proba(X_test)\n\n    wandb.log(\ufeff{\ufeff\"roc\" : wandb.plot.roc_curve(y, y_hat\ufeff)\ufeff}\ufeff)\n\n    wandb.finish()\n</code></pre>\n<p>Also here is a more advanced example using sweeps. Let me know if this helps to clarify or if you have any more questions about this.</p>\n<p>Thank you,<br>\nNate</p>\n<p>[Discourse post]</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-15T19:01:31.888Z",
				"Answer_body": "<p>Thanks a lot, Nate!</p>\n<p>I ended up with something similar by playing around with various approaches. One thing I did differently though was calling</p>\n<p>wandb.finish()</p>\n<p>only once at the end of the script outside the KFold for loop. Looking at your code suggestions, I understand that I should finish every single run with wandb.finish().</p>\n<p>Thanks a lot also for the example using sweeps. That will come in handy.</p>\n<p>Cheers<br>\nOliver</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-16T18:01:35.240Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/olto\">@olto</a> No problem! Thanks for the question. It gave me a chance to dig into this myself.</p>\n<p>When you start a new run with <code>wandb.init()</code> it basically calls <code>wandb.finish()</code> on the previous run so both codes work essentially the same.  I just like to explicitly call it to finish a run but either works!</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-17T18:01:47.437Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Loading Keras model-best.h5 saved with W&B run",
		"Question_link": "https://community.wandb.ai/t/loading-keras-model-best-h5-saved-with-w-b-run/786",
		"Question_created_time": "2021-09-26T22:45:33.709Z",
		"Question_answer_count": 5,
		"Question_score_count": 6,
		"Question_view_count": 1140,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>While using <code>wandb.keras.WandbCallback()</code> I noticed that W&amp;B saves a \u201c<code>model-best.h5</code>\u201d file at every run. However, I run into errors while trying to load this model. In contrast, the model saved by <code>tf.keras</code>\u2019 <code>ModelCheckpoint</code> callback works fine.</p>\n<p>Could this be an error due to <code>keras</code> vs. <code>tf.keras</code> protocols or clashing between different <code>tf.keras</code> versions? Would love to get more insight in how <code>wandb.keras.WandbCallback()</code> saves <code>model-best.h5</code>.</p>\n<p><strong>Error traceback:</strong></p>\n<pre data-code-wrap=\"---------------------------------------------------------------------------\"><code class=\"lang-nohighlight\">OSError                                   Traceback (most recent call last)\n/tmp/ipykernel_25/1740475024.py in &lt;module&gt;\n      1 model = tf.keras.models.load_model(MODEL_PATH, \n      2                                    custom_objects={'FixedDropout': PermaDropout, \n----&gt; 3                                                    'rmse_tf': rmse_tf})\n\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py in load_model(filepath, custom_objects, compile, options)\n    205           (isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n    206         return hdf5_format.load_model_from_hdf5(filepath, custom_objects,\n--&gt; 207                                                 compile)\n    208 \n    209       filepath = path_to_string(filepath)\n\n/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py in load_model_from_hdf5(filepath, custom_objects, compile)\n    170   opened_new_file = not isinstance(filepath, h5py.File)\n    171   if opened_new_file:\n--&gt; 172     f = h5py.File(filepath, mode='r')\n    173   else:\n    174     f = filepath\n\n/opt/conda/lib/python3.7/site-packages/h5py/_hl/files.py in __init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\n    406                 fid = make_fid(name, mode, userblock_size,\n    407                                fapl, fcpl=make_fcpl(track_order=track_order),\n--&gt; 408                                swmr=swmr)\n    409 \n    410             if isinstance(libver, tuple):\n\n/opt/conda/lib/python3.7/site-packages/h5py/_hl/files.py in make_fid(name, mode, userblock_size, fapl, fcpl, swmr)\n    171         if swmr and swmr_support:\n    172             flags |= h5f.ACC_SWMR_READ\n--&gt; 173         fid = h5f.open(name, flags, fapl=fapl)\n    174     elif mode == 'r+':\n    175         fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl)\n\nh5py/_objects.pyx in h5py._objects.with_phil.wrapper()\n\nh5py/_objects.pyx in h5py._objects.with_phil.wrapper()\n\nh5py/h5f.pyx in h5py.h5f.open()\n\nOSError: Unable to open file (bad object header version number\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-28T14:20:15.655Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/carlolepelaars\">@carlolepelaars</a>,</p>\n<p>Yes <code>wandb.keras.WandbCallback()</code> saves a <code>model-best.h5</code> file. Not sure if it\u2019s the \u201cbest\u201d model (model state for which the <code>val_loss</code> is the lowest) or the model saved at the end of the epoch.</p>\n<p>However, I was successfully able to load the model using <code>somemodel = tf.keras.models.load_model('wandb/run-20210926_235741-1khkh9qd/files/model-best.h5')</code>. Note that I have used the local path to the <code>model-best.h5</code> file.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-28T16:49:37.479Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/ayut\">@ayut</a>,</p>\n<p>Thanks for the answer! Seems likely that it would be saved at the end of the epoch.</p>\n<p>I downloaded the <code>model-best.h5</code> directly from the W&amp;B run GUI so not sure if its exactly the same file as saved in the <code>wandb/</code> folder. Will check it out! Will also try specifying the local path.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-16T13:45:51.112Z",
				"Answer_body": "<p>This issue is fixed by the way! The callback may save some custom objects so be sure to specify <code>compile=False</code> for inference applications.</p>\n<p>Example:<br>\n<code>model = tf.keras.models.load_model(MODEL_PATH, compile=False)</code></p>\n<p>Thanks, <a class=\"mention\" href=\"/u/ayut\">@ayut</a> !</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:01:40.220Z",
				"Answer_body": "<p>This issue is fixed by the way! The callback may save some custom objects so be sure to specify <code>compile=False</code> for inference applications.</p>\n<p>Example:<br>\n<code>model = tf.keras.models.load_model(MODEL_PATH, compile=False)</code></p>\n<p>Thanks, <a class=\"mention\" href=\"/u/ayut\">@ayut</a> !</p>\n<p>[Discourse post]</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.404Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "WandB login problem when i use the Huggingface accelerator on a TPU runtime",
		"Question_link": "https://community.wandb.ai/t/wandb-login-problem-when-i-use-the-huggingface-accelerator-on-a-tpu-runtime/1886",
		"Question_created_time": "2022-02-09T12:30:36.875Z",
		"Question_answer_count": 12,
		"Question_score_count": 1,
		"Question_view_count": 297,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey Guys,</p>\n<p>I have been using WandB for a while now and everything is working fine but since I switched from a GPU runtime to a TPU runtime (8 cores) (Using the Huggingface accelerator on Google Colab) its not working anymore.</p>\n<p>The main process just never gets further than the code line with the WandB login while the other cores continue to work normally so i dont get any error message\u2026</p>\n<p>If i switch back to a GPU runtime afterwards, the same code runs without any problems.</p>\n<p>It is possible to login before using the notebook_launcher, but then of course I get an error message about different pids</p>\n<p>Im using the wandb version 0.12.10, torch-xla 1.9 and accelerate-0.5.1</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-02-09T16:32:04.004Z",
				"Answer_body": "<p>Hi Chris,</p>\n<p>Sorry you\u2019re having issues with this. Could you tell me a little bit more about how you are running your code so I can try to replicate your issue? I\u2019m connected to a TPU right now and running !wandb login in its own cell is working for me. How are you integrating Accelerate in your training process and where is your wandb login at?</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-10T12:40:37.456Z",
				"Answer_body": "<p>Hey Nate,</p>\n<p>sure, here are some screenshots of my heavily shortened code:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/2e76339b0b74e6d3cb9616a92562cd8835cf2cc6.png\" data-download-href=\"/uploads/short-url/6D1cYO9P3vk4f46EOZF9nTUehcG.png?dl=1\" title=\"code\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/2e76339b0b74e6d3cb9616a92562cd8835cf2cc6.png\" alt=\"code\" data-base62-sha1=\"6D1cYO9P3vk4f46EOZF9nTUehcG\" width=\"678\" height=\"500\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2e76339b0b74e6d3cb9616a92562cd8835cf2cc6_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">code</span><span class=\"informations\">1248\u00d7919 43.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-10T12:41:34.098Z",
				"Answer_body": "<p>And this is what the result of the code looks like when it is run with a tpu:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/cae288037de9d17f6b1810a8c384ba21330996b0.png\" data-download-href=\"/uploads/short-url/sWNMZbfdM9bi4dNHQ9Vl0D5Avqo.png?dl=1\" title=\"not_running_tpu_output\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/cae288037de9d17f6b1810a8c384ba21330996b0.png\" alt=\"not_running_tpu_output\" data-base62-sha1=\"sWNMZbfdM9bi4dNHQ9Vl0D5Avqo\" width=\"380\" height=\"500\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/cae288037de9d17f6b1810a8c384ba21330996b0_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">not_running_tpu_output</span><span class=\"informations\">666\u00d7875 10.2 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>(Sorry, im just allowed to send 1 Image per Message\u2026 -.-)</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-10T12:42:12.334Z",
				"Answer_body": "<p>And this is what the result of the code looks like when it is run with a gpu:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/a09936dd2e6c46f3f0bb370b8627b4ce0d7489f3.png\" data-download-href=\"/uploads/short-url/mUIEDrvcT2zX42f8LSEQEOXjuDN.png?dl=1\" title=\"running_gpu_output\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/a09936dd2e6c46f3f0bb370b8627b4ce0d7489f3.png\" alt=\"running_gpu_output\" data-base62-sha1=\"mUIEDrvcT2zX42f8LSEQEOXjuDN\" width=\"558\" height=\"500\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a09936dd2e6c46f3f0bb370b8627b4ce0d7489f3_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">running_gpu_output</span><span class=\"informations\">994\u00d7890 18.6 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Thank you <img src=\"https://emoji.discourse-cdn.com/twitter/slightly_smiling_face.png?v=12\" title=\":slightly_smiling_face:\" class=\"emoji\" alt=\":slightly_smiling_face:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-10T12:50:56.422Z",
				"Answer_body": "<p>By the way, if i comment out the wandb part, then the code runs in a tpu runtime also without problems.</p>\n<p>furthermore i also tried to use the wandb code already in the train_pipeline, but then i logically get the following error message:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b8ddeaa9a63d324f812cc175e8ee1f54f7868f4a.png\" data-download-href=\"/uploads/short-url/qnpj90tE01gX2cT7a2EQCgsx1JE.png?dl=1\" title=\"using wandb in the trainPipeline before notebook_launcher\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b8ddeaa9a63d324f812cc175e8ee1f54f7868f4a.png\" alt=\"using wandb in the trainPipeline before notebook_launcher\" data-base62-sha1=\"qnpj90tE01gX2cT7a2EQCgsx1JE\" width=\"690\" height=\"105\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b8ddeaa9a63d324f812cc175e8ee1f54f7868f4a_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">using wandb in the trainPipeline before notebook_launcher</span><span class=\"informations\">1104\u00d7169 5.06 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>So nothing is logged, but everything runs as desired.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-10T15:40:36.351Z",
				"Answer_body": "<p>Chris, thank you for the detailed response. Could you try using the CLI command !wandb login directly after you pip install wandb and then commenting wandb.login() out of your training script? The login will persist over any scripts ran on the Colab instance. It\u2019s interesting that this worked on GPU but not the TPU. I\u2019m working on replicating now as this may be a bug with the way wandb.login/notebook_launcher/colab TPU all interact.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-10T16:56:40.204Z",
				"Answer_body": "<p>Hey Nate,</p>\n<p>thank you for your fast reply.</p>\n<p>I have tried your suggestion, but unfortunately without success.</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/82a6d70c3c27f881e5e5a9137f466aa62686abcd.png\" alt=\"wandb login\" data-base62-sha1=\"iDNwvjq9PgTf8CiPDvvnB0bdrhX\" width=\"663\" height=\"92\"></p>\n<p>I am also surprised that it runs with a GPU, but not with a TPU.<br>\nPossibly the reason for this could be the process ID (PID).<br>\nWhen I use a GPU, the PID does not change but i get 8 new PIDs, when i use a TPU.</p>\n<p>One more difference between the GPU and TPU runtime is, that i dont execute the following line, when i use a GPU:</p>\n<p>!pip install accelerate cloud-tpu-client==0.10 torch==1.9.0 <a href=\"https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\" rel=\"noopener nofollow ugc\">https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl</a></p>\n<p>Instead I just install accelerate (!pip install accelerate)<br>\nwhich means i am using a newer torch version (torch-1.10.0+cu111) on a GPU runtime.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-11T16:40:56.058Z",
				"Answer_body": "<p>Hi Chris, I\u2019m able to replicate the issue with some minimal code. Great suggestion about the PID\u2019s. I think it is related to how multiprocessing is working with notebook launcher. Taking notebook launcher out and running the training code works fine. Also if you set num_processes=1 in notebook_launcher it runs correctly. The documentation on notebook launcher is a little vague as to if this means it only trains on 1 core but it looks like this is the case so this isn\u2019t really a helpful solution. I\u2019ll escalate this as a bug to our engineering team to see if they have any more insight on this.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-14T21:16:26.643Z",
				"Answer_body": "<p>Hey Nate,<br>\nI am glad to hear that.<br>\nDo you know if your engineering team has already been able to fix the bug or can you at least estimate how long it will take to fix it?</p>\n<p>Thanks. <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-14T22:26:44.094Z",
				"Answer_body": "<p>Hi Chris,</p>\n<p>Unfortunately I don\u2019t have a timeline when this may be implemented. I can let you know when I see any movement on this and keep you up to date on progress being made on the issue though.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-15T13:41:03.517Z",
				"Answer_body": "<p>Hey,</p>\n<p>that would be very nice.</p>\n<p>Thank you very much! <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-16T13:41:32.365Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How do I upload code to WandB every time I run it",
		"Question_link": "https://community.wandb.ai/t/how-do-i-upload-code-to-wandb-every-time-i-run-it/1922",
		"Question_created_time": "2022-02-15T02:43:08.773Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 207,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>To back up the code, I want to upload my training code to Wandb every time I run it. Is this possible?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-02-15T08:13:39.266Z",
				"Answer_body": "<p>No, wandb does not have an option to store code. Why do you want to save the code?</p>\n<ol>\n<li>\n<p>Are you changing the hparams in your code in every run?  - Then you could try using wandb.sweep() instead, as it visualizes your model\u2019s performance for different hparams</p>\n</li>\n<li>\n<p>Are you using different architectures while training? -   Wandb artifacts logs datasets and model/training data. There are functions that track all your parameters (wandb. watch() iirc). This leads to an ONNX format of your model being saved.  This ONNX model can be visualized, and you could use that to see what model was trained. Or you could even save a string in your config file with details of the model you\u2019re training</p>\n</li>\n</ol>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-02-15T09:22:03.079Z",
				"Answer_body": "<p>Actually you can upload the code by passing the save_code argument to <a href=\"https://docs.wandb.ai/ref/python/init\">wandb.init()</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-18T14:21:01.769Z",
				"Answer_body": "<p>Hey there, have you tried that out?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-22T10:02:02.969Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-16T09:22:30.291Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Saving model's weights",
		"Question_link": "https://community.wandb.ai/t/saving-models-weights/1924",
		"Question_created_time": "2022-02-15T07:44:25.288Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 116,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\nI\u2019m training a BERT model and I\u2019m trying to save the weights to wandb\u2019s files tab in the end of the training.<br>\nHow can I accomplish that?<br>\nAlso - how can I load the weights from wandb\u2019s files tab?<br>\nI\u2019m using this code:<br>\n<a href=\"https://wandb.ai/cayush/bert-finetuning/reports/Sentence-classification-with-Huggingface-BERT-and-W&amp;B--Vmlldzo4MDMwNA\">https://wandb.ai/cayush/bert-finetuning/reports/Sentence-classification-with-Huggingface-BERT-and-W&amp;B\u2013Vmlldzo4MDMwNA</a></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-20T18:02:05.599Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Why is min and max causing errors when logging gradients for biases in model?",
		"Question_link": "https://community.wandb.ai/t/why-is-min-and-max-causing-errors-when-logging-gradients-for-biases-in-model/720",
		"Question_created_time": "2021-09-20T22:08:44.071Z",
		"Question_answer_count": 5,
		"Question_score_count": 3,
		"Question_view_count": 663,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Why is this error happening when wandb is logging the grad.data field?</p>\n<pre><code class=\"lang-auto\">  File \"/home/miranda9/automl-meta-learning/automl-proj-src/experiments/meta_learning/main_metalearning.py\", line 360, in &lt;module&gt;\n    main(args)\n  File \"/home/miranda9/automl-meta-learning/automl-proj-src/experiments/meta_learning/main_metalearning.py\", line 333, in main\n    meta_train_fixed_iterations_full_epoch_possible(args)\n  File \"/home/miranda9/automl-meta-learning/automl-proj-src/meta_learning/training/meta_training.py\", line 216, in meta_train_fixed_iterations_full_epoch_possible\n    log_train_val_stats(args, args.it, train_loss, train_acc, valid=meta_eval, bar=bar_it,\n  File \"/home/miranda9/automl-meta-learning/automl-proj-src/meta_learning/training/meta_training.py\", line 129, in log_train_val_stats\n    val_loss, val_acc = valid(args, save_val_ckpt=save_val_ckpt)\n  File \"/home/miranda9/automl-meta-learning/automl-proj-src/meta_learning/training/meta_training.py\", line 274, in meta_eval\n    eval_loss, eval_acc = args.meta_learner(spt_x, spt_y, qry_x, qry_y)\n  File \"/home/miranda9/miniconda3/envs/metalearning_cpu/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/miranda9/automl-meta-learning/automl-proj-src/meta_learning/meta_learners/maml_meta_learner.py\", line 159, in forward\n    (qry_loss_t / meta_batch_size).backward()  # note this is more memory efficient (as it removes intermediate data that used to be needed since backward has already been called)\n  File \"/home/miranda9/miniconda3/envs/metalearning_cpu/lib/python3.9/site-packages/torch/_tensor.py\", line 255, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n  File \"/home/miranda9/miniconda3/envs/metalearning_cpu/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 147, in backward\n    Variable._execution_engine.run_backward(\n  File \"/home/miranda9/miniconda3/envs/metalearning_cpu/lib/python3.9/site-packages/wandb/wandb_torch.py\", line 285, in &lt;lambda&gt;\n    handle = var.register_hook(lambda grad: _callback(grad, log_track))\n  File \"/home/miranda9/miniconda3/envs/metalearning_cpu/lib/python3.9/site-packages/wandb/wandb_torch.py\", line 283, in _callback\n    self.log_tensor_stats(grad.data, name)\n  File \"/home/miranda9/miniconda3/envs/metalearning_cpu/lib/python3.9/site-packages/wandb/wandb_torch.py\", line 235, in log_tensor_stats\n    tensor = flat.histc(bins=self._num_bins, min=tmin, max=tmax)\nRuntimeError: max must be larger than min\n</code></pre>\n<p>I am not doing anything myself so I am unsure how I can fix this\u2026</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-21T03:45:14.806Z",
				"Answer_body": "<p>Hmm, this appears to be a new bug. <a href=\"https://github.com/wandb/client/blob/master/wandb/wandb_torch.py#L225-L235\">We fixed a similar <code>RunTimeError</code> a while back</a>, so it\u2019s surprising to me that this is happening. For now, turning off gradient logging in <code>watch</code> (set <code>wandb.watch(log=None)</code>) will prevent this from triggering.</p>\n<p>I suggest you raise this issue with W&amp;B Support via the small gray bubble in the bottom-right of the screen on <a href=\"https://wandb.ai\">https://wandb.ai</a>. If you don\u2019t see a bubble, turn off any ad-blockers or email <a href=\"mailto:support@wandb.com\">support@wandb.com</a>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-12T21:15:53.463Z",
				"Answer_body": "<p>I get the same error message.</p>\n<pre><code class=\"lang-auto\">DcnPool553Model(\n  (encoder): DcnPool553ModelEncoder(\n    (conv1): Sequential(\n      (0): Conv3d(1, 32, kernel_size=(5, 5, 5), stride=(1, 1, 1))\n      (1): LeakyReLU(negative_slope=0.01)\n    )\n    (conv2): Sequential(\n      (0): Conv3d(32, 64, kernel_size=(5, 5, 5), stride=(1, 1, 1))\n      (1): LeakyReLU(negative_slope=0.01)\n    )\n    (pool1): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n    (conv3): Sequential(\n      (0): DeformConv3d(\n        (zero_padding): ConstantPad3d(padding=(0, 0, 0, 0, 0, 0), value=0)\n        (conv_kernel): Conv3d(1728, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n        (offset_conv_kernel): Conv3d(64, 81, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n      )\n      (1): LeakyReLU(negative_slope=0.01)\n    )\n    (pool2): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n    (fc1): Linear(in_features=3456, out_features=128, bias=True)\n    (relu): LeakyReLU(negative_slope=0.01)\n    (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop): Dropout(p=0.15, inplace=False)\n    (fc2): Linear(in_features=128, out_features=128, bias=True)\n  )\n  (decoder): DcnPool553ModelDecoder(\n    (fc2): Linear(in_features=128, out_features=128, bias=True)\n    (drop): Dropout(p=0.15, inplace=False)\n    (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): LeakyReLU(negative_slope=0.01)\n    (fc1): Linear(in_features=128, out_features=3456, bias=True)\n    (pool2): MaxUnpool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 0, 0))\n    (conv3): Sequential(\n      (0): LeakyReLU(negative_slope=0.01)\n      (1): DeformConv3d(\n        (zero_padding): ConstantPad3d(padding=(2, 2, 2, 2, 2, 2), value=0)\n        (conv_kernel): Conv3d(3456, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n        (offset_conv_kernel): Conv3d(128, 81, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2))\n      )\n    )\n    (pool1): MaxUnpool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 0, 0))\n    (conv2): Sequential(\n      (0): LeakyReLU(negative_slope=0.01)\n      (1): ConvTranspose3d(64, 32, kernel_size=(5, 5, 5), stride=(1, 1, 1))\n    )\n    (conv1): Sequential(\n      (0): LeakyReLU(negative_slope=0.01)\n      (1): ConvTranspose3d(32, 1, kernel_size=(5, 5, 5), stride=(1, 1, 1))\n    )\n  )\n)\nDevice used for training: cuda:0\n  0% 0/100 [00:00&lt;?, ?it/s]\n\nwandb: Waiting for W&amp;B process to finish, PID 859... (failed 1). Press ctrl-c to abort syncing.\nwandb:                                                                                \nwandb: Run history:\nwandb:   train_epoch \u2581\u2581\u2581\nwandb:    train_loss \u2581\u2581\u2588\nwandb: \nwandb: Run summary:\nwandb:   train_epoch 0\nwandb:    train_loss 607629.75\nwandb: \nwandb: Synced 5 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\nwandb: Synced true-forest-14: https://wandb.ai/dezzardhd/large_dataset/runs/3qfwvzdm\nwandb: Find logs at: ./wandb/run-20220212_210203-3qfwvzdm/logs/debug.log\nwandb: \nTraceback (most recent call last):\n  File \"main.py\", line 47, in &lt;module&gt;\n    train_setups.start_training_sessions(project=project)\n  File \"/content/drive/MyDrive/Workspace/large_dataset_0/train_setups.py\", line 15, in start_training_sessions\n    model_pipeline(config, project=project)\n  File \"/content/drive/MyDrive/Workspace/large_dataset_0/learning.py\", line 76, in model_pipeline\n    train(model, train_loader, validation_loader, criterion, optimizer, scheduler, config)\n  File \"/content/drive/MyDrive/Workspace/large_dataset_0/learning.py\", line 149, in train\n    loss = train_batch(batch, model, optimizer, criterion)\n  File \"/content/drive/MyDrive/Workspace/large_dataset_0/learning.py\", line 176, in train_batch\n    loss.backward()\n  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 307, in backward\n    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 156, in backward\n    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n  File \"/usr/local/lib/python3.7/dist-packages/wandb/wandb_torch.py\", line 282, in &lt;lambda&gt;\n    handle = var.register_hook(lambda grad: _callback(grad, log_track))\n  File \"/usr/local/lib/python3.7/dist-packages/wandb/wandb_torch.py\", line 280, in _callback\n    self.log_tensor_stats(grad.data, name)\n  File \"/usr/local/lib/python3.7/dist-packages/wandb/wandb_torch.py\", line 232, in log_tensor_stats\n    tensor = flat.histc(bins=self._num_bins, min=tmin, max=tmax)\nRuntimeError: max must be larger than min\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-12T21:58:55.528Z",
				"Answer_body": "<p>Thanks for the tip!</p>\n<p>After setting wandb.watch(log=None) the RuntimeError disappeared.<br>\nMy train loss became NaN. Managed to fix the problem by normalizing data.</p>\n<p>Maybe this error occurs due to high values in loss\u2026 idk\u2026</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-14T22:15:20.272Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dezzardhd\">@dezzardhd</a> , this sounds like an issue with overflow/underflow</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:07.460Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Overriding logged media",
		"Question_link": "https://community.wandb.ai/t/overriding-logged-media/1855",
		"Question_created_time": "2022-02-01T15:36:21.223Z",
		"Question_answer_count": 6,
		"Question_score_count": 1,
		"Question_view_count": 371,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey there <img src=\"https://emoji.discourse-cdn.com/twitter/raised_hand.png?v=12\" title=\":raised_hand:\" class=\"emoji\" alt=\":raised_hand:\"></p>\n<p>During my training I want to produce some visual outputs every epoch to monitor that the predictions make sense. I am logging a matplotlib figure with:</p>\n<pre><code class=\"lang-python\"> logger.log({'last epoch': fig})\n</code></pre>\n<p>The issue is that wandb is saving every figure that is produced instead of overwriting the last one. How can this be achieved?</p>\n<p>Thanks in advance<br>\nArturo</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-02-01T17:16:15.443Z",
				"Answer_body": "<p>Hi, <a class=\"mention\" href=\"/u/artuntun\">@artuntun</a> , right now you are logging the figure to the key called \u201clast epoch\u201d. If you just log it normally like <code>wandb.log({'epoch': epoch, 'predictions_fig': fig})</code> then you will be able to see the most recent figure but also have the option to toggle back through all the other figures at each epoch to see how your predictions evolved overtime.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-02T09:44:04.124Z",
				"Answer_body": "<p>that is the behavior that is already happening. What I actually want is to not save all of them. It a heavy figure and I don\u2019t want to save that much data.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-04T11:34:55.878Z",
				"Answer_body": "<p>Ahh I see. In that case, I would recommend only logging your final image. By design, it is difficult to delete or overwrite data logged to a run, during a run. This is to prevent accidental data loss and preserve as much of the experiment as possible. Alternatively, if you just wanted to log the image file, you could save it with wandb.save(path-to-image).</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-07T08:40:16.925Z",
				"Answer_body": "<p>thanks for the response aidanjd<br>\nIs it possible to log the final image if I stop the training loop manually?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-10T17:29:04.403Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/artuntun\">@artuntun</a> , saving the image with <code>wandb.save()</code> will achieve this naturally though your image won\u2019t appear in the workspace panels. The other way of doing this would be to catch whatever interrupt errors you are throwing to stop you training loop and call your end of training image logging then.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-11T17:29:36.280Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "About manually assign weights & biases",
		"Question_link": "https://community.wandb.ai/t/about-manually-assign-weights-biases/1884",
		"Question_created_time": "2022-02-08T23:40:01.355Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 134,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>How can we manually assign weights and biases rather than using randomly generated weights and biases at the beginning?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-02-09T12:47:11.996Z",
				"Answer_body": "<p>You can manually assign the tensors like <code>arr[0] = 0</code>.<br>\nIt\u2019s usually better practise to assign weights &amp; biases randomly before training.<br>\nIf you\u2019re using PyTorch, here are a bunch of different init methods: <a href=\"https://pytorch.org/docs/master/nn.init.html\" class=\"inline-onebox\">torch.nn.init \u2014 PyTorch master documentation</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.073Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Get a link to share project",
		"Question_link": "https://community.wandb.ai/t/get-a-link-to-share-project/1873",
		"Question_created_time": "2022-02-06T06:52:01.779Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 534,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have an existing project. I want to be able to make it public and share it to someone so that they can take a look at the graphs</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-02-07T14:58:08.519Z",
				"Answer_body": "<p>Hi Aditya!</p>\n<p>You would need to turn off the \u201cForce all projects in this team to be private\u201d setting in your user settings (<a href=\"http://wandb.ai/settings\" class=\"inline-onebox-loading\">wandb.ai/settings</a>) to make this project Public or Open. Please let me know if you still run into this issue.</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-10T15:27:45.701Z",
				"Answer_body": "<p>Hi Aditya, this was a bug that was fixed earlier this week. Please let me know if you still run into this issue</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-07T06:52:52.497Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Access to study group",
		"Question_link": "https://community.wandb.ai/t/access-to-study-group/1850",
		"Question_created_time": "2022-01-31T09:11:41.251Z",
		"Question_answer_count": 4,
		"Question_score_count": 2,
		"Question_view_count": 159,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Can you please help with content for hf-fastai2</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-02-01T09:24:23.924Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/anupam_mitra\">@anupam_mitra</a> , what specifically would you like help with?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-01T14:26:13.738Z",
				"Answer_body": "<p>Hello Aidan,</p>\n<p>I  have registered for event Hugging Face + Fast AI Study group and I was looking for the notebook+ppt which were discussed earlier</p>\n<p>Thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-06T02:30:59.106Z",
				"Answer_body": "<p>Slides can be found in fastai <a href=\"https://discord.com/channels/689892369998676007/859175939368026162/937472311836176425\" rel=\"noopener nofollow ugc\">discord.</a></p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-04-07T02:31:10.472Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to visualize HTML run in Kubeflow Pipeline?",
		"Question_link": "https://community.wandb.ai/t/how-to-visualize-html-run-in-kubeflow-pipeline/1862",
		"Question_created_time": "2022-02-02T12:53:25.410Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 867,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hello,</p>\n<p>We use Pytorch Lightning for training and we use Kubeflow Pipelines and are thinking about using wandb to track and visualize the training and test metrics.</p>\n<p>Kubeflow pipelines offers the possibility to view a static html page (see <a href=\"https://www.kubeflow.org/docs/components/pipelines/sdk/output-viewer/#single-html-file\" rel=\"noopener nofollow ugc\">this link</a> ).<br>\nI was wondering if it would be possible via the wandb python sdk to get a read-only embeded code (iframe) that I could then simply pass to Kubeflow pipeline sdk to show the html ?</p>\n<p>Thanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-02-02T14:20:18.566Z",
				"Answer_body": "<p><strong>UPDATE :</strong><br>\nAfter checking the doc further I came across  <code>wandb_logger.experiment.to_html()</code> which seems to do exactly what I wanted but I still need to find a way to authenticate for read only anonymous viewer.<br>\nIs it possible to generate an html iframe with the API token built-into the url? Something like <code>wandb_logger.experiment.to_html(api_key=$API_KEY)</code></p>\n<p>Or is it possible to set environment variables so that when we visit the url in the iframe we get authentication automatically? The Kubeflow ml-pipeline-ui pod can have secrets/env variables.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-03T22:11:34.745Z",
				"Answer_body": "<p>After some tests it looks like the auth part works out-of-the-box in Kubeflow.<br>\nBut there is one issue, Kubeflow HTML output creates an iframe with a srcdoc that contains our html.<br>\nTherefore if we pass an iframe to kubeflow, then we\u2019ll end up with an iframe (from the viewer) with a nested iframe (from wandb <code>.to_html()</code>) and the nested iframe is not displayed ( I think the iframe\u2019s srcdoc expects raw static html).</p>\n<p>Is there a way I could export a wandb run to STATIC html or perhaps there is a way to make the inner iframe display?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-03T23:26:27.864Z",
				"Answer_body": "<p>Ok I found the solution.<br>\nKubeflow Pipelines also support markdown visualization therefore instead of using kubeflow HTML output I used markdown and since markdown supports html inline I was able to directly use the wandb run html.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/21d1b9f84b7948659b75b981b04f21235e528615.png\" data-download-href=\"/uploads/short-url/4Pb5MStVV77kGP5bCR1nBTvaK7H.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/21d1b9f84b7948659b75b981b04f21235e528615_2_690x333.png\" alt=\"image\" data-base62-sha1=\"4Pb5MStVV77kGP5bCR1nBTvaK7H\" width=\"690\" height=\"333\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/21d1b9f84b7948659b75b981b04f21235e528615_2_690x333.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/21d1b9f84b7948659b75b981b04f21235e528615_2_1035x499.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/21d1b9f84b7948659b75b981b04f21235e528615_2_1380x666.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/21d1b9f84b7948659b75b981b04f21235e528615_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1678\u00d7812 57.6 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Here is the code if someone is interested :</p>\n<pre><code class=\"lang-python\">import kfp\nfrom kfp.v2.dsl import component, Output, Markdown, pipeline\n\n@component(packages_to_install=['wandb'])\ndef wandb_visualization(markdown_artifact: Output[Markdown]):\n    import wandb\n    wandb.login(key=\"you_key\")\n\n    run = wandb.init(project=\"your-project\", entity=\"your-entity\")\n\n    wandb.log({\"train/loss\" : 5.0})\n    wandb.log({\"train/loss\" : 4.0})\n    wandb.log({\"train/loss\" : 3.0})\n    wandb.log({\"train/loss\" : 2.0})\n    wandb.log({\"train/loss\" : 1.0})\n\n    wandb.finish()\n    with open(markdown_artifact.path, 'w') as f:\n        f.write(f\"&lt;iframe src=\\\"{run.get_url()}\\\" width=\\\"100%\\\" height=\\\"700\\\"/&gt;\")\n</code></pre>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-04-04T23:26:42.679Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "[Potential Bugs] Issues with `wandb sync` after running `wandb artifact cache cleanup 10GB`",
		"Question_link": "https://community.wandb.ai/t/potential-bugs-issues-with-wandb-sync-after-running-wandb-artifact-cache-cleanup-10gb/1784",
		"Question_created_time": "2022-01-19T05:15:57.992Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 591,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I am using the offline mode to train models and sync the wandb logs/artifacts later using <code>wandb sync</code> command. As the number of artifact files get larger, I used <code>wandb artifact cache cleanup 10GB</code> to clean up some disk space. However, after running this command, I can no longer to <code>wandb sync</code> to upload the logs to the wandb online server.</p>\n<p>I got the following error when using <code>wandb sync</code> after running <code>wandb artifact cache cleanup 10GB</code>. There are many artifacts in this run, some of them might be deleted via the <code>cache cleanup</code> command. However, the logs (learning curves etc.) are all there,  but the following error prevents the logs being sync to the cloud server. Is there a way to still upload the logs?</p>\n<pre><code class=\"lang-auto\">FileNotFoundError, [Errno 2] No such file or directory: '/home/user/.cache/wandb/artifacts/obj/md5/93/a2248a657e599da7c97f43d292b1c'\nwandb: ERROR Uploading artifact file failed. Artifact won't be committed.</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-19T11:56:10.835Z",
				"Answer_body": "<p>Hey Tao, which wandb version are you using?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-19T14:51:58.262Z",
				"Answer_body": "<p>Hi, I am using <code>0.12.9</code>. Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-01T22:19:33.665Z",
				"Answer_body": "<p>Hey Tao, sorry about the delay on this. Could you try syncing to new run id: <code>wandb sync [PATH] --id new_run_id</code> ? Generate the new run id via <code>wandb.util.generate_id()</code></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-04T15:58:51.255Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-02T22:19:41.343Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Problem with wandb.plot.pr_curve",
		"Question_link": "https://community.wandb.ai/t/problem-with-wandb-plot-pr-curve/1857",
		"Question_created_time": "2022-02-01T17:33:32.021Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 108,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello. My code for each training epoch:</p>\n<pre><code class=\"lang-auto\">wandb.log({\n    \"PR_curve\":  wandb.plot.pr_curve(y_true, [(x, 1 - x) for x in y_predict])\n})\n</code></pre>\n<p>But I had plots like that(the left part):<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/44df6eaaba224cfd4133696ef68c21a9de1f33d5.jpeg\" data-download-href=\"/uploads/short-url/9PhavrmCKrRlTKNxaRThfK8TGZv.jpeg?dl=1\" title=\"imgonline-com-ua-2to1-fyiDuqxQ397nx579\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/44df6eaaba224cfd4133696ef68c21a9de1f33d5_2_690x210.jpeg\" alt=\"imgonline-com-ua-2to1-fyiDuqxQ397nx579\" data-base62-sha1=\"9PhavrmCKrRlTKNxaRThfK8TGZv\" width=\"690\" height=\"210\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/44df6eaaba224cfd4133696ef68c21a9de1f33d5_2_690x210.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/44df6eaaba224cfd4133696ef68c21a9de1f33d5_2_1035x315.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/44df6eaaba224cfd4133696ef68c21a9de1f33d5_2_1380x420.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/44df6eaaba224cfd4133696ef68c21a9de1f33d5_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">imgonline-com-ua-2to1-fyiDuqxQ397nx579</span><span class=\"informations\">1565\u00d7477 91.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nWhen I used pyplot I got the right part for some epoche:<br>\nAs I understand curve for class \u201c1\u201d must be equal to one of curves from second picture.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-02-01T19:10:44.842Z",
				"Answer_body": "<p>I\u2019ve changed predicted labels and now it\u2019s working:</p>\n<pre><code class=\"lang-auto\">wandb.plot.pr_curve(y_true, [(1 - x, x) for x in y_predict])\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-01T19:32:40.045Z",
				"Answer_body": "<p>Hi Miro,<br>\nGlad you were able to figure this out. Let us know if you need any additional help with this.</p>\n<p>Thank you,<br>\nNate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-02T19:11:30.325Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "A colleague accidentally deleted some projects, any chance to get them back?",
		"Question_link": "https://community.wandb.ai/t/a-colleague-accidentally-deleted-some-projects-any-chance-to-get-them-back/1774",
		"Question_created_time": "2022-01-17T17:30:42.480Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 148,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Some of our teams projects were erroneously deleted by a colleague since he wanted to clean up his account and probably thought it were his own projects. Is there any chance to get the data back (I assume not, but worth a try\u2026)?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-18T12:19:56.235Z",
				"Answer_body": "<p>Hey there, can you tell me the username and the project nanes?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-18T13:57:47.750Z",
				"Answer_body": "<p>Hello.</p>\n<p>One project was <a href=\"https://wandb.ai/abiz/airspace-rl\" class=\"inline-onebox\">Weights &amp; Biases</a>. There are already new runs in there now I think. I don\u2019t know the other projects by heart but I could ask around and gather a list. It was all the projects in the team.</p>\n<p>Edit: With username you meant the user that deleted the projects? It was \u201ctobycheese\u201d I think.</p>\n<p>Kind regards</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-19T11:24:52.149Z",
				"Answer_body": "<p>Please check the names of the project. By username I meant the entity name where the projects were logged. If these were team projects then I need the team name.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-01-19T14:53:05.559Z",
				"Answer_body": "<p>Hi</p>\n<p>The link above was weirdly formatted, it points to the team/entity. The name is \u201cabiz\u201d.</p>\n<p>I will check the project names</p>\n<p>Thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-24T13:34:37.729Z",
				"Answer_body": "<p>Hey there, did you get a chance to check the project names?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-01T10:20:44.000Z",
				"Answer_body": "<p>Hi, I asked for feedback from my colleagues, it seems they were not actively using it at this moment so they are fine with the loss of data, as am I. I was not aware of this, sorry for taking your time. Thank you for your help anyway.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-02T10:21:34.390Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Out of memory",
		"Question_link": "https://community.wandb.ai/t/out-of-memory/1737",
		"Question_created_time": "2022-01-09T07:30:13.801Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 195,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have a question about how to free memory when integrating weights and biases  with yolox implementation?<br>\nAfter using weights and biases, my memory crashes before even completing the first epoch<br>\nI am using kaggle for yolox training<br>\nAny suggestions for this issue?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-13T14:31:21.101Z",
				"Answer_body": "<p>Is it crashing without W&amp;B?<br>\nUsing W&amp;B shouldn\u2019t add much memory overhead so it would be pretty unexpected if just adding W&amp;B gave you a OOM error. Typical ways to reduce memory usage is to reduce your batch size, and make sure you\u2019re not accidentally keeping data on the GPU.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-13T15:40:14.861Z",
				"Answer_body": "<p>Yes sir.<br>\nIt only crashes only after adding wandb to the code</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-31T13:01:20.954Z",
				"Answer_body": "<p>Hey,<br>\nSorry for the late response. Can you share some code so we can try reproduce please?<br>\nThanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-01T21:51:04.817Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-01T13:01:54.309Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Why are curves in different relative positions when zooming?",
		"Question_link": "https://community.wandb.ai/t/why-are-curves-in-different-relative-positions-when-zooming/1747",
		"Question_created_time": "2022-01-11T16:27:19.680Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 241,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi team,</p>\n<p>Why am I seeing the green curve below the crimson curve in default view, but when I zoom into an x-range they overlap? FYI there is exponential avg smoothing with beta = 0.9</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/13ff04711b564d6fe57e7e360436af1cb51c0316.gif\" alt=\"curves_off\" data-base62-sha1=\"2QTrx5Mqnr4RbpOBcE5izW3FbXU\" width=\"690\" height=\"397\" class=\"animated\"></p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-11T19:00:15.564Z",
				"Answer_body": "<p>Furthermore while continuing to play around with zoom I\u2019ve realised the curves is all over the place even when not comparing against another curve but rather just looking at the shape or looking at it\u2019s position relative to the horizontal guidelines.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-12T18:19:27.152Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/alexander-soare\">@alexander-soare</a>,</p>\n<p>Thanks for bringing this to our attention. Do you notice this behavior with other plots too or just this plot? Also, does this error also happen when you zoom into other parts of this plot?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-13T09:33:34.061Z",
				"Answer_body": "<p>Hi Ramit,</p>\n<p>It happens on other plots. And yes it happens on other parts of the plot. Here\u2019s another example. Look at the kind of hump shape on the tail end of the chart. When I zoom in, the shape is completely different.</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/f0cea53ed4bbf2088162b16cc939776560d4c92f.gif\" alt=\"Peek 2022-01-13 09-32\" data-base62-sha1=\"ymhko0Xuva0jSA6hJFAloIm6FGL\" width=\"690\" height=\"290\" class=\"animated\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-19T21:55:39.232Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/alexander-soare\">@alexander-soare</a>,</p>\n<p>This seems like a bug on our end. I have notified our engineering team of this issue, and we should have it resolved soon. As a workaround till then, could you try putting the X and Y values in the chart through the input boxes on \u201cEdit Chart\u201d?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-30T12:59:53.524Z",
				"Answer_body": "<p>Thanks for looking into this Ramit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-31T12:59:56.865Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Decoding .wandb files?",
		"Question_link": "https://community.wandb.ai/t/decoding-wandb-files/1803",
		"Question_created_time": "2022-01-21T16:11:33.396Z",
		"Question_answer_count": 9,
		"Question_score_count": 1,
		"Question_view_count": 223,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am hoping to inspect some thing in the .wandb file before I upload them (it is faster to get some quick results this way than to upload and then redownload data), but I am not sure what they are encoded in. Do you know if there are tools in the wandb library I can use to open these?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-21T17:18:57.198Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/evanv\">@evanv</a> , we don\u2019t really support tools to do this. Can you give me some more context around why this is a desired feature?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-21T17:38:55.816Z",
				"Answer_body": "<p>I have a lot of runs I need to do because of seeding issues and they take a while to upload to wandb (I have to run everything offline). I definitely want to have them in wandb for reproducibility, logging, and analysis, but there is some analysis I can do very quickly if I am able to extract it from the logged data. Otherwise I need to wait several hours to upload to wandb and several more hours to download everything to get the data I need which is a bit counter-intuitive. Thanks so much for your help!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-21T17:55:59.510Z",
				"Answer_body": "<p>It sounds like <a href=\"https://docs.wandb.ai/guides/self-hosted/local\">local</a>, the self hosted version of wandb might be a better option for your use case.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-21T18:11:42.872Z",
				"Answer_body": "<p>Yeah, that is the general sense I have gotten. Unfortunately it doesn\u2019t seem to be an option for me because the HPC I am using does not permit docker (it seems most HPCs don\u2019t because of security vulnerabilities). Do you know if I can setup wandb locally on my laptop and still run on seperate machines that don\u2019t have access to that wandb local setup?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-27T21:59:17.678Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/evanv\">@evanv</a> , I guess you could run your experiments on your HPC, scp all the wandb data over to your laptop where you\u2019ve set up a local instance. Then you could view the results without having to upload them to the internet.</p>\n<p>However, I\u2019m not sure it wouldn\u2019t be simpler to write some kind of function that logs the high level data you want to inspect before uploading to a csv or pdf plot.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-27T22:12:21.437Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/aidanjd\">@aidanjd</a> ,</p>\n<p>That actually is a great idea if it works and would solve a lot of issues! Is there anything inherent to the .wandb files that specifies that they are read by your servers as opposed to a wandb local instance? The thing I am trying to wrap my brain around is how I actually view the files from my local device using the wandb local instance.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-27T22:13:59.108Z",
				"Answer_body": "<p>The only thing you\u2019d have to worry about is making sure the are accessible from the docker container that is running the local instance.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-27T22:14:10.362Z",
				"Answer_body": "<p>The only thing you\u2019d have to worry about is making sure the are accessible from the docker container that is running the local instance.</p>\n<p>[Discourse post]</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-28T22:14:44.605Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Logging temporal data / overriding single image",
		"Question_link": "https://community.wandb.ai/t/logging-temporal-data-overriding-single-image/1809",
		"Question_created_time": "2022-01-23T19:13:21.882Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 209,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey, I have 1D data that I\u2019d like to show it at every step (think hidden state of a model) as a 2D image (x-axis would correspond to time/epoch and y axis to # of neurons). Can I do this?</p>\n<p>If not, I can maintain the image myself and simply resend the data as an image, but then I\u2019d have to overwrite the image on the server. Can I do that?</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-24T19:03:35.034Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/aiaiai\">@aiaiai</a> , have you looked at using <code>wandb.Histogram</code>? Here are the reference <a href=\"https://docs.wandb.ai/ref/python/data-types/histogram\">docs</a>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-24T19:54:09.731Z",
				"Answer_body": "<p>Hey, yes I have. But this is different from what I want: to report positional, not aggregate, data. If I could send an array at each step, say [0.1, 0.3] at step 1, and [0.2, 0.,6] at step 2 I would like to see an image that would like like [[0.1, 0.3], [0.2, 0.6]] on the dashboard.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-27T21:51:33.364Z",
				"Answer_body": "<p>Ahh ok I see. Your best best bet is to maintain the image yourself and logging it to wandb. You won\u2019t actually be overwriting the image and will be able to see all the previous images logged. I would just make sure you keep the image dimensions consistent.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-28T21:51:47.347Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb Local on Singularity?",
		"Question_link": "https://community.wandb.ai/t/wandb-local-on-singularity/1820",
		"Question_created_time": "2022-01-26T16:52:59.794Z",
		"Question_answer_count": 3,
		"Question_score_count": 2,
		"Question_view_count": 187,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Has anyone found a good way to host wandb local on singularity rather than Docker? My understanding is that many institutions, mine included, do not allow use of docker because of security flaws within it.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-26T20:02:14.985Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/evanv\">@evanv</a>,</p>\n<p>We do not have official support for singularity. You could, however, follow existing tutorials on running Docker containers with Singularity.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-01-26T22:21:41.710Z",
				"Answer_body": "<p>Thank you so much! I will look into it and post if I am successful</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-27T22:22:35.420Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to make select group use a different x axis",
		"Question_link": "https://community.wandb.ai/t/how-to-make-select-group-use-a-different-x-axis/1813",
		"Question_created_time": "2022-01-24T18:28:32.031Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 144,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>In my project, one of the network is larger than the others and has to use a smaller batch size. To keep the comparison fair, I used a 2x smaller batch size but accumulate gradients for 2 batches, which is theoretically the same amount of gradient updates as long as I keep the number of epochs 2x larger than the normal models. However, in the plots that are being tracked, the bigger model will look like it learns twice as slow as the normal model. This is expected, but to simulate the effect training with the same batch size, I need to shrink the x axis of the big model\u2019s learning curve.</p>\n<p>How would I do that? There is an expression column that I can use when editing the panels, but this seems to only work for all the curves in the plot, not selectively.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-25T11:34:31.593Z",
				"Answer_body": "<p>Maybe somebody else will have a better solution but I believe this is only possible if you know ahead of time that you want to change the x-axis.</p>\n<p>You need to use a method called <code>define_metric</code> in which you can define a custom step.</p>\n<p>Here\u2019s an example of setting a custom x-axis metric, instead of using the default step:</p>\n<pre><code class=\"lang-python\">import wandb\n\nwandb.init()\n# define our custom x axis metric\nwandb.define_metric(\"custom_step\")\n# define which metrics will be plotted against it\nwandb.define_metric(\"validation_loss\", step_metric=\"custom_step\")\n\nfor i in range(10):\n  log_dict = {\n      \"train_loss\": 1/(i+1),\n      \"custom_step\": i**2,\n      \"validation_loss\": 1/(i+1)   \n  }\n  wandb.log(log_dict)\n</code></pre>\n<p>from the docs here: <a href=\"https://docs.wandb.ai/guides/track/log#customize-axes\">https://docs.wandb.ai/guides/track/log#customize-axes</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-26T11:34:45.555Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Where are artifacts stored locally?",
		"Question_link": "https://community.wandb.ai/t/where-are-artifacts-stored-locally/1733",
		"Question_created_time": "2022-01-08T20:46:19.166Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 474,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>As the title says, where are the artifacts stored locally when I save an artifact? How can I change its default location? It seems that changing <code>WANDB_DIR</code> does not change where artifacts are stored. On the other hand, I found many folders in <code>.../wandb/artifacts/obj/md5</code>,  what are these folders? Can I change its default saving location? Thanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-11T12:06:51.571Z",
				"Answer_body": "<p>Hey Tao, checking on that for you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-21T14:11:22.157Z",
				"Answer_body": "<p>Hey Tao, apologies about the delay on this one. The artifacts you create during a run will be placed in the run directory where the run information is logged (and as such the artifacts logged to a run will be placed in a nested directory starting with the WANDB_DIR).<br>\nWhen you are downloading an artifact you can pass the directory  to save to in that case: <a href=\"https://docs.wandb.ai/ref/python/artifact#download\">https://docs.wandb.ai/ref/python/artifact#download</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-22T14:11:22.869Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Initiate Sweep Agent with Specific Hyperparameter Value",
		"Question_link": "https://community.wandb.ai/t/initiate-sweep-agent-with-specific-hyperparameter-value/1789",
		"Question_created_time": "2022-01-19T22:12:32.515Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 160,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am running a sweep from several different machines. The machines have different GPU RAM, so I need to manually set the batch size on each machine. I would like to set batch size as a sweep parameter,  however, I can not figure out how to specify that certain agents use a specific value for a given hyperparameter, and randomly assign the rest.</p>\n<p>Thanks,<br>\nEdward</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-19T22:29:49.279Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/edwardwang1\">@edwardwang1</a>,</p>\n<p>The W&amp;B Sweep server sends out hyperparameter configurations agnostic of your system\u2019s capabilities, so I don\u2019t think this can be done from inside the sweep config.</p>\n<p>I think the best way to achieve this would be to have your script find out the amount of GPU VRAM on the system it is running on (I think <a href=\"https://pypi.org/project/pynvml/\" rel=\"noopener nofollow ugc\">PyNVML</a> could be useful here) and then calculate the batch size using that information.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-19T22:46:10.498Z",
				"Answer_body": "<p>Hi Ramit, thanks for the response. I know a priori what batch size I should use for a given machine, and I just want to hardcode that in to a given agent.</p>\n<p>I\u2019ve attempted to change the config  via <code>wandb.config.update</code>, but it seems that does not work (I get the following message: \u201cConfig item \u2018batch_size\u2019 was locked by \u2018sweep\u2019 (ignored update).\u201d</p>\n<p>Thanks,<br>\nEdward</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-20T21:11:45.393Z",
				"Answer_body": "<p>Hey Edward,</p>\n<p>Even if you know the batch sizes a priori, I don\u2019t think this would be possible from inside the sweep config. We plan to release conditional sweep configurations in the future, through which this should be possible.</p>\n<p>For now, I think the best method would still be to calculate the batch sizes from inside your script. If you know the batch sizes you want to use, you should be able to set up a conditional statement to assign batch sizes according to the machine the script is running on.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-20T21:26:38.823Z",
				"Answer_body": "<p>Hi Ramit,</p>\n<p>Gotcha. Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-21T21:27:35.607Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Downloading best sweep model from python",
		"Question_link": "https://community.wandb.ai/t/downloading-best-sweep-model-from-python/1781",
		"Question_created_time": "2022-01-18T01:44:14.498Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 286,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have run a few sweeps, and now I want to get the best models from any given sweeps. I follow the tutorial here: <a href=\"https://docs.wandb.ai/guides/track/public-api-guide\">https://docs.wandb.ai/guides/track/public-api-guide</a> and run my code as following</p>\n<pre><code class=\"lang-auto\">import wandb\napi = wandb.Api()\nruns = api.sweep(f\"{team_name}/{project_name}/{sweep_id}\").runs\nrun = sorted(runs, key=lambda run: run.summary.get(\"val_accuracy\", 0), reverse=True)[0]\nrun.file(f\"{path}{run.name}.h5\").download(replace=True)\n</code></pre>\n<p>And I get a \u201cPermission denied, ask the project owner to grant you access\u201d error on the run.file().download(), even though I followed the tutorial. I tried this in two different settings, (1) in a team where I am the admin and (2) on my personal account (note that these are the \u201cteam_name\u201d I am using in the api.sweep).</p>\n<p>It does find my sweep and the runs, I can also see the validation accuracies of all runs, it just doesn\u2019t allow me to download the files.</p>\n<p>Furthermore, and this might be unrelated, whenever I try to inspect the run elements in my pycharm, the debugger crashes. This has never happened before, but it\u2019s consistent on my machine, crashing my debugger every time</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-18T19:10:24.862Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/tjobbertjob\">@tjobbertjob</a>,</p>\n<p>You should be able to access your artifact through <code>run.logged_artifacts()</code>. I\u2019ve written a small script for you (though you might have to edit it a little bit) to achieve this for you:</p>\n<pre><code class=\"lang-auto\">api = wandb.Api()\n\nsweep = api.sweep(f'{entity}/{project}/{sweep_id}')\nruns = sweep.runs\n\nruns = sorted(runs, key = lambda run: run.summary.get('val_loss'))\nbest_run = runs[0]\n\nartifacts = best_run.logged_artifacts()\n\nbest_model = [artifact for artifact in artifacts if artifact.type == 'model'][0]\nbest_model.download()\n</code></pre>\n<p>Please let me know if this solves your issue.</p>\n<p>Thanks,<br>\nRamit<br>\nWeights and Biases Support</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-18T23:37:38.517Z",
				"Answer_body": "<p>The artifacts list is empty, I suspect this is because I never configured it to log or send any artifacts during my sweep? Sadly though, this answer doesn\u2019t fix the issue  due to that fact. Still have not figured out why I am getting an access error when trying to download from my own account.</p>\n<p>I also tried it on my Linux server (my PC is windows), to see if it was machine specific, but it wasn\u2019t. I get the exact same issue on the Linux server.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-20T21:09:07.372Z",
				"Answer_body": "<p>I see. In that case, could you check if you are able to access the name of the file you want to download through <code>run.file</code>?</p>\n<p>It would also help if you could send over the full stack trace you received and the link of the project you are trying to download the file for.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-24T23:15:58.806Z",
				"Answer_body": "<p>Hi Tobias,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-28T00:27:14.847Z",
				"Answer_body": "<p>Hi Tobias, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-21T21:09:34.339Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Accesing wandb.ai takes too long",
		"Question_link": "https://community.wandb.ai/t/accesing-wandb-ai-takes-too-long/1797",
		"Question_created_time": "2022-01-20T10:11:12.749Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 232,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello!</p>\n<p>The time that takes to visit <a href=\"http://wandb.ai\">wandb.ai</a> is extremely long. I don\u2019t know what is happening. The problem is not that there is too much data/graphs to load. Even when I have to go to <a href=\"https://wandb.ai/authorize\" class=\"inline-onebox\">Weights &amp; Biases</a> I have to wait for about 10-20 seconds. That is really disappointing.</p>\n<p>My internet connection is about 10 Mbit/s. It is not fast, but it is okay to view simple websites. I don\u2019t experience problems with other websites. LinkedIn, Facebook, Twitter, Netflix works fine.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-20T20:32:42.763Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mrpositron\">@mrpositron</a>,</p>\n<p>This could be because of memory pressure on your computer. It might be helpful to clear your browser cache, and make sure there are no memory intensive processes running on your system.</p>\n<p>For your project workspaces, one way to reduce the time to load is Toggle some of your panels to be closed and select \u201cCopy to my Default Workspace\u201d from your workspace settings at the bottom of your screen. This will reduce the number of points to be rendered and improve performance.</p>\n<p>Hope this is helpful in getting a more responsive load time from our webpage.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-24T23:15:47.767Z",
				"Answer_body": "<p>Hi Nauryzbay,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-28T00:27:57.338Z",
				"Answer_body": "<p>Hi Nauryzbay, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-21T20:33:29.762Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Directly Querying Runs?",
		"Question_link": "https://community.wandb.ai/t/directly-querying-runs/1787",
		"Question_created_time": "2022-01-19T21:42:31.538Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 154,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have a project with a good number of runs (~30k). My overall goal is to find the best performing runs across a series of parameters specifying the data configuration (these parameters in my configs). Performance is measured as the maximum of the test accuracy obtained during training. This is relatively burdensome to do computationally if I read out each run individually. However it seems like something that any SQL-like database should be able to handle with ease (group by some parameters, measure maximums and sort, show only the top ones). Is this feasible with the wandb API?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-19T22:05:37.690Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/evanv\">@evanv</a>,</p>\n<p>You should be able to sort runs from the API using the <code>order</code> parameter for the <code>api.Runs</code> method. <a href=\"https://docs.wandb.ai/ref/python/public-api/runs\">Here</a> are some docs for the <code>api.Runs</code> method.</p>\n<p>Please let me know if this resolves your issue.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-24T19:43:36.453Z",
				"Answer_body": "<p>Hi Evan,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-27T21:19:48.345Z",
				"Answer_body": "<p>Hi Evan, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-20T22:05:56.516Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Setting up a sweep using port forwarding?",
		"Question_link": "https://community.wandb.ai/t/setting-up-a-sweep-using-port-forwarding/1696",
		"Question_created_time": "2022-01-05T18:51:02.663Z",
		"Question_answer_count": 6,
		"Question_score_count": 1,
		"Question_view_count": 228,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have a compute environment in which I have a university hosted cluster (so I am not admin) with a login node connected to the internet and not meant for compute jobs and several compute nodes which are connected to the login node but not to the internet. I would love to run a sweep in this environment but in the standard setup I would need my compute nodes to be connected to the internet. Is there a way I can setup port forwarding on the compute nodes so they can access the W&amp;B server via the login node? For reference, all environments are Ubuntu 18.04.6</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-06T17:09:49.203Z",
				"Answer_body": "<p>Hi Evan,</p>\n<p>Currently we don\u2019t have a way to have a completely offline version of sweeps. But a workaround that we do have is to run wandb local and use wandb offline, then use wandb sync to sync those results to your computer that has access to the internet.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-07T14:23:45.714Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/lesliewandb\">@lesliewandb</a> ,<br>\nThanks so much for your help. That is the workaround I am using right now although it is a bit cumbersome. Is there no way to engineer a way for \u201coffline\u201d nodes to communicate with the wandb server through an online node they are connected to? I definitely understand that a fully offline node could not but I\u2019d imagine if ports are aligned correctly it could be done. Do you know if there is a section of the wandb sweep sdk that deals with this which I could explore?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-11T16:25:28.332Z",
				"Answer_body": "<p>I\u2019m sorry, but right now that\u2019s the only option we have for offline sweeps</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-17T19:01:57.999Z",
				"Answer_body": "<p>I assume your compute nodes have ssh access to the login node. If that\u2019s the case, have you tried to set up a socks proxy using a ssh tunnel? You can follow any online tutorial, like this one: <a href=\"https://ma.ttias.be/socks-proxy-linux-ssh-bypass-content-filters/\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Create a SOCKS proxy on a Linux server with SSH to bypass content filters</a>.</p>\n<p>After you have set up your tunnel, you could set the following environment variables so your proxy is picked up by the <code>requests</code> library for http and https traffic:</p>\n<pre><code class=\"lang-auto\">export HTTP_PROXY=\"socks5://localhost:1337\"\nexport HTTPS_PROXY=\"socks5://localhost:1337\"\n</code></pre>\n<p>Assuming wandb uses <code>requests</code> and http or https traffic (which I don\u2019t really know), this should work.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-19T21:38:47.652Z",
				"Answer_body": "<p>Thanks so much <a class=\"mention\" href=\"/u/pcuenq\">@pcuenq</a> ! I am speaking with the sysadmins at my server about setting this up</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-20T21:38:55.333Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Is it possible to override a Table",
		"Question_link": "https://community.wandb.ai/t/is-it-possible-to-override-a-table/1776",
		"Question_created_time": "2022-01-17T20:25:01.000Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 330,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I\u2019m using a Table as it\u2019s the simplest to log text (Input output expected).</p>\n<p>However, I would like to keep only the last logged item in the Table, else I have thousand of rows or hundred of tables if I create a new table instead.</p>\n<p>Is there any fix for that ?</p>\n<p>Thanks in advance,<br>\nHave a great day <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=11\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-18T20:38:13.605Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ierezell\">@ierezell</a>,</p>\n<p>I think the simplest way about this would be to create a new table, for the last logged item, log it, and then delete it using python\u2019s <code>del</code> command.</p>\n<p>This way, you get to store the last row as desired, but deleting the table also means that you don\u2019t use up all your memory in the process.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-18T20:56:56.616Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a>,</p>\n<p>Thanks a lot for the response,</p>\n<p>The problem is that I will then have many tables as artifacts in weight and biases\u2026<br>\nI guess it\u2019s the best solution as it will only show the latest table in the report\u2026</p>\n<p>I will try that <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>\n<p>Have a great day</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-19T20:56:58.381Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Hiding runs in a sweep chart export",
		"Question_link": "https://community.wandb.ai/t/hiding-runs-in-a-sweep-chart-export/1778",
		"Question_created_time": "2022-01-18T01:04:26.195Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 231,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>I have a large sweep (~ 150 runs) and I want to hide some runs (these are not crashed runs) in the final sweep chart that I export. However, even if I turn off these runs in my visualization, I still see them with very faint lines (low opacity) in the chart that I see in my workspace and the PNG/PDF that I export. Is there a way to completely turn off the visualization of completed runs in my sweep plots without deleting the runs? Thank you!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-18T12:34:21.805Z",
				"Answer_body": "<p>Hey there, I don\u2019t think it is possible at the moment. I\u2019ll file a ticket for your request.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-19T12:34:59.426Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to show run name in repport Table",
		"Question_link": "https://community.wandb.ai/t/how-to-show-run-name-in-repport-table/1775",
		"Question_created_time": "2022-01-17T18:32:35.909Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 356,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I\u2019m using Tables to log text (input, output, and expected) and I\u2019m showing it in a report.</p>\n<p>That\u2019s working perfectly, I changed \u201cMerged Table\u201d to \u201cList of tables\u201d to be able to change Run and see one table per run.</p>\n<p>However, it shows \u201c1 of 8\u201d so okay I need to open runs, check the first one, and get its name.</p>\n<p>Is there any way to show the run name instead of the little colors dot in the table ?</p>\n<p>Thanks in advance,<br>\nHave a great day <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=11\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-18T21:18:29.053Z",
				"Answer_body": "<p>Hi Pierre! You can add the run name by first creating a new column on your table. This is done by clicking on the three dots on the right of a column name and then clicking on either \u2018Insert 1 left\u2019 or \u2018insert 1 right\u2019. Then, under \u2018Cell expression\u2019, type in row.run.name and the run names will appear in that column.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-24T13:15:38.081Z",
				"Answer_body": "<p>Hi Pierre, I\u2019m just checking in to see if you still need help with this?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-27T15:12:12.744Z",
				"Answer_body": "<p>Hi Pierre, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-18T18:33:20.302Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Uploading basic data only once with wandb",
		"Question_link": "https://community.wandb.ai/t/uploading-basic-data-only-once-with-wandb/1770",
		"Question_created_time": "2022-01-17T09:12:11.020Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 138,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi guys,<br>\nnot sure if this is the right place to ask, but i\u2019m trying to figure out how i can upload an \u201cartifact\u201d only once for my project.<br>\nI would like to upload a plot of my data to visualize some basic information. Adding it with wandb.log will upload this information on each run. Artifacts seem to be for data that should be versioned, which also doesn\u2019t seem to fit my usecase very well.</p>\n<p>I\u2019ve also tried uploading the dataset and then plotting it using the table information, but wandb seems to struggle with pandas datetimeindex, so i\u2019m not very happy with that solution either.</p>\n<p>Whats the proper way to go about doing this?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-18T21:15:32.194Z",
				"Answer_body": "<p>Please let me know if I\u2019m understanding this information properly. Are you trying to upload numerical values only once to plot? I agree that it looks like you\u2019re not supposed to be using Artifacts in this case, but rather wandb.log(). However, when you do try to use wandb.log(), datetimeindex isn\u2019t working well? Can you send an image of what you are seeing when you use it?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-24T13:15:09.483Z",
				"Answer_body": "<p>Hi Leon, I\u2019m just checking in to see if you need help with this issue still?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-27T15:11:01.415Z",
				"Answer_body": "<p>Hi Leon, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-18T09:12:31.293Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Error uploading dataset to colab",
		"Question_link": "https://community.wandb.ai/t/error-uploading-dataset-to-colab/1728",
		"Question_created_time": "2022-01-08T12:42:36.058Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 247,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am having issues when I try to upload my dataset. I don\u00b4t know why but when I upload just one image and label in each folder(train and val) everything works perfectly, but when I try to upload more than one image I get the next error:</p>\n<p>Traceback (most recent call last):<br>\nFile \u201cC:\\Users\\Robcib\\Desktop\\Miguel\\YOLO_Miguel\\yolov5-master\\utils\\loggers\\wandb\\log_dataset.py\u201d, line 27, in <br>\ncreate_dataset_artifact(opt)<br>\nFile \u201cC:\\Users\\Robcib\\Desktop\\Miguel\\YOLO_Miguel\\yolov5-master\\utils\\loggers\\wandb\\log_dataset.py\u201d, line 11, in create_dataset_artifact<br>\nlogger = WandbLogger(opt, None, job_type=\u2018Dataset Creation\u2019)  # TODO: return value unused<br>\nFile \u201cC:\\Users\\Robcib\\Desktop\\Miguel\\YOLO_Miguel\\yolov5-master\\utils\\loggers\\wandb\\wandb_utils.py\u201d, line 190, in <em>init</em><br>\nself.data_dict = self.check_and_upload_dataset(opt)<br>\nFile \u201cC:\\Users\\Robcib\\Desktop\\Miguel\\YOLO_Miguel\\yolov5-master\\utils\\loggers\\wandb\\wandb_utils.py\u201d, line 203, in check_and_upload_dataset<br>\nconfig_path = self.log_dataset_artifact(opt.data,<br>\nFile \u201cC:\\Users\\Robcib\\Desktop\\Miguel\\YOLO_Miguel\\yolov5-master\\utils\\loggers\\wandb\\wandb_utils.py\u201d, line 345, in log_dataset_artifact<br>\nself.train_artifact = self.create_dataset_table(LoadImagesAndLabels(<br>\nFile \u201cC:\\Users\\Robcib\\Desktop\\Miguel\\YOLO_Miguel\\yolov5-master\\utils\\loggers\\wandb\\wandb_utils.py\u201d, line 428, in create_dataset_table<br>\nartifact.add(table, name)<br>\nFile \u201cC:\\Users\\Robcib\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sdk\\wandb_artifacts.py\u201d, line 500, in add<br>\nval = obj.to_json(self)<br>\nFile \u201cC:\\Users\\Robcib\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\data_types.py\u201d, line 610, in to_json<br>\nmapped_row.append(_json_helper(v, artifact))<br>\nFile \u201cC:\\Users\\Robcib\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\data_types.py\u201d, line 105, in _json_helper<br>\nreturn val.to_json(artifact)<br>\nFile \u201cC:\\Users\\Robcib\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sdk\\data_types.py\u201d, line 2303, in to_json<br>\nclasses_entry = artifact.add(self._classes, class_name)<br>\nFile \u201cC:\\Users\\Robcib\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sdk\\wandb_artifacts.py\u201d, line 520, in add<br>\nwith self.new_file(name) as f:<br>\nFile \u201cC:\\Users\\Robcib\\AppData\\Local\\Programs\\Python\\Python39\\lib\\contextlib.py\u201d, line 117, in <em>enter</em><br>\nreturn next(self.gen)<br>\nFile \u201cC:\\Users\\Robcib\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\wandb\\sdk\\wandb_artifacts.py\u201d, line 359, in new_file<br>\nraise ValueError(<br>\nValueError: File with name \u201cmedia\\classes\\56699adf4321fa19e6264a528fad82c4_cls.classes.json\u201d already exists at \u201cC:\\Users\\Robcib\\AppData\\Local\\Temp\\tmph3c76g8x\\media\\classes\\56699adf4321fa19e6264a528fad82c4_cls.classes.json\u201d</p>\n<p>command line: C:\\Users\\Robcib\\Desktop\\Miguel\\YOLO_Miguel\\yolov5-master&gt;python utils/loggers/wandb/log_dataset.py --project custom_yolov5 --data data/custom_dataset.yaml</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-10T21:43:40.384Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/miguel_gd\">@miguel_gd</a>,</p>\n<p>This seems to be an issue specific to the YOLOv5 integration with Windows. <a href=\"https://github.com/ultralytics/yolov5/issues/6109\" rel=\"noopener nofollow ugc\">Here</a> is a discussion about this issue, along with a solution which has seemed to work for multiple users.</p>\n<p>Please let us know if this resolves your issue.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-14T20:39:12.672Z",
				"Answer_body": "<p>Hi,</p>\n<p>Just following up here. Did the above solution work for you? Please let us know if we can be of further assistance.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-14T21:21:10.000Z",
				"Answer_body": "<p>Hi,</p>\n<p>Yes it worked. Thank you for your answer and help.</p>\n<p>Kind regards,</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-15T21:21:36.555Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "YOLOv5 sweeps?",
		"Question_link": "https://community.wandb.ai/t/yolov5-sweeps/1735",
		"Question_created_time": "2022-01-09T02:44:07.744Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 252,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Does anyone know if it\u2019s possible to use YOLOv5 train.py with sweeps?</p>\n<p>Thanks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-11T11:20:00.087Z",
				"Answer_body": "<p>Hey David, checking on this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-11T13:03:22.331Z",
				"Answer_body": "<p>Thanks Arman!</p>\n<p>I\u2019ve been using YOLOv5 evolve, which is similar to HP sweeps.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-12T11:48:11.179Z",
				"Answer_body": "<p>Hey David, you can find instructions on how to use Sweeps with YOLOv5 <a href=\"https://github.com/ultralytics/yolov5/issues/607\" rel=\"noopener nofollow ugc\">here</a>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-12T13:56:35.985Z",
				"Answer_body": "<p>Thank you again Arman!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-13T13:57:34.280Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How can I make a Confusion Matrix that does not overlap?",
		"Question_link": "https://community.wandb.ai/t/how-can-i-make-a-confusion-matrix-that-does-not-overlap/1634",
		"Question_created_time": "2021-12-28T07:49:53.568Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 270,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\nI just made a confusion matrix in validation step, but it overlapped like this during training.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/ea61626463c01a256837c5b06f5f95a92b9ad9d2.png\" data-download-href=\"/uploads/short-url/xrqn87xjrMZ9EDb39gqB8tmMu6C.png?dl=1\" title=\"dd\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ea61626463c01a256837c5b06f5f95a92b9ad9d2_2_690x70.png\" alt=\"dd\" data-base62-sha1=\"xrqn87xjrMZ9EDb39gqB8tmMu6C\" width=\"690\" height=\"70\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ea61626463c01a256837c5b06f5f95a92b9ad9d2_2_690x70.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ea61626463c01a256837c5b06f5f95a92b9ad9d2_2_1035x105.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ea61626463c01a256837c5b06f5f95a92b9ad9d2_2_1380x140.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ea61626463c01a256837c5b06f5f95a92b9ad9d2_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">dd</span><span class=\"informations\">2046\u00d7208 15.2 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>I want to make a confusion matrix or table that can be seen by epoch.</p>\n<pre><code class=\"lang-auto\">            wandb.log({\n                \"Confusion Matrix\": wandb.sklearn.plot_confusion_matrix(\n                                                                y_true=targets,\n                                                                y_pred=outputs,\n                                                                labels=['Normal','COVID','Others']\n                                                                )\n            })\n</code></pre>\n<p>Is there any way to solve this?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-04T22:37:37.032Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ozoooooh\">@ozoooooh</a> ,</p>\n<p>Could you share a link to the project where you see this behavior?</p>\n<p>Thanks,<br>\nRamit<br>\nWeights and Biases Support</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-10T23:00:05.773Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ozoooooh\">@ozoooooh</a>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-11T23:00:17.341Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Table metrics are not logged when killing a wandb run early",
		"Question_link": "https://community.wandb.ai/t/table-metrics-are-not-logged-when-killing-a-wandb-run-early/1694",
		"Question_created_time": "2022-01-05T16:55:39.311Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 165,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi I have the following problem. I log several statistics, e.g. with</p>\n<pre><code>run.log({\"train-loss\": loss.item()}\nrun.summary[\"best_accuracy\"] =  best_acc1\n</code></pre>\n<p>and then I kill my wandb run early in the terminal. Unfortunately the metric \u201ctrain-loss\u201d and \u201cbest_accuracy\u201d is not logged in the table in wandb. The plots are available. It seems that summary metrics aren\u2019t.  Does anyone know how I can fix this? For early prototyping, I kill jobs quite often.</p>\n<p>Thanks and cheers!</p>\n<p>Stefan</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-05T19:22:26.773Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/skolek\">@skolek</a>,</p>\n<p>How are you killing your jobs? If you are using something like a KeyboardInterrupt, I would recommend using something like a <code>try/except</code> block to enclose your code, and have a call to <code>wandb.finish()</code> in your except block.</p>\n<p>Calling <code>wandb.finish()</code> starts a cleanup process for the run and makes sure all the data from your run gets synced.</p>\n<p>Please let me know if this solves your issue.</p>\n<p>Thanks,<br>\nRamit<br>\nWeights and Biases Support</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-10T22:07:06.321Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/skolek\">@skolek</a>,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-11T22:07:07.391Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb.plot.confusion_matrix() just show a Table!",
		"Question_link": "https://community.wandb.ai/t/wandb-plot-confusion-matrix-just-show-a-table/1744",
		"Question_created_time": "2022-01-10T02:30:29.922Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 676,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hello,</p>\n<p>I used this code to create a confusion matrix:</p>\n<pre><code class=\"lang-auto\"># confusion matrix\n        wandb.log({\"confusion-matrix-test\": wandb.plot.confusion_matrix(\n            probs=None,\n            y_true=all_gt, preds=all_pre,\n            class_names=classes_names)})\n</code></pre>\n<p>However, Wanda\u2019s website only shows a table instead of the confusion matrix. This is a screenshot from the issue:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/3e79ae0d1bed34de85b7a5a0f60df3ac167ed046.png\" data-download-href=\"/uploads/short-url/8UGiFwpsOZ6Pivp7qmFXgL1OuvI.png?dl=1\" title=\"Screenshot from 2022-01-09 20-58-35\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3e79ae0d1bed34de85b7a5a0f60df3ac167ed046_2_690x249.png\" alt=\"Screenshot from 2022-01-09 20-58-35\" data-base62-sha1=\"8UGiFwpsOZ6Pivp7qmFXgL1OuvI\" width=\"690\" height=\"249\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3e79ae0d1bed34de85b7a5a0f60df3ac167ed046_2_690x249.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3e79ae0d1bed34de85b7a5a0f60df3ac167ed046_2_1035x373.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3e79ae0d1bed34de85b7a5a0f60df3ac167ed046_2_1380x498.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3e79ae0d1bed34de85b7a5a0f60df3ac167ed046_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot from 2022-01-09 20-58-35</span><span class=\"informations\">1741\u00d7629 29.6 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-10T10:12:33.312Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"fdaliran\" data-post=\"1\" data-topic=\"1744\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/f/73ab20/40.png\" class=\"avatar\"> fdaliran:</div>\n<blockquote>\n<pre><code class=\"lang-auto\">        wandb.log({\"confusion-matrix-test\": wandb.plot.confusion_matrix(\n            probs=None,\n            y_true=all_gt, preds=all_pre,\n            class_names=classes_names)})\n</code></pre>\n</blockquote>\n</aside>\n<p>If you click the section called \u201cCustom Charts\u201d above the Table, it\u2019ll show the line plot that you\u2019ve logged.</p>\n<p>Logging the Table also is expected behaviour because this will allow users to interactively explore the logged data in a W&amp;B Table after logging it.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-03-11T10:12:41.284Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Error with wandb on win10",
		"Question_link": "https://community.wandb.ai/t/error-with-wandb-on-win10/1656",
		"Question_created_time": "2022-01-01T16:42:48.878Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 234,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I got this on win10,it\u2019s stucked<br>\nthe enviornment is</p>\n<ul>\n<li>python3.7.10</li>\n<li>wandb 0.12.9</li>\n</ul>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b2ce90f5e63f7db9be89aa163ee55f0ab468a430.png\" data-download-href=\"/uploads/short-url/pvNysR6Ps6qxY0fl0Y5gjzfovBK.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b2ce90f5e63f7db9be89aa163ee55f0ab468a430.png\" alt=\"image\" data-base62-sha1=\"pvNysR6Ps6qxY0fl0Y5gjzfovBK\" width=\"547\" height=\"500\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b2ce90f5e63f7db9be89aa163ee55f0ab468a430_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">686\u00d7626 26.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-04T04:34:18.999Z",
				"Answer_body": "<p>Hey there, have you tried setting the LOCAL_RESTORE variable?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-06T07:05:27.148Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-07T01:54:32.752Z",
				"Answer_body": "<p>is this the right way to set the variable<br>\nseems also stucked<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/35267e52d2fb1f88e49e10136936a1b8ce87161e.png\" data-download-href=\"/uploads/short-url/7AbMdL2TPUcAqwnkiktDhrmbmdU.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/35267e52d2fb1f88e49e10136936a1b8ce87161e_2_690x420.png\" alt=\"image\" data-base62-sha1=\"7AbMdL2TPUcAqwnkiktDhrmbmdU\" width=\"690\" height=\"420\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/35267e52d2fb1f88e49e10136936a1b8ce87161e_2_690x420.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/35267e52d2fb1f88e49e10136936a1b8ce87161e_2_1035x630.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/35267e52d2fb1f88e49e10136936a1b8ce87161e.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/35267e52d2fb1f88e49e10136936a1b8ce87161e_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1303\u00d7794 53.5 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-09T01:03:19.763Z",
				"Answer_body": "<p>I\u2019ve deleted wandb in docker and pip ,then I reinstalled them.<br>\nAnd I got the right page after waiting about 5 or 6 minutes.<br>\nBut I don\u2019t know whtether the reason is the versions are different or something.<br>\nThis time I didn\u2019t set the LOCAL_RESOTRE var, I don\u2019t know whether the time will decrease.<br>\nAnd I notice that once I get the right page, the next time I can get in immediately.<br>\nThanks a lot.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-03-10T01:04:06.382Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Connecting to existing sweep from Python",
		"Question_link": "https://community.wandb.ai/t/connecting-to-existing-sweep-from-python/1721",
		"Question_created_time": "2022-01-07T14:53:55.002Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 247,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I have a few questions regarding the hyperparameter sweeps from Python.<br>\nI am wanting to essentially start a few tmux sessions on my server, and connect them all to the same sweep agent, but no keyword in the sweep_config (that i have found) allow me to connect to a specific sweep ID, and rather just a sweep name that doesnt connect to the same sweep, but just makes multiple sweeps of the same name.  If this possible or strongly advised against due to computational usage or similar?</p>\n<p>Furthermore, sweeps take up a great deal of storage requirements due to saving all the models, is it possible to store the model file from the best model only, while keeping the statistics from all the models for plots and interpretation? This would allow me to keep the great information gathered from sweeps, while not taking up 100+ GB from a single sweep.</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-07T19:04:08.949Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tjobbertjob\">@tjobbertjob</a> , for your first question. Try creating a new agent and passing your existing (running) sweep id to the new agent.</p>\n<p>As for your questions regarding the model saving, you would need to either write some custom saving behaviour to check if model is the best model in the sweep thus far (by using the public api) or you could write some script that asynchronously and programmatically deletes all but the top-k models every every so often.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-07T20:22:52.891Z",
				"Answer_body": "<p>When and where should i add the sweep id? in the sweep_id config dictionary, or in the wandb.agent? and what is the key for the id?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-07T22:09:09.991Z",
				"Answer_body": "<p>I found the issue, i was trying to create a new wandb.sweep(config, project, entity) and pass the ID into the config dictionary, but instead i just needed to take the ID directly, and just do sweep_id = sweep_id_string which worked.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-03-08T22:09:42.782Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Help Adding To Tacotron Model",
		"Question_link": "https://community.wandb.ai/t/help-adding-to-tacotron-model/1660",
		"Question_created_time": "2022-01-02T00:04:47.756Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 257,
		"Question_has_accepted_answer": true,
		"Question_body": "<p><strong>Hello, can someone please help Me get this set up?</strong><br>\nI am running this in <strong>Google Colab</strong></p>\n<p>I am unable to get any data from my tacotron model.  I was able to login/create multiple wandb runs and it tracks usage(log is connected, Utilization updates) but no data has been entered and the way it trains it runs one line forever so i dont even know how to begin.</p>\n<p>This is the Script that currently runs the training</p>\n<pre><code class=\"lang-auto\">print('FP16 Run:', hparams.fp16_run)\nprint('Dynamic Loss Scaling:', hparams.dynamic_loss_scaling)\nprint('Distributed Run:', hparams.distributed_run)\nprint('cuDNN Enabled:', hparams.cudnn_enabled)\nprint('cuDNN Benchmark:', hparams.cudnn_benchmark)\n\nfrom IPython.display import Javascript\ndisplay(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 200})'''))\n#for i in range(200):\n#  print(i)\n\ntrain(output_directory, log_directory, checkpoint_path,\n      warm_start, n_gpus, rank, group_name, hparams, log_directory2)\n\n</code></pre>\n<p><strong>I tried doing this but it didnt work either. here is my code to start the training with wandb</strong></p>\n<p>Install and login</p>\n<pre><code class=\"lang-auto\">#@markdown Login and start a new run\nprint('Installing wandb')\n!pip -q install wandb\nimport wandb\nprint('Login To wanb!!!\\n')\n!wandb login\n</code></pre>\n<p>Capture a dictionary of hyperparameters</p>\n<pre><code class=\"lang-auto\">#@markdown Capture a dictionary of hyperparameters\nwandb.config.p_attention_dropout=hparams.p_attention_dropout\nwandb.config.p_decoder_dropout=hparams.p_decoder_dropout\nwandb.config.decay_start=hparams.decay_start\nwandb.config.A_=hparams.A_\nwandb.config.B_=hparams.B_\nwandb.config.C_=hparams.C_\nwandb.config.min_learning_rate=hparams.min_learning_rate\nwandb.config.batch_size=hparams.batch_size\nwandb.config.epochs=hparams.epochs\nwandb.config.generate_mels=generate_mels\nwandb.config.show_alignments=hparams.show_alignments\nwandb.config.alignment_graph_height=alignment_graph_height\nwandb.config.alignment_graph_width=alignment_graph_width\nwandb.config.load_mel_from_disk=hparams.load_mel_from_disk\nwandb.config.ignore_layers=hparams.ignore_layers\nwandb.config.checkpoint_path=checkpoint_path\n</code></pre>\n<p>Start wanb and get runID<br>\n<code>wandb.init(project=\"tacotron\", entity=\"gmirsky2\")</code></p>\n<p><strong>start wandb run then Train</strong></p>\n<pre><code class=\"lang-auto\">#Run\napi = wandb.Api()\nrun = api.run(\"gmirsky2/tacotron/\" + wandb.run.id)\n\n#train\ntrain(output_directory, log_directory, checkpoint_path,\n      warm_start, n_gpus, rank, group_name, hparams, log_directory2)\n\n# save the metrics for the run to a csv file\nmetrics_dataframe = run.history()\nmetrics_dataframe.to_csv(\"metrics.csv\")\n</code></pre>\n<p>When The Training Runs it Just goes to the train line and then never finishes.<br>\nI am looking for help with how to incorporate wandb with the tacotron train script\u2026</p>\n<pre><code class=\"lang-auto\">train(output_directory, log_directory, checkpoint_path,\n      warm_start, n_gpus, rank, group_name, hparams, log_directory2)\n</code></pre>\n<p>I thought that was what the hyperparameters were for but i guess im wrong.</p>\n<p>Any help would be welcome. Thanks a bunch!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-07T19:43:34.231Z",
				"Answer_body": "<p>I was able to get it working after blood\u2026 sweat\u2026 and time.<br>\nWell really it was just time.</p>\n<p>I ended up having to install then import it before Training and stop it after training\u2026 who would have thought. lol</p>\n<pre><code class=\"lang-auto\">#@markdown Install W&amp;B\n%%capture\n!pip install wandb --upgrade\n</code></pre>\n<p>wandb is super helpful and have a tf module: <em><strong>config=tf.flags.FLAGS</strong></em></p>\n<pre><code class=\"lang-auto\">import wandb\nimport tensorflow as tf\nwandb.init(config=tf.flags.FLAGS, sync_tensorboard=True, project=model_filename)\n</code></pre>\n<p>Then after training is done Close the wandb connection<br>\n<code>wandb_run.finish(exit_code=0)</code></p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-03-08T19:43:36.284Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "String bug in the parallel coordinates chart",
		"Question_link": "https://community.wandb.ai/t/string-bug-in-the-parallel-coordinates-chart/1674",
		"Question_created_time": "2022-01-03T17:28:10.493Z",
		"Question_answer_count": 5,
		"Question_score_count": 1,
		"Question_view_count": 181,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hey Guys, i just started using wandb and so far everything is working pretty well, however I noticed that there seems to be a problem with strings as parameters in parallel coordinates chart</p>\n<p>Attached is a screenshot to illustrate the problem</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/f0054aff74ba40b8cb33e86b18b172e51cd527c7.jpeg\" data-download-href=\"/uploads/short-url/yfjVQxyNGXrfluwDks1707BnsO3.jpeg?dl=1\" title=\"wandb_string_problem\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f0054aff74ba40b8cb33e86b18b172e51cd527c7_2_690x374.jpeg\" alt=\"wandb_string_problem\" data-base62-sha1=\"yfjVQxyNGXrfluwDks1707BnsO3\" width=\"690\" height=\"374\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f0054aff74ba40b8cb33e86b18b172e51cd527c7_2_690x374.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f0054aff74ba40b8cb33e86b18b172e51cd527c7_2_1035x561.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f0054aff74ba40b8cb33e86b18b172e51cd527c7_2_1380x748.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f0054aff74ba40b8cb33e86b18b172e51cd527c7_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">wandb_string_problem</span><span class=\"informations\">1502\u00d7816 332 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>So now I wonder if I made a mistake or if I have to wait for a fix from you.</p>\n<p>Kind regards<br>\nChris</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-03T17:40:17.424Z",
				"Answer_body": "<p>By the way, thats how i added it to the sweep_config:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b3cb65db1dd4e1ab575177b7c8148534ba640778.png\" data-download-href=\"/uploads/short-url/pExfclqAlO39KUQsj36ESOI3vcI.png?dl=1\" title=\"sweep_conf\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b3cb65db1dd4e1ab575177b7c8148534ba640778.png\" alt=\"sweep_conf\" data-base62-sha1=\"pExfclqAlO39KUQsj36ESOI3vcI\" width=\"690\" height=\"424\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3cb65db1dd4e1ab575177b7c8148534ba640778_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">sweep_conf</span><span class=\"informations\">768\u00d7473 9.17 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Sorry for the double post but i was not allowed to upload another picture to show you my config.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-03T20:20:06.894Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/chrismartin\">@chrismartin</a>,</p>\n<p>This is a known bug, our engineering team should have a fix out for this soon.</p>\n<p>Thanks,<br>\nRamit<br>\nWeights and Biases Support</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-04T09:13:23.223Z",
				"Answer_body": "<p>Thank you very much for your fast reply.  <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-07T00:27:08.650Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/chrismartin\">@chrismartin</a>,</p>\n<p>This issue has been fixed. Parallel Coordinate charts  with strings should behave as expected now.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-03-08T00:27:25.275Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Invalid filename characters exception on uploading image",
		"Question_link": "https://community.wandb.ai/t/invalid-filename-characters-exception-on-uploading-image/1711",
		"Question_created_time": "2022-01-06T15:24:48.588Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 243,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi. I am using windows 10 &amp; venv &amp; python<br>\nthis is my code to upload image to wandb</p>\n<pre><code class=\"lang-auto\">wandb_log[\"Image/train_image\"] = wandb.Image('tmp.jpg')\nwandb.log(wandb_log, step)\n</code></pre>\n<p>the full directory of image is \u201cC:\\Users\\\uc774\uc900\ud601\\Documents\\Github\\terenz\\tmp.jpg\u201d<br>\nHowever it creates this error</p>\n<pre><code class=\"lang-auto\">Media Image/train_image is invalid. Please remove invalid filename characters\n</code></pre>\n<p>reinstalling wandb did not help to solve this problem.<br>\nwhat should I do?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-07T17:27:49.191Z",
				"Answer_body": "<p>Hi Junhyuk,</p>\n<p>This is a bug we have in our system that we are aware of. I\u2019m going to boost the priority on the ticket we have for this and update you once it has been fixed. In the meantime, this bug is not present in 0.12.4, if this is crucial for your project.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-23T22:23:27.025Z",
				"Answer_body": "<p>Hi Junhyuk,</p>\n<p>This ticket has been completed, please let us know if you still run into this issue!</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-07T15:25:07.417Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Model stopped training once I introduced << report_to = 'wandb' >> in TrainingArguments",
		"Question_link": "https://community.wandb.ai/t/model-stopped-training-once-i-introduced-report-to-wandb-in-trainingarguments/1712",
		"Question_created_time": "2022-01-06T15:31:50.793Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 409,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am downloading the model <a href=\"https://huggingface.co/microsoft/Multilingual-MiniLM-L12-H384/tree/main\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">microsoft/Multilingual-MiniLM-L12-H384 at main</a> microsoft/Multilingual-MiniLM-L12-H384 and then using it.</p>\n<p>Transformer Version: \u20184.11.3\u2019</p>\n<p>I have written the below code:</p>\n<pre><code class=\"lang-auto\">import wandb\nwandb.login()\n%env WANDB_LOG_MODEL=true\n\nmodel = tr.BertForSequenceClassification.from_pretrained(\"/home/pc/minilm_model\",num_labels=2)\nmodel.to(device)\n\nprint(\"hello\")\n\ntraining_args = tr.TrainingArguments(\nreport_to = 'wandb',\noutput_dir='/home/pc/proj/results2', # output directory\nnum_train_epochs=10, # total number of training epochs\nper_device_train_batch_size=16, # batch size per device during training\nper_device_eval_batch_size=32, # batch size for evaluation\nlearning_rate=2e-5,\nwarmup_steps=1000, # number of warmup steps for learning rate scheduler\nweight_decay=0.01, # strength of weight decay\nlogging_dir='./logs', # directory for storing logs\nlogging_steps=1000,\nevaluation_strategy=\"epoch\",\nsave_strategy=\"no\"\n)\n\nprint(\"hello\")\n\ntrainer = tr.Trainer(\nmodel=model, # the instantiated \ud83e\udd17 Transformers model to be trained\nargs=training_args, # training arguments, defined above\ntrain_dataset=train_data, # training dataset\neval_dataset=val_data, # evaluation dataset\ncompute_metrics=compute_metrics\n)\n\n</code></pre>\n<p>After Executing this:</p>\n<p>The model stuck at this point:</p>\n<p>***** Running training *****</p>\n<pre><code class=\"lang-auto\">Num examples = 12981\n Num Epochs = 20\n Instantaneous batch size per device = 16\n Total train batch size (w. parallel, distributed &amp; accumulation) = 32\n Gradient Accumulation steps = 1\n Total optimization steps = 8120\nAutomatic Weights &amp; Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\n</code></pre>\n<p><strong>What could be the possible solution?</strong></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-07T14:49:56.911Z",
				"Answer_body": "<p>Hi Pratik, thank you for writing in! I see for your compute_metrics argument in your trainer that you are calling compute_metrics, but there\u2019s no function to tell it what to compute. Is this code that you have removed or is this actually missing?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-10T15:05:50.391Z",
				"Answer_body": "<p>Hi Pratik, I\u2019m just checking up to see if you still have this issue?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-13T19:56:32.254Z",
				"Answer_body": "<p>Hi Pratik, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-07T15:32:09.336Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sweep in DDP mode",
		"Question_link": "https://community.wandb.ai/t/sweep-in-ddp-mode/1664",
		"Question_created_time": "2022-01-02T18:33:49.166Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 568,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I wonder how Sweep works in multi-GPU mode? I want to initialize the parameters that need to be optimized in just one process, and then use Sweep for hyperparametric optimization. However, if I only initialize parameters in one process, other processes will report an error because they did not query parameters when loading the model. I didn\u2019t find the answer to using Sweep in multi-GPU mode, thanks for answering!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-05T05:23:29.121Z",
				"Answer_body": "<p>Hey there, to use sweeps in multi-gpu setup you need to do the following:</p>\n<ul>\n<li>\n<p>Specify the hyperparameters you\u2019re sweeping over in a YAML file, as detailed further in the <a href=\"https://docs.wandb.com/sweeps\" rel=\"noopener nofollow ugc\">sweep docs</a>.</p>\n</li>\n<li>\n<p>Get the sweep id by running the wandb sweep command and passing the yaml file as an argument</p>\n</li>\n<li>\n<p>Run the wandb agent with the sweep id you just got. You will also need the to specify the GPU like this:</p>\n<pre><code> CUDA_VISIBLE_DEVICES=0 wandb agent sweep_id\n CUDA_VISIBLE_DEVICES=1 wandb agent sweep_id</code></pre>\n</li>\n</ul>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-05T06:27:45.653Z",
				"Answer_body": "<p>Thank you ! I will have a try.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-05T09:48:08.619Z",
				"Answer_body": "<p>Feel free to message us if there are any issues.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-06T09:48:27.267Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Saving Model Class Source, including forward() method",
		"Question_link": "https://community.wandb.ai/t/saving-model-class-source-including-forward-method/1592",
		"Question_created_time": "2021-12-22T11:14:13.390Z",
		"Question_answer_count": 5,
		"Question_score_count": 6,
		"Question_view_count": 228,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey folks,</p>\n<p>I couldn\u2019t find the best practice when it comes to saving the model definition to <code>wandb</code>, including the forward call.</p>\n<p>Most of my research is done by changing the forward function, so it is an important piece of data I want to track.</p>\n<p>I tried using <code>inspect.getsource(class)</code> however, there seems to be an issue with using it in IPython.</p>\n<p>I am aware that I can save the whole notebook / file, but this means a lot of auxiliary information is also saved which makes it hard to compare just the models.</p>\n<p>Please let me know how you would approach this issue.</p>\n<p>thank you very much and enjoy life,<br>\nbatu</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-23T15:33:32.774Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/batu\">@batu</a>!</p>\n<p>I would recommend having your model definition (with the <code>forward</code> method) in an external <code>.py</code> file like <code>model.py</code>. Once saved in such a file you can use <code>wandb</code>'s <code>log_code</code> function <a href=\"https://docs.wandb.ai/ref/python/run#examples-1\">shown here</a> to log your model definition. This allows you to grab the model code as you would normally would with an artifact. As such you would be able to <code>download()</code> your logged model definition and import it like any other <code>.py</code> file.</p>\n<p>You also get the nice side effect of versioning of your model definitions as it changes with little change for your downstream scripts!</p>\n<p>Enjoying life and wishing you the same,<br>\nAnish</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-24T08:21:53.253Z",
				"Answer_body": "<p>I think being able to commit the source code of a class directly to <code>wandb</code>  would be a useful future but until then this is a good way to go!</p>\n<p>Thank you very much</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-04T20:30:45.729Z",
				"Answer_body": "<p>you may like to check this out as well: <a href=\"https://pytorch.org/docs/stable/package.html\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">torch.package \u2014 PyTorch 1.10.1 documentation</a></p>\n<p>pytorch has a built-in solution for this for newer versions of pytorch (added in 1.9 I think), and these model packages can be logged to wandb as an artifact.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:01:45.301Z",
				"Answer_body": "<p>you may like to check this out as well: torch.package \u2014 PyTorch 1.10.1 documentation</p>\n<p>pytorch has a built-in solution for this for newer versions of pytorch (added in 1.9 I think), and these model packages can be logged to wandb as an artifact.</p>\n<p>[Discourse post]</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:07.097Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Api key + entity verification",
		"Question_link": "https://community.wandb.ai/t/api-key-entity-verification/1687",
		"Question_created_time": "2022-01-04T19:30:10.203Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 317,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello Everyone,</p>\n<p>I\u2019ve been using this package for the past year to keep track of all my phd experiments (it is awesome!!!). I am in the process of developing an application (using streamlit) that makes use of my neural network framework more accessible to users.  For that reason, I want to provide users with the ability to use their wandb credentials to start logging results to their accounts. As far as I understand you need a valid API key and entity. Is there a way to verify that this API_key+entity combination exists?? Passing a random 40 character string in the key parameter of wandb.login() returns true, so I suspect that it only checks the length of the key and not if it actually exists. I guess I can try logging to a dummy project and then catch an exception (this means that the API key or the entity name is wrong) but I\u2019m looking for something more elegant.</p>\n<p>Thanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-04-20T18:02:05.401Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to provide fold information in WandbCallback?",
		"Question_link": "https://community.wandb.ai/t/how-to-provide-fold-information-in-wandbcallback/1599",
		"Question_created_time": "2021-12-23T06:50:46.866Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 231,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>How to provide fold information in multi-fold training?</p>\n<p>I am trying to do something like this:</p>\n<pre><code class=\"lang-auto\">for fold in range(5):\nmodel.fit()\n</code></pre>\n<p>So it actually creates a single graph where steps are continued from the last executed step of previous epoch.<br>\nFor ref see below:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/5384d8c3e8faa471e61a07d930f7f839a42650b5.png\" data-download-href=\"/uploads/short-url/bUQfG2SdqWgNhB5QoDwBGjbyy3P.png?dl=1\" title=\"Screenshot 2021-12-23 at 12.19.28 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/5384d8c3e8faa471e61a07d930f7f839a42650b5_2_690x382.png\" alt=\"Screenshot 2021-12-23 at 12.19.28 PM\" data-base62-sha1=\"bUQfG2SdqWgNhB5QoDwBGjbyy3P\" width=\"690\" height=\"382\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/5384d8c3e8faa471e61a07d930f7f839a42650b5_2_690x382.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/5384d8c3e8faa471e61a07d930f7f839a42650b5_2_1035x573.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/5384d8c3e8faa471e61a07d930f7f839a42650b5.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/5384d8c3e8faa471e61a07d930f7f839a42650b5_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2021-12-23 at 12.19.28 PM</span><span class=\"informations\">1098\u00d7608 28.2 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-26T17:38:34.237Z",
				"Answer_body": "<p>I am thinking about this as well. I am about to give each fold a run name in wandb but not sure it is a good practice.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-27T18:09:52.185Z",
				"Answer_body": "<p>Not sure if I fully understand the question, you\u2019d like to train on different folds, but continue training the model, as opposed to training a fresh model on each fold?</p>\n<p>If you\u2019re resuming the run you could update a <code>fold</code> config variable at the beginning of each for loop, so you would know the latest fold the model is training on?</p>\n<pre><code class=\"lang-auto\">for fold in range(5):\n    wandb.config.update({'fold':fold})\n    model.fit()\n\n</code></pre>\n<p>What other fold information were you hoping to log?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-04T13:05:22.890Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"harveenchadha\" data-post=\"1\" data-topic=\"1599\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https://sea2.discourse-cdn.com/business7/user_avatar/community.wandb.ai/harveenchadha/40/575_2.png\" class=\"avatar\"> harveenchadha:</div>\n<blockquote>\n<p>How to provide fold information in multi-fold</p>\n</blockquote>\n</aside>\n<p>I\u2019d love to help more here if you could clarify what you\u2019re hoping would happen.</p>\n<p>You can customise your x-axis using x-axis expressions if that\u2019s all you want to do:</p>\n<p>Here you can see I\u2019m redefining the x-axis to be <code>step - (fold*num_steps)</code> where <code>config:num_steps</code> is the number of steps in each fold (100 in this case), fold is the current fold, and <code>_step</code> is the internal step logged by wandb.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/ed686bc99de10d283012548a0979562bad514c2e.png\" data-download-href=\"/uploads/short-url/xScSEGZ1o1ynq5HNnGOUgCYtis6.png?dl=1\" title=\"image\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ed686bc99de10d283012548a0979562bad514c2e_2_690x242.png\" alt=\"image\" data-base62-sha1=\"xScSEGZ1o1ynq5HNnGOUgCYtis6\" width=\"690\" height=\"242\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ed686bc99de10d283012548a0979562bad514c2e_2_690x242.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ed686bc99de10d283012548a0979562bad514c2e_2_1035x363.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ed686bc99de10d283012548a0979562bad514c2e_2_1380x484.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ed686bc99de10d283012548a0979562bad514c2e_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1540\u00d7541 75.6 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:07.232Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to create a panel that reports number of successful runs per group",
		"Question_link": "https://community.wandb.ai/t/how-to-create-a-panel-that-reports-number-of-successful-runs-per-group/1683",
		"Question_created_time": "2022-01-04T10:56:01.794Z",
		"Question_answer_count": 3,
		"Question_score_count": 3,
		"Question_view_count": 233,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I\u2019m currently performing a hyperparameter search (I\u2019m not using wandb\u2019s sweeep feature for that) on a GPU cluster.  I group the runs into different categories, let\u2019s say that\u2019s simply \u201cGroup A\u201d, \u201cGroup B\u201d, etc.</p>\n<p>Now, since jobs can crash for various reasons, I would love to have a panel that reports the number of successful runs <em>for each group</em>, so I know how each group is doing (\u201cGroup A has 200 successful runs, while Group B only has 50, so I need to start some more jobs for Group B\u201d). I know I can get there by using the general filter and group feature in my project\u2019s run-table, but this is rather tedious and it would be more convenient for me to have it as a panel for quick access (e.g., inside a report).</p>\n<p>I\u2019ve fiddled around with the \u201cscalar chart\u201d and the \u201cweave\u201d panel, but without success \u2013 any ideas?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-04T12:30:12.679Z",
				"Answer_body": "<p>Good question. By the sounds of it, W&amp;B Reports would solve this for you.<br>\nYou could create a W&amp;B Report and add your panel, do the grouping and filtering there, and then you could see these each time you run something new. It\u2019ll create sections for each of your groups, and subsections for each state.</p>\n<p>Here I\u2019ve grouped by <code>learning_rate</code> and a secondary group by <code>State</code>, you could use your group name in place of <code>learning_rate</code>.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/8ca8b5ef7db8b9ed281fb989ff905f1f9a1b3345.png\" data-download-href=\"/uploads/short-url/k4kj1uuH2UXMolLEubbw7XQOq7r.png?dl=1\" title=\"image\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/8ca8b5ef7db8b9ed281fb989ff905f1f9a1b3345_2_690x210.png\" alt=\"image\" data-base62-sha1=\"k4kj1uuH2UXMolLEubbw7XQOq7r\" width=\"690\" height=\"210\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/8ca8b5ef7db8b9ed281fb989ff905f1f9a1b3345_2_690x210.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/8ca8b5ef7db8b9ed281fb989ff905f1f9a1b3345_2_1035x315.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/8ca8b5ef7db8b9ed281fb989ff905f1f9a1b3345.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/8ca8b5ef7db8b9ed281fb989ff905f1f9a1b3345_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1077\u00d7329 48.3 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Here\u2019s a link to that report: <a href=\"https://wandb.ai/the-geoffrey-hinton-fan-club/pytorch-demo/reports/Example-Report--VmlldzoxMzQ5MDY5\" class=\"inline-onebox\">Weights &amp; Biases</a></p>\n<p>Let me know if that helps <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-04T13:03:10.180Z",
				"Answer_body": "<p>ah yes, this works, thanks!</p>\n<p>I was hoping for a way to compile these sorts of information inside dedicated panels (like a \u201cscalar chart\u201d), since this would generally allow for more concise reports \u2013 but this would be a \u201cnice to have\u201d, rather than a \u201cmust have\u201d <img src=\"https://emoji.discourse-cdn.com/twitter/grinning.png?v=10\" title=\":grinning:\" class=\"emoji\" alt=\":grinning:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:07.165Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "The parallel coordinate panel seems to be inaccurate",
		"Question_link": "https://community.wandb.ai/t/the-parallel-coordinate-panel-seems-to-be-inaccurate/1563",
		"Question_created_time": "2021-12-18T21:11:09.786Z",
		"Question_answer_count": 8,
		"Question_score_count": 0,
		"Question_view_count": 229,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I really love the parallel coordinate panel but something about it seemed off.  It turns out it\u2019s not consistent. I tried creating a new parallel coordinate panel once I saw the error but nothing changed.</p>\n<p>Here\u2019s an example. It says my out_activation for this run was tanh but the line goes through relu under out_activation.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/7a3841626ef83df8db3398271d23de5997adfca2.jpeg\" data-download-href=\"/uploads/short-url/hrcMePlFcUEqviIaQmCWRCSfYGu.jpeg?dl=1\" title=\"Screen Shot 2021-12-18 at 3.55.16 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7a3841626ef83df8db3398271d23de5997adfca2_2_690x411.jpeg\" alt=\"Screen Shot 2021-12-18 at 3.55.16 PM\" data-base62-sha1=\"hrcMePlFcUEqviIaQmCWRCSfYGu\" width=\"690\" height=\"411\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7a3841626ef83df8db3398271d23de5997adfca2_2_690x411.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7a3841626ef83df8db3398271d23de5997adfca2_2_1035x616.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/7a3841626ef83df8db3398271d23de5997adfca2.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7a3841626ef83df8db3398271d23de5997adfca2_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2021-12-18 at 3.55.16 PM</span><span class=\"informations\">1284\u00d7766 141 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Thanks in advance.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-20T17:26:49.043Z",
				"Answer_body": "<p>Hi Samuel, thank you for bringing this bug up with us! Before I create a ticket can you tell me what version of wandb you are using?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-20T19:48:25.083Z",
				"Answer_body": "<p>Yea, I\u2019m currently using version 0.12.9, but, if my memory isn\u2019t failing me, it was happening while I was using 0.12.7 too.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-20T20:06:53.511Z",
				"Answer_body": "<p>From my brief investigation, I didn\u2019t notice it affecting any of my continuous columns, which in this case are lrdk, lr, and loss.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-20T20:56:34.506Z",
				"Answer_body": "<p>Thank you Samuel! I\u2019ll make sure to put this in the ticket</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-04T06:38:04.369Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/lesliewandb\">@lesliewandb</a> Hi, Leslie. I have the same problem, It seems to affect strings more, almost all of the lines in my sweep go to the wrong string values, numeric values are fine though. This issue persitst even if delete the panel and load it again, I think it started to happen as I added more runs. I\u2019m also on version 0.12.9. Has the issue been identified? It\u2019s kind of pity that this is happenning, considering how useful parallel coordinate is.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-11T13:39:48.653Z",
				"Answer_body": "<p>Hi Samuel,</p>\n<p>We have fixed the bug regarding the parallel coordinate plot. Please let me know if you are still running into this bug.</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-14T14:33:05.866Z",
				"Answer_body": "<p>Hi Samuel,</p>\n<p>Since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-05T06:38:58.796Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb is doing the same possibility multiple times",
		"Question_link": "https://community.wandb.ai/t/wandb-is-doing-the-same-possibility-multiple-times/1667",
		"Question_created_time": "2022-01-02T21:38:15.641Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 222,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>hi, i am working on private data with keras. I use different activation functions and optimization algorithms. I\u2019m doing this wandb sweep, but it trains one possibility more than once. example relu-lr=0.001-adam-batch_size=4 has trained probability more than 6 times. what is the reason of this. and I\u2019m not sure of the correctness of my code</p>\n<p>my code :</p>\n<pre><code class=\"lang-auto\">import tensorflow as tf\nimport numpy as np\nbase_dir=\"/content/f1\"\n\ntrain_datagen=tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.1\n    )\n\ntest_datagen=tf.keras.preprocessing.image.ImageDataGenerator(\n     rescale=1./255,\n     validation_split=0.1\n)\n\ntrain_datagen=train_datagen.flow_from_directory(\n    base_dir,\n    target_size=(500,500),\n    subset='training',\n    batch_size=2\n)\n\ntest_datagen=test_datagen.flow_from_directory(\n    base_dir,\n    target_size=(500,500),\n    subset='validation',\n    batch_size=2\n)\nwandb.login()\nsweep_config = {\n    'method': 'random',\n    'metric': {\n      'name': 'accuracy',\n      'goal': 'maximize'   \n    },\n    'parameters': {\n        'epochs': {\n            'values': [2,4]\n        },\n        'learning_rate': {\n            'values': [0.01,0.001]\n        },\n        'optimizer': {\n            'values': ['adam','rmsprop']\n        },\n        'activation': {\n            'values': ['relu', 'elu', 'selu']\n        }\n    }\n}\nsweep_id = wandb.sweep(sweep_config, entity=\"sdad\", project=\"func\")\ndef train():\n    config_defaults = {\n        'epochs': 2,\n        'batch_size': 2,\n        'learning_rate': 0.001,\n        'activation': 'relu',\n        'optimizer': 'adam',\n        'seed': 42\n    }\n\n    wandb.init(config=config_defaults)\n    \n    config = wandb.config\n    \n    model= Sequential()\n\n    model.add(layers.Conv2D(filters=4,activation=config.activation,kernel_size=(5,5),input_shape=(500,500,3)))\n    model.add(layers.MaxPooling2D((2,2)))\n    model.add(layers.Conv2D(filters=8,activation=config.activation,kernel_size=(3,3)))\n    model.add(layers.MaxPooling2D((2,2)))\n    model.add(layers.Conv2D(filters=16,activation=config.activation,kernel_size=(2,2)))\n    model.add(layers.MaxPooling2D((2,2)))\n    model.add(layers.Conv2D(filters=32,activation=config.activation,kernel_size=(2,2)))\n\n    model.add(layers.Flatten())\n\n    model.add(Dense(50,activation=config.activation))\n    model.add(Dense(100,activation=config.activation))\n    model.add(Dense(100,activation=config.activation))\n    model.add(Dense(50,activation=config.activation))\n    model.add(Dense(4,activation=\"softmax\"))\n\n  \n    model.compile(loss = \"categorical_crossentropy\", optimizer = config.optimizer, metrics=['accuracy'])\n\n    model.fit(train_datagen, batch_size=config.batch_size,\n              epochs=config.epochs,\n              validation_data=test_datagen,\n              callbacks=[WandbCallback(data_type=\"image\", validation_data=test_datagen)])\n</code></pre>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9dbbeab2a807227267a91e6519a401beaaa15592.jpeg\" data-download-href=\"/uploads/short-url/mvnzvxYGjBl6IgsCgOkOZueYeoa.jpeg?dl=1\" title=\"swepl\u0131nt\u0131s\u0131\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9dbbeab2a807227267a91e6519a401beaaa15592_2_690x36.jpeg\" alt=\"swepl\u0131nt\u0131s\u0131\" data-base62-sha1=\"mvnzvxYGjBl6IgsCgOkOZueYeoa\" width=\"690\" height=\"36\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9dbbeab2a807227267a91e6519a401beaaa15592_2_690x36.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9dbbeab2a807227267a91e6519a401beaaa15592_2_1035x54.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9dbbeab2a807227267a91e6519a401beaaa15592_2_1380x72.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9dbbeab2a807227267a91e6519a401beaaa15592_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">swepl\u0131nt\u0131s\u0131</span><span class=\"informations\">1780\u00d795 18.6 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-03T04:27:32.203Z",
				"Answer_body": "<p>Hey Yasar, I believe the issue is that you are using random search with a list of constant parameters. Random search will retry parameter combinations after a while. You can pass a <a href=\"https://docs.wandb.ai/guides/sweeps/faq#why-are-my-sweep-agents-running-forever-is-there-a-way-to-set-a-maximum-number-of-runs\">count argument to the wandb agent</a> call to specify the number of experiments to run to avoid this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-03T09:36:37.704Z",
				"Answer_body": "<p>Thank you my friend, the problem has been solved thanks to you. I am thankful to you</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-04T05:16:37.360Z",
				"Answer_body": "<p>Glad to hear it, Yasar</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-05T05:16:57.341Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Violin plots are inaccurate",
		"Question_link": "https://community.wandb.ai/t/violin-plots-are-inaccurate/1644",
		"Question_created_time": "2021-12-30T08:43:55.684Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 249,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I really like the violin plots but there is something strange in my plots.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/19acb7ed3ad4d2c1f2fc8f2037098205c753e63a.png\" data-download-href=\"/uploads/short-url/3F7Z1TdRo1hxg9aaZQGaFCcjA8i.png?dl=1\" title=\"screen_violin\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/19acb7ed3ad4d2c1f2fc8f2037098205c753e63a_2_690x358.png\" alt=\"screen_violin\" data-base62-sha1=\"3F7Z1TdRo1hxg9aaZQGaFCcjA8i\" width=\"690\" height=\"358\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/19acb7ed3ad4d2c1f2fc8f2037098205c753e63a_2_690x358.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/19acb7ed3ad4d2c1f2fc8f2037098205c753e63a_2_1035x537.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/19acb7ed3ad4d2c1f2fc8f2037098205c753e63a.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/19acb7ed3ad4d2c1f2fc8f2037098205c753e63a_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">screen_violin</span><span class=\"informations\">1062\u00d7552 21.2 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nAll of these distributions have the lower bound at 0.0, however they appear to be \u2018randomly\u2019 translated of some shift. Moreover, I have realized that the maximum value that you can estimate by looking at the extremum of the plot is clearly not corresponding with the maximum value you get from the tabular data.<br>\nIs this intended or not?</p>\n<p>Thanks in advance</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-30T19:05:08.379Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/bznm\">@bznm</a>,</p>\n<p>Could you share a link to the page where you see this behaviour? It will be very helpful to get a reproduction of this issue.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-31T10:45:35.934Z",
				"Answer_body": "<p>Please, have a look <a href=\"https://wandb.ai/bznm/pytorch-demo?workspace=user-bznm\">here</a>.<br>\nIf you look at the tabular values, you can see that both the arch have some experiments with accuracy 0.0, so I expect the two violin plots to have the same extremum. Instead, they appear to be shifted. Moreover, you can see from the table that the maximum accuracy reached by arch4 is about 0.81. However, looking at the violin plot you would say that the max value is about 0.9. In so doing the plots are misleading. Can you help?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-04T00:25:49.877Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/bznm\">@bznm</a> ,</p>\n<p>I have created an internal ticket on this issue for our engineering team to investigate this. I will notify you as soon as there is some movement on this issue.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-05T00:26:28.389Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Pytorch sweep help",
		"Question_link": "https://community.wandb.ai/t/pytorch-sweep-help/1669",
		"Question_created_time": "2022-01-03T12:10:16.566Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 220,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi . I want to do a study in pytorch with wandb sweep. I want to try activation function optimization algorithm and lr value with various combinations. but I have no idea how to do this. I did it with keras but not in pytorch. can you help me</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-03T22:06:54.243Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/yasarniyaz\">@yasarniyaz</a> ,</p>\n<p>We have an example Colab Notebook detailing how to run a sweep in PyTorch. You can access it <a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W%26B.ipynb\" rel=\"noopener nofollow ugc\">here</a>.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-03T22:19:41.346Z",
				"Answer_body": "<p>thank you my friend. I looked at this resource, but it doesn\u2019t show how to change my activation functions here, and frankly, this resource seems very confusing to me. do you have any other suggestions?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-03T22:24:43.701Z",
				"Answer_body": "<p>I would say you would have to do some manipulation in your code to get this going. Something like:</p>\n<pre><code class=\"lang-auto\">if config.activation == 'relu':\n  self.activation = nn.ReLU\nelif config.activation == 'tanh':\n  self.activation = nn.tanh\n</code></pre>\n<p>in your <code>__init__</code> function. You can then use the <code>self.activation</code> object to set up your activations in your model based on the sweep config.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-04T22:24:46.283Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Bug in WandB's Keras callback when specifying args",
		"Question_link": "https://community.wandb.ai/t/bug-in-wandbs-keras-callback-when-specifying-args/1651",
		"Question_created_time": "2021-12-31T19:27:08.765Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 262,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I am using WandB\u2019s Keras callback in <code>autokeras</code> (which uses <code>keras-tuner</code> behind the scenes along with other modules). However, if I specify any args things immediately grind down to a halt.</p>\n<p>For reproduction, using the official <a href=\"https://autokeras.com/tutorial/image_regression/\" rel=\"noopener nofollow ugc\">example</a> would be adequate.</p>\n<p>The problem for me is here,</p>\n<pre><code class=\"lang-auto\">WandbCB = WandbCallback(\n    monitor=\"val_loss\", verbose=0, mode=\"min\",\n    log_weights=(True), save_model=(True),\n    validation_data=validation,\n    predictions=5, generator=validation, input_type='images', output_type='images',\n    log_evaluation=(True), validation_steps=None, class_colors=None,\n)\n\nmodel.fit(x=training, validation_data=validation, batch_size=BATCH_SIZE, shuffle=True, callbacks=[WandCB, EStop])\n</code></pre>\n<p>However, if I specify WandB callback <em>without</em> any args,</p>\n<pre><code class=\"lang-auto\">model.fit(x=training, validation_data=validation, batch_size=BATCH_SIZE, shuffle=True, callbacks=[WandbCallback(), EStop])\n</code></pre>\n<p>it works very well.</p>\n<p>This is the error I am getting in the former case,</p>\n<pre><code class=\"lang-auto\">2021-12-31 19:18:38.582746: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n2021-12-31 19:18:38.583261: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199995000 Hz\nTraceback (most recent call last):\n  File \"/usr/local/envs/ak_env/lib/python3.7/site-packages/keras_tuner/engine/tuner.py\", line 287, in _deepcopy_callbacks\n    callbacks = copy.deepcopy(callbacks)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 150, in deepcopy\n    y = copier(x, memo)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 216, in _deepcopy_list\n    append(deepcopy(a, memo))\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 180, in deepcopy\n    y = _reconstruct(x, memo, *rv)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 281, in _reconstruct\n    state = deepcopy(state, memo)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 150, in deepcopy\n    y = copier(x, memo)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 241, in _deepcopy_dict\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 180, in deepcopy\n    y = _reconstruct(x, memo, *rv)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 281, in _reconstruct\n    state = deepcopy(state, memo)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 150, in deepcopy\n    y = copier(x, memo)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 241, in _deepcopy_dict\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 180, in deepcopy\n    y = _reconstruct(x, memo, *rv)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 281, in _reconstruct\n    state = deepcopy(state, memo)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 150, in deepcopy\n    y = copier(x, memo)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 241, in _deepcopy_dict\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 180, in deepcopy\n    y = _reconstruct(x, memo, *rv)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 281, in _reconstruct\n    state = deepcopy(state, memo)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 150, in deepcopy\n    y = copier(x, memo)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 241, in _deepcopy_dict\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 180, in deepcopy\n    y = _reconstruct(x, memo, *rv)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 281, in _reconstruct\n    state = deepcopy(state, memo)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 150, in deepcopy\n    y = copier(x, memo)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 241, in _deepcopy_dict\n    y[deepcopy(key, memo)] = deepcopy(value, memo)\n  File \"/usr/local/envs/ak_env/lib/python3.7/copy.py\", line 169, in deepcopy\n    rv = reductor(4)\nTypeError: can't pickle _thread.RLock objects\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"nas.py\", line 125, in &lt;module&gt;\n    log_evaluation=True, validation_steps=None, class_colors=None), EStop])\n  File \"/usr/local/envs/ak_env/lib/python3.7/site-packages/autokeras/auto_model.py\", line 291, in fit\n    **kwargs\n  File \"/usr/local/envs/ak_env/lib/python3.7/site-packages/autokeras/engine/tuner.py\", line 175, in search\n    new_callbacks = self._deepcopy_callbacks(callbacks)\n  File \"/usr/local/envs/ak_env/lib/python3.7/site-packages/keras_tuner/engine/tuner.py\", line 293, in _deepcopy_callbacks\n    \"It is not possible to do `copy.deepcopy(%s)`\" % (callbacks,)\nValueError: All callbacks used during a search should be deep-copyable (since they are reused across trials). It is not possible to do `copy.deepcopy([&lt;wandb.integration.keras.keras.WandbCallback object at 0x7f399310b690&gt;, &lt;tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f39918b1710&gt;])`\n\nwandb: Waiting for W&amp;B process to finish, PID 6373... (failed 1). Press ctrl-c to abort syncing.\n</code></pre>\n<p>Does anyone have any idea?</p>\n<p><strong>EDIT-</strong> This is the <code>EarlyStopping</code> snippet</p>\n<pre><code class=\"lang-auto\">EStop = tf.keras.callbacks.EarlyStopping(\n    monitor='MAPEMetric', min_delta=2, patience=3, verbose=0, mode=\"min\", baseline=100, #baseline is 100\n    restore_best_weights=True)\n</code></pre>\n<p>The difference is perhaps the metrics being monitored in both - MAPEMetric is a simple custom TF metric that computes the \u201cMean Absolute Percentage Error\u201d;</p>\n<pre><code class=\"lang-auto\">def MAPEMetric(target, output):\n        return tf.math.reduce_mean(tf.math.abs((output - target) / output)) * 100   #100 for %\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-04T20:37:33.261Z",
				"Answer_body": "<p>Hello Neel,</p>\n<p>Unfortunately I was not able to reproduce your issue. Could you possibly send a minimal reproduction in a colab?</p>\n<p>Thanks,</p>\n<p>Nate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-11T21:07:37.271Z",
				"Answer_body": "<p>Hi Neel,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Thanks,</p>\n<p>Nate</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-19T18:03:06.471Z",
				"Answer_body": "<p>Hi Neel, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-01T19:27:27.833Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to control grid sweep's parameters order?",
		"Question_link": "https://community.wandb.ai/t/how-to-control-grid-sweeps-parameters-order/1648",
		"Question_created_time": "2021-12-30T22:12:13.984Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 242,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have several parameters that I intend to grid sweep e.g. batch size, learning rate and optimizer. How can one specify the order in which the parameters are changed?</p>\n<p>For instance, suppose I think choice of optimizer will matter least and learning rate will matter most. I\u2019d like to try all possible learning rates on one optimizer before moving on to the next optimizer. How do I do this?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-30T22:14:57.975Z",
				"Answer_body": "<p>Based on the below plot, it looks like wandb might alphabetize the parameters and then change the last ones (alphabetically speaking) most frequently. Is that correct? If so, how do I change that?</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/22c83bedee795f087ef188798cfc7f979ec22117.jpeg\" data-download-href=\"/uploads/short-url/4XHetRl6peJuZe2BMnn5c93KwLl.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/22c83bedee795f087ef188798cfc7f979ec22117_2_690x303.jpeg\" alt=\"image\" data-base62-sha1=\"4XHetRl6peJuZe2BMnn5c93KwLl\" width=\"690\" height=\"303\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/22c83bedee795f087ef188798cfc7f979ec22117_2_690x303.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/22c83bedee795f087ef188798cfc7f979ec22117.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/22c83bedee795f087ef188798cfc7f979ec22117.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/22c83bedee795f087ef188798cfc7f979ec22117_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">970\u00d7427 165 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-03T17:45:35.306Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/rylan\">@rylan</a>,</p>\n<p>This is not supported currently. I have created a feature request for this, I\u2019ll keep you updated on the status of the request!</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-03-04T17:45:56.059Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Custom sweep configuration",
		"Question_link": "https://community.wandb.ai/t/custom-sweep-configuration/1589",
		"Question_created_time": "2021-12-22T02:35:57.776Z",
		"Question_answer_count": 2,
		"Question_score_count": 3,
		"Question_view_count": 316,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>How can I create more complex logic for defining the parameter space of a sweep? For example, for each model family, I\u2019d like to define a different set of parameters, or there a parameter that is a (variable) list of values.</p>\n<p>I can write code that generates all possible hyperparameter combinations by myself (as a list or as generator).</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2022-01-03T17:34:58.734Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/shlomihod\">@shlomihod</a></p>\n<ul>\n<li>\n<p><a href=\"https://docs.wandb.ai/ref/python/run#log_code\">We have this documentation on custom sweeps.</a> It shows you how to define more fine-tuned control over what command the controller will be calling to the agent and not the functionality of the sweeps tuning directly. You can usually find a good way to combine sweeps with your training script to work out most search space workloads. To do fine tuning on the functionality of sweeps you could use the <a href=\"https://docs.wandb.ai/guides/sweeps/advanced-sweeps/local-controller\">local controller</a> but it is not intended for actual hyperparameter optimization workloads.</p>\n</li>\n<li>\n<p>I\u2019m not entirely sure what you mean by \u201ceach model family\u201d but I\u2019m assuming you mean some degree of conditional control over sweeps, which isn\u2019t supported natively at the moment. Let me know if I\u2019m misunderstanding though! You can most likely use the custom sweeps suggestion I mentioned to achieve something to this effect.</p>\n</li>\n<li>\n<p>You can pass a list in YAML and that can be used with grid search strategy. However, it does not work with our other search strategies like Bayes (because that wouldn\u2019t really make sense for lists). Do you have a specific use case you\u2019d like to support if this isn\u2019t what you\u2019re looking for?</p>\n</li>\n</ul>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.757Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Why can't I delete multiple runs in W&B at once",
		"Question_link": "https://community.wandb.ai/t/why-cant-i-delete-multiple-runs-in-w-b-at-once/1585",
		"Question_created_time": "2021-12-21T22:57:53.795Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 233,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>As shown in the picture below, I selected multiple runs but still can\u2019t hit delete, which was ok before, did I set something wrong?<br>\nThank you for your help!<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/0a51eb43f9c351b2492802fcef3dd96b673771fe.jpeg\" data-download-href=\"/uploads/short-url/1tihGWyfSAk2zp9Y2O4VmZiNf3g.jpeg?dl=1\" title=\"20211218195831\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0a51eb43f9c351b2492802fcef3dd96b673771fe_2_690x283.jpeg\" alt=\"20211218195831\" data-base62-sha1=\"1tihGWyfSAk2zp9Y2O4VmZiNf3g\" width=\"690\" height=\"283\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0a51eb43f9c351b2492802fcef3dd96b673771fe_2_690x283.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0a51eb43f9c351b2492802fcef3dd96b673771fe_2_1035x424.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/0a51eb43f9c351b2492802fcef3dd96b673771fe.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/0a51eb43f9c351b2492802fcef3dd96b673771fe_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">20211218195831</span><span class=\"informations\">1072\u00d7441 33.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-22T13:30:12.386Z",
				"Answer_body": "<p>Hey there, this is a known issue that we are working on right now. I\u2019ll notify you once this is fixed.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-28T17:01:19.641Z",
				"Answer_body": "<p>Hey there, can you check if the issue still persists?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-30T01:10:49.998Z",
				"Answer_body": "<p>I\u2019m sorry I just saw your reply, this problem has been solved,  thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-28T01:11:08.297Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sweep from existing runs not showing up in parallel coordinates, is this intended or a bug?",
		"Question_link": "https://community.wandb.ai/t/sweep-from-existing-runs-not-showing-up-in-parallel-coordinates-is-this-intended-or-a-bug/1601",
		"Question_created_time": "2021-12-23T07:47:19.181Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 253,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi, I created a sweep from existing runs, but the panel Parallel Coordinates are empty, is this an intended behaviour or a bug?</p>\n<p>Here is what I did:</p>\n<ul>\n<li>populate projects with many runs (using ray\u2019s wandb_mixin)</li>\n<li>create a sweep following <a href=\"https://docs.wandb.ai/guides/sweeps/existing-project#seed-a-new-sweep-with-existing-runs\">https://docs.wandb.ai/guides/sweeps/existing-project#seed-a-new-sweep-with-existing-runs</a>\n</li>\n<li>the panel at \u201cSweeps &gt; [2]\u201d contains only 1 run, should contains all 42 runs.</li>\n</ul>\n<p>The sweep is at <a href=\"https://wandb.ai/inc/try_ray_tune/sweeps/smh3d0wg\" class=\"inline-onebox\">Weights &amp; Biases</a>, if any one is interested.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-23T21:43:17.019Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/inc\">@inc</a>,</p>\n<p>Checking the link for your run, I see all 42 runs, grouped together as one single grouped run. Are you still facing this issue?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-24T01:21:21.696Z",
				"Answer_body": "<p>I can see all 42 runs no problem, but I expect to see them on the sweeps\u2019 parallel coordinates panel:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/7417aff14e55470287a1e936710606abe4488cbf.png\" data-download-href=\"/uploads/short-url/gz08s2oOYUdETsRiUUbSDUf6ZKD.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7417aff14e55470287a1e936710606abe4488cbf_2_690x242.png\" alt=\"image\" data-base62-sha1=\"gz08s2oOYUdETsRiUUbSDUf6ZKD\" width=\"690\" height=\"242\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7417aff14e55470287a1e936710606abe4488cbf_2_690x242.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7417aff14e55470287a1e936710606abe4488cbf_2_1035x363.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7417aff14e55470287a1e936710606abe4488cbf_2_1380x484.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/7417aff14e55470287a1e936710606abe4488cbf_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1793\u00d7631 35.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Thanks for the reply.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-24T01:39:21.154Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/inc\">@inc</a>,</p>\n<p>You should be able to see all 42 runs on your parallel coordinates plot by ungrouping the runs. Grouping runs groups them for charts on your workspace as well.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2021-12-24T02:54:06.812Z",
				"Answer_body": "<p>Thanks, that solved it.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-22T02:54:52.566Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Resources on how to use wandb docker",
		"Question_link": "https://community.wandb.ai/t/resources-on-how-to-use-wandb-docker/1596",
		"Question_created_time": "2021-12-23T00:04:04.715Z",
		"Question_answer_count": 2,
		"Question_score_count": 2,
		"Question_view_count": 628,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Greetings:</p>\n<p>After lots of research, I decided to go with wandb as the solution to several of the project management organization currently in place (or lack thereof).</p>\n<p>With that, I am looking to acquire the most effective workflow using <code>wandb docker</code> and <code>wandb local</code>.</p>\n<p>There is a page on this in the documents, and another in Github, but both are brief, and do not provide much information. All other documentation appears quite impressive (a major factor to me choosing this over the many other solutions). Whether featured by the company or a blog done by a third party, any good references to set up docker with wandb? Eventually, we will be spanning many parts of the data science pipeline (i.e., this is me doing a trial for a group at a company). So figured best practices and an efficient work environment should be set up first. Then, to start playing around with the outputs from the container runs to the project space (dashboard).</p>\n<p>Any pointers, references, samples projects, or any other material that might be out there?</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-23T21:45:20.337Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/jvisionvs\">@jvisionvs</a></p>\n<p>I\u2019m glad to hear about your decision to use <code>wandb</code> as the solution of choice for your organization.<br>\nI apologize for the lack of clarity in the documentation regarding <code>wandb docker</code> and <code>wandb local</code> . We are always updating our documentation so if there is something specific you would have liked to have seen about these commands please let us know!</p>\n<p><code>wandb docker</code> and <code>wandb local</code> are two different but heavily related container solutions to interacting with <code>wandb</code> .</p>\n<blockquote>\n<p><a href=\"https://docs.wandb.ai/guides/integrations/other/docker\">\u201d <code>wandb docker</code> is a command that starts a docker container, passes in wandb environment variables, mounts your code, and ensures wandb is installed. By default the command uses a docker image with TensorFlow, PyTorch, Keras, and Jupyter installed.\u201c</a></p>\n</blockquote>\n<p><code>wandb docker</code> is intended to be used as pre-made docker container in which it makes it easy to interact with your <code>wandb</code> instance, with the necessary environment variables pre-configured and with the standard suite of deep-learning toolkits. You could as easily make your own docker container with a different base image by making sure to simply set the <a href=\"https://docs.wandb.ai/guides/track/advanced/environment-variables#optional-environment-variables\">proper environment variables.</a> <strong>This makes it so you have no need to directly login from your script to be able to log to your</strong> <code>wandb</code> <strong>instance</strong>. <a href=\"https://medium.com/@stephanie_88121/we-made-docker-easy-to-use-for-reproducibility-in-machine-learning-experiments-521c0eef94f6\" rel=\"noopener nofollow ugc\">Here is one of the older articles we have outlining the usefulness of <code>wandb docker</code>.</a></p>\n<p>Now I used the phrase \u201c <code>wandb</code> instance\u201d <a href=\"https://docs.wandb.ai/guides/self-hosted/local\">because <code>wandb local</code> operates as your own <code>wandb</code> server.</a> If the cloud solution does not suit your use case for a variety of reasons (<a href=\"https://docs.wandb.ai/guides/track/limits\">be it the limitations set in place that can be adjusted</a>, security reasons, etc.), you can spin up your own instance of <code>wandb</code> that would be exclusive to your organization. However, <code>wandb local</code> on localhost is good only for testing purposes. If you so decide to move with <code>wandb local</code> , you can use the <a href=\"https://docs.wandb.ai/guides/self-hosted/setup\">documentation here to set up your instance for production workloads</a>.</p>\n<p>If you have any more questions please don\u2019t hesitate to ask!<br>\nHappy Holidays,<br>\nAnish</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.522Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How can I update custom plots in real-time?",
		"Question_link": "https://community.wandb.ai/t/how-can-i-update-custom-plots-in-real-time/1578",
		"Question_created_time": "2021-12-20T03:17:53.918Z",
		"Question_answer_count": 6,
		"Question_score_count": 2,
		"Question_view_count": 812,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m currently using a custom line-plot to plot some metrics on one graph. Here\u2019s an example plot that tracks train and valid loss over a number of epochs:</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/3d95989b82878fed32b4b1ab123082013f3a229b.png\" alt=\"image\" data-base62-sha1=\"8MNDiL6poCrJxDhGbGFy3XTViGv\" width=\"566\" height=\"302\"></p>\n<p>Here\u2019s my current procedure to create this plot:</p>\n<ol>\n<li>First I create an empty W&amp;B Table (let\u2019s call it <code>loss_table</code>)</li>\n<li>At the end of each epoch, I calculate the train and valid loss and add it to the Table with the <code>loss_table.add_data()</code> method.</li>\n<li>Then at the end of training, I log <code>loss_table</code> to W&amp;B.</li>\n<li>Finally I create the chart from a vega spec <code>spec_name</code> with the command <code>chart = wandb.plot_table(vega_spec_name=spec_name, data_table=loss_table,...)</code> and log the chart with<br>\n<code>wandb.log({\"loss vs epoch\": chart})</code>\n</li>\n</ol>\n<p>This gives me the chart but doesn\u2019t let me see how the metrics change in real-time. Given that my training times are long (in the order of days and weeks) it is pretty important to me to see this real-time.</p>\n<p>My main problem is that W&amp;B doesn\u2019t support updating rows of a table, but instead supports only one upload of a table.  This prevents updating metrics and logging them to W&amp;B after each epoch, instead pushing for uploading the table only once training is finished.  There is an <a href=\"https://github.com/wandb/client/issues/1826\" rel=\"noopener nofollow ugc\">Github issue</a> that talks about this.</p>\n<p>Any suggestions would be welcomed.  Not sure how to get around this.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-21T19:16:57.972Z",
				"Answer_body": "<p>Hello! This flow might not be ideal (and we\u2019re working on it), but the current best thing to do is probably what Carey\u2019s suggesting in the GitHub issue:</p>\n<blockquote>\n<p>Hi there, we can\u2019t support adding new rows to existing tables that you\u2019ve already logged, but here are two approaches:</p>\n<ol>\n<li>Keep the wandb.Table locally and add new rows to it. Once you\u2019ve got all the rows in, call wandb.log</li>\n<li>Keep logging the same table at each step, and just add new rows to it. the final table you log will have all the rows you want, and you\u2019ll be able to see the latest table logged in the UI. This would be risky if you have large table sizes.</li>\n</ol>\n</blockquote>\n<p>Let me know if you have more questions/feature suggestions for the product though. <img src=\"https://emoji.discourse-cdn.com/twitter/slightly_smiling_face.png?v=10\" title=\":slightly_smiling_face:\" class=\"emoji\" alt=\":slightly_smiling_face:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-21T22:57:58.036Z",
				"Answer_body": "<p>Thanks for your reply.</p>\n<blockquote>\n<ol start=\"2\">\n<li>Keep logging the same table at each step, and just add new rows to it. the final table you log will have all the rows you want, and you\u2019ll be able to see the latest table logged in the UI. This would be risky if you have large table sizes.</li>\n</ol>\n</blockquote>\n<p>Sounds like this would be the option. If I did this, is there a way I could delete the old table after I create the new one (preferably via a Python command)?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-22T18:14:08.442Z",
				"Answer_body": "<p>Sure thing, happy to help! Well, because of how Artifacts work all the files within your Tables (even if there are many, many versions of them) wouldn\u2019t be duplicated and the actual files defining Tables are usually really small (like several kilobytes or, tops, megabytes if your Table is really large), so you could easily keep all the versions of your Tables this way.</p>\n<p>In terms of deleting the older versions of those Tables (which, again, probably wouldn\u2019t make much of a difference in terms of storage) you could do in the UI by clicking here, and in Python using this code. <a href=\"https://docs.wandb.ai/guides/artifacts/artifacts-faqs#how-do-i-delete-an-artifact-with-associated-aliases\">Here it\u2019s in the docs.</a></p>\n<pre><code class=\"lang-auto\">for artifact in run.logged_artifacts():\n    artifact.delete(delete_aliases=True)\n</code></pre>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/1a5777b3b667a3a5624a4ce82db59725b54e0ec2.png\" data-download-href=\"/uploads/short-url/3L1OnU5hh5bDi7UlIIms19QnNOW.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1a5777b3b667a3a5624a4ce82db59725b54e0ec2_2_690x220.png\" alt=\"image\" data-base62-sha1=\"3L1OnU5hh5bDi7UlIIms19QnNOW\" width=\"690\" height=\"220\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1a5777b3b667a3a5624a4ce82db59725b54e0ec2_2_690x220.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1a5777b3b667a3a5624a4ce82db59725b54e0ec2_2_1035x330.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1a5777b3b667a3a5624a4ce82db59725b54e0ec2_2_1380x440.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1a5777b3b667a3a5624a4ce82db59725b54e0ec2_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1883\u00d7603 43.6 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-22T18:27:04.950Z",
				"Answer_body": "<p>Also, here\u2019s some more info on how Artifacts work <a href=\"https://docs.wandb.ai/guides/artifacts/artifacts-core-concepts#storage-layout\">https://docs.wandb.ai/guides/artifacts/artifacts-core-concepts#storage-layout</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-22T21:59:13.218Z",
				"Answer_body": "<p>Thanks for your help! I will give it a go.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:07.787Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Only a subset of the artifacts exist issue",
		"Question_link": "https://community.wandb.ai/t/only-a-subset-of-the-artifacts-exist-issue/1569",
		"Question_created_time": "2021-12-19T12:44:15.017Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 340,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\nI generated different 7 cells datasets.</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://wandb.ai/chen-brestel/cells_dataset/runs/z5lo24hn/overview?workspace=user-chen-brestel\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/18b592222b97bc09df3743831bb4929dec23611c.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https://wandb.ai/chen-brestel/cells_dataset/runs/z5lo24hn/overview?workspace=user-chen-brestel\" target=\"_blank\" rel=\"noopener\">W&amp;B</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://s.gravatar.com/avatar/984d35ad02a6fb4388e6f91a95a0e805?s=480&amp;r=pg&amp;d=https%3A%2F%2Fcdn.auth0.com%2Favatars%2Fch.png\" class=\"thumbnail onebox-avatar\" width=\"120\" height=\"120\">\n\n<h3><a href=\"https://wandb.ai/chen-brestel/cells_dataset/runs/z5lo24hn/overview?workspace=user-chen-brestel\" target=\"_blank\" rel=\"noopener\">chen-brestel</a></h3>\n\n  <p>Weights &amp; Biases, developer tools for machine learning</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>The pkl data of <em>all</em> the seven datasets do exist.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/a8c17350da9dea9b06094ba90955d0690f3d8bf0.png\" data-download-href=\"/uploads/short-url/o4SGcGfGg8KdPBsRnNdwBIRYPVC.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a8c17350da9dea9b06094ba90955d0690f3d8bf0_2_690x487.png\" alt=\"image\" data-base62-sha1=\"o4SGcGfGg8KdPBsRnNdwBIRYPVC\" width=\"690\" height=\"487\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a8c17350da9dea9b06094ba90955d0690f3d8bf0_2_690x487.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a8c17350da9dea9b06094ba90955d0690f3d8bf0_2_1035x730.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a8c17350da9dea9b06094ba90955d0690f3d8bf0_2_1380x974.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/a8c17350da9dea9b06094ba90955d0690f3d8bf0_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1389\u00d7981 52.8 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>However, There exist artifacts for <em>only</em> 3/7.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/bb3ef6d248c7add270d8c59a4932fe6ae2229787.png\" data-download-href=\"/uploads/short-url/qIsbAXGhKr2J7Gt2hOwV2tE1l9J.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/bb3ef6d248c7add270d8c59a4932fe6ae2229787_2_690x489.png\" alt=\"image\" data-base62-sha1=\"qIsbAXGhKr2J7Gt2hOwV2tE1l9J\" width=\"690\" height=\"489\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/bb3ef6d248c7add270d8c59a4932fe6ae2229787_2_690x489.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/bb3ef6d248c7add270d8c59a4932fe6ae2229787_2_1035x733.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/bb3ef6d248c7add270d8c59a4932fe6ae2229787.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/bb3ef6d248c7add270d8c59a4932fe6ae2229787_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1360\u00d7965 59.8 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Screenshots attached.</p>\n<p>Thanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-20T20:02:17.877Z",
				"Answer_body": "<p>Hi Chen! It looks like you are saving your files differently. Where it says that there\u2019s only 3 files, it\u2019s because you\u2019ve only uploaded 3 files using wandb.Artifacts compared to the ones in your root.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-27T13:35:35.353Z",
				"Answer_body": "<p>Hi again, I\u2019m just checking in to see if you need any further assistance?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-30T14:08:43.006Z",
				"Answer_body": "<p>Hi Chen, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-17T12:44:33.276Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to plot multiline in one plot with smoothing features?",
		"Question_link": "https://community.wandb.ai/t/how-to-plot-multiline-in-one-plot-with-smoothing-features/1512",
		"Question_created_time": "2021-12-12T02:15:05.880Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 305,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I\u2019m trying to plot the figure as in [W&amp;B Smoothing Features], but it didn\u2019t provide any code:</p>\n<p>                    <a href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9b0793db422eac619667bd11a7c56351d9d69149.png\" target=\"_blank\" rel=\"noopener nofollow ugc\" class=\"onebox\">\n            <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9b0793db422eac619667bd11a7c56351d9d69149.png\" width=\"690\" height=\"301\">\n          </a>\n\n</p>\n<p>Tutorials I could find by searching <code>wandb multiline in one plot</code> is [Custom Multi-Line Plots] which introduces <code>wandb.plot.line_series()</code>.  So I tried the code following</p>\n<pre><code class=\"lang-python\">import wandb\nimport numpy as np\n\n\nwandb.init(project=\"test\", entity=\"xxxx\")\n\nwandb.log({\"my_custom_id\":\n           wandb.plot.line_series(\n               xs=range(100),\n               ys=[range(100), np.random.randint(100, size=100)],\n               keys=[\"y1\", \"y2\"],\n               title=\"Multiline\",\n               xname=\"steps\"\n           )})\n</code></pre>\n<p>It gives me the following pic after choosing <code>Edit panel</code></p>\n<p>                    <a href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/4e32b0d8ec1fb96df36dd2a7609f129875cb9e8e.png\" target=\"_blank\" rel=\"noopener nofollow ugc\" class=\"onebox\">\n            <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/4e32b0d8ec1fb96df36dd2a7609f129875cb9e8e.png\" width=\"690\" height=\"351\">\n          </a>\n\n</p>\n<p>Unlike the first picture:</p>\n<ol>\n<li>It <strong>doesn\u2019t</strong> have <code>Data</code>, <code>Group</code> etc tabs.</li>\n<li>There are <strong>two types</strong> of legend <code>name</code> and <code>lineKey</code> rather than one type.</li>\n</ol>\n<p>My question is how to plot exactly the same as the first picture with same function supported in wandb web?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-13T21:52:48.032Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/hoo-leo\">@hoo-leo</a> could you link me to your chart so I can take a look for you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-14T00:46:13.096Z",
				"Answer_body": "<p>The link is <a href=\"https://wandb.ai/hoo-leo/example/runs/2q2qigsk?workspace=user-hoo-leo\">Example</a>, the corresponding code is in my question.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-15T00:32:50.761Z",
				"Answer_body": "<p>First I need to log the data I want</p>\n<pre><code class=\"lang-python\">import random\nimport wandb\n\nwandb.init(project=\"test\", entity=\"xxxx\")\nfor i in range(100):\n    wandb.log({\"y1\": random.random(), \"y2\": random.random(), \"x\": i})\n</code></pre>\n<p>Then, I need to mannually choosing y1 and y2 on Y Axis.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/1794a161b9d71b6745d9a5c7f4beff76003a4d5c.jpeg\" data-download-href=\"/uploads/short-url/3mBq6eTgdFLO5BAFCPEQmOUHYoQ.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1794a161b9d71b6745d9a5c7f4beff76003a4d5c_2_690x262.jpeg\" alt=\"image\" data-base62-sha1=\"3mBq6eTgdFLO5BAFCPEQmOUHYoQ\" width=\"690\" height=\"262\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1794a161b9d71b6745d9a5c7f4beff76003a4d5c_2_690x262.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1794a161b9d71b6745d9a5c7f4beff76003a4d5c_2_1035x393.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1794a161b9d71b6745d9a5c7f4beff76003a4d5c_2_1380x524.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1794a161b9d71b6745d9a5c7f4beff76003a4d5c_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1807\u00d7687 214 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2021-12-20T09:26:01.746Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/hoo-leo\">@hoo-leo</a> glad you figured this out!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-18T09:26:49.263Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Download .html of plotly figures",
		"Question_link": "https://community.wandb.ai/t/download-html-of-plotly-figures/1538",
		"Question_created_time": "2021-12-15T11:46:46.509Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 189,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Can we download HTML figures from plotly exported to wandb?<br>\nI.e., I see in the media section the figure, but I wish to have the HTML plotly created to be used externally. The format by wandb not as reach as plotly\u2019s, as full-screen mode</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/f048e63a7a6ffaf4ada01c95d688904ceb612281.jpeg\" data-download-href=\"/uploads/short-url/yhEMitSPZB9d8EKYfKmZE2SeJzz.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f048e63a7a6ffaf4ada01c95d688904ceb612281_2_690x263.jpeg\" alt=\"image\" data-base62-sha1=\"yhEMitSPZB9d8EKYfKmZE2SeJzz\" width=\"690\" height=\"263\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f048e63a7a6ffaf4ada01c95d688904ceb612281_2_690x263.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f048e63a7a6ffaf4ada01c95d688904ceb612281_2_1035x394.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f048e63a7a6ffaf4ada01c95d688904ceb612281_2_1380x526.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f048e63a7a6ffaf4ada01c95d688904ceb612281_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1920\u00d7732 89.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-16T00:05:53.451Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dvirginz\">@dvirginz</a> are asking for the ability to embed a wandb plotly plot or to export the html (along with the data since it\u2019s an interactive plot)?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-20T09:13:11.580Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dvirginz\">@dvirginz</a> , just following up here.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-23T17:18:59.313Z",
				"Answer_body": "<p>Hi Dvir, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-18T09:13:42.729Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Workspace Bug",
		"Question_link": "https://community.wandb.ai/t/workspace-bug/974",
		"Question_created_time": "2021-10-14T07:49:08.869Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 274,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Dear WandB hello.</p>\n<p>When I\u2019m trying to work in my workspace and looking at the graph I could not see the model\u2019s menu, is there a way to fix it at my level?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-15T14:22:48.601Z",
				"Answer_body": "<p>Hey there, can you send the link to the workspace?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-16T17:30:50.000Z",
				"Answer_body": "<p><a href=\"https://wandb.ai/nilu/ArtificialNeuron?workspace=user-nilu\">https://wandb.ai/nilu/ArtificialNeuron?workspace=user-nilu</a></p>\n<p>Thank you for the assistance</p>\n<p>\u202b\u05d1\u05ea\u05d0\u05e8\u05d9\u05da \u05d9\u05d5\u05dd \u05d5\u05f3, 15 \u05d1\u05d0\u05d5\u05e7\u05f3 2021 \u05d1-17:32 \u05de\u05d0\u05ea \u202aArman Harutyunyan via W&amp;B Community\u202c\u200f &lt;\u202a<a href=\"mailto:wandb@discoursemail.com\">wandb@discoursemail.com</a>\u202c\u200f&gt;:\u202c</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-25T11:23:03.533Z",
				"Answer_body": "<p>Hey there, sorry about the delay on this. Clearing the workspace should fix this issue. Add <code>?workspace=clear </code> to the end of the URL and press enter. This should take you to a cleared version of your project page workspace. Please let me know if the issue persists.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-25T13:27:56.000Z",
				"Answer_body": "<p>Great ,thank you!</p>\n<p>\u202b\u05d1\u05ea\u05d0\u05e8\u05d9\u05da \u05d9\u05d5\u05dd \u05d1\u05f3, 25 \u05d1\u05d0\u05d5\u05e7\u05f3 2021 \u05d1-14:33 \u05de\u05d0\u05ea \u202aArman Harutyunyan via W&amp;B Community\u202c\u200f &lt;\u202a<a href=\"mailto:wandb@discoursemail.com\">wandb@discoursemail.com</a>\u202c\u200f&gt;:\u202c</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-08T17:18:01.000Z",
				"Answer_body": "<p>Hi again ,how are you doing?</p>\n<p>The other time I had opened a new workspace and dumped the previous model history, nowadays i tried your method and it didn\u2019t work. What can I do?</p>\n<p>\u202b\u05d1\u05ea\u05d0\u05e8\u05d9\u05da \u05d9\u05d5\u05dd \u05d1\u05f3, 25 \u05d1\u05d0\u05d5\u05e7\u05f3 2021 \u05d1-16:27 \u05de\u05d0\u05ea \u202agoulux\u202c\u200f &lt;\u202a<a href=\"mailto:nitzanlux@gmail.com\">nitzanlux@gmail.com</a>\u202c\u200f&gt;:\u202c</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-17T08:12:11.458Z",
				"Answer_body": "<p>hello\u2026claim!!offers hurry up</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Having problems with LaTeX reports",
		"Question_link": "https://community.wandb.ai/t/having-problems-with-latex-reports/1514",
		"Question_created_time": "2021-12-12T10:46:53.787Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 200,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>When I try to download a LaTeX report the download spinning wheel starts, but never stops.<br>\nDoes it take so long or is this an issue with my setup?</p>\n<p>I\u2019m working on a MacBook accessing wandb from Apple Safari browser.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-14T12:07:48.666Z",
				"Answer_body": "<p>Hey J\u00fcrgen, can you send the link to the report?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-14T14:04:59.000Z",
				"Answer_body": "<p>Hi,</p>\n<p>This report is not downloadable as LaTeX version: <a href=\"https://wandb.ai/thetaphipsi/CNEP/reports/Training-CNEP-with-different-LR-Warmup--VmlldzoxMzMxNTg2?accessToken=d19fhd2vegr1y65xnjkaqqnc758fsav3edcsmc264gsmen4k1ngppz6v4ii4kbpq\">https://wandb.ai/thetaphipsi/CNEP/reports/Training-CNEP-with-different-LR-Warmup\u2013VmlldzoxMzMxNTg2?accessToken=d19fhd2vegr1y65xnjkaqqnc758fsav3edcsmc264gsmen4k1ngppz6v4ii4kbpq</a></p>\n<p>I created a different one, without any table of contents and it works, don\u2019t know what the issues is in that case.</p>\n<p>Regards<br>\nJ\u00fcrgen</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-23T14:36:26.666Z",
				"Answer_body": "<p>Hey J\u00fcrgen.</p>\n<p>There seems to be a bug on our end. We\u2019ll need to investigate this. I have created a ticket.<br>\nSorry about the inconvenience.</p>\n<p>Best,<br>\nArman</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-12T14:05:04.249Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Does wandb charges for data transfer as s3 does(apart from data storage cost)?",
		"Question_link": "https://community.wandb.ai/t/does-wandb-charges-for-data-transfer-as-s3-does-apart-from-data-storage-cost/1487",
		"Question_created_time": "2021-12-08T11:22:03.480Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 315,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>The pricing on the wandb website states cost of data storage.Does wandb also charges downloading and uploading of artifacts like S3 does for data transfer?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-08T12:17:21.755Z",
				"Answer_body": "<p>Hey Jasdeep,</p>\n<p>Double-checking this with the team. Will get back to you as soon as possible.</p>\n<p>Best,<br>\nArman</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-09T17:02:40.287Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/armanharutyunyan\">@armanharutyunyan</a>  Any updates?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-14T12:14:01.873Z",
				"Answer_body": "<p>Hey there, sorry about the delay on this. We are only charging for storage, not transfer of data.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-12T12:14:08.550Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Plotting array-like values in a parallel coordinates plot",
		"Question_link": "https://community.wandb.ai/t/plotting-array-like-values-in-a-parallel-coordinates-plot/1371",
		"Question_created_time": "2021-11-23T11:53:21.807Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 304,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I have set up a sweep where one of the parameters possible values (arrays) are [0, 1, 3, 5], [0, 1, 5, 8], [0, 1, 8, 11], etc. The sweep is working fine and the model receives the correct value from the agent, but when visualizing the sweep using the parallel coordinates plot, every possible value of this hyperparameter is plotted at zero, since it is the first element of every array.</p>\n<p>I have thought of two solutions:</p>\n<ul>\n<li>Download all the data using the API, modify each value with an alias, and reupload the data.</li>\n<li>Write a custom plot to modify how that axe is plotted.</li>\n</ul>\n<p>However, I would like to know if there is a more straightforward solution so that each experiment line correctly passes through its value of this hyperparameter.</p>\n<p>Thank you in advance!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-23T20:43:14.807Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/guillesanbri\">@guillesanbri</a> , could you please link me to your sweeps page so I can take a look for you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-23T22:17:23.912Z",
				"Answer_body": "<p>Sure <a class=\"mention\" href=\"/u/aidanjd\">@aidanjd</a> , here is the link <a href=\"https://wandb.ai/guillesanbri/DPT/sweeps/vyv6zl0c\" class=\"inline-onebox\">Weights &amp; Biases</a></p>\n<p>If you hover with the mouse over different runs, you can see that the hooks parameter is indeed different while going through zero.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-29T17:13:50.721Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/guillesanbri\">@guillesanbri</a> , are the values for hooks multiple different lists?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-30T12:45:21.395Z",
				"Answer_body": "<p>Yep <a class=\"mention\" href=\"/u/aidanjd\">@aidanjd</a> , I would like each value (each different list) to be shown as a string like if they were categorical values in the plots, if that makes sense. I have remedied it in the following experiments defining the values as strings (ie. \u201ch[0,1,3,5]\u201d) and processing them inside the training script.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-06T23:56:03.290Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/guillesanbri\">@guillesanbri</a>, that\u2019s a good workaround and overall a good feature suggestion. I\u2019ll file something internally and keep you updated when there\u2019s progress on this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-13T08:37:20.460Z",
				"Answer_body": "<p>Great! Thank you <a class=\"mention\" href=\"/u/aidanjd\">@aidanjd</a> !</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-11T08:37:45.279Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Semi-transparent smoothing stopped working",
		"Question_link": "https://community.wandb.ai/t/semi-transparent-smoothing-stopped-working/1492",
		"Question_created_time": "2021-12-09T03:12:19.043Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 398,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Smoothing suddenly stopped making the original graph semi-transparent.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/2efe82c897ae30783052f01c9383e9582d1f229e.png\" data-download-href=\"/uploads/short-url/6HJfxA7ERNAiH7FwWeL8MzvFDIi.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2efe82c897ae30783052f01c9383e9582d1f229e_2_512x500.png\" alt=\"image\" data-base62-sha1=\"6HJfxA7ERNAiH7FwWeL8MzvFDIi\" width=\"512\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2efe82c897ae30783052f01c9383e9582d1f229e_2_512x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/2efe82c897ae30783052f01c9383e9582d1f229e.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/2efe82c897ae30783052f01c9383e9582d1f229e.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/2efe82c897ae30783052f01c9383e9582d1f229e_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">517\u00d7504 48.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Any way your could rollback to the previous behavior? Some ETA for fixing this would be much appreciated, so our team could plan accordingly.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-09T03:25:43.450Z",
				"Answer_body": "<p>PS. For anyone facing this issue - a colleague of mine found a work-around in the \u201cEdit panel\u201d to turn off the original chart:<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/de2a9528f51e0238785436562d02036c199af134.png\" alt=\"image\" data-base62-sha1=\"vHnellx3bs9OhnqiUZ1lqfZ0unW\" width=\"227\" height=\"463\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-09T12:06:18.979Z",
				"Answer_body": "<p>Hey Sebastian,<br>\nthank you for reporting this. I\u2019ll share this with the team so we can fix this as soon as possible.<br>\nWill let you know once the issue is resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-13T08:19:32.556Z",
				"Answer_body": "<p>Hey there, the issue has been fixed. Thank you for your patience!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-11T08:19:42.541Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How can use W&B locally and not publically?",
		"Question_link": "https://community.wandb.ai/t/how-can-use-w-b-locally-and-not-publically/1523",
		"Question_created_time": "2021-12-12T18:34:26.662Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 243,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi</p>\n<p>I am trying to learn WB, I was wondering how can I use WB more like tensorboard locally and dont share my stuff on the cloud or publically?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-12T19:43:03.524Z",
				"Answer_body": "<p>Hi,</p>\n<p>You can use <code>wandb local</code>. You can run the app locally or host in a private cloud. The self hosted server is a single Docker image that is simple to deploy</p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/guides/self-hosted/local\">\n  <header class=\"source\">\n      \n\n      <a href=\"https://docs.wandb.ai/guides/self-hosted/local\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/guides/self-hosted/local\" target=\"_blank\" rel=\"noopener\">Local</a></h3>\n\n  <p>Run Weights and Biases on your own machines using Docker</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.409Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "What should the .gitignore file be when using wandb?",
		"Question_link": "https://community.wandb.ai/t/what-should-the-gitignore-file-be-when-using-wandb/756",
		"Question_created_time": "2021-09-23T16:15:40.148Z",
		"Question_answer_count": 6,
		"Question_score_count": 2,
		"Question_view_count": 419,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I noticed that my pycharm suggests some wandb files that are created automatically\u2026to avoid pushing those (btw what are they?) what is the recommended .gitignore files contents?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-24T17:46:56.481Z",
				"Answer_body": "<p>Could you list the files you\u2019re seeing?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-24T18:04:57.057Z",
				"Answer_body": "<p>As a first rule of thumb, I would suggest adding <code>wandb/</code>, or whatever your <a href=\"https://docs.wandb.ai/guides/track/advanced/environment-variables\"><code>$WANDB_DIR</code></a> is, to your <code>.gitignore</code>.</p>\n<p>I would not recommend using a directory that\u2019s also used for other purposes as your <code>$WANDB_DIR</code>, because that would require a finer filter to just ignore our files. The precise files that may be generated can change as you change which features you are using \u2013 and as we update the library with new features and behaviors! \u2013 so it\u2019s simpler to make a dedicated directory and ignore the whole thing.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-08T15:50:15.870Z",
				"Answer_body": "<pre><code class=\"lang-auto\">\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_161835-1wce8lzx/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_161925-grsux6zy/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_162007-j58q0jt6/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_162242-1xwuq3ww/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_162436-3hsozjsa/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_163827-1e1dp6nz/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_164857-3dp6x8rn/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_165332-2jbmriun/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_165544-2erqkfwh/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_165737-2psf88ix/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_170313-1k1myycj/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_171210-4h52tiwx/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_171500-13dcn06j/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_171603-2upkj7pb/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_173120-33amt2gj/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_173154-5juib0we/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_173342-1vjw09fq/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_173606-3fe6bcwv/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_173910-2kr8v5ik/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_174014-1h9z1mxa/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_175741-22nvv6rv/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_181013-3si7rzmg/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_182845-erra08wm/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_185155-1tsucnkn/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_185326-1sjxqfcy/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_185403-2samgi25/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_185631-3c0fy7cm/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_190219-1771kddz/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_192209-v3ed59cq/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_192333-rvclmsan/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_192733-1m8gnxem/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_192842-1vcxw8od/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_193210-30yzadb4/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_193424-2s8kcx3u/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_193754-2tbabocb/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_194622-24ydusom/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_194723-3q8h5qo5/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_194823-4eivjytc/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_195933-awy1x6yx/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_200104-1d5gml5u/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_200224-2i5sl4om/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_200406-mbbbz5ls/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_200551-l7yd6pk4/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_201917-39s1dczq/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_201932-9m5ngsw4/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_201949-d5g3129r/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_201957-1sekbk8a/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_204342-s4derlx8/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_204351-3gtkvv95/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_204403-330lz5of/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_204415-3cavok3t/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_204455-kk0lsomm/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_204504-1bpl06ok/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_204516-ufpf7dvo/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_204529-3vt8237y/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_205300-2b38420l/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_205635-3q0fyny8/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_205803-2qqdhw88/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_210229-2gisbne8/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_210526-p6c4nem8/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_210618-25ldiq5i/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_210716-2hdkaavm/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_210818-a6iq9g1r/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_211020-2qjiv5zu/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_213751-3nidt1aa/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_213816-os29qk1o/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_214232-3vlnx0uu/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_214236-1myx118k/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_214245-2a4m2e1s/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_214255-cwu0ejw8/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_214302-2nk96nkr/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_214308-84rx7pll/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_214313-1of62mls/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_214714-9kaqs08s/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_214832-1pwrgnb0/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_220639-wgmu9c35/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_220739-25gwsjsr/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_220747-xw9fd5dc/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_220759-1922c1s3/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_220810-1s149ieq/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_220816-25q67210/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210929_220823-1a4jlg1n/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210930_005247-u9u262kb/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20210930_010709-acdh9d97/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20211001_124151-1pb52a1z/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20211001_133122-221fe0xw/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20211001_134145-1dv3lfbj/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20211001_134600-1em1uq9v/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20211001_135006-3ecu2ol9/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20211001_135206-1ksbwbcw/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20211001_135600-3lj91wi9/\n\tresults_plots_ml_vs_maml_ml/fall2021/wandb/run-20211001_135946-18loi2se/\n\tresults_plots_sl_vs_ml/fall2021/wandb/\n</code></pre>\n<p>I don\u2019t want to commt that. Thanks charles!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-08T15:53:21.996Z",
				"Answer_body": "<p>They\u2019re the local version of your <code>wandb</code> runs. As <a class=\"mention\" href=\"/u/charlesfrye\">@charlesfrye</a> suggested, you can add <code>wandb</code> to your <code>.gitignore</code>, these files are synced to W&amp;B.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-09T19:39:34.925Z",
				"Answer_body": "<aside class=\"quote group-team\" data-username=\"charlesfrye\" data-post=\"3\" data-topic=\"756\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https://sea2.discourse-cdn.com/business7/user_avatar/community.wandb.ai/charlesfrye/40/52_2.png\" class=\"avatar\"> charlesfrye:</div>\n<blockquote>\n<p>wandb/</p>\n</blockquote>\n</aside>\n<p>Thanks! I will be using:</p>\n<pre><code class=\"lang-auto\"># wand: https://community.wandb.ai/t/what-should-the-gitignore-file-be-when-using-wandb/756/2\nwandb/\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:07.565Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Dataset artifact organization",
		"Question_link": "https://community.wandb.ai/t/dataset-artifact-organization/1495",
		"Question_created_time": "2021-12-09T09:07:50.341Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 401,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Typically pre wandb my approach to organizing dataset was to have lots of subfolders -</p>\n<pre><code class=\"lang-auto\">mnist\n     complete\n          augmented-mild\n          augmented-heavy\n     sampled-examples\n          mnist-1000\n               augmented-mild\n               augmented-heavy\n          mnist-10k\n              augmented-mild\n              augmented-heavy\n   sampled-class-examples\n        mnist-1000-5cls\n        mnist-10k-5cls\n\n</code></pre>\n<p>On going through wandb artifacts docs, it seems it is best to have a flattened structure for dataset versioning. How much flattening is ideal? A complete flattening would mean each of those above to have a different name and same type(say \u201cbalanced-dataset\u201d).Completely flattening dataset hierarchy seems to take away the \u201cversioning\u201d ability of wandb as now all of them are different artifacts.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-09T10:50:17.338Z",
				"Answer_body": "<p>One option you can do if you want each stage of your preprocessing and splitting to be versioned by Artifacts is create new Artifact for each stage. You would have one complete dataset Artifact, and then one for each split of your dataset. You would use <code>run.use_artifact(\"your_artifact_name:latest\")</code> to download the complete dataset, then log new Artifacts after you\u2019ve split it.</p>\n<p>Here\u2019s a W&amp;B Report about that approach: <a href=\"https://wandb.ai/wandb/arttest/reports/Intro-to-W-B-Artifacts--VmlldzozNTAzMDM?galleryTag=posts\" class=\"inline-onebox\">Weights &amp; Biases</a></p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d44bcdeb7122e567bfc0860fdf1ac50e95050ec3.png\" data-download-href=\"/uploads/short-url/ui3DixSQYtzI68dSWnrxDDKwLnR.png?dl=1\" title=\"image\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d44bcdeb7122e567bfc0860fdf1ac50e95050ec3_2_690x275.png\" alt=\"image\" data-base62-sha1=\"ui3DixSQYtzI68dSWnrxDDKwLnR\" width=\"690\" height=\"275\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d44bcdeb7122e567bfc0860fdf1ac50e95050ec3_2_690x275.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d44bcdeb7122e567bfc0860fdf1ac50e95050ec3_2_1035x412.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d44bcdeb7122e567bfc0860fdf1ac50e95050ec3_2_1380x550.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d44bcdeb7122e567bfc0860fdf1ac50e95050ec3_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1566\u00d7626 83.2 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.403Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Track train script version along with hyperaparams (ideally automated)",
		"Question_link": "https://community.wandb.ai/t/track-train-script-version-along-with-hyperaparams-ideally-automated/1479",
		"Question_created_time": "2021-12-06T23:02:22.465Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 228,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m just getting started with experiments, my goal is to ablation-study some potentially new methods for finetuning NLP models. I use HuggingFace trainer and the W&amp;B integration works flawlessly, so the hyperparams are super easy to track. I\u2019m going to be doing some experimentation within the training code though - is there an easy way to track the training script version/content along with the experiments, ideally integrated with Github?  Thanks! Darek</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-08T11:12:17.638Z",
				"Answer_body": "<p>Hi Darek,<br>\nThey sound like interesting experiments, we\u2019re happy you\u2019ve chosen W&amp;B to track them!</p>\n<p>You can track your code by turning on code saving in your settings: <a href=\"https://docs.wandb.ai/ref/app/features/panels/code\">https://docs.wandb.ai/ref/app/features/panels/code</a></p>\n<p>You can also call <code>wandb.run.log_code(\".\")</code> after calling <code>wandb.init()</code> to capture all python source code files in the current directory and all subdirectories as an <a href=\"https://docs.wandb.ai/ref/python/artifact\">artifact</a>.</p>\n<p>Soon you should be able to use <code>wandb</code> Sweeps as a backend of the <code>hyperparameter_search</code> call in HuggingFace if this PR gets merged: <a href=\"https://github.com/huggingface/transformers/pull/14582\" class=\"inline-onebox\">Add W&amp;B backend for hyperparameter sweep by AyushExel \u00b7 Pull Request #14582 \u00b7 huggingface/transformers \u00b7 GitHub</a></p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/ref/app/features/panels/code\">\n  <header class=\"source\">\n      \n\n      <a href=\"https://docs.wandb.ai/ref/app/features/panels/code\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/ref/app/features/panels/code\" target=\"_blank\" rel=\"noopener\">Code Saving</a></h3>\n\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-08T15:55:03.967Z",
				"Answer_body": "<p>Thanks Scott, this is exactly what I needed! Also looking forward to the HF sweep PR <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:07.029Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Best practices for many quick runs?",
		"Question_link": "https://community.wandb.ai/t/best-practices-for-many-quick-runs/1145",
		"Question_created_time": "2021-10-29T00:39:52.556Z",
		"Question_answer_count": 13,
		"Question_score_count": 4,
		"Question_view_count": 579,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have a project where I am doing many, many runs across seeds none of which take a particularly long amount of time and for all of which I would like to log metrics (both the individual run metrics and the group metrics are relevant for me). Unfortunately my compute environment is such that I must run W&amp;B in offline mode (compute nodes are not connected to the internet), and as a result I have found sync to be an extreme bottleneck in my work. Has anyone encountered this kind of issue before and come up with a way to deal with it?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-01T21:24:10.910Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/evanv\">@evanv</a> , thanks for writing in. We\u2019re looking into this for you.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-01T21:26:51.709Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/evanv\">@evanv</a>,</p>\n<p>I\u2019m sorry to hear that the offline to online sync for wandb has been acting as a bottleneck for you. Would you be able to share more context on what commands / a minimal example to reproduce the issues you\u2019ve been running into?</p>\n<p>In the meantime have you tried adjusting the arguments to <code>wandb sync</code> (<a href=\"https://docs.wandb.ai/ref/cli/wandb-sync\" class=\"inline-onebox\">wandb sync - Documentation</a>) to send batches of runs in at a time? Using glob patterns or cleaning you can reduce the load needed when syncing all runs at once</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-02T15:56:55.684Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/a-sh0ts\">@a-sh0ts</a> , sure thing!<br>\nA minimal example for what I am doing looks like this:</p>\n<pre><code class=\"lang-auto\">def do_hyperparam_search():\n    configs = [\n        {'lr': lr, 'lambda': lmbda, 'model_type': m}\n        for lr in [1, 0.1, 0.001]\n        for lmbda in [1, 10, 100]\n        for model_type in ['foo', 'bar']\n    ]\n    for config in configs:\n        run_config(config)\n\n\ndef run_config(config):\n    for seed in range(100):\n        do_wandb_run(seed, config)\n\ndef do_wandb_run(seed, config):\n    torch.manual_seed(seed)\n    wandb.init(config=config, mode='offline')\n    for epoch in range(100):\n        for cls in range(5):\n            wandb.log({'some_metric_for_class': value}, step=epoch)\n    wandb.finish()\n</code></pre>\n<p>I have a particular algorithm I am testing which is only sometimes convergent, so it is necessary to run it over many different seed and view both the average behavior and the variance in this behavior. The issue I am running into is that doing even just one run with a particular config produces hundreds of runs, and testing over different hyperparameter configurations multiplies the issue. Unfortunately my compute nodes are all offline so I have to manually synch all my runs. Although I have been using <code>wandb sync --sync-all</code>, when I have thousands of runs that also becomes untenable. Is there a better way I can run these experiments?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-03T10:18:30.749Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/evanv\">@evanv</a>!<br>\nYou could try using <a href=\"https://docs.wandb.ai/guides/sweeps\">W&amp;B Sweeps</a> and use the <code>bayes</code>/<code>random</code> search strategies. In these cases, you wouldn\u2019t be searching the entire space but you would get a good picture of the search landscape without needing to. That would then reduce the number of runs you\u2019d have to sync with <code>wandb</code>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-03T13:33:55.892Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/_scott\">@_scott</a> , thanks so much for the advice! I have been wanting to integrate Sweeps in for a while but was not quite clear how they would work\u2013if I create a sweep will it only require me to synch one file (for the sweep) or all the runs associated with the sleep. The primary multiplicity in my code comes from the fact that I have to run 100 seeds per configuration.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-03T14:22:32.546Z",
				"Answer_body": "<p>You\u2019ll still have to sync your runs if you want to view them in W&amp;B.</p>\n<blockquote>\n<p>The primary multiplicity in my code comes from the fact that I have to run 100 seeds per configuration.</p>\n</blockquote>\n<p>Wow, that\u2019s a lot of seeds. I\u2019ll move this back into \u201cW&amp;B Best Practises\u201d and hopefully someone in the community has seen this and can give some advice. You could also try <code>wandb local</code> which would mean you have your own self-hosted W&amp;B, this would be a require a bit of upfront time investment but would likely speed up that syncing bottleneck.</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/guides/self-hosted/local\">\n  <header class=\"source\">\n      \n\n      <a href=\"https://docs.wandb.ai/guides/self-hosted/local\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/guides/self-hosted/local\" target=\"_blank\" rel=\"noopener\">Local</a></h3>\n\n  <p>Run Weights and Biases on your own machines using Docker</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-05T13:52:39.297Z",
				"Answer_body": "<p>Got it. Thanks for the advice. I will look into wandb local to see whether it is tenable to set it up on my system. If anyone else has advice it is welcomed too <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-19T18:21:12.532Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/evanv\">@evanv</a>!</p>\n<p><a class=\"mention\" href=\"/u/_scott\">@_scott</a> 's advice using <code>wandb sweeps</code>and/or <code>wandb local</code> should have hopefully helped with some of your issues with logging/syncing large volumes of runs in an offline setting. The engineering team is aware of the problems you\u2019re facing and would love to hear suggestions on behavior around this!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-20T03:17:55.694Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/a-sh0ts\">@a-sh0ts</a> , thanks so much for making the engineering team aware! I have been thinking a bit about what optimal functionality would be for me. On a day to day, I mostly care about some kind of statistic related to the seeds I am collecting (mean, median, max, etc\u2026) as well as standard errors of this statistic across runs. Perhaps setting up functionality to store only these statistics, rather than all the information across all runs, would allow for efficient storage and processing of the data?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-08T11:35:45.096Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/evanv\">@evanv</a>,<br>\nIn the case where you want to limit the data you\u2019re logging, you could aggregate that data locally and only log the summary metrics to W&amp;B for comparison.<br>\nYou would do this by just setting</p>\n<pre><code class=\"lang-python\">wandb.run.summary['my_metric'] = the_final_metric_you_care_about\n</code></pre>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/ref/python/summary\">\n  <header class=\"source\">\n      \n\n      <a href=\"https://docs.wandb.ai/ref/python/summary\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/ref/python/summary\" target=\"_blank\" rel=\"noopener\">wandb.summary</a></h3>\n\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>I\u2019m aware that leaves a bit of work for you to do on your end. You would replace your <code>wandb.log</code> calls to only log to a list or np.array, then you would do the different calculations yourself and log them to <code>wandb.run.summary</code> after the run is complete.<br>\nHope this helps</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-08T14:41:14.278Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/_scott\">@_scott</a> ,</p>\n<p>Thanks so much for the suggestion! Unfortunately I am not sure that would solve the issue I am dealing with since the bottleneck is really the uploading of so many runs files (each of which is relatively small) to wandb. Currently what I do is run all seeds and aggregate locally and then upload the aggregate of all runs to wandb, but unfortunately this loses the level of distributional information about statistics that wandb provides when i upload all the runs. Another (maybe better?) solution to this problem could be creating a method to do batch uploading of wandb runs rather than having to synch each one individually. Is there a functionality like that which already exists?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-08T15:48:48.179Z",
				"Answer_body": "<p>That exact function doesn\u2019t already exist, but you can use <code>--include-globs</code> to do it yourself batch by batch. This isn\u2019t ideal but could potentially speed up your syncing.</p>\n<p>Here\u2019s an example command for that, within <code>wandb</code>:</p>\n<p><code>wandb sync --include-globs offline-run-20211208_15*</code></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-06T15:48:51.431Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Handling imbalance dataset without altering the original dataset",
		"Question_link": "https://community.wandb.ai/t/handling-imbalance-dataset-without-altering-the-original-dataset/1472",
		"Question_created_time": "2021-12-05T11:04:27.373Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 257,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>i tried several methods to handle imbalanced datasets</p>\n<p>i used a simple single neuron ANN as a logistic regression model and a churn dataset</p>\n<p>under- and oversampling worked well (especially SMOTE) but to get deeper understanding i wonder if there are even simpler ways to do than altering the original dataset?</p>\n<p>my questions (sorry, too many of them):</p>\n<ol>\n<li>\n<p>is changing the threshold value after training a model a usual and proper/professional way to handle imbalance dataset classification problem?</p>\n<ul>\n<li>if so, how to do it? just run over the trained model and test data modifying threshold and calculating f1?<br>\nis the best threshold where F1 score is the highest?</li>\n</ul>\n</li>\n<li>\n<p>is it a good idea to try to find a model with best AUC score using wandb sweeps and then find the best threshold value of that model maximizing the F1 score?</p>\n</li>\n<li>\n<p>what if i train a model with a threshold value other than 0.5</p>\n<ul>\n<li>doing wandb sweeps finding the best AUC or f1 score?</li>\n</ul>\n</li>\n<li>\n<p>applying class weights will help to improve recall but in return precision will decrease</p>\n<ul>\n<li>how to make it right? how to maximize F1 score?</li>\n</ul>\n</li>\n<li>\n<p>does it improve my model if i add one or more hidden layers to it?</p>\n</li>\n</ol>\n<p>thank you!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-07T20:57:47.005Z",
				"Answer_body": "<p>can you help me?  <a class=\"mention\" href=\"/u/bhutanisanyam1\">@bhutanisanyam1</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-08T11:29:35.517Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/teamtom\">@teamtom</a></p>\n<p>These are all good questions and I wouldn\u2019t say there\u2019s concrete answers that apply in all cases.</p>\n<p>For tuning the output of your model, choosing a threshold value is generally a tradeoff between False Positives versus False Negatives. It\u2019s a consideration you\u2019ll want to make depending on the task. If getting the highest F1 is all you care about, then tuning your threshold to achieve this is ok. The only extra consideration here is to be sure to not tune to a test set, because that\u2019s considered bad practise.</p>\n<p>I would say for questions 1-4, they\u2019re all pretty similar and the answer is generally that it depends how you want your system to behave.</p>\n<p>For question 5, for questions like these where you\u2019re considering your model architecture, I would say you are better off using off the shelf architectures and understanding how they work by reading the papers that introduced them. The <a href=\"https://github.com/rwightman/pytorch-image-models\">Timm library</a> is a good resource to find image architectures and papers. Generally, more model capacity is a good thing, but deeper models can cause issues like vanishing gradients so there are approaches to overcome these like skip connections etc. For those reasons, it can often be a good idea to choose off-the-shelf architectures that\u2019ll fit on your machine.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.969Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb.watch not logging parameters",
		"Question_link": "https://community.wandb.ai/t/wandb-watch-not-logging-parameters/1197",
		"Question_created_time": "2021-11-02T14:31:07.980Z",
		"Question_answer_count": 19,
		"Question_score_count": 1,
		"Question_view_count": 417,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I just started to use w&amp;b to monitor the training of my few-shot learning NNs in Pytorch. I use wandb.watch(model, log=\u2018all\u2019) but it only logs the gradients. Any idea what could be causing this? Also, is there an easy way to log the activation histograms of the different layers for pytorch?</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-03T14:20:17.285Z",
				"Answer_body": "<p>Hi Nora, that is an interesting bug. The default is to log gradients. Can you try putting \u201call\u201d in double quotes instead of single quotes?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-03T16:22:39.471Z",
				"Answer_body": "<p>Hi Leslie,</p>\n<p>Thanks for the reply. Unfortunately, the double quotes didn\u2019t change the result, still only gradients. When I put \u2018parameters\u2019 nothing is logged.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-04T15:23:53.687Z",
				"Answer_body": "<p>Can you tell me what version of wandb you\u2019re using?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-05T09:10:05.410Z",
				"Answer_body": "<p>I recently installed it, version is wandb 0.12.5.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-15T15:48:59.267Z",
				"Answer_body": "<p>Are you using wandb.log in your code?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-15T17:28:52.053Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/norav\">@norav</a> , you might want to make sure if you\u2019re logging at least one piece of data with <code>wandb.log()</code> <strong>first</strong>. Also, it would be worth mentioning that we only log gradients every 1000 steps by default.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-18T16:52:07.945Z",
				"Answer_body": "<p>Hi Nora, we wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-19T09:52:31.833Z",
				"Answer_body": "<p>Hi Leslie,</p>\n<p>The issue has not been resolved. I do use wandb.log() in my code for the loss and I use it now as well to log the parameters using hooks. I\u2019m afraid this slows down my code but see no other solution since wandb.watch() is only logging gradients.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-22T16:36:24.771Z",
				"Answer_body": "<p>Can you let us know how many steps you are running?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-25T11:43:13.037Z",
				"Answer_body": "<p>I am running 50-100 steps. I use the command watch(model, log=\u2018all\u2019, log_freq=1)</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-01T19:34:21.420Z",
				"Answer_body": "<p>Can you send an image of what you see on your dashboard as to what is appearing and give us a script of how you are implementing wandb.log into your code?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-02T15:40:54.418Z",
				"Answer_body": "<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/17f2c16284d2751c60649611a962c64992e1497e.png\" data-download-href=\"/uploads/short-url/3pR58CbGFOHxQpDJumZ9RJM8ca2.png?dl=1\" title=\"panelwb\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/17f2c16284d2751c60649611a962c64992e1497e_2_690x405.png\" alt=\"panelwb\" data-base62-sha1=\"3pR58CbGFOHxQpDJumZ9RJM8ca2\" width=\"690\" height=\"405\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/17f2c16284d2751c60649611a962c64992e1497e_2_690x405.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/17f2c16284d2751c60649611a962c64992e1497e_2_1035x607.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/17f2c16284d2751c60649611a962c64992e1497e.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/17f2c16284d2751c60649611a962c64992e1497e_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">panelwb</span><span class=\"informations\">1197\u00d7704 25.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nThis is the dashboard where I only get the gradients, not the parameters.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-02T15:42:55.570Z",
				"Answer_body": "<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/363b37aefcf9ef3c5681e1df6a1a3f8c1ef0c5c2.png\" data-download-href=\"/uploads/short-url/7JKEGYOa3SP7bDY1ts5q71113NM.png?dl=1\" title=\"wan\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/363b37aefcf9ef3c5681e1df6a1a3f8c1ef0c5c2.png\" alt=\"wan\" data-base62-sha1=\"7JKEGYOa3SP7bDY1ts5q71113NM\" width=\"690\" height=\"85\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/363b37aefcf9ef3c5681e1df6a1a3f8c1ef0c5c2_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">wan</span><span class=\"informations\">1294\u00d7160 9.55 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Here I initialize the wandb run and I pass it to the train functino (wrapper.fit()) where I log the loss with the next code snippet</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-02T15:43:27.327Z",
				"Answer_body": "<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/86e52e1bb508b59925192897385b870cd9694f8b.png\" alt=\"loggingwb\" data-base62-sha1=\"jfkZP5Bitmo6D7bFouZRrzpqzXl\" width=\"649\" height=\"112\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-03T17:37:11.752Z",
				"Answer_body": "<p>Can you use wandb.log once before you use wanbd.watch? Wandb.watch won\u2019t work properly if wandb.log is not there beforehand</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-06T13:09:36.367Z",
				"Answer_body": "<p>Still no parameters with logging something before the watch:<br>\nrun.log({\u2018trainidx\u2019:trainidx})<br>\nrun.watch(model, log='all, log_freq=1)</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-06T20:07:23.430Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/norav\">@norav</a> , is there any chance you\u2019re calling <code>model.forward(inputs)</code> instead of <code>model(inputs)</code>? Also, if you could share your script, that would be very helpful to reproduce the issue.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-07T10:24:01.906Z",
				"Answer_body": "<p>Yes this seems to be it. Thank you!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-05T10:24:20.399Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "App UI Bug: Can't see project's artifacts when it has no runs",
		"Question_link": "https://community.wandb.ai/t/app-ui-bug-cant-see-projects-artifacts-when-it-has-no-runs/1461",
		"Question_created_time": "2021-12-02T19:23:43.932Z",
		"Question_answer_count": 5,
		"Question_score_count": 1,
		"Question_view_count": 348,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>First, you may call it <em>a flaw</em> instead of <em>a bug</em> if you like. Second, I am not sure if this is a bug in the App UI or a flaw in your data model (I am new to WandB). Third, I am not sure if I am supposed to report bugs here, on github, or elsewhere. I could not find a non-public means of communicating this.</p>\n<p><strong>Expected behaviour.</strong><br>\nI should be able to see all artifacts created and/or used within a given project via App UI (my browser) at all times. If the project has no artifacts, then I should see an explicit indication of that fact, just as on the first screenshot.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/fd930d039ffbcbc6df6018430d9da2148658814a.png\" data-download-href=\"/uploads/short-url/AbdR0zySJTKb4nfew90jfroE6W6.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/fd930d039ffbcbc6df6018430d9da2148658814a_2_345x227.png\" alt=\"image\" data-base62-sha1=\"AbdR0zySJTKb4nfew90jfroE6W6\" width=\"345\" height=\"227\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/fd930d039ffbcbc6df6018430d9da2148658814a_2_345x227.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/fd930d039ffbcbc6df6018430d9da2148658814a_2_517x340.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/fd930d039ffbcbc6df6018430d9da2148658814a_2_690x454.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/fd930d039ffbcbc6df6018430d9da2148658814a_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">741\u00d7489 27.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p><strong>Observed behaviour.</strong><br>\nThe \u201cArtifacts\u201d icon on the side panel disappears when a project has no runs, <em>whether there are artifacts or not</em>.  As depicted on the second screenshot.</p>\n<p><strong>What I did.</strong><br>\nAll I did between the first and the second screenshots was deleting the only remaining (and empty) run within this project.</p>\n<p><strong>Why the observed behaviour is problematic:</strong></p>\n<ul>\n<li>If there are no artifacts in the project, I do not get an <em>explicit</em> confirmation of that.</li>\n<li>I cannot see the remaining artifacts if they still exist.</li>\n<li>Basically, you are forcing the user to keep a dummy run in a project, so that the bloody icon stays in place. (Figuratively speaking, because it\u2019s not just an icon issue: if you type the <code>/entity/project/artifacts/</code> in the address bar, you still can\u2019t get there)</li>\n</ul>\n<p>Now, you may argue that artifacts are attached to runs, and not to projects, therefore all artifacts created in a project that has become run-less are doomed to be orphaned (i.e., neither \u201cused\u201d, nor \u201clogged\u201d by any run), therefore they will be garbage-collected sooner or later, therefore there is no reason for the Artifacts tab. But this does not make sense for two reasons. First, why not keep the Artifact tab anyways? Second, if the user creates a dummy run so that the Artifact tab comes back, he/she will be able to see the orphaned artifacts, as shown on the third screenshot.<br>\nHere\u2019s how I produced the third screenshot. I created a run and \u201cused\u201d a new artifact in this run, all via Python interface. Then I deleted the run, leaving the artifact orphaned. Then I created a new run within the same project, went back to the Artifact tab and found the orphaned artifact from the first run, as on the screenshot. If artifacts are attached to runs and not to projects, why does WandB show the orphaned artifact in this project\u2019s tab?</p>\n<hr>\n<p>P.S. Many thanks for all your work and, of course, for making your product available for free. But I can\u2019t help but point out that to facilitate neat and well-organised data science, WandB should be transparent, understandable, and predictable. So far, I have been having a hard time understanding your model and figuring out things like the unexpected difference between <code>wandb.sdk.wandb_run.Run</code> and <code>wandb.apis.public.Run</code>. I can\u2019t understand why any deviation from the simplest use cases and \u201cBest Practices\u201d must be so painful that it may be easier to re-run all experiments in order to correct how they are logged in WandB than to correct the record directly.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-02T19:24:30.383Z",
				"Answer_body": "<p>Second screenshot.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/145f6670e50f371e8dc4637aa4016bf6672b6c6d.png\" data-download-href=\"/uploads/short-url/2UdWu52XaxZOKzQYr6FkybVCKKh.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/145f6670e50f371e8dc4637aa4016bf6672b6c6d_2_345x235.png\" alt=\"image\" data-base62-sha1=\"2UdWu52XaxZOKzQYr6FkybVCKKh\" width=\"345\" height=\"235\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/145f6670e50f371e8dc4637aa4016bf6672b6c6d_2_345x235.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/145f6670e50f371e8dc4637aa4016bf6672b6c6d_2_517x352.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/145f6670e50f371e8dc4637aa4016bf6672b6c6d_2_690x470.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/145f6670e50f371e8dc4637aa4016bf6672b6c6d_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">691\u00d7471 26.6 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-02T19:25:08.501Z",
				"Answer_body": "<p>Third screenshot.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/17dcfd656a9b968d4c39eb3c51233a116d690a12.png\" data-download-href=\"/uploads/short-url/3p6rV7M025AZbMVaNZbv59XoKIy.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/17dcfd656a9b968d4c39eb3c51233a116d690a12_2_345x241.png\" alt=\"image\" data-base62-sha1=\"3p6rV7M025AZbMVaNZbv59XoKIy\" width=\"345\" height=\"241\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/17dcfd656a9b968d4c39eb3c51233a116d690a12_2_345x241.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/17dcfd656a9b968d4c39eb3c51233a116d690a12_2_517x361.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/17dcfd656a9b968d4c39eb3c51233a116d690a12_2_690x482.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/17dcfd656a9b968d4c39eb3c51233a116d690a12_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">841\u00d7589 24.3 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-02T20:14:27.078Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/avm21\">@avm21</a>,</p>\n<p>Thanks for reporting this! It does indeed look like a bug on our end.  In general, I would start on GitHub for bug reporting, just to see if someone else has already filed the same bug; however, it is totally fine to post bugs and issues here as well. Alternatively if you want to get more direct support you can chat with the support team from our website 5am-5pm PST on Weekdays or email us at <a href=\"mailto:support@wandb.com\">support@wandb.com</a>.</p>\n<p>Circling back to your issue, I would log  a dummy run in the interim so you can see your artifacts in the UI; however, they should still be accessible via the public API and the <code>run.use_artifact()</code> method.</p>\n<p>I\u2019ll post back on this thread when I have an update on the bug fix.</p>\n<p>All the best,</p>\n<p>Aidan</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2021-12-02T20:35:16.529Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/aidanjd\">@aidanjd</a></p>\n<p>Thanks for your prompt and to-the-point response! I\u2019ll be checking this thread for any updates.</p>\n<p>Kind regards,<br>\navm21</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-31T20:36:08.005Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Local mirror of artifacts",
		"Question_link": "https://community.wandb.ai/t/local-mirror-of-artifacts/1422",
		"Question_created_time": "2021-11-28T11:43:34.764Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 547,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi<br>\nIs there an api to maintain a local mirror for artifacts?</p>\n<p>This way the artifact is downloaded only once (till it\u2019s remote update <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>\n<p>For example:</p>\n<pre><code class=\"lang-auto\">artifact.download(mirror_dir=XXX)\nor\nrun.use(artifact, mirror_dir=XXX)\n</code></pre>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/guides/artifacts/api\">\n  <header class=\"source\">\n      \n\n      <a href=\"https://docs.wandb.ai/guides/artifacts/api\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/guides/artifacts/api\" target=\"_blank\" rel=\"noopener\">Artifacts Walkthrough</a></h3>\n\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>Thanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-02T21:04:56.999Z",
				"Answer_body": "<p>Hi Chen, can you elaborate more on your question? Is this mirror for wandb offline? What is the use case for this feature?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-06T13:25:27.264Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-09T14:31:46.624Z",
				"Answer_body": "<p>Hi Chen, I\u2019m going to close this ticket, but please respond to this thread if you want me to open it up again.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-19T09:12:58.363Z",
				"Answer_body": "<p>Hi Leslie</p>\n<p>Sorry, was OOO and missed your messages \u2026</p>\n<p>The scenario is as ffolows:</p>\n<ul>\n<li>\n<p>An atrtifact is generated and uploaded to wandb</p>\n</li>\n<li>\n<p>Later, one wants to use this artifact</p>\n</li>\n<li>\n<p>So he has to download it</p>\n</li>\n</ul>\n<p>\u2013 However if someone is using the same artifact 100 times on the same machine, it\u2019ll be much more efficient to download it <em>once</em> to the machine.</p>\n<ul>\n<li>\n<p>So first download should be saved locally for example in <em>mirror_dir</em> .</p>\n</li>\n<li>\n<p>Then, next 99 times the artifact will be taken from <em>mirror_dir</em> instead of re-downloading it 99 times,</p>\n</li>\n</ul>\n<p>Is the need more clear now?</p>\n<p>Thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-21T16:58:00.921Z",
				"Answer_body": "<p>That helps a lot thank you! We actually have a ticket to create a local mirror and I\u2019ll respond here whenever it is finished.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-27T11:44:07.851Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Publishing Graphs/Visualizations",
		"Question_link": "https://community.wandb.ai/t/publishing-graphs-visualizations/1457",
		"Question_created_time": "2021-12-02T14:45:42.347Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 216,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I\u2019m soon going to start implementing W&amp;B for my neural network\u2019s hyperparameter tuning. This is in preparation for an academic paper I\u2019m writing on the subject. The software seems very pragmatic and well-polished, so I\u2019m quite excited to get started.</p>\n<p>Its visualizations in particular seem to be of a very high quality. Some present sophisticated functionality that other experiment trackers can\u2019t touch. With proper citation, can these be included for publication?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-12-02T17:40:47.308Z",
				"Answer_body": "<p>Hi Logan,</p>\n<p>I\u2019m so happy you\u2019re excited to use our product! Our engineers have worked very hard in order to get it to where it is today. We would love for you to use our graphs in your paper. We have a few examples of how to do so here (<a href=\"https://docs.wandb.ai/company/academics#cite-weights-and-biases\" class=\"inline-onebox-loading\">https://docs.wandb.ai/company/academics#cite-weights-and-biases</a>).</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2021-12-06T13:25:54.781Z",
				"Answer_body": "<p>Hi Logan,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-09T14:33:11.838Z",
				"Answer_body": "<p>Hi Logan,</p>\n<p>I\u2019m going to close this ticket, but if you have any more questions regarding wandb please let me know!</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-31T14:46:26.430Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to save/restore model using artifact on servers that do not have internet access?",
		"Question_link": "https://community.wandb.ai/t/how-to-save-restore-model-using-artifact-on-servers-that-do-not-have-internet-access/1313",
		"Question_created_time": "2021-11-16T05:24:40.243Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 345,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I just started using wandb tools. According to the instruction <a href=\"https://docs.wandb.ai/ref/python/save\">here</a>, it suggests using Artifact for new code to save models. And I am able to save the model in the offline mode. However, I wonder how to restore the model from an artifact with a particular version (e.g., v3, not necessarily the latest version of the artifact) if I want to resume the training after it\u2019s interrupted?</p>\n<p>I am running code on compute nodes that do not have access to internet, so I have to use the offline mode. And in offline mode, I cannot run <code>use_artifact</code> command as it only works in online mode. However, I think all the artifact data is already saved locally using <code>log_artifact</code> command. So in theory, I should be able to restore a particular version of the artifact? How can I get that? Even though I know the model file location, it is the latest model file, not a particular history version of the model file (that\u2019s the point of using Artifact to track the model?).</p>\n<pre><code class=\"lang-auto\">    run = wandb.init(mode='offline', project='test')\n    artifact = run.use_artifact('hello-world:v3')\n    artifact_dir = artifact.download(root=run.dir)\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-23T16:12:26.922Z",
				"Answer_body": "<p>Hey Tao,</p>\n<p>checking on this for you.</p>\n<p>Best,<br>\nArman</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-30T13:56:39.151Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/armanharutyunyan\">@armanharutyunyan</a> Hi Arman, did you find a solution by any chance? Thanks.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-02T10:59:40.420Z",
				"Answer_body": "<p>Hey Tao, sorry about the delay on this. The offline run will be logged within your <code>wandb</code> folder that gets generated. You can access the run given the <code>run_id</code> by constructing the path and accessing the <code>files</code> within the directory. Other than that there is no way to access offline runs</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-31T11:00:13.207Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "What is the best way to log multi-stage pipelines?",
		"Question_link": "https://community.wandb.ai/t/what-is-the-best-way-to-log-multi-stage-pipelines/1323",
		"Question_created_time": "2021-11-17T07:29:48.035Z",
		"Question_answer_count": 5,
		"Question_score_count": 4,
		"Question_view_count": 412,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\nIn the project we have a multi-stage pipeline where each stage has a set of hyperparameters. It looks something like that:<br>\n<code>preprocesing -&gt; vectorization -&gt; clustering</code></p>\n<p>For sake of simplicity, let\u2019s assume that each stage has a single hyperparameter:</p>\n<pre><code class=\"lang-auto\">preprocesing: cutoff_threshold\nvectorizaiton: model_name\nclustering: num_clusters\n</code></pre>\n<p>Currently each stage logs everything in a separate run. All stages from a single run are grouped into a single group .</p>\n<p>At the moment we are doing hyperaparemeter sweep naively and we end up running whole pipeline 8 times (2x2x2) and using grouping feature we can nicely compare how changing hyperparameters of each stage affected end results.</p>\n<p>However preprocessing and vectorization steps are quite compute-intensive. In theory, in described setup we would only need to run preprocessing twice and vectorization 4 times (instead of 8 runs of each one). However then we can not (or at least i can\u2019t think of a way) group such runs so that we can get a nice sweep view. I.e. whe can not inform wandb which run of <code>clustering</code> was based on which run of <code>vectorization</code> and <code>preprocessing</code></p>\n<p>I wonder if what is the best way to setup such a pipeline in wandb?</p>\n<p>Thanks,<br>\nMicha\u0142</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-20T08:46:42.110Z",
				"Answer_body": "<p>Thanks for joining the forum and posting this great question, this is the exact type of thing we had in mind for this category.</p>\n<p>I think I need to clarify things to properly understand your question. Are you hoping for sweeps to help you with ablation studies, doing <em>conditional</em> steps based on earlier parts of the pipeline? I wonder if you could use tags to help with this, so that each run doesn\u2019t have to be only in one collection.</p>\n<p>I\u2019m going to ask around and have a think myself to see if we can find a way to do this nicely, otherwise I can +1 this to make it into the product roadmap to support these kind of efforts.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-29T14:04:11.197Z",
				"Answer_body": "<p>Hi Scott, thanks for your quick reply and sorry for such a slow response on my part</p>\n<p>Yes, you pretty much spot on wha I would like to do. I have multiple steps that are only conditional on the previous steps (a fairly typical data processing + training DAG). More than one step in such a DAG is parameterized, and there is no obvious way to tell in advance how the parameters from each step interact and how the composition of specific hyperparameter values affects the final model performance. Ideally I would like to somehow have a summarised view of all the hyperparameters combinations used in the pipleine in a table, sort by the final metrics score and then see what I should focus on and what not.</p>\n<p>Currently the only ways I can think of to do it is to run the whole pipeline each time  and then group the results or log hyperparametrs for each stage offline (eg. to a file) and pushing it to wandb only on the final stage. Both are not ideal, as the first one is quite slow and the second one seems cumbestone (however it does work)</p>\n<p>I also thought about somehow using tags, however, If I undersetand correctly, tags can only be using for filtering. So if I have a 3-stage grid search of 2x2x2, In the table/sweep view I would like to have 8 entries, however if I can only filter (reduce number of runs), I would end up with maximum of 2 entries (as I have only 2 runs of first stage)</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-01T12:50:40.905Z",
				"Answer_body": "<p>An option here would be to use W&amp;B Artifacts as a way to capture the state of expensive parts of the pipeline. You could build logic that would save each combination of the steps, and then you could consume those artifacts if that ablation had already occurred. This is an interesting idea which I haven\u2019t fully explored but I think it would be a really useful approach that would stop a lot of redundant computation.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:01:44.133Z",
				"Answer_body": "<p>Hi Scott, thanks for your quick reply and sorry for such a slow response on my part</p>\n<p>Yes, you pretty much spot on wha I would like to do. I have multiple steps that are only conditional on the previous steps (a fairly typical data processing + training DAG). More than one step in such a DAG is parameterized, and there is no obvious way to tell in advance how the parameters from each step interact and how the composition of specific hyperparameter values affects the final model performance. Ideally I would like to somehow have a summarised view of all the hyperparameters combinations used in the pipleine in a table, sort by the final metrics score and then see what I should focus on and what not.</p>\n<p>Currently the only ways I can think of to do it is to run the whole pipeline each time and then group the results or log hyperparametrs for each stage offline (eg. to a file) and pushing it to wandb only on the final stage. Both are not ideal, as the first one is quite slow and the second one seems cumbestone (however it does work)</p>\n<p>I also thought about somehow using tags, however, If I undersetand correctly, tags can only be using for filtering. So if I have a 3-stage grid search of 2x2x2, In the table/sweep view I would like to have 8 entries, however if I can only filter (reduce number of runs), I would end up with maximum of 2 entries (as I have only 2 runs of first stage)</p>\n<p>[Discourse post]</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.929Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How is one suppose to do custom logging in wandb especially with the x-axis?",
		"Question_link": "https://community.wandb.ai/t/how-is-one-suppose-to-do-custom-logging-in-wandb-especially-with-the-x-axis/1400",
		"Question_created_time": "2021-11-27T00:58:10.752Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 247,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I feel I\u2019ve discussed this with someone somewhere (perhaps a gitissue\u2026can\u2019t find it!) but I can\u2019t find it and now I came back and can\u2019t figure out why my wandb command looks the way it does:</p>\n<pre><code class=\"lang-auto\">        # - log to wandb\n        if log_to_wandb:\n            if it == 0:\n                wandb.define_metric(\"train loss\", step_metric=it_or_epoch)\n                wandb.define_metric(\"train acc\", step_metric=it_or_epoch)\n                wandb.define_metric(\"val loss\", step_metric=it_or_epoch)\n                wandb.define_metric(\"val val\", step_metric=it_or_epoch)\n                # if mdl_watch_log_freq == -1:\n                #     wandb.watch(args.base_model, args.criterion, log=\"all\", log_freq=mdl_watch_log_freq)\n            # - log to wandb\n            wandb.log(data={it_or_epoch: it,  # custom step,\n                            'train loss': train_loss,\n                            'train acc': train_acc,\n                            'val loss': val_loss,\n                            'val acc': val_acc},\n                            commit=True)\n            # if it == total_its:  # not needed here, only needed for normal SL training\n            #     wandb.finish()\n</code></pre>\n<p>can someone help me decipher what this was supposed to mean? Especially the commit option?</p>\n<hr>\n<p>related:</p>\n<ul>\n<li><a href=\"https://docs.wandb.ai/guides/track/log\">https://docs.wandb.ai/guides/track/log</a></li>\n<li><a href=\"https://docs.wandb.ai/guides/track/log#customize-axes-and-summaries-with-define_metric\">https://docs.wandb.ai/guides/track/log#customize-axes-and-summaries-with-define_metric</a></li>\n<li><a href=\"https://colab.research.google.com/drive/1uegSY1HRGlKfK-07Uuw-ZxPJsNA9BN_9#scrollTo=0BIYhmSROGmq\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Google Colab</a></li>\n<li><a href=\"https://github.com/wandb/examples/issues/89\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Why isn't wandb logging at the last iteration? (when I want to log figs, ckpts etc) \u00b7 Issue #89 \u00b7 wandb/examples \u00b7 GitHub</a></li>\n</ul>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-30T16:14:34.730Z",
				"Answer_body": "<p>Hi Brando,<br>\nIt looks like it is logging steps to our UI. To know more about commit = True, look at this doc <a href=\"https://docs.wandb.ai/guides/track/log#stepwise-and-incremental-logging\" class=\"inline-onebox-loading\">https://docs.wandb.ai/guides/track/log#stepwise-and-incremental-logging</a></p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-03T17:42:01.407Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-06T19:48:01.472Z",
				"Answer_body": "<p>Hi Brando, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-26T00:59:08.848Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How does one change how wandb logs/prints to my screen so that it always shows it?",
		"Question_link": "https://community.wandb.ai/t/how-does-one-change-how-wandb-logs-prints-to-my-screen-so-that-it-always-shows-it/1401",
		"Question_created_time": "2021-11-27T03:05:55.385Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 234,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I think wandb might be logging with some <code>WARN</code> flag or something because I can\u2019t always see the printing when I <code>tail -f </code> my scripts output.</p>\n<p><strong>How do I change wandb\u2019s settings so that it prints to stdout?</strong></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-30T16:56:11.519Z",
				"Answer_body": "<p>Hi Brando,</p>\n<p>Can you clarify where you are logging to, and what you are trying to see from your logs. Can you also clarify if you are unable to see any wandb system messages from your script in general.</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-03T17:42:34.896Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-06T19:46:44.512Z",
				"Answer_body": "<p>Hi Brando, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-26T03:06:32.992Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Account storage not being freed?",
		"Question_link": "https://community.wandb.ai/t/account-storage-not-being-freed/1375",
		"Question_created_time": "2021-11-23T22:42:27.325Z",
		"Question_answer_count": 6,
		"Question_score_count": 0,
		"Question_view_count": 254,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I deleted all my projects in order to free up my account storage, but the usage dashboard page still shows it as being used. 36gb of the 100gb available to be precise. Isn\u2019t it supposed to be reclaimed after the projects/artifacts are deleted?</p>\n<p>I used all this space just by uploading some Driverless AI (<a href=\"https://www.h2o.ai/products/h2o-driverless-ai/\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">H2O Driverless AI | H2O.ai</a>) models and temporary files I was experimenting with. But if I certainly won\u2019t continue doing this if this space is gone for good.</p>\n<p>I can\u2019t really complain as I\u2019ve a free account, but I wonder if you are charging your paying customers for deleted files too\u2026</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-25T13:11:02.558Z",
				"Answer_body": "<p>Hey there,</p>\n<p>The storage should be reclaimed. This appears to be a bug on our end. Can you tell me your username so I can take a look?</p>\n<p>Best,<br>\nArman</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-27T01:17:23.798Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/armanharutyunyan\">@armanharutyunyan</a>, my account is <code>ogoid</code>, thanks.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-10T05:12:02.603Z",
				"Answer_body": "<p>Hello! Our engineers are aware of the issue and will be working to ensure the storage you see matches the actual amount of storage you occupy.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-23T14:57:11.387Z",
				"Answer_body": "<p>Hello Andreas,</p>\n<p>The issue with the incorrectly displayed used storage has been fixed. I have double checked your account to ensure all is proper. Let me know if you still are facing any issues.</p>\n<p>Regards,<br>\nAnish</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-23T14:58:20.713Z",
				"Answer_body": "<p>Hello Andreas,</p>\n<p>There actually still seems to be lingering issues which I have escalated to our engineers. Ignore the last message.</p>\n<p>Regards,<br>\nAnish Shah</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-26T01:18:10.436Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "New to Wandb making sense of the gradient dashboard, am I seeing exploding gradients?",
		"Question_link": "https://community.wandb.ai/t/new-to-wandb-making-sense-of-the-gradient-dashboard-am-i-seeing-exploding-gradients/1388",
		"Question_created_time": "2021-11-25T14:59:42.246Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 400,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi</p>\n<p>I\u2019m running my first experiments with weights and biases, I find it pretty cool and quite intuitive to use.</p>\n<p>The dashboard is a little confusing at the moment though<br>\nI have random initialized weights, and they seem to gro pretty quickly and then stagnate.<br>\nThe absolute value still seems very small so I\u2019m not sure fi this is due to scaling, are these exploding gradients?</p>\n<p>Thanks for any insights and help understanding and getting the most out of this awesome tool.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9d1ac40d14dfafcdf60d54ece33952b38cc444ac.png\" data-download-href=\"/uploads/short-url/mpOj7osjgYRoiIi15BRgeygWpEE.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9d1ac40d14dfafcdf60d54ece33952b38cc444ac_2_690x235.png\" alt=\"image\" data-base62-sha1=\"mpOj7osjgYRoiIi15BRgeygWpEE\" width=\"690\" height=\"235\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9d1ac40d14dfafcdf60d54ece33952b38cc444ac_2_690x235.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9d1ac40d14dfafcdf60d54ece33952b38cc444ac_2_1035x352.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9d1ac40d14dfafcdf60d54ece33952b38cc444ac_2_1380x470.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9d1ac40d14dfafcdf60d54ece33952b38cc444ac_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1785\u00d7610 53.4 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-30T14:51:53.855Z",
				"Answer_body": "<p>Hi Oliver,</p>\n<p>Here\u2019s an article we have that explains what you are seeing in your gradients (<a href=\"https://wandb.ai/site/articles/exploring-gradients\" class=\"inline-onebox-loading\">https://wandb.ai/site/articles/exploring-gradients</a>)</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-03T15:28:06.114Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-06T16:24:28.741Z",
				"Answer_body": "<p>Hi Oliver, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-24T14:59:51.833Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How does wandb.tensorboard.patch works?",
		"Question_link": "https://community.wandb.ai/t/how-does-wandb-tensorboard-patch-works/1386",
		"Question_created_time": "2021-11-25T13:26:44.538Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 304,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi everyone,<br>\nI\u2019m trying to move from <code>tensorboard</code> to <code>wandb</code> that seems more flexible and has some useful additional feature to customize plots.</p>\n<p>In my code I defined two<code> Tensorboard</code> <code>SummaryWriter</code>; I\u2019d like to import the plot associated to one of them in <code>wandb</code>.</p>\n<p>In other words I want to include in <code>wandb</code> only a part of the <code>tensorboard</code> logs of my code.<br>\nIs it possible to do it?<br>\nIf, for example, I have the 2 summaries stored in 2 different folders a and a/b</p>\n<pre><code class=\"lang-auto\">Sum1 = SummaryWriter('a')\nSum2 = SummaryWriter('a/b')\n</code></pre>\n<p>and I\u2019m only interested in import Sum2 in<code> wandb</code> .</p>\n<p>I thought that<br>\n<code>wandb.tensorboard.patch(root_logdir='a/b', pytorch=True)</code><br>\nwas the way but it doesn\u2019t seem the case.<br>\nIn fact I get this message:</p>\n<p><code>e[34me[1mwandbe[0m: e[33mWARNINGe[0m Found logdirectory outside of given root_logdir, dropping given root_logdir for eventfile in a</code></p>\n<p>I want that paths outside root_logdir to be ignored.<br>\nApart from this page I did\u2019t found a clear documentation about wandb.tensorboard.patch.<br>\nAny idea about how to proceed?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-30T16:03:43.715Z",
				"Answer_body": "<p>Have you been able to look at this doc (<a href=\"https://docs.wandb.ai/guides/integrations/tensorboard#how-do-i-configure-tensorboard-when-im-using-it-with-wandb\" class=\"inline-onebox-loading\">https://docs.wandb.ai/guides/integrations/tensorboard#how-do-i-configure-tensorboard-when-im-using-it-with-wandb</a>)</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-06T17:33:41.670Z",
				"Answer_body": "<p>Hi Emanuele, was the document I provided able to help you, or are you still running into this issue?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-24T13:27:02.380Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Listing files of refence artifacts with temporary mounted folder (Azure)",
		"Question_link": "https://community.wandb.ai/t/listing-files-of-refence-artifacts-with-temporary-mounted-folder-azure/1384",
		"Question_created_time": "2021-11-25T09:53:15.251Z",
		"Question_answer_count": 5,
		"Question_score_count": 0,
		"Question_view_count": 304,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am trying to make wandb work with Azure for versioning my datasets.<br>\nMy dataset is too big for any upload, so I am keeping it in Azure and add it by reference.<br>\nI am using the file based reference (file:///) for a folder that is mounted to the compute instance.<br>\nRegistering the dataset, checksumming it etc all works fine.</p>\n<p>My problem is now how I <em>USE</em> the artifact.</p>\n<p>Since the folder is mounted by azure using a randomly generated name each time I cannot use the stored reference name. What I am doing right now is using the keys of the manifest entries:<br>\n<code>artifact.manifest.entries.keys()</code><br>\nThis gives me all the filenames and I manually concat it to the mounted folder pathname.</p>\n<p>Is there a better, less hacky, way of doing it? (Or even a better way to use Azure, since wandb supports s3 and gc?)<br>\n<code>.download()</code> is no option since the dataset is to big and the mounted folder is fine. <code>.checkout()</code> does not work, since the folder also contains other files which I do not want to delete. <code>.get()</code> and similar also dont work since I dont know the file paths.</p>\n<p>In my ideal world I would just have a function <code>artifact.files(root=\"mount_path\", verify=True)</code> which returns a list of all filenames and verifies they are correct via checksum. So I can just use the dataset and be sure it is the same one.</p>\n<p>Thank you! Artifacts are such a great addition to wandb and I would love to use them <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-29T21:35:32.387Z",
				"Answer_body": "<p>Hi DesertGator,</p>\n<p>It looks like add_reference (<a href=\"https://docs.wandb.ai/ref/python/public-api/artifact#add_reference\" class=\"inline-onebox-loading\">https://docs.wandb.ai/ref/python/public-api/artifact#add_reference</a>) is what you\u2019re looking for. I\u2019m going to double check with our engineering team to make sure that we have this feature for azure though.</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-30T13:08:02.352Z",
				"Answer_body": "<p>I double checked and as long as path to the file is accessible over https you should be able to use add_reference.</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-03T14:27:20.087Z",
				"Answer_body": "<p>Was this able to help you, or are you still experiencing this problem?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-06T16:45:13.722Z",
				"Answer_body": "<p>Hi DesertGator, since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-24T09:54:07.345Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sweep initial value",
		"Question_link": "https://community.wandb.ai/t/sweep-initial-value/1372",
		"Question_created_time": "2021-11-23T14:42:21.453Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 282,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>is there a way to set min-max values, but to start based on a predefined initial value?</p>\n<p>Best<br>\nKarol</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-23T18:25:41.828Z",
				"Answer_body": "<p>Can you give a bit more detail about what you\u2019re trying to do please? This sounds quite specific and is not a common workflow, but I\u2019d love to hear more details. You can log whatever you want so you could do the min-max and initial value yourself if that works.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.381Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Plot tables with best results from runs",
		"Question_link": "https://community.wandb.ai/t/plot-tables-with-best-results-from-runs/1365",
		"Question_created_time": "2021-11-22T10:28:34.409Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 292,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I would like to create a report not just with graph plots of my metrics but also a table with the best metric results (accuracy, mAP, \u2026). So that the viewer does not have to compare each line of  a run, but can instead look at the table with the scalar best results if he wants to identify the best run.</p>\n<p>It seems to me as there is currently no such feature implemented?</p>\n<p>Best<br>\nKarol</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-23T00:13:08.161Z",
				"Answer_body": "<p>Hi Karol,</p>\n<p>We do provide such a feature, it is called a Scalar Chart. You should be able to add a scalar chart to any panel by clicking the top right of the panel and selecting \u201cScalar Chart\u201d. You can then define the metric you want to consider in that one chart.</p>\n<p>I hope this answers your question.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-23T08:34:53.261Z",
				"Answer_body": "<p>Sorry, but that is not really what I want. The scalar chart can only be used for tracked parameters and then aggregates over all values of that parameter for every run.<br>\nThe result is always just a single value for all runs combined.<br>\nExample: I select the parameter accuracy and choose \u201cAgg=Max\u201d. Then the mean accuracy for every run is computed and then the maximum mean value of all runs is chosen.<br>\nThis is not what I want. I want that the max of a single run is chosen and plotted in a table along the max values of every other run.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-23T18:21:55.008Z",
				"Answer_body": "<p>This is a workflow that we\u2019ll be making much easier in the future, making it easier to get min, max etc. for a given metric for a given run / group of runs. In the meantime, you can just log the max value at the end of your runs and get the median of that. We have a convenience method called <code>define_metric</code> which you can use to automatically do this for you.</p>\n<pre><code class=\"lang-python\">wandb.init(entity=\"wandb\", project=\"define-metric-demo\")\n# define a metric we are interested in the minimum of\nwandb.define_metric(\"loss\", summary=\"min\")\n# define a metric we are interested in the maximum of\nwandb.define_metric(\"acc\", summary=\"max\")\n</code></pre>\n<p>This will then log the max/min value of a given logged metric for you.<br>\nHere\u2019s more documentation of this method:</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/guides/track/log#customize-axes-and-summaries-with-define_metric\">\n  <header class=\"source\">\n      \n\n      <a href=\"https://docs.wandb.ai/guides/track/log#customize-axes-and-summaries-with-define_metric\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/dc5ecc73965b87f6468f2495eed0a5dd9d21ad63_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/guides/track/log#customize-axes-and-summaries-with-define_metric\" target=\"_blank\" rel=\"noopener\">Log Data with wandb.log</a></h3>\n\n  <p>Keep track of metrics, videos, custom plots, and more</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-22T18:22:29.688Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to download the artifact with a specific alias?",
		"Question_link": "https://community.wandb.ai/t/how-to-download-the-artifact-with-a-specific-alias/1310",
		"Question_created_time": "2021-11-15T20:17:31.357Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 257,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>What\u2019s the best way to download the artifact with a specified alias (the version with the alias I want)? Also, during the inference time, how can I download the artifact and use it without creating a new wandb run directory? At inference time, if a new wandb run directory is created, it will be uploaded to my account, which will add more unnecessary runs in my wandb project. Is there a way to disable creating a new run folder if I just want to download the model in artifact and test the model? Thanks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-22T22:14:15.486Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/taochen\">@taochen</a>, <code>wandb artifact get</code> might be what you\u2019re looking for (<a href=\"https://docs.wandb.ai/ref/cli/wandb-artifact/wandb-artifact-get\">docs</a>)</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-21T22:14:47.413Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "404 error running sweep from local jupyter nb",
		"Question_link": "https://community.wandb.ai/t/404-error-running-sweep-from-local-jupyter-nb/1270",
		"Question_created_time": "2021-11-12T09:01:15.154Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 319,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi when I run a project with sweep configuration and click on the link I get a 404 error message. This is my own account so privacy settings should not be an issue. Also under my projects the sweep run from my local jupyter nb is not displayed even though in the overview tab I can see that I run the experiment.<br>\nAny help here?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-22T21:42:09.660Z",
				"Answer_body": "<p>Hi Zooshi, could you please share a link to your project page where this is happening so I can take a look for you?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-21T21:42:44.024Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Group by tag",
		"Question_link": "https://community.wandb.ai/t/group-by-tag/1364",
		"Question_created_time": "2021-11-22T10:05:44.090Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 288,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>is there a way to group runs in a plot by a given tag? Currently you can only group by hyperparameters, but that is not enough in my case.</p>\n<p>Best<br>\nKarol</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-22T12:53:18.683Z",
				"Answer_body": "<p>Thanks for this request. I\u2019ve added a +1 to this feature request and passed it to the engineering team.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-21T12:53:33.523Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sweeps hyperparameter tuning with cross validation",
		"Question_link": "https://community.wandb.ai/t/sweeps-hyperparameter-tuning-with-cross-validation/1354",
		"Question_created_time": "2021-11-20T20:10:16.373Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 225,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey,</p>\n<p>I want to do hyperparameter tuning using sweeps for my project. The experiments all involve k-fold cross-validation. Prior to doing hyperparameter tuning, I was separating the folds into different runs in wandb.init() by assigning them to the same group but giving them the fold number as a name. That works well.<br>\nHowever, now that I\u2019m using sweeps for hyperparameter tuning, wandb shows only one run per group (Fold 1) and all folds get packed together into this one run.</p>\n<p>Is there any best practice how to do both hyperparameter search with sweeps and k-fold cross-validation?</p>\n<p>Thanks a lot!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-23T16:03:14.941Z",
				"Answer_body": "<p>Hey there,</p>\n<p>Here is an example on how to do k-fold cross-validation with sweeps.</p>\n<p>Best,<br>\nArman</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-19T20:10:47.029Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb Tables to Latex Tables, anyway?",
		"Question_link": "https://community.wandb.ai/t/wandb-tables-to-latex-tables-anyway/1060",
		"Question_created_time": "2021-10-21T13:09:10.155Z",
		"Question_answer_count": 3,
		"Question_score_count": 2,
		"Question_view_count": 969,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I discovered Wandb few years back but I finally sat down to integrate everything with my experiments. I am loving this so much! Something I\u2019d like to know is if there is anyway to export tables to Latex from Wandb itself.</p>\n<p>I\u2019m in ML research and I have to include my results in Latex tables for papers. So it would be really cool if I could export them from Wandb, just like reports or graphs. I\u2019m open to suggestions you may have. thank you</p>\n<p>(willing to submit a feature request as well)</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-25T13:02:11.187Z",
				"Answer_body": "<p>Thanks for sharing this. This is an interesting idea and would definitely be a valuable function for other W&amp;B users! Just to clarify, is this to display metrics from your runs within Latex Tables or are you looking to extract information from our model evaluation tool <a href=\"https://docs.wandb.ai/guides/data-vis/tables\">W&amp;B Tables</a>?</p>\n<p>If you\u2019re looking for metrics from your runs, you can use the Runs API to get these, which you could then format into a Latex Table dynamically. I\u2019ve seen this being done from the team at Github to display run metrics within a markdown table in Github Issue comments:</p><aside class=\"onebox githubblob\" data-onebox-src=\"https://github.com/machine-learning-apps/wandb-action/blob/master/wandb_get_runs.py\">\n  <header class=\"source\">\n\n      <a href=\"https://github.com/machine-learning-apps/wandb-action/blob/master/wandb_get_runs.py\" target=\"_blank\" rel=\"noopener\">github.com</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <h4><a href=\"https://github.com/machine-learning-apps/wandb-action/blob/master/wandb_get_runs.py\" target=\"_blank\" rel=\"noopener\">machine-learning-apps/wandb-action/blob/master/wandb_get_runs.py</a></h4>\n\n\n    <pre><code class=\"lang-py\">\"\"\"\nRetrieves all runs from wandb that either:\n- correspond to a Git SHA\n- have specific tags.\n\nThe purpose is to compare runs from a given SHA to runs you may have tagged as baselines.\n\"\"\"\n\n\nimport os\nos.environ[\"WANDB_API_KEY\"] = os.getenv('INPUT_WANDB_API_KEY')\nimport wandb\nimport logging\nimport pandas as pd\n\nlogging.root.setLevel(logging.DEBUG)\n\napi = wandb.Api()\n\n# Read Inputs\n</code></pre>\n\n\n  This file has been truncated. <a href=\"https://github.com/machine-learning-apps/wandb-action/blob/master/wandb_get_runs.py\" target=\"_blank\" rel=\"noopener\">show original</a>\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/guides/track/public-api-guide\">\n  <header class=\"source\">\n      \n\n      <a href=\"https://docs.wandb.ai/guides/track/public-api-guide\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/guides/track/public-api-guide\" target=\"_blank\" rel=\"noopener\">Import &amp; Export Data</a></h3>\n\n  <p>Best practices and common use cases for our public API to export data and update existing runs</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-20T17:39:09.458Z",
				"Answer_body": "<p>So thanks to a chat in Reddit, progress has been made on this. Just putting runs into a DataFrame using the runs api and then use to_latex.</p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/guides/track/public-api-guide#querying-multiple-runs\">\n  <header class=\"source\">\n      \n\n      <a href=\"https://docs.wandb.ai/guides/track/public-api-guide#querying-multiple-runs\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/guides/track/public-api-guide#querying-multiple-runs\" target=\"_blank\" rel=\"noopener\">Import &amp; Export Data</a></h3>\n\n  <p>Best practices and common use cases for our public API to export data and update existing runs</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://www.reddit.com/r/MachineLearning/comments/qc2apm/d_what_is_your_ml_experiment_workflow_discussion/hlegwga/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf&amp;context=3\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/a70ab5d077374748901898cfcd9c7a09b8a303a9.png\" class=\"site-icon\" width=\"192\" height=\"192\">\n\n      <a href=\"https://www.reddit.com/r/MachineLearning/comments/qc2apm/d_what_is_your_ml_experiment_workflow_discussion/hlegwga/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf&amp;context=3\" target=\"_blank\" rel=\"noopener\">reddit</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e1e6bc8397e7c5baf7819d4743b7e8d04145c522_2_690x362.jpeg\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e1e6bc8397e7c5baf7819d4743b7e8d04145c522_2_690x362.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e1e6bc8397e7c5baf7819d4743b7e8d04145c522_2_1035x543.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/e1e6bc8397e7c5baf7819d4743b7e8d04145c522.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/e1e6bc8397e7c5baf7819d4743b7e8d04145c522_2_10x10.png\"></div>\n\n<h3><a href=\"https://www.reddit.com/r/MachineLearning/comments/qc2apm/d_what_is_your_ml_experiment_workflow_discussion/hlegwga/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=iossmf&amp;context=3\" target=\"_blank\" rel=\"noopener\">r/MachineLearning - [D] What is your ML experiment workflow? Discussion on...</a></h3>\n\n  <p>1 vote and 7 comments so far on Reddit</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<pre><code class=\"lang-python\">\nimport pandas as pd \nimport wandb\n\napi = wandb.Api()\nentity, project = \"&lt;entity&gt;\", \"&lt;project&gt;\"  # set to your entity and project \nruns = api.runs(entity + \"/\" + project) \n\nsummary_list, config_list, name_list = [], [], []\nfor run in runs: \n    # .summary contains the output keys/values for metrics like accuracy.\n    #  We call ._json_dict to omit large files \n    summary_list.append(run.summary._json_dict)\n\n    # .config contains the hyperparameters.\n    #  We remove special values that start with _.\n    config_list.append(\n        {k: v for k,v in run.config.items()\n         if not k.startswith('_')})\n\n    # .name is the human-readable name of the run.\n    name_list.append(run.name)\n\nruns_df = pd.DataFrame({\n    \"summary\": summary_list,\n    \"config\": config_list,\n    \"name\": name_list\n    })\n\nruns_df.to_latex()\n\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.677Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to do a wandb sweep for each dataset from a bash script?",
		"Question_link": "https://community.wandb.ai/t/how-to-do-a-wandb-sweep-for-each-dataset-from-a-bash-script/1316",
		"Question_created_time": "2021-11-16T15:01:34.881Z",
		"Question_answer_count": 2,
		"Question_score_count": 1,
		"Question_view_count": 357,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have a function <code>train_model.py</code> which fits a model and takes arguments like so.</p>\n<pre><code class=\"lang-auto\">parser = argparse.ArgumentParser(description='Train a model.')\nparser.add_argument('--dataset', type=str, default='MUTAG')\nparser.add_argument('--weight_decay', type=float, default=0.0)\nparser.add_argument('--layers', type=int, default=2)\nparser.add_argument('--dropout', type=float, default=0.0)\nparser.add_argument('--monitor', type=str, default='valid_loss')\nparser.add_argument('--seed', type=int, default=0)\nparser.add_argument('--max_epochs', type=int, default=50)\nargs = parser.parse_args()\n</code></pre>\n<p>I would like to run a sweep over a large dimensional hyper-parameter space (there are more arguments/parameters than shown above, this is just an illustrative example) and do one sweep per dataset.</p>\n<p>Currently, I am doing a random search and my config is like so.</p>\n<pre><code class=\"lang-auto\">program: train_model.py\nmethod: random\nmetric:\n  name: valid_accuracy\n  goal: maximise\nparameters:\n  dataset:\n    values: [MUTAG, ENZYMES, PROTEINS]\n  weight_decay:\n    values: [0.0, 0.0001, 0.001, 0.01]\n  layers:\n    values: [1, 2, 3]\n</code></pre>\n<p>This works for now because (approximately) each dataset is chosen 1/3 of the time. This is suboptimal however because</p>\n<ol>\n<li>The dashboard makes little sense, because the accuracy/loss range varies for dataset. Hyper-parameter importance may also depend on the dataset. To make sense of the data I have to download the table and filter it per dataset.</li>\n<li>I would like to use <code>bayes</code> search strategy, but the search will end up focusing on just one dataset (the easiest as it will give higher accuracies).</li>\n</ol>\n<p>My question is what is the best way to modify my setup so I can specify the dataset and run a sweep via command line? Ideally, I would like to be able to run a bash script like the following where a bayes hyper-parameter search is run over each dataset for 100 runs.</p>\n<pre><code class=\"lang-auto\">wandb sweep config.yaml --dataset MUTAG --count 100\nwandb sweep config.yaml --dataset ENZYMES --count 100\nwandb sweep config.yaml --dataset PROTEINS --count 100\n</code></pre>\n<p>The reason I am unable to do this is</p>\n<ol>\n<li>I\u2019m not sure how to pass the dataset flag separately.</li>\n<li>To run a sweep I use the command <code>wandb sweep config.yaml</code> which gives another command in the terminal output (<code>wandb: Run sweep agent with: wandb agent user/project/ccdfy44v</code> to actually run the sweep which I manually copy and paste).</li>\n</ol>\n<p>Another way would be to use the controller in a python script but the docs warn</p>\n<blockquote>\n<p>This feature is offered to support faster development and debugging of new algorithms for the Sweeps tool. It is not intended for actual hyperparameter optimization workloads.</p>\n</blockquote>\n<p>It doesn\u2019t explain why this is the case though.</p>\n<p>Thanks in advance.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-20T11:31:28.130Z",
				"Answer_body": "<p>Thanks for joining the forum and posting this interesting question. Would it be ok for you to have a different sweep config for each dataset? You can pass the dataset as an argument in the config via the <code>command</code> key, then the rest of your config would be passed in via <code>wandb.config</code>.</p>\n<pre><code class=\"lang-auto\">command:\n- ${env}\n- ${interpreter}\n- ${program}\n- \u2014dataset=MUTAG\n</code></pre>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/guides/sweeps/configuration\">\n  <header class=\"source\">\n      \n\n      <a href=\"https://docs.wandb.ai/guides/sweeps/configuration\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/guides/sweeps/configuration\" target=\"_blank\" rel=\"noopener\">Sweep Configuration</a></h3>\n\n  <p>Syntax to set the hyperparameter ranges, search strategy, and other aspects of your sweeps</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>Hope this helps, happy to clarify further if this isn\u2019t clear.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.398Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to compare different runs' config changes directly in my Workspace",
		"Question_link": "https://community.wandb.ai/t/how-to-compare-different-runs-config-changes-directly-in-my-workspace/1330",
		"Question_created_time": "2021-11-17T19:34:41.516Z",
		"Question_answer_count": 2,
		"Question_score_count": 1,
		"Question_view_count": 294,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Currently, we can only pin the final values that we \u201clog\u201d. How to pin a certain config / parameter for each run, so that its easier to compare the runs or understand what that run is.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-18T11:01:20.564Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"sk_imago\" data-post=\"1\" data-topic=\"1330\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/s/a5b964/40.png\" class=\"avatar\"> sk_imago:</div>\n<blockquote>\n<p>How to pin a certain config / parameter for each run, so that its easier to compare the runs or understand what that run is</p>\n</blockquote>\n</aside>\n<p>You can pin configs that you\u2019ve tracked with <code>wandb.config</code>.<br>\nYou can see an example of this in <a href=\"https://wandb.ai/_scott/wandb_example?workspace=user-\">this wandb_example workspace</a> where I\u2019ve pinned <code>lr</code>.</p>\n<p>Here\u2019s the docs describing how to do that:</p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/ref/app/features/runs-table#add-sidebar-columns\">\n  <header class=\"source\">\n      \n\n      <a href=\"https://docs.wandb.ai/ref/app/features/runs-table#add-sidebar-columns\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/ref/app/features/runs-table#add-sidebar-columns\" target=\"_blank\" rel=\"noopener\">Runs Table</a></h3>\n\n  <p>How to use the sidebar and table on the project page</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<blockquote>\n<p>On the project page, we show runs in a sidebar. To show more columns:</p>\n<ol>\n<li>Click the button in the upper right corner of the sidebar to expand the table.</li>\n<li>On a column header, click the dropdown menu to pin a column.</li>\n<li>Pinned columns will be available in the sidebar when you collapse the table.</li>\n</ol>\n</blockquote>\n<p>If you don\u2019t see your column in that table, you may need to click \u201cColumns\u201d above the table on the right, which should show a dialog in which you can show / hide columns.</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/0a1bebb6265dc7dafe45ac8e1cfe2f382ff18929.gif\" alt=\"\" data-base62-sha1=\"1rqARLkDvFU2UFK9YTc2i5SRLEB\" width=\"679\" height=\"500\" class=\"animated\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.384Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb online/offline status breaks when using WANDB_DIR environment variable",
		"Question_link": "https://community.wandb.ai/t/wandb-online-offline-status-breaks-when-using-wandb-dir-environment-variable/1230",
		"Question_created_time": "2021-11-05T11:23:04.127Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 294,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, while starting to get familiar with <code>wandb</code> I ran into a bug.</p>\n<p>I was testing a very simple setup with the following file:</p>\n<p><em>train.py</em></p>\n<pre><code class=\"lang-python\">import wandb\nimport random\nimport logging\n\nlog = logging.getLogger(__name__)\n\n\ndef train():\n    with wandb.init(\n        entity=\"jeroenboss\",\n        project=\"wandb_demo\"\n    ) as run:\n        log.info(f\"Running experiment with name {run.name}\")\n        config = run.config\n\n        log.info(f\"Loaded configuration: {config}\")\n        accuracy = 0\n        for x in range(config.get('epochs', 100)):\n            accuracy += (1 - accuracy) * (random.random()*0.9+0.1) * config.get('alpha', 0.1)\n\n            run.log({\"accuracy\": accuracy})\n\n        log.info(\"Finished\")\n\n\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.INFO)\n    train()\n</code></pre>\n<p>Because I was testing a few things I wanted to prevent uploading the runs to your servers before I had figured out some bugs. But when I tried to use the <code>wandb offline</code> command, it did not seem to work.<br>\nAfter some testing I found that setting <code>WANDB_DIR</code> in my <code>~/.bashrc</code> breaks the functionality. Below you can see the output of my commands. Removing <code>WANDB_DIR</code> made everything work correctly.</p>\n<pre><code class=\"lang-auto\">(wandb_demo) jeroen@jeroen-ThinkPad-P50:~/sandbox/wandb_test$ wandb status\nCurrent Settings\n{\n  \"base_url\": \"https://api.wandb.ai\",\n  \"entity\": null,\n  \"git_remote\": \"origin\",\n  \"ignore_globs\": [],\n  \"project\": null,\n  \"section\": \"default\"\n}\n(wandb_demo) jeroen@jeroen-ThinkPad-P50:~/sandbox/wandb_test$ wandb offline\nW&amp;B offline, running your script from this directory will only write metadata locally.\n(wandb_demo) jeroen@jeroen-ThinkPad-P50:~/sandbox/wandb_test$ wandb status\nCurrent Settings\n{\n  \"base_url\": \"https://api.wandb.ai\",\n  \"disabled\": \"true\",\n  \"entity\": null,\n  \"git_remote\": \"origin\",\n  \"ignore_globs\": [],\n  \"mode\": \"offline\",\n  \"project\": null,\n  \"section\": \"default\"\n}\n(wandb_demo) jeroen@jeroen-ThinkPad-P50:~/sandbox/wandb_test$ python train.py\nwandb: Currently logged in as: jeroenboss (use `wandb login --relogin` to force relogin)\nwandb: Tracking run with wandb version 0.12.6\nwandb: Syncing run misunderstood-night-24\nwandb: \u2b50\ufe0f View project at https://wandb.ai/jeroenboss/wandb_demo\nwandb: \ud83d\ude80 View run at https://wandb.ai/jeroenboss/wandb_demo/runs/kv7r7fst\nwandb: Run data is saved locally in /home/jeroen/.wandb/runs/wandb/run-20211105_121404-kv7r7fst\nwandb: Run `wandb offline` to turn off syncing.\n\nINFO:__main__:Running experiment with name misunderstood-night-24\nINFO:__main__:Loaded configuration: {'epochs': 50, 'alpha': 0.1}\nINFO:__main__:Finished\n\nwandb: Waiting for W&amp;B process to finish, PID 17238... (success).\nwandb:                                                                                \nwandb: Run history:\nwandb:   accuracy \u2581\u2582\u2582\u2582\u2583\u2583\u2583\u2584\u2584\u2584\u2585\u2585\u2585\u2585\u2585\u2586\u2586\u2586\u2586\u2586\u2587\u2587\u2587\u2587\u2587\u2587\u2587\u2587\u2587\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\nwandb: \nwandb: Run summary:\nwandb:   accuracy 0.95235\nwandb: \nwandb: Synced 7 W&amp;B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\nwandb: Synced misunderstood-night-24: https://wandb.ai/jeroenboss/wandb_demo/runs/kv7r7fst\nwandb: Find logs at: /home/jeroen/.wandb/runs/wandb/run-20211105_121404-kv7r7fst/logs/debug.log\nwandb: \n(wandb_demo) jeroen@jeroen-ThinkPad-P50:~/sandbox/wandb_test$ wandb status\nCurrent Settings\n{\n  \"base_url\": \"https://api.wandb.ai\",\n  \"disabled\": \"true\",\n  \"entity\": null,\n  \"git_remote\": \"origin\",\n  \"ignore_globs\": [],\n  \"mode\": \"offline\",\n  \"project\": null,\n  \"section\": \"default\"\n}\n</code></pre>\n<p>I\u2019m running Python 3.7.12 and wandb 0.12.6</p>\n<p>I would like to store my runs in a central folder, so I would like to be able to use <code>WANDB_DIR</code>.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-08T16:23:37.185Z",
				"Answer_body": "<p>Hi Jeroen,</p>\n<p>Can you show me what errors would pop up before you removed WANDB_DIR?</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-10T12:55:27.663Z",
				"Answer_body": "<p>What do you mean by that?</p>\n<p>If I don\u2019t set the <code>WANDB_DIR</code> environment variable then there are no errors and the <code>wandb status</code> is working as expected.<br>\nIf I do set the <code>WANDB_DIR</code> environment variable then there are also no errors but the <code>wandb status</code> does not work as expected.</p>\n<p>It seems like <code>wandb</code> does not check the correct location to retrieve the mode that is active.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-18T08:13:14.853Z",
				"Answer_body": "<p>This problem still persists. Could someone have a look?</p>\n<p>The problem is easily replicated:</p>\n<ol>\n<li>set the <code>WANDB_DIR</code> environment variable</li>\n<li>run the <code>wandb offline</code> command</li>\n<li>run a python script to run <code>wandb.init</code>\n</li>\n</ol>\n<p>The init call will create a run in online mode, even though it is storing the results in the <code>WANDB_DIR</code>. The settings file in that directory is ignored.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-18T19:23:42.200Z",
				"Answer_body": "<p>Is your WANDB_DIR variable set to ? Is this a HPC cluster, your own machine, or somewhere else? What permissions do you have for your device.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-22T12:56:52.248Z",
				"Answer_body": "<p>Hi Jeroen,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-29T14:01:31.047Z",
				"Answer_body": "<p>Hi Jeroen,<br>\nSince we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-17T08:13:30.210Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Loading past runs in offline mode",
		"Question_link": "https://community.wandb.ai/t/loading-past-runs-in-offline-mode/1299",
		"Question_created_time": "2021-11-15T16:54:53.288Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 260,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>So I just recently started using wandb local, tracking experiments running on the GPU cluster at the lab where I work, hosted at localhost on my machine.</p>\n<p>I suspect I\u2019ve misunderstood the setup at some point, but the problem I\u2019m having is that every time I spin up a Docker container to run wandb/local, it requires me to create a new account, with none of my previous project data available through the web server, even though the files and metadata from all previous runs are saved to a persistent folder on my machine. I\u2019m using the following command to set up the container:</p>\n<pre><code class=\"lang-auto\">sudo docker run --rm -d -v wandb_vol:/vol -p 8080:8080 --name wandb-local wandb/local\n</code></pre>\n<p>and run metadata is indeed saved to <code>wandb_vol</code> locally.  However, each time I spin up the container again, I have to re-enter all my details and I see this:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/262d90592453acb356f466258e064d66dd885d02.png\" data-download-href=\"/uploads/short-url/5rJLmNX4woMxT36lYkqCQvNoVrA.png?dl=1\" title=\"wandb_forum_pic\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/262d90592453acb356f466258e064d66dd885d02_2_690x305.png\" alt=\"wandb_forum_pic\" data-base62-sha1=\"5rJLmNX4woMxT36lYkqCQvNoVrA\" width=\"690\" height=\"305\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/262d90592453acb356f466258e064d66dd885d02_2_690x305.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/262d90592453acb356f466258e064d66dd885d02_2_1035x457.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/262d90592453acb356f466258e064d66dd885d02_2_1380x610.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/262d90592453acb356f466258e064d66dd885d02_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"></use></svg><span class=\"filename\">wandb_forum_pic</span><span class=\"informations\">1715\u00d7760 54.6 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nwhen I click on \u201cGet a free license\u201d I get an error saying \u201cYour account already has a deployment\u201d, which is true, but is there a way to have a persistent account and project folders locally?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-16T18:31:14.657Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/aidanm\">@aidanm</a> (great name/spelling). So wandb local is essentially hosting a local version of the site for users who don\u2019t want to or can\u2019t have their data on our servers. It\u2019s not really meant to be spun up and down for each project but is meant to be a part of a team\u2019s infrastructure. That being said, you should still have access to your locally stored information. ARe you able to inspect your volume inside your container with <code>docker volume inspect &lt;your-vol&gt;</code>?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-17T09:58:56.144Z",
				"Answer_body": "<p>Ok thanks! Yes I can access all the locally stored information and WandB logs, and inspect the volume in the container while it\u2019s running, the problem was just that I couldn\u2019t load past runs (from previous container instances) into the workspace on localhost, to directly compare metrics with current runs.</p>\n<p>This problem, however, seems to have fixed itself? The last couple of times I stopped the container and then spun it up the next day, I don\u2019t need to log in again and all the previous session\u2019s metrics are still in the project workspaces. I\u2019m not sure what changed or why it wasn\u2019t working like that before!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-18T04:46:10.255Z",
				"Answer_body": "<p>Weird but I\u2019m glad things are working now! Let us know if something like this happens again.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-17T04:46:13.855Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How does one do hyper parameter sweeps when using HPCs/clusters?",
		"Question_link": "https://community.wandb.ai/t/how-does-one-do-hyper-parameter-sweeps-when-using-hpcs-clusters/1317",
		"Question_created_time": "2021-11-16T15:55:10.724Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 300,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I saw the great video:</p>\n<div class=\"youtube-onebox lazy-video-container\" data-video-id=\"9zrmUIlScdY\" data-video-title=\"\ud83e\uddf9 Tune Hyperparameters Easily with W&amp;B Sweeps\" data-provider-name=\"youtube\">\n  <a href=\"https://www.youtube.com/watch?v=9zrmUIlScdY\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n    <img class=\"youtube-thumbnail\" src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/2X/7/717a711d1aa4e9e0b03bfca700e6c8f019960c7d.jpeg\" title=\"\ud83e\uddf9 Tune Hyperparameters Easily with W&amp;B Sweeps\" width=\"690\" height=\"388\">\n  </a>\n</div>\n\n<p>but I still wasn\u2019t 100% how to use it in a HPC cluster. I understand there is a central sweep master at wandb\u2019s servers sending commands, but how does it connect to the HPC/clsuter?</p>\n<p>There are some cases I am worried baout</p>\n<ol>\n<li>the HPC needs my password</li>\n<li>the HPC needs an ssh key</li>\n<li>a VPN to connect to the hpc</li>\n<li>the HPC needs duo authentication</li>\n<li>the HPC uses a workload manager e.g. slurm or condor</li>\n</ol>\n<p>it would be very nice to have a concrete example with some of these. Perhaps slurm + password is the most common (although I admit I\u2019ve been using condor with a VPN wall + password is my real use case right now).</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-17T12:45:55.282Z",
				"Answer_body": "<p>Hey,</p>\n<p>I run W&amp;B sweeps on HPC clusters with slurm as well.<br>\nJust prepare all your code and data on the cluster and create the sweep as explained above.</p>\n<p>Then from the sweep page in your project, copy the wandb agent command.<br>\nLogin to your hpc, and put the wandb agent command in the queue.<br>\nIt is especially usefull o nHPC clusters as you have multiple nodes available. the wandb API automatically puts the right set of new hyperparameters on seperate nodes!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-18T14:59:49.656Z",
				"Answer_body": "<p>Thank you for the help Joris, let us know if you still need further assistance Brando.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-16T12:46:36.956Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Error with logging a wandb table that contains pandas dataframe",
		"Question_link": "https://community.wandb.ai/t/error-with-logging-a-wandb-table-that-contains-pandas-dataframe/1245",
		"Question_created_time": "2021-11-09T02:36:42.038Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 285,
		"Question_has_accepted_answer": false,
		"Question_body": "<pre><code class=\"lang-auto\">   wandb.log({'full_results': wandb.Table(dataframe=self.averages_results_df, allow_mixed_types=True)})\n</code></pre>\n<p>error:<br>\nTypeError: keys must be str, int, float, bool or None, not a tuple</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-09T20:13:02.112Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohamed_ragab\">@mohamed_ragab</a>,</p>\n<p>Thanks for writing in! Could you send the stack trace associated with the error? It will help up figure out what is happening better.</p>\n<p>Thanks,<br>\nRamit<br>\nWeights and Biases Support</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-10T01:16:02.626Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"ramit_goolry\" data-post=\"2\" data-topic=\"1245\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/r/85e7bf/40.png\" class=\"avatar\"> ramit_goolry:</div>\n<blockquote>\n<p>stack trace associated</p>\n</blockquote>\n</aside>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"D:/AdaTime/main.py\", line 38, in &lt;module&gt;\n    trainer.train()\n  File \"D:\\AdaTime\\trainer.py\", line 143, in train\n    wandb.log({'full_results': wandb.Table(dataframe=self.averages_results_df, allow_mixed_types=True)})\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1229, in log\n    self.history._row_add(data)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_history.py\", line 44, in _row_add\n    self._flush()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_history.py\", line 59, in _flush\n    self._callback(row=self._data, step=self._step)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 972, in _history_callback\n    self._backend.interface.publish_history(\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py\", line 491, in publish_history\n    data = data_types.history_dict_to_json(run, data, step=step)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\data_types.py\", line 2325, in history_dict_to_json\n    payload[key] = val_to_json(run, key, val, namespace=step)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\data_types.py\", line 2397, in val_to_json\n    art.add(val, key)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_artifacts.py\", line 522, in add\n    do_write(f)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_artifacts.py\", line 510, in do_write\n    f.write(json.dumps(val, sort_keys=True))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\json\\__init__.py\", line 234, in dumps\n    return cls(\n  File \"C:\\ProgramData\\Anaconda3\\lib\\json\\encoder.py\", line 199, in encode\n    chunks = self.iterencode(o, _one_shot=True)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\json\\encoder.py\", line 257, in iterencode\n    return _iterencode(o, 0)\nTypeError: keys must be str, int, float, bool or None, not tuple\nwandb: ERROR Problem finishing run\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1671, in _atexit_cleanup\n    self._on_finish()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 1815, in _on_finish\n    self.history._flush()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_history.py\", line 59, in _flush\n    self._callback(row=self._data, step=self._step)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 972, in _history_callback\n    self._backend.interface.publish_history(\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py\", line 491, in publish_history\n    data = data_types.history_dict_to_json(run, data, step=step)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\data_types.py\", line 2325, in history_dict_to_json\n    payload[key] = val_to_json(run, key, val, namespace=step)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\data_types.py\", line 2397, in val_to_json\n    art.add(val, key)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_artifacts.py\", line 522, in add\n    do_write(f)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\wandb\\sdk\\wandb_artifacts.py\", line 510, in do_write\n    f.write(json.dumps(val, sort_keys=True))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\json\\__init__.py\", line 234, in dumps\n    return cls(\n  File \"C:\\ProgramData\\Anaconda3\\lib\\json\\encoder.py\", line 199, in encode\n    chunks = self.iterencode(o, _one_shot=True)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\json\\encoder.py\", line 257, in iterencode\n    return _iterencode(o, 0)\nTypeError: keys must be str, int, float, bool or None, not tuple\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-16T20:35:35.847Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/mohamed_ragab\">@mohamed_ragab</a>,</p>\n<p>It seems like the keys in your data frame are tuples, a feature that is not supported by Wandb Tables right now. From the looks of it, your data frame is being logged like this:</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b9f8c4658e4d5c29c4c0cb9bdaea82ce0d2c4870.png\" alt=\"Screen Shot 2021-11-16 at 12.32.03 PM\" data-base62-sha1=\"qxbjq7rdNMns1GvHp62bEaYAJAA\" width=\"392\" height=\"300\"></p>\n<p>As a workaround, you can pass in the string representation of the tuple, which will allow you to pass the dataframe to wandb:</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/70e92e9eb6d1d1309d47ad6effd7b9f2bbb5037c.png\" alt=\"Screen Shot 2021-11-16 at 12.32.12 PM\" data-base62-sha1=\"g6R49LapJ05YwYBPVtWe4GRjQG8\" width=\"418\" height=\"278\"></p>\n<p>This will work to upload your data to wandb.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-15T20:35:54.564Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Unable to run wandb online after running offline",
		"Question_link": "https://community.wandb.ai/t/unable-to-run-wandb-online-after-running-offline/1252",
		"Question_created_time": "2021-11-10T00:54:00.810Z",
		"Question_answer_count": 9,
		"Question_score_count": 2,
		"Question_view_count": 371,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I have a compute environment where I was running wandb offline for quite a while. I am now hoping to use it online (to get automatic syncing), however I seem to be unable to set this up now. The following is a minimal reproducible example:</p>\n<pre><code class=\"lang-auto\">&gt;&gt; import wandb\n&gt;&gt; test = wandb.init(mode='online')\nTraceback (most recent call last):\n  File \"[path]/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 867, in init\n    wi.setup(kwargs)\n  File \"[path]/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 182, in setup\n    user_settings = self._wl._load_user_settings()\n  File \"[path]/lib/python3.9/site-packages/wandb/sdk/wandb_setup.py\", line 183, in _load_user_settings\n    flags = self._server._flags\nAttributeError: 'NoneType' object has no attribute '_flags'\nwandb: ERROR Abnormal program exit\n</code></pre>\n<p>I have tried</p>\n<ul>\n<li>running wandb online in the terminal</li>\n<li>setting the wandb mode environment variable to be online</li>\n<li>uninstalling and reinstalling wandb</li>\n</ul>\n<p>Is there any way I can run this online?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-10T04:21:13.153Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/evanv\">@evanv</a>, you shouldn\u2019t have a problem changing between <code>online</code> and <code>offline</code>,  can you give me the version of wandb you\u2019re using?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-10T16:20:43.744Z",
				"Answer_body": "<p>Thanks so much! I am using wandb v 0.12.6. In case it is useful I also wanted to make you aware of a peculiarity of the system I am using. It is a shared HPC and if I try to use wandb in a folder which <strong>does not</strong> have its own wandb folder, I get the following:</p>\n<pre><code class=\"lang-auto\">(my_conda_env) user@login-2:[path to folder with no wandb folder]$ wandb --version\nTraceback (most recent call last):\n  File \"[conda env path]/bin/wandb\", line 5, in &lt;module&gt;\n    from wandb.cli.cli import cli\n  File \"[conda env path]/lib/python3.9/site-packages/wandb/cli/cli.py\", line 48, in &lt;module&gt;\n    logging.basicConfig(\n  File \"[conda env path]/lib/python3.9/logging/__init__.py\", line 2003, in basicConfig\n    h = FileHandler(filename, mode,\n  File \"[conda env path]/lib/python3.9/logging/__init__.py\", line 1146, in __init__\n    StreamHandler.__init__(self, self._open())\n  File \"[conda env path]/lib/python3.9/logging/__init__.py\", line 1175, in _open\n    return open(self.baseFilename, self.mode, encoding=self.encoding,\nPermissionError: [Errno 13] Permission denied: '/tmp/debug-cli.log'\n(my_conda_env) user@login-2:[path to folder with no wandb folder]$ cd [folder with wandb folder]\n(my_conda_env) user@login-2:[path to folder with wandb folder]$ wandb --version\nwandb, version 0.12.6\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-10T20:42:15.004Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/evanv\">@evanv</a> It looks like your <code>/tmp</code> directory is not writable. if you run <code>ls -al /tmp</code> in your terminal I\u2019m guessing we will see that this directory is not readable except by root users (hence why you need to run <code>sudo</code> to read from the directory). You should be able to fix this by issuing the command <code>chmod +r /tmp</code> from your terminal. Or, if you can\u2019t change the permissions, the my recommendation would be to specify a directory by specific the env var: <code>WANDB_DIR=/home/username/tmp</code>.<br>\nHope this helps.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-11T05:38:13.376Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/anmolmann\">@anmolmann</a> , thank you for letting me know! Indeed <code>/tmp</code> is not writable. I tried modifying the WANDB_DIR environment variable, both in my .bash_profile and just in the terminal, to an existing and writeable directory `/home/my_username/tmp/\u2019. Unfortunately, the above problem still persists <img src=\"https://emoji.discourse-cdn.com/twitter/frowning.png?v=10\" title=\":frowning:\" class=\"emoji\" alt=\":frowning:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-15T20:56:47.290Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/evanv\">@evanv</a>, we should have a <a href=\"https://github.com/wandb/client/pull/2924\" rel=\"noopener nofollow ugc\">fix</a> in for the original issue posted at the top here, however I suspect that it might not resolve your problem. I have a couple questions for you:</p>\n<ul>\n<li>You mentioned that you were using the offline mode \u2013 do you know where things were logged to locally? wandb should have said something like</li>\n</ul>\n<pre><code class=\"lang-auto\">wandb: W&amp;B syncing is set to `offline` in this directory.  \nwandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n\nwandb: Waiting for W&amp;B process to finish, PID 85946... (success).\nwandb: You can sync this run to the cloud by running:\nwandb: wandb sync /&lt;path&gt;/wandb/offline-run-&lt;tag&gt;-3ktlmbnl\nwandb: Find logs at: ./wandb/offline-run-&lt;tag&gt;-3ktlmbnl/logs/debug.log\n</code></pre>\n<ul>\n<li>In your script where you init wandb - what does <code>print(os.environ.get(\"WANDB_DIR\"))</code> print, the expected value you set (<code>/home/your_username/tmp/</code>)? Have you tried setting it inside the script itself with <code>os.environ[\"WANDB_DIR\"] = \"/home/your_username/tmp/\"</code>?</li>\n</ul>\n<p>Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-16T00:10:54.258Z",
				"Answer_body": "<p>Also, <a class=\"mention\" href=\"/u/evanv\">@evanv</a>, have you tried initializing wandb like this:</p>\n<pre><code class=\"lang-python\">wandb.init(dir=\"/home/your_username/tmp/\")\n</code></pre>\n<p>?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-16T03:47:28.659Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/dimaduev\">@dimaduev</a> , thanks so much for the fixes! I think I was able to resolve this through looking at the different WANDB_DIR locations\u2026 I had several in different bashrc/zshrc files and I suspect this was causing an issue. It seems to be resolved now!</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2021-11-16T07:07:09.521Z",
				"Answer_body": "<p>Excellent, glad to hear that!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-15T07:07:14.727Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Memory Error Cause Fail Sweep Runnings",
		"Question_link": "https://community.wandb.ai/t/memory-error-cause-fail-sweep-runnings/1259",
		"Question_created_time": "2021-11-11T13:55:35.189Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 302,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I really liked ur amazing tool and just started to use it. I m using sweep config for hyperparameters. Sometimes my running is get broke due to some reason in the models parameters etc. and my gpu get stuck with full memory. Is there a way to kill the gpu\u2019s current job to free the gpu ram? it would be amazing to apply it to my code with a given PID number and kill it.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-15T13:18:46.409Z",
				"Answer_body": "<p>Hey there, <a href=\"https://docs.wandb.ai/guides/sweeps/quickstart#6.-stop-the-agent\">here</a> is how you can kill the current job that\u2019s running. Let me know if there are any questions.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-17T14:15:47.330Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-14T13:19:14.854Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Save_period Not Working",
		"Question_link": "https://community.wandb.ai/t/save-period-not-working/1264",
		"Question_created_time": "2021-11-12T02:28:56.179Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 258,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I\u2019m trying to train a model, but I keep receiving an error that tells me \u201ctrain.py: error: unrecognized arguments: --save_period 1.\u201d<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/3ad842158d3fe6c02426800cceb90f785a60b755.png\" data-download-href=\"/uploads/short-url/8oz1v5B3P0W95o6FWMDht4yfVLD.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3ad842158d3fe6c02426800cceb90f785a60b755_2_690x337.png\" alt=\"image\" data-base62-sha1=\"8oz1v5B3P0W95o6FWMDht4yfVLD\" width=\"690\" height=\"337\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3ad842158d3fe6c02426800cceb90f785a60b755_2_690x337.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3ad842158d3fe6c02426800cceb90f785a60b755_2_1035x505.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/3ad842158d3fe6c02426800cceb90f785a60b755.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/3ad842158d3fe6c02426800cceb90f785a60b755_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1326\u00d7648 66 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nWhat issue do I have here?  Thanks in advance.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-13T06:40:50.863Z",
				"Answer_body": "<p>I think you have  a typo. According to the usage info, the argument name is <code>--save-period</code>  , not <code>--save_period</code></p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2021-11-14T00:54:05.542Z",
				"Answer_body": "<p>It worked. Thanks! <img src=\"https://emoji.discourse-cdn.com/twitter/smiley.png?v=10\" title=\":smiley:\" class=\"emoji\" alt=\":smiley:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-13T00:54:51.119Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Transfer my account (email change)",
		"Question_link": "https://community.wandb.ai/t/transfer-my-account-email-change/1247",
		"Question_created_time": "2021-11-09T11:47:45.080Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 328,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>My current email id will be deactivated soon, so I need to change the email id associated with W&amp;B. Following the advice from this <a href=\"https://community.wandb.ai/t/possible-to-add-options-to-edit-profile/123/7\">thread</a>, I have created a new account. Can someone help me on this? (Had emailed someone from the Community team last week as well)</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-09T22:15:46.540Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dsteam\">@dsteam</a>!</p>\n<p>I will be happy to help you move your projects to your new account. Could you email us at <a href=\"mailto:support@wandb.com\">support@wandb.com</a> about this with the details of the move? Specifically:</p>\n<ul>\n<li>The entity name of the account you want projects moved from</li>\n<li>The entity name of the account you want projects moved into</li>\n<li>Which projects you want moved (or if you want all)</li>\n</ul>\n<p>Thanks,<br>\nRamit<br>\nWeights and Biases support</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2021-11-10T16:39:10.075Z",
				"Answer_body": "<p>Thanks a lot for the quick response! Emailed <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-10T16:39:43.597Z",
				"Answer_body": "<blockquote>\n<p><img src=\"https://avatars.discourse-cdn.com/v4/letter/r/85e7bf/40.png\" alt=\"\"> ramit_goolry:</p>\n<ul>\n<li>Which projects you want moved (or if you want all)</li>\n</ul>\n</blockquote>\n<p>Thanks! Emailed <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" alt=\":slight_smile:\" title=\":slight_smile:\"></p>\n<p>[Discourse post]</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-09T16:39:53.728Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb API run.history() skip some values",
		"Question_link": "https://community.wandb.ai/t/wandb-api-run-history-skip-some-values/1126",
		"Question_created_time": "2021-10-28T08:36:56.225Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 344,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\nI have a task to analyses and choose best model from metrics.<br>\nAnd follow instructions of wnadb API  its easy to use.<br>\nBut when i call run.history() \u2013 my result table skip some values \u2013 there is nan in front of some existing test metric values. API have 48 rows and export csv have 71 rows</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-28T15:53:57.924Z",
				"Answer_body": "<p>Hello! Welcome to our forums and Thank you for your question!</p>\n<p>Could you kindly check if the same is being logged during the run?</p>\n<p>Logged values get appended to <code>run.history()</code></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-29T09:31:20.454Z",
				"Answer_body": "<p>I dont know how to get full log from web interface. (In log tab i cant download,  its redirect to storage. googleapis. com and it is empty )<br>\nDownloaded one of metrics with 72 rows<br>\nAnd <code>run.history()</code>  return <strong>different</strong> results 52 and 46<br>\n<a href=\"https://storage.yandexcloud.net/kaggle/wandb_debug/hist.csv\" class=\"onebox\" target=\"_blank\" rel=\"noopener nofollow ugc\">https://storage.yandexcloud.net/kaggle/wandb_debug/hist.csv</a><br>\n<a href=\"https://storage.yandexcloud.net/kaggle/wandb_debug/wandb_export_2021-10-28T11%2019%2023.558%2B03%2000.csv\" class=\"onebox\" target=\"_blank\" rel=\"noopener nofollow ugc\">https://storage.yandexcloud.net/kaggle/wandb_debug/wandb_export_2021-10-28T11%2019%2023.558%2B03%2000.csv</a><br>\nPS: how can i attach files here?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-29T09:33:04.451Z",
				"Answer_body": "<p><a href=\"https://storage.yandexcloud.net/kaggle/wandb_debug/hist2.csv\" class=\"onebox\" target=\"_blank\" rel=\"noopener nofollow ugc\">https://storage.yandexcloud.net/kaggle/wandb_debug/hist2.csv</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-29T09:36:41.450Z",
				"Answer_body": "<pre><code class=\"lang-python\"> df=run.history()\nfiltered_df = df[df['test/epoch'].notnull()]\nfiltered_df.to_csv('/home/dereyly/tmp/hist2.csv')\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-03T15:08:38.966Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dereyly\">@dereyly</a> , if you\u2019d like to chart a link to your project page (<a href=\"http://wandb.ai/\">wandb.ai/</a>/&lt;project_name&gt;) I can take a look and see what exactly is going on.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-12T20:03:46.014Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/dereyly\">@dereyly</a>, just following up here.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-11T20:03:53.394Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Collab example for building an \"evaluation\" table using wandb.log()",
		"Question_link": "https://community.wandb.ai/t/collab-example-for-building-an-evaluation-table-using-wandb-log/1232",
		"Question_created_time": "2021-11-05T16:32:49.253Z",
		"Question_answer_count": 4,
		"Question_score_count": 2,
		"Question_view_count": 274,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi - in the <a href=\"https://wandb.ai/_scott/wandb_example?workspace=\">wandb_example Workspace</a>, there is a table visualisation showing \u201cevaluation\u201d results logged from a run:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/f7f77fb07316f11f2805765bd0e420843cb50185.png\" data-download-href=\"/uploads/short-url/znCckAyMsQCwsr3hGddC1h58tN3.png?dl=1\" title=\"Screenshot 2021-11-05 at 16.21.56\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f7f77fb07316f11f2805765bd0e420843cb50185_2_689x426.png\" alt=\"Screenshot 2021-11-05 at 16.21.56\" data-base62-sha1=\"znCckAyMsQCwsr3hGddC1h58tN3\" width=\"689\" height=\"426\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f7f77fb07316f11f2805765bd0e420843cb50185_2_689x426.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f7f77fb07316f11f2805765bd0e420843cb50185_2_1033x639.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/f7f77fb07316f11f2805765bd0e420843cb50185.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f7f77fb07316f11f2805765bd0e420843cb50185_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2021-11-05 at 16.21.56</span><span class=\"informations\">1212\u00d7749 52.6 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>My understanding is that this table has to be created using wandb.log() in the training code, but I can\u2019t access the notebook used for the run in the example workspace.</p>\n<p>I want to create a similar evaluation table using one of your examples:  <a href=\"https://github.com/wandb/examples/examples/pytorch/pytorch-cnn-fashion/train.py\" rel=\"noopener nofollow ugc\">https://github.com/wandb/examples/examples/pytorch/pytorch-cnn-fashion/train.py</a></p>\n<p>Is there a code snippet or collab example for doing this? I\u2019ve seen the docs for logging a table, but I need a specific example like the one in the example workspace that shows clothing images, and metrics e.g. \u2018guess\u2019. \u2018truth\u2019 etc.</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-11T11:32:06.972Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/omerm\">@omerm</a>,</p>\n<p>I\u2019m glad to hear you\u2019re excited to log a <code>wandb.Table</code>. You can create a <code>wandb.Table</code> with <code>wandb.Image</code>, strings and floats for the values in each row, and then log it using <code>wandb.log({'my_eval_table': table})</code>.</p>\n<pre><code class=\"lang-auto\"># create a Table with the same columns as above,\n# plus confidence scores for all labels\ncolumns=\ufeff[\ufeff\"id\"\ufeff, \"image\"\ufeff, \"guess\"\ufeff, \"truth\"\ufeff]\nfor digit in range\ufeff(\ufeff10\ufeff)\ufeff:\n    columns.append(\ufeff\"score_\" + str\ufeff(digit)\ufeff)\ntest_table = wandb.Table(columns=columns)\n\n# run inference on every image, assuming my_model returns the\n# predicted label, and the ground truth labels are available\nfor img_id, img in enumerate(mnist_test_data):\n    true_label = mnist_test_data_labels[img_id]\n    guess_label = my_model.predict(img)\n    test_table.add_data(img_id, wandb.Image(img), \\\n                         guess_label, true_label)\n</code></pre>\n<p>Here is the colab used to create the table: <a href=\"http://wandb.me/model-eval-colab\" class=\"inline-onebox\">Google Colab</a>. If you\u2019d rather a more direct introduction to <code>wandb.Table</code>s you can follow the guide here:<br>\n<a href=\"https://docs.wandb.ai/guides/data-vis/log-tables#create-tables\">https://docs.wandb.ai/guides/data-vis/log-tables#create-tables</a></p>\n<p>Hope that helps.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-12T10:44:25.025Z",
				"Answer_body": "<p>That\u2019s super helpful, thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:01:44.822Z",
				"Answer_body": "<p>That\u2019s super helpful, thanks!</p>\n<p>[Discourse post]</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.884Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to show max performance and average across trials",
		"Question_link": "https://community.wandb.ai/t/how-to-show-max-performance-and-average-across-trials/1172",
		"Question_created_time": "2021-10-31T06:59:33.755Z",
		"Question_answer_count": 7,
		"Question_score_count": 6,
		"Question_view_count": 492,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>So I\u2019ve been using the default curves to monitor my RL experiments for a while now. They are very handy and easier to manage than my old <code>.csv</code> workflow. In my experiments, I have multiple runs with the same hyperparameters and they are organized into groups. What I\u2019m trying to plot is this: create a bar plot of max performance averaged across trials for each group, versus the name of the group.</p>\n<p>I tried to create a panel of bar plot, and in general it looks like what I want: it lists all the groups of runs, and automatically calculates some aggregated value of them, e.g. mean or median. But it seems that the plot is taking the mean/median of all the values from the whole group (like the concat of all trials) instead of giving me a choice of, e.g., averaging over the max return of each run. Here is what the plot looks like:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/1b148885f64e24dbdf9496970c581de3a1c06a3e.png\" data-download-href=\"/uploads/short-url/3RySOpsmjzfJzAkEHbaGE2ilpro.png?dl=1\" title=\"WX20211031-025712@2x\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1b148885f64e24dbdf9496970c581de3a1c06a3e_2_575x500.png\" alt=\"WX20211031-025712@2x\" data-base62-sha1=\"3RySOpsmjzfJzAkEHbaGE2ilpro\" width=\"575\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1b148885f64e24dbdf9496970c581de3a1c06a3e_2_575x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/1b148885f64e24dbdf9496970c581de3a1c06a3e.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/1b148885f64e24dbdf9496970c581de3a1c06a3e.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1b148885f64e24dbdf9496970c581de3a1c06a3e_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">WX20211031-025712@2x</span><span class=\"informations\">716\u00d7622 17.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>I saw that there are custom tables, but I\u2019m not quite sure how to use them. If it\u2019s easy to write, can someone give some hints about how to get custom tables to do this for me? Lots of thanks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-01T12:57:57.004Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/aceticia\">@aceticia</a>! Welcome to our W&amp;B forums and glad you\u2019re enjoying using W&amp;B for helping with your RL experiments.</p>\n<p>This is a workflow that we\u2019ll be making much easier in the future, making it easier to get min, max etc. for a given metric for a given run / group of runs. In the meantime, you can just log the max value at the end of your runs and get the median of that. We have a convenience method called <code>define_metric</code> which you can use to automatically do this for you.</p>\n<pre><code class=\"lang-python\">wandb.init(entity=\"wandb\", project=\"define-metric-demo\")\n# define a metric we are interested in the minimum of\nwandb.define_metric(\"loss\", summary=\"min\")\n# define a metric we are interested in the maximum of\nwandb.define_metric(\"acc\", summary=\"max\")\n</code></pre>\n<p>This will then log the max/min value of a given logged metric for you.<br>\nHere\u2019s more documentation of this method:</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/guides/track/log#customize-axes-and-summaries-with-define_metric\">\n  <header class=\"source\">\n      \n\n      <a href=\"https://docs.wandb.ai/guides/track/log#customize-axes-and-summaries-with-define_metric\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/guides/track/log#customize-axes-and-summaries-with-define_metric\" target=\"_blank\" rel=\"noopener\">Log Data with wandb.log</a></h3>\n\n  <p>Keep track of metrics, videos, custom plots, and more</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-01T17:41:31.664Z",
				"Answer_body": "<p>Thank you for the quick reply! This looks easy to change in my code. But for experiments that already happened, I assume there is no easy fix?</p>\n<p>The reason I\u2019m asking this is because currently I\u2019m using an RL platform called RLLib, which handles all wandb related code. I can\u2019t do the <code>wandb.define_metric</code> call without breaking their interface. I tried to call <code>init</code> and <code>define_metric</code> before  their <code>init</code> call, but this turns out to not log anything.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-03T09:53:34.470Z",
				"Answer_body": "<p>In future, this should be a lot easier and visible after experiments from the GUI, but currently, logging it yourself is the best option.<br>\nI\u2019ll reach out for more input for people on the team that might have more information about that RLLib integration. If that isn\u2019t fruitful, it might be worth opening an issue with the library maintainer (you could tag me, <span class=\"mention\">@scottire</span> on Github) to see if they have any recommendations.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-03T09:56:17.494Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"aceticia\" data-post=\"3\" data-topic=\"1172\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/a/7c8e57/40.png\" class=\"avatar\"> aceticia:</div>\n<blockquote>\n<p>The reason I\u2019m asking this is because currently I\u2019m using an RL platform called RLLib, which handles all wandb related code. I can\u2019t do the <code>wandb.define_metric</code> call without breaking their interface. I tried to call <code>init</code> and <code>define_metric</code> before their <code>init</code> call, but this turns out to not log anything.</p>\n</blockquote>\n</aside>\n<p>Looking at this documentation: <a href=\"https://docs.ray.io/en/latest/tune/tutorials/tune-wandb.html\" class=\"inline-onebox\">Using Weights &amp; Biases with Tune \u2014 Ray v1.8.0</a><br>\nIt seems possible to use the <code>@wandb_mixin</code> to access <code>wandb</code>. Have you been able to try that?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-03T13:54:06.211Z",
				"Answer_body": "<p>I have the exact same problem using PyTorch Lightning and WandbLogger. I am logging the metrics within my (general) PL framework, so it is not at all clear to me how to change the summary mode. Any suggestion? Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-11T17:17:01.691Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/nsacco\">@nsacco</a> In the case of PyTorch Lightning, you can hook in using a callback to ask <code>wandb</code> to log a summary metric.</p>\n<p>Here\u2019s an example callback that you can give to your trainer that will do that:</p>\n<pre><code class=\"lang-python\">class LogMinLossCallback(pl.Callback):\n    def on_train_epoch_start(self, trainer, pl_module):\n      if trainer.current_epoch == 0:\n        wandb.define_metric('train/loss_step', summary=\"min\")\n</code></pre>\n<p>This will add a new <code>train/loss_step.min</code> metric, the minimum loss, to be tracked by <code>wandb</code>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:07.730Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Delete artifact in s3",
		"Question_link": "https://community.wandb.ai/t/delete-artifact-in-s3/1228",
		"Question_created_time": "2021-11-04T20:04:44.051Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 351,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>\n<p>I was wondering if it\u2019s possible to delete an artifact that is a reference to an S3 object.<br>\nI mean deleting it within weight and biases but also from S3.</p>\n<p>If it\u2019s not built-in, is there any webhook that I can use to delete my model in S3 when deleting it from W&amp;B?</p>\n<p>The flow would be :</p>\n<ol>\n<li>Train =&gt; Push metrics to W&amp;B, push model to S3, add the S3 reference of the model as an artifact in W&amp;B.</li>\n<li>Evaluate, do some comparison, ML magic, etc\u2026</li>\n<li>Deciding to delete the run as another was better. Delete in W&amp;B, which will remove all the run and all the files in S3 associated with this run.</li>\n</ol>\n<p>Thanks in advance for any help.</p>\n<p>Have a great day <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-05T21:54:49.774Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ierezell\">@ierezell</a>,</p>\n<p>This is not supported inside of wandb. You can use <a href=\"https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html\" rel=\"noopener nofollow ugc\">Boto3\u2019s S3</a> API to delete objects from S3.</p>\n<p>W&amp;B does not store the data from any artifact references, only metadata related to the artifacts. As a result, we can not operate on that data.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-05T22:25:45.505Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a>,</p>\n<p>Thanks for the clarification <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>\n<p>Is there any possibility to have a webhook then?<br>\nSo when a delete is called wandb executes my hook to delete the corresponding S3 files ?</p>\n<p>Thanks in advance,<br>\nhave a great day</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-08T20:42:31.118Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ierezell\">@ierezell</a>,</p>\n<p>I apologize, but we don\u2019t support web hooks to S3 currently. The most secure way to programmatically delete your artifacts would be through Amazon\u2019s Boto3 API.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-07T20:42:42.921Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Using Wandb with HParams on TF",
		"Question_link": "https://community.wandb.ai/t/using-wandb-with-hparams-on-tf/1233",
		"Question_created_time": "2021-11-06T01:07:59.946Z",
		"Question_answer_count": 2,
		"Question_score_count": 1,
		"Question_view_count": 574,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>I think I may have got confused with this one. I had to code up a custom model using TF. It is training and running but I want to do some hyper parameter tuning so been working on getting HParms integrated.</p>\n<p>But I\u2019m trying to link up Wandb to keep track of things.</p>\n<p>Currently, since I\u2019m using hparms, when I initialize wandb with wandb.init(), it seems to initialize it for the whole process and it doesn\u2019t change when it is a new parameter set.</p>\n<p>I am calling the wandb.init() and logging after each parameter run, but still it doesn\u2019t create a unique job.</p>\n<p>This the function I call,</p>\n<pre><code class=\"lang-auto\">def write_to_wandb(ldl_model_params, KLi, f1_macro):\n    wandb.init(project=\"newjob1\", entity=\"demou\")\n    wandb.config = ldl_model_params\n\n    wandb_log = {\n        \"train KL\": KLi,\n        \"train F1\": f1_macro,\n        }\n\n    # logging accuracy\n    wandb.log(wandb_log)   \n</code></pre>\n<p>This is called from this train function (a high-level version of it). This <code>train_model</code> function is repeated again through another hyperparamter function with different hyper-parameter.</p>\n<pre><code class=\"lang-auto\">\ndef train_model(ldl_model_params,X,Y):\n    model = new_model(ldl_model_params)\n    model.fit(X,Y)\n    predict = model.transform(X)\n    KLi,F1 = model.evaluate(predict,Y)\n    write_to_wandb(ldl_model_params,KLi,F1)\n</code></pre>\n<p>So how do I fix this? I want each call to train_model to be recorded in a new run.</p>\n<p>I\u2019m new to wandb so I have a feeling that I am not using it as it should be. Thanks.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-08T17:17:12.513Z",
				"Answer_body": "<p>Just had a chat with the support and figured out how to fix the problem with over-writing.</p>\n<p>Issue was with the init function and there is a flag for reinitializing (<code>reinit=True</code>)</p>\n<p><code>wandb.init(project=\"newjob1\", entity=\"demou\",reinit=True)</code>  this fixed this issue.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-01-07T17:17:59.939Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sweep track loss from Tensorboard",
		"Question_link": "https://community.wandb.ai/t/sweep-track-loss-from-tensorboard/1226",
		"Question_created_time": "2021-11-04T18:57:27.640Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 224,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\nIs it possible to use sweep with a metric that is only visible in Tensorboard?<br>\nIt does show up on WandB when  sync_tensorboard=True</p>\n<p>But sweep does not seem to work properly when I use the name showing up in the GUI to be tracked and minimized.</p>\n<p>Thanks<br>\nBen</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-05T20:29:34.757Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ben-spex\">@ben-spex</a>, the metric needs to be visible on wandb for sweeps to work properly. If you like to share a link to your sweep page I can take a look at this.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-04T20:29:45.939Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb sweeps running on Kaggle GPU or Colab GPU are much slower than on my local CPU",
		"Question_link": "https://community.wandb.ai/t/wandb-sweeps-running-on-kaggle-gpu-or-colab-gpu-are-much-slower-than-on-my-local-cpu/794",
		"Question_created_time": "2021-09-27T10:02:32.286Z",
		"Question_answer_count": 6,
		"Question_score_count": 4,
		"Question_view_count": 424,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi there,</p>\n<p>i have run a few sweeps on my local computer and the same sweeps on Kaggle and Colab</p>\n<p>i have an i7 (10th gen) CPU in my home computer but no GPU<br>\ni measured around 50secs for 100 epochs (1 run)</p>\n<p>on Kaggle and Colab the same 100 epochs took 2mins 30secs (Colab) and ~3mins  (Kaggle) <em>using GPU</em></p>\n<p>how is that possible? am i doing something wrong?</p>\n<p>i observed this extreme slowdown only when using W&amp;B Sweeps<br>\nno slowdown when running single experiments</p>\n<p>please help, any idea appreciated!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-27T15:48:26.562Z",
				"Answer_body": "<p>Without seeing the code or a W&amp;B workspace, it\u2019s hard to say, but here are some thoughts:</p>\n<ol>\n<li>Running the agent is not enough overhead to cause a slowdown like you\u2019re seeing, so I suspect there\u2019s something else happening.</li>\n<li>Just switching to a GPU doesn\u2019t always speed you up, especially with eager evaluation. Selecting and launching kernels can take longer than executing them on the device.</li>\n<li>Could you check the per-epoch iteration time versus the total experiment time? If that has increased by 50%, we\u2019ll need to look inside each epoch for the cause of slowdown.</li>\n<li>If the per-epoch time hasn\u2019t gone up, it\u2019s likely that the end of the run is where you\u2019re getting the slowdown. This could be because you\u2019re logging more information during the sweep runs (large numbers/GB of media files, model files). The run won\u2019t terminate until everything has been uploaded.</li>\n</ol>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-28T07:54:48.683Z",
				"Answer_body": "<p>thank you for your answer!<br>\ni will try to run a few experiments with detailed timing data and get back</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-16T18:23:36.916Z",
				"Answer_body": "<p>Hi,</p>\n<p>i have run two different experiments with several runs and sweeps and shared everything using GitHub: <a href=\"https://github.com/teamtom/kaggle-vs-colab-speed\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">GitHub - teamtom/kaggle-vs-colab-speed: testing CPU/GPU speeds</a><br>\nthis Github repo contains the Jupyter files and my pipeline code</p>\n<p>The original slowdown were noticed with the Churn imbalanced dataset. I created a logistic regression model with a very simple network and tried to find a better threshold to improve the model with W&amp;B sweeps.</p>\n<p>I found that <strong>using GPU</strong> on either Kaggle or Colab the <strong>epoch time was way slower</strong> compared to running on CPU (on local machine, Kaggle and Colab)<br>\neg. Colab GPU was 2 times slower than Colab CPU or my local CPU (I7, 10th gen Intel)<br>\nKaggle GPU was better than Colab\u2019s but still slower than my local CPU</p>\n<hr>\n<p>I also run another experiment: it was MNIST dataset with a CNN to compare. This experiment contained solo runs and sweeps.<br>\ni observed <strong>no GPU slowdown</strong>, the acceleration proved to be ~3x using Kaggle; Colab was only ~2x</p>\n<p>so the questions:</p>\n<ul>\n<li>why GPU proved way slower than CPU with the first experiment? Is it related to the problem itself?</li>\n<li>is there any error in my models, calculations or in the pipeline?</li>\n</ul>\n<p>please help to understand, thank you!</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/bd774e4ba9518473bb4221a43d7d52287d992ea3.png\" data-download-href=\"/uploads/short-url/r25QURxA5wxj2kDhI5Ehe5eXWdJ.png?dl=1\" title=\"Churn+MNIST-W&amp;amp;B-Chart-10_16_2021\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/bd774e4ba9518473bb4221a43d7d52287d992ea3_2_435x500.png\" alt=\"Churn+MNIST-W&amp;B-Chart-10_16_2021\" data-base62-sha1=\"r25QURxA5wxj2kDhI5Ehe5eXWdJ\" width=\"435\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/bd774e4ba9518473bb4221a43d7d52287d992ea3_2_435x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/bd774e4ba9518473bb4221a43d7d52287d992ea3_2_652x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/bd774e4ba9518473bb4221a43d7d52287d992ea3_2_870x1000.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/bd774e4ba9518473bb4221a43d7d52287d992ea3_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"></use></svg><span class=\"filename\">Churn+MNIST-W&amp;amp;B-Chart-10_16_2021</span><span class=\"informations\">2090\u00d72400 110 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-16T18:32:34.925Z",
				"Answer_body": "<p>Hi,</p>\n<p>i have run two different experiments with several runs and sweeps and shared everything using GitHub: <a href=\"https://github.com/teamtom/kaggle-vs-colab-speed\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">GitHub - teamtom/kaggle-vs-colab-speed: testing CPU/GPU speeds</a></p>\n<p>this Github repo contains the Jupyter files and my pipeline code also my related W&amp;B projects</p>\n<p>The original slowdown were noticed with the Churn imbalanced dataset. I created a logistic regression model with a very simple network and tried to find a better threshold to improve the model with W&amp;B sweeps.</p>\n<p>I found that <strong>using GPU</strong> on either Kaggle or Colab the <strong>epoch time was way slower</strong> compared to running on CPU (on local machine, Kaggle and Colab)<br>\neg. Colab GPU was 2 times slower than Colab CPU or my local CPU (I7, 10th gen Intel)<br>\nKaggle GPU was better than Colab\u2019s but still slower than my local CPU</p>\n<hr>\n<p>I also run another experiment: it was MNIST dataset with a CNN to compare. This experiment contained solo runs and sweeps.<br>\ni observed <strong>no GPU slowdown</strong>, the acceleration proved to be ~3x using Kaggle; Colab was only ~2x</p>\n<p>so the questions:</p>\n<ul>\n<li>why GPU proved way slower than CPU with the first experiment? Is it related to the problem itself?</li>\n<li>is there any error in my models, calculations or in the pipeline?</li>\n</ul>\n<p>please help me to understand, thank you!</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/bd774e4ba9518473bb4221a43d7d52287d992ea3.png\" data-download-href=\"/uploads/short-url/r25QURxA5wxj2kDhI5Ehe5eXWdJ.png?dl=1\" title=\"Churn+MNIST-W&amp;amp;B-Chart-10_16_2021\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/bd774e4ba9518473bb4221a43d7d52287d992ea3_2_435x500.png\" alt=\"Churn+MNIST-W&amp;B-Chart-10_16_2021\" data-base62-sha1=\"r25QURxA5wxj2kDhI5Ehe5eXWdJ\" width=\"435\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/bd774e4ba9518473bb4221a43d7d52287d992ea3_2_435x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/bd774e4ba9518473bb4221a43d7d52287d992ea3_2_652x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/bd774e4ba9518473bb4221a43d7d52287d992ea3_2_870x1000.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/bd774e4ba9518473bb4221a43d7d52287d992ea3_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"></use></svg><span class=\"filename\">Churn+MNIST-W&amp;amp;B-Chart-10_16_2021</span><span class=\"informations\">2090\u00d72400 110 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-05T19:55:07.875Z",
				"Answer_body": "<p>Finally solved this issue.<br>\nI googled it and found that it is worth trying <strong>to increase batch size</strong> (it was as low as 32 in my original experiments)<br>\nso i tried again the same experiment with much higher bach sizes (512, 1000) and tadam!<br>\n<strong>i experienced  no GPU slowdown (not on Kaggle, either Colab)</strong></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:07.514Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Chrome Inline JavaScript Issue when Rendering Molecules",
		"Question_link": "https://community.wandb.ai/t/chrome-inline-javascript-issue-when-rendering-molecules/1217",
		"Question_created_time": "2021-11-03T21:20:07.326Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 304,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello, everyone.<br>\nI recently have been trying to log wandb.Molecule objects via PyTorch Lightning. However, when I view the logged Molecules in my web browser (Google Chrome, Version 95.0.4638.69, 64-Bit), I see the following error, preventing my Molecules from being rendered.</p>\n<p><em>[Report Only] Refused to apply inline style because it violates the following Content Security Policy directive: \u201cdefault-src \u2018none\u2019\u201d. Either the \u2018unsafe-inline\u2019 keyword, a hash (\u2018sha256-NFPvvJTeausaOnuU9syzBhm5OjQ9MGcbA9SexsBrsF4=\u2019), or a nonce (\u2018nonce-\u2026\u2019) is required to enable inline execution. Note also that \u2018style-src\u2019 was not explicitly set, so \u2018default-src\u2019 is used as a fallback.</em></p>\n<p>It looks to me like Chrome is preventing WandB\u2019s web site from rendering inline JavaScript. For reference, I have disabled any browser extension that may be affecting this, and that didn\u2019t seem to help.<br>\nAny ideas as to how to get around this issue? Without of course using a new browser <img src=\"https://emoji.discourse-cdn.com/twitter/wink.png?v=10\" title=\":wink:\" class=\"emoji\" alt=\":wink:\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-04T19:01:46.225Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/amorehead\">@amorehead</a>!</p>\n<p>Thank you for your question! This seems to be an issue on our end. I have notified the engineers of this issue and we will have it resolved ASAP.</p>\n<p>Thank you,<br>\nRamit<br>\nWeights &amp; Biases Support</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-04T21:03:05.057Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/amorehead\">@amorehead</a>! This problem has been fixed, you should be able to render molecules in your workspace now.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-04T21:29:31.000Z",
				"Answer_body": "<p>Ramit,</p>\n<p>Thank you very much for letting me know, and please thank the team on my behalf for their very quick response!</p>\n<p>Best,<br>\nAlex</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-03T21:30:09.055Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Parallelizing runs with multiple logical GPU's",
		"Question_link": "https://community.wandb.ai/t/parallelizing-runs-with-multiple-logical-gpus/1220",
		"Question_created_time": "2021-11-04T00:31:12.090Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 248,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>With Google Colab (or similar large GPUs setups and JupyterHub) you can create multiple logical/virtual GPU\u2019s and parallelize training runs assuming your models are small enough.</p>\n<pre><code class=\"lang-auto\">gpus = tf.config.list_physical_devices('GPU')\nif gpus:\n  # Create 2 virtual GPUs with 1GB memory each\n  try:\n    tf.config.set_logical_device_configuration(\n        gpus[0],\n        [tf.config.LogicalDeviceConfiguration(memory_limit=1024),\n         tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n    logical_gpus = tf.config.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    # Virtual devices must be set before GPUs have been initialized\n    print(e)\n</code></pre>\n<p>Is it possible to train multiple sweeps runs in parallel with logical GPU\u2019s within a Colab like environment?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-04T13:52:50.782Z",
				"Answer_body": "<p>Hi Kevin,</p>\n<p>Yes it is possible. To do so, you can do CUDA_VISIBLE_DEVICE=2 wandb agent , once for each of the GPUs on each of the machines.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-04T18:46:43.572Z",
				"Answer_body": "<p>I guess more specifically can this be done from a notebook environment? Looks like you\u2019re referencing a shell command. I believe that would break the virtual devices created by TF since you\u2019re leaving the environment in which the virtual devices were created.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-05T19:18:32.961Z",
				"Answer_body": "<p>Yes you can use multiple GPUs in both jupyter and google colab with wandb</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-03T18:46:53.881Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb process not getting terminated properly",
		"Question_link": "https://community.wandb.ai/t/wandb-process-not-getting-terminated-properly/1166",
		"Question_created_time": "2021-10-30T13:24:58.677Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 336,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>My process is not getting terminated properly (running in a multi-GPU setting). It is trying to upload information but gets stuck for some reason. I am facing this problem since yesterday, and haven\u2019t made any changes to the version of the library (although this didn\u2019t get resolved after upgrading the library to the latest version). Any help will be highly appreciated. I can disable wandb completely by passing <code>mode = \"disabled\"</code> in the test setting, but need it while running sweeps or logging training metrics.<br>\nP.S.: Same code was running just fine till yesterday.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/342fa335656c0535a9ca21307507f30ef53feb1d.png\" data-download-href=\"/uploads/short-url/7rETgzwUz7nuCquITds6NyYKXVj.png?dl=1\" title=\"Screenshot 2021-10-30 at 6.52.11 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/342fa335656c0535a9ca21307507f30ef53feb1d_2_690x69.png\" alt=\"Screenshot 2021-10-30 at 6.52.11 PM\" data-base62-sha1=\"7rETgzwUz7nuCquITds6NyYKXVj\" width=\"690\" height=\"69\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/342fa335656c0535a9ca21307507f30ef53feb1d_2_690x69.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/342fa335656c0535a9ca21307507f30ef53feb1d_2_1035x103.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/342fa335656c0535a9ca21307507f30ef53feb1d.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/342fa335656c0535a9ca21307507f30ef53feb1d_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2021-10-30 at 6.52.11 PM</span><span class=\"informations\">1048\u00d7106 27.4 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-01T22:01:27.217Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/adi-iitd\">@adi-iitd</a>,</p>\n<p>Thanks for your question! Could you share some details of your project so that I can get a better understanding of the issue. Specifically:</p>\n<ul>\n<li>What OS are you using?</li>\n<li>What version of python are you currently running?</li>\n<li>What version of the wandb client are you using?</li>\n<li>What library are you working with?</li>\n</ul>\n<p>If possible, I would also appreciate a minimal script that replicates the issue, so that I can get to the root of the problem.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-04T02:33:49.953Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a>, thanks for the response.<br>\nOS: Linux 18.04<br>\nPython: 3.8<br>\nWandb: Faced this issue first in 0.12.4, later updated it to 0.12.6, but the problem is not resolved yet.<br>\nLibrary: PyTorch Lightning (DDP Setting) + HuggingFace</p>\n<p>Hope this helps!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-04T16:32:49.788Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/adi-iitd\">@adi-iitd</a>,</p>\n<p>We have noticed a few users have similar issues with PyTorch Lightning DDP - your issue probably is related to how PyTorch lightning synchronizes GPUs with DDP. You can refer <a href=\"https://github.com/PyTorchLightning/pytorch-lightning/issues/5319\" rel=\"noopener nofollow ugc\">to this issue</a>, there is a workaround over there that might work for you.</p>\n<p>We are currently working on updating our Documentation and Examples so that we have better guides for situations like this. Till then, I hope the link above is helpful!</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-03T16:33:24.981Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Change logger handler",
		"Question_link": "https://community.wandb.ai/t/change-logger-handler/1203",
		"Question_created_time": "2021-11-02T19:30:50.395Z",
		"Question_answer_count": 3,
		"Question_score_count": 2,
		"Question_view_count": 295,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I use <a href=\"https://rich.readthedocs.io/en/stable/logging.html\" rel=\"noopener nofollow ugc\">RichHandler</a> everywhere in my code as well as <a href=\"https://rich.readthedocs.io/en/stable/traceback.html\" rel=\"noopener nofollow ugc\">Rich Tracebacks</a> as they\u2019re just useful beautiful and really convenient.</p>\n<p>I was wondering how I could integrate the handler with WandB to have my logs in the same format.</p>\n<p>Thanks in advance for any help.<br>\nHave a great day.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-03T16:48:28.423Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ierezell\">@ierezell</a> , let me check with some folks on this to see if this is possible.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-04T15:57:32.493Z",
				"Answer_body": "<p>There\u2019s not currently an easy way to do this but I think this would make a good feature request. I\u2019ll keep you updated on the status of this ticket.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-03T15:58:26.938Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "WandB not using user PID when updating",
		"Question_link": "https://community.wandb.ai/t/wandb-not-using-user-pid-when-updating/1204",
		"Question_created_time": "2021-11-02T19:49:53.147Z",
		"Question_answer_count": 5,
		"Question_score_count": 2,
		"Question_view_count": 328,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hello,</p>\n<p>I used  <code>tempfile.mkdtemp() </code> to create a temporary directory for my runs (as I don\u2019t want a persistent folder with tons of runs)</p>\n<p>For training everything works fine but when resuming the run to do some validation / evaluation updates, and using <code>run.summary.update({\"key\": value})</code> I got a</p>\n<pre><code class=\"lang-auto\">wandb: WARNING Path /tmp/tmpq5uafy4d/wandb/ wasn't writable, using system temp directory\n</code></pre>\n<p>with obviously</p>\n<pre><code class=\"lang-auto\">File \"/mnt/Projets/nlp/.venv/lib/python3.9/site-packages/wandb/sdk/internal/sender.py\", line 855, in _update_summary\n    with open(summary_path, \"w\") as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpq5uafy4d/wandb/run-20211102_153311-37264m5k/files/wandb-summary.json'\n</code></pre>\n<p>As in the doc of <a href=\"https://docs.python.org/3.9/library/tempfile.html#tempfile.mkdtemp\" rel=\"noopener nofollow ugc\"><code>mkdtemp</code></a> :</p>\n<pre><code class=\"lang-auto\"> The directory is readable, writable, and searchable only by the creating user ID.\n</code></pre>\n<p>So I guess WandB is not using the user ID and thus is not able to write in the directory for updating.<br>\nNote that this directory is different from the training one (as it\u2019s random at each init)</p>\n<p>Thanks in advance for any help.<br>\nHave a great day.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-03T15:31:05.874Z",
				"Answer_body": "<p>For the posterity :</p>\n<p>After searching for a long time with it, wandb firstly deletes my class object (which call deletion of the temp folder) <strong>and then</strong> try to update the run.</p>\n<p>To avoid that you need to first call <code>run.finish() or wandb.finish()</code> which will first update and then delete your object (or let the garbage collector do it)  thus it will be synced before the object is destroyed and the temp file removed.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-03T16:45:59.689Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ierezell\">@ierezell</a>, there are some reasons why you don\u2019t want to automatically delete your run folders, especially if there is an issue with the run. However, I do understand your desire to manage the clutter in your file system. It sounds like having a feature where you could tell wandb to delete the local files it created after a successful run would be the most preferable option for you. Currently, calling <code>wandb sync --clean</code> will sync any unsynced runs and then remove those run folders from your computer. The wandb dir will still be there and there but it will only be taking up bytes of space as most of the information will have been deleted. If you still find it annoying to have mostly empty <code>./wandb</code> folders in your project dirs, you can set the <code>WANDB_DIR</code> environment variable to an absolute path where all of your run data will be stored until you call <code>wandb sync --clean</code>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-03T18:08:15.337Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/aidanjd\">@aidanjd</a>,</p>\n<p>I didn\u2019t know the <code>wandb sync --clean</code> option!<br>\nIt\u2019s quite what I wanted to do, saving space and your solution will only delete finished runs which is nice <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>\n<p>I don\u2019t mind deleting failed run as I can just relaunch them again (it\u2019s small models on only one machine). This is why I put all my wandb folders in <code>/tmp</code> which means I keep the folder until I reboot.</p>\n<p>Is there any option to have the <code>clean</code> feature enabled by default? I mean for any run if sync is complete: delete the folder.</p>\n<p>Thanks for the response, I guess it solves it but we can continue discussing it.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-03T18:21:20.198Z",
				"Answer_body": "<p>As of now, there isn\u2019t an option to enable that by default. One issue you should be aware of is that if you are currently logging a run when you call <code>wandb sync --clean</code> bad things will happen. We\u2019re working on improving the the robustness of these features and will likely support an automatic clean option in the future.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2022-01-02T18:22:08.008Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wandb Agent - some runs fail",
		"Question_link": "https://community.wandb.ai/t/wandb-agent-some-runs-fail/1094",
		"Question_created_time": "2021-10-25T21:34:42.205Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 312,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019ve been using the Wandb agent to do some hyperparameter optimization with sweep config. Somehow approx. 70% of my runs fails.  This message is persisted:</p>\n<p>wandb: ERROR Run kyg8jl2m errored: InternalError()</p>\n<p>Is this a known issue?</p>\n<p>edit: I just did another 20 runs<br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/6fa137232597a0d819fa8d93bcea31af5fc491c8.png\" alt=\"image\" data-base62-sha1=\"fVwoTFqCbnNIdB63Atkf4ye1nm0\" width=\"585\" height=\"211\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-03T17:02:35.060Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/gazi\">@gazi</a>,</p>\n<p>Could you email us at <a href=\"mailto:support@wandb.com\">support@wandb.com</a> about this?</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-02T17:03:24.930Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "HP sweep - correct way to stop a specific agent (and not the entire sweep)",
		"Question_link": "https://community.wandb.ai/t/hp-sweep-correct-way-to-stop-a-specific-agent-and-not-the-entire-sweep/1173",
		"Question_created_time": "2021-10-31T13:23:16.678Z",
		"Question_answer_count": 5,
		"Question_score_count": 3,
		"Question_view_count": 676,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I am conducting a parameter sweep, and I use my dev machine during the night for extra compute. My problem is that I don\u2019t know how to correctly stop the local runs. Any suggestions or best practices would be appreciated.</p>\n<p>A related question - if I stop an agent run forcefully (for instance, close the process running the agent) how would the sweep controller handle the run data? would it remove it from the dashboard? would it be indicated in any way?</p>\n<p>Thanks,<br>\nTom</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-01T19:18:59.802Z",
				"Answer_body": "<p>Hi Tom,</p>\n<p>You can use the W&amp;B Dashboard or end the process in order to kill a sweep. You can use the \u201csweep controls\u201d option in the sweeps menu to control your sweep. I have attached an image of the sweep dashboard for context:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9976ac854c5c805b000120b63110dcc2fe640d06.jpeg\" data-download-href=\"/uploads/short-url/lTBjga2bfz2xwlt26urnnf6KxBY.jpeg?dl=1\" title=\"Screen Shot 2021-11-01 at 12.14.17 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9976ac854c5c805b000120b63110dcc2fe640d06_2_646x500.jpeg\" alt=\"Screen Shot 2021-11-01 at 12.14.17 PM\" data-base62-sha1=\"lTBjga2bfz2xwlt26urnnf6KxBY\" width=\"646\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9976ac854c5c805b000120b63110dcc2fe640d06_2_646x500.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9976ac854c5c805b000120b63110dcc2fe640d06_2_969x750.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9976ac854c5c805b000120b63110dcc2fe640d06_2_1292x1000.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9976ac854c5c805b000120b63110dcc2fe640d06_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2021-11-01 at 12.14.17 PM</span><span class=\"informations\">1418\u00d71096 57.6 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>The pause option lets you pause the sweep, which means that the agent will finish the current run and wait till you unpause the run again. You can also stop the run, which will wait for the current run to end, after which it will end the process.</p>\n<p>In case you choose to Cancel the run, any run taking place at the time will stop without waiting for the training cycle to end. Any metrics that have already been logged to W&amp;B will still be visible in your dashboard.</p>\n<p>Similarly, if you were to forcefully stop a process, the agent will stop running and any metrics already logged to the W&amp;B Dashboard will still be present.</p>\n<p>All the best,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-02T14:35:57.807Z",
				"Answer_body": "<p>Thank you for your response!</p>\n<p>In that case, if I may suggest a feature request: since the sweep is aware of the agents currently running, it would be great to kill or pause\\resume a specific agent (instead of all the agents).</p>\n<p>Cheers,<br>\nTom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-02T17:29:18.413Z",
				"Answer_body": "<p>You are welcome! Thank you for your feature request, I will pass this information to the engineering team.</p>\n<p>Is there anything else I can help you with?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-03T11:55:52.183Z",
				"Answer_body": "<p>Thank you for your help <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-02T11:56:18.704Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to log multiple metrics to the same chart?",
		"Question_link": "https://community.wandb.ai/t/how-to-log-multiple-metrics-to-the-same-chart/1160",
		"Question_created_time": "2021-10-30T06:05:46.747Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 753,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Under <a href=\"https://docs.wandb.ai/guides/track/log#common-workflows\" class=\"inline-onebox\">Log Data with wandb.log - Documentation</a> it says I can have multiple metrics show up on the same chart by logging them in the same dict. On the UI they still show up on different charts though <img src=\"https://emoji.discourse-cdn.com/twitter/frowning.png?v=10\" title=\":frowning:\" class=\"emoji\" alt=\":frowning:\"><br>\nAny ideas on what I could be doing wrong? I can post code if necessary but I really don\u2019t think I\u2019m using the API incorrectly</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-01T13:04:41.401Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/rowan-dempster\">@rowan-dempster</a>, welcome to our forums!</p>\n<p>By default, each chart has one metric but you can easily add other metrics in the UI by editing a chart using the pencil icon in the top right (appears on hover) and adding the other metric or metrics you care about to your Y-axis.<br>\nHope this helps!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-01T16:36:54.491Z",
				"Answer_body": "<p>Hi Scott,</p>\n<p>Thanks for your reply and your suggestion. This is the approach I have been taking and would be satisfactory if I did not have to re-create the chart parameters for every run. Is there a way to have a specific chart config show up by default on new runs of the same project?</p>\n<p>Thanks,<br>\nRowan</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-01T16:45:04.327Z",
				"Answer_body": "<p>Glad you found that solution yourself.</p>\n<blockquote>\n<p>Is there a way to have a specific chart config show up by default on new runs of the same project?</p>\n</blockquote>\n<p>When you create or edit a chart (panel) in a <a href=\"https://docs.wandb.ai/ref/app/pages/run-page\">Run Page</a>, it should appear on your other runs\u2019 Run Page.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-01T17:37:36.694Z",
				"Answer_body": "<blockquote>\n<p>When you create or edit a chart (panel) in a <a href=\"https://docs.wandb.ai/ref/app/pages/run-page\">Run Page</a>, it should appear on your other runs\u2019 Run Page.</p>\n</blockquote>\n<p>This is the behavior I was expecting, but I am not observing it. Specifically, whenever a new run is logged the charts I see are always the same (just one chart per metric). New custom charts, and sections for that matter, are not preserved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-01T21:24:11.432Z",
				"Answer_body": "<blockquote>\n<p>but I am not observing it</p>\n</blockquote>\n<p>I take this back, I just observed the charts synchronizing themselves across runs. But it does not happen consistently, I just started another runs and the custom charts are not present. Maybe they show after the run finishes?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-03T10:10:28.296Z",
				"Answer_body": "<aside class=\"quote no-group quote-modified\" data-username=\"rowan-dempster\" data-post=\"5\" data-topic=\"1160\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/r/73ab20/40.png\" class=\"avatar\"> rowan-dempster:</div>\n<blockquote>\n<blockquote>\n<p>When you create or edit a chart (panel) in a <a href=\"https://docs.wandb.ai/ref/app/pages/run-page\">Run Page</a>, it should appear on your other runs\u2019 Run Page.</p>\n</blockquote>\n</blockquote>\n</aside>\n<p>The expected behaviour of this is that the chart will show up when possible in the run. For example, if you try plot \u201ctest_accuracy\u201d but you haven\u2019t logged that yet for a given run, that chart won\u2019t show up. As soon as you have logged a value for the metric you\u2019re trying to display, you chart displaying that should appear.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-02T10:11:20.754Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Get S3 Filepath for WandB Artifact",
		"Question_link": "https://community.wandb.ai/t/get-s3-filepath-for-wandb-artifact/990",
		"Question_created_time": "2021-10-15T17:13:38.300Z",
		"Question_answer_count": 2,
		"Question_score_count": 2,
		"Question_view_count": 373,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi team,</p>\n<p>If I use W&amp;B Artifacts with an S3 Reference, is there any easy way to get the underlying S3 URI?</p>\n<pre><code class=\"lang-auto\">artifact = run.use_artifact('my_artifact:latest')\ns3_path = artifact.&lt;some_method&gt;()\n</code></pre>\n<p>For context, I\u2019m trying to train a HuggingFace model with Sagemaker. When I spin up the job, Sagemaker expects paths to local files or S3 URIs to the dataset. I\u2019m trying to avoid downloading the data to my local machine, by getting the proper S3 URL via W&amp;B Artifacts; since I\u2019m already using Artifacts for data versioning.</p>\n<p>Thank you in advance!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-18T12:45:14.201Z",
				"Answer_body": "<p>Hey Sahil,</p>\n<p>We don\u2019t save it automatically but you can save the s3 uri in the artifact metadata object. Here is a link to the documentation for more details.</p>\n<p>Regards,<br>\nArman</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-02T22:57:40.635Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/armanharutyunyan\">@armanharutyunyan</a>  and <a class=\"mention\" href=\"/u/sahilchopra\">@sahilchopra</a></p>\n<p>I would love to have a similar function.</p>\n<p>When you go to your Dataset Artifact on the WandB web interface it actually shows under Files all the s3 URLs of all objects within the dataset.</p>\n<p>It would be awesome if we could use the same logic as described here: <a href=\"https://wandb.ai/wandb/arttest/reports/Intro-to-W-B-Artifacts--VmlldzozNTAzMDM\" class=\"inline-onebox\">Weights &amp; Biases</a> without the need to actually download the data.</p>\n<p>Especially since most of us will eventually train on GCP or AWS, the workflow will almost never including the download of the files into the current instance.<br>\nTensorFlow lets you use and query data from S3 or GCP buckets without any problems.</p>\n<p>Please look into this</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to find out if wandb service is down",
		"Question_link": "https://community.wandb.ai/t/how-to-find-out-if-wandb-service-is-down/1188",
		"Question_created_time": "2021-11-01T19:37:25.251Z",
		"Question_answer_count": 4,
		"Question_score_count": 2,
		"Question_view_count": 341,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Yesterday, wandb initialization was working for me both from my local desktop and on a remote EC2 instance. Today, I get the following error:</p>\n<pre><code class=\"lang-auto\">**wandb** : Network error (ReadTimeout), entering retry loop. See wandb/debug-internal.log for full traceback.\n</code></pre>\n<p>I haven\u2019t changed anything about the settings, so this makes me think this is a wandb service issue. Is there a page on the website that tells the status of wandb services?</p>\n<p>Thanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-01T20:24:51.681Z",
				"Answer_body": "<p>Hi Ryan,</p>\n<p>We are currently experiencing some issues with degraded performance, which is likely the cause of the error. We are aware of this problem, and are trying to fix it as soon as possible. You can check  <a href=\"https://status.wandb.com\" rel=\"noopener nofollow ugc\">here</a> to check the status of our service.</p>\n<p>As a workaround for now, you can run wandb fully <a href=\"https://docs.wandb.ai/guides/technical-faq#can-i-run-wandb-offline\">offline</a>, and sync your files later using  <code>wandb sync</code>. Since you will be training offline, no network requests will be made.</p>\n<p>We apologize for the inconvenience caused.</p>\n<p>Thanks</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-02T17:39:22.355Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/ramit_goolry\">@ramit_goolry</a> I encountered the same issue, and at the time the status page hadn\u2019t been updated (despite getting the aforementioned timeout message for about an hour).</p>\n<p>It would be useful to have it either updated faster, or have status updates posted on Twitter (or equivalent). I spent about 2 hours trying to figure out the issue on our side before realising it was an issue on the W&amp;B side after seeing a random comment on Twitter.</p>\n<p>Thanks!</p>\n<p>Nicolas</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-02T21:12:54.596Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/nicjac\">@nicjac</a>,</p>\n<p>I apologize for the delay for the update. I will let the engineering team know that the status page needs to be updated more frequently in case of an outage.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-01T21:13:41.751Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Programmatically accessing artifact object very slow for first call for large artifacts",
		"Question_link": "https://community.wandb.ai/t/programmatically-accessing-artifact-object-very-slow-for-first-call-for-large-artifacts/1158",
		"Question_created_time": "2021-10-29T17:07:26.634Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 349,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello!</p>\n<p>I came across this issue recently, and I was wondering whether anything can be done to speed up this process. We are using W&amp;B as source of truth for versioning of our datasets. Each dataset is an artefact in a specific project, and files making up this dataset are added as references (everything is stored on S3).</p>\n<p>We sometime need to retrieve the path (including version) to a specific file in the artefact. This is typically very fast (&lt;1s) but for larger artefact (made up of &gt;10K references), the process can slow down significantly and take up to 30 seconds. We realized that this holds true whenever we try to access the artifact for the first time (e.g. getting its digest).</p>\n<p>Is it expected that artifacts with a large number of files will result in long wait for the first operation when accessing in programmatically in Python?</p>\n<p>We typically use the public API to access the artifact (see below for example) but the same happens when using a run.</p>\n<pre><code class=\"lang-auto\">api = wandb.Api()\nartifact = api.artifact(\"my_org/my_project/my_artifact:latest\")\nfile_info = artifact.get_path(\"example_file_in_artifact\")\ns3_path = file_info.ref\ns3_version = file_info.extra[\"versionID\"]\n</code></pre>\n<p>Thanks!</p>\n<p>Nicolas</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-01T13:19:04.665Z",
				"Answer_body": "<p>Hi Nicolas, if the artifact is large, it will take longer for it to download for the first operation. As you already stated, if you indicate the path, it\u2019ll be faster to download, and you can also indicate the type of artifact you want in order to get a specific datatype from the artifact by using the following code:</p>\n<p>runs = api.runs(\u2026) for run in runs:<br>\nfor artifact in run.logged_artifacts():<br>\nif artifact.type == \u201cmodel\u201d:<br>\nartifact.download()</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-02T17:36:50.999Z",
				"Answer_body": "<p>Hi <span class=\"mention\">@Leslie</span>,</p>\n<p>Thank you for your reply.</p>\n<p>In my case, I am not trying to download the artefact, but merely to get the path to one of the file it includes. It is not obvious to me that the length of this operation should be proportional to the size of the dataset?</p>\n<p>Happy to provide more details if useful.</p>\n<p>Thanks.</p>\n<p>Regards,<br>\nNicolas</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-04T19:16:48.510Z",
				"Answer_body": "<p>Thank you for the clarification. We are currently working on optimizing our artifacts to speed up artifact.get, but yes currently to get the time to get these artifacts is correlated to the size of the artifacts.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-01T17:36:58.869Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-05T21:10:17.472Z",
				"Answer_body": "<p>Hi again Nicolas, when our engineers tried to repro this, two artifacts with S3 references (one with 10K and one with 100K), it takes 0.5 seconds and 2 seconds, respectively using the code that is given. Is it possible for you to give us a more detailed script of what you are doing to get this lag?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-18T19:58:49.879Z",
				"Answer_body": "<p>Hi Nicolas,</p>\n<p>Is it possible for you to give us a more detailed script so we can fix this issue?</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-02-22T14:12:55.701Z",
				"Answer_body": "<p>Hi Nicolas,</p>\n<p>Since we have not heard back from you we are going to close this request. If you would like to re-open the conversation, please let us know!</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Invalid artifact",
		"Question_link": "https://community.wandb.ai/t/invalid-artifact/1198",
		"Question_created_time": "2021-11-02T14:31:28.014Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 352,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>When trying to add a reference to an object stored on s3 I got a :</p>\n<pre><code class=\"lang-auto\">CommError: Invalid artifact path: s3://my_bucket_names/my_lang_folder/my_subfolder/my_file.json\n</code></pre>\n<p>I used :</p>\n<pre><code class=\"lang-auto\"> self.run = wandb.init(\n     project=\"my_project\",\n     entity=\"my_group_name\",\n      dir=self.temp_dir,\n      resume=bool(config.previous_model),\n )\n\n for dataset in config.datasets:\n    self.run.use_artifact(\n        f\"s3://my_bucket_name/{make_path(dataset['lang'],dataset['type'],[],dataset['name'],'json')}\",\n        type=\"train_dataset\",\n    )\n</code></pre>\n<p>I\u2019m sure the dataset exists in this bucket. However, it\u2019s a private bucket but I have access to it with my credentials.</p>\n<p>Thanks in advance for any help.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-02T14:47:32.463Z",
				"Answer_body": "<p>Note for the posterity:</p>\n<p>I managed to make it work by firstly creating an Artifact like so :</p>\n<pre><code class=\"lang-auto\">artifact = wandb.Artifact(\"dataset_name\", type=\"train_dataset\")\nartifact.add_reference(f\"s3://my_bucket/{make_path(dataset_metas['lang'],dataset_metas['type'],[],dataset_metas['name'],'json')}\", name=\"dataset_name\")\nself.run.use_artifact(artifact)\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-02T14:59:36.564Z",
				"Answer_body": "<p>I\u2019m glad you were able to solve your problem. Have a good rest of the day</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-01T14:48:30.705Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Moving projects from one team to another",
		"Question_link": "https://community.wandb.ai/t/moving-projects-from-one-team-to-another/1192",
		"Question_created_time": "2021-11-02T08:52:48.904Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 277,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi All,<br>\nWanted to know if it is possible to move projects from one team to another. I want to add a user for a specific project instead of adding him to the team which owns the project. Since it was not possible I thought that a workaround would be to create new team with the specific user and transferring the desired project.</p>\n<p>Thanks in advance.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-02T12:57:47.006Z",
				"Answer_body": "<p>Hi Aviv,</p>\n<p>We can transfer projects for you back here. Can you please let us know the team you want to transfer to and from and the project name? Since this is a public forum, you can send us the information at <a href=\"mailto:support@wandb.com\">support@wandb.com</a> if you want to.</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-05T13:04:27.206Z",
				"Answer_body": "<p>Hi Aviv,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-08T14:20:19.931Z",
				"Answer_body": "<p>Hello Aviv,</p>\n<p>Our agent Leslie has tried to contact you about this request but we haven\u2019t heard back from you yet. Please let us know if we can be of further assistance.</p>\n<p>Thanks,<br>\nWeights and Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-01-01T08:52:50.778Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Scripting reports?",
		"Question_link": "https://community.wandb.ai/t/scripting-reports/1170",
		"Question_created_time": "2021-10-30T22:10:40.070Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 316,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello Wandb community,</p>\n<p>Is there a way to script reports in Wandb or make report templates? I find myself having to make similar reports for different wandb projects and t would be awesome if there was a way to do this programmatically</p>\n<p>Thanks<br>\nTed</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-11-01T13:57:15.188Z",
				"Answer_body": "<p>Hi Ted,</p>\n<p>We don\u2019t currently have that functionality, but I will put in a ticket for the engineering team for this <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-01T23:24:56.403Z",
				"Answer_body": "<p>Thank you Leslie, that\u2019s awesome!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-31T23:25:13.804Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-07-06T15:09:04.739Z",
				"Answer_body": "<p>Hi Ted,</p>\n<p>Programmatic report templates have been implemented into wandb! Please update to the most current version to use this feature.</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Create your team fails",
		"Question_link": "https://community.wandb.ai/t/create-your-team-fails/1149",
		"Question_created_time": "2021-10-29T07:18:07.008Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 761,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hey! I am trying to create a team but after trying 10 times (with obscure team names) I still get the following error: \u201cError creating team (an organization with this name already exists). Please try again.\u201d</p>\n<p>What am I doing wrong? Thank you!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-29T09:32:32.755Z",
				"Answer_body": "<p>Hi, Sorry that you\u2019re having this issue. We\u2019ll be making it much easier to make teams in the near future. For the moment, have you tried to change the organization name (as opposed to the team name)?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-29T10:34:10.122Z",
				"Answer_body": "<p>Yes! that worked! You should allow people to create a team from ETH Zurich <img src=\"https://emoji.discourse-cdn.com/twitter/wink.png?v=10\" title=\":wink:\" class=\"emoji\" alt=\":wink:\"></p>\n<p>Thanks for the super quick answer. WANDB is amazing! Gracias</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-29T16:02:32.696Z",
				"Answer_body": "<p>Glad that fixed your issue and you\u2019re enjoying using W&amp;B!</p>\n<blockquote>\n<p>Gracias</p>\n</blockquote>\n<p>De nada</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-28T16:03:29.755Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Running wandb.init() locally causes permission error",
		"Question_link": "https://community.wandb.ai/t/running-wandb-init-locally-causes-permission-error/824",
		"Question_created_time": "2021-09-30T22:36:10.454Z",
		"Question_answer_count": 4,
		"Question_score_count": 1,
		"Question_view_count": 516,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello, wandb newbie here. I\u2019m trying to run my first local wandb project locally on a work machine (macOS) where I have admin status. Unfortunately when I run,</p>\n<p><code>wandb.init(project=\"my_project\")</code></p>\n<p>I get the following permission error. Thanks in advance for any helpful feedback!</p>\n<pre><code class=\"lang-auto\">wandb: You can find your API key in your browser here: http://localhost:8080/authorize\nTraceback (most recent call last):\n  File \"/opt/miniconda3/envs/abcnet/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 800, in init\n    wi.setup(kwargs)\n  File \"/opt/miniconda3/envs/abcnet/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 167, in setup\n    wandb_login._login(anonymous=anonymous, force=force, _disable_warning=True)\n  File \"/opt/miniconda3/envs/abcnet/lib/python3.7/site-packages/wandb/sdk/wandb_login.py\", line 268, in _login\n    wlogin.prompt_api_key()\n  File \"/opt/miniconda3/envs/abcnet/lib/python3.7/site-packages/wandb/sdk/wandb_login.py\", line 196, in prompt_api_key\n    key, status = self._prompt_api_key()\n  File \"/opt/miniconda3/envs/abcnet/lib/python3.7/site-packages/wandb/sdk/wandb_login.py\", line 184, in _prompt_api_key\n    no_create=self._settings.force if self._settings else None,\n  File \"/opt/miniconda3/envs/abcnet/lib/python3.7/site-packages/wandb/sdk/lib/apikey.py\", line 121, in prompt_api_key\n    write_key(settings, key, api=api)\n  File \"/opt/miniconda3/envs/abcnet/lib/python3.7/site-packages/wandb/sdk/lib/apikey.py\", line 211, in write_key\n    api.clear_setting(\"anonymous\", globally=True, persist=True)\n  File \"/opt/miniconda3/envs/abcnet/lib/python3.7/site-packages/wandb/sdk/internal/internal_api.py\", line 256, in clear_setting\n    Settings.DEFAULT_SECTION, key, globally=globally, persist=persist\n  File \"/opt/miniconda3/envs/abcnet/lib/python3.7/site-packages/wandb/old/settings.py\", line 69, in clear\n    clear_setting(self._global_settings, Settings._global_path(), persist)\n  File \"/opt/miniconda3/envs/abcnet/lib/python3.7/site-packages/wandb/old/settings.py\", line 65, in clear_setting\n    with open(settings_path, \"w+\") as f:\nPermissionError: [Errno 13] Permission denied: '/Users/andrew/.config/wandb/settings'\nwandb: ERROR Abnormal program exit\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-11T23:16:51.644Z",
				"Answer_body": "<p>Hi Andrew, I\u2019m sorry you\u2019re having problems with this. Can you try making sure you\u2019re logged in by running <code>wandb login</code> in your terminal.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-20T21:31:21.422Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/andrew1\">@andrew1</a>, are you still having issues?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-21T03:01:18.517Z",
				"Answer_body": "<p>Thanks for the reply. When I go to check login I now can\u2019t see my API and it says I need to contact sales team to obtain a free license (just did that)</p>\n<pre><code class=\"lang-auto\">wandb login\n</code></pre>\n<p>Go to localhost</p>\n<p>Get the following screen. <div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/f9da3a942d7fd9d2446584794a643de8307c2d9e.jpeg\" data-download-href=\"/uploads/short-url/zEirtOt4OXwWe2cUVPeZv42GeEC.jpeg?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f9da3a942d7fd9d2446584794a643de8307c2d9e_2_690x497.jpeg\" alt=\"image\" data-base62-sha1=\"zEirtOt4OXwWe2cUVPeZv42GeEC\" width=\"690\" height=\"497\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f9da3a942d7fd9d2446584794a643de8307c2d9e_2_690x497.jpeg, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f9da3a942d7fd9d2446584794a643de8307c2d9e_2_1035x745.jpeg 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/f9da3a942d7fd9d2446584794a643de8307c2d9e.jpeg 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f9da3a942d7fd9d2446584794a643de8307c2d9e_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1179\u00d7850 102 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-28T19:45:01.934Z",
				"Answer_body": "<p>Hi Andrew,</p>\n<p>Have you gone through the steps successfully or are you hung up on something?</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Delete user account",
		"Question_link": "https://community.wandb.ai/t/delete-user-account/1140",
		"Question_created_time": "2021-10-28T14:41:47.787Z",
		"Question_answer_count": 2,
		"Question_score_count": 1,
		"Question_view_count": 246,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have accidentally created two accounts.<br>\nI want to delete this account please.</p>\n<p>My user name is ab3-yang</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-28T15:52:05.438Z",
				"Answer_body": "<p>Hey there, the account has been deleted.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-27T15:52:31.952Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Is there a way to only update specific parts of a Table?",
		"Question_link": "https://community.wandb.ai/t/is-there-a-way-to-only-update-specific-parts-of-a-table/1110",
		"Question_created_time": "2021-10-27T09:35:20.572Z",
		"Question_answer_count": 10,
		"Question_score_count": 10,
		"Question_view_count": 453,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello Everyone! (Long time user, first time poster <img src=\"https://emoji.discourse-cdn.com/twitter/slightly_smiling_face.png?v=12\" title=\":slightly_smiling_face:\" class=\"emoji\" alt=\":slightly_smiling_face:\" loading=\"lazy\" width=\"20\" height=\"20\">)</p>\n<p>I just started using WandB tables to log my predictions alongside their input images. It has been very useful so far. My problem arises when I run my code on a cluster we have at my university.</p>\n<p>For simplicity, let\u2019s say that every epoch, I am logging a table with the following columns: <code>[id, Image, prediction]</code> which is a list of <code>[string, wandb.Image, int]</code>.</p>\n<p>Every time<code> wandb.Image()</code> is called, it saves the image employing the PIL library (can be seen below).  My problem arises when, after a certain number of epochs, I run into memory problems:</p>\n<pre><code class=\"lang-auto\"> Traceback (most recent call last):\n  File \"/mnt/gpid07/imatge/carlos.hernandez/Documents/PhD/2021/marato-derma/derma/sol/cnn_recommendations/processing/train_utils.py\", line 206, in log_wandb_table\n    row = [img_id, wandb.Image(image),\n  File \"/mnt/gpid07/imatge/carlos.hernandez/Documents/base/lib/python3.6/site-packages/wandb/sdk/data_types.py\", line 1587, in __init__\n    self._initialize_from_data(data_or_path, mode)\n  File \"/mnt/gpid07/imatge/carlos.hernandez/Documents/base/lib/python3.6/site-packages/wandb/sdk/data_types.py\", line 1700, in _initialize_from_data\n    self._image.save(tmp_path, transparency=None)\n  File \"/mnt/gpid07/imatge/carlos.hernandez/Documents/base/lib/python3.6/site-packages/PIL/Image.py\", line 2102, in save\n    save_handler(self, fp, filename)\n  File \"/mnt/gpid07/imatge/carlos.hernandez/Documents/base/lib/python3.6/site-packages/PIL/PngImagePlugin.py\", line 900, in _save\n    ImageFile._save(im, _idat(fp, chunk), [(\"zip\", (0, 0) + im.size, 0, rawmode)])\n  File \"/mnt/gpid07/imatge/carlos.hernandez/Documents/base/lib/python3.6/site-packages/PIL/ImageFile.py\", line 511, in _save\n    fp.write(d)\n  File \"/mnt/gpid07/imatge/carlos.hernandez/Documents/base/lib/python3.6/site-packages/PIL/PngImagePlugin.py\", line 748, in write\n    self.chunk(self.fp, b\"IDAT\", data)\n  File \"/mnt/gpid07/imatge/carlos.hernandez/Documents/base/lib/python3.6/site-packages/PIL/PngImagePlugin.py\", line 735, in putchunk\n    fp.write(data)\nOSError: [Errno 28] No space left on device\n</code></pre>\n<p>I was wondering if Tables allow only to update specific columns. The <code>id</code> and <code>Image</code> remain constant for the entire training, the only values that I am interested in their evolution are the predictions.</p>\n<p>Has anyone encountered a similar problem? Any ideas on how to shortcut my lack of memory would be welcome!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-27T11:45:27.914Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/carloshernandezp\">@carloshernandezp</a> , thanks for asking this question. I think you can prevent this from happening by logging the table with actual data once and using the reference to already logged data to build the table for the next iteration.<br>\nHere\u2019s a snippet for more clarity.</p>\n<pre><code class=\"lang-auto\">\n# define the main table \nevalset_table = None\n\ndef log_new_table():\n       # initialize new table\n       table = ... # [\"image\", \"id\"]\n       for i, img in enumerate(loader):\n          if not evalset_table: \n              # add images if evalset table isn't initialized\n         else:\n             # use reference to evalset table if it is already logged\n             table.add_data(evalset_table.data[i], i)\n         \n         # log this table as evalset is not logged already. \n       if evalset_table is None:\n            eval_art = wandb.Artifact(_run.id + table_name, type=\"dataset\")\n            eval_art.add(table, \"evalset\")\n            _run.use_artifact(eval_art)\n            evalset_table= eval_art.get(\"evalset\")\n\n</code></pre>\n<p>Let me know if something isn\u2019t clear</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-27T13:48:52.379Z",
				"Answer_body": "<p>Hello <a class=\"mention\" href=\"/u/cayush\">@cayush</a>, thanks for the quick response.</p>\n<p>I understand how using the reference to the already logged data will solve my issue. But two questions come to my mind.</p>\n<p>Firstly, in the line <code>table.add_data(evalset_table.data[i], i)</code> did you mean to type <code>...(evalset_table.data[i], img)</code> implying that at position <code>i</code> you add the data of <code>img</code>.  A</p>\n<p>Secondly, how is the data at <code>evalset_table</code> updated in <code>wandb</code>? The way I was updating the data was through a <code>wandb.Table</code> that I would then log with <code>wand.run.log</code>. Is it uploaded automatically through changing the values in <code>table.add_data(...)</code>?</p>\n<p>Here is a simplified version of what I am doing so far:</p>\n<pre><code class=\"lang-auto\">table = wand.Table(columns=columns) # columns are [id, Image, prediction]\n\nfor i, id, img, pred in enumerate(...): #omitting what I'm iterating for simplicity\n      row = [id, img, pred]\n      table.add(*row)\n</code></pre>\n<p>So, as far as I understand I should change the iteration to:</p>\n<pre><code class=\"lang-auto\">table = wand.Table(columns=columns) # columns are [id, Image, prediction]\n\nfor i, id, img, pred in enumerate(...): #omitting what I'm iterating for simplicity\n      row = [id, img, pred]\n      table.add_data(evalset_table.data[i], *row)\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-27T15:02:47.457Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/carloshernandezp\">@carloshernandezp</a> yes you\u2019re right about point 1. I was just using that as example.<br>\nfor point 2, you\u2019ll still need to log the tables using <code>run.log{name: table}</code>. It just that the tables that use the reference to other tablets won\u2019t upload the images again. Just add <code>run.log{name: table}</code> at the end of the loop</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-27T16:35:12.642Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/cayush\">@cayush</a>  Gotcha, I think I am almost there:</p>\n<p>So far my code is looking like this:</p>\n<pre><code class=\"lang-auto\">\ndef log_new_table():\n       # initialize new table\n       table = wand.Table(columns=columns) # columns are [id, Image, prediction]\n       for i, id, img, pred  in enumerate(loader):\n         row = [id, img, pred] \n         if not evalset_table: \n              # add images if evalset table isn't initialized\n             table_add_data(*row)\n         else:\n             # use reference to evalset table if it is already logged\n             evalset_table.data[i] = *row\n             table.add_data(*evalset_table.data[i])       #Mark 1\n         \n         # log this table as evalset is not logged already. \n       if evalset_table is None:\n            eval_art = wandb.Artifact(wand.run.id + table_name, type=\"dataset\")\n            eval_art.add(table, \"evalset\")\n            wand.run.use_artifact(eval_art)\n            eval_art.wait() # Without this line the code broke\n            evalset_table= eval_art.get(\"evalset\")\n            wandb.run.log({'Evaluation table' : evalset_table}) # Mark2\n</code></pre>\n<p>The change in  <code>#Mark1</code> compared to your snippet is due to the size of the table. Therefore, I needed to give something of the same length.  Also, in <code>Mark2</code>, I logged the <code>evalset_table</code>, but I am unsure that this is needed.</p>\n<p>I have run some training logging things for 30 minutes, and I have not had a space issue. However, I do see that the every few epochs, some errors pop up regarding the <code>/tmp</code> files, such as:</p>\n<pre><code class=\"lang-auto\">Traceback (most recent call last):\n  File \"/mnt/gpid07/imatge/carlos.hernandez/Documents/base/lib/python3.6/weakref.py\", line 548, in __call__\n    return info.func(*info.args, **(info.kwargs or {}))\n  File \"/mnt/gpid07/imatge/carlos.hernandez/Documents/base/lib/python3.6/tempfile.py\", line 938, in _cleanup\n    _rmtree(name)\n  File \"/mnt/gpid07/imatge/carlos.hernandez/Documents/base/lib/python3.6/shutil.py\", line 477, in rmtree\n    onerror(os.lstat, path, sys.exc_info())\n  File \"/mnt/gpid07/imatge/carlos.hernandez/Documents/base/lib/python3.6/shutil.py\", line 475, in rmtree\n    orig_st = os.lstat(path)\nFileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmprh45rrv6'\nException ignored in: &lt;finalize object at 0x7f77a6a096d0; dead&gt; \n</code></pre>\n<p>It does not stop execution, so I don\u2019t expect to solve it on this thread, but it baffled me as I had never seen this error.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-27T16:37:58.640Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"carloshernandezp\" data-post=\"5\" data-topic=\"1110\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/c/258eb7/40.png\" class=\"avatar\"> carloshernandezp:</div>\n<blockquote>\n<pre><code class=\"lang-auto\">         # log this table as evalset is not logged already. \n       if evalset_table is None:\n            eval_art = wandb.Artifact(wand.run.id + table_name, type=\"dataset\")\n            eval_art.add(table, \"evalset\")\n            wand.run.use_artifact(eval_art)\n            eval_art.wait() # Without this line the code broke\n            evalset_table= eval_art.get(\"evalset\")\n            wandb.run.log({'Evaluation table' : evalset_table}) # Mark2\n</code></pre>\n</blockquote>\n</aside>\n<p>You\u2019ll need to change the last line. You don\u2019t need to call .log if you\u2019ve already called <code>use_artifact</code> . just call .log outside the scope of if statement.</p>\n<pre><code class=\"lang-auto\">\n      if evalset_table is None:\n            eval_art = wandb.Artifact(wand.run.id + table_name, type=\"dataset\")\n            eval_art.add(table, \"evalset\")\n            wand.run.use_artifact(eval_art)\n            eval_art.wait() # Without this line the code broke\n            evalset_table= eval_art.get(\"evalset\")\n      wandb.run.log({'Evaluation table' : table}) # Mark2\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-27T16:42:33.164Z",
				"Answer_body": "<p>I forgot to add the <code>wandb.run.log({'Evaluation table' : table}) # Mark2</code> line on my last reply.</p>\n<p>As far as I understand, the solution comes from adjusting the information inside evalset_table as it is linked to our <code>table</code> by means of adding it to the artifact.</p>\n<p>Thank you very much the time you took to solve my problem.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-27T16:45:46.394Z",
				"Answer_body": "<p>Sure no problem :). Were you able to solve this?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-27T16:47:45.194Z",
				"Answer_body": "<p>I think so!</p>\n<p>I have left some CNN training for a while to see if it breaks at some point while logging. Normally it stopped sooner than the current run so I am confident it is solved.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-27T16:51:15.816Z",
				"Answer_body": "<aside class=\"quote no-group quote-modified\" data-username=\"carloshernandezp\" data-post=\"9\" data-topic=\"1110\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/c/258eb7/40.png\" class=\"avatar\"> carloshernandezp:</div>\n<blockquote></blockquote>\n</aside>\n<p>Awesome. If this is a public project, I\u2019d love to see the dashboard <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:07.730Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "SOLVED: Runs are not logged separately",
		"Question_link": "https://community.wandb.ai/t/solved-runs-are-not-logged-separately/1103",
		"Question_created_time": "2021-10-26T17:27:02.662Z",
		"Question_answer_count": 4,
		"Question_score_count": 4,
		"Question_view_count": 403,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello, I\u2019m trying to run several studies and have them log into separate runs but be grouped un der the name \u201cScenario Eval\u201d as part of the project \u201cScenario\u201d. I have one python script running a for-loop with multiple calls of the following lines:</p>\n<pre><code class=\"lang-auto\">for STUDY_NAME, study ...:\n    wandb_logger = WandbLogger(project=\"Scenario\",  name=STUDY_NAME+'_EVAL_'+str(study.best_params['lr']),\ngroup='Scenario Eval',\n log_model=\"all\",\n reinit=True)\n            trainer = pl.Trainer(\n                stochastic_weight_avg=False,\n                logger=wandb_logger,\n                checkpoint_callback=False,\n                log_every_n_steps=10,\n                default_root_dir = cache_path,\n                max_epochs=N_EPOCHS_EVAL,\n                gpus=1 if torch.cuda.is_available() else None,\n            )\n            wandb_logger.watch(model)\n            trainer.fit(model, datamodule=datamodule)\n            trainer.logger.log_hyperparams(hyperparameters)\n</code></pre>\n<p>In Wandb everything shows up as a single run, despite multiple loggers being created in python with explicit \u201creinit=True\u201d.<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/d1e8a5e923f3641d8ba225411a83542eece543f7.png\" data-download-href=\"/uploads/short-url/tWWeJa1q9uMmt5B1QFE3PPNWdHV.png?dl=1\" title=\"W&amp;amp;B Chart 26.10.2021, 19_30_41\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d1e8a5e923f3641d8ba225411a83542eece543f7_2_690x345.png\" alt=\"W&amp;B Chart 26.10.2021, 19_30_41\" data-base62-sha1=\"tWWeJa1q9uMmt5B1QFE3PPNWdHV\" width=\"690\" height=\"345\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d1e8a5e923f3641d8ba225411a83542eece543f7_2_690x345.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d1e8a5e923f3641d8ba225411a83542eece543f7_2_1035x517.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d1e8a5e923f3641d8ba225411a83542eece543f7_2_1380x690.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/d1e8a5e923f3641d8ba225411a83542eece543f7_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">W&amp;amp;B Chart 26.10.2021, 19_30_41</span><span class=\"informations\">2400\u00d71200 225 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nDo I need to do something else to separate these runs?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-26T17:42:43.197Z",
				"Answer_body": "<p>Fix mentioned here:</p><aside class=\"onebox githubissue\" data-onebox-src=\"https://github.com/PyTorchLightning/pytorch-lightning/issues/5212#issuecomment-748898571\">\n  <header class=\"source\">\n\n      <a href=\"https://github.com/PyTorchLightning/pytorch-lightning/issues/5212#issuecomment-748898571\" target=\"_blank\" rel=\"noopener nofollow ugc\">github.com/PyTorchLightning/pytorch-lightning</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"github-row\">\n  <div class=\"github-icon-container\" title=\"Issue\">\n\t  <svg width=\"60\" height=\"60\" class=\"github-icon\" viewbox=\"0 0 14 16\" aria-hidden=\"true\"><path d=\"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z\"></path></svg>\n  </div>\n\n  <div class=\"github-info-container\">\n    <h4>\n      <a href=\"https://github.com/PyTorchLightning/pytorch-lightning/issues/5212#issuecomment-748898571\" target=\"_blank\" rel=\"noopener nofollow ugc\">Logging multiple runs with WandbLogger</a>\n    </h4>\n\n    <div class=\"github-info\">\n      <div class=\"date\">\n        opened <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2020-12-21\" data-time=\"08:06:35\" data-timezone=\"UTC\">08:06AM - 21 Dec 20 UTC</span>\n      </div>\n\n        <div class=\"date\">\n          closed <span class=\"discourse-local-date\" data-format=\"ll\" data-date=\"2020-12-23\" data-time=\"10:17:41\" data-timezone=\"UTC\">10:17AM - 23 Dec 20 UTC</span>\n        </div>\n\n      <div class=\"user\">\n        <a href=\"https://github.com/bask0\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n          <img alt=\"bask0\" src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/7092584b8ec6e2a785f255f71b649ec8ed9057d8.png\" class=\"onebox-avatar-inline\" width=\"20\" height=\"20\">\n          bask0\n        </a>\n      </div>\n    </div>\n\n    <div class=\"labels\">\n        <span style=\"display:inline-block;margin-top:2px;background-color: #B8B8B8;padding: 2px;border-radius: 4px;color: #fff;margin-left: 3px;\">\n          question\n        </span>\n    </div>\n  </div>\n</div>\n\n  <div class=\"github-row\">\n    <p class=\"github-body-container\">#### What is your question?\n\nWhat is the proposed approach to log multiple run<span class=\"show-more-container\"><a href=\"\" rel=\"noopener\" class=\"show-more\">\u2026</a></span><span class=\"excerpt hidden\">s (e.g., models with different hyperparameters) in one script using the WandbLogger?\n\nI use optuna for hyperparameter tuning and create a wandb logger in each run. Although I have unique names per run (`WandbLogger(name='unique_name', project='MNIST')`), the runs are not logged separately. Instead, they are put in the same wandb run-file. After the first run, every logging step gives the following warning: `wandb: WARNING Step must only increase in log calls.  Step 599 &lt; 644; dropping {'train_loss': 0.098867267370224, 'train_acc': 0.96484375}.`, obviously because the step starts again at 0 for the second run.\n\nEdit for clarity: I expect each run to appear as separate wandb run, such that I can compare training progress etc.\n\n#### Code\n\nI copied a basic MNIST example from [here](https://colab.research.google.com/drive/16d1uctGaw2y9KhGBlINNTsWpmlXdJwRW#scrollTo=NI1Bh8CGI-FG). The data and model definition don't matter here, just the logging part at the end.\n\n```python\n# Weights &amp; Biases\nfrom pytorch_lightning.loggers import WandbLogger\n\n# Pytorch modules\nimport torch\nfrom torch.nn import functional as F\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader, random_split\n\n# Pytorch-Lightning\nfrom pytorch_lightning import LightningDataModule, LightningModule, Trainer\nimport pytorch_lightning as pl\n\n# Dataset\nfrom torchvision.datasets import MNIST\nfrom torchvision import transforms\n\n\nclass LitMNIST(LightningModule):\n\n    def __init__(self, n_classes=10, n_layer_1=128, n_layer_2=256, lr=1e-3):\n        '''method used to define our model parameters'''\n        super().__init__()\n\n        # mnist images are (1, 28, 28) (channels, width, height)\n        self.layer_1 = torch.nn.Linear(28 * 28, n_layer_1)\n        self.layer_2 = torch.nn.Linear(n_layer_1, n_layer_2)\n        self.layer_3 = torch.nn.Linear(n_layer_2, n_classes)\n\n        # optimizer parameters\n        self.lr = lr\n\n        # metrics\n        self.accuracy = pl.metrics.Accuracy()\n\n        # optional - save hyper-parameters to self.hparams\n        # they will also be automatically logged as config parameters in W&amp;B\n        self.save_hyperparameters()\n\n    def forward(self, x):\n        '''method used for inference input -&gt; output'''\n\n        batch_size, channels, width, height = x.size()\n\n        # (b, 1, 28, 28) -&gt; (b, 1*28*28)\n        x = x.view(batch_size, -1)\n        x = self.layer_1(x)\n        x = F.relu(x)\n        x = self.layer_2(x)\n        x = F.relu(x)\n        x = self.layer_3(x)\n\n        x = F.log_softmax(x, dim=1)\n        return x\n\n    def training_step(self, batch, batch_idx):\n        '''needs to return a loss from a single batch'''\n        x, y = batch\n        logits = self(x)\n        loss = F.nll_loss(logits, y)\n\n        # Log training loss\n        self.log('train_loss', loss)\n\n        # Log metrics\n        self.log('train_acc', self.accuracy(logits, y))\n\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        '''used for logging metrics'''\n        x, y = batch\n        logits = self(x)\n        loss = F.nll_loss(logits, y)\n\n        # Log validation loss (will be automatically averaged over an epoch)\n        self.log('valid_loss', loss)\n\n        # Log metrics\n        self.log('valid_acc', self.accuracy(logits, y))\n\n    def test_step(self, batch, batch_idx):\n        '''used for logging metrics'''\n        x, y = batch\n        logits = self(x)\n        loss = F.nll_loss(logits, y)\n\n        # Log test loss\n        self.log('test_loss', loss)\n\n        # Log metrics\n        self.log('test_acc', self.accuracy(logits, y))\n\n    def configure_optimizers(self):\n        '''defines model optimizer'''\n        return Adam(self.parameters(), lr=self.lr)\n\n\nclass MNISTDataModule(LightningDataModule):\n\n    def __init__(self, data_dir='./', batch_size=256):\n        super().__init__()\n        self.data_dir = data_dir\n        self.batch_size = batch_size\n        self.transform = transforms.ToTensor()\n\n    def prepare_data(self):\n        '''called only once and on 1 GPU'''\n        # download data\n        MNIST(self.data_dir, train=True, download=True)\n        MNIST(self.data_dir, train=False, download=True)\n\n    def setup(self, stage=None):\n        '''called one ecah GPU separately - stage defines if we are at fit or test step'''\n        # we set up only relevant datasets when stage is specified (automatically set by Pytorch-Lightning)\n        if stage == 'fit' or stage is None:\n            mnist_train = MNIST(self.data_dir, train=True, transform=self.transform)\n            self.mnist_train, self.mnist_val = random_split(mnist_train, [55000, 5000])\n        if stage == 'test' or stage is None:\n            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n\n    def train_dataloader(self):\n        '''returns training dataloader'''\n        mnist_train = DataLoader(self.mnist_train, batch_size=self.batch_size)\n        return mnist_train\n\n    def val_dataloader(self):\n        '''returns validation dataloader'''\n        mnist_val = DataLoader(self.mnist_val, batch_size=self.batch_size)\n        return mnist_val\n\n    def test_dataloader(self):\n        '''returns test dataloader'''\n        mnist_test = DataLoader(self.mnist_test, batch_size=self.batch_size)\n        return mnist_test\n\n\n# setup data\nmnist = MNISTDataModule()\n\n# -------------- relevant part starts here --------------\n\n# create logger for first run.\nwandb_logger = WandbLogger(name='run0', project='MNIST')\n\n# setup model - choose different hyperparameters per experiment\nmodel = LitMNIST(n_layer_1=128, n_layer_2=256, lr=1e-3)\n\ntrainer = Trainer(\n    logger=wandb_logger,    # W&amp;B integration\n    gpus=0,                 # no GPU\n    max_epochs=3            # number of epochs\n)\n\ntrainer.fit(model, mnist)\n\n# create logger for second run.\nwandb_logger = WandbLogger(name='run1', project='MNIST')\n\n# setup model - choose different hyperparameters per experiment\nmodel = LitMNIST(n_layer_1=128, n_layer_2=256, lr=1e-2)\n\ntrainer = Trainer(\n    logger=wandb_logger,    # W&amp;B integration\n    gpus=0,                 # no GPU\n    max_epochs=3            # number of epochs\n)\n\ntrainer.fit(model, mnist)\n```\n\n#### What's your environment?\n\n - OS: MacOS\n - Packaging: pip\n - Version: pytorch-lightning 1.1.1, wandb 0.10.12</span></p>\n  </div>\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n<p>\nseems to be just weird behaviour</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-26T18:30:46.879Z",
				"Answer_body": "<p>Thanks for updating this.<br>\nDid you solve your issue? Were you able to get different runs for your different studies?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-26T21:41:41.793Z",
				"Answer_body": "<p>Yup, I\u2019m now getting new runs for every training as expected</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.834Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Get all the artifacts of a project from the API",
		"Question_link": "https://community.wandb.ai/t/get-all-the-artifacts-of-a-project-from-the-api/1088",
		"Question_created_time": "2021-10-25T15:18:59.226Z",
		"Question_answer_count": 4,
		"Question_score_count": 4,
		"Question_view_count": 285,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>How can I use the API to get all the artifacts of a project, possibly of a given type?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-26T02:59:00.649Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/vrodriguezf90\">@vrodriguezf90</a> , you can use <code>type</code> method to filter out the artifact type as elaborated in our public api <a href=\"https://docs.wandb.ai/ref/python/public-api/artifact\">docs here</a>. There are many ways in which you can fetch all the artifacts logged for a project, one possible way is:</p>\n<pre><code class=\"lang-auto\">runs = api.runs(...)\nfor run in runs:\n   for artifact in run.logged_artifacts():\n      if artifact.type == \"model\": # check the artifact type\n          artifact.download()\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-26T08:26:33.708Z",
				"Answer_body": "<p>Thanks! It\u2019s a simple way indeed, hadn\u2019t thought about it. What I finally did is to take <a href=\"https://github.com/wandb/client/blob/7d699387090ff3ce0420793db2d9932cec4057fc/wandb/cli/cli.py#L1550\" rel=\"noopener nofollow ugc\">the code</a> of the CLI function <code>wandb artifact ls</code>, and adapt it to return the artifacts in a list instead of printing them. I also added an option to constraint the name of the artifact, and to whether only the last version of the artifact will be returned:</p>\n<pre><code class=\"lang-auto\">def get_wandb_artifacts(project_path, type=None, name=None, last_version=True):\n    public_api = wandb.Api()\n    if type is not None:\n        types = [public_api.artifact_type(type, project_path)]\n    else:\n        types = public_api.artifact_types(path)\n\n    res = L()\n    for kind in types:\n        for collection in kind.collections():\n            if name is None or name == collection.name:\n                versions = public_api.artifact_versions(\n                    kind.type,\n                    \"/\".join([kind.entity, kind.project, collection.name]),\n                    per_page=1,\n                )\n                if last_version: res += next(versions)\n                else: res += L(versions)\n    return res\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-26T20:24:48.055Z",
				"Answer_body": "<p>Thanks for the update <a class=\"mention\" href=\"/u/vrodriguezf90\">@vrodriguezf90</a> .</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-25T20:25:44.766Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Sweeps with multiple seeds for the same config values",
		"Question_link": "https://community.wandb.ai/t/sweeps-with-multiple-seeds-for-the-same-config-values/1077",
		"Question_created_time": "2021-10-24T14:31:01.671Z",
		"Question_answer_count": 8,
		"Question_score_count": 8,
		"Question_view_count": 1182,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>Sometimes (for example in RL) agents are very unstable and you only know how a config behaves if you tested it on 5-10 seeds. So I was wondering if there is a feature in wandb sweeps that allows the aggregation of a metric over multiple seeds (but the same config values)?</p>\n<p>I know one solution is to define a for loop in my own training script that repeats the same config, but I would like these runs to be executed in parallel, and possibly even on different machines.</p>\n<p>Thanks,<br>\nTom</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-25T12:49:35.818Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/tomjur\">@tomjur</a>, this is an interesting question!<br>\nThis is possible if you use the seed as a parameter in your sweep config and then group based on the parameters you care about.<br>\nThere are a bunch of ways to group your runs and aggregate your metrics. You can click the group button above your runs and choose the metrics you care about, or you can group within each plot by editing a plot and clicking the Group tab and choosing the parameter you want to group on.</p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/guides/track/advanced/grouping#grouping-dynamically-in-the-ui\">\n  <header class=\"source\">\n      \n\n      <a href=\"https://docs.wandb.ai/guides/track/advanced/grouping#grouping-dynamically-in-the-ui\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/guides/track/advanced/grouping#grouping-dynamically-in-the-ui\" target=\"_blank\" rel=\"noopener\">Group Runs</a></h3>\n\n  <p>Group training and evaluation runs into larger experiments</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-25T13:05:01.637Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/_scott\">@_scott</a> thanks for the replay!</p>\n<p>Sorry, but I still don\u2019t understand the solution. Maybe I can try to be more explicit in my description of the problem (in the following I assume bayes \\ random search since I do not have the budget to do a grid search):</p>\n<p>Let\u2019s say I defined a distribution over all parameters, and specifically, I defined 3 uniform values for seeds. Now if an agent samples a configuration with seed 1, what forces the hyper-parameter optimization process (in the wandb controller) to select the same configuration again but with seed no. 2?<br>\nIf the optimization is random, it is possible but not likely (especially with a continuous random variable), if the optimization is bayes it is unlikely but might also have the bad side-effect of preferring easy seeds.</p>\n<p>I think this might be a common pain point in RL (and possibly GAN) sweeps.</p>\n<p>Thanks again!<br>\nTom</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-25T13:49:16.270Z",
				"Answer_body": "<p>Thanks for sharing more detail about your question. I understand now. In essence, you want a grid search over random seeds while also doing a bayes / random search for your other configs, and make sure the configs are the same for each Sweep.</p>\n<p>It isn\u2019t currently possible to do this, but this is definitely a feature we will try to support in the future because it\u2019s a common workflow for people like you trying to deterministically run Sweeps. Thank you for adding another +1 to this feature request.</p>\n<p>Unfortunately, my only suggestion for now is doing a grid search for each of the configurations you want to test, including the random seed in that search.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-25T14:16:33.610Z",
				"Answer_body": "<p>Thank you for adding this as a feature request!<br>\nBTW I am a new user, how can I track the progress on this feature?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-25T15:36:30.825Z",
				"Answer_body": "<p>Our CLI is Open Source so you can track the release notes here: <a href=\"https://github.com/wandb/client/releases\" class=\"inline-onebox\">Releases \u00b7 wandb/client \u00b7 GitHub</a><br>\nAnd here\u2019s the code for Sweeps: <a href=\"https://github.com/wandb/sweeps\" class=\"inline-onebox\">GitHub - wandb/sweeps: W&amp;B Hyperparameter Sweep Engine. File sweeps related issues at the W&amp;B client: https://github.com/wandb/client</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-25T15:37:43.123Z",
				"Answer_body": "<blockquote>\n<p>BTW I am a new user</p>\n</blockquote>\n<p>Welcome! Hope you\u2019re enjoying using W&amp;B, here to help if you have anymore questions or issues.<br>\n<img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji only-emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-26T14:13:20.651Z",
				"Answer_body": "<p>Yes W&amp;B is great (: thanks for all the help so far</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:07.673Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Get best model from artifacts",
		"Question_link": "https://community.wandb.ai/t/get-best-model-from-artifacts/992",
		"Question_created_time": "2021-10-15T18:42:05.709Z",
		"Question_answer_count": 4,
		"Question_score_count": 5,
		"Question_view_count": 353,
		"Question_has_accepted_answer": true,
		"Question_body": "<p>Hi,</p>\n<p>I guess this use-case is common but I cannot figure it out\u2026</p>\n<p>I would like to log one model per run, and in the end, be able to load the best overall model for production.</p>\n<p>So like :<br>\nRun 1,2,3,4,5\u2026</p>\n<pre><code class=\"lang-auto\">run.log_artifact(my_model_artifact)\n</code></pre>\n<p>Production:</p>\n<pre><code class=\"lang-auto\">artifact = api.artifact.get_best_of_all_my_runs()\n</code></pre>\n<p>For now my solution is :</p>\n<pre><code class=\"lang-auto\">Runs : \nartifact.save() # with the same name so only one artifact for all runs\n\nProduction\nartifact = api.artifact(\"entity/project/artifact:alias\") # Get the only model (which also should be the best)\n</code></pre>\n<p>Thanks in advance for any help.<br>\nhave a great day</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-18T23:37:22.999Z",
				"Answer_body": "<p>Hi there! You can do this in a couple of ways but you don\u2019t have to limit yourself to logging just one artifact. A common flow would be to log a model checkpoint every but then to also log a \u201cbest model\u201d artifact. Since artifacts are versioned you don\u2019t have to worry about renaming the new \u201cbest model\u201d artifact. Then at the end of your run you not only have an artifact history of your model at each of the checkpoints but also a versioned history of all the best models.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-19T17:22:20.423Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/aidanjd\">@aidanjd</a>,</p>\n<p>Thanks a lot for the reply !</p>\n<p>I indeed do this and have my <code>best model</code> for each run and it works great.</p>\n<p>Then I can see all my runs in the <code>Table</code> Tab, with their hyperparameters, and a column for the score/accuracy.</p>\n<p>However my questions is : Could I get the best model among all my runs so I can use it in production ?</p>\n<p>Let say I have one parameter P :<br>\nI run Run1 with P1, get Accuracy A1 // Run 2 with P2 get Accuracy A2 // Run3 with P3 get Accurary A3</p>\n<p>Then in the table I can see Run1, Run2 and Run3 each with logs / metrics / models / Parameters.</p>\n<p>I would like to be able to do in my production/inference code :<br>\n\u201cSelect best Accuracy model from Run1, Run2, Run3 so I can use the best model in inference mode in production\u201d</p>\n<p>I hope my explanation was clear\u2026<br>\nThanks a lot for your time.,</p>\n<p>Have a great day</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-22T19:28:10.719Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/ierezell\">@ierezell</a>,</p>\n<p>I think I understand your question a little better. We are currently working on a feature that will make exactly what you\u2019re asking for super clean and easy <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>\n<p>In the meantime the most straightforward way of going about this would be to save the performance of all of the metrics you care about to the <code>run.summary</code> of the run that produced that model. Then from the <code>api</code> you can query all the runs in the project and select the best run using the metrics you set in the summary. Then you can get the download the best model and use it as an input to your production code.</p>\n<p>Here is a <a href=\"https://docs.wandb.ai/guides/track/public-api-guide#download-the-best-model-file-from-a-sweep\">related example</a> querying the best model from a sweep but the process will be slightly different for you use case.</p>",
				"Answer_has_accepted": true
			},
			{
				"Answer_created_time": "2021-10-25T14:07:41.400Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/aidanjd\">@aidanjd</a>,</p>\n<p>Thanks for the reply, this is indeed what I was looking for ! <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>\n<p>I will be glad to test the new feature (even in beta) but I\u2019m sure you will communicate when it will be available.<br>\nElse I was thinking about using the API and you just confirmed it so I will be headed for that.</p>\n<p>Have a great day.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Detectron2 Visualization",
		"Question_link": "https://community.wandb.ai/t/detectron2-visualization/1086",
		"Question_created_time": "2021-10-25T09:35:46.674Z",
		"Question_answer_count": 3,
		"Question_score_count": 3,
		"Question_view_count": 531,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>Has anyone already implemented a visulalization of segmentation or object detection tasks using the detectron2 library?<br>\nThere is already a GitHub issue on this: <a href=\"https://github.com/facebookresearch/detectron2/issues/3404\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Visualizations on W&amp;B \u00b7 Issue #3404 \u00b7 facebookresearch/detectron2 \u00b7 GitHub</a> but I was wondering if anyone might already has a somewhat usable code to start with.</p>\n<p>Thanks<br>\nBen</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-25T12:45:30.157Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/ben-spex\">@ben-spex</a> Hi. I\u2019m AyushExel from that github thread. I\u2019m working on a detectron2 integration. detection and instance segmentation is supported but I\u2019m refining it further to support more use cases.<br>\nHere\u2019s my branch - <a href=\"https://github.com/AyushExel/detectron2/tree/wandb\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">GitHub - AyushExel/detectron2 at wandb</a><br>\nHere are the changes I made - <a href=\"https://github.com/AyushExel/detectron2/pull/2\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">W&amp;B integration by AyushExel \u00b7 Pull Request #2 \u00b7 AyushExel/detectron2 \u00b7 GitHub</a></p>\n<p>I\u2019ll add more instructions for using this integration by the end of the week. Stay tuned!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-25T13:11:22.055Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/cayush\">@cayush</a><br>\nah perfect awesome. I just had a quick glance and it looks like exactly what I was hoping for.</p>\n<p>I will not have time this week, except for maybe the weekend. But I will definitely give it a try next week.</p>\n<p>Thanks a lot for all the effort.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.781Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "I think that W&B is having some connection issues since yesterday night",
		"Question_link": "https://community.wandb.ai/t/i-think-that-w-b-is-having-some-connection-issues-since-yesterday-night/1073",
		"Question_created_time": "2021-10-23T15:10:04.843Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 327,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Although it\u2019s still possible to update data to W&amp;B, since yesterday night no data can be downloaded with the error:</p>\n<pre><code class=\"lang-auto\">/requests/models.py\", line 953, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://api.wandb.ai/graphql\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-25T12:52:05.743Z",
				"Answer_body": "<p>Thanks for sharing this, I have shared it with the site reliability engineering team and it is being investigated. If this problem persists, please continue to let us know. I\u2019m sorry for any inconvenience this has caused.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.370Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How can I log best values of a metric/loss in wandb summary using Pytorch-Lightning?",
		"Question_link": "https://community.wandb.ai/t/how-can-i-log-best-values-of-a-metric-loss-in-wandb-summary-using-pytorch-lightning/941",
		"Question_created_time": "2021-10-13T06:07:10.356Z",
		"Question_answer_count": 5,
		"Question_score_count": 3,
		"Question_view_count": 350,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>In wandb documentation there are examples like this: <code>wandb.run.summary[\"best_accuracy\"] = best_accuracy</code><br>\nNot sure how to do something like that in training_step/validation_step using self.log, considering the values of metrics are automatically calculated on epochs under the hood of the API.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-15T10:18:22.561Z",
				"Answer_body": "<p>Hi,<br>\nCan you give a bit more info of what you\u2019re trying to do? Have you tried doing the above in your own lightning module? You could also try adding a Callback which has access to the logger.</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/guides/integrations/lightning#how-do-i-log-media-objects\">\n  <header class=\"source\">\n      \n\n      <a href=\"https://docs.wandb.ai/guides/integrations/lightning#how-do-i-log-media-objects\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/guides/integrations/lightning#how-do-i-log-media-objects\" target=\"_blank\" rel=\"noopener\">PyTorch Lightning</a></h3>\n\n  <p>Build scalable, structured, high-performance PyTorch models with Lightning and log them with W&amp;B.</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-15T11:18:44.567Z",
				"Answer_body": "<p>I have the following code:</p>\n<pre><code>def training_step(self, batch, *args, **kwargs):  # type: ignore\n    pred = self(batch).squeeze(-1)\n    loss = self.loss(pred, batch['p'], batch['u_out']).mean()\n    self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n\n    score = self.metric(pred, batch['p'], batch['u_out']).mean()\n    self.log(f'train_mae', score, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n    return loss\n</code></pre>\n<p>As you can see, I calculate the metric and the loss only during the training step (and the validation step) and the values at epoch level are aggregated and logged automatically by pytorch-lightning and wandb.</p>\n<p>I suppose  I could return the loss and the metric in <code>training_step</code> and then calculate epoch level values manually in <code>training_epoch_end</code> and then log the best value.</p>\n<p>But I hope there is a better solution.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-15T16:28:03.172Z",
				"Answer_body": "<p>One thing you can do is use <code>wandb.run.define_metric(\"train_mae\", summary=\"max\")</code></p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/ref/python/run#define_metric\">\n  <header class=\"source\">\n      \n\n      <a href=\"https://docs.wandb.ai/ref/python/run#define_metric\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/ref/python/run#define_metric\" target=\"_blank\" rel=\"noopener\">wandb.Run</a></h3>\n\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>This will automatically store both the latest and the max value in the summary for filtering.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-22T17:28:08.269Z",
				"Answer_body": "<p>It turns out, that wandb logger doesn\u2019t have a possibility to define the metric or summary. In the end I use a simple hacking solution:</p>\n<pre><code class=\"lang-auto\">self.mae = score if score &lt; self.mae else self.mae\nself.log('mae', self.mae, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.689Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "UI : How to drag/move in a plot?",
		"Question_link": "https://community.wandb.ai/t/ui-how-to-drag-move-in-a-plot/1021",
		"Question_created_time": "2021-10-18T07:50:20.154Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 290,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Let\u2019s say I\u2019m watching a plot.<br>\nThen I zoom in a specific section within the plot.<br>\nThen I want to look a bit more to the right.<br>\nWhat kind of key/mouse button allows me to move my view to the right  ?<br>\nMiddle mouse button does not work <img src=\"https://emoji.discourse-cdn.com/twitter/frowning.png?v=12\" title=\":frowning:\" class=\"emoji\" alt=\":frowning:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-21T09:36:37.203Z",
				"Answer_body": "<p>You can expand the plot to get more granular control over it and zoom into each section separately. I will file a ticket to request that key/mouse buttons give control over navigating zoomed in plots. Sorry I couldn\u2019t give a nicer answer here.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.379Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "HP Sweep: Conditional Sampling",
		"Question_link": "https://community.wandb.ai/t/hp-sweep-conditional-sampling/726",
		"Question_created_time": "2021-09-21T16:50:31.093Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 296,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Suppose I have a somewhat complicated hyper parameter distribution I\u2019d like to sample:</p>\n<p>For example, I have a hyperparameter called HP1 controlling normalization applied my dataset. If I sample HP1 \u2190 maximum-eigenvalue-norm, then maybe I have another hyperparameter I must sample; in this case that could be how to compute maximum eigenvalue which could be in the set {fancy-eigenvalue-computation, torch-built-in-symeig}.</p>\n<p>But suppose if normalization technique was sampled as HP1 \u2190 Frobenius-norm, then I have no other hyper parameters to sample.</p>\n<p>Optuna handles this nicely, and I was hoping W&amp;B\u2019s had a similar way of auto-magically handling it.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-21T05:09:57.551Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/max_wasserman\">@max_wasserman</a> , thanks for your request and providing details for your use-case as well. We\u2019ve a feature request filed for this and I\u2019ve bumped up the priority for it too. We\u2019ll keep you posted once there\u2019s an update.</p>\n<p>Current workaround: One way to address this problem for now is to <em>pre-process</em> the <code>sweep.yaml</code> and provide plausible combinations of pairs of <code>(HP1, HP2)</code> that satisfy your condition (which you can do because of your prior knowledge).</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Launching More Agents in HP Sweep",
		"Question_link": "https://community.wandb.ai/t/launching-more-agents-in-hp-sweep/733",
		"Question_created_time": "2021-09-21T18:59:12.251Z",
		"Question_answer_count": 3,
		"Question_score_count": 5,
		"Question_view_count": 331,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>The documentation shows how, once the sweep is running, <a href=\"https://docs.wandb.ai/guides/sweeps/existing-project\">we can spawn off more agents</a>.</p>\n<p>But I can\u2019t figure out a way to get to that actual page and do it.</p>\n<p>If I open the \u201cSweeps\u201d tab, I see the button \u201cCreate Sweep\u201d, but I\u2019m not sure that\u2019s what I\u2019m looking to do (right?). I want to launch a new agent of this sweep, not an entirely new sweep.</p>\n<p>Can I simply run the same code on multiple machines, and will it automatically know (through the same project name?) to combine all those runs in the same overall sweep?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-23T16:59:12.517Z",
				"Answer_body": "<p>Thanks for flagging this! Allow me to replicate the issue on my end to help debug.</p>\n<p>I\u2019ll give it a spin tonight and get back to you by tomorrow evening <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-21T04:24:18.059Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/max_wasserman\">@max_wasserman</a> You should be able to launch agents from an existing sweep as specified in the <a href=\"https://docs.wandb.ai/guides/sweeps/existing-project#3.-launch-agents\">docs here</a>.<br>\n<code>wandb agent</code> <a href=\"https://docs.wandb.ai/ref/cli/wandb-agent\">command</a> would require you to pass in a <code>sweep_id</code> ( which you\u2019ll have as the sweep is up &amp; running).</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-21T04:24:48.122Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/max_wasserman\">@max_wasserman</a> You should be able to launch agents from the sweep as specified in the docs here. <code>wandb agent</code> command would require you to pass in a <code>sweep_id</code> ( which you\u2019ll have as the sweep is up &amp; running).</p>\n<p>[Discourse post]</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Copying run from a project to another and adding the right hyperparameter",
		"Question_link": "https://community.wandb.ai/t/copying-run-from-a-project-to-another-and-adding-the-right-hyperparameter/1049",
		"Question_created_time": "2021-10-20T13:54:12.400Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 335,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>I have been running several test on differents on different projects and I am struggling for doing something pretty simple I think.<br>\nI have run a sweep in a project:\u201cproject 1\u201d for testing for hyperparameter.<br>\nA bit later I modified a bit my architecture and run another test and send it to another project: \u201cproject 2\u201d.<br>\nNow I want to compare some of the run of project 1 with the one of project 2. I tried to use the option move, however the runs I moved disappeared from project1\u2026 and I don\u2019t want that\u2026 How can I copy the run from one project to another one (Q1)<br>\nMoreover I did not logged my hyperparameter for project 2. Can I add them manually from wandb interface ? (Q2)</p>\n<p>Finally I don\u2019t understand why some hyperparameters of my run for project 2 were not logged I did the following:</p>\n<pre><code class=\"lang-auto\">\nimport wandb\nwandb.login()\n\nimport stuff\ndefine model and dataloaders\n\nwandb.init(project=\"Structural encoder\", entity=\"barthelemymp\")\nwandb.config = {\n  \"num_layers\": 6,\n  \"forward_expansion\": 2048,\n  \"batch_size\": 10,\n  \"Encoder\": \"Structural\"\n}\n\nfor epoch in range(num_epochs):\n      ...\n      ...\n      ...\n      wandb.log({\"Train loss\": mean_lossTrain, \"Val Loss\":mean_lossVal, \"epoch\":epoch})\n</code></pre>\n<p>In the end on wandb website for this run I see only the trainloss valloss and epoch but not the config. What have I done wrong ? (Q3)</p>\n<p>Lot\u2019s of Question in one post, but any help will be appreciated,</p>\n<p>Best</p>\n<p>Barth</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-20T21:47:11.300Z",
				"Answer_body": "<p>Hi Barth,</p>\n<p>(q1)<br>\nThat is the intended behaviour for the way projects, sweeps, and runs are structured. For your use case, I would recommend keeping everything you want to compare in the same project. There are various ways to keep things organized with tags and notes.</p>\n<p>(q2)<br>\nAs for the config, you\u2019ll need to call <code>wandb.config.update(config_dict)</code> to persist changes. You can read more about config <a href=\"https://docs.wandb.ai/guides/track/config#efficient-initialization\">here</a></p>\n<p>All the best,</p>\n<p>Aidan</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-20T21:47:24.804Z",
				"Answer_body": "<p>Hi Barth,</p>\n<p>(q1)<br>\nThat is the intended behaviour for the way projects, sweeps, and runs are structured. For your use case, I would recommend keeping everything you want to compare in the same project. There are various ways to keep things organized with tags and notes.</p>\n<p>(q2)<br>\nAs for the config, you\u2019ll need to call <code>wandb.config.update(config_dict)</code> to persist changes. You can read more about config here</p>\n<p>All the best,</p>\n<p>Aidan</p>\n<p>[Discourse post]</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-19T21:48:08.915Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Delete files from a run",
		"Question_link": "https://community.wandb.ai/t/delete-files-from-a-run/1031",
		"Question_created_time": "2021-10-19T08:14:59.024Z",
		"Question_answer_count": 2,
		"Question_score_count": 1,
		"Question_view_count": 685,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I need to free up some space and want to delete an heavy file uploaded within a run.<br>\nI dont want to delete the whole logs of the runs, only this one heavy file</p>\n<p>How to ?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-20T14:54:32.816Z",
				"Answer_body": "<p>Was this file uploaded as an Artifact?<br>\nYou can use the Artifacts API to delete the artifacts you\u2019ve logged.</p>\n<pre><code class=\"lang-auto\">artifact = api.artifact('project/artifact:alias')\nartifact.delete()\n</code></pre>\n<p>Here\u2019s some documentation of cleaning up logged Artifacts:</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/guides/artifacts/api#cleaning-up-unused-versions\">\n  <header class=\"source\">\n      \n\n      <a href=\"https://docs.wandb.ai/guides/artifacts/api#cleaning-up-unused-versions\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/guides/artifacts/api#cleaning-up-unused-versions\" target=\"_blank\" rel=\"noopener\">Artifacts Walkthrough</a></h3>\n\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>Here\u2019s a good reference documentation page for Artifacts for it\u2019s more complete usage.</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/ref/python/public-api/artifact#delete\">\n  <header class=\"source\">\n      \n\n      <a href=\"https://docs.wandb.ai/ref/python/public-api/artifact#delete\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b3ea0f16b83c6c9d59a62cd31bf26f336a797687_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/ref/python/public-api/artifact#delete\" target=\"_blank\" rel=\"noopener\">wandb.apis.public.Artifact</a></h3>\n\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.366Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "ValueError('signal only works in main thread')",
		"Question_link": "https://community.wandb.ai/t/valueerror-signal-only-works-in-main-thread/686",
		"Question_created_time": "2021-09-18T01:45:50.462Z",
		"Question_answer_count": 4,
		"Question_score_count": 3,
		"Question_view_count": 2183,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Has anyone else run into this error:<br>\n<code>ValueError('signal only works in main thread')</code></p>\n<p>I\u2019m running a hyper parameter sweep using PL and Weights and Biases\u2019s framework.</p>\n<p>Running on a GPU on Google Colab which causes all launched runs to fail. Running it locally (Mac OS) prompts \u2018signal only works in main thread\u2019 to be printed to stdout (which also happens on Colab) but it doesn\u2019t crash.</p>\n<p>When I train the model with just PL outside of a W&amp;B sweep, it works fine.</p>\n<p>Any ideas? It seems people using <a href=\"https://github.com/PyTorchLightning/pytorch-lightning/issues/3651\" rel=\"noopener nofollow ugc\">Ray with PL</a> have come across this. The hacky solution presented there ( <code>os.environ['SLURM_JOB_NAME'] = 'bash'</code> ) doesn\u2019t work in my case (neither on Mac OS or Colab).</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-07T17:45:10.227Z",
				"Answer_body": "<p>Linking the GitHub Discussion where the conversation was <a href=\"https://github.com/PyTorchLightning/pytorch-lightning/discussions/9589\">continued</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-08T00:20:28.232Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/max_wasserman\">@max_wasserman</a> , did your issue get resolved?<br>\nIf not, could you please share the debug log bundle? Also, which wandb version are you on, is it v0.12.4?<br>\nI\u2019m assuming this is related to <a href=\"https://github.com/wandb/client/issues/834#issuecomment-927143070\">this</a> thread as well.</p>\n<ol>\n<li>A minimalist script would help us here in reproducing &amp; pin-pointing the issue. If you could provide us with one, that would be very helpful.</li>\n<li>Also, how are you creating and starting the sweep? How many sweep parameters do you have? (I\u2019ve noticed sometimes fewer parameters resolve the issue, hence my reason for asking this question. If this is the case, we file an internal bug report).</li>\n<li>Did you try setting <code>WANDB_CONSOLE</code> env var to \u201coff\u201d and see if the error still occurs? This won\u2019t capture the <code>stdout</code> / <code>stderr</code> of the process and would help us in figuring out what might be blocked. Maybe, our console logging got in the way of telling you why it crashed. Hence, you might want to run some runs with: <code>WANDB_CONSOLE=off</code>\n</li>\n</ol>\n<p>We intend that the library never gets into this state and we\u2019re working hard to make it more robust.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-09T01:34:18.094Z",
				"Answer_body": "<p>I\u2019m traveling and away from my work station right now, so an incomplete answer is below.</p>\n<p>I believe the version was the latest as of the date of posting, and yes, same issue. I created and started the sweep all inside a python script, as Charles showed in the sweep tutorials on YouTube, which utilized Colab. No YAML files where used.</p>\n<p>The issue was totally resolved when I fully ported to YAML files, and only had python file define train() function and call the wandb.init() as in the docs.</p>\n<p>As for sweep parameters, anywhere from 10-25. Most only have one value and are simply there for documentation purposes.</p>\n<hr>\n<p>I would recommend trying to set up the simplest pytorch lightning model and you can think of while logging some scalars and some dicts of data (I didn\u2019t log anything fancy), set up a hyperparameter sweep inside the python file, use the wandb/PL callback for logging.</p>\n<p>If you can\u2019t reproduce with that setup, let me know, and I\u2019d be happy to try the aforementioned fixes when I return next week.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-19T20:58:57.717Z",
				"Answer_body": "<p>Thanks for the updates <a class=\"mention\" href=\"/u/max_wasserman\">@max_wasserman</a>, this was very helpful. We were able to reproduce this bug without using PTL lib on our side. I\u2019ve filed an internal bug report and our eng team is looking into it. We\u2019ll follow-up with you once we\u2019ve an update regarding this issue.<br>\nMeanwhile, could you try turning off console logging and re-run your script? For instance: <code>wandb.init(settings=wandb.Settings(console='off'))</code> or you can just set this <a href=\"https://docs.wandb.ai/guides/track/advanced/environment-variables#optional-environment-variables\">env variable</a> like: <code>WANDB_CONSOLE=off</code>.</p>\n<p>Please let us know if you require any further assistance.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Parameter importance panel empty in created report",
		"Question_link": "https://community.wandb.ai/t/parameter-importance-panel-empty-in-created-report/1036",
		"Question_created_time": "2021-10-19T17:20:32.088Z",
		"Question_answer_count": 7,
		"Question_score_count": 0,
		"Question_view_count": 403,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I completed about 40 hyperparameter tuning runs with Ray Tune, all beautifully logged-in W&amp;B. I wanted to add the parameter importance panel but it does not load any graphs even though I selected all these runs as instructed.</p>\n<p>All I get is this empty panel <div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/ba846238f88dfc543119347ce20730a9afa05f86.png\" data-download-href=\"/uploads/short-url/qC0rig18Mj3Pbm03LKWO3wwZUEu.png?dl=1\" title=\"Screen Shot 2021-10-19 at 7.19.15 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ba846238f88dfc543119347ce20730a9afa05f86_2_690x320.png\" alt=\"Screen Shot 2021-10-19 at 7.19.15 PM\" data-base62-sha1=\"qC0rig18Mj3Pbm03LKWO3wwZUEu\" width=\"690\" height=\"320\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ba846238f88dfc543119347ce20730a9afa05f86_2_690x320.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/ba846238f88dfc543119347ce20730a9afa05f86.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/ba846238f88dfc543119347ce20730a9afa05f86.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/ba846238f88dfc543119347ce20730a9afa05f86_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2021-10-19 at 7.19.15 PM</span><span class=\"informations\">770\u00d7358 8.55 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>What I am doing wrong?</p>\n<p>Best,<br>\nVladimir</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-19T20:54:10.152Z",
				"Answer_body": "<p>Hi Vladmir,</p>\n<p>I\u2019m glad you like our product so far. Can you please share with me the version of wandb you\u2019re running and also a link to the run you\u2019re experiencing this problem. Since this is a public forum, you can send the run page link to <a href=\"mailto:support@wandb.com\">support@wandb.com</a>.</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-20T05:37:28.074Z",
				"Answer_body": "<p>Hi Leslie,</p>\n<p>Please find the report at <a href=\"https://wandb.ai/vblagoje/Retriever/reports/Parameter-importance-issue--VmlldzoxMTM0NjEw\" class=\"inline-onebox-loading\">https://wandb.ai/vblagoje/Retriever/reports/Parameter-importance-issue--VmlldzoxMTM0NjEw</a></p>\n<p>Parameter importance panel is at the bottom.</p>\n<p>Best,</p>\n<p>Vladimir</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-20T15:41:07.358Z",
				"Answer_body": "<p>Hi again,</p>\n<p>I see the issue you are running into. When I tried to recreate it however, I\u2019m not running into the same problem. Did you use the same way as shown in the docs (<a href=\"https://docs.wandb.ai/ref/app/features/panels/parameter-importance\" class=\"inline-onebox-loading\">https://docs.wandb.ai/ref/app/features/panels/parameter-importance</a>)?</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-20T15:51:07.243Z",
				"Answer_body": "<p>Yes, I did. Here I have four runs and I clicked on + at the top right (below Create report), selected \u201cparameter importance\u201d and got this:<br>\n<img src=\"https://weightsandbiases.zendesk.com/attachments/token/oV77buuCjqOtsybwJC6g26bjM/?name=Screen+Shot+2021-10-20+at+5.47.10+PM.png\" alt=\"Screen Shot 2021-10-20 at 5.47.10 PM.png\"></p>\n<p>Thanks in advance. Please advise.</p>\n<p>Vladimir</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-20T15:59:03.668Z",
				"Answer_body": "<p>Ok, figured it out. I had to ungroup runs first - which was default. Now it works. Perhaps you can add this detail to documentation. <img src=\"https://weightsandbiases.zendesk.com/attachments/token/FXjuLBoDcj90oID16hKrx4HOH/?name=Screen+Shot+2021-10-20+at+5.56.57+PM.png\" alt=\"Screen Shot 2021-10-20 at 5.56.57 PM.png\"></p>\n<p>Thanks and all the best.</p>\n<p>Vladimir</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-20T16:15:33.229Z",
				"Answer_body": "<p>I\u2019m so happy you were able to figure it out by yourself! I\u2019ll put a documentation ticket in for it</p>\n<p>Warmly,<br>\nLeslie</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-12-18T17:20:38.697Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Report command '/' not working in chrome",
		"Question_link": "https://community.wandb.ai/t/report-command-not-working-in-chrome/952",
		"Question_created_time": "2021-10-13T16:15:22.845Z",
		"Question_answer_count": 5,
		"Question_score_count": 2,
		"Question_view_count": 286,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,<br>\ncurrently trying to access the commands in a report like for creating a panel etc. through typing \u2018/\u2019 doesn\u2019t work for me in chrome. If I type \u2018/\u2019  nothing happens. It worked until recently and still works in fire fox.<br>\nMy chrome version is 94.0.4606.81.<br>\nThanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-13T17:29:15.717Z",
				"Answer_body": "<p>Hey Jobro, I am on the same version of chrome and it is working for me. Which OS are you using?<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/da7365909cd39187f4b65851642df5b8623a3903.png\" data-download-href=\"/uploads/short-url/vavk91z2tiCKRVgw7BmXrtqNrZp.png?dl=1\" title=\"Screen Shot 2021-10-13 at 21.26.57\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/da7365909cd39187f4b65851642df5b8623a3903_2_690x131.png\" alt=\"Screen Shot 2021-10-13 at 21.26.57\" data-base62-sha1=\"vavk91z2tiCKRVgw7BmXrtqNrZp\" width=\"690\" height=\"131\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/da7365909cd39187f4b65851642df5b8623a3903_2_690x131.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/da7365909cd39187f4b65851642df5b8623a3903_2_1035x196.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/da7365909cd39187f4b65851642df5b8623a3903.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/da7365909cd39187f4b65851642df5b8623a3903_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2021-10-13 at 21.26.57</span><span class=\"informations\">1362\u00d7260 20.1 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\n<img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/f304df9a3aec1ce806bf13de9ddb990fdea145e8.gif\" alt=\"2021-10-13 21.27.25\" data-base62-sha1=\"yFQsVJkvfrOqG05xLXtvSmpAqQU\" width=\"632\" height=\"500\" class=\"animated\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-13T17:33:44.754Z",
				"Answer_body": "<p>I am using Ubuntu 20.04</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-15T18:43:19.927Z",
				"Answer_body": "<p>Will try to reproduce on our my end and get back to you. Meanwhile can you try using other browsers?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-18T13:06:01.783Z",
				"Answer_body": "<p>I only tried it using chrome and fire fox. In fire fox it works. In chrome it doesn\u2019t, I tried it on two different machines with Ubuntu.<br>\nOn the same machine it works if I use chrome on windows 10.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-11-01T12:38:03.881Z",
				"Answer_body": "<p>Hi Jobro, both me and Arman weren\u2019t able to reproduce this issue. Is this still something that you are seeing?</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Add Metadata after an artifact has been logged",
		"Question_link": "https://community.wandb.ai/t/add-metadata-after-an-artifact-has-been-logged/970",
		"Question_created_time": "2021-10-14T04:20:51.523Z",
		"Question_answer_count": 3,
		"Question_score_count": 2,
		"Question_view_count": 376,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi All,</p>\n<p>I\u2019m currently using the W&amp;B Metaflow Integration: <a href=\"https://docs.wandb.ai/guides/integrations/other/metaflow\">https://docs.wandb.ai/guides/integrations/other/metaflow</a>. Any instance variables that are Pandas Dataframes or PathLibs are automatically logged as dataset artifacts. Due to this, I\u2019m not able to supply a description for the artifact or any metadata for it when the artifact is created. Is there any way to supply this information after the artifact is created?</p>\n<p>Thanks for the help!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-14T19:25:42.862Z",
				"Answer_body": "<p>I ended up adding a metaflow step that updates the artifact that was just automatically logged, like in this example: <a href=\"https://docs.wandb.ai/guides/artifacts/api#updating-artifacts\">https://docs.wandb.ai/guides/artifacts/api#updating-artifacts</a>.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-15T09:43:32.584Z",
				"Answer_body": "<p>Thank you so much for answering your own question! Feel free to share a code snippet for future readers going down the same path.<br>\n<img src=\"https://emoji.discourse-cdn.com/twitter/raised_hands.png?v=10\" title=\":raised_hands:\" class=\"emoji only-emoji\" alt=\":raised_hands:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-18T12:33:59.760Z",
				"Answer_body": "<p>I\u2019ve updated the docs to reflect this solution <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Colab Disconnecting",
		"Question_link": "https://community.wandb.ai/t/colab-disconnecting/911",
		"Question_created_time": "2021-10-11T09:19:10.285Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 325,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Please help. I\u2019m trying to use wandb in colab and was able to do so yesterday for the first time. All be it, the runtime would disconnect and then reconnect in the same state after each training session.</p>\n<p>Today however, Everytime i login, it crashes after hanging for 30 seconds or so.</p>\n<p>Has anyone had any similar experiences?</p>\n<p>here is my code,<br>\nall in seperate cells</p>\n<p><strong>!pip install wandb -qqq</strong></p>\n<p><strong>import wandb</strong></p>\n<p><strong>wandb.login()</strong></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-11T17:56:01.143Z",
				"Answer_body": "<p>Hey Leo! <img src=\"https://emoji.discourse-cdn.com/twitter/wave.png?v=10\" title=\":wave:\" class=\"emoji\" alt=\":wave:\"></p>\n<p>Welcome to our forums!</p>\n<p>I\u2019ve moved this post to the <a class=\"hashtag\" href=\"/c/help/30\">#<span>help</span></a> category, I hope that\u2019s okay <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>\n<p>Could you please check your network for any possible issues? Generally our materials have been tested well on colab and this shouldn\u2019t be happening</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-16T00:31:31.236Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/deepleo\">@deepleo</a>  I also experienced more Colab disconnections when I integrated wandb.  It resolved when I placed the codes in separate cells (which I see did not work for you).</p>\n<p>Maybe it\u2019s the code.  I use:</p>\n<p>from fastai.callback.wandb import *</p>\n<p>wandb.init(project = \u2018project_name\u2019, name = \u2018model_training_name\u2019, reinit = True)</p>\n<p>Hope this helps!</p>\n<p>Maria</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.567Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Creating Artifact Manually While Using Metaflow <> WandB Integration",
		"Question_link": "https://community.wandb.ai/t/creating-artifact-manually-while-using-metaflow-wandb-integration/935",
		"Question_created_time": "2021-10-12T18:54:06.799Z",
		"Question_answer_count": 3,
		"Question_score_count": 3,
		"Question_view_count": 298,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi everyone,</p>\n<p>I\u2019m using the <a href=\"https://docs.wandb.ai/guides/integrations/other/metaflow\">MetaFlow Integration with WandB</a>. I understand the decorator will help me log instance variables (e.g., pandas data frames) as artifacts to WandB automatically.</p>\n<p>In one of Metaflow steps, I\u2019m trying to write a set of arrow files to disk and then upload these to an artifact with WandB. To do such I must run:</p>\n<pre><code class=\"lang-auto\">run.log_artifact(artifact)\n</code></pre>\n<p>Is there an easy way to extract / get the <a href=\"https://github.com/wandb/client/blob/master/wandb/integration/metaflow/metaflow.py#L278\" rel=\"noopener nofollow ugc\">run object created by the wandb metaflow decorator</a> so that it can be used to log this artifact explicitly?</p>\n<p>Thanks!<br>\nSahil</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-15T13:41:14.775Z",
				"Answer_body": "<p>Hi Sahil!</p>\n<p>We don\u2019t expose the run object directly, but you can log to that run implicitly by calling this inside your step.</p>\n<pre><code class=\"lang-auto\">artifact = wandb.Artifact(name, type=\"dataset\")\nartifact.add_file(\"file.arrow\")\nwandb.log_artifact(artifact)\n</code></pre>\n<p>Are you trying to save dataframes as <code>.arrow</code>?  We <a href=\"https://github.com/wandb/client/blob/master/wandb/integration/metaflow/metaflow.py#L122\" rel=\"noopener nofollow ugc\">save this as <code>.parquet</code> today</a>, but can add an arrow option.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-15T17:08:28.162Z",
				"Answer_body": "<p>That\u2019s awesome! Thanks so much <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.731Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Logging dictionary from Pytorch Lightning Logger",
		"Question_link": "https://community.wandb.ai/t/logging-dictionary-from-pytorch-lightning-logger/725",
		"Question_created_time": "2021-09-21T16:36:43.176Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 315,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>When logging using the W&amp;B Callback, a call to <code>self.log()</code> will only take scalars (the call won\u2019t fail, it just won\u2019t show up in the W&amp;B plots). I\u2019d like to to something like the following:</p>\n<p>Using the standard PL log call:<br>\n<code>self.log(name='my_metrics', value={ 'a': 1, 'b':2} ).</code><br>\nand have nice plots show up auto-magically with all these plots on the same axis or in the same tab.</p>\n<p>Currently I am simply looping through my dict and logging them as scalars manually</p>\n<p>Note I would like to avoid unpacking the the W&amp;B logger from the PL Trainer, and calling it directly.<br>\n<code>wandb = self.logger.experiment</code></p>\n<p>I haven\u2019t tested this, but I assume it would work. But it would make my code messy and dependent on knowledge of whether I was using W&amp;B for a particular run.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-15T10:25:19.301Z",
				"Answer_body": "<p>Sorry for not replying <a class=\"mention\" href=\"/u/max_wasserman\">@max_wasserman</a>. Thanks for passing these requests on, I agree that it would be nice to be able to pass a dict using the standard PL call. I\u2019ll pass this request on to the owners of the PL integration and see what they think about adding that call.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-15T14:51:01.150Z",
				"Answer_body": "<p>Turns out this feature already exists and I didn\u2019t know.<br>\nHere\u2019s how to log a dict with PyTorch Lightning: <a href=\"https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html?highlight=Log_dict#log-dict\" class=\"inline-onebox\">LightningModule \u2014 PyTorch Lightning 1.5.0rc0 documentation</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.263Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "[BUG] Config param name inclusing a dot",
		"Question_link": "https://community.wandb.ai/t/bug-config-param-name-inclusing-a-dot/916",
		"Question_created_time": "2021-10-11T14:42:56.319Z",
		"Question_answer_count": 4,
		"Question_score_count": 0,
		"Question_view_count": 327,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have a config param with the following name:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/5e256d34409e2dff601a90b30f46f777c31ca555.png\" data-download-href=\"/uploads/short-url/dqR4ex4NYNlpeVlIDbLPCuUMzPL.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/5e256d34409e2dff601a90b30f46f777c31ca555_2_690x152.png\" alt=\"image\" data-base62-sha1=\"dqR4ex4NYNlpeVlIDbLPCuUMzPL\" width=\"690\" height=\"152\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/5e256d34409e2dff601a90b30f46f777c31ca555_2_690x152.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/5e256d34409e2dff601a90b30f46f777c31ca555.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/5e256d34409e2dff601a90b30f46f777c31ca555.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/5e256d34409e2dff601a90b30f46f777c31ca555_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">893\u00d7198 10.5 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>However, when I call him in my graph, there is a bug and the graph stays white:</p>            <div class=\"onebox imgur-album\">\n              <a href=\"https://imgur.com/a/EIML6VO\" target=\"_blank\" rel=\"noopener nofollow ugc\">\n                <span class=\"outer-box\" style=\"width:600px\">\n                  <span class=\"inner-box\">\n                    <span class=\"album-title\">[Album] imgur.com</span>\n                  </span>\n                </span>\n                <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/2f6fef7dba514e4297115fb6caaa0d05a941ddf4.jpeg\" title=\"imgur.com\" height=\"315\" width=\"600\">\n              </a>\n            </div>\n",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-14T09:59:15.348Z",
				"Answer_body": "<p>Hi,<br>\nThanks for posting that here. I\u2019ve been able to reproduce this and will pass it on to get it fixed.<br>\nSorry for any inconvenience this has caused.<br>\nThanks again <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-15T14:34:30.068Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/boilario\">@boilario</a>,<br>\nwe have created a ticket for this bug. The team will look into this soon. I\u2019ll notify you once this is fixed.<br>\nThank you for your patience</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:01:40.993Z",
				"Answer_body": "<p>Hi,<br>\nThanks for posting that here. I\u2019ve been able to reproduce this and will pass it on to get it fixed.<br>\nSorry for any inconvenience this has caused.<br>\nThanks again <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" alt=\":slight_smile:\" title=\":slight_smile:\"></p>\n<p>[Discourse post]</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.517Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Set x axis expression for multiple plots at once",
		"Question_link": "https://community.wandb.ai/t/set-x-axis-expression-for-multiple-plots-at-once/978",
		"Question_created_time": "2021-10-14T12:54:16.421Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 286,
		"Question_has_accepted_answer": false,
		"Question_body": "<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9382546d321c088f70d9f648e6c6f42f91eff90f.png\" data-download-href=\"/uploads/short-url/l2VpWvmsWouis0P14ZE8w2DtEWr.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9382546d321c088f70d9f648e6c6f42f91eff90f_2_638x500.png\" alt=\"image\" data-base62-sha1=\"l2VpWvmsWouis0P14ZE8w2DtEWr\" width=\"638\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9382546d321c088f70d9f648e6c6f42f91eff90f_2_638x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9382546d321c088f70d9f648e6c6f42f91eff90f.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/9382546d321c088f70d9f648e6c6f42f91eff90f.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/9382546d321c088f70d9f648e6c6f42f91eff90f_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">693\u00d7543 28.2 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use href=\"#discourse-expand\"></use></svg>\n</div></a></div><br>\nI use this feature to show Epoch instead of Iter on the X axis.<br>\nIt\u2019s a bit laborious to go trough all my plots to set this expression manually.</p>\n<p>Is there a workaround ?<br>\nOtherwise, please flag this with [feature request]</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-14T13:13:38.518Z",
				"Answer_body": "<p>found my workaround, by reporting my own epoch_number in the tags I upload  to wandb then using this feature:<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/72ad578c0e9d9f536d22adc0cbdbcc89a0c2e630.png\" data-download-href=\"/uploads/short-url/gmtOxi6aOgNJIP1xUVr4MCUOAec.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/72ad578c0e9d9f536d22adc0cbdbcc89a0c2e630_2_690x216.png\" alt=\"image\" data-base62-sha1=\"gmtOxi6aOgNJIP1xUVr4MCUOAec\" width=\"690\" height=\"216\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/72ad578c0e9d9f536d22adc0cbdbcc89a0c2e630_2_690x216.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/72ad578c0e9d9f536d22adc0cbdbcc89a0c2e630_2_1035x324.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/72ad578c0e9d9f536d22adc0cbdbcc89a0c2e630.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/72ad578c0e9d9f536d22adc0cbdbcc89a0c2e630_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1191\u00d7373 26.6 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-15T09:53:11.308Z",
				"Answer_body": "<p>Interesting workaround. Thanks for sharing your answer. I\u2019ll make sure to pass this feedback on! <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.618Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Reopen wandb backend process after finish",
		"Question_link": "https://community.wandb.ai/t/reopen-wandb-backend-process-after-finish/943",
		"Question_created_time": "2021-10-13T14:11:25.843Z",
		"Question_answer_count": 6,
		"Question_score_count": 8,
		"Question_view_count": 371,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,<br>\nI am running  wandb with pytorch Lit. After running the training mode and log all the metric in the dashboard, I want to close the session by running <code>wandb.finish()</code>. After that I want to execute the test mode so I ativated the mode by <code>trainer.test(...)</code> but i get an error says \u201cThe wandb backend process has shutdown\u201d. it seems logic to me that it can not log to the project to save the test loss because I already close it.<br>\nMy question here, is there any possible way to reopen the same session with the same project name and ID ?<br>\nFYI, i uses the resume mode with the same name and ID but didn\u2019t not work wit me. Each time, it create a new run but in the same project.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-13T16:42:34.779Z",
				"Answer_body": "<p>Hi<br>\nThanks for joining our community <img src=\"https://emoji.discourse-cdn.com/twitter/wave.png?v=10\" title=\":wave:\" class=\"emoji\" alt=\":wave:\"><br>\nWould running <code>wandb.init</code> between training and testing fix the issue?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-14T14:12:58.604Z",
				"Answer_body": "<p>Hello,<br>\ngreat to hear from you (again <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"> )<br>\nNo, I tried <code>wandb.init</code> but I always get a new run!<br>\nI even used the same name of the project and the resume option <code>wandb.init(project=\"lit-wandb\", resume=True)</code><br>\nyou can check with this screen how I get a new run after the <code>wandb.finish()</code><br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/1a901c0e8aaa0a842386221b96d67436b462d7e5.png\" data-download-href=\"/uploads/short-url/3MZaokjru6i56Ex1lPPBUxi9H8h.png?dl=1\" title=\"Screenshot 2021-10-14 at 4.11.38 PM\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1a901c0e8aaa0a842386221b96d67436b462d7e5_2_435x500.png\" alt=\"Screenshot 2021-10-14 at 4.11.38 PM\" data-base62-sha1=\"3MZaokjru6i56Ex1lPPBUxi9H8h\" width=\"435\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1a901c0e8aaa0a842386221b96d67436b462d7e5_2_435x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1a901c0e8aaa0a842386221b96d67436b462d7e5_2_652x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1a901c0e8aaa0a842386221b96d67436b462d7e5_2_870x1000.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/1a901c0e8aaa0a842386221b96d67436b462d7e5_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot 2021-10-14 at 4.11.38 PM</span><span class=\"informations\">974\u00d71117 120 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-14T14:26:23.412Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"bttx\" data-post=\"1\" data-topic=\"943\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/b/258eb7/40.png\" class=\"avatar\"> bttx:</div>\n<blockquote>\n<p>wandb.finish()</p>\n</blockquote>\n</aside>\n<p>Thanks for that additional context.<br>\nSo the typical workflow for logging training and testing metrics <em>would</em> be to have a different run for each. You can use run groups if you\u2019d like to group these runs.<br>\nYou can do this dynamically in the UI or by passing in <code>group</code> and <code> job_type</code> to  <code>wandb.init</code> like <code>wandb.init(group=\"experiment_1\", job_type=\"eval\")</code>.<br>\nDo you have any particular reason for wanting the run for both to be the same?</p>\n<p>Edit: Here\u2019s the docs for run groups: <a href=\"https://docs.wandb.ai/guides/track/advanced/grouping\">https://docs.wandb.ai/guides/track/advanced/grouping</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-14T14:47:14.574Z",
				"Answer_body": "<p>Thank you for your quick replay.<br>\nthe reason behind this \u2018re-run\u2019 that is when I finish the training of my model I dont need wandb so I do <code>wandb.finish()</code> but after that I want to test my model (either with a test dataset or a new data). In this way, I can\u2019t do the test . so i need to leave the session open. (please excuse me if I did not describe the problem in a clear way)</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-15T09:46:55.124Z",
				"Answer_body": "<p>Ah I understand. You want to disable <code>wandb</code> entirely while you\u2019re running your test script.<br>\nYou can disable wandb which will \u201cnoop\u201d the wandb.log calls by initialising with<br>\n<code>wandb.init(mode=\"disabled\")</code>.<br>\nHope that helps</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:07.642Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Two y-axis chart plotting",
		"Question_link": "https://community.wandb.ai/t/two-y-axis-chart-plotting/939",
		"Question_created_time": "2021-10-12T23:20:43.431Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 423,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello, I was wondering if it is possible to create a custom chart with two axis in y direction, such that the first one has a value scale and the other have another scale.</p>\n<p>Thank you very much in advance!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-13T20:53:16.309Z",
				"Answer_body": "<p>Hi Hany,</p>\n<p>Our custom charts are visualized using Vega. In order to have to y-axis, use the \u2018orient\u2019 property and indicate both a left and a right to get a y-axis on both sides.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-13T21:52:00.114Z",
				"Answer_body": "<p>Hi Leslie,</p>\n<p>Great, thank you very much for the fast reply!!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Integrate a new plugin to Weights & Biases",
		"Question_link": "https://community.wandb.ai/t/integrate-a-new-plugin-to-weights-biases/792",
		"Question_created_time": "2021-09-27T07:42:46.426Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 281,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello,</p>\n<p>What is the best way to integrate a new plugin (that compares two runs) in weights &amp; biases interface ?</p>\n<p>Best,</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-27T14:13:36.098Z",
				"Answer_body": "<p>Hey there, you can\u2019t integrate a plugin but we already have a built-in feature to compare runs. Here is the <a href=\"https://docs.wandb.ai/ref/app/features/panels/run-comparer\">link</a> to the documentation.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Make user admin for trial",
		"Question_link": "https://community.wandb.ai/t/make-user-admin-for-trial/826",
		"Question_created_time": "2021-10-01T00:40:01.825Z",
		"Question_answer_count": 6,
		"Question_score_count": 6,
		"Question_view_count": 310,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi!</p>\n<p>I\u2019m trialing wanb for my company to see if its something we\u2019re interested in using.  My account is a \u201cmember\u201d account even though i\u2019m the one who created the Team.  I\u2019d like to invite other team members to my team but because my user isn\u2019t \u201cadmin\u201d status I cannot.  How can I get my team members added to the wand team I created?</p>\n<p>Thank you,<br>\nBlake</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-01T04:54:48.739Z",
				"Answer_body": "<p>Hi Blake,</p>\n<p>Welcome to our forums and Thanks for flagging this! I\u2019ll request the team to look into this and help you out ASAP. I\u2019ll reply as soon as I hear back (Slack appears to be down today so it might take a little longer <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"> )</p>\n<p>In the meantime, please feel free to send any feedback/questions our way about W&amp;B or beyond.</p>\n<p>Thanks,<br>\nSanyam</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-06T21:18:15.380Z",
				"Answer_body": "<p>Hello!<br>\nI was wondering if there has been any update on this?  We are trialing different services and will be making a decision shortly, so it would be helpful for me to show this to my team.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-07T12:56:40.044Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/openblake\">@openblake</a>,</p>\n<p>Apologies for the small delay and Thanks for giving this a bump and checking!</p>\n<p>I\u2019ve re-requested the team to look into it, we\u2019ll have someone help you out today.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-07T15:59:28.359Z",
				"Answer_body": "<p>Hey Blake, can you tell me your organization name and your username?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-07T16:32:32.850Z",
				"Answer_body": "<p>openblakeis my username and my organization is OpenSpace</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-12T12:17:56.521Z",
				"Answer_body": "<p>You are now an admin of the team, Blake. Let me know if there are any issues</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Feature request: adding zip files to reports",
		"Question_link": "https://community.wandb.ai/t/feature-request-adding-zip-files-to-reports/877",
		"Question_created_time": "2021-10-06T21:26:06.071Z",
		"Question_answer_count": 5,
		"Question_score_count": 4,
		"Question_view_count": 316,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I often want to upload zip files with a bunch of info from experiments to wandb but currently the web UI does not respond to this. May we have this as a feature?</p>\n<hr>\n<p>originally asked as a help question but realized it was likely a feature request or tech support question. Original question: <a href=\"https://community.wandb.ai/t/how-do-i-upload-artifacts-e-g-zip-files-manually-in-the-website-gui/840/2\" class=\"inline-onebox\">How do I upload artifacts (e.g. zip files) manually in the website GUI? - #2 by brando</a></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-06T23:11:04.112Z",
				"Answer_body": "<p>What kind of information is in your zip files?</p>\n<p>It\u2019s a bit unnatural to attach data to a report. The natural place for data to live is on a run (either as metadata, history, summary, or artifact), with workspaces and reports designed to give views on that data.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-07T15:51:28.440Z",
				"Answer_body": "<p>well, I like it on my reports <img src=\"https://emoji.discourse-cdn.com/twitter/stuck_out_tongue.png?v=10\" title=\":stuck_out_tongue:\" class=\"emoji\" alt=\":stuck_out_tongue:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-07T15:52:57.305Z",
				"Answer_body": "<p>If it helps to add context, when writing a paper, or drafts etc I manipulate manually data, figs, etcs and it\u2019s nice to be able to post them to reports. The code is nice for automatic stuff, but it\u2019s not as nice for the \u201cmuseum\u201d idea. Just my 2 cents.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-09T03:29:43.782Z",
				"Answer_body": "<aside class=\"quote group-team\" data-username=\"charlesfrye\" data-post=\"2\" data-topic=\"877\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https://sea2.discourse-cdn.com/business7/user_avatar/community.wandb.ai/charlesfrye/40/52_2.png\" class=\"avatar\"> charlesfrye:</div>\n<blockquote>\n<p>What kind of information is in your zip files?</p>\n</blockquote>\n</aside>\n<p>For example, I want to download all media files i.e. images. I can download any image separately, but I cannot download image folder.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-11T17:55:08.993Z",
				"Answer_body": "<p><a class=\"mention\" href=\"/u/mirage\">@mirage</a>, if you\u2019re looking to download lots of info from W&amp;B,  you\u2019re better off using the public API (<a href=\"https://docs.wandb.ai/guides/track/public-api-guide\">guide here</a>) to access it programmatically, rather than using the UI.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Access denied",
		"Question_link": "https://community.wandb.ai/t/access-denied/870",
		"Question_created_time": "2021-10-05T19:43:49.810Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 321,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I created a hello world example on Jupiter lab, and when I use Iframe to display the wand curves I get a screen with access denied, even though I am already signed in. Could you please help solve this problem?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-07T19:57:13.101Z",
				"Answer_body": "<p>Hi Walid, thanks for reporting this. It sounds like there might be controls in your Jupyter Lab setup that are preventing W&amp;B from signing you in to that iframe. Is there a way you could share a link with us so we can see what\u2019s happening and reproduce the problem? When I\u2019ve tested the iframe feature in Google Colab it\u2019s worked correctly for signing me into my session.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-19T20:39:44.929Z",
				"Answer_body": "<p>Hi Walid,</p>\n<p>We wanted to follow up with you regarding your support request as we have not heard back from you. Please let us know if we can be of further assistance or if your issue has been resolved.</p>\n<p>Best,<br>\nWeights &amp; Biases</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-19T20:41:48.580Z",
				"Answer_body": "<p>This actually occurs only with Safari browser, however, on Chrome everything is fine.</p>\n<p>Sent from my iPad</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How do I upload artifacts (e.g. zip files) manually in the website GUI?",
		"Question_link": "https://community.wandb.ai/t/how-do-i-upload-artifacts-e-g-zip-files-manually-in-the-website-gui/840",
		"Question_created_time": "2021-10-01T18:03:05.957Z",
		"Question_answer_count": 2,
		"Question_score_count": 2,
		"Question_view_count": 532,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I just want to upload artifacts manually place and drop and the end of the project. I have 2 zip files. How do I do that?</p>\n<p>Ideally, I want to avoid writing code. I tried dropping it into a report but the report didn\u2019t do anything when I dropped my zip files.</p>\n<hr>\n<p>also, the artifacts guide seems unncesserily long and not explain the most basic questions imho. e.g.</p>\n<ol>\n<li>Are we suppose to upload artifacts on every run?</li>\n<li>how do we make sure we don\u2019t double upload data?</li>\n<li>how does wandb version to avoid duplicate data uploaded</li>\n</ol>\n<p>perhaps a shorter tutorial that is more to the point would be nice, especially explaining the expected/common workflow with artifacts.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-06T21:24:01.391Z",
				"Answer_body": "<p>I am particularly interested to upload zip files to my reports.</p>\n<hr>\n<p>posted in tech support since the web UI doesn\u2019t do it its more likely to be a feature request: <a href=\"https://community.wandb.ai/t/feature-request-adding-zip-files-to-reports/877\" class=\"inline-onebox\">Feature request: adding zip files to reports</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-08T15:39:46.085Z",
				"Answer_body": "<p>Hey Brando,</p>\n<p>You can find the information about how Artifacts handle duplication here. I\u2019d also suggest checking out this tutorial showing the common workflows with Artifacts.<br>\nI followed up in the other thread on uploading zip files. Let me know if you have any questions.</p>\n<p>Best,<br>\nArman</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Artifact.add_reference('s3://...'): error in finding credentials",
		"Question_link": "https://community.wandb.ai/t/artifact-add-reference-s3-error-in-finding-credentials/866",
		"Question_created_time": "2021-10-05T02:48:57.833Z",
		"Question_answer_count": 3,
		"Question_score_count": 3,
		"Question_view_count": 334,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi, I am trying to track an artifact that lives in AWS S3. I have a <code>~/.aws/credentials</code> file with two profiles and I would like to talk to AWS and store the reference with one of those profiles. I rather not use environment variables (i.e. AWS_ACCESS_KEY_ID, etc), but stick with the credentials folder and maintain the existing profiles. Are there any ways of making this work? Thanks!</p>\n<p>Problem code:</p>\n<pre><code class=\"lang-auto\">    raw_data_uri = os.path.join('s3://', cfg.bucket_name, cfg.prefix)\n    bucket = S3Bucket(cfg.bucket_name, cfg.aws_profile) # my handler to talk to S3\n    num_items = len(bucket.ls(cfg.prefix))\n    \n    with wandb.init(project=cfg.project, job_type=cfg.job_type, name=cfg.run_stamp) as run:\n        artifact = wandb.Artifact(name='raw_data', type='raw_data',\n                                    metadata={\n                                        'aws_profile': cfg.aws_profile,\n                                        'num_items': num_items\n                                        })\n            \n        artifact.add_reference(raw_data_uri)\n        run.log_artifact(artifact)\n</code></pre>\n<p>Error:</p>\n<pre><code class=\"lang-auto\">botocore.exceptions.NoCredentialsError: Unable to locate credentials\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-05T02:54:49.016Z",
				"Answer_body": "<p>Solved my own problem. Forgot I could set a temp env variable in the script itself:</p>\n<pre><code class=\"lang-auto\">os.environ['AWS_PROFILE'] = cfg.aws_profile\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-05T13:54:20.420Z",
				"Answer_body": "<p>Thanks for writing an answer to your own question for any future readers!!</p>\n<p><img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"> <img src=\"https://emoji.discourse-cdn.com/twitter/clap.png?v=10\" title=\":clap:\" class=\"emoji\" alt=\":clap:\"><img src=\"https://emoji.discourse-cdn.com/twitter/raised_hands.png?v=10\" title=\":raised_hands:\" class=\"emoji\" alt=\":raised_hands:\"> <img src=\"https://emoji.discourse-cdn.com/twitter/raised_hands.png?v=10\" title=\":raised_hands:\" class=\"emoji\" alt=\":raised_hands:\"> <img src=\"https://emoji.discourse-cdn.com/twitter/raised_hands.png?v=10\" title=\":raised_hands:\" class=\"emoji\" alt=\":raised_hands:\"> <img src=\"https://emoji.discourse-cdn.com/twitter/raised_hands.png?v=10\" title=\":raised_hands:\" class=\"emoji\" alt=\":raised_hands:\"> <img src=\"https://emoji.discourse-cdn.com/twitter/clap.png?v=10\" title=\":clap:\" class=\"emoji\" alt=\":clap:\">  <img src=\"https://emoji.discourse-cdn.com/twitter/clap.png?v=10\" title=\":clap:\" class=\"emoji\" alt=\":clap:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.476Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "HuggingFace Trainer Doesn't Log Validation Loss to WandB",
		"Question_link": "https://community.wandb.ai/t/huggingface-trainer-doesnt-log-validation-loss-to-wandb/862",
		"Question_created_time": "2021-10-04T17:58:12.447Z",
		"Question_answer_count": 4,
		"Question_score_count": 5,
		"Question_view_count": 416,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019m trying to use HuggingFace\u2019s Trainer API to fine-tune BERT:</p>\n<pre><code class=\"lang-auto\">    # Skip trainer till we can figure out how to specify MSE as loss\n    trainer = Trainer(\n        model=model,  # the instantiated \ud83e\udd17 Transformers model to be trained\n        args=training_args,  # training arguments, defined above\n        train_dataset=train_dataset,\n        eval_dataset=eval_dataset)\n\n    trainer.train()\n\n</code></pre>\n<p>However, the validation loss is not logged to WandB:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/bd50bff34014905293a02009ee020924aed36c37.png\" data-download-href=\"/uploads/short-url/r0LflG5PietHrlamoq63Tc6RaLR.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/bd50bff34014905293a02009ee020924aed36c37_2_690x132.png\" alt=\"image\" data-base62-sha1=\"r0LflG5PietHrlamoq63Tc6RaLR\" width=\"690\" height=\"132\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/bd50bff34014905293a02009ee020924aed36c37_2_690x132.png, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/bd50bff34014905293a02009ee020924aed36c37.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/bd50bff34014905293a02009ee020924aed36c37.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/bd50bff34014905293a02009ee020924aed36c37_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1015\u00d7195 6.61 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>This problem was observed by someone else on the HuggingFace forum: <a href=\"https://discuss.huggingface.co/t/no-loss-being-logged-when-running-mlm-script-colab/8134\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">No loss being logged, when running MLM script (Colab) - \ud83e\udd17Transformers - Hugging Face Forums</a></p>\n<p>Can someone please tell me how to ensure the validation loss is logged to WandB?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-04T21:07:31.744Z",
				"Answer_body": "<p>Hi Rylan, what do you have stored in the <code>training_args</code> variable? There are several ways to integrate W&amp;B for HuggingFace. One is to make sure that <code>training_args</code> is a <code>transformers.TrainingArguments</code> object with <code>TrainingArguments(report_to='wandb')</code>.</p>\n<p>Hope this helps! Full W&amp;B documentation for HuggingFace can be found here:</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/guides/integrations/huggingface\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/41cd209363aac9340aa990ad198a67c63ad5a47b.png\" class=\"site-icon\" width=\"256\" height=\"256\">\n\n      <a href=\"https://docs.wandb.ai/guides/integrations/huggingface\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/guides/integrations/huggingface\" target=\"_blank\" rel=\"noopener\">Hugging Face</a></h3>\n\n  <p>A Weights &amp; Biases integration for Hugging Face's Transformers library: solving NLP, one logged run at a time!</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-04T21:13:34.048Z",
				"Answer_body": "<p>Yep! <code>report_to='wandb'</code> is successfully logging the training loss to W&amp;B, but the validation loss isn\u2019t being logged\u2026</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-05T01:01:53.502Z",
				"Answer_body": "<p>It seems that adding the following arguments to the <code>TrainingArguments</code> solved the problem <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>\n<pre><code class=\"lang-auto\">        do_eval=True,\n        evaluation_strategy=\"steps\",\n        eval_steps=10,\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-05T13:03:02.286Z",
				"Answer_body": "<p><img src=\"https://emoji.discourse-cdn.com/twitter/+1.png?v=10\" title=\":+1:\" class=\"emoji\" alt=\":+1:\"> Nice to hear that you solved it!</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Stop button",
		"Question_link": "https://community.wandb.ai/t/stop-button/614",
		"Question_created_time": "2021-09-15T13:53:00.302Z",
		"Question_answer_count": 3,
		"Question_score_count": 2,
		"Question_view_count": 294,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi<br>\nI\u2019m running training on aws batch (on docker image) and I want to be able to stop the run manually using the button on the wandb and ideally therefore stop that aws batch instance (since the command finished executing).<br>\nThe training runs are using bot key that was given to me. And when I click the stop button (on website, using my account), it says I can\u2019t view the page.<br>\nIs it a permission issue? Will it work as I described?<br>\nThanks</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-16T03:35:41.791Z",
				"Answer_body": "<p>Hi there,</p>\n<p>Can you share a little more about how you\u2019re running these runs? Are they attributed to your personal account or to a service account?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-16T20:55:54.823Z",
				"Answer_body": "<p>basically we have a script to start up a aws docker run given a command, in this case to start training. The docker run stops when the command finished executing and I want to stop the training and thus stop the docker  run.<br>\nIt\u2019s service account? work account.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-04T15:34:04.339Z",
				"Answer_body": "<p>Hi! Were you the original creator of the run? I think what is likely happening is that someone else created the run and therefore you may not have permissions to stop it.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "W&B support vs help?",
		"Question_link": "https://community.wandb.ai/t/w-b-support-vs-help/844",
		"Question_created_time": "2021-10-01T19:15:24.242Z",
		"Question_answer_count": 2,
		"Question_score_count": 2,
		"Question_view_count": 306,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>what is the difference between the categories?</p>\n<p>which one to use?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-02T06:48:26.876Z",
				"Answer_body": "<p>Thanks for the Q!</p>\n<p>Support is for Product support/bug reporting. Help section is for getting help from the community with the best practises/etc <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.423Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to have wandb print how long experiment ran on console?",
		"Question_link": "https://community.wandb.ai/t/how-to-have-wandb-print-how-long-experiment-ran-on-console/845",
		"Question_created_time": "2021-10-01T19:16:30.901Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 262,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I always print this string:</p>\n<pre><code class=\"lang-auto\">wandb: Find logs at: ./wandb/run-20211001_135946-18loi2se/logs/debug.log\nwandb: \n-- wandb finished\ntime_passed_msg = time passed: hours:0.0714601335922877, minutes=4.287608015537262, seconds=257.2564809322357\n</code></pre>\n<p>but it\u2019s sort of annying if I am already running <code>wandb.finish</code>. Is it possible to have wandb print it for me? (especially to save it on my wandb log/print std out file?)</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-25T17:45:37.869Z",
				"Answer_body": "<p>Hi Brando,</p>\n<p>Thanks for your question! Unfortunately, <code>wandb.finish()</code> does not support printing functionality. As a workaround, you can call your <code>print</code> call right before calling <code>wandb.finish()</code> and the message will be saved into your wandb logs.</p>\n<p>Regards,<br>\nRamit</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-29T18:07:30.974Z",
				"Answer_body": "<p>Hello,</p>\n<p>I wanted to follow up on this issue to check if it has been resolved or if I can help you with anything else.</p>\n<p>Thanks,<br>\nRamit</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Is wandb suppose to get pycharm stuck?",
		"Question_link": "https://community.wandb.ai/t/is-wandb-suppose-to-get-pycharm-stuck/842",
		"Question_created_time": "2021-10-01T18:55:45.923Z",
		"Question_answer_count": 1,
		"Question_score_count": 1,
		"Question_view_count": 305,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I ran <code>wand.finish()</code> but it doesn\u2019t seem to finish properly (e.g. not showing the links to my runs etc):</p>\n<pre><code class=\"lang-auto\">wandb: Waiting for W&amp;B process to finish, PID 86593... (success).\nInvalidVersionSpec: Invalid version '1&lt;2': invalid character(s)\n</code></pre>\n<p>why is wandb not interacting well with pycharm?</p>\n<p>or is it just taking time because it\u2019s uploading artifacts?</p>\n<p>script</p>\n<pre><code class=\"lang-auto\">#%%\n\"\"\"\nI think artifacts are used per run or something but I will just create one run upload of the zip of the data and\nfigs I made. Then create a report that links to the artifact run.\n\nrefs:\nhttps://docs.wandb.ai/guides/artifacts\nhttps://community.wandb.ai/t/how-does-one-manually-upload-a-single-artifact/841\n\nfailed artifact push: https://wandb.ai/brando/meta-learning-neurips-workshop/runs/221fe0xw\n\"\"\"\nfrom argparse import Namespace\nfrom pathlib import Path\n\nimport wandb\n\nimport uutils\n\n# uutils.setup_args_for_experiment() does the following:\n# if hasattr(args, 'log_to_wandb'):\n#     if args.log_to_wandb:\n#         # os.environ['WANDB_MODE'] = 'offline'\n#         import wandb\n#\n#         print(f'{wandb=}')\n#\n#         # - set run name\n#         run_name = None\n#         # if in cluster use the cluster jobid\n#         if hasattr(args, 'jobid'):\n#             # if jobid is actually set to something, use that as the run name in ui\n#             if args.jobid is not None and args.jobid != -1 and str(args.jobid) != '-1':\n#                 run_name: str = f'jobid={str(args.jobid)}'\n#         # if user gives run_name overwrite that always\n#         if hasattr(args, 'run_name'):\n#             run_name = args.run_name if args.run_name is not None else run_name\n#         args.run_name = run_name\n#         # - initialize wandb\n#         wandb.init(project=args.wandb_project,\n#                    entity=args.wandb_entity,\n#                    # job_type=\"job_type\",\n#                    name=run_name,\n#                    group=args.experiment_name\n#                    )\n#         wandb.config.update(args)\n\ndef get_args_for_experiment() -&gt; Namespace:\n    # - get my default args\n    args = uutils.parse_basic_meta_learning_args()\n    args.log_to_wandb = False\n    args.log_to_wandb = True\n    args.wandb_project = 'meta-learning-neurips-workshop'\n    args.experiment_name = 'upload-of-zip-files-synthetic-data-set-all-figs-and-hps'\n    args.run_name = f'{args.experiment_name}_1'\n    args = uutils.setup_args_for_experiment(args)\n    return args\n\ndef get_zips_paths():\n    log_root: Path = Path('~/Desktop/').expanduser()\n    dataset_filename: str = 'dataset_LS_fully_connected_NN_with_BN_nb_tasks200_data_per_task1000_l_4_nb_h_layes3_out1_H15.zip'\n    all_figs_zip_filename: str = 'all_ckpts_and_figures.zip'\n    return log_root, dataset_filename, all_figs_zip_filename\n\n# wandb.init(job_type=\"dataset-creation\")  # done in uutils.setup_args_for_experiment()\nprint('-- getting args')\nargs = get_args_for_experiment()\n\n# https://docs.wandb.ai/ref/python/artifact for Artifact api\nprint('-- creating artifacts')\nartifact_data = wandb.Artifact('dataset_LS_fully_connected_NN_with_BN_nb_tasks200_data_per_task1000_l_4_nb_h_layes3_out1_H15.zip', type='dataset-as-zip')\nartifact_figs = wandb.Artifact('all_figs_for_paper', type='figs-as-zip')\n\n# - get zip files to log as artifacts\nprint('-- getting path to zipz')\nlog_root, dataset_filename, all_figs_zip_filename = get_zips_paths()\n\n# todo - Imagine more lines of text were added to this text file: (what does this mean?)\nprint('-- wandb artifact logging1 (artifact_data.add_file)')\n# artifact.add_file('my-dataset.txt')\nartifact_data.add_file(log_root / dataset_filename)\nartifact_figs.add_file(log_root / all_figs_zip_filename)\n\n# Log that artifact, and we identify the changed file\nprint('-- wandb artifact logging2 (wandb.log_artifact)')\nwandb.log_artifact(artifact_data)\nwandb.log_artifact(artifact_figs)\n# todo - Now you have a new version of the artifact, tracked in W&amp;B (don't get it)\n\n# - wandb\nif args.log_to_wandb:\n    print('-- finishing wandb')\n    wandb.finish()\n    print('-- wandb finished')\n\nprint('Done!\\a')\n</code></pre>\n<p>smallish files ~200mb ~100mb</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-01T19:14:46.882Z",
				"Answer_body": "<p>seems it just takes time to push the artifacts! even if they are small</p>\n<pre><code class=\"lang-auto\">wandb: Find logs at: ./wandb/run-20211001_135946-18loi2se/logs/debug.log\nwandb: \n-- wandb finished\ntime_passed_msg = time passed: hours:0.0714601335922877, minutes=4.287608015537262, seconds=257.2564809322357\n</code></pre>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How does one manually upload a single artifact?",
		"Question_link": "https://community.wandb.ai/t/how-does-one-manually-upload-a-single-artifact/841",
		"Question_created_time": "2021-10-01T18:35:03.047Z",
		"Question_answer_count": 3,
		"Question_score_count": 0,
		"Question_view_count": 710,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have two zip files I want to upload as an artifact (or in any way) to wanbd. I tried:</p>\n<pre><code class=\"lang-auto\">#%%\n\"\"\"\nI think artifacts are used per run or something but I will just create one run upload of the zip of the data and\nfigs I made. Then create a report that links to the artifact run.\n\nrefs:\nhttps://docs.wandb.ai/guides/artifacts\nhttps://community.wandb.ai/t/how-does-one-manually-upload-a-single-artifact/841\n\nfailed artifact push: https://wandb.ai/brando/meta-learning-neurips-workshop/runs/221fe0xw\n\"\"\"\nfrom argparse import Namespace\nfrom pathlib import Path\n\nimport wandb\n\nimport uutils\n\n# uutils.setup_args_for_experiment() does the following:\n# if hasattr(args, 'log_to_wandb'):\n#     if args.log_to_wandb:\n#         # os.environ['WANDB_MODE'] = 'offline'\n#         import wandb\n#\n#         print(f'{wandb=}')\n#\n#         # - set run name\n#         run_name = None\n#         # if in cluster use the cluster jobid\n#         if hasattr(args, 'jobid'):\n#             # if jobid is actually set to something, use that as the run name in ui\n#             if args.jobid is not None and args.jobid != -1 and str(args.jobid) != '-1':\n#                 run_name: str = f'jobid={str(args.jobid)}'\n#         # if user gives run_name overwrite that always\n#         if hasattr(args, 'run_name'):\n#             run_name = args.run_name if args.run_name is not None else run_name\n#         args.run_name = run_name\n#         # - initialize wandb\n#         wandb.init(project=args.wandb_project,\n#                    entity=args.wandb_entity,\n#                    # job_type=\"job_type\",\n#                    name=run_name,\n#                    group=args.experiment_name\n#                    )\n#         wandb.config.update(args)\n\ndef get_args_for_experiment() -&gt; Namespace:\n    # - get my default args\n    args = uutils.parse_basic_meta_learning_args()\n    args.log_to_wandb = False\n    args.log_to_wandb = True\n    args.wandb_project = 'meta-learning-neurips-workshop'\n    args.experiment_name = 'upload-of-zip-files-synthetic-data-set-all-figs-and-hps'\n    args.run_name = f'{args.experiment_name}_1'\n    args = uutils.setup_args_for_experiment(args)\n    return args\n\ndef get_zips_paths():\n    log_root: Path = Path('~/Desktop/').expanduser()\n    dataset_filename: str = 'dataset_LS_fully_connected_NN_with_BN_nb_tasks200_data_per_task1000_l_4_nb_h_layes3_out1_H15.zip'\n    all_figs_zip_filename: str = 'all_ckpts_and_figures.zip'\n    return log_root, dataset_filename, all_figs_zip_filename\n\n# wandb.init(job_type=\"dataset-creation\")  # done in uutils.setup_args_for_experiment()\nargs = get_args_for_experiment()\n\n# https://docs.wandb.ai/ref/python/artifact for Artifact api\nartifact_data = wandb.Artifact('dataset_LS_fully_connected_NN_with_BN_nb_tasks200_data_per_task1000_l_4_nb_h_layes3_out1_H15.zip', type='dataset-as-zip')\nartifact_figs = wandb.Artifact('all_figs_for_paper', type='figs-as-zip')\n\n# - get zip files to log as artifacts\nlog_root, dataset_filename, all_figs_zip_filename = get_zips_paths()\n\n# todo - Imagine more lines of text were added to this text file: (what does this mean?)\n# artifact.add_file('my-dataset.txt')\nartifact_data.add_file(log_root / dataset_filename)\nartifact_figs.add_file(log_root / all_figs_zip_filename)\n\n# Log that artifact, and we identify the changed file\nwandb.log_artifact(artifact_data)\nwandb.log_artifact(artifact_figs)\n# todo - Now you have a new version of the artifact, tracked in W&amp;B (don't get it)\n\n# - wandb\nif args.log_to_wandb:\n    wandb.finish()\n\nprint('Done!')\n</code></pre>\n<h2>\n<a name=\"but-my-run-is-emptyhow-do-i-upload-my-two-zip-files-to-wandb-ideally-using-artifacts-i-suppose-1\" class=\"anchor\" href=\"#but-my-run-is-emptyhow-do-i-upload-my-two-zip-files-to-wandb-ideally-using-artifacts-i-suppose-1\"></a>but my run is empty\u2026how do I upload my two zip files to wandb? (ideally using artifacts I suppose)</h2>\n<p>based from</p>\n<pre><code class=\"lang-auto\">wandb.init()\n\nartifact = wandb.Artifact('mnist', type='dataset')\nartifact.add_dir('mnist/')\nwandb.log_artifact(artifact)\n</code></pre>\n<p>and</p>\n<pre><code class=\"lang-auto\">run = wandb.init(job_type=\"dataset-creation\")\nartifact = wandb.Artifact('my-dataset', type='dataset')\n# Imagine more lines of text were added to this text file:\nartifact.add_file('my-dataset.txt')\n# Log that artifact, and we identify the changed file\nrun.log_artifact(artifact)\n# Now you have a new version of the artifact, tracked in W&amp;B\n</code></pre>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/guides/artifacts\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/41cd209363aac9340aa990ad198a67c63ad5a47b.png\" class=\"site-icon\" width=\"256\" height=\"256\">\n\n      <a href=\"https://docs.wandb.ai/guides/artifacts\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/guides/artifacts\" target=\"_blank\" rel=\"noopener\">Data + Model Versioning</a></h3>\n\n  <p>Dataset versioning, model versioning, pipeline tracking with flexible and lightweight building blocks</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/ref/python/artifact\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/41cd209363aac9340aa990ad198a67c63ad5a47b.png\" class=\"site-icon\" width=\"256\" height=\"256\">\n\n      <a href=\"https://docs.wandb.ai/ref/python/artifact\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/ref/python/artifact\" target=\"_blank\" rel=\"noopener\">wandb.Artifact</a></h3>\n\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
		"Answer_list": [
			{
				"Answer_created_time": "2021-10-01T18:43:45.619Z",
				"Answer_body": "<p>hu, seems that the only thing I needed was to finish wandb? forgot that part:</p>\n<pre><code class=\"lang-auto\"># - wandb\nif args.log_to_wandb:\n    wandb.finish()\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-08T15:35:32.485Z",
				"Answer_body": "<p>Hey Brando, sorry about the delay on this. Wanted to confirm that you were able to upload the files.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-10-12T12:20:43.833Z",
				"Answer_body": "<p>Hi there, I wanted to follow up on this request. Please let us know if we can be of further assistance or if your issue has been resolved.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to include citation of wandb easily with zotero or mendeley?",
		"Question_link": "https://community.wandb.ai/t/how-to-include-citation-of-wandb-easily-with-zotero-or-mendeley/772",
		"Question_created_time": "2021-09-25T18:54:27.622Z",
		"Question_answer_count": 3,
		"Question_score_count": 2,
		"Question_view_count": 324,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I\u2019d like to help support wandb and I think its important to make it as trivial as possible for user to cite wandb as thats valueble - in the spirit of how amazon makes it trivial to buy things with one click. I believe most of us researchers use zotero or mendeley. I usually go to a webpage and then download the citation automatically that I use for all my future papers - with mendeley or zotero. I suggest something like that is done for wandb. Perhaps with a whitepaper report (like tensorflow has) and then we can download the citation for it.</p>\n<p>For now I am just copy pasting this</p>\n<pre><code class=\"lang-auto\">@misc{wandb,\ntitle = {Experiment Tracking with Weights and Biases},\nyear = {2020},\nnote = {Software available from wandb.com},\nurl={https://www.wandb.com/},\nauthor = {Biewald, Lukas},\n}\n</code></pre>\n<p>but I don\u2019t think copy pasting this is a good long term solution to promote/support wanbd.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-27T15:38:52.195Z",
				"Answer_body": "<p>This is a good suggestion!</p>\n<p>FYI for others finding this post, that LaTeX/BibTeX snippet comes from here:</p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/company/academics#cite-weights-and-biases\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/41cd209363aac9340aa990ad198a67c63ad5a47b.png\" class=\"site-icon\" width=\"256\" height=\"256\">\n\n      <a href=\"https://docs.wandb.ai/company/academics#cite-weights-and-biases\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/company/academics#cite-weights-and-biases\" target=\"_blank\" rel=\"noopener\">Academics</a></h3>\n\n  <p>Use Weights &amp; Biases for free to track experiments, collaborate, and publish results</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-27T16:17:21.528Z",
				"Answer_body": "<p>unfortunately, that doesn\u2019t seem to add all the bibtext automatically in mendeley (and likely in zotero). Some type of arvix report is likely the easiest best/ less friction <img src=\"https://emoji.discourse-cdn.com/twitter/wink.png?v=10\" title=\":wink:\" class=\"emoji\" alt=\":wink:\"></p>\n<p>Hope my feedback helps!</p>\n<p>Onwards <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.391Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Cannot use artifact when in offline mode",
		"Question_link": "https://community.wandb.ai/t/cannot-use-artifact-when-in-offline-mode/739",
		"Question_created_time": "2021-09-22T12:25:02.310Z",
		"Question_answer_count": 8,
		"Question_score_count": 3,
		"Question_view_count": 359,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>How can I use artifacts without actually enabling wandb syncing? Sometimes I want just to play around my notebook without logging anything, but using data/models logged as artifacts in my project. I think I can do it via cli but I would like to know if there\u2019s something I\u2019m missing in the API.</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-23T20:10:20.762Z",
				"Answer_body": "<p>Hello!</p>\n<p>Here\u2019s a copy pasta from the <a href=\"https://docs.wandb.ai/guides/technical-faq\">docs-faq</a>, please lmk if this doesn\u2019t answer your Q:</p>\n<h2><a name=\"heading-1\" class=\"anchor\" href=\"#heading-1\"></a></h2>\n<p>Can I run wandb offline?</p>\n<p>If you\u2019re training on an offline machine and want to upload your results to our servers afterwards, we have a feature for you!</p>\n<ol>\n<li>\n<p>Set the environment variable <code>WANDB_MODE=offline</code> to save the metrics locally, no internet required.</p>\n</li>\n<li>\n<p>When you\u2019re ready, run <code>wandb init</code> in your directory to set the project name.</p>\n</li>\n<li>\n<p>Run <code>wandb sync YOUR_RUN_DIRECTORY</code> to push the metrics to our cloud service and see your results in our hosted web app.</p>\n</li>\n</ol>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-24T03:44:17.983Z",
				"Answer_body": "<p>You can do something like this:</p>\n<pre><code class=\"lang-auto\">artifact =  wandb.Artifact(name=\"folds\", type=\"dataset\")\nartifact.add_file('./df_train.csv')\nartifact.add_file('./df_valid.csv')\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-24T07:54:15.442Z",
				"Answer_body": "<p>The thing is that I want to be online, but just to use/download artifacts, but not for logging anything. In other words, I want to be able to download from my project but not to upload.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-24T09:38:30.540Z",
				"Answer_body": "<p>You could try the following pseudocode:</p>\n<ol>\n<li>wandb.login()</li>\n<li>wandb.init()</li>\n<li>Download from Artifacts</li>\n<li>wandb.finish()</li>\n<li>set WANDB_MODE=offline</li>\n<li>do training</li>\n</ol>\n<p>An alternative to 4 + 5 would be to  turn on <a href=\"https://docs.wandb.ai/ref/app/features/anon?q=disable\">anonymous mode</a> for your training, everything will  be tracked and synced to a temporary anon account and not linked to your account</p>\n<p><code>wandb.init(anonymous=\"allow\")</code></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-24T10:52:16.926Z",
				"Answer_body": "<p>Thanks! The anonymus mode could do the trick for me\u2026however, I can\u2019t udnerstand how it exactly works. I\u2019m trying the <a href=\"http://bit.ly/anon-mode\" rel=\"noopener nofollow ugc\">colab notebook they provide</a>,  setting <code>anonymous=must</code> but  it still creates a run linked to my account</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-24T11:43:51.750Z",
				"Answer_body": "<p>hmmm ok, I guess maybe you have to log out\u2026will forward that feedback. Maybe instead of anonymous you could use set the <code>mode</code> parameter to <code>offline</code>, or <code>disabled</code> then</p>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/ref/python/init\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/41cd209363aac9340aa990ad198a67c63ad5a47b.png\" class=\"site-icon\" width=\"256\" height=\"256\">\n\n      <a href=\"https://docs.wandb.ai/ref/python/init\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/ref/python/init\" target=\"_blank\" rel=\"noopener\">wandb.init</a></h3>\n\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-24T12:24:22.844Z",
				"Answer_body": "<p>Yes that\u2019s what I used to do (<code>mode=disabled</code>) when my run does not use artifacts as input datasets. The problem is that with mode=disabled I cannot use artifacts</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:07.422Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Span filtering prodigy datasets using W&B Tables",
		"Question_link": "https://community.wandb.ai/t/span-filtering-prodigy-datasets-using-w-b-tables/646",
		"Question_created_time": "2021-09-16T12:37:01.780Z",
		"Question_answer_count": 3,
		"Question_score_count": 4,
		"Question_view_count": 302,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi! I am currently testing the new prodigy integration to visualize NER datasets and it works great, thank you! But I have some problems.<br>\nI would like to filter  <code>row[\"spans\"][\"label\"] </code> by the special entities and I have problems here. My use case:</p>\n<ul>\n<li>Which texts contain only people (PERSON)? Which organisations (ORG) or locations (LOCATION)? How many people do I find in total?</li>\n<li>I would like to create new rows/columns to visualize the results.</li>\n</ul>\n<p>My problem: I can\u2019t manage to filter according to the entities. What am I doing wrong?<br>\nYour example here is also ok for the test:</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://wandb.ai/kshen/prodigy/reports/Visualizing-Prodigy-Datasets-Using-W-B-Tables--Vmlldzo5NDE2MTc\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/7a7a7077833cb4ec4be6e63ad7c2db322d3e15a6.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https://wandb.ai/kshen/prodigy/reports/Visualizing-Prodigy-Datasets-Using-W-B-Tables--Vmlldzo5NDE2MTc\" target=\"_blank\" rel=\"noopener\" title=\"02:05PM - 17 August 2021\">W&amp;B \u2013 17 Aug 21</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/6f5cc42f5be5838eaa024b6166848b71312afb4e.png\" class=\"thumbnail onebox-avatar\" width=\"300\" height=\"300\">\n\n<h3><a href=\"https://wandb.ai/kshen/prodigy/reports/Visualizing-Prodigy-Datasets-Using-W-B-Tables--Vmlldzo5NDE2MTc\" target=\"_blank\" rel=\"noopener\">Visualizing Prodigy Datasets Using W&amp;B Tables</a></h3>\n\n  <p>Use the W&amp;B/Prodigy integration to upload your Prodigy annotated datasets to W&amp;B for easier visualization. Made by Kevin Shen using Weights &amp; Biases</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/b9a81ed4d714e6b33f97a5dcdc6f3ca749dfe8e0.png\" data-download-href=\"/uploads/short-url/quowLbwH5KL7ZM97JjbPxcjnfNe.png?dl=1\" title=\"image\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b9a81ed4d714e6b33f97a5dcdc6f3ca749dfe8e0_2_517x186.png\" alt=\"image\" data-base62-sha1=\"quowLbwH5KL7ZM97JjbPxcjnfNe\" width=\"517\" height=\"186\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b9a81ed4d714e6b33f97a5dcdc6f3ca749dfe8e0_2_517x186.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b9a81ed4d714e6b33f97a5dcdc6f3ca749dfe8e0_2_775x279.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b9a81ed4d714e6b33f97a5dcdc6f3ca749dfe8e0_2_1034x372.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/b9a81ed4d714e6b33f97a5dcdc6f3ca749dfe8e0_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"></use></svg><span class=\"filename\">image</span><span class=\"informations\">1762\u00d7637 64 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>Thank you<br>\nAlfred</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-18T20:59:51.751Z",
				"Answer_body": "<p>Glad you\u2019re enjoying the prodigy integration!</p>\n<p>I\u2019ll try get an answer for this for you ASAP.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-24T10:20:07.557Z",
				"Answer_body": "<p>I don\u2019t know what I did wrong last time, but it works perfectly. Thanks!</p>\n<p><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/65110a2cb18407338e0a0ea30428977c2e81e590.png\" alt=\"image\" data-base62-sha1=\"eq4JnNYDJ8fJExgVYAeDukhCpjO\" width=\"447\" height=\"320\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-24T11:30:29.718Z",
				"Answer_body": "<p>Nice! Glad you got it working <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Clarification on Early Termination (Hyperband)",
		"Question_link": "https://community.wandb.ai/t/clarification-on-early-termination-hyperband/673",
		"Question_created_time": "2021-09-17T18:57:22.768Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 298,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Looking to run a large HP Sweep. I\u2019m using Pytorch Lightning (PL) for the model training and W&amp;B for experiment management. I have already have it up and running (using the WandbLogger callback for PL) and I\u2019m hoping to utilize the Early Termination feature that W&amp;B provides, but I find the documentation a little confusing. I\u2019d like to do something as simple as: Check some metric at ~[100, 500, 2500, \u2026] epochs and terminate those who aren\u2019t performing well.</p>\n<p>The documentation for HyperBand says:</p>\n<blockquote>\n<p>Brackets are based on the number of <em>logged</em> iterations, i.e. elements in the run\u2019s history. Depending on where you are calling <code>wandb.log</code> , these iterations may correspond to steps, epochs, or something in between. The numerical value of the step counter is not used in bracket calculations.</p>\n</blockquote>\n<p>I\u2019m having trouble deciphering this.</p>\n<p>For example, in my case I only check (and log) validation stuff every 10 epochs (check_val_every_n_epoch=10 is fed to the PL trainer) to save compute. I also log things at the end of a train batch, train epoch, and validation epoch. I log both dicts (in PL: self.log_dict() ) and values (self.log()). In some cases the logger flag is False in the call: self.log( , logger=False) or self.log_dict( , logger=False).</p>\n<p>So how is the number of logged iterations computed? How do I go about using this to achieve my original goal: check some metric every [100, 500, 2500, \u2026] epochs and terminate the \u2018bad\u2019 ones (as per the HyperBand alg)?</p>\n<p>Thanks in advance,<br>\nMax</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-17T20:03:09.221Z",
				"Answer_body": "<p>Thanks for the Q!<br>\nAllow me to look into this and get back with an answer <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-22T14:19:50.397Z",
				"Answer_body": "<p>Any update on this? Would save me lots of GPU hours <img src=\"https://emoji.discourse-cdn.com/twitter/upside_down_face.png?v=10\" title=\":upside_down_face:\" class=\"emoji\" alt=\":upside_down_face:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.315Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Change pointsizes, background, etc. in Object3D objects",
		"Question_link": "https://community.wandb.ai/t/change-pointsizes-background-etc-in-object3d-objects/564",
		"Question_created_time": "2021-09-14T10:49:01.633Z",
		"Question_answer_count": 3,
		"Question_score_count": 1,
		"Question_view_count": 288,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am logging pointclouds using numpy arrays following the shape [x,y,z,class], all integers.<br>\nLogging works, but the points are tiny and barely visible. Is it possible to make them larger?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-16T07:42:59.248Z",
				"Answer_body": "<p>Welcome to the forums!</p>\n<p>I haven\u2019t worked with point cloud data so I\u2019m not sure if there\u2019s a standard way to rescaling them:</p>\n<p>Did you get a chance to take a look at the <a href=\"https://docs.wandb.ai/guides/track/log/media#3d-visualizations\">Docs Section here</a>, does this not answer the Q?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-22T07:22:08.839Z",
				"Answer_body": "<p>Thanks for the answer!<br>\nSadly no, this only answers how to change point colors, not how to change point (marker) sizes or background color.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.222Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "What is the recommended way to use the name value in wandb.init?",
		"Question_link": "https://community.wandb.ai/t/what-is-the-recommended-way-to-use-the-name-value-in-wandb-init/721",
		"Question_created_time": "2021-09-20T22:16:35.961Z",
		"Question_answer_count": 2,
		"Question_score_count": 4,
		"Question_view_count": 313,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I usually track runs based on the job id of the HPC. So I was thinking I wanted to tack that value to the end to the nice 2 word name that wandb gives. How do I do that?</p>\n<p>Also, I am interested in knowing the recommended way to name runs or the common way wandb users, developers etc use this.</p>\n<p>note: I am already using the config to track the hyperparams and the group name to group similar experiments. I don\u2019t usually use jobtype actually.</p>\n<hr>\n<p>current script:</p>\n<pre><code class=\"lang-auto\">    if hasattr(args, 'log_to_wandb'):\n        if args.log_to_wandb:\n            # os.environ['WANDB_MODE'] = 'offline'\n            import wandb\n\n            # - experiment name\n            experiment_name = args.wandb_group\n            # - set run name\n            run_name = None\n            if hasattr(args, 'jobid'):\n                if args.jobid is not None:\n                    run_name: str = f'jobid={str(args.jobid)}'\n            # - initialize wandb\n            wandb.init(project=args.wandb_project,\n                       entity=args.wandb_entity,\n                       # job_type=\"job_type\",\n                       name=run_name,\n                       group=experiment_name\n                       )\n            wandb.config.update(args)\n</code></pre>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-21T03:21:34.006Z",
				"Answer_body": "<p>There\u2019s not a good way to adjust the randomly-generated name.</p>\n<p>The main workflows I have seen around names, besides just keeping the random name, are</p>\n<ol>\n<li>to rename runs with semantically-meaningful names later (<code>best-human-acc</code>, <code>that-one-weird-experiment</code>), or</li>\n<li>to name the runs with git hashes plus short random strings.</li>\n</ol>\n<p>If you want adjective-verb random names that you have control over (e.g. prepend/postpend), you might try the approach I\u2019ve used (<a href=\"https://github.com/wandb/lit_utils/blob/a9a5d9f0a6f7eef8001a280f5acc99c12b3d5959/utils.py#L25-L29\">code</a>) to generate nice names for runs <a href=\"http://wandb.me/yolo-chess\">using our YOLOv5 integration</a>.</p>\n<p>My instinct with the jobid info is to put it in the config, so that you can, e.g., find runs with it later, use it to filter run sets in reports.</p>\n<p>FYI, the <code>jobtype</code> is also useful for organizing your runs so that they can be grouped/filtered in the Project Workspace. This kind of grouping is separate from <code>group</code> info, and usually more ad hoc.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.362Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Structuring Code For Interruptible session",
		"Question_link": "https://community.wandb.ai/t/structuring-code-for-interruptible-session/697",
		"Question_created_time": "2021-09-18T13:43:52.591Z",
		"Question_answer_count": 2,
		"Question_score_count": 5,
		"Question_view_count": 359,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Looking to scale up my project to some cloud service, and it seems the prices are much cheaper for interruptible sessions.</p>\n<p>How do I use W&amp;B for an experiment (either a single train run or a HP sweep) in such an environment? Is there anything fancy needed to re-start a sweep where it left off?</p>\n<p>I\u2019m using Pytorch Lightning for the model/trainer and hoping to use AWS/Grid.ai/other cloud service to scale up.</p>\n<p>Thanks,<br>\nMax</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-18T20:49:55.589Z",
				"Answer_body": "<p>Hi Max!</p>\n<p>Here\u2019s some documentation on running wandb sweeps on preemptible instances.</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/guides/track/advanced/resuming#preemptible-sweeps\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/41cd209363aac9340aa990ad198a67c63ad5a47b.png\" class=\"site-icon\" width=\"256\" height=\"256\">\n\n      <a href=\"https://docs.wandb.ai/guides/track/advanced/resuming#preemptible-sweeps\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/guides/track/advanced/resuming#preemptible-sweeps\" target=\"_blank\" rel=\"noopener\">Resume Runs</a></h3>\n\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>I know I sent this on the PyTorch Lightning forum, but hopefully this\u2019ll help people who find this post.</p>\n<p>I\u2019d love to hear how you get on experimenting with this and PyTorch Lightning <img src=\"https://emoji.discourse-cdn.com/twitter/zap.png?v=10\" title=\":zap:\" class=\"emoji\" alt=\":zap:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.366Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How does one plot plots with error bars?",
		"Question_link": "https://community.wandb.ai/t/how-does-one-plot-plots-with-error-bars/651",
		"Question_created_time": "2021-09-16T18:10:46.597Z",
		"Question_answer_count": 2,
		"Question_score_count": 1,
		"Question_view_count": 714,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>How does one plot plots with error bars?</p>\n<p>I saw it was mentioned here: <a href=\"https://docs.wandb.ai/ref/app/features/custom-charts\">https://docs.wandb.ai/ref/app/features/custom-charts</a> but there aren\u2019t any concrete examples. What is a concrete example that is quick and simple to use?</p>\n<p>Btw, I am using custom steps\u2026 e.g. <a href=\"https://colab.research.google.com/drive/1uegSY1HRGlKfK-07Uuw-ZxPJsNA9BN_9?usp=sharing\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">Google Colab</a></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-17T17:53:13.013Z",
				"Answer_body": "<p><a href=\"https://docs.wandb.ai/guides/track/log/plots\">Our preset charts</a> don\u2019t include error bars, so to create a chart with error bars, you\u2019d need to write a custom Vega spec. You might be able <a href=\"https://docs.wandb.ai/ref/app/features/custom-charts/walkthrough\">to tweak our existing preset specs</a>.</p>\n<p>Here\u2019s an example of error bars from Vega:</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://vega.github.io/vega/examples/error-bars/\">\n  <header class=\"source\">\n      <img src=\"https://vega.github.io/favicon.ico\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https://vega.github.io/vega/examples/error-bars/\" target=\"_blank\" rel=\"noopener\">Vega</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:580/200;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/58ab69920d28c788bcb862f223d84c6c56fc6492.png\" class=\"thumbnail\" width=\"580\" height=\"200\"></div>\n\n<h3><a href=\"https://vega.github.io/vega/examples/error-bars/\" target=\"_blank\" rel=\"noopener\">Error Bars Example</a></h3>\n\n  <p>Vega - A Visualization Grammar. Vega is a visualization grammar, a declarative format for creating, saving, and sharing interactive visualization designs. With Vega, you can describe the visual appearance and interactive behavior of a visualization...</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.350Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Is wanbd giving me a multiprocessing error when my code is serially running?",
		"Question_link": "https://community.wandb.ai/t/is-wanbd-giving-me-a-multiprocessing-error-when-my-code-is-serially-running/655",
		"Question_created_time": "2021-09-16T21:34:45.267Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 712,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I have a multiprocessing error but my code is not multiprocessing (its running serially) - even the pytorch dataloader as <code>num_workers=0</code> but I get this error:</p>\n<pre><code class=\"lang-auto\">N/A% (0 of 100) |         | Elapsed Time: 0:00:00 | ETA:  --:--:-- |   0.0 s/itTraceback (most recent call last):\n  File \"/Users/brando/anaconda3/envs/metalearning/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n    self = reduction.pickle.load(from_parent)\n  File \"/Users/brando/anaconda3/envs/metalearning/lib/python3.9/multiprocessing/synchronize.py\", line 110, in __setstate__\n    self._semlock = _multiprocessing.SemLock._rebuild(*state)\nFileNotFoundError: [Errno 2] No such file or directory\npython-BaseException\nTraceback (most recent call last):\n  File \"/Users/brando/anaconda3/envs/metalearning/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n    self = reduction.pickle.load(from_parent)\n  File \"/Users/brando/anaconda3/envs/metalearning/lib/python3.9/multiprocessing/synchronize.py\", line 110, in __setstate__\n    self._semlock = _multiprocessing.SemLock._rebuild(*state)\nFileNotFoundError: [Errno 2] No such file or directory\npython-BaseException\n</code></pre>\n<p>How do I start debugging this?</p>\n<hr>\n<p>I am running this in pycharm. Not sure what else to say, will think about it\u2026</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-17T17:01:08.364Z",
				"Answer_body": "<p><a href=\"https://community.wandb.ai/t/how-often-to-log-to-avoid-slow-down-of-code/516/2\">W&amp;B does use multiprocessing</a> so it\u2019s possible there\u2019s an issue, but it\u2019s hard to be sure without more info.</p>\n<p>Do you have a larger stack trace or can you otherwise identify the place in your code that\u2019s triggering this?</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Previsualization of wandb.plot before logging it",
		"Question_link": "https://community.wandb.ai/t/previsualization-of-wandb-plot-before-logging-it/664",
		"Question_created_time": "2021-09-17T10:02:55.308Z",
		"Question_answer_count": 3,
		"Question_score_count": 2,
		"Question_view_count": 254,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>Is there any way to previsualize a wandb plot before logging it to the project?</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-17T12:20:24.657Z",
				"Answer_body": "<p>Hello! Welcome to the forums <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>\n<p>Is there any reason you would want to checkout the plots before logging them?</p>\n<p>An alternate could be logging them and then updating the same.</p>\n<p>Please let me know if this is helpful.<br>\nThanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-17T13:07:28.991Z",
				"Answer_body": "<p>thank you! well it\u2019s not really important, it\u2019s just a matter of speed, being able to check if the plot is ok in the same place where I create it is handy!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.194Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How does one have high disk utilization in pytorch?",
		"Question_link": "https://community.wandb.ai/t/how-does-one-have-high-disk-utilization-in-pytorch/553",
		"Question_created_time": "2021-09-13T23:18:34.171Z",
		"Question_answer_count": 2,
		"Question_score_count": 4,
		"Question_view_count": 285,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I saw that being mentioned here <a href=\"https://youtu.be/G7GH0SeNBMA?t=1141\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">\ud83d\udd25 Integrate Weights &amp; Biases with PyTorch - YouTube</a> so I was curious - how do we have the data loaders in pytorch to have high disk utilization e.g. is increasing the batch size, num_workers the way to go or something else?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-16T16:19:58.530Z",
				"Answer_body": "<p>So, the idea I had in mind when I said that was that there are three categories of time-consuming operations:</p>\n<ol>\n<li>Getting data off disk</li>\n<li>Running data/network logic in Python on CPU</li>\n<li>Running data/network operations in CUDA on GPU</li>\n</ol>\n<p>Roughly, the fraction of available resources used by these 3 categories is tracked by three system metrics in wandb: Disk Utilization, CPU Utilization, and GPU Utilization.</p>\n<p>Again roughly, you\u2019re squeezing every last drop of juice out of your hardware when all three of those are maximized. In every second, bits are being read from disk while the CPU is moving forward in the compute graph and the GPU is executing the operation, all at full capacity.</p>\n<p>This is probably not achievable for every problem, but that\u2019s what I had in mind when I was talking about the system metrics in that video.</p>\n<p>Looking back, I think parts 1+2 are less important than I did at the time. The real killer for GPU-accelerated tensor workloads like DNN training is that the GPU is sitting idle \u2013 it\u2019s waiting on a disk read or waiting on the <img src=\"https://emoji.discourse-cdn.com/twitter/sloth.png?v=10\" title=\":sloth:\" class=\"emoji\" alt=\":sloth:\"> Python layer. The optimizations to fix this aren\u2019t always <em>in</em> the GPU (maybe you need to write a faster file loading strategy, with cacheing or multiprocessing; maybe you need to move more logic out of pure Python and into your tensor library) but they tend to show up as low GPU Utilization.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.359Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Is the InvalidVersionSpec: Invalid version '1<2': invalid character(s) to wandb?",
		"Question_link": "https://community.wandb.ai/t/is-the-invalidversionspec-invalid-version-1-2-invalid-character-s-to-wandb/556",
		"Question_created_time": "2021-09-13T23:21:10.538Z",
		"Question_answer_count": 2,
		"Question_score_count": 1,
		"Question_view_count": 296,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I noticed that all my scripts that have wandb started to give this error:</p>\n<pre><code class=\"lang-auto\">InvalidVersionSpec: Invalid version '1&lt;2': invalid character(s)\n</code></pre>\n<p>and was wondering if this is something that others have experienced when incorporating wandb and how do you remove it?</p>\n<p>Thanks in advance! wandb is pretty cool <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-16T16:07:58.968Z",
				"Answer_body": "<p>Looking around, it seems like this is probably due to conda and pip stepping on each other\u2019s toes: <a href=\"https://stackoverflow.com/questions/60205992/conda-environment-export-to-yaml-file-fails\" class=\"inline-onebox\">Conda environment export to yaml file fails - Stack Overflow</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.346Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Molecule Visualizations",
		"Question_link": "https://community.wandb.ai/t/molecule-visualizations/413",
		"Question_created_time": "2021-09-02T22:48:55.192Z",
		"Question_answer_count": 3,
		"Question_score_count": 3,
		"Question_view_count": 274,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019ve been looking at the wandb.Molecule object and it looks awesome! I\u2019d like to use it for small molecules, but converting molecules to one of the specified file types is a bit of a pain point for me. Any chance of one day being able to create Molecule objects straight from a SMILES string?</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-13T16:55:23.420Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/rex-boyce\">@rex-boyce</a>! <img src=\"https://emoji.discourse-cdn.com/twitter/wave.png?v=10\" title=\":wave:\" class=\"emoji\" alt=\":wave:\"><br>\nWelcome to the forums!</p>\n<p>I\u2019m looking into this and will get a response from the team <img src=\"https://emoji.discourse-cdn.com/twitter/+1.png?v=10\" title=\":+1:\" class=\"emoji\" alt=\":+1:\"></p>\n<p>Meanwhile, please do introduce yourself in the <a class=\"hashtag\" href=\"/c/start-here/2\">#<span>start-here</span></a> thread if you\u2019d like <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-16T11:57:31.019Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"rex-boyce\" data-post=\"1\" data-topic=\"413\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/r/b782af/40.png\" class=\"avatar\"> rex-boyce:</div>\n<blockquote>\n<p>Any chance of one day being able to create Molecule objects straight from a SMILES string?</p>\n</blockquote>\n</aside>\n<p>Hi <img src=\"https://emoji.discourse-cdn.com/twitter/wave.png?v=10\" title=\":wave:\" class=\"emoji\" alt=\":wave:\"><br>\nCan you elaborate on your process, have you been able to convert from a SMILES string into a Molecule object?<br>\nHere are the supported filetypes at the moment:<br>\n<code>'pdb', 'pqr', 'mmcif', 'mcif', 'cif', 'sdf', 'sd', 'gro', 'mol2', 'mmtf'</code></p>\n<p>This website can convert from SMILES into some of the supported filetypes: <a href=\"https://cactus.nci.nih.gov/translate/\" class=\"inline-onebox\">Online SMILES Translator</a></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.865Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Couldn't make Wandb run on a TPU",
		"Question_link": "https://community.wandb.ai/t/couldnt-make-wandb-run-on-a-tpu/633",
		"Question_created_time": "2021-09-16T01:57:43.951Z",
		"Question_answer_count": 1,
		"Question_score_count": 0,
		"Question_view_count": 492,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I tried a lot of things but was not able to run Wandb on TPU.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/6ac7b539cf35cb8e5b4160099c1f51f226d94626.png\" data-download-href=\"/uploads/short-url/feCu0Sg0RhG0KlIVQ3CeQYH2Tlk.png?dl=1\" title=\"Screenshot from 2021-09-15 21-32-25\" rel=\"noopener nofollow ugc\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/6ac7b539cf35cb8e5b4160099c1f51f226d94626_2_472x500.png\" alt=\"Screenshot from 2021-09-15 21-32-25\" data-base62-sha1=\"feCu0Sg0RhG0KlIVQ3CeQYH2Tlk\" width=\"472\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/6ac7b539cf35cb8e5b4160099c1f51f226d94626_2_472x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/6ac7b539cf35cb8e5b4160099c1f51f226d94626_2_708x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/6ac7b539cf35cb8e5b4160099c1f51f226d94626.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/6ac7b539cf35cb8e5b4160099c1f51f226d94626_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"></use></svg><span class=\"filename\">Screenshot from 2021-09-15 21-32-25</span><span class=\"informations\">807\u00d7854 105 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p><a href=\"https://www.kaggle.com/harveenchadha/chaii-tpu-train-nfold-xlm-hf-tf-data-extra?scriptVersionId=74865075\" rel=\"noopener nofollow ugc\">Kernel</a></p>\n<p>If there is something wrong in my code structure please let me know <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"> . Have raised an issue on <a href=\"https://github.com/wandb/client/issues/2672\" rel=\"noopener nofollow ugc\">github</a>  as well.</p>\n<p>Cheers!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-16T07:31:30.602Z",
				"Answer_body": "<p>Thanks Harveen!</p>\n<p>The conversation is continued <a href=\"https://github.com/wandb/client/issues/2672\">Here</a></p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "What happens if the code crashes in the middle and there was no time to fo a .finish?",
		"Question_link": "https://community.wandb.ai/t/what-happens-if-the-code-crashes-in-the-middle-and-there-was-no-time-to-fo-a-finish/508",
		"Question_created_time": "2021-09-10T19:47:51.423Z",
		"Question_answer_count": 6,
		"Question_score_count": 9,
		"Question_view_count": 1738,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I use DDP a lot and was worried something bad might happen with wandb if my code crashes in the middle.</p>\n<p>What happens if the code crashes in the middle? Would there be further processing I need to do to make sure my computer, experiment, resources, account etc are ok?</p>\n<p>related: <a href=\"https://github.com/wandb/examples/issues/88\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">DDP example is not calling .finish in either log_all nor log with lead worker (rank0) \u00b7 Issue #88 \u00b7 wandb/examples \u00b7 GitHub</a></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-11T17:40:06.237Z",
				"Answer_body": "<p>As per my understanding, wandb runs in a seperate process altogether from training, so even if you training gets crashed due to some reason your wandb process will log this this as well on the dashboard.</p>\n<p>A wandb run can be in any one of the stages: running, finished, crashed.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-13T05:50:39.976Z",
				"Answer_body": "<p>In my experience, it\u2019s best to use a context manager such as <code>with()</code> or just define your <code>run</code> variable within a function and have the <code>run.finish()</code> within the function as well.</p>\n<p>For example,</p>\n<pre><code class=\"lang-auto\">def train_model(...):\n    run = wandb.init(....)\n    ....\n    run.finish()\n</code></pre>\n<hr>\n<p>Also, after a particular run crashes, wandb logs all the prior information anyways and you can always <strong><a href=\"https://docs.wandb.ai/guides/track/advanced/resuming\">resume</a></strong> the run.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-13T16:51:29.811Z",
				"Answer_body": "<p>what is the pro vs cons of doing <code>wandb.run</code> and <code>wandb.finish</code> instead of creating a run object?</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-13T17:44:24.451Z",
				"Answer_body": "<p><code>wandb.run</code> and  <code>wandb.finish</code> refer to global state \u2013 the \"current <code>wandb.Run</code>\". This can be confusing and can introduce long-range dependencies in your code, especially when you\u2019re also doing multiprocessing of your own, e.g. DDP.</p>\n<p>So I prefer to be more explicit and to use actual <code>wandb.Run</code> objects, just as I prefer to use actual <code>Figure</code>s and <code>Axes</code> in <code>matplotlib</code>, as opposed to relying on the <code>.gcf</code>/<code>.gca</code> magic.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-13T17:48:47.821Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"sauravmaheshkar\" data-post=\"3\" data-topic=\"508\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https://sea2.discourse-cdn.com/business7/user_avatar/community.wandb.ai/sauravmaheshkar/40/50_2.png\" class=\"avatar\"> sauravmaheshkar:</div>\n<blockquote>\n<p>Also, after a particular run crashes, wandb logs all the prior information anyways and you can always <strong><a href=\"https://docs.wandb.ai/guides/track/advanced/resuming\">resume</a></strong> the run.</p>\n</blockquote>\n</aside>\n<p>Yep, this is the solution if the right way to resolve the crash is to restart the experiment and keep going. But note that you\u2019ll need to be able to restore the state of your model + training setup, which can be tricky.</p>\n<p>You can also just sync the log information, without restarting a run, with <a href=\"https://gitbook-docs.wandb.ai/ref/cli/wandb-sync\"><code>wandb sync</code></a>. This is useful in the case that the <code>wandb</code> backend process doesn\u2019t finish syncing before it is killed, e.g. by the OS, by another Ctrl+C.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:07.365Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "When is one supposed to run wandb.watch so that weights and biases tracks params and gradients?",
		"Question_link": "https://community.wandb.ai/t/when-is-one-supposed-to-run-wandb-watch-so-that-weights-and-biases-tracks-params-and-gradients/518",
		"Question_created_time": "2021-09-11T17:29:44.170Z",
		"Question_answer_count": 3,
		"Question_score_count": 3,
		"Question_view_count": 964,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I run <code>wandb.watch</code> before my training script starts but that doesn\u2019t seem to track the histograms of weights and gradients. The script I have is nothing too complicated - just generating random data and fitting it after applying a quadratic:</p>\n<p>code in github: <a href=\"https://github.com/brando90/ultimate-utils/blob/master/tutorials_for_myself/my_wandb/my_wandb_basic1.py\" class=\"inline-onebox\" rel=\"noopener nofollow ugc\">ultimate-utils/my_wandb_basic1.py at master \u00b7 brando90/ultimate-utils \u00b7 GitHub</a></p>\n<p>sample run: <a href=\"https://wandb.ai/brando/playground/runs/wpupxvg1\" class=\"inline-onebox\">Weights &amp; Biases</a></p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-13T16:57:09.660Z",
				"Answer_body": "<p>Thanks for sharing!<br>\nLet me dig into the code and get back with an answer <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-13T17:20:49.337Z",
				"Answer_body": "<p>There are two things you might be running into here \u2013 can\u2019t confirm because your code relies on the <code>ultimate-utils</code> package.</p>\n<ol>\n<li>\n<code>wandb.watch</code> will only start working once you call <code>wandb.log</code> <em>after</em> a backwards pass that touches the watched <code>Module</code> (<a href=\"https://docs.wandb.ai/guides/integrations/pytorch#logging-gradients-with-wandb-watch\">docs</a>).</li>\n<li>The frequency with which gradients/params are logged is controlled by the <code>log_freq</code> argument. If the number of logging calls is less than the value of <code>log_freq</code>, then no information will be logged. Here\u2019s <a href=\"https://colab.research.google.com/drive/1ZnzV9NqOdMiBCKXGipkguqTn5UvN2aSg?usp=sharing\">a short colab</a> reproducing this behavior.</li>\n</ol>\n<p>Also, if you want params and gradients, you need to set the <code>log</code> kwarg to <code>\"all\"</code>. By default, we log only gradients.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.019Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "What are the recommended practices on how to use DDP with wandb?",
		"Question_link": "https://community.wandb.ai/t/what-are-the-recommended-practices-on-how-to-use-ddp-with-wandb/502",
		"Question_created_time": "2021-09-10T16:03:44.937Z",
		"Question_answer_count": 2,
		"Question_score_count": 2,
		"Question_view_count": 373,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I often use distributed data laoders in pytorch DDP and often just check the rank and have only rank 0 log. Is that the recommended way to use DDP and wandb?</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-13T17:17:20.017Z",
				"Answer_body": "<p><a href=\"https://docs.wandb.ai/guides/track/advanced/distributed-training#logging-distributed-training-experiments-with-w-and-b\">Here</a> is link to the docs sharing the relevant suggestions. Please let me know incase you have any follow up Qs <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.406Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Separating Training From Testing",
		"Question_link": "https://community.wandb.ai/t/separating-training-from-testing/353",
		"Question_created_time": "2021-08-30T11:19:16.926Z",
		"Question_answer_count": 2,
		"Question_score_count": 0,
		"Question_view_count": 317,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi!</p>\n<p>I\u2019ve got a sort of lopsided ML workflow where most of my time is spent producing plots and metrics, and my set of trained models is rarely updated. Is there a good way to separate my training code from all of my evaluation scripts?</p>\n<p>I\u2019d like my experiments to have the logging information from when the model was trained, but not to have to retrain it every time.</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-13T17:09:23.238Z",
				"Answer_body": "<p>Hey Marcel!</p>\n<p>I\u2019m not sure if you\u2019re asking generic feedback on this. Usually structuring code separately into similar models for training and evaluation and logging information accordingly is the best approach for this.</p>\n<p>Please let me know if you have any specific Qs around this <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.344Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How often to log to avoid slow down of code?",
		"Question_link": "https://community.wandb.ai/t/how-often-to-log-to-avoid-slow-down-of-code/516",
		"Question_created_time": "2021-09-11T17:15:14.205Z",
		"Question_answer_count": 2,
		"Question_score_count": 4,
		"Question_view_count": 1442,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Just curious, do ppl sync artifacts with wandb\u2019s cloud stuff every time they log or less often? I was curious to know if calling <code>wandb.log</code> or logging artifacts was slow or does it use a different process and thus slow down is minimum? \u2026 (in the past I discovered that the slowest part of my code was model checkpointing)</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-13T17:04:18.370Z",
				"Answer_body": "<p>The hard work of <code>wandb.log</code> runs in a different process, so that it doesn\u2019t always slow down your code.</p>\n<p>The rough guideline we give in our <a href=\"https://docs.wandb.ai/guides/technical-faq\">Technical FAQ</a> is that you shouldn\u2019t see a performance impact if you are <a href=\"https://docs.wandb.ai/guides/technical-faq#will-wandb-slow-down-my-training\">\u201clogging less than once a second and logging less than a few megabytes of data at each step\u201d</a>. That Technical FAQ has lots more useful information about the technical details of <code>wandb</code> logging.</p>\n<p>Two caveats on avoiding slowdown:</p>\n<ol>\n<li>If you\u2019re writing to disk (e.g. with <a href=\"https://pytorch.org/tutorials/beginner/saving_loading_models.html\"><code>torch.save</code></a>) as part of your checkpointing, that might slow your training down, even though the W&amp;B logging component of checkpointing does not. If that\u2019s a bottleneck, you could handle writing the model to disk in a separate process.</li>\n<li>\n<code>wandb.log</code> runs in a separate process, but that process needs to finish before the process that created it, the process where you called <code>wandb.init</code>, can finish.  So if you\u2019ve called <code>wandb.log</code> on a large amount of data during training, when your training run finishes, it could take some time for the information to be fully uploaded. You can avoid this with <a href=\"https://docs.wandb.ai/guides/technical-faq#can-i-run-wandb-offline\"><code>WANDB_MODE=offline</code></a>, which only saves information locally \u2013 synchronization with the cloud service is then done separately (e.g. manually or via cron job).</li>\n</ol>\n<p>FYI, we also have <a href=\"http://wandb.me/log-hf-colab\">a short colab</a> about ways to reduce the weight of high-frequency logging for metric data using downsampling, summary statistics, and histograms.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.339Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Is there a way to aggregate/transform logged metrics in the UI?",
		"Question_link": "https://community.wandb.ai/t/is-there-a-way-to-aggregate-transform-logged-metrics-in-the-ui/488",
		"Question_created_time": "2021-09-10T04:27:41.175Z",
		"Question_answer_count": 4,
		"Question_score_count": 5,
		"Question_view_count": 299,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>For example, if I logged the F1 of various classes, and I want to average them into a single plot</p>\n<p>Or, on a related note, how to average metrics from only certain runs (that have already been logged independently)</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-10T08:27:40.517Z",
				"Answer_body": "<p>Hello! <a class=\"mention\" href=\"/u/divadi\">@divadi</a></p>\n<p>Thanks for the great question and first of all welcome to our forum! <img src=\"https://emoji.discourse-cdn.com/twitter/smiley.png?v=10\" title=\":smiley:\" class=\"emoji\" alt=\":smiley:\"></p>\n<p>Please also feel free to say hello &amp; tell us about your journey in the <a class=\"hashtag\" href=\"/c/start-here/2\">#<span>start-here</span></a> category (It\u2019s a hyper link, clicking on start-here should take you to it <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"> )</p>\n<p>To answer your question, here\u2019s a way showcased in our docs.</p>\n<p><a href=\"https://docs.wandb.ai/ref/app/features/panels/line-plot#visualize-average-values-on-a-plot\">Visualising average values on a plot</a>.</p>\n<p>You can use the Grouping feature in the table. Click \u201cGroup\u201d above the run table and select \u201cAll\u201d to show averaged values in your graphs.</p>\n<p>Please let me know if this solves it.</p>\n<p>PS: Thanks to <a class=\"mention\" href=\"/u/_scott\">@_scott</a> for helping me figure this out ASAP <img src=\"https://emoji.discourse-cdn.com/twitter/tea.png?v=10\" title=\":tea:\" class=\"emoji\" alt=\":tea:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-10T08:52:42.633Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"divadi\" data-post=\"1\" data-topic=\"488\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/d/53a042/40.png\" class=\"avatar\"> divadi:</div>\n<blockquote>\n<p>Or, on a related note, how to average metrics from only certain runs (that have already been logged independently)</p>\n</blockquote>\n</aside>\n<p>As for averaging metrics from only certain runs, if you just want to see these results once, you could quickly create a plot as <a class=\"mention\" href=\"/u/bhutanisanyam1\">@bhutanisanyam1</a> showed and you could select only the runs you want and the UI will update with their average.</p>\n<p>You could also use Group runs and see the averages per group.</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://docs.wandb.ai/guides/track/advanced/grouping\">\n  <header class=\"source\">\n      <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/41cd209363aac9340aa990ad198a67c63ad5a47b.png\" class=\"site-icon\" width=\"256\" height=\"256\">\n\n      <a href=\"https://docs.wandb.ai/guides/track/advanced/grouping\" target=\"_blank\" rel=\"noopener\">docs.wandb.ai</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_690x362.png\" class=\"thumbnail\" width=\"690\" height=\"362\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_690x362.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_1035x543.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/75ad225cd4a0f29cec0e6dd7859f017ee0df3c7a_2_10x10.png\"></div>\n\n<h3><a href=\"https://docs.wandb.ai/guides/track/advanced/grouping\" target=\"_blank\" rel=\"noopener\">Group Runs</a></h3>\n\n  <p>Group training and evaluation runs into larger experiments</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>Hope this answers your question, let me know if it doesn\u2019t <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-12T19:23:48.462Z",
				"Answer_body": "<p>Thank you for the responses</p>\n<p>I mean, for a single run, I have logged the average precision of different classes. I hope to take the average precision over all these classes and visualize it as a single graph (for a single run)</p>\n<p>I apologize if I misunderstood your answer, but how might I do this?</p>\n<p>Edit: <img src=\"https://emoji.discourse-cdn.com/twitter/man_facepalming.png?v=10\" title=\":man_facepalming:\" class=\"emoji\" alt=\":man_facepalming:\"> I see grouping also works for metrics, I got it, thank you!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.968Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Wanb.watch(model) causing CUDA OOM",
		"Question_link": "https://community.wandb.ai/t/wanb-watch-model-causing-cuda-oom/499",
		"Question_created_time": "2021-09-10T15:20:05.142Z",
		"Question_answer_count": 5,
		"Question_score_count": 3,
		"Question_view_count": 702,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am trying to use wandb gradient visualization to debug the gradient flow in my neural net on Google Colab. Without wandb logging, the training runs without error, taking up 11Gb/16GB on the p100 gpu. However, adding this line <code>wandb.watch(model, log='all', log_freq=3)</code> causes a cuda out of memory error. How does wandb logging create extra gpu memory overhead? Is there some way to reduce the overhead? Thank you for your help.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-10T20:21:45.773Z",
				"Answer_body": "<p>Hello and welcome to the forums <a class=\"mention\" href=\"/u/ambrose\">@ambrose</a>! <img src=\"https://emoji.discourse-cdn.com/twitter/wave.png?v=10\" title=\":wave:\" class=\"emoji\" alt=\":wave:\"></p>\n<p>Please do introduce yourself in the <a class=\"hashtag\" href=\"/c/start-here/2\">#<span>start-here</span></a> category if you\u2019d like to!</p>\n<p>Please allow me to replicate this issue, and ask the team for help.<br>\nI\u2019ll get back once I\u2019m able to replicate the issue, Thanks for the Q! <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-11T00:52:29.061Z",
				"Answer_body": "<p>Hi <a class=\"mention\" href=\"/u/bhutanisanyam1\">@bhutanisanyam1</a>,</p>\n<p>Thank you for your reply and welcome! I am quite excited to use WandB and join the community.</p>\n<p>Ambrose</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-11T19:32:36.707Z",
				"Answer_body": "<p>Hmm I think WandB is creating extra copies of the gradients during the logging. In case it helps, here is the error traceback:</p>\n<pre><code class=\"lang-auto\">---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n&lt;ipython-input-11-13de83557b55&gt; in &lt;module&gt;()\n     60         get_ipython().system(\"nvidia-smi | grep MiB | awk '{print $9 $10 $11}'\")\n     61 \n---&gt; 62         loss.backward()\n     63 \n     64         print('check 10')\n\n4 frames\n/usr/local/lib/python3.7/dist-packages/torch/_tensor.py in backward(self, gradient, retain_graph, create_graph, inputs)\n    253                 create_graph=create_graph,\n    254                 inputs=inputs)\n--&gt; 255         torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n    256 \n    257     def register_hook(self, hook):\n\n/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\n    147     Variable._execution_engine.run_backward(\n    148         tensors, grad_tensors_, retain_graph, create_graph, inputs,\n--&gt; 149         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n    150 \n    151 \n\n/usr/local/lib/python3.7/dist-packages/wandb/wandb_torch.py in &lt;lambda&gt;(grad)\n    283             self.log_tensor_stats(grad.data, name)\n    284 \n--&gt; 285         handle = var.register_hook(lambda grad: _callback(grad, log_track))\n    286         self._hook_handles[name] = handle\n    287         return handle\n\n/usr/local/lib/python3.7/dist-packages/wandb/wandb_torch.py in _callback(grad, log_track)\n    281             if not log_track_update(log_track):\n    282                 return\n--&gt; 283             self.log_tensor_stats(grad.data, name)\n    284 \n    285         handle = var.register_hook(lambda grad: _callback(grad, log_track))\n\n/usr/local/lib/python3.7/dist-packages/wandb/wandb_torch.py in log_tensor_stats(self, tensor, name)\n    219         # Remove nans from tensor. There's no good way to represent that in histograms.\n    220         flat = flat[~torch.isnan(flat)]\n--&gt; 221         flat = flat[~torch.isinf(flat)]\n    222         if flat.shape == torch.Size([0]):\n    223             # Often the whole tensor is nan or inf. Just don't log it in that case.\n\nRuntimeError: CUDA out of memory. Tried to allocate 4.65 GiB (GPU 0; 15.90 GiB total capacity; 10.10 GiB already allocated; 717.75 MiB free; 14.27 GiB reserved in total by PyTorch)\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-11T20:00:25.419Z",
				"Answer_body": "<p>Indeed, commenting out the offending line <code>flat = flat[~torch.isinf(flat)]</code> gets the WandB log step to just barely fit into the GPU memory. This is not a great solution though.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:07.124Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to use tensorboard and wandb?",
		"Question_link": "https://community.wandb.ai/t/how-to-use-tensorboard-and-wandb/501",
		"Question_created_time": "2021-09-10T15:48:02.476Z",
		"Question_answer_count": 2,
		"Question_score_count": 4,
		"Question_view_count": 339,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I\u2019ve used tensorboard in the past but I am wondering if I really even need it anymore\u2026so my questions are:</p>\n<ol>\n<li>can I do everything in wandb?</li>\n<li>when is tensorboard useful or a good complement</li>\n<li>how do people use both if at all in general?</li>\n</ol>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-11T17:06:49.653Z",
				"Answer_body": "<p>I have used both Tensorboard and wandb. When I was using tensorboard, I was very reluctant to use wandb but once I got the hang of it, I never used Tensorboard again.</p>\n<p>Wandb is far more superior to tensorboard in terms of experiment tracking and managing logs.</p>\n<ol>\n<li>Yes almost everything plus 100 new things</li>\n<li>Tensorflow is useful when you want to control your logs in local and the same can be done with wandb local (which I just got to know few days back)</li>\n<li>Answered already. Tensorboard is dead to me.</li>\n</ol>\n<p>Thanks!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.356Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Clarity on wandb offline",
		"Question_link": "https://community.wandb.ai/t/clarity-on-wandb-offline/429",
		"Question_created_time": "2021-09-05T08:09:48.916Z",
		"Question_answer_count": 3,
		"Question_score_count": 5,
		"Question_view_count": 365,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi,</p>\n<p>I was using wandb offline on kaggle. During submission time Internet has to be disabled I noticed that even if you mention the wandb key in secrets, it won\u2019t be able to fetch it because</p>\n<pre><code class=\"lang-auto\">user_secrets = UserSecretsClient()\nwandb_api = user_secrets.get_secret(\"wandb_api\")\n\n</code></pre>\n<p>user_secrets.get_secret requires an active internet connection.</p>\n<p>It took me some time to find out that we can specify a dummy key like this to login in offline mode:</p>\n<pre><code class=\"lang-auto\">key='X'*40\nwandb.login(key=key)\n\n</code></pre>\n<p>If my understanding is correct, Can we please update the same information on wandb offline documentation page with a subsection on kaggle?</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-06T15:53:58.228Z",
				"Answer_body": "<p>Hey, you are correct that Kaggle User Secrets cannot be used when the internet is turned off. I tried it myself and running a cell with the code snippet shown below throw the<code> ConnectionError: Connection error trying to communicate with service</code> error.</p>\n<p>I don\u2019t think you need to log in to use W&amp;B offline. The whole idea of using offline mode is to write metrics easily on a disk which can later be synced online with a single command line.</p>\n<p>Over Kaggle, if you have turned off the internet (submission kernel) you simply need to do these steps:</p>\n<pre><code class=\"lang-auto\">import wandb\nprint(wandb.__version__)\n&gt;&gt;&gt; 0.10.33 # Note that the Kaggle W&amp;B version is always few versions old but we can't pip install. \n\n!wandb offline\n&gt;&gt;&gt; W&amp;B offline, running your script from this directory will only write metadata locally.\n\n# Example logging\nwandb.init()\nfor i in range(10):\n    wandb.log({\"i\": i})\nwandb.finish()\n\n&gt;&gt;&gt; wandb sync /kaggle/working/wandb/offline-run-20210906_152752-3mkpi45e # You get the path to the directory where the run is saved. \n</code></pre>\n<p>I made this <a href=\"https://www.kaggle.com/ayuraj/testing-w-b-offline-flow\" rel=\"noopener nofollow ugc\">kernel</a> to show the flow. Let me know if it\u2019s what you are trying to do.</p>\n<p>I have a question from you - Why do you want to use W&amp;B with the submission kernel? Would love to know your thoughts.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-06T17:04:42.680Z",
				"Answer_body": "<p>Thanks for the notebook. 2 kernels are good but that\u2019s not always the case. <img src=\"https://emoji.discourse-cdn.com/twitter/smiley.png?v=10\" title=\":smiley:\" class=\"emoji\" alt=\":smiley:\"></p>\n<p>Sometimes when I create a baseline, I tend to create a single kernel to keep it simple just like <a href=\"https://www.kaggle.com/harveenchadha/chaii-muril-hf-keras-wb\" rel=\"noopener nofollow ugc\">here</a>. If you  edit, you will be able to see the below code I used to setup wandb.</p>\n<pre><code class=\"lang-auto\">#Intialize wandb run\n\nif config['use_wandb']:\n    import wandb\n    from wandb.keras import WandbCallback\n    from kaggle_secrets import UserSecretsClient\n    \n\n    if config['wandb_mode'] == 'offline':\n        os.environ[\"WANDB_MODE\"] = \"offline\"\n        key='X'*40\n        wandb.login(key=key)\n    else:\n        user_secrets = UserSecretsClient()\n        wandb_api = user_secrets.get_secret(\"wandb_api\")\n        wandb.login(key=wandb_api)\n\n    run = wandb.init(project='chaii', \n                     group =config['group'], \n                     job_type='train',\n                     config = config)\n\n    LOGGER.info(\"Wandb is initialized\")\n</code></pre>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.900Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Early Stopping",
		"Question_link": "https://community.wandb.ai/t/early-stopping/422",
		"Question_created_time": "2021-09-03T21:39:56.042Z",
		"Question_answer_count": 7,
		"Question_score_count": 13,
		"Question_view_count": 1720,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hello All,</p>\n<p>I\u2019m configuring a hyper parameter sweep. I have training, validation, and test set.</p>\n<p>I\u2019d like to use the test_loss as the final metric to optimize and val_loss for early stopping.</p>\n<p>I don\u2019t see a place to specify a metric for early stopping. Does it default to the same metric specified for overall optimization (of hyper parameters)? If so, how can I change this?</p>\n<p>Thanks!</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-04T10:00:58.565Z",
				"Answer_body": "<p>It isn\u2019t possible to have a different metric for hyperband early stopping and search strategy. <a href=\"https://github.com/wandb/sweeps/blob/master/hyperband_stopping.py#L176\">https://github.com/wandb/sweeps/blob/master/hyperband_stopping.py#L176</a></p>\n<p>One workaround would be to use a search strategy that doesn\u2019t require a metric like <code>random</code> or <code>grid</code> and then use <code>val_loss</code> as your metric for early stopping. You can then easily reconfigure the resulting parameter importance and parallel coordinate plots to show <code>test_loss</code> in your dashboard.</p>\n<p>If you would would like this feature, you can file a feature request on our client repo issues.</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://github.com/wandb/client\">\n  <header class=\"source\">\n      <img src=\"https://github.githubassets.com/favicons/favicon.svg\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https://github.com/wandb/client\" target=\"_blank\" rel=\"noopener\">GitHub</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/345;\"><img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f17a1f5cd507f0b9925c2434a26722ca80471a98_2_690x345.png\" class=\"thumbnail\" width=\"690\" height=\"345\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f17a1f5cd507f0b9925c2434a26722ca80471a98_2_690x345.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f17a1f5cd507f0b9925c2434a26722ca80471a98_2_1035x517.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/original/1X/f17a1f5cd507f0b9925c2434a26722ca80471a98.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/f17a1f5cd507f0b9925c2434a26722ca80471a98_2_10x10.png\"></div>\n\n<h3><a href=\"https://github.com/wandb/client\" target=\"_blank\" rel=\"noopener\">GitHub - wandb/client: \ud83d\udd25 A tool for visualizing and tracking your machine...</a></h3>\n\n  <p>\ud83d\udd25 A tool for visualizing and tracking your machine learning experiments. This repo contains the CLI and Python API. - GitHub - wandb/client: \ud83d\udd25 A tool for visualizing and tracking your machine learn...</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-05T01:21:46.052Z",
				"Answer_body": "<p>Welcome to the forum, <a class=\"mention\" href=\"/u/max_wasserman\">@max_wasserman</a>! Great first question.</p>\n<p>While I can see why it might be good for us to add the ability to separate the early-stopping metric from the Bayesian optimization metric, <strong>I would strongly caution against using the test loss in any step of the process</strong> \u2013 whether its the optimization of parameters (obviously a  no-no!) or the optimization of hyperparameters. The PyTorch Lightning docs even say that you should only call <code>.test</code> <a href=\"https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#testing\">\u201c[o]nly right before publishing your paper or pushing to production\u201d</a>.</p>\n<p>The purpose of metrics measured on the test set is to reflect, as veridically as possible, the performance of the model on more data drawn from the same distribution, which we in turn hope reflects the performance of the model on data in production. Selecting hyperparameters based on the test set breaks the \u201cinformation wall\u201d (more technically, the conditional independence relation) between the test data and the model\u2019s parameters that make the test set useful for getting unbiased estimates of true generalization performance.</p>\n<p>There is at least some indication that the use of fixed validation and test sets has led the ML field as a whole to \u201coverfit\u201d, in the sense of over-estimation of true generalization performance:</p><aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"https://arxiv.org/abs/1806.00451\">\n  <header class=\"source\">\n      <img src=\"https://static.arxiv.org/static/browse/0.3.2.8/images/icons/favicon.ico\" class=\"site-icon\" width=\"32\" height=\"32\">\n\n      <a href=\"https://arxiv.org/abs/1806.00451\" target=\"_blank\" rel=\"noopener\">arXiv.org</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    <img src=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/c677c3b1d6c1743743356c807ff179c64f4f4f48_2_500x500.png\" class=\"thumbnail onebox-avatar\" width=\"500\" height=\"500\" srcset=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/c677c3b1d6c1743743356c807ff179c64f4f4f48_2_500x500.png, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/c677c3b1d6c1743743356c807ff179c64f4f4f48_2_750x750.png 1.5x, https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/c677c3b1d6c1743743356c807ff179c64f4f4f48_2_1000x1000.png 2x\" data-small-upload=\"https://global.discourse-cdn.com/business7/uploads/wandb/optimized/1X/c677c3b1d6c1743743356c807ff179c64f4f4f48_2_10x10.png\">\n\n<h3><a href=\"https://arxiv.org/abs/1806.00451\" target=\"_blank\" rel=\"noopener\">Do CIFAR-10 Classifiers Generalize to CIFAR-10?</a></h3>\n\n  <p>Machine learning is currently dominated by largely experimental work focused\non improvements in a few key tasks. However, the impressive accuracy numbers of\nthe best performing models are questionable because the same test sets have\nbeen used to...</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n<aside class=\"onebox allowlistedgeneric\" data-onebox-src=\"http://proceedings.mlr.press/v97/recht19a.html\">\n  <header class=\"source\">\n      <img src=\"https://proceedings.mlr.press/v97/assets/images/favicon-pmlr.ico\" class=\"site-icon\" width=\"48\" height=\"48\">\n\n      <a href=\"http://proceedings.mlr.press/v97/recht19a.html\" target=\"_blank\" rel=\"noopener\" title=\"12:00AM - 24 May 2019\">PMLR \u2013 24 May 19</a>\n  </header>\n\n  <article class=\"onebox-body\">\n    \n\n<h3><a href=\"http://proceedings.mlr.press/v97/recht19a.html\" target=\"_blank\" rel=\"noopener\">Do ImageNet Classifiers Generalize to ImageNet?</a></h3>\n\n  <p>We build new test sets for the CIFAR-10 and ImageNet datasets. Both benchmarks have been the focus of intense research for almost a decade, raising the danger of overfitting to excessively re-used ...</p>\n\n\n  </article>\n\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n\n  <div style=\"clear: both\"></div>\n</aside>\n",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-05T19:17:08.278Z",
				"Answer_body": "<aside class=\"quote group-team\" data-username=\"charlesfrye\" data-post=\"3\" data-topic=\"422\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https://sea2.discourse-cdn.com/business7/user_avatar/community.wandb.ai/charlesfrye/40/52_2.png\" class=\"avatar\"> charlesfrye:</div>\n<blockquote>\n<p>electing hyperparameters based on the test set breaks the \u201cinformation wall\u201d (more technically, the conditional independence relation) betw</p>\n</blockquote>\n</aside>\n<p>Thanks so much for the responses.</p>\n<p>In this case I am using synthetic data (I can generate a lot it cheaply). I used the names val/test_loss instead of validation set 1 (for early stopping) and validation set 2 (for bayes optimization) for simplicity.  I will generate more data after this (my true test set) for final unbiased estimation of generalization.</p>\n<p>It seems the best solution at the moment is to simply do what <a class=\"mention\" href=\"/u/_scott\">@_scott</a> recommended: use a random search and log \u2018test_loss\u2019 (actually validation set 2) for viz later.</p>\n<p>PS is this the preferred location/forum where I should post technical questions of this kind? The GitHub page refers to a slack group that appears to be closed.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-05T19:34:38.217Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"max_wasserman\" data-post=\"4\" data-topic=\"422\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/m/7bcc69/40.png\" class=\"avatar\"> max_wasserman:</div>\n<blockquote>\n<p>PS is this the preferred location/forum where I should post technical questions of this kind? The GitHub page refers to a slack group that appears to be closed.</p>\n</blockquote>\n</aside>\n<p>Yes, this is the place, Thanks for checking!</p>\n<p>We really want to make sure our community enjoys the forums so we\u2019re silently moving from slack to discourse and we\u2019ll be making the announcement soon once we\u2019re confident the forums are all setup <img src=\"https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=10\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-05T19:54:39.788Z",
				"Answer_body": "<aside class=\"quote no-group\" data-username=\"max_wasserman\" data-post=\"4\" data-topic=\"422\">\n<div class=\"title\">\n<div class=\"quote-controls\"></div>\n<img alt=\"\" width=\"20\" height=\"20\" src=\"https://avatars.discourse-cdn.com/v4/letter/m/7bcc69/40.png\" class=\"avatar\"> max_wasserman:</div>\n<blockquote>\n<p>I will generate more data after this (my true test set) for final unbiased estimation of generalization.</p>\n</blockquote>\n</aside>\n<p>Ah okay, if you\u2019ve got an actual unbiased test set, then you\u2019re golden. I\u2019d be interested to hear more about your project!</p>\n<p>And yes, as <a class=\"mention\" href=\"/u/_scott\">@_scott</a> points out, if you aren\u2019t using Bayesian optimization, the choice of <code>metric</code> won\u2019t impact the behavior of your search. <code>random</code> is actually a pretty good choice for HPO, competitive with <code>bayes</code> in my and others\u2019 experience \u2013 and less prone to error/misconfiguration. Also BTW, <a href=\"https://docs.wandb.ai/guides/sweeps/configuration#early_terminate\">the <code>early_terminate</code> feature uses HyperBand</a>, which is more aggressive than the usual early stopping folks learn about in an ML class, based on stopping training when you see increasing validation set error. That style of early stopping is best delegated to the ML framework you\u2019re using.</p>\n<p>Thanks for pointing out the issue with the Slack link. As <a class=\"mention\" href=\"/u/bhutanisanyam1\">@bhutanisanyam1</a> said, we are moving discussion to this forum, but that link should\u2019ve still been in operation anyway. Will fix it shortly.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-05T23:48:41.384Z",
				"Answer_body": "<p>I\u2019m doing some graph learning work (inputs are graphs, labels are graphs). Submitting paper soon, so I\u2019ll post it to one of these forums after!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:07.313Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "View-only report will still expose whole project",
		"Question_link": "https://community.wandb.ai/t/view-only-report-will-still-expose-whole-project/387",
		"Question_created_time": "2021-09-01T13:49:16.357Z",
		"Question_answer_count": 4,
		"Question_score_count": 6,
		"Question_view_count": 360,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I add a report to a private project named \u201csomething\u201d and create a view-only link to this report. By clicking on the link, you can see a report. This is expected. However, by clicking the project name displayed in the navigator, you will see all information about the project, even some runs that are not expected to expose.</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-09-02T16:48:23.508Z",
				"Answer_body": "<p>Thanks for reporting this! We are investigating.</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-02T17:52:57.664Z",
				"Answer_body": "<p>Thank you for reporting this! The bug is now fixed. Let <a class=\"mention\" href=\"/u/laxels\">@laxels</a> and I know if you have any more questions!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:01:40.066Z",
				"Answer_body": "<p>Thank you for reporting this! The bug is now fixed. Let <a class=\"mention\" href=\"/u/laxels\">@laxels</a> and I know if you have any more questions!</p>\n<p>[Discourse post]</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:06.131Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "Use W&B in a Jupyter notebook to load a dataset",
		"Question_link": "https://community.wandb.ai/t/use-w-b-in-a-jupyter-notebook-to-load-a-dataset/358",
		"Question_created_time": "2021-08-30T14:33:42.499Z",
		"Question_answer_count": 4,
		"Question_score_count": 6,
		"Question_view_count": 375,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>Hi all,</p>\n<p>after a few years working in the field and suggesting people to try W&amp;B, I\u2019m excited to finally get to use it myself <img src=\"https://emoji.discourse-cdn.com/twitter/grinning.png?v=12\" title=\":grinning:\" class=\"emoji\" alt=\":grinning:\" loading=\"lazy\" width=\"20\" height=\"20\"></p>\n<p>As part of a remote team, I\u2019m doing an EDA (Exploratory Data Analysis) in Jupyter. We\u2019re storing the dataset as a W&amp;B artifact, and I need my notebook to download the dataset locally,  so I wrote something like:</p>\n<pre><code class=\"lang-python\">import wandb\n\nartifact_file = \"my_entity/my_project/my_dataset:v0\"\ndata_dir = Path('.').parent / 'data'\n\n# Download data from W&amp;B\ndata = wandb.use_artifact(artifact_file)\ndata.download(root=data_dir)\n</code></pre>\n<p>However,  when I run the cells I get the error:</p>\n<p><code>Error: You must call wandb.init() before wandb.use_artifact()</code></p>\n<p>Two questions:</p>\n<ol>\n<li>how do I fix this? Would something like this suffice?</li>\n</ol>\n<pre><code class=\"lang-python\">run = wandb.init(\n        reinit=True,\n        project=\"my_project\",\n        entity=\"my_entity\",\n        group=\"eda\",\n    )\n\n# Download data from W&amp;B\ndata = wandb.use_artifact(artifact_file)\ndata.download(root=data_dir)\n</code></pre>\n<ol start=\"2\">\n<li>Since I called <code>wandb.init()</code>, I guess I should call  <code>run.finish()</code>at the end of my EDA, otherwise the background process will run forever (or more realistically until some timeout). Now, in the usual training script, where all the code has been written and debugged before I launch the <code>wandb</code> background process, this would be easy: I would just add the <code>run.finish()</code> line at the end of the script. Here however I edit and add code while I continue with the analysis (it\u2019s Jupyter). So what\u2019s the best practice? Do I just go on with my analysis and add a <code>run.finish()</code> line in the last cell? Or do I call <code>run.finish()</code> immediately after downloading the data to the <code>data_dir</code>? In other words, I know the standard workflow for using W&amp;B logger and artifacts in non-interactive mode (Python scripts), but I\u2019m not so familiar with the W&amp;B workflow for interactive analyses (Jupyter notebook). Can you help me? Thanks,</li>\n</ol>\n<p>Andrea</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-08-31T17:59:41.605Z",
				"Answer_body": "<p>Great question <a class=\"mention\" href=\"/u/andreapi\">@andreapi</a>.</p>\n<p>Yes, <code>Artifact</code>s are connected to <code>Run</code>s in <code>wandb</code> \u2013 that\u2019s what lets us give you that nice graph showing which run used which artifact.</p>\n<p>Your solution works, and the data will be available locally at <code>data_dir</code>.</p>\n<p>In terms of best practice, it depends on how you\u2019re using W&amp;B with your EDA.</p>\n<p><strong>If your EDA is not logged to W&amp;B</strong>, that is if you\u2019re just using Artifacts to store versioned data, rather than versioned analysis results, then <strong>you should close the run immediately</strong>. I would make sure you create <code>run</code> with the <code>job_type</code> argument to <code>wandb.init</code> set to <code>download</code> or something like that.</p>\n<p><strong>If your EDA is logged to W&amp;B</strong>, that is if you\u2019re also going to be tracking things you do inside the EDA to W&amp;B, then you should <strong>wait to close the run until you\u2019re done with the analysis you\u2019ll be tracking</strong>. This has the benefit of actually logging (if you have code saving turned on!) all the cells you run and their outputs, which has saved my <img src=\"https://emoji.discourse-cdn.com/twitter/bacon.png?v=10\" title=\":bacon:\" class=\"emoji\" alt=\":bacon:\"> when doing EDA and other prototyping in a notebook. You can also log <a href=\"https://docs.wandb.ai/guides/track/log/plots\">charts</a> and <a href=\"https://docs.wandb.ai/guides/track/log/media\">media</a> and <a href=\"https://docs.wandb.ai/guides/data-vis\">dataframes/tables</a> while you do your EDA. These features are in very active development, so we\u2019d love to hear how they work for you and your team!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-01T12:46:08.148Z",
				"Answer_body": "<p>Hi Charles,</p>\n<p>thanks for the suggestion! In meantime I found a better solution where I don\u2019t even need to start a run. <em>Look ma, no</em> <code>init</code>! <img src=\"https://emoji.discourse-cdn.com/twitter/stuck_out_tongue_winking_eye.png?v=10\" title=\":stuck_out_tongue_winking_eye:\" class=\"emoji\" alt=\":stuck_out_tongue_winking_eye:\"></p>\n<pre><code>artifact_URI =...\ndata_dir = ...\n\napi = wandb.Api()\nartifact = api.artifact(artifact_URI)\nartifact.checkout(data_dir)\n</code></pre>\n<p>Not bad, eh? All thanks to your very good documentation and the very responsive <code>wandb/client</code> repository!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2021-09-02T00:48:35.012Z",
				"Answer_body": "<p><img src=\"https://emoji.discourse-cdn.com/twitter/tada.png?v=10\" title=\":tada:\" class=\"emoji\" alt=\":tada:\"> ! Indeed, you can do a lot via the public API, which avoids the need to make runs. It\u2019s convenient and allows you to do things like change the history to correct errors.</p>\n<p>I think, btw, you can/should use <code>artifact.download</code> instead of <code>checkout</code>. The difference is the same as that between just downloading the files (which is non-destructive) and doing a \u201ccheckout\u201d in <code>git</code> \u2013 which guarantees that the state of the directory locally is exactly the same as it is in the remote, meaning files will get deleted/clobbered. Depends on your workflow, but most folks want <code>download</code>.</p>\n<p>One more plug: this works to pull down artifacts for use without logging anything to W&amp;B, but if you want your EDA tracked (including the session history of your notebook, as I mentioned above), you\u2019d need to treat the EDA as a \u201crun\u201d. If you track it and log your results with us, you could share what you find as a Report!</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.559Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	},
	{
		"Question_title": "How to show \"f1_macro\" when using hugging face transformer?",
		"Question_link": "https://community.wandb.ai/t/how-to-show-f1-macro-when-using-hugging-face-transformer/182",
		"Question_created_time": "2021-08-24T05:16:18.516Z",
		"Question_answer_count": 2,
		"Question_score_count": 2,
		"Question_view_count": 291,
		"Question_has_accepted_answer": false,
		"Question_body": "<p>I am using hugging face transforer to fine tune a Bert model. How to show f1 with wandb?</p>\n<pre><code class=\"lang-auto\">training_args = TrainingArguments(\n    output_dir='./results_'+folder+'/',          # output directory\n    num_train_epochs = 3,              # total # of training epochs\n    per_device_train_batch_size = n_batch,  # batch size per device during training\n    per_device_eval_batch_size = n_batch,   # batch size for evaluation               \n    weight_decay = 0.01,               # strength of weight decay\n    logging_dir ='./logs',            # directory for storing logs\n    learning_rate = lr,\n    #warmup_steps = 1000,  # number of warmup steps for learning rate scheduler\n    load_best_model_at_end = True,\n    evaluation_strategy = 'steps',\n    metric_for_best_model='accuracy',\n    report_to=\"wandb\",\n)\n</code></pre>\n<p>does not work</p>",
		"Answer_list": [
			{
				"Answer_created_time": "2021-08-24T10:22:09.281Z",
				"Answer_body": "<p>Hey <a class=\"mention\" href=\"/u/lawrencexu\">@lawrencexu</a> could you share some more information please? Can you share a link to a W&amp;B Dashboard or a screenshot? Can you share the code in your \u201ccompute_metrics\u201d function ? the W&amp;B integration should pick up all metrics defined in there I think</p>",
				"Answer_has_accepted": false
			},
			{
				"Answer_created_time": "2022-04-20T18:02:05.348Z",
				"Answer_body": "<p>This topic was automatically closed 60 days after the last reply. New replies are no longer allowed.</p>",
				"Answer_has_accepted": false
			}
		]
	}
]