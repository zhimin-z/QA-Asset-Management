[
    {
        "Question_title":"How does it work underhood: Predictions of multiple instances (Batch) to Vertex AI online serving",
        "Question_creation_date":"2022-08-31T21:25:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-does-it-work-underhood-Predictions-of-multiple-instances\/td-p\/462022\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":59.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,Vertex AI online serving:When multiple instances are passed for prediction to an endpoint, Does prepackaged container serve the inferences in the same manner as TFX Serving does with enable_batching.  If so how do we optimize batching parameters with multiple instances sent to Vertex AI online.If multi_instances prediction is different from TFX serving batching, how do we gain GPU resources efficient usage optimization with prepackaged serving container.On a general note, how to handle efficient GPU usage for both prepackaged container and custom container using a custom trained model.Please guide.Thank you.",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-12T11:51:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Depending on how you perform the custom training you\u2019ll need to set the WorkerPoolSpec. See this document\u00a0to see what how to create a custom job and what it includes."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Vertex AI Datasets & batch predictions",
        "Question_creation_date":"2022-07-24T13:53:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-Datasets-amp-batch-predictions\/td-p\/446346\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "Vertex AI Model Registry"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":134.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi all,I just started to play with Vartex AI. I am working with \"Tabular\" - \"Forecasting\" and currently struggling with few things and i hope you can help me in order i can continue. I tried to organize my questions to three categories:1) Datasets for training:      a) \"series identifier\" define to which time series data are belonging ... lets assume that i have two series identifier - one is called \"A\" and one is called \"B\". Does this means that AI treats them as completely separate and noncorrelated - this means any data that belongs to series A don't have any correlation to B, right? This give me possibility to train different dataset with one shot right? Otherwise i would need to make (in my case) two trainings - one for A and one for B.2) Training new model --> Model detailsa) Is possible to predict more then one target column? b) lets assume that my dataset data granularity is 1 day. Can i use data granularity of \"5min\" for Forecast configuration or can this setup decrease quality of my forecast? Should it be more correct to use already at beginning lets say dataset granularity of 5 minute and afterwards it could be more flexible when setting data granularity for forecast configuration without influencing forecast quality?c) If I set Forecast horizon of 7 and context window 30, does this means that this setting limit my forecast to maximum 7 time steps and requesting always exactly 30 time steps of historical data as input when forecasting on existing trained model?3) Batch predictionsa) Batch Source fileLets assume that i have data with 15 columns from which one is \"serial identifier\" , one is \"time step\" - actually date and one of those columns is target column. Rest of 12 columns are used as influencer and used to train my model. I know that i need to have same structure for batch source file - i read that i can use same file as i used for training, but i just need to add in my case a 2x7 new rows with adding 7 dates and serial identification (in my case 7x A and 7xB) and target column need to be empty. But what should i do with data of rest 12 columns? Do i need manually to enter data for those new rows (2x7) of those 12 columns which values should be for future? But what if i don't have those data? Does this means i cannot do prediction?I tried to make prediction without those future data and i got following message:\"There are rows with non-empty target values after this row. The time series has been excluded from predictions.\"I hope you can help me with above questions. Tnx in advance! Regards, Arny ",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-01T09:20:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"A)\nYes, that's correct you can train different datasets with the same shot (only if there is a specific column that differentiates them). Follow this document\u00a0for best practices.\n\nB)\nNo, for datasets that train AutoML models, one column must be the target, and there must be at least one feature available to train the model.\n\nWhen you train a forecasting model, you specify the data granularity, or the time interval between the training data rows. It can be hourly, daily, weekly, monthly, or yearly. In addition, it can be every 1, 5, 10, 15, or 30 minutes.\u00a0 Vertex AI treats the interim day as missing data, which can degrade model performance.\n\nC)\nFor this error what you could do is to copy the table into another and set the value to NULL to the other columns or set the data values manually."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How can I explicitly authenticate to the ai-platform using the java PredictionServiceClient",
        "Question_creation_date":"2022-11-21T14:42:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-can-I-explicitly-authenticate-to-the-ai-platform-using-the\/td-p\/491537\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":66.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"I have a model hosted on a Google Cloud endpoint and I would like to access it via the Java client.  I've created a service account and a key for that service account with the , when I run my client code with the GOOGLE_APPLICATION_CREDENTIALS env var pointed to the key, I am able to call the service.  When I try to authenticate explicitly using FixedCredentialProvider, it fails with an \"unauthenticated\" message.  The code is as follows`````` ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-22T09:27:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nUpon checking your code, FixedCredentialsProvider.create()\u00a0accepts\u00a0com.google.auth.Credentials\u00a0as a parameter. Can you try a Credentials object to\u00a0FixedCredentialsProvider.create()? See code below:\n\nGoogleCredentials credentials = GoogleCredentials.fromStream(new FileInputStream(\"\/Users\/ME\/Downloads\/XYZ.json\")).createScoped(Lists.newArrayList(\"https:\/\/www.googleapis.com\/auth\/cloud-platform\"));\n\n\u00a0If code above did not work, can you provide the stack trace of the error? Also what roles did you assign on your service account?\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-11-22T09:27:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nUpon checking your code, FixedCredentialsProvider.create()\u00a0accepts\u00a0com.google.auth.Credentials\u00a0as a parameter. Can you try a Credentials object to\u00a0FixedCredentialsProvider.create()? See code below:\n\nGoogleCredentials credentials = GoogleCredentials.fromStream(new FileInputStream(\"\/Users\/ME\/Downloads\/XYZ.json\")).createScoped(Lists.newArrayList(\"https:\/\/www.googleapis.com\/auth\/cloud-platform\"));\n\n\u00a0If code above did not work, can you provide the stack trace of the error? Also what roles did you assign on your service account?"
            },
            {
                "Answer_creation_date":"2022-11-22T13:31:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"This worked. Thank you!"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How should the input JSONL look for a batch prediction job?",
        "Question_creation_date":"2022-04-04T10:42:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-should-the-input-JSONL-look-for-a-batch-prediction-job\/td-p\/410193\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":109.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I can't find any examples online of how an input jsonl is supposed to look for a batch training job. When I tried with this:  I got an error email saying  Error Messages: BatchPrediction could not start because no valid instances \nwere found in the input file. Is there some other way this should look for it to work? Maybe like      ",
        "Answers":[
            {
                "Answer_creation_date":"2022-04-08T13:36:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hell sangersteel,\nIt is not possible to use a JSONL file for batch prediction of text classification. Only a CSV file format is accepted for text classification. This is indicated in the [1] [AutoML Natural Language documentation] The CSV file should only contain 1 file (input file) per row. The CSV file and each input file needs to be stored in your Cloud Storage bucket.\n\n[1]\u00a0https:\/\/cloud.google.com\/natural-language\/automl\/docs\/predict#batch_prediction."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Unable to get textStyle in JSON response with Document ai",
        "Question_creation_date":"2022-08-04T05:40:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Unable-to-get-textStyle-in-JSON-response-with-Document-ai\/td-p\/450434\/jump-to\/first-unread-message",
        "Question_topic":[
            "Document AI"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":46.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I was trying to get text style or Font style with document ai but was getting null list..This is the file I wanted text style to be extractedThis was the response I received.can someone help me with this?",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-10T10:58:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I previously answered on this Stack Overflow post"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Too many pages",
        "Question_creation_date":"2022-10-17T05:32:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Too-many-pages\/td-p\/478806\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":42.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I sent a 13 page pdf thru a document ai parser.  GCP, instead of populating the errors collection of the result with an error indicating too many pages, instead throws a runtime error causing a crash.Is try...except... really the best solution for this as I've not seen use of try...except in any of Google parser examples.",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-17T16:04:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"For this kind of issues, you could file a report as shown in the documentation:\n\n\nIssue reports\n\nGoogle reviews every new issue report submitted by users. Sometimes one of our staff will ask for clarification or follow up. After we're able to replicate the issue, we'll tell you that it's been forwarded to the appropriate team.\n\nDepending on the circumstances, we may be able to provide periodic updates while an issue is being looked at, but usually we cannot provide too many specifics about the exact cause of an issue, or when it will be fixed.\n\nWhen we've fixed an issue in production, we'll indicate this and then we'll close the issue.\n\nYou can create a new Document AI issue here."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Google Cloud Platform - Vertex AI - Workbench JupyterLab - Spark\/Hadoop - JAVA_HOME is not set error",
        "Question_creation_date":"2022-04-13T15:12:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Cloud-Platform-Vertex-AI-Workbench-JupyterLab-Spark\/td-p\/413482\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":382.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi All,I am trying to connect to a SparkSession on Vertex AI's Workbench JupyterLab, but receive this error. Locally, my JAVA_HOME system environments and path environments are already set, and can work when I run Jupyter locally. But only on Vertex AI's Workbench JupyterLab I get this error. Code: \n\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder \\\n.appName('Jupyter BigQuery Storage')\\\n.config('spark.jars', 'gs:\/\/spark-lib\/bigquery\/spark-bigquery-latest_2.12.jar') \\\n.getOrCreate()Full Error:Do let me know if you have advice or help, thank you!",
        "Answers":[
            {
                "Answer_creation_date":"2022-04-20T13:40:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You would need to have Java installed on your Mac, Linux or Windows, without Java installation & not having JAVA_HOME environment variable set with Java installation path or not having PYSPARK_SUBMIT_ARGS, you would get this Exception.\n\n\u00a0\n\nYou need to Set PYSPARK_SUBMIT_ARGS with master, this resolves Exception: Java gateway process exited before sending the driver its port number.\n\n\u00a0\n\nexport PYSPARK_SUBMIT_ARGS=\"--master local[3] pyspark-shell\"\n\nvi ~\/.bashrc , add the above line and reload the bashrc file using source ~\/.bashrc\n\n\u00a0\n\nIn case the issue is still not\u00a0 resolved, check your Java installation and JAVA_HOME environment variable.\n\n\u00a0\n\nYou can see this troubleshooting documentation[1].\n\n\n[1] https:\/\/cloud.google.com\/vertex-ai\/docs\/general\/troubleshooting"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Can i show alias instead of voice name?",
        "Question_creation_date":"2022-06-22T23:31:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Can-i-show-alias-instead-of-voice-name\/td-p\/434016\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":114.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"[ ko-KR-Wavenet-A ] This name is so awkward for me.Can i show alias instead of that voice name?like this. [ ko-KR-Wavenet-A ] -> [ Jinsung ]------------------------------------------------------I'm developing a web service that can edit videos on the web.I will provide Google TTS on that web service.I show the Google (source of the voice) on the side, just wanna alias.",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-01T13:43:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The issue you are facing is happening since somewhere within your code something is calling the API in that form and not on the one you are trying to do so, also google cloud community isn\u2019t the best place to make questions about coding, my recommendation for you would be that you post your question on StackOverflow."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"The new languages are missing",
        "Question_creation_date":"2022-05-17T01:43:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/The-new-languages-are-missing\/td-p\/423648\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":89.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Google cloud translation have added new languages. About 24 new languages has been added to Google Translate. Very good job, well done. But they are not listed on this link.\nhttps:\/\/cloud.google.com\/translate\/docs\/languages\n\nI tried to access it using basic v2 API code, but no response came to my translation request. When will this new languages be available to be accessed by v2 APIs? ",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-18T16:00:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"These are the new 24 languages[1].\n\nIn that post there is a research paper[2] where you can see the codes it begins on page 57.\n\nThe document that you shared it is in an internal Work in Progress with no launch date yet.\n\n[1]https:\/\/blog.google\/products\/translate\/24-new-languages\/\u00a0\n\n[2]https:\/\/arxiv.org\/pdf\/2205.03983.pdf\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-05-18T16:00:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"These are the new 24 languages[1].\n\nIn that post there is a research paper[2] where you can see the codes it begins on page 57.\n\nThe document that you shared it is in an internal Work in Progress with no launch date yet.\n\n[1]https:\/\/blog.google\/products\/translate\/24-new-languages\/\u00a0\n\n[2]https:\/\/arxiv.org\/pdf\/2205.03983.pdf"
            },
            {
                "Answer_creation_date":"2022-05-22T09:33:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Thank you for the update. I hope they do it soon. That would be good."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Translating streaming audio into text",
        "Question_creation_date":"2022-04-11T14:33:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Translating-streaming-audio-into-text\/td-p\/412679\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":33.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi, I'm using @Google-cloud\/media-translation in node with express js server. I want to translate media file (\".wav\" format) with media-translation. At first, i got an error because of authentication and I fixed it with env variable as specified in documentation, I followed each and every step exactly told in the documentation but I'm getting no response from server. When i looked into APIs & Services tab it only recorded my failed auth attempts no other API calls are recorded. Please help because there is no help available online about this product and it doesn't even send error responses so i can debug. ",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nWould you please share with us the error message ? Please make sure there are PII in it.\n\nYou can also share the reproduction steps?\n\nThanks"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Meetup on machine translation for low-resource languages this Friday!",
        "Question_creation_date":"2022-10-19T12:13:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Meetup-on-machine-translation-for-low-resource-languages-this\/td-p\/479955\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_tag":null,
        "Question_upvote_count":1.0,
        "Question_view_count":19.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"The last machine translation meetup featured a PM for the Google Cloud Translation API in person.The next machine translation meetup is all about low-resource machine translation and it'll be online.",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-19T12:13:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The last machine translation meetup featured a PM for the Google Cloud Translation API in person.\n\nThe next machine translation meetup is all about low-resource machine translation\u00a0and it'll be online.\n\n\u00a0\nmachinetranslate.org\/meetup\n\u00a0\nThe 25-minute panel features guests from Meta AI,\u00a0NeuralSpace, LoResMT, and Masakhane!\n\nRegister to join us\u00a0this Friday at 8am PST"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to organize intents\/pages for a non-service\/support application",
        "Question_creation_date":"2022-11-21T04:03:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-organize-intents-pages-for-a-non-service-support\/td-p\/491306\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":44.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am a new Dialogflow user and I need to create an agent for an application that is not service or support oriented.  The application is educational and has a large collection of questions and answers (1,000s) with no concrete conclusion (for example,  to renew a driver's license).  For the POC I did in Watson I was able to use folders to organize sub-topics.  What is the best way to group intents and responses by topic and sub-topic (for example, President Lincoln's early life President Lincoln's career)?  I expect it would be difficult to manage a list of 1,000s of pages in the left pane.  Thank you.",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-22T09:48:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi\u00a0@NoankMary, are you using Dialogflow CX or ES?"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"is there any list of brands\/logos supported by google vision api?",
        "Question_creation_date":"2021-11-10T21:01:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/is-there-any-list-of-brands-logos-supported-by-google-vision-api\/td-p\/175425\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":233.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"is there anyplace i can see the list of brands\/logos that are currently supported by the google vision api's logo recognition service?",
        "Answers":[
            {
                "Answer_creation_date":"2021-11-23T11:41:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"The product team does not currently publish such a list. I recommend for you to submit a Feature Request to the Vision API product team.\u00a0\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2021-11-23T11:41:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"The product team does not currently publish such a list. I recommend for you to submit a Feature Request to the Vision API product team."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Billing & Cloud Vision API issue with \"Recognize Text\" on Android system",
        "Question_creation_date":"2022-09-21T23:22:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Billing-amp-Cloud-Vision-API-issue-with-quot-Recognize-Text-quot\/td-p\/469422\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_tag":null,
        "Question_upvote_count":1.0,
        "Question_view_count":29.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi there,Here I got a billing problem with Cloud Vision API.First, I follow this link to setup my Firebase project to enable the feature of \"Recognize Text\".https:\/\/firebase.google.com\/docs\/ml\/android\/recognize-textThen all the functions used are normal. I call the function of \"annotateImage\" in Cloud Functions to invoke the Cloud Vision API, then can also used successful.Absolutely, I have trace the flow and requests on Cloud Vision API, it is just looks reasonable.But the issue I encountered is, \"it still charges when I'm not using it\", also when it has no any flow and requests! Billing, September 1-22, 2022 (the project has billing alerts set up now) :Cloud Vision API, 30 days to 9\/22\/2022 : It would be so gratefull if there any good suggestions !",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-21T23:22:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi there,\n\nHere I got a billing problem with Cloud Vision API.\n\nFirst, I follow this link to setup my Firebase project to enable the feature of \"Recognize Text\".\n\nhttps:\/\/firebase.google.com\/docs\/ml\/android\/recognize-text\n\nThen all the functions used are normal. I call the function of \"annotateImage\" in Cloud Functions to invoke the Cloud Vision API, then can also used successful.\n\nAbsolutely, I have trace the flow and requests on Cloud Vision API, it is just looks reasonable.But the issue I encountered is, \"it still charges when I'm not using it\", also when it has no any flow and requests!\u00a0\n\nBilling, September 1-22, 2022 (the project has billing alerts set up now) :\n\nCloud Vision API, 30 days to 9\/22\/2022 :\n\n\u00a0\n\nIt would be so gratefull if there any good suggestions !"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"DocAI - Response in a single json file",
        "Question_creation_date":"2022-11-17T23:30:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/DocAI-Response-in-a-single-json-file\/td-p\/490702\/jump-to\/first-unread-message",
        "Question_topic":[
            "Document AI"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":59.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello Experts,\nI'm doing BatchProcessDocument. I have 18 pages of a PDF file and tried to process this using DocumentProcessorServiceClient API. After the process, Im getting response in json file. This is perfect.\nBut the json output file is created only for the 5 pages of the source PDF file. Each 5 pages of the content are converted into a separate json file.My question here is, is it possible to have a single output json file for a PDF source file? ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-18T15:57:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nJust to confirm, when you said \"Each 5 pages of the content are converted into a separate json file.\" does it mean that 1 json per page? or 1 json per 5 pages? Also can you provide the code and sample file that you are using? Please make sure there are no PIIs (Personal Identifiable Information) in your file when providing it here."
            },
            {
                "Answer_creation_date":"2022-11-20T21:41:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nThanks for you response. Actually I have two points.\n\nA pdf file should be processed and the response for this file in a single json file\nI have a file with a table of around 1000 rows. This table data can not be displayed in a single page. I just want a json object for this whole table. But currently the code is working for objects in a single page.\n\nBelow is my sample source code. I could not attach my sample file to this discussion.\n\n\u00a0\n\nimport java.io.File;\nimport java.io.FileInputStream;\nimport java.io.FileReader;\nimport java.io.IOException;\nimport java.util.List;\nimport java.util.concurrent.ExecutionException;\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.TimeoutException;\n\nimport com.google.api.gax.core.FixedCredentialsProvider;\n\n\/\/ [START documentai_batch_process_document]\n\nimport com.google.api.gax.longrunning.OperationFuture;\nimport com.google.api.gax.paging.Page;\nimport com.google.auth.oauth2.GoogleCredentials;\nimport com.google.cloud.documentai.v1.BatchDocumentsInputConfig;\nimport com.google.cloud.documentai.v1.BatchProcessMetadata;\nimport com.google.cloud.documentai.v1.BatchProcessRequest;\nimport com.google.cloud.documentai.v1.BatchProcessResponse;\nimport com.google.cloud.documentai.v1.Document;\nimport com.google.cloud.documentai.v1.DocumentOutputConfig;\nimport com.google.cloud.documentai.v1.DocumentOutputConfig.GcsOutputConfig;\nimport com.google.cloud.documentai.v1.DocumentProcessorServiceClient;\nimport com.google.cloud.documentai.v1.DocumentProcessorServiceSettings;\nimport com.google.cloud.documentai.v1.GcsDocument;\nimport com.google.cloud.documentai.v1.GcsDocuments;\nimport com.google.cloud.storage.Blob;\nimport com.google.cloud.storage.BlobId;\nimport com.google.cloud.storage.Bucket;\nimport com.google.cloud.storage.Storage;\nimport com.google.cloud.storage.StorageOptions;\nimport com.google.common.collect.Lists;\nimport com.google.protobuf.util.JsonFormat;\n\npublic class CustomProcessDocument {\n\t\n\tpublic static void main(String a[]) {\n\t\t\n\t\ttry {\n\t\t\tCustomProcess();\n\t\t} catch (IOException | InterruptedException | ExecutionException | TimeoutException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\t\n\tpublic static void CustomProcess() \n\t\t\tthrows IOException, InterruptedException, ExecutionException, TimeoutException {\n\t\t\n        String projectId = \"my-project-id\";\n        String location = \"us\"; \/\/ Format is \"us\" or \"eu\".\n        String processerId = \"my-processor-id\";\n        String outputGcsBucketName = \"my-storage-bucket-name\";\n        String outputGcsPrefix = \"my-output-path\";\n        String inputGcsUri = \"gs:\/\/my-storage-bucket-name\/sample-pdf-file.pdf\";\n        String tokenPath = \"credentials-json-file-path\";\n        CustomProcessDoc(projectId, location, processerId, inputGcsUri, outputGcsBucketName, outputGcsPrefix, tokenPath);\n\t}\n\n    public static void CustomProcessDoc(String projectId, String location, String processorId, String gcsInputUri, \n    \t\tString gcsOutputBucketName, String gcsOutputUriPrefix, String tokenPath) {\n    \t\n        \/\/ Initialize client that will be used to send requests. This client only needs to be created\n        \/\/ once, and can be reused for multiple requests. After completing all of your requests, call\n        \/\/ the \"close\" method on the client to safely clean up any remaining background resources.\n        try {\n        \t\n        \tGoogleCredentials credentials = GoogleCredentials.fromStream(new FileInputStream(tokenPath)).createScoped(Lists.newArrayList(\"https:\/\/www.googleapis.com\/auth\/cloud-platform\"));\n        \tDocumentProcessorServiceSettings setting = DocumentProcessorServiceSettings.newBuilder().setCredentialsProvider(FixedCredentialsProvider.create(credentials)).build();\n        \tDocumentProcessorServiceClient client = DocumentProcessorServiceClient.create(setting);\n        \t\n            \/\/ The full resource name of the processor, e.g.:\n            \/\/ projects\/project-id\/locations\/location\/processor\/processor-id\n            \/\/ You must create new processors in the Cloud Console first\n            String name = String.format(\"projects\/%s\/locations\/%s\/processors\/%s\", projectId, location, processorId);\n\n            GcsDocument gcsDocument = GcsDocument.newBuilder().setGcsUri(gcsInputUri).setMimeType(\"application\/pdf\").build();\n\n            GcsDocuments gcsDocuments = GcsDocuments.newBuilder().addDocuments(gcsDocument).build();\n\n            BatchDocumentsInputConfig inputConfig = BatchDocumentsInputConfig.newBuilder().setGcsDocuments(gcsDocuments).build();\n\n            String fullGcsPath = String.format(\"gs:\/\/%s\/%s\/\", gcsOutputBucketName, gcsOutputUriPrefix);\n            GcsOutputConfig gcsOutputConfig = GcsOutputConfig.newBuilder().setGcsUri(fullGcsPath).build();\n\n            DocumentOutputConfig documentOutputConfig = DocumentOutputConfig.newBuilder().setGcsOutputConfig(gcsOutputConfig).build();\n\n            \/\/ Configure the batch process request.\n            BatchProcessRequest request = BatchProcessRequest.newBuilder().setName(name).setInputDocuments(inputConfig).setDocumentOutputConfig(documentOutputConfig).build();\n\n            OperationFuture<BatchProcessResponse, BatchProcessMetadata> future = client.batchProcessDocumentsAsync(request);\n\n            \/\/ Batch process document using a long-running operation.\n            \/\/ You can wait for now, or get results later.\n            \/\/ Note: first request to the service takes longer than subsequent\n            \/\/ requests.\n            System.out.println(\"Waiting for operation to complete...\");\n            future.get(240, TimeUnit.SECONDS);\n\n            System.out.println(\"Document processing complete.\");\n\n\/\/            Storage storage = StorageOptions.newBuilder().setProjectId(projectId).build().getService();\n            Storage storage = StorageOptions.newBuilder().setCredentials(credentials).setProjectId(projectId).build().getService();\n            Bucket bucket = storage.get(gcsOutputBucketName);\n\n            \/\/ List all of the files in the Storage bucket.\n            Page<Blob> blobs = bucket.list(Storage.BlobListOption.prefix(gcsOutputUriPrefix + \"\/\"));\n            System.out.println(\"blobs : \"+blobs);\n            int idx = 0;\n            for (Blob blob : blobs.iterateAll()) {\n                if (!blob.isDirectory()) {\n                    System.out.printf(\"Fetched file #%d\\n\", ++idx);\n                    \/\/ Read the results\n\n                    \/\/ Download and store json data in a temp file.\n                    File tempFile = File.createTempFile(\"file\", \".json\");\n                    Blob fileInfo = storage.get(BlobId.of(gcsOutputBucketName, blob.getName()));\n                    fileInfo.downloadTo(tempFile.toPath());\n\n                    \/\/ Parse json file into Document.\n                    FileReader reader = new FileReader(tempFile);\n                    Document.Builder builder = Document.newBuilder();\n                    JsonFormat.parser().merge(reader, builder);\n\n                    Document document = builder.build();\n\n                    \/\/ Get all of the document text as one big string.\n                    String text = document.getText();\n\n                    \/\/ Read the text recognition output from the processor\n                    System.out.println(\"The document contains the following paragraphs:\");\n                    Document.Page page1 = document.getPages(0);\n                    List<Document.Page.Paragraph> paragraphList = page1.getParagraphsList();\n                    for (Document.Page.Paragraph paragraph : paragraphList) {\n                        String paragraphText = getText(paragraph.getLayout().getTextAnchor(), text);\n                        System.out.printf(\"Paragraph text:%s\\n\", paragraphText);\n                    }\n\n                    \/\/ Form parsing provides additional output about\n                    \/\/ form-formatted PDFs. You must create a form\n                    \/\/ processor in the Cloud Console to see full field details.\n                    System.out.println(\"The following form key\/value pairs were detected:\");\n\n                    for (Document.Page.FormField field : page1.getFormFieldsList()) {\n                        String fieldName = getText(field.getFieldName().getTextAnchor(), text);\n                        String fieldValue = getText(field.getFieldValue().getTextAnchor(), text);\n\n                        System.out.println(\"Extracted form fields pair:\");\n                        System.out.printf(\"\\t(%s, %s))\", fieldName, fieldValue);\n                    }\n\n                    \/\/ Clean up temp file.\n                    tempFile.deleteOnExit();\n                }\n            }\n        } catch (IOException | InterruptedException | TimeoutException | ExecutionException e) {\n        \te.printStackTrace();\n        }\n    }\n\n    \/\/ Extract shards from the text field\n    private static String getText(Document.TextAnchor textAnchor, String text) {\n    \t\n        if (textAnchor.getTextSegmentsList().size() > 0) {\n        \t\n            int startIdx = (int) textAnchor.getTextSegments(0).getStartIndex();\n            int endIdx = (int) textAnchor.getTextSegments(0).getEndIndex();\n            return text.substring(startIdx, endIdx);\n        }\n        return \"[NO TEXT]\";\n    }\n}"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"hello custom training tutorial failed on cloud function deploy",
        "Question_creation_date":"2022-03-10T15:58:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/hello-custom-training-tutorial-failed-on-cloud-function-deploy\/td-p\/402689\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":385.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi guys I'm following this tutorial to get my had around Vertex AI - https:\/\/cloud.google.com\/vertex-ai\/docs\/tutorials\/image-recognition-custom\/ On step  - https:\/\/cloud.google.com\/vertex-ai\/docs\/tutorials\/image-recognition-custom\/serving#2_deploy_a   since I'm new on GCP anyone tried this tutorial and have the same error? any tips on how to fix this?thank you very much guys",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-15T18:39:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The gcloud tool comes with a set of options which are not easily to spot but offer features like verbosity. Add -- verbosity debug to your deplyment command in order to debug the deployment process with more meaningful logs.\n\nFind all the options here:[1]\n\n[1] https:\/\/cloud.google.com\/sdk\/gcloud\/reference\/functions\/deploy"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Manage Labeling Assignments on DataCompute",
        "Question_creation_date":"2021-11-11T20:14:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Manage-Labeling-Assignments-on-DataCompute\/td-p\/175499\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":1.0,
        "Question_view_count":416.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Our team has started to use the DataCompute console to assign labelers to labeling tasks created in Vertex AI. Currently, the Assignments tab requires the Labeling Manager to Populate the Specialists Column and Populate the Tasks Column I wanted to highlight some issues we are facing and ask if there's any plan to implement fixes.Issues: 1. The dropdown for task selection does not order the tasks alphabetically so it is difficult to find a specific task.2. There's no \"Select All\" option, instead, the manager must select each task individually.3. There is no drop down for the specialist emails even though they are available under the Specialists tab.Generally, it would be nice to see the entire assignment table by default rather than nothing on this page.Let me know if some of these issues can be addressed! ",
        "Answers":[
            {
                "Answer_creation_date":"2021-11-25T15:25:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thank you for your input. Can you provide the reproduction steps so we can update it on this thread\u00a0\nPlease note that such issues are usually submitted and handled by the product teams via Public Issue Tracker. Therefore, I just submitted your request to the Vertex AI product team on\u00a0this thread, and I recommend you to star it as all future updates will occur there."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"BigQueryML Explainability Apparently Not Working",
        "Question_creation_date":"2021-12-22T09:25:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/BigQueryML-Explainability-Apparently-Not-Working\/td-p\/181036\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":319.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"I'm using BigQueryML to train an XGBoost model on some of my data. When I create the model, I set the ENABLE_GLOBAL_EXPLAIN flag to TRUE, the model then trains properly and I can evaluate it. However there is no Interpretability tab on the model's page, and when I try to query the model with the ML.GLOBAL_EXPLAIN command, I get an error that says: Is this a bug or am I doing something wrong?Here's my create model code: ",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-29T17:47:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You are using the right syntax for creating the model\u00a0 as per the examples mentioned in documentation[1].\n\n=> Some possibilities for the error are :\n\n- Models with the same id were re-training again with the script during the evaluation.\n\n- Evaluation data was not provided (might have been explicitly disabled)\n\nYou can \u00a0open up details about the model in the UI in BigQuery, under Evaluation and verify what details it shows.\u00a0Also, you can try to rerun the model again (creating, training, evaluating) and verify if it works for you.\n\n[1] https:\/\/cloud.google.com\/bigquery-ml\/docs\/reference\/standard-sql\/bigqueryml-syntax-create#create_mod..."
            },
            {
                "Answer_creation_date":"2021-12-30T09:18:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi\u00a0@dikaur\u00a0\n\nThanks so much for your response!\n\nI did try to train new models with new names, and as you can tell from the code above, we do provide the \"RANDOM\" method for data evaluation. In addition, on the model's page, there is information about the model's evaluation, so I believe it is receiving an evaluation dataset. I've also tried several other models with several different datasets and unfortunately they are all seeing the same error.\n\nThis was working about 2 months ago so it's possible that something changed recently.\n\nAre there any other possible explanations for something that I'm doing wrong?\n\nThanks!"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"BatchPredict could not start due to empty input CSV file",
        "Question_creation_date":"2021-12-31T03:53:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/BatchPredict-could-not-start-due-to-empty-input-CSV-file\/td-p\/181685\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML",
            "Cloud Natural Language API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":49.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,\nI have a problem with batch prediction for text classification.\nAccording to the documentation I have created a csv file in which every single line refers to a PDF in my bucket. However I get the error message \"InvalidArgument: 400 BatchPredict could not start due to empty input CSV file\".I would be infinitely grateful for help in this case....",
        "Answers":[
            {
                "Answer_creation_date":"2022-01-03T09:35:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hey,\u00a0\n\nI would suggest that you consider reaching the\u00a0StackOverflow for technical questions as\u00a0Google Groups are reserved for general product discussion.\u00a0\n\nTo get a better support you should post to the relevant forum, thus please read the Community Support article for better understanding."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Google Translate javascript API",
        "Question_creation_date":"2022-08-06T01:26:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Translate-javascript-API\/td-p\/451250\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_tag":null,
        "Question_upvote_count":1.0,
        "Question_view_count":94.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-11T13:54:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"If my understanding is correct, you only want to use that part of the script to translate a web page, right?\u00a0\n\nIf yes I think you can use it as long as you don\u2019t meet the quotas described on this documentation free of charge, and also if you have doubts on how to implement the script you are sharing, you could look up for tutorials online on how to properly make use of it."
            },
            {
                "Answer_creation_date":"2022-08-16T17:08:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nThank you for your kind reply.\u00a0\n\nYes, you're right, I only want to use the script to translate a webpage.\n\nI'll go through the document you have referred to.\n\nMinoru Kume"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"What's the order for the labels in txt file after I have exported my tflite model from Vertex AI",
        "Question_creation_date":"2022-10-21T12:13:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/What-s-the-order-for-the-labels-in-txt-file-after-I-have\/td-p\/480804\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML",
            "Vertex AI Model Registry"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":116.0,
        "Question_answer_count":3,
        "Question_has_accepted_answer":true,
        "Question_body":"I have exported my trained tflite model. But I noticed the order of the labels in the txt file matters. I'm using image classification models. The ones with only two labels, it's an easy fix. I just switch the two. But when I have more than two labels, I notice the predictions are way off. Does it say in Vertex AI or is there a general rule to what label should go first, second, third..etc in the txt file that we create on our own? ",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"After reviewing more about Export AutoML Edge models, you can see the following TensorFlow documentation to learn more about extracting this information.\n\nTensorFlow Lite inference with metadata\nGenerate model interfaces with TensorFlow Lite code generator\nAdding metadata to TensorFlow Lite models\n\nThe documentation that might help more for your question is the last one \u201cAdding metadata to TensorFlow Lite Models\u201d.\n\nBut what I can suggest to you is to send an email to tensorflow-enterprise-support@google.com with your question, and hopefully they can give you a direct solution to your concerns.\n\nAdditionally, I found this Stack Overflow question to create labels.txt manually.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-10-25T10:25:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"I am still reviewing documentation to determine if there is one way to create a rule.\n\nAs soon as I collect more information about your main concern, I will share it with you as soon as possible."
            },
            {
                "Answer_creation_date":"2022-10-25T15:27:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"After reviewing more about Export AutoML Edge models, you can see the following TensorFlow documentation to learn more about extracting this information.\n\nTensorFlow Lite inference with metadata\nGenerate model interfaces with TensorFlow Lite code generator\nAdding metadata to TensorFlow Lite models\n\nThe documentation that might help more for your question is the last one \u201cAdding metadata to TensorFlow Lite Models\u201d.\n\nBut what I can suggest to you is to send an email to tensorflow-enterprise-support@google.com with your question, and hopefully they can give you a direct solution to your concerns.\n\nAdditionally, I found this Stack Overflow question to create labels.txt manually."
            },
            {
                "Answer_creation_date":"2022-10-25T17:31:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks! I was able to use unzip command in my terminal and extract the label file."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Vertex AI create endpoint error - FAILED_PRECONDITION: Project xxxxxxxx is not active.",
        "Question_creation_date":"2022-08-27T00:45:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-create-endpoint-error-FAILED-PRECONDITION-Project\/td-p\/460565\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":144.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi, I'm stuck at following error message when I try to create vertex-ai endpoint from workbench notebook.  I have enabled aiplatform.googleapis.com.Command:\ngcloud ai endpoints create \\\n--project=XXXXX\n--region=us-central1 \\\n--display-name=ld-test-resnet-classifierUsing endpoint [https:\/\/us-central1-aiplatform.googleapis.com\/]\nERROR: (gcloud.ai.endpoints.create) FAILED_PRECONDITION: Project XXXXXXXXXX is not active.Please suggest what am I missing.   ",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-27T04:38:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\nThe issue is resolved.\nAt least one model has to be uploaded first to model registry for this command to work.\nThe official documentation titled \"Deploy a model using the Vertex AI API\" - implies deploy a model uploaded to model registry\".\n\nThanks for the views.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-08-27T04:38:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\nThe issue is resolved.\nAt least one model has to be uploaded first to model registry for this command to work.\nThe official documentation titled \"Deploy a model using the Vertex AI API\" - implies deploy a model uploaded to model registry\".\n\nThanks for the views."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Make deep learning VM JupyterLab publicly available?",
        "Question_creation_date":"2022-01-27T11:02:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Make-deep-learning-VM-JupyterLab-publicly-available\/td-p\/386576\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":96.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"I was able to create a deep learning VM from the marketplace and when I open up the VM instance in the Console I see a metadata tag called `proxy-url` which has a format like `https:\/\/[alphanumeric string]-dot-us-central1.notebooks.googleusercontent.com\/lab`\n\nClicking on that link takes me to a JupyterLab UI that is running on my VM. Amazing! Unfortunately, when I try opening that link on an incognito window, I'm asked to sign in. If I sign in, I get a 403 forbidden.\n\nMy question now is, how can I make that link available to someone else?",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi gopalv\n\nAs far as I understand, it sounds like your Jupyter Notebook isn't configured for remote access. since it doesn't work when trying to access it from the incognito window with a 403 error.\n\nYou can try looking here and here for details on how to set up a publicly accessible\/remote access notebook. There are additional troubleshooting steps in our documentation here as well.\n\nHope this helps!\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"I think the problem was that I had selected the option to enable access via URL and this only grants access to users who are Editors or Owners in the workspace (step 9 here)\u00a0\n\n\u00a0\n\nhttps:\/\/cloud.google.com\/deep-learning-vm\/docs\/tensorflow_start_instance#creating_ainstance_from_the\n\u00a0\n\n\nWhen I created a new VM and left this option unchecked, I was able to use my public SSH cert to get access.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-01-31T13:58:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Hi gopalv\n\nAs far as I understand, it sounds like your Jupyter Notebook isn't configured for remote access. since it doesn't work when trying to access it from the incognito window with a 403 error.\n\nYou can try looking here and here for details on how to set up a publicly accessible\/remote access notebook. There are additional troubleshooting steps in our documentation here as well.\n\nHope this helps!"
            },
            {
                "Answer_creation_date":"2022-01-31T14:09:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"I think the problem was that I had selected the option to enable access via URL and this only grants access to users who are Editors or Owners in the workspace (step 9 here)\u00a0\n\n\u00a0\n\nhttps:\/\/cloud.google.com\/deep-learning-vm\/docs\/tensorflow_start_instance#creating_ainstance_from_the\n\u00a0\n\n\nWhen I created a new VM and left this option unchecked, I was able to use my public SSH cert to get access."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Create an instance of TextToSpeechClient() and ApplicationDefaultCredentials ...",
        "Question_creation_date":"2022-05-01T16:07:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Create-an-instance-of-TextToSpeechClient-and\/td-p\/418964\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":146.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi Folks,My first post here. This was posted on stackoverflow without much feedback - it is a little specific to the TextToSpeechClient and using ApplicationDefaultCredentials.  The link to the stackoverflow article is below just for reference.https:\/\/stackoverflow.com\/questions\/72074724\/trying-to-create-an-instance-of-googles-class-texttospe...I'm attempting to Create an instance of TextToSpeechClient() and an getting an exception - Could not construct ApplicationDefaultCredentials. I was able to get the php sample code provided on your github site running from the command line. I'm now executing in a browser session on an apache server. I have added the putenv() function to set the GOOGLE_APPLICATION_CREDENTIALS value.Below is the code sample <?php\nheader(\"Content-Type: application\/json; charset=UTF-8\");\nheader(\"Access-Control-Allow-Methods: POST\");\nheader(\"Access-Control-Max-Age: 3600\");\nheader(\"Access-Control-Allow-Headers: Content-Type, Access-Control-Allow- Headers, Authorization, X-Requested-With\");require_once '\/home\/macgowan\/vendor\/autoload.php';\/\/ [START tts_synthesize_text]\nuse Google\\Cloud\\TextToSpeech\\V1\\AudioConfig;\nuse Google\\Cloud\\TextToSpeech\\V1\\AudioEncoding;\nuse Google\\Cloud\\TextToSpeech\\V1\\SsmlVoiceGender;\nuse Google\\Cloud\\TextToSpeech\\V1\\SynthesisInput;\nuse Google\\Cloud\\TextToSpeech\\V1\\TextToSpeechClient;\nuse Google\\Cloud\\TextToSpeech\\V1\\VoiceSelectionParams;putenv('GOOGLE_APPLICATION_CREDENTIALS=\/Users\/macgowan\/google_cloud\/service-account-text-to-speech-test-00.json');try\n{putenv('GOOGLE_APPLICATION_CREDENTIALS=\/Users\/macgowan\/google_cloud\/service-account-text-to-speech-test-00.json');\n\/\/ $client->useApplicationDefaultCredentials();$ip = getenv('GOOGLE_APPLICATION_CREDENTIALS');\nprintf(\"Get env var - GOOGLE_APPLICATION_CREDENTIALS: %s<br \/>\", $ip);$ip = getenv('APACHE_RUN_USER');\nprintf(\"Get env var - APACHE_RUN_USER: %s<br \/>\", $ip);\/\/ *** FAILS HERE ***\n$client = new TextToSpeechClient();$text = \"Hello Joe\";print('Set input text using the SynthesisInput() object' . PHP_EOL);\n$input_text = (new SynthesisInput())\n->setText($text);$voice = (new VoiceSelectionParams())\n->setLanguageCode('en-US')\n->setSsmlGender(SsmlVoiceGender::FEMALE);$audioConfig = (new AudioConfig())\n->setAudioEncoding(AudioEncoding::MP3);$response = $client->synthesizeSpeech($input_text, $voice, $audioConfig);\n$audioContent = $response->getAudioContent();file_put_contents('\/home\/macgowan\/output.mp3', $audioContent);\n$client->close();\n}\ncatch (Exception $e)\n{\nprintf(\"Caught exception: %s<br \/>\", $e->getMessage());\n}\n?>Thanks for your help - Chris   ",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-09T09:39:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, this might be occurring because you don\u2019t have the proper composer package in your composer json file. You need to have the next package installed within your JSON..\n\n{\n\n\u00a0 \u00a0\u00a0\"require\": {\u00a0\n\n\u00a0 \u00a0 \u00a0 \u00a0\"google\/cloud-text-to-speech\": \"^1.0\"\n\n\u00a0 \u00a0}\n\n\u00a0}"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"AI Augmented Sensory Headset",
        "Question_creation_date":"2022-10-07T20:18:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/AI-Augmented-Sensory-Headset\/td-p\/475836\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":20.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Wondering when Google will develop olfactory sensor addition to VR headsets and technology. In laymens terms, adding the sense of smell to VR headsets using an add on similar to a printer ink cartridge, but designed specifically for the sense of smell. Theoretically, it is possible, but to manufacture it in a large scale. It can change the way programs, especially helping boost the food and hospitality industry as well as giving everyday people a very good reason to smell fresh food and drink... from their phone! Where and how can we further this research for this wonderful idea?",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-07T20:18:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Wondering when Google will develop olfactory sensor addition to VR headsets and technology. In laymens terms, adding the sense of smell to VR headsets using an add on similar to a printer ink cartridge, but designed specifically for the sense of smell. Theoretically, it is possible, but to manufacture it in a large scale. It can change the way programs, especially helping boost the food and hospitality industry as well as giving everyday people a very good reason to smell fresh food and drink... from their phone! Where and how can we further this research for this wonderful idea?"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Vocal emojis in Speech-to-Text",
        "Question_creation_date":"2022-11-03T07:41:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vocal-emojis-in-Speech-to-Text\/td-p\/485418\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":25.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello! I am majoring in Theoretical Linguistics this year and I would like to write my dissertation on Google Cloud API and the vocal emojis supported, delving into the neural network to find out how they are translated. I have seen that my native language is missing and could build a dataset of spoken forms. Following the tutorial for using the Speech-to-Text API with Phyton I found out that very little information on this project are public.Should I contact some specific person\/service via my institutional account to receive material for a study case?Thank you!",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-03T07:41:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello! I am majoring in Theoretical Linguistics this year and I would like to write my dissertation on Google Cloud API and the vocal emojis supported, delving into the neural network to find out how they are translated. I have seen that my native language is missing and could build a dataset of spoken forms. Following the tutorial for using the Speech-to-Text API with Phyton I found out that very little information on this project are public.\n\nShould I contact some specific person\/service via my institutional account to receive material for a study case?\n\nThank you!"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"AI\/ML",
        "Question_creation_date":"2021-06-18T13:29:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/AI-ML\/td-p\/31\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML",
            "Cloud Natural Language API",
            "Cloud TPU",
            "Cloud Translation API",
            "Cloud Vision API",
            "Contact Center AI",
            "Dialogflow CX",
            "Document AI",
            "Recommendations AI",
            "Speech-to-Text",
            "Text-to-Speech",
            "Video Intelligence API"
        ],
        "Question_tag":null,
        "Question_upvote_count":10.0,
        "Question_view_count":532.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"This is the discussion space to talk about all things AI\/ML related.",
        "Answers":[
            {
                "Answer_creation_date":"2021-06-18T13:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"This is the discussion space to talk about all things AI\/ML related."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Google Translate API",
        "Question_creation_date":"2021-12-30T10:46:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Translate-API\/td-p\/181620\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":272.0,
        "Question_answer_count":3,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi,I would like to use Google Translate API in plain javascript.As far as I understand from this guide, the supported languages are : ... and some additional languages :Does translate API is supported for Javascript as well? If so, where is the guide?Thanks in advance.",
        "Answers":[
            {
                "Answer_creation_date":"2022-01-10T14:09:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Here is a third-party solution you may find useful [1].\u00a0You may also report it to the Public Issue Tracker (PIT) [2]\u00a0 as well as feature request.\n\n[1]\u00a0 https:\/\/github.com\/topics\/javascript-translate\n\n[2]\u00a0https:\/\/cloud.google.com\/support\/docs\/issue-trackers\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2021-12-30T17:04:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"I could not find any official documentation\/tutorial on Google Translate API for plain JavaScript. It looks like the previously used \"Google Transliterate API\" which was officially deprecated as of May 26, 2011 had support for plain JavaScript [1].\nThe client libraries are currently available for seven popular programming languages \u2013 C#, Go, Java, Node.js, PHP, Python, and Ruby.\n\nHowever, the following un-official link [2] (July 20, 2021) may help.\n\n[1] https:\/\/developers.google.com\/transliterate\/v1\/getting_started\n[2] https:\/\/rapidapi.com\/blog\/google-translate-api-tutorial\/"
            },
            {
                "Answer_creation_date":"2021-12-31T05:36:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for the reply sf.\u00a0\n\nHow can it be that there is not documentation for one of the most popular programming languages such as Javascript?"
            },
            {
                "Answer_creation_date":"2022-01-10T14:09:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Here is a third-party solution you may find useful [1].\u00a0You may also report it to the Public Issue Tracker (PIT) [2]\u00a0 as well as feature request.\n\n[1]\u00a0 https:\/\/github.com\/topics\/javascript-translate\n\n[2]\u00a0https:\/\/cloud.google.com\/support\/docs\/issue-trackers"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Google cloud text to speech",
        "Question_creation_date":"2021-09-26T06:11:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-cloud-text-to-speech\/td-p\/171231\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text",
            "Text-to-Speech"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":771.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I registered myself for the google cloud text-to-speech service recently. Speech Studio worked just fine for the first few days, but today, to my dismay, there is distortion in the text reader's voice.What can I do about it?Thanks.  ",
        "Answers":[
            {
                "Answer_creation_date":"2021-10-01T14:27:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Speech Studio is not a Google product. TTS voices are always the same though and do not change over time if the same one is selected."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Vonage Smart Number",
        "Question_creation_date":"2022-10-25T00:59:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vonage-Smart-Number\/td-p\/481819\/jump-to\/first-unread-message",
        "Question_topic":[
            "Contact Center AI",
            "Dialogflow CX"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":113.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Trying to find a way to link a Vonage Smart Number (Vonage Communications, not API) to Dialogflow ",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-26T08:13:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You can use Contact Center AI\n\nContact Center AI (CCAI) is an extension of Dialogflow services that helps create contact center solutions. You need to request access to Contact Center AI documentation. For information, see the Contact Center AI solution overview.\n\nAs shown in this Google Cloud Blog entry Deliver an exceptional customer experience with Contact Center AI, now GA:\n\nYou can now integrate Contact Center AI with your existing workflows and start seeing results within 3-6 months, thanks to integrations with partners such as Avaya and Mitel, who are GA today, as well as 8x8, Cisco, Five9, Genesys, NICE inContact, Salesforce, Twilio, and Vonage.\n\n\u2026\n\nTo find out how Contact Center AI can increase CSAT, deflection rates, and operational efficiency, visit our site, contact your Google sales representative, or request to be contacted."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"What's the training corpus of models behind GCP Natural Language APIs?",
        "Question_creation_date":"2022-11-17T14:36:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/What-s-the-training-corpus-of-models-behind-GCP-Natural-Language\/td-p\/490614\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "Cloud Natural Language API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":45.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi, where can I find some information about which datasets are used for training models that power the natural language APIs for sentiment analysis, entity extraction, etc.? Thanks!",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-23T08:41:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Natural Language API is trained using different types of datasets.\n\nPublic datasets Examples: Five crowd-flower\u00a0sentiment benchmarks\nEAP customer datasets Examples: Feefo sentiment dataset\nAcademic datasets Examples: Stanford rotten tomatoes sentences, UCI Sentiment Labeled Sentences Data Set. See.\nGoogle datasets Examples: Shopping, Play."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Feature Engineering Vertex AI\/AutoML",
        "Question_creation_date":"2022-07-28T09:18:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Feature-Engineering-Vertex-AI-AutoML\/td-p\/447814\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":88.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hey There,I am writing my Master Thesis at the moment. I am comparing AutoML products for image classification. There I compare the product Vertex AI with Azure from Microsoft. However, I can't find the concrete methods of feature engineering and model selection from the documentation. Does anybody know these methodes used for Google AutoML for image classification?Thanks a lot!Arndt",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-03T15:31:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Think you are looking for this documentation it describes how feature engineering works within autoML and how it supports it in different ways."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"\u062a\u062d\u0633\u064a\u0646 \u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u0628\u062d\u062b",
        "Question_creation_date":"2021-12-01T21:19:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/%D8%AA%D8%AD%D8%B3%D9%8A%D9%86-%D8%B9%D9%85%D9%84%D9%8A%D8%A9-%D8%A7%D9%84%D8%A8%D8%AD%D8%AB\/td-p\/176885\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":37.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"\u0627\u0633\u0639\u062f \u0627\u0644\u0644\u0647 \u0635\u0628\u0627\u062d\u0643\u0645\u0641\u064a \u0639\u0645\u0644\u064a\u0629 \u0627\u0644\u0628\u062d\u062b \u0641\u064a \u0627\u0644\u0623\u0633\u0626\u0644\u0629 \u0627\u0644\u0634\u0627\u0626\u0639\u0629 \u0648 \u0627\u0644\u0623\u0633\u0626\u0644\u0629 \u0627\u0644\u062a\u064a \u062a\u062c\u0639\u0644 \u0627\u0644\u0634\u062e\u0635 \u0644\u0627 \u064a\u0639\u0628\u0631 \u0639\u0646 \u0633\u0624\u0627\u0644\u0647 \u0623\u0648 \u0645\u0648\u0636\u0648\u0639\u0647 \u0647\u0648 \u0639\u062f\u0645 \u0627\u0644\u0648\u0635\u0648\u0644 \u0625\u0644\u0649 \u0627\u0644\u0643\u062a\u0627\u0628\u0647 \u0627\u0644\u062e\u0637\u064a\u0629 \u0628\u0634\u0643\u0644 \u0635\u062d\u064a\u062d \u0623\u0648 \u0639\u0646\u062f\u0645\u0627 \u064a\u0633\u0623\u0644 \u0633\u0624\u0627\u0644 \u0644\u0627 \u064a\u0633\u062a\u0637\u064a\u0639 \u0634\u0631\u062d\u0647\u0627 \u0639\u0646 \u0637\u0631\u064a\u0642 \u0627\u0644\u0643\u0644\u0627\u0645)\u0627\u0642\u062a\u0631\u062d \u0639\u0646\u062f\u0645\u0627 \u064a\u062a\u0643\u0644\u0645 \u0627\u0644\u0628\u0627\u062d\u062b \u0639\u0646 \u0645\u0639\u0644\u0648\u0645\u0629 \u0623\u0648 \u0633\u0624\u0627\u0644 \u064a\u062a\u0643\u0644\u0645\u0647\u0627 \u0627\u0644\u0628\u0627\u062d\u062b \u0628\u0627\u0644\u0635\u0648\u062a \u0648\u0639\u0644\u0649 \u0637\u0631\u064a\u0642\u062a\u0647 \u0627\u0644\u0639\u0627\u0645\u064a\u0629 \u0648\u0627\u0644\u0643\u0644\u0627\u0645 \u0627\u0644\u0645\u062a\u062f\u0627\u0648\u0644 \u0639\u0644\u064a\u0647 \u0641\u064a \u0645\u0646\u0637\u0642\u062a\u0647 \u0648\u064a\u0643\u0648\u0646 \u0647\u0646\u0627\u0644\u0643 \u0627\u0634\u062e\u0627\u0635  \u0645\u0646 \u0646\u0641\u0633 \u0627\u0644\u0645\u0646\u0637\u0642\u0629 \u064a\u0641\u0647\u0645 \u0644\u063a\u0629 \u0627\u0644\u0645\u062a\u0643\u0644\u0645 \u0648\u064a\u062c\u064a\u0628\u0647 \u0639\u0644\u0649 \u0627\u0633\u0627\u0633\u0647\u0627 \u0648\u064a\u0648\u062c\u062f \u0627\u0634\u062e\u0627\u0635 \u0643\u062b\u0631 \u0645\u062a\u0637\u0648\u0639\u064a\u0646 \u0641\u064a \u0646\u0634\u0631 \u0627\u0644\u0645\u0639\u0644\u0648\u0645\u0629 \u0648\u0627\u0644\u062e\u064a\u0631 \u0628\u0627\u0644\u0645\u062c\u0627\u0646 \u0633\u0648\u0627\u0621 \u0643\u0627\u0646\u062a \u0627\u0644\u0637\u0628 \u0627\u0648 \u0627\u0644\u0647\u0646\u062f\u0633\u0629 \u0627\u0648 \u0639\u0644\u0645 \u0645\u0639\u064a\u0646 \u0627\u0648 \u0627\u064a \u0639\u0644\u0645 \u0648\u0645\u0639\u0644\u0648\u0645\u0629\u0627\u0644\u0645\u062e\u062a\u0635\u0631 \u0639\u0646\u062f\u0645\u0627 \u0627\u062a\u0643\u0644\u0645 \u0645\u0646 \u0627\u0644\u062e\u0627\u062f\u0645 \u062d\u0648\u062c\u0644 \u0635\u0648\u062a \u0644\u0627 \u064a\u062a\u0643\u0644\u0645 \u0628\u0627\u0644\u0644\u063a\u0629 \u0627\u0644\u0639\u0631\u0628\u064a\u0629 \u0627\u0644\u0641\u0635\u062d\u0649 \u0648\u0644\u0643\u0646 \u064a\u0648\u062c\u062f \u0627\u0634\u062e\u0627\u0635 \u0643\u0627\u062f\u0645 \u062d\u0648\u062c\u0644 \u064a\u062d\u0644\u0644\u0648\u0646 \u0627\u0644\u0643\u0644\u0627\u0645 \u0628\u0644\u063a\u0629 \u0627\u0644\u0634\u062e\u0635 \u0627\u0644\u0645\u062a\u0643\u0644\u0645 \u0643\u0644\u064b \u062d\u0633\u0628 \u0645\u0646\u0637\u0642\u062a\u0647..\u0627\u062a\u0645\u0646\u0627 \u0648\u0635\u0644\u062a \u0627\u0644\u0645\u0639\u0644\u0648\u0645\u0629 \u0648\u0627\u0630\u0627 \u0628\u062f\u0643\u0645 \u0627\u062d\u0643\u064a\u0647\u0627 \u0635\u0648\u062a \u0648\u0627\u0634\u0631\u062d\u0647\u0627 \u0627\u0641\u0636\u0644 \u064a\u0627\u0631\u064a\u062a \u062a\u062e\u0628\u0631\u0648\u0646\u064a \u0648\u0627\u062a\u0648\u0627\u0635\u0644 \u0645\u0639\u0643\u0645 ",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-07T09:07:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, I would like to inform you that Arabic\u00a0 is not a supported language [1]. I would recommend you to re-formulate your issue in English and we will be very happy to help you.\n\n\u00a0\n\nThanks\n\n[1]\n\nhttps:\/\/cloud.google.com\/support\/docs\/language-working-hours#language_support"
            },
            {
                "Answer_creation_date":"2021-12-07T09:08:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, I would like to inform you that Arabic\u00a0 is not a supported language [1]. I would recommend you to re-formulate your issue in English and we will be very happy to help you.\n\n\u00a0\n\nThanks\n\n[1]\n\nhttps:\/\/cloud.google.com\/support\/docs\/language-working-hours#language_support"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Retail API predict call saves the userEvent. It should NOT!",
        "Question_creation_date":"2022-07-17T17:45:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Retail-API-predict-call-saves-the-userEvent-It-should-NOT\/td-p\/443911\/jump-to\/first-unread-message",
        "Question_topic":[
            "Recommendations AI"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":62.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"According to document, the userEvent sent as part of the predict body is not recorded.  https:\/\/cloud.google.com\/retail\/docs\/predict#recommendHowever, I noticed this was not TRUE.  Here is how to reproduce thisBecause both \"FAKE_SESSION_ID_1\" and \"FAKE_SESSION_ID_2\" are never used before this experient.   The recommendation result for the same sku should be same or very similar.  But they diff a lot.  ",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-20T12:58:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I reproduce this and it gives me similar results from what you say, so I decided to investigate this, and I found that this usually is not a great test of the prediction capabilities unless you use real, live data, but you can try this using sample data but it is possible that you get different results.\n\n\nFor using sample data to test prediction capabilities it is recommended to use the following demo."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Create TPU Node - Malformed Name",
        "Question_creation_date":"2022-02-26T05:03:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Create-TPU-Node-Malformed-Name\/td-p\/397566\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud TPU"
        ],
        "Question_tag":null,
        "Question_upvote_count":1.0,
        "Question_view_count":180.0,
        "Question_answer_count":5,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi! Im trying to create a Google Cloud TPU node using TPU client API and I cannot figure out the parent resource name of a TPU node in Google Cloud.I tried all the possible combinations, for example:And I always get the same error (google.api_core.exceptions.InvalidArgument: 400 Malformed name) :        Below you can find the full code I'm using to create the node. Im using Python 3.8, google-cloud-tpu v1.2.1, on a Conda virtualenv. Any help would be much apprecciated!",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-02T06:35:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"It appears that you have created a StackOverflow thread where a Google Cloud Platform Engineer has already replied.\u00a0\n\nHe has suggested you that\u00a0you can find the expected format of\u00a0parent\u00a0in the documentation for the underlying API method:\u00a0projects.locations.nodes.create.parent\u00a0should be formatted as\u00a0projects\/*\/locations\/*. That is, change\u00a0zones\u00a0to\u00a0locations\u00a0and remove the\u00a0\/tpus\u00a0from the end which you had included at the StackOverflow thread.\n\nThe Google Cloud Platform Engineer has further suggested you to remove\u00a0nodes\u00a0from the path. i.e. change\u00a0projects\/my-project-id\/locations\/europe-west4-a\/nodes\/\u00a0that is shown at the stack trace to\u00a0projects\/my-project-id\/locations\/europe-west4-a\/."
            },
            {
                "Answer_creation_date":"2022-03-03T23:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi!\n\nAs I answered in the same stackoverflow, it appears that following the recommended parent=projects\/*\/locations\/* (to be 100% clear: without \/nodes\/ ) does not work and gives the error actually shared by the authors.\n\nWe cannot remove a \/nodes\/ that we do not set in the first place.\n\nLibraries version:\ngoogle-api-core 2.6.0\ngoogle-auth 2.6.0\ngoogle-cloud-tpu 1.3.1\ngoogleapis-common-protos 1.55.0"
            },
            {
                "Answer_creation_date":"2022-03-07T13:19:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The Google Cloud Engineer has updated the response along with the code here. Please let us know if you can use the code and whether that works."
            },
            {
                "Answer_creation_date":"2022-03-11T12:21:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, it worked.\n\nWhen cleaning the resources though, there seems to be an issue with the lib:\n\n\u00a0\n\nNAME = f\"projects\/{manifest.tpu.gcpProject}\/locations\/{manifest.tpu.gcpZone}\/nodes\/{manifest.name}\"\n\nclient = tpu_v2alpha1.TpuClient()\n        \nrequest = tpu_v2alpha1.DeleteNodeRequest(\n    name=NAME,\n)\n\n# Make the request\noperation = client.delete_node(request=request)\n\nlogging.info(\"Waiting for operation to complete...\")\nresponse = operation.result()\n\n\u00a0\n\n\nThe TPU VM is successfully deleted, but the python code eventually fails:\n\n\u00a0\n\nCleaning TPU\nWaiting for operation to complete...\nTraceback (most recent call last):\nFile \"\/argo\/staging\/script\", line 29, in <module>\nresponse = operation.result()\nFile \"\/root\/.local\/lib\/python3.9\/site-packages\/google\/api_core\/future\/polling.py\", line 132, in result\nself._blocking_poll(timeout=timeout, **kwargs)\nFile \"\/root\/.local\/lib\/python3.9\/site-packages\/google\/api_core\/future\/polling.py\", line 110, in _blocking_poll\nretry_(self._done_or_raise)(**kwargs)\nFile \"\/root\/.local\/lib\/python3.9\/site-packages\/google\/api_core\/retry.py\", line 283, in retry_wrapped_func\nreturn retry_target(\nFile \"\/root\/.local\/lib\/python3.9\/site-packages\/google\/api_core\/retry.py\", line 190, in retry_target\nreturn target()\nFile \"\/root\/.local\/lib\/python3.9\/site-packages\/google\/api_core\/future\/polling.py\", line 88, in _done_or_raise\nif not self.done(**kwargs):\nFile \"\/root\/.local\/lib\/python3.9\/site-packages\/google\/api_core\/operation.py\", line 170, in done\nself._refresh_and_update(retry)\nFile \"\/root\/.local\/lib\/python3.9\/site-packages\/google\/api_core\/operation.py\", line 159, in _refresh_and_update\nself._set_result_from_operation()\nFile \"\/root\/.local\/lib\/python3.9\/site-packages\/google\/api_core\/operation.py\", line 130, in _set_result_from_operation\nresponse = protobuf_helpers.from_any_pb(\nFile \"\/root\/.local\/lib\/python3.9\/site-packages\/google\/api_core\/protobuf_helpers.py\", line 65, in from_any_pb\nraise TypeError(\nTypeError: Could not convert Any to Node"
            },
            {
                "Answer_creation_date":"2022-03-23T07:40:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"@Mohammad_I\u00a0could you please have a look at my response, I also created a github ticket:\u00a0https:\/\/github.com\/googleapis\/python-tpu\/issues\/92\nIt creates wrong fail warnings in our Pipelines today"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Node hours vs actual time",
        "Question_creation_date":"2022-06-16T01:10:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Node-hours-vs-actual-time\/td-p\/431897\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML",
            "Vertex AI Model Registry"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":153.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"What is meant by node hours in VertexAI?I set the budget in VertexAI AUtoML to a 1 node hour but my model has been training for 1 hr and 30+ minutes. ",
        "Answers":[
            {
                "Answer_creation_date":"2022-06-16T01:10:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"What is meant by node hours in VertexAI?\n\nI set the budget in VertexAI AUtoML to a 1 node hour but my model has been training for 1 hr and 30+ minutes."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"EntityAnalysis, Version 2 model in natural language API",
        "Question_creation_date":"2022-11-17T12:28:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/EntityAnalysis-Version-2-model-in-natural-language-API\/td-p\/490557\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Natural Language API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":162.0,
        "Question_answer_count":5,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,could anyone share the python code on how to get natural language API to use version 2 for Entity  Sentiment Analysis?\nThe Demo can be run for that, but it seems like in the docs this part is missing:\nhttps:\/\/cloud.google.com\/natural-language\/docs\/reference\/rest\/v1\/documents\/analyzeEntitySentiment\n\nHowever, for the classification, it is possible, as it is described here: \nhttps:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Version-2-model-in-natural-language-API\/m-p\/484641\n\nThanks ",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"When using the classifyText method of the API, the classification models are available. However, for Entity Sentiment Analysis there is no mention of available options or models that can be declared. Can you add more details of your use case to review?"
            },
            {
                "Answer_creation_date":"2022-11-22T20:15:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I was using a demo from:\nhttps:\/\/cloud.google.com\/natural-language\n\nAnd here the API provides an example for the V2 of the model, including Entity Analysis for the German\nHowever, when I go to the docs (https:\/\/cloud.google.com\/natural-language\/docs\/reference\/rest\/v1\/documents\/analyzeEntitySentiment)\nI can`t see the option to use V2 model for Entity Analysis, one V1\nHowever, for the Classification Model there is an option:\u00a0https:\/\/cloud.google.com\/natural-language\/docs\/reference\/rest\/v1\/ClassificationModelOptions\n\nSo, my question is: can I use V2 model for the Entity Analysis?\u00a0\nThanks"
            },
            {
                "Answer_creation_date":"2022-11-23T13:50:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The Natural Language API documentation includes all available code samples. Could you direct me to the one you refer to? Most likely there is some clarification to make, as there is no mention of a V2 model that can be used."
            },
            {
                "Answer_creation_date":"2022-11-24T05:46:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I am interested in the:\nhttps:\/\/cloud.google.com\/natural-language\/docs\/samples\/language-entities-text\n\nHowever, I want to use V2 model for Entity Analysis, as it supports German\nIs it possible to use V2 here ?\u00a0\n\nThanks"
            },
            {
                "Answer_creation_date":"2022-11-25T15:17:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"German language support is not available for Entity Sentiment Analysis, as the only listed languages\u00a0for it are English, Japanese, and Spanish. There might have been some confusion with the V2 model for Content Classification, since it includes broader language options. However, this model is only for Content Classification, not for Entity Sentiment Analysis, which offers no such option.\n\nKeep in mind that standalone Sentiment analysis and Entity analysis do offer support for German, in case you need either of those API features instead. As a note, you can raise a Feature Request in Google\u2019s Issue Tracker. It would be brought to the attention of the appropriate teams to implement support in the future; however, there\u2019s no assurance of an ETA."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Vertex AI workbench and Google cloud storage problems accesing files",
        "Question_creation_date":"2022-02-07T05:27:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-workbench-and-Google-cloud-storage-problems-accesing\/td-p\/390712\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":353.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am trying to create a ML project in which the job is a classification task of videos, so I upload those videos in Google cloud storage, and then I create a notebook on the workbench of vertex AI, for making data balancing, and then train my respective ML algorithm. But I have this problem:1. I want to use the video files from GCS without the need of downloading them again(that was the purpose of uploading them in GCS), but I don't know how can i do this?.I also try uploading de videos into the dataset space of the vertex AI workbench but still don't know how to acces to this files without downloading them again.",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"If I'm not mistaken, you simply need to provide a schema file to set the structure and then provide the json input file with the right paths according to the schema file you've uploaded.\nWhat do you mean by this?:\n\nwithout the need of downloading them again\n\nI'm not aware of any requirement to download a file in order to use it in Vertex AI, the learning algorithm should access the files on Cloud Storage and use them as needed."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Unable to use audio to text transcribe",
        "Question_creation_date":"2022-03-20T00:44:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Unable-to-use-audio-to-text-transcribe\/td-p\/405132\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text",
            "Text-to-Speech"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":97.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am new to this Google Audio transcription and I have set up the whole Google Free Trial thing and I have tried to use the function of Google's Audio to Speech transcript and well so far my customer experience has been so hard.  I have two files and *.mpa and a *.mp4 file and no matter what i do i keep getting an error that it cannot transcribe.Can someone  please help me with this.  Here are the errors I am getting.",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-31T23:38:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You can try another variant of\u00a0audio transcription -Audext.\u00a0I like that the software supports various audio file formats like Mp3, WAV, and M4A and it allows editing of the transcript."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Deploying AutoML tabular model changes feature column types to text",
        "Question_creation_date":"2022-03-15T03:21:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Deploying-AutoML-tabular-model-changes-feature-column-types-to\/td-p\/403658\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":1.0,
        "Question_view_count":49.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I\u2019ve trained an AutoML tabular model using a pretty simple CSV file of numeric data. When I ran the training I ensured each feature column was set as numeric. When viewing the column meta data of the trained model, all columns show as numeric. However, when I deploy the model they all show as text and will only accept strings. What am I doing wrong?",
        "Answers":[
            {
                "Answer_creation_date":"2022-04-29T07:33:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The possible cause may be the incorrect format of the used data type .You can find some examples of the the valid and invalid numeric formats in documentation [1] that can be used in AutoML Tables dataset.\n\n[1] https:\/\/cloud.google.com\/automl-tables\/docs\/data-types#numeric"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How can I avoid being charged for Tensorboard?",
        "Question_creation_date":"2021-12-21T12:22:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-can-I-avoid-being-charged-for-Tensorboard\/td-p\/180658\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":2.0,
        "Question_view_count":331.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Today I received an email from GCP saying that my account will be charged for using Vertex AI Tensorboard from February. It is quite expensive and I want to stop using the service and avoid being charged.How can I do that? There is no option for Tensorboard in the API dashboard (just one for Vertex AI generally). I only have \"basic support\" so I cannot contact technical support, and I am not the billing administrator so I cannot contact billing support. Is there any way I can disable Tensorboard?Thank you.",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-23T12:57:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nThanks for reaching out regarding Vertex AI TensorBoard pricing, and disabling the service.\u00a0\n\nTensorBoard is currently free of charge as it is a preview product. Vertex AI will launch a new generally available (GA) pricing model for Vertex AI TensorBoard in February 2022, as you mentioned, which will be charged per user, per month.\u00a0\n\n\n\n=> You will be charged for a user if they view the Vertex AI TensorBoard webapp during a given billing period, and the VertexAI product teams plan will be to have this gated by a custom IAM role.\u00a0\n\n=> Given that Tensorboard is part of the VertexAI API, it cannot be disabled without also disabling\u00a0all of VertexAI. It may however be possible to avoid\u00a0being charged by setting all the TensorBoard quotas to zero in the Google Cloud Platform Quotas page [1], and restricting\u00a0what users get assigned\u00a0the IAM role once it is available.\n\n\u00a0\n\n[1] GCP quotas:\u00a0console.cloud.google.com\/iam-admin\/quotas"
            },
            {
                "Answer_creation_date":"2021-12-23T14:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I think I have a super user role, so it sounds like I should set the quotas to zero when they become available. Thank you slando."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Feature Store Calculations",
        "Question_creation_date":"2022-05-12T13:49:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Feature-Store-Calculations\/td-p\/422580\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML",
            "Vertex AI Model Registry"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":57.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,I have a Google Colab notebook with some functions (Python) that been used to calculate the features for a model.The functions use as inputs data from an API.The question is if I can or should calculate the features inside a Features Store and feed the results to the Model?Or in which Instance do I need to make the calculations and then feed the results into the model?",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-17T11:05:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"It is possible to use Vertex AI Features Store to Fetch the data, so you can use it as a part of the Vertex AI Workflow to train Custom or AutoML models in Vertex.\n\nYou can see here[1] the Vertex AI workflow.\n\n[1]https:\/\/cloud.google.com\/vertex-ai\/docs\/beginner\/beginners-guide#workflow"
            },
            {
                "Answer_creation_date":"2022-05-17T13:04:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for your comments\n\nAfter reading the documents, I understand that the data that should be\nstored in the Feature Store is \"static data\".\n\nBy static I mean data from previously loaded databases and not calculated\nwithin the Feature Store.\n\nFor example I wanted to add a simple average of the last 30 data entries\nobtained from an API that sends data in real time in 5 minute intervals I\nshould::\n\nConnect the API to the feature Store, store each data entry from the API\nand then calculate the average inside the Feature Store?\n\nOr should I connect the API to Goolge BiGQuery, store the data in Google\nBigQuery, calculate the average and then send the data to the model deploy\nin the end point?\n\nOr connect a google colab notebook to the API, perform the calculations,\nupload the Notebook to a container and send the data to the endpoint in\nwhich the model was deployed?\n\nAnce again thanks for your help"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"ML",
        "Question_creation_date":"2021-11-12T04:50:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/ML\/td-p\/175533\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML",
            "Cloud Natural Language API",
            "Contact Center AI",
            "Document AI",
            "Recommendations AI"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":311.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"How to start my journey for being an ML\/AI or data science engineer?",
        "Answers":[
            {
                "Answer_creation_date":"2021-11-12T04:50:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"How to start my journey for being an ML\/AI or data science engineer?"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Vision AI labels",
        "Question_creation_date":"2022-05-12T13:17:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vision-AI-labels\/td-p\/422564\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":48.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Where can I find list of all labels what could be detected in Vision AI ?",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You can read this documentation\u00a0about labels with Vision AI."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Google Translation issue",
        "Question_creation_date":"2022-10-28T08:27:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Translation-issue\/td-p\/483154\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":205.0,
        "Question_answer_count":5,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello Team,I am trying to document translation using Google cloud translate V3.I found some issue in below-1. Text Overlapping from German to English2.Some text position was not correct3.table column name show in bottom of pages.4.Some pages were not being Translate. ",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-31T16:35:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Can you please share more information about your project and the process that you are following ?"
            },
            {
                "Answer_creation_date":"2022-11-03T00:20:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nWe are using google translate cloud Service V3 with \"BatchDocumentService\".\n\nFirst Image is in German Language and Second Image is translate into english but you can see Text overlapping in below-"
            },
            {
                "Answer_creation_date":"2022-11-08T00:53:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello Team,\n\nAny update from your side ,it is really urgent."
            },
            {
                "Answer_creation_date":"2022-11-15T22:45:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello Team,\n\nAny update?"
            },
            {
                "Answer_creation_date":"2022-11-23T12:02:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Following this process using projects.translateText Method on Cloud Translation API, the translation worked fine.\n\nIn order to better understand how we might assist, please provide more details about how you are utilizing the Cloud Translation API if this behavior seems unique to your use-case and implementation. You may, for instance, let us know what version of the Translation API is being used. Aside from that, consider the translation process you're using. Tell us how you are gathering the data; is it through a web user interface?"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Vertex AI endpoint deployment",
        "Question_creation_date":"2022-11-04T04:53:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-endpoint-deployment\/td-p\/485783\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML",
            "Video Intelligence API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":77.0,
        "Question_answer_count":4,
        "Question_has_accepted_answer":false,
        "Question_body":"How can I utilize the mega GPU during endpoint deployment  for vertex ai work? Are there any model for examples or other resources that I can use to better grasp this?",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-07T11:00:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"What kind of model are you deploying on the endpoint? Can you clarify on what you mean in this statement \"utilizing the GPU during endpoint deployment\"?"
            },
            {
                "Answer_creation_date":"2022-11-08T00:25:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thank you for responding. It is a simple tensorflow tabular classification model, and deployment takes about 18-20 minutes after model registration. I decided to use a mega GPU since I want to shorten this time as much as I can; perhaps this decision will shorten the time for deployment."
            },
            {
                "Answer_creation_date":"2022-11-08T09:25:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thank you for clarifying. As far as I know the deployment of an endpoint is handled at the backend of GCP so it is not possible to use a GPU in order to shorten the deployment time."
            },
            {
                "Answer_creation_date":"2022-11-08T11:45:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"okay thanks , but when I use another account for the same , it's done within 2-3 min only !!!!"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Short polish inputs recognized but not returned by ASR.",
        "Question_creation_date":"2022-09-22T01:19:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Short-polish-inputs-recognized-but-not-returned-by-ASR\/td-p\/469439\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX",
            "Speech-to-Text"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":36.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"For some languages STT engine requires a longer time to decide the end of a single utterance, so you could use some Fast recognition."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Where is Visual Inspection AI?",
        "Question_creation_date":"2022-01-04T06:23:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Where-is-Visual-Inspection-AI\/td-p\/181914\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":179.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Does anybody know where to get started with the Visual Inspection AI?  It has been advertised for more than 6 months, but I cannot find where it is available.   The landing page is here: https:\/\/cloud.google.com\/solutions\/visual-inspection-ai  However, it has never shown up in my Google Cloud Platform Console. ",
        "Answers":[
            {
                "Answer_creation_date":"2022-01-17T08:26:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"It involves the analysis of products on the production line for quality control. Visual inspection can also be used for internal and external assessment of the various equipment in a production facility, such as storage tanks, pressure vessels, piping, and other equipment.\nArtificial intelligence (AI) is one of the most exciting and fastest-growing fields in computer science. If you're starting to learn about it, you'll need a solid E-Learning Platform by Edureka. This is an Artificial Intelligence course program accredited by E&ICT academy, NIT Warangal, India."
            },
            {
                "Answer_creation_date":"2022-02-02T16:09:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I think you should ask Google's sales team."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Run Colab with Mulitple GPUs using Drive Files OR workaround",
        "Question_creation_date":"2022-07-18T15:30:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Run-Colab-with-Mulitple-GPUs-using-Drive-Files-OR-workaround\/td-p\/444346\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":312.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,I am trying to run my ML model in Colab utilizing a custom VM with multiple GPUs. I can successfully spin up a 2 GPU DeepLearning VM and connect to a Colab notebook via port-forwarding to a locally-hosted connection (Jupyter Notebook), as shown here.Although I can connect to custom runtimes directly WITHOUT port-forwarding to a locally-hosted connection, I can only access 1 of the 2 GPUs this way (i.e. I can successfully connect to a locally-hosted, port-forwarded runtime and verify that the notebook can access the 2 GPUs; however I am running into issues when trying to mount my Google Drive.I know that ocamlfuse was offered as a suggestion to this Drive issue,  however, none of the download options work. Specifically, it seems like a locally-hosted port-forwarded runtime doesn't allow terminal inputs, so I can't \"Press [ENTER]\" to allow the download, as shown below:User import cursor shows up for a direct connection to a custom or hosted runtime:User import cursor fails to show up\/accept inputs in a locally-hosted, port-forwarded custom VM.In general, it seems like terminal commands don't work in Colab in a locally-hosted runtime.  Another option is PyDrive, which I've used in the past. However, since PyDrive relies on authentication through a local port, I can't get it to work on my locally-hosted custom VM.In short I'm looking for tips\/suggestions for any of the following issues:1) An alternative workflow to run my ML model using multiple GPUs (i.e. that's not through port-forwarding to a locally-hosted connection)2) How to get that user cursor to show up (enabling me to download ocamlfuse)3) How to authenticate in PyDrive, given I'm already using a local port connection to host my runtime.4) Alternatives to accessing my Drive\/Drive files.  Thank you so much!     ",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-18T15:30:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nI am trying to run my ML model in Colab utilizing a custom VM with multiple GPUs. I can successfully spin up a 2 GPU DeepLearning VM and connect to a Colab notebook via port-forwarding to a locally-hosted connection (Jupyter Notebook), as shown here.\n\nAlthough I can connect to custom runtimes directly WITHOUT port-forwarding to a locally-hosted connection, I can only access 1 of the 2 GPUs this way (i.e.\u00a0\n\nlen(tf.config.list_physical_devices('GPU')) always returns 1); hence, I'm tied to port-forwarding, unless there's an alternative option.\n\nI can successfully connect to a locally-hosted, port-forwarded runtime and verify that the notebook can access the 2 GPUs; however I am running into issues when trying to mount my Google Drive.\n\nI know that ocamlfuse was offered as a suggestion to this Drive issue,\u00a0 however, none of the download options work. Specifically, it seems like a locally-hosted port-forwarded runtime doesn't allow terminal inputs, so I can't \"Press [ENTER]\" to allow the download, as shown below:\n\nUser import cursor shows up for a direct connection to a custom or hosted runtime:\n\nUser import cursor fails to show up\/accept inputs in a locally-hosted, port-forwarded custom VM.\n\nIn general, it seems like terminal commands don't work in Colab in a locally-hosted runtime.\n\n\u00a0\n\n\u00a0\n\nAnother option is\u00a0PyDrive, which I've used in the past. However, since\u00a0PyDrive\u00a0relies on authentication through a local port, I can't get it to work on my locally-hosted custom VM.\n\nIn short I'm looking for tips\/suggestions for any of the following issues:\n\n1) An alternative workflow to run my ML model using multiple GPUs (i.e. that's not through port-forwarding to a locally-hosted connection)\n\n2) How to get that user cursor to show up (enabling me to download\u00a0ocamlfuse)\n\n3) How to authenticate in PyDrive, given I'm already using a local port connection to host my runtime.\n\n4) Alternatives to accessing my Drive\/Drive files.\u00a0\n\n\u00a0\n\nThank you so much!"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Getting started DialogFlow CX",
        "Question_creation_date":"2022-09-24T12:41:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Getting-started-DialogFlow-CX\/td-p\/470603\/jump-to\/first-unread-message",
        "Question_topic":[
            "Contact Center AI",
            "Dialogflow CX"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":51.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Looking into starting a project using DialogFlow CX. Seems rather promising but have one issue I cannot seem to find an answer for. The agent will be connected to via IVR (from Flex\/Callcenter). I need to gather some information on start so that I can identify the hotel\/property that will be referenced in the conversation.  I found session parameters but those are isolated to the session from start to finish but not passed to the start of a session. We are starting with about 60 properties and when the agent starts, it needs to \"know\" what property it is dealing with. Another quick question - will I need a separate telephony integration number to run multiple concurrent instances? I am really new to all this so my language may be off. Thanks in advance!!Robert ",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-24T13:28:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Howdy Robert,\n\nI think the answer to the puzzle will be to look in detail at how the integration from your IVR to DialogFlow will happen.\u00a0 From what I can tell, at the DialogFlow API level, there is a call called \"detectIntent\" ... this is where the audio\/text is passed in and the DialogFlow engine processes a part of the conversation.\u00a0 Looking at the API we find:\n\nhttps:\/\/cloud.google.com\/dialogflow\/cx\/docs\/reference\/rest\/v3\/projects.locations.agents.environments...\n\nwhich has a query parameters set of options.\u00a0 That all said, can you explain some more about how you see the overall flow happening?\u00a0 Will the hotel\/property be somehow passed in before the call or will the identification of the hotel be part of the start of the conversation?\u00a0 Depending on your overall goals, you might also consider contacting Google Cloud sales.\u00a0 They will always be delighted to hear from a prospective customer and be able to guide you on how to understand and get assistance with CCAI.\u00a0 \u00a0It is also possible that your IVR supplier may be able to offer assistance and have an existing relationship with Google Cloud for services and support."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Get Cloud Vision API as good as Google Lens",
        "Question_creation_date":"2022-06-24T13:24:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Get-Cloud-Vision-API-as-good-as-Google-Lens\/td-p\/434624\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":375.0,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"As part of a student team, I am building a system to classify used shoes.I know that Google Lens is doing a really good job here.I came across Google Cloud Vision API (which should be a similar thing) and implemented this in python.For clean, well-angled images like this Air Force One:  I am getting really promising results:If however, i input real-world images like this old used Nike Tanjun:  Things fall apart:But if I upload the image to google lens, I could still figure out the right label:  Logo detection (Nike) almost always works. And using this, I could for example search after the most often occurring word after the Logo (Tanjun) to figure out the model.It must be mentioned that the data of our system will be better than that, there will be multiple images taken from different angles and very good lighting conditions.Now i am trying to figure out how toEITHER: Get Vision API working in the same way as Google LensOR: Acces Google Lens data in a somehow convenient way (should in the best case run from a raspberry pi)   ",
        "Answers":[
            {
                "Answer_creation_date":"2022-06-26T05:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"push. I urgently need help."
            },
            {
                "Answer_creation_date":"2022-10-06T02:13:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I'm in the same shoes. The real answer is, the API does not work so well."
            },
            {
                "Answer_creation_date":"2022-11-01T23:18:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, i'm facing the same problem, do you find any solution to it?"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Issues with Handover Protocols - Facebook & Dialogflow",
        "Question_creation_date":"2021-09-29T18:02:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Issues-with-Handover-Protocols-Facebook-amp-Dialogflow\/td-p\/171609\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":343.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"",
        "Answers":[
            {
                "Answer_creation_date":"2021-09-29T18:02:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"We're currently experiencing an ongoing issue where Bot conversations in our Facebook inbox are moving from \u2018Main\u2019 to \u2018Done\u2019 without any manual agent involvement. This means that conversations being escalated to the Main folder from the Bot will revert to the Done folder and the Bot will answer again.\n\u00a0\nOnce the conversation with the bot has been escalated to a human, there should be no further Bot involvement.\n\u00a0\nThis issue originally started after we noticed a failed payment on our Dialogflow account, where we went in, updated payment information and successfully charged the card to resume services. However, once we initiated a few test conversations, we noticed the above.. any advice or suggestions?"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"AutoML Tables for model where comparison is required?",
        "Question_creation_date":"2021-09-29T05:05:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/AutoML-Tables-for-model-where-comparison-is-required\/td-p\/171520\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":361.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi there,I have used GCP for a while now, and have trained quite a few models using AutoML Tables - all of these have been fairly simple datasets with probably a maximum of 20 columns. I now have a problem that I would like to solve, but the dataset is a lot more complicated. I want to be able to predict the results of Greyhound Racing, or at least the % chances of each Greyhound winning a given race, compared to the other greyhounds running in that same race. To be able to do this I need to feed multiple pieces of data for each Greyhound in each given race, to be able to predict the winning chance of that greyhound in that day's race.However, I am very stuck on how to structure my data. Using AutoML Tables - would I need to structure the data in a tabular form with many columns? Or is there a better way to tackle this problem.Here is an example of the data I would be using:Race:Example data for each Greyhound in the race: Does anyone please have any advice of how to tackle this kind of problem, and how best to structure the data to attempt to predict the winning chance of each Greyhound for that day's race, based on that greyhound's previous data, compared to the other greyhounds in that day's race? Thanks,\nRob",
        "Answers":[
            {
                "Answer_creation_date":"2021-10-16T08:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, this is tabular data and hence has to be structured as a tabular data. I know this will call for lot of data prep work."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Dialogflox cx conflict: \"intents matching\" and \"parameters form\" at the same page.",
        "Question_creation_date":"2022-11-15T05:55:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Dialogflox-cx-conflict-quot-intents-matching-quot-and-quot\/td-p\/489582\/jump-to\/first-unread-message",
        "Question_topic":[
            "Contact Center AI",
            "Dialogflow CX",
            "Document AI"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":67.0,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello everyone,I found an unexpected behavior with the following page-level configuration.CONFLICT: After the question \"What do you want? \", if the user input is not clear there will not be any intent matching, but if the user include in the sentence the word \"Value1\" which is synonym of \"Entity1\", then the parameter \"intent_param\" (entity type \"@intent\") will be collected with value \"Entity1\". When this happens I was expecting \"sys.no-match-1\" to be activated, but this did not occurred and the page state status is \"PROCESSING_FORM\" (FormFilled: false).Does anyone knows why this happens and if is there a way to avoid this behavior? In this situation I would like to continue the workflow with the  parameter collected and no intents matched.Thank you,\nMiguel.",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-15T15:25:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Can you provide an example of\u00a0Value1? It would also help if you provide the whole response for investigation purposes."
            },
            {
                "Answer_creation_date":"2022-11-16T06:46:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello, this would be an example for the previous explanation:\n\nEntity type:\nEntity1: Tarjetas\nSynonyms: \"Tarjetas\", \"Cart\u00f3n\", \"Pl\u00e1stico\"\n\nPage (not start page):\n- Agent Fulfillment: \"What do you want?\"\n- Required\/Not required Parameter: \"intent_param\" (I said required in the previous explanation, in both cases I can't achieve what I was expecting)\n- Some intent Routes\n- Event handler (\"sys.no-match-1\")\n\nUser input: \"Pl\u00e1stico\"\n\nThe behavior which I was expecting is that Agent tried to match any of the intents and:\n1. If match, activates the corresponding intent route\n2. If no-match, activates the\u00a0\"sys.no-match-1\" event handler\n\nAnd I also expected that simultaneously, if the input matches with the Entity\/Synonym, the parameter was also collected and mapped with the corresponding entity.\n\nSummarizing, is it possible to collect a parameter (map entity type) and try to match intents, with one unique user input at the same time?\n\nResponse for Required parameter (Parameter is collected but event handler is not activated):\n\n{\n  \"advancedSettings\": {\n    \"audioExportGcsDestination\": {},\n    \"loggingSettings\": {\n      \"enableInteractionLogging\": true\n    },\n    \"speechSettings\": {\n      \"endpointerSensitivity\": 90,\n      \"noSpeechTimeout\": \"5s\"\n    }\n  },\n  \"currentPage\": {\n    \"displayName\": \"Prueba params\",\n    \"name\": \"projects\/dev-bbva-dialogflow-poc\/locations\/us-central1\/agents\/57dc60ad-5e59-4913-9c5a-dcef53842159\/flows\/9aecdd7b-3a57-4342-aaf9-caf3f2c6a9f8\/pages\/5409aed3-7c85-47a8-aa87-2a84947d8b5d\"\n  },\n  \"diagnosticInfo\": {\n    \"Alternative Matched Intents\": [\n      {\n        \"Score\": 1,\n        \"Active\": true,\n        \"Parameters\": {\n          \"intent_param\": {\n            \"resolved\": \"REDACTED\",\n            \"original\": \"REDACTED\",\n            \"type\": \"@resolve_intent\"\n          }\n        },\n        \"Type\": \"NLU_SLOT\"\n      }\n    ],\n    \"Transition Targets Chain\": [],\n    \"Session Id\": \"19db1e-467-50c-8d4-69fdb3e1a\",\n    \"Triggered Transition Names\": [],\n    \"Execution Sequence\": [\n      {\n        \"Step 1\": {\n          \"InitialState\": {\n            \"SessionParameters\": {\n              \"intent_param\": \"REDACTED\"\n            },\n            \"MatchedIntent\": {\n              \"Active\": true,\n              \"Parameters\": {\n                \"intent_param\": {\n                  \"resolved\": \"REDACTED\",\n                  \"type\": \"@resolve_intent\",\n                  \"original\": \"REDACTED\"\n                }\n              },\n              \"Type\": \"NLU_SLOT\",\n              \"Score\": 1\n            },\n            \"FlowState\": {\n              \"Name\": \"Prueba params\",\n              \"FlowId\": \"9aecdd7b-3a57-4342-aaf9-caf3f2c6a9f8\",\n              \"Version\": 0,\n              \"PageState\": {\n                \"Name\": \"Prueba params\",\n                \"ActiveParameter\": \"intent_param\",\n                \"PageId\": \"5409aed3-7c85-47a8-aa87-2a84947d8b5d\",\n                \"FormFilled\": false,\n                \"Status\": \"PROCESSING_FORM\"\n              }\n            }\n          },\n          \"Type\": \"INITIAL_STATE\"\n        }\n      },\n      {\n        \"Step 2\": {\n          \"StateMachine\": {\n            \"FlowState\": {\n              \"Name\": \"Prueba params\",\n              \"Version\": 0,\n              \"PageState\": {\n                \"PageId\": \"5409aed3-7c85-47a8-aa87-2a84947d8b5d\",\n                \"FormFilled\": true,\n                \"Name\": \"Prueba params\",\n                \"Status\": \"TRANSITION_ROUTING\"\n              },\n              \"FlowId\": \"9aecdd7b-3a57-4342-aaf9-caf3f2c6a9f8\"\n            }\n          },\n          \"Type\": \"STATE_MACHINE\"\n        }\n      }\n    ]\n  },\n  \"intentDetectionConfidence\": 1,\n  \"languageCode\": \"es\",\n  \"match\": {\n    \"confidence\": 1,\n    \"matchType\": \"PARAMETER_FILLING\",\n    \"parameters\": {\n      \"intent_param\": \"Tarjetas\"\n    },\n    \"parametersOriginalValues\": {\n      \"intent_param\": \"Pl\u00e1stico\"\n    },\n    \"resolvedInput\": \"Pl\u00e1stico\"\n  },\n  \"parameters\": {\n    \"intent_param\": \"Tarjetas\"\n  },\n  \"redactedParameters\": [\n    \"intent_param\"\n  ],\n  \"responseMessages\": [\n    {\n      \"interactiveVoiceResponseSettings\": {\n        \"audioExportGcsDestination\": {},\n        \"speechSettings\": {\n          \"endpointerSensitivity\": 90,\n          \"noSpeechTimeout\": \"5s\"\n        }\n      }\n    }\n  ],\n  \"text\": \"Pl\u00e1stico\"\n}\n\n\u00a0Response for no roquired parameter (Event handler is activated, but no parameter is collected):\n\n{\n  \"advancedSettings\": {\n    \"audioExportGcsDestination\": {},\n    \"loggingSettings\": {\n      \"enableInteractionLogging\": true\n    },\n    \"speechSettings\": {\n      \"endpointerSensitivity\": 90,\n      \"noSpeechTimeout\": \"5s\"\n    }\n  },\n  \"currentPage\": {\n    \"displayName\": \"End Session\",\n    \"name\": \"projects\/dev-bbva-dialogflow-poc\/locations\/us-central1\/agents\/57dc60ad-5e59-4913-9c5a-dcef53842159\/flows\/9aecdd7b-3a57-4342-aaf9-caf3f2c6a9f8\/pages\/END_SESSION\"\n  },\n  \"diagnosticInfo\": {\n    \"Execution Sequence\": [\n      {\n        \"Step 1\": {\n          \"InitialState\": {\n            \"Event\": \"sys.no-match-1\",\n            \"FlowState\": {\n              \"PageState\": {\n                \"Name\": \"Prueba params\",\n                \"Status\": \"TRANSITION_ROUTING\",\n                \"PageId\": \"5409aed3-7c85-47a8-aa87-2a84947d8b5d\",\n                \"FormFilled\": true\n              },\n              \"FlowId\": \"9aecdd7b-3a57-4342-aaf9-caf3f2c6a9f8\",\n              \"Name\": \"Prueba params\",\n              \"Version\": 0\n            }\n          },\n          \"Type\": \"INITIAL_STATE\"\n        }\n      },\n      {\n        \"Step 2\": {\n          \"Type\": \"STATE_MACHINE\",\n          \"FunctionExecution\": {\n            \"Responses\": [\n              {\n                \"responseType\": \"HANDLER_PROMPT\",\n                \"text\": {\n                  \"redactedText\": [\n                    \"No se a qu\u00e9 te refieres ex\u00e1ctamente, pero tiene que ver con $session.params.intent_param\"\n                  ],\n                  \"text\": [\n                    \"No se a qu\u00e9 te refieres ex\u00e1ctamente, pero tiene que ver con $session.params.intent_param\"\n                  ]\n                },\n                \"source\": \"VIRTUAL_AGENT\"\n              }\n            ]\n          },\n          \"StateMachine\": {\n            \"FlowState\": {\n              \"Name\": \"Prueba params\",\n              \"PageState\": {\n                \"PageId\": \"5409aed3-7c85-47a8-aa87-2a84947d8b5d\",\n                \"Name\": \"Prueba params\",\n                \"FormFilled\": true,\n                \"Status\": \"TRANSITION_ROUTING\"\n              },\n              \"Version\": 0,\n              \"FlowId\": \"9aecdd7b-3a57-4342-aaf9-caf3f2c6a9f8\"\n            },\n            \"TriggeredEvent\": \"sys.no-match-1\",\n            \"TriggeredEventHandlerId\": \"f6760455-fb9b-49fb-acae-69142ec33188\"\n          }\n        }\n      },\n      {\n        \"Step 3\": {\n          \"StateMachine\": {\n            \"FlowState\": {\n              \"FlowId\": \"9aecdd7b-3a57-4342-aaf9-caf3f2c6a9f8\",\n              \"PageState\": {\n                \"Name\": \"End Session\",\n                \"PageId\": \"END_SESSION\",\n                \"Status\": \"ENTERING_PAGE\"\n              },\n              \"Name\": \"Prueba params\",\n              \"Version\": 0\n            }\n          },\n          \"Type\": \"STATE_MACHINE\"\n        }\n      }\n    ],\n    \"Alternative Matched Intents\": [],\n    \"Session Id\": \"946ef0-346-0ee-be7-ec290fb95\",\n    \"Unfulfilled Parameters\": [\n      \"$session.params.intent_param\"\n    ],\n    \"Transition Targets Chain\": [\n      {\n        \"TargetPage\": \"END_SESSION\"\n      }\n    ],\n    \"Triggered Transition Names\": [\n      \"f6760455-fb9b-49fb-acae-69142ec33188\"\n    ]\n  },\n  \"intentDetectionConfidence\": 0.3,\n  \"languageCode\": \"es\",\n  \"match\": {\n    \"confidence\": 0.3,\n    \"event\": \"sys.no-match-1\",\n    \"matchType\": \"NO_MATCH\"\n  },\n  \"responseMessages\": [\n    {\n      \"responseType\": \"HANDLER_PROMPT\",\n      \"source\": \"VIRTUAL_AGENT\",\n      \"text\": {\n        \"redactedText\": [\n          \"No se a qu\u00e9 te refieres ex\u00e1ctamente, pero tiene que ver con $session.params.intent_param\"\n        ],\n        \"text\": [\n          \"No se a qu\u00e9 te refieres ex\u00e1ctamente, pero tiene que ver con $session.params.intent_param\"\n        ]\n      }\n    },\n    {\n      \"interactiveVoiceResponseSettings\": {\n        \"audioExportGcsDestination\": {},\n        \"speechSettings\": {\n          \"endpointerSensitivity\": 90,\n          \"noSpeechTimeout\": \"5s\"\n        }\n      }\n    },\n    {\n      \"endInteraction\": {}\n    }\n  ],\n  \"text\": \"Pl\u00e1stico\"\n}"
            },
            {
                "Answer_creation_date":"2022-11-18T08:45:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"This seems to be not reproducible on my end.\u00a0If you have premium support, you can check with\u00a0GCP Support\u00a0to further check your issue since this is specific to your project."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Confirmation page \/ custom text",
        "Question_creation_date":"2022-10-22T03:23:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Confirmation-page-custom-text\/td-p\/480915\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "Dialogflow CX"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":36.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi All,I'm just migrating over from AWS to CX, and so far I think its great. However - the tutorial section I'm working through kind of hit a 'draw the rest of the owl' meme - if you don't know it, look it up.The difficult bit is where it gets to 'confirmation page' in the quick start - here: ",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-25T13:34:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"In order to fulfill the create confirmation page step, you could follow the instructions given in the Create the location page section.\n\nIn order to get the example working, please double check that all steps are completed and the variable names are the same as used in order to test the completed agent.\n\nThis article could be helpful to create A Conversational Agent with Dialogflow.\n\nSome important concepts used in the quickstart:\n\nIntent\nParameters\nEntity types\nSession parameters\nConditions"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Recover deleted Vertex AI resources",
        "Question_creation_date":"2022-03-22T22:23:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Recover-deleted-Vertex-AI-resources\/td-p\/405934\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":210.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,In order to save on billing, I deleted most of the resources in the data sources, workbench, pipelines in Vertex AI.Is there a way I can recover them??",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-22T22:23:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nIn order to save on billing, I deleted most of the resources in the data sources, workbench, pipelines in Vertex AI.\n\nIs there a way I can recover them??"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Being told to contact Vertex AI support but we don't have a support contract?!",
        "Question_creation_date":"2022-03-08T11:34:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Being-told-to-contact-Vertex-AI-support-but-we-don-t-have-a\/td-p\/401449\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":51.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Getting an internal error when training a model on Vertex AI.I have gotten repeated emails from Google telling me to contact Vertex AI support about this.We don't pay for a support contract.It seems odd that there is no way to report issues like this to Vertex AI without a support contract.",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-08T11:34:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Getting an internal error when training a model on Vertex AI.\n\nI have gotten repeated emails from Google telling me to contact Vertex AI support about this.\n\nWe don't pay for a support contract.\n\nIt seems odd that there is no way to report issues like this to Vertex AI without a support contract."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Vision API - Text detection training",
        "Question_creation_date":"2022-01-05T03:59:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vision-API-Text-detection-training\/td-p\/182002\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":75.0,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi there,I'd like to train my Vision Project to improve document text detection for manuscript books. I couldn't find the solution anywhere. The current result is awful. The language is Portuguese.Please advise. Thanks.",
        "Answers":[
            {
                "Answer_creation_date":"2022-01-10T06:49:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\u00a0\n\nI hope I understand your concern. The issue seems to be about the Quality of the result observed.\u00a0\n\nCould you give more insights and details on what you observed? As per this doc[0], Portuguese is one of the Supported languages by the Cloud Vision API's text recognition feature. So, if the result is not what you expected, perhaps sharing more info about your use-case, your image\/file and the output observed, will help to understand how we could help.\u00a0You can share a screenshot as an example, while describing what you observed and what you expected.\n\n\u00a0\n\n[0]https:\/\/cloud.google.com\/vision\/docs\/languages"
            },
            {
                "Answer_creation_date":"2022-01-10T06:50:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Please ensure that whatever Documents or Screenshots added to this thread does not include PII or SPII.\u00a0\n\nThank you."
            },
            {
                "Answer_creation_date":"2022-01-10T12:49:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Oakinlaja,\n\nThanks for replying. I'm sending to you my code, image file and result. It does not include PII or SPII. Please advise.\nhttps:\/\/1drv.ms\/u\/s!Ap4FzqZLgHXGpYlNTp8Y8Q6eP_7jiw?e=3tGSIx"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Dialogflow cx caller abandoned call event",
        "Question_creation_date":"2022-10-26T05:13:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Dialogflow-cx-caller-abandoned-call-event\/td-p\/482361\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_tag":null,
        "Question_upvote_count":2.0,
        "Question_view_count":98.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Is there a way to trigger a webhook, as soon as the caller abandons the call?",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Currently working with your question."
            },
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"In regards to your main question, the best option would be to create a Cloud Function. You can actually review the Quickstart: Create a webhook.\n\nWhen the call ends, there must be some variable that you can grab to start the function.\n\nIf we get more information for your main issue, it will be shared with you as soon as possible."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Voice\/language options during conversion of long text files to speech",
        "Question_creation_date":"2021-08-02T19:55:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Voice-language-options-during-conversion-of-long-text-files-to\/td-p\/165947\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":375.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"The voice\/language options during conversion of long text files to speech. Can anyone help with the doc\/sample for the same.",
        "Answers":[
            {
                "Answer_creation_date":"2021-08-03T15:53:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Howdy Ram56.\u00a0 Could you perhaps elaborate on what you are looking for?\u00a0 We'll be delighted to try and assist.\u00a0\u00a0\n\nHere is the home page for the GCP Text To Speech materials with links to docs:\n\nhttps:\/\/cloud.google.com\/text-to-speech\n\nI fully realize that is a fluffy response ... so if you can add a little more detail to the voice\/language query in your question, we'll get back to you ASAP.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2021-08-03T15:53:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Howdy Ram56.\u00a0 Could you perhaps elaborate on what you are looking for?\u00a0 We'll be delighted to try and assist.\u00a0\u00a0\n\nHere is the home page for the GCP Text To Speech materials with links to docs:\n\nhttps:\/\/cloud.google.com\/text-to-speech\n\nI fully realize that is a fluffy response ... so if you can add a little more detail to the voice\/language query in your question, we'll get back to you ASAP."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Vertex AI dataset permissions",
        "Question_creation_date":"2021-09-20T07:15:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-dataset-permissions\/td-p\/170536\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":432.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Is there a way to assign IAM roles to datasets in Vertex AI so only certain people have access to certain datasets?",
        "Answers":[
            {
                "Answer_creation_date":"2021-09-20T07:15:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Is there a way to assign IAM roles to datasets in Vertex AI so only certain people have access to certain datasets?"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to use Recommendations AI(Retail API) for multiple stores?",
        "Question_creation_date":"2022-10-12T04:51:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-use-Recommendations-AI-Retail-API-for-multiple-stores\/td-p\/477225\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML",
            "Recommendations AI"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":39.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi Guys,We are trying to build an e-commerce personalized recommendation system. we want to make it worthwhile for our clients.  We are trying to use the recommendations API(retail API) for multiple e-commerce stores. But in the retail API, it seems we can use retail API under one project per store. Importing catalogs, creating models, and getting recommendations are only applicable to a single store under one project.One solution is to create separate projects per store only to use retail API, which is not the right way for numerous customers.So, is there any way to do this or any other GCP service that we can go for? Please suggest. Thanks in advance.",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-14T11:13:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"If you are currently working to build an e-commerce system, one suggestion as an alternative GCP service is to follow the Building an e-commerce recommendation system by using BigQuery ML.\n\n\nAdditionally, here is a guide written by Polong Lin\u00a0using the documentation referred above."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to disable TLS 1.0 and 1.1 in dialogflow?",
        "Question_creation_date":"2022-09-16T08:32:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-disable-TLS-1-0-and-1-1-in-dialogflow\/td-p\/467528\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":32.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Need to disable TLS 1.0 and 1.1 for oauth api and events api in the dialogflow. We get those apis while integrating with slack.",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-16T08:32:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Need to disable TLS 1.0 and 1.1 for oauth api and events api in the dialogflow. We get those apis while integrating with slack."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Document AI fails for one particular image, else works great",
        "Question_creation_date":"2022-05-02T13:25:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Document-AI-fails-for-one-particular-image-else-works-great\/td-p\/419233\/jump-to\/first-unread-message",
        "Question_topic":[
            "Document AI"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":84.0,
        "Question_answer_count":7,
        "Question_has_accepted_answer":false,
        "Question_body":"We are delivering a platform to a customer based on Document AI. The use case it to send a lottery ticket via API and return the structure information using Document AI. We tried for several hundred images and the Document AI OCR worked great (95%+ times captured right string, only errors were line feeds and Q turning into O etc. that we could resolve using a post-processor). But for one set of images (from DC), the OCR fails miserably.  This is a corner case that seems to throw the Document AI engine off the mark.I will appreciate greatly if anyone can help explain it.See one particular image which is the most problematic.",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-09T11:37:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Could you please share the output that you are receiving, and what errors are the ones that you are presenting?"
            },
            {
                "Answer_creation_date":"2022-05-10T00:18:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Eduardo,\n\nThe error is that several characters that are on the image are not captured by OCR (whereas it does capture in case of several other images).\n\nRefer to the screenshot attached. See the right side after line \"DCLOTTERY.COM\".\u00a0 You will notice lines \"8\", \"B. 4\" etc.\n\nLine \"8\", the rest of the characters 0 1 1 4 STRAIGHT ... are missing.\n\nLine \"4 0\", characters 2 8 4 STRAIGHT ... are missing.\n\nSame for following 3 lines.\n\n----"
            },
            {
                "Answer_creation_date":"2022-05-13T16:01:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I could find this guide that might seem helpful for your case, if not, please give me more time so I can provide you a proper answer for the issue you are facing."
            },
            {
                "Answer_creation_date":"2022-05-13T22:13:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Sorry, you missed the entire point, the issue is that the core OCR engine is failing to process the image properly. If the product team takes a look at the image and result, it may give a clue. Hopefully they may be able to find a corner case that will improve the OCR results.\n\nWe are quite familiar with the documents and how to parse the result of the DOcument AI."
            },
            {
                "Answer_creation_date":"2022-06-21T07:00:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Anil, sorry it took me so long to answer you, couldn't find any information on why the OCR is failing for that image that you specify, so my best recommendation for you, is that you file an issue tracker or open a support ticket since this seems like an issue that you are only facing."
            },
            {
                "Answer_creation_date":"2022-06-27T21:17:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"What DocAI processor are you using?\u00a0 What, if anything, is returned from the processing?"
            },
            {
                "Answer_creation_date":"2022-08-03T12:31:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Deskewing the image in a pre processing step is doing the trick"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Speech-to-Text for many langages",
        "Question_creation_date":"2022-03-28T06:33:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Speech-to-Text-for-many-langages\/td-p\/407723\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":53.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,I'm testing bunch of variety of the Speech-to-Text API to transcribe audio from microphone but I'm going through two issues:Note: I didn't see anywhere how to use utf-8 for transcriptionHow can I fix it I used the code found here https:\/\/github.com\/googleapis\/python-speech\/blob\/main\/samples\/microphone\/transcribe_streaming_infini...",
        "Answers":[
            {
                "Answer_creation_date":"2022-04-05T10:20:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I solved the first part of my problem, if anyone is going through the same problem\n\nIn windows terminal you can type: chcp 1256 . This allow arabic characters in terminal"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Google Vertex AI Automl Model ID is invalid. It should start with 3 letters Error",
        "Question_creation_date":"2022-11-20T02:40:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Vertex-AI-Automl-Model-ID-is-invalid-It-should-start-with\/td-p\/491126\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":30.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nYou get the error because you are using the old AutoML API to run predictions. See model_id created when the old AutoML API is used.\n\nSince you have trained your model using Vertex AutoML Classification (you got the 18 digit number), you should use aiplatform to run your predictions. See sample prediction code."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Authentication errors running vaictl in container",
        "Question_creation_date":"2022-11-07T15:09:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Authentication-errors-running-vaictl-in-container\/td-p\/486888\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":37.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I'm trying to run vaictl on OSX inside a docker container based on these Vertex AI Vision instructions, but hitting the following auth error:  I've run gcloud auth login in the container and saved the authorization code.Are there any extra steps needed to make this work?",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-08T10:53:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"How did you reproduce the error? Can you provide the reproduction steps? Just so I can reproduce it on my end."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Vertex AI data lost on VM stop",
        "Question_creation_date":"2022-07-22T08:40:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-data-lost-on-VM-stop\/td-p\/445990\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":131.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"I am new to Vertex AI and wanted to try it out for a Kaggle competition. I was able to get a GPU machine up and running, as well as download the data to the machine. The download script was automatically generated when uploading my notebook to Vertex AI. I ran the script and 5 hours later all of the data was there successfully (to the boot disk -  standard persistent disk with 1000 GB). I then ran a first iteration of my model and everything worked great. When I was done, I went back to GCP and stopped my VM, assuming all of my data would be saved. It was not!I then started over and once the data was on the machine I took a snapshot so I wouldn't have to redownload the data a third time. I then made some edits to my model and ran it again. After I was done, I again stopped my VM to not leave it running. All of the data was lost again, but less surprisingly this time. I thought a snapshot could be used as a backup to the original machine, but the documentation makes it seem like it is only for creating a new VM from the boot disk. I then made a new machine but cannot figure out how to use it. I also tried looking for a way to make a new notebook on Vertex with the disk snapshot, but it did not look possible. Questions: ",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-29T08:56:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Create a snapshot\n\ngcloud compute snapshots create SNAPSHOT_NAME \\\n\n--source-disk SOURCE_DISK \\\n\n--source-disk-zone SOURCE_DISK_ZONE\n\nssh instance and run command: sudo umount \/dev\/disk\/by-id\/google-<INSTANCE NAME>\nStop the instance\nDetach data disk\n\ngcloud compute instances detach-disk $INSTANCE_NAME --disk $DATA_DISK_NAME --zone $ZONE\n\nDelete data disk\n\ngcloud compute disks delete $DATA_DISK_NAME --zone $ZONE\n\nCreate the new disk using the snapshot created: gcloud compute disks create $DATA_DISK_NAME $DATA_DISK_SIZE --source-snapshot=$SNAPSHOT_NAME $DATA_DISK_TYPE --zone $ZONE\nAttach the disk into the notebook instances: gcloud compute instances attach-disk $INSTANCE_NAME --disk $DATA_DISK_NAME --zone $ZONE\nCreate directory that serves as the mount point sudo mkdir -p \/mnt\/disks\/MOUNT_DIR\nMount the disk sudo mount -o discard,defaults \/dev\/DEVICE_NAME \/mnt\/disks\/MOUNT_DIR\nStart the VM"
            },
            {
                "Answer_creation_date":"2022-07-29T09:02:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks, that is helpful but I still do not understand why the data was deleted in the first place? It says it is a persistent disk"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"[Vertex AI] Bug - Failed to create endpoint due to the error: INTERNAL",
        "Question_creation_date":"2022-03-15T06:40:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-Bug-Failed-to-create-endpoint-due-to-the-error\/td-p\/403711\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":338.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"When attempting to create a new Vertex AI endpoint in us-central1 using a healthy model, I keep getting the error: \"Failed to create endpoint \"NAME\" due to the error: INTERNAL\"\n\nI expected the endpoint to get deployed successfully.  In fact, up to about 7 days ago, this operation worked perfectly.\n\nSteps to reproduce:\nAttempt to deploy a health Vertex AI model to a new endpoint in us-central1\n\nI'm currently trying to figure out if this INTERNAL error is specific to a region (or not), but it will take me hours before I can determine if the region is a factor.  I suspect there's some other global issue that's the problem.Has anyone else encountered this problem?",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-17T10:23:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi\u00a0Darien,\u00a0\n\nI see that you have already reported this on our Public Issue Tracker\u00a0here and I am glad that you are no longer having this issue."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"load a .h5 trained model directly from GCS ?",
        "Question_creation_date":"2022-02-21T03:57:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/load-a-h5-trained-model-directly-from-GCS\/td-p\/395442\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":242.0,
        "Question_answer_count":4,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello, it's the fist time I actually try to put in a production environment a locally trained .h5 model. I have a website hosted on a cloud run container and I'm trying to run an Image processing pipeline every-time a file is uploaded to GCS via the website (that's why I want to use a cloud function that triggers when a new file is created).my issue:I have found a way to load my .h5 model from GCS but It's taking way too mush time and I'm sure there's surely a better way to do what i'm trying to do:almost 1 minute to load on my local machine. Do you have any recommendation on how to trigger the prediction of my trained model + (pre\/post processing) easily upon file upload from my website (in a serverless context) ?",
        "Answers":[
            {
                "Answer_creation_date":"2022-02-23T17:23:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nCan you kindly advise of your complete workflow. Additionally, how big are these h5 files?\n\nRegards"
            },
            {
                "Answer_creation_date":"2022-02-28T12:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I am using a could run docker container. And instead of packaging the model inside the container I would prefer to tell the code to load it directly from GCS (in python). Model .h5 size is 22.4Mo"
            },
            {
                "Answer_creation_date":"2022-03-01T17:17:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nGCS does offer low latency which applies to all storage classes. If your app and GCS buckets are in the same region, I suggest to file an official support [1] so we can take a look at it in details using our internal tooling.\n\nRegards,\n\n[1]\u00a0https:\/\/cloud.google.com\/support-hub"
            },
            {
                "Answer_creation_date":"2022-03-01T17:25:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Additionally,\u00a0\n\nHave you tried comparing the results when fetching the same file directly through gsutil?"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"timeSegments vs timeSegmentAnnotations",
        "Question_creation_date":"2022-11-16T08:02:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/timeSegments-vs-timeSegmentAnnotations\/td-p\/490092\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML",
            "Video Intelligence API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":47.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"timeSegments vs timeSegmentAnnotationsCan anyone explain what's the difference between these 2 fields described here? https:\/\/storage.cloud.google.com\/google-cloud-aiplatform\/schema\/dataset\/ioformat\/video_action_recogn...why would I want to tag timeSegments? what's the objective of this? associate a label to a time segment?  ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-17T15:51:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"timeSegments is a parameter that should be included to your schema's YAML and JSONL files so that it can be used to determine the timestamps of the operations, not something that should be made from the terminal. I.e., a section of the film that contains a number of actions or annotations. And when you import data into your dataset later, you add those files.\n\nHowever, I checked timeSegmentAnnotations and found that although I set the endTime to be different from startTime, the action is only labeled on the startTime, so it doesn't seem to be that useful (hence, one frame)."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Action Needed | OAuth Google Cloud platform | multiple unique domains",
        "Question_creation_date":"2022-04-04T02:55:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Action-Needed-OAuth-Google-Cloud-platform-multiple-unique\/td-p\/410024\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":93.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi,I am carrying out the OAuth verification in Google Cloud Platform, I received an email that said:\n\"Thanks for your patience while we reviewed your project.Your project pc-api-XXXXXXXXXXXXXXX-XX has multiple unique domains in the redirect URI and origin URLs, many of which have unrelated applications. This is in direct violation of the Google API Services: User Data Policy, which requires that projects accurately represent their identity and intent to Google and to our users when they request access to Google user data.Please follow the instructions on the Google API Console to:You can find more information in the OAuth Application Verification FAQ.  To make sure we don't miss your messages, respond directly to this email to continue with the verification process.\"I have a web server, which checks the validity (domain-1.com) in-app purchases, and I also have a site with a different domain containing: privacy-policy and terms-of-service (domain-2.com).My settings are as follows:OAuth consent screen:\n- Home page application: https:\/\/www.domain-2.com\/\n- Privacy Policy: https:\/\/www.domain-2.com\/privacy-policy\/\n- Terms of Service: https:\/\/www.domain-2.com\/terms-of-service\/\n\nAuthorized domains:\n- domain-2.com\n- domain-1.comID client OAuth 2.0 -> Authorized Redirect URIs:\n- https:\/\/game.domain-1.com:8443I have a working service account.\nI have successfully verified all 2 domains.Where is the mistake?",
        "Answers":[
            {
                "Answer_creation_date":"2022-04-04T21:08:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"I have found the solution:\n\nI had 2 Google Cloud Platform projects for the same application.\n\nI deleted a Google Cloud Platform.\nI implemented all the configurations of the deleted project in the other project, and it worked!\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-04-04T21:08:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"I have found the solution:\n\nI had 2 Google Cloud Platform projects for the same application.\n\nI deleted a Google Cloud Platform.\nI implemented all the configurations of the deleted project in the other project, and it worked!"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Cloud Vision model change",
        "Question_creation_date":"2021-12-13T05:01:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Cloud-Vision-model-change\/td-p\/178017\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":95.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello, The changes for the Vision API's model from latest -> stable and stable -> legacy are scheduled around Dec 30th\/Jan 1st. Is there a more concrete date and time for this planned change?I'd like to use the currently stable model for the time being, which would involve switching from \"stable\" to \"legacy\". Since this could have an impact on some environments, I will need to make this swap shortly after the model references are being changed. Thanks!",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Please follow the Release Notes for official updates, as Google does not disclose any updates otherwise."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Eliminacion de fondos personalizados",
        "Question_creation_date":"2022-11-12T05:01:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Eliminacion-de-fondos-personalizados\/td-p\/488739\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":21.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hay documentos que tienen un fondo personalizado ya sea con logos o texto referencial a la empresa o al proceso que se lleva a cabo, es o ser\u00e1 posible eliminar estas caracter\u00edsticas y as\u00ed poder hacer m\u00e1s eficiente el nivel de eficiencia del OCR",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-12T05:01:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hay documentos que tienen un fondo personalizado ya sea con logos o texto referencial a la empresa o al proceso que se lleva a cabo, es o ser\u00e1 posible eliminar estas caracter\u00edsticas y as\u00ed poder hacer m\u00e1s eficiente el nivel de eficiencia del OCR"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Google Vision API pricing",
        "Question_creation_date":"2022-06-10T09:35:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Vision-API-pricing\/td-p\/430454\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":185.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,I'm currently using the service of the Google Cloud Vision API. On the website it says that the first 1000 Request are for free every month. But for that I need a Billing account which is not for free if I understand correctly.  So basically you can't use the Cloud Vision API completely for free. Am I right or can you use the service without any costs?",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"A Cloud Billing account is set up in Google Cloud and is used to define who pays for a given set of Google Cloud resources.This is needed in Google Vision API because if it passes the request limit these needs to be charged. The Billing account is needed because it tracks all of the costs (charges and usage credits) incurred by your Google Cloud usage."
            },
            {
                "Answer_creation_date":"2022-10-06T02:20:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The first 1000 credits can be used each month without charge, but a billing account is required."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Streaming Ingestion into Vertex AI Feature Store",
        "Question_creation_date":"2022-07-12T09:26:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Streaming-Ingestion-into-Vertex-AI-Feature-Store\/td-p\/441577\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":256.0,
        "Question_answer_count":4,
        "Question_has_accepted_answer":false,
        "Question_body":"I'm just wondering if Vertex AI Feature Store supports streaming ingestions rather than just batch ingestion as seen here (https:\/\/cloud.google.com\/vertex-ai\/docs\/featurestore\/ingesting-batch). I figured that the presence of an online store (https:\/\/cloud.google.com\/vertex-ai\/pricing) means that there is a way to store the most up-to-date data and serve them.Thanks!",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello, at the moment it\u2019s impossible to stream ingestion onto vertex, what you could do is to create a feature request.\n\nIf you find an issue or feature request that matches yours, star it.\n\nIf you don't see a matching issue or feature request, you can create one:\n\nIn the following tables of issue trackers, locate the product.\nClick on the link to create a new issue.\nIn the form's Template drop-down menu, select either Defect report to report an issue or Feature request to request a feature.\nIn the Description text box, complete the rest of the form using the prompts provided.\nClick Create."
            },
            {
                "Answer_creation_date":"2022-07-15T03:31:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Eduardo,\n\nThanks for the reply! Then could I check, what features would populate the online store then? Would it just be the latest features from any batch ingestion?"
            },
            {
                "Answer_creation_date":"2022-07-15T03:32:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Also, what is the online store based on? Is it a BigTable?"
            },
            {
                "Answer_creation_date":"2022-07-21T16:01:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You would need to wait for the Release note since i don't really have an answer for your first question, secondly, the store is based on cloud storage if i'm not mistaken."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Text to speech data residency",
        "Question_creation_date":"2022-10-05T12:25:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Text-to-speech-data-residency\/td-p\/474727\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":84.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Compliance team is asking for Data residency for text to speech data. On Google website, it says,\u201cText-to-Speech is both stateless and resourceless. This means Data Access and System Event data don't apply. As a result, Text-to-Speech is out of the scope of Client Access Licenses (CAL). Google does not log any customer Text-to-Speech text or audio data.\u201dDoes logging here refer to data storage. We do not want to store any data in the cloud. Regards,",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-07T08:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Reviewing the documentation you shared, you might also want to review Data Logging.\n\nYou will find that if you enable the information log, it helps to enhance speech to text, but not all the information you will use will be preserved, so, the log will only be saved if you actually want to use it or not."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to package custom prediction code and serve it using an Endpoint in Vertex AI ?",
        "Question_creation_date":"2021-10-25T11:36:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-package-custom-prediction-code-and-serve-it-using-an\/td-p\/173876\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":2.0,
        "Question_view_count":204.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Goal: serve prediction request from a Vertex AI Endpoint by executing custom prediction logic.Expected Workflow:1. Upload a pretrained image_quality.pb model (developed in a non vertex-ai pythonic environment) in a gcs bucket2. Port existing image inference logic into a container and serve the prediction functionality through a vertex AI endpoint. 3. Use Vertex AI api for logging and capturing metrics inside the  custom inference logic.4. Finally we want to pass a list of images (stored in another gcs bucket) to that endpoint.5. We also want to see the logs and metrics in tensorboard.Existing Vertex AI code samples provide examples for custom training , invoking model.batch_predict \/ endpoint.predict , but don't mention how to execute custom prediction code.It would be great if someone can provide guidelines and links to documents\/code in order to implement the above steps.Thanks  ",
        "Answers":[
            {
                "Answer_creation_date":"2021-11-19T07:46:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Please find the following guides respective of the points\n\n1.\n[1] Import model:\u00a0https:\/\/cloud.google.com\/vertex-ai\/docs\/general\/import-model\n[2] What cannot be migrated:\u00a0https:\/\/cloud.google.com\/vertex-ai\/docs\/start\/migrating-to-vertex-ai#migration-exceptions\n2.\n[3] Custom containers:\u00a0https:\/\/cloud.google.com\/vertex-ai\/docs\/training\/containers-overview\n[4] https:\/\/cloud.google.com\/vertex-ai\/docs\/training\/create-custom-container\n3.\n[5] About metrics:\u00a0https:\/\/cloud.google.com\/vertex-ai\/docs\/general\/monitoring-metrics\n4.\n[6] Passing list of images:\u00a0https:\/\/cloud.google.com\/vertex-ai\/docs\/datasets\/create-dataset-api\n5.\n[7] Metrics in Tensorboard:\u00a0https:\/\/cloud.google.com\/architecture\/ml-on-gcp-best-practices?hl=en#use-vertex-tensorboard-to-visua...\n\n\nAs there is no existing unifying guide for these operations, I created a documentation feature request to have one, and asked the documentation team to post updates here."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"503 on translations",
        "Question_creation_date":"2022-07-20T05:46:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/503-on-translations\/td-p\/445069\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":71.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I started to see this error on multiple clusters in America. But there is nothing in the status page. I don't think we had any updates to our code.google.api_core.exceptions.ServiceUnavailable: 503 POST https:\/\/translation.googleapis.com\/language\/translate\/v2?prettyPrint=false: The service is unavailable at this time.I guess I need to wait, but posting here just to raise it",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-25T15:31:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Sometimes this issue happens because the Product is getting an Update.\nOthers it's because you are sending too many requests, and to mitigate this issue the recommendation is to split up the code."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Steps to get Real life data into the features section",
        "Question_creation_date":"2022-04-29T15:39:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Steps-to-get-Real-life-data-into-the-features-section\/td-p\/418695\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":34.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi, I already create a tabular classification model using AutoML. All ready have the features created in a Goolge colab and now I need to get the real life data from a Public API to feed the features, then pass the features into the Model and finally get the classifications.The question is are the steps and which tools should I use in order to connect to the API in order to receive the real time data? ",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-09T11:05:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, I think you are looking for this documentation that can help you understand how you can create datasets and import the data into AutoML. The documentation will provide you with the steps you need to follow."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Speech changes to a more robotic feel if I use certain phonemes",
        "Question_creation_date":"2022-01-17T00:19:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Speech-changes-to-a-more-robotic-feel-if-I-use-certain-phonemes\/td-p\/184068\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":47.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"I am using phonemes for some speaks, to make them sound more natural, but some phonemes change the rest of the sentence feel. I have made a demo here.Using these settings:In the speak below I have two identical speaks, where one word is replaced with a phoneme. Notice how the end of the sentence changes to a more robotic feel in the first. How do I avoid this?<speak>\nIn this training, you will learn more about how you sell <phoneme alphabet=\"ipa\" ph=\"k\u0251\u02d0d\">placeholder<\/phoneme> as a solution for companies that want to minimize out-of-pocket spending and have better control of company spending by employees.In this training, you will learn more about how you sell card as a solution for companies that want to minimize out-of-pocket spending and have better control of company spending by employees.\n<\/speak>",
        "Answers":[
            {
                "Answer_creation_date":"2022-01-20T04:18:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi! I see there is an issue already open regarding this. I\u2019ve tested your SSML and I understand what the issue is and it seems like unintended behavior. I tried to workaround it but I didn\u2019t find a way to do so. Any updates regarding your issue will be on the issue tracker"
            },
            {
                "Answer_creation_date":"2022-01-23T23:28:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Yes. I created the issue. Thx for the reply"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Vertex AI integration with mlflow ?",
        "Question_creation_date":"2022-02-18T03:57:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-integration-with-mlflow\/td-p\/394738\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":918.0,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"Is there any way to integrate vertex AI with mlflow ? \nAny articles or resources I can go through ?",
        "Answers":[
            {
                "Answer_creation_date":"2022-02-18T04:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi\u00a0avinashbhawnani,\u00a0\n\nI would suggest to have a look at MLflow plugin for Google Cloud Vertex AI\n\nhttps:\/\/pypi.org\/project\/google-cloud-mlflow\/\n\nFeel free to reach out in case of questions\n\nThanks"
            },
            {
                "Answer_creation_date":"2022-02-20T23:50:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi\u00a0\u00a0ilnardo92,\n\nThanks for sharing the resource, will have a look into it and reach out in case of any queries.\n\nThanks"
            },
            {
                "Answer_creation_date":"2022-02-26T06:42:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi!... i saw right now this post and tanks to sharing...\u00a0\n\nYou know if is possible to share another container registry how to \"nexus\" instead of GCR ?"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Poor OCR results from PDF files compared to TIFFs",
        "Question_creation_date":"2022-10-14T03:18:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Poor-OCR-results-from-PDF-files-compared-to-TIFFs\/td-p\/478060\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_tag":null,
        "Question_upvote_count":1.0,
        "Question_view_count":63.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,We're using DOCUMENT_TEXT_DETECTION in production to perform OCR on documents. We've found  the quality of OCR of PDF documents compared to the exact same TIFF to be very poor (with missing characters, extra whitespace etc).I've attached an example test image in both PDF and TIFF formats. You can see the text is very legible and the OCR from the TIFF is 100% correct. The OCR from the PDF has multiple missing characters.This leads me to believe that the internal rendering of PDFs performed by the cloud vision API is buggy.Can anyone shed any light?Correct OCR results from TIFF:Poor read from PDF:See missing hyphen, missing 'ME' from 'PAYMENT', and various lost hash\/pound characters with extra newlines.The pdf and tiff can be found in this shared gdrive: https:\/\/drive.google.com\/drive\/folders\/1M4VZ3cT3YDoEn5o565fdWP6_47Y_KISL?usp=sharingHere's a screenshot of the PDF for ease: ",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-17T09:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, phildrip,\n\nCould you try TEXT_DETECTION instead of DOCUMENT_TEXT_DETECTION and share your results?\n\nTo update your model, simply set the 'model' value to \"builtin\/latest\", e.g code sample:\n\nclient = vision.ImageAnnotatorClient()\nfeature = vision.types.Feature(\ntype=vision.enums.Feature.Type.TEXT_DETECTION, model=\"builtin\/latest\")\n\nI will be awaiting your response."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How can I deploy a pretrained fasttext model?",
        "Question_creation_date":"2022-03-13T01:31:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-can-I-deploy-a-pretrained-fasttext-model\/td-p\/403114\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":235.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi, I have this code : \"",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-16T17:06:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nSeeing that there is already an existing post [1] on Stack Overflow, kindly follow up on that post to avoid any work duplication.\u00a0\n\n\u00a0\n\n[1]\u00a0https:\/\/stackoverflow.com\/questions\/71455187\/how-can-i-deploy-a-fasttext-model-on-google-cloud"
            },
            {
                "Answer_creation_date":"2022-03-17T22:12:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi! Thanks for answering, that question actually is mine, and there hasn't been an answer yet. Anyways I have a question, all I want to do, is deploy a couple pretrained fasttext models :\u00a0\n\nimport fasttext\nft = fasttext.load_model('pretrainedmodelpath')\nJust that, a couple times and be able to have an api get word vectors for words, which google cloud service would best be suited for this task? Most of the google cloud services want me to train my own model and don't let me just load a pretrained one. And in for example Dataflow, I can't just send text via the API and get an answer because it wants a file input. Any ideas? Thanks!"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"[Vertex AI] Bug - Failed to download file",
        "Question_creation_date":"2022-07-07T07:35:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-Bug-Failed-to-download-file\/td-p\/439222\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":69.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Vertex AI recently fails to download any file greater than 30M. Any downloaded file will be trimmed at 30M. The download speed is also way slower recently (200k\/s). It was working a few days ago. (downloads files of 100+M at 5M\/s) Any ideas?",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-14T07:42:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You can see this documentation about troubleshooting with vertex, it mentions working with files that are truncated or do not complete downloading and possible solutions."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"AutoML tables - sample size of an average",
        "Question_creation_date":"2022-02-25T06:44:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/AutoML-tables-sample-size-of-an-average\/td-p\/397276\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":66.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi everyonesI'm new to google automl tables and have a basic question about which data is worthwhile including in the training of my model.I have a dataset of golfers and will be looking at the averages of scores over different periods. For example, average over the past 3 months, 6 months, 1 year etc.My question is, is it worthwhile also including the sample size for each date range for each player. For example, over the past 3 months, some players will have a sample size of 28 while some will only have 2. Those players that have 28 rounds will have more accurate averages than those with 2. However, I didn't know whether google automl tables would pick up this link automatically, whether I could create a different weighting\/reliability variable, or whether there's a way to specify a link between columns? Or if this automated type of automl isn't really suitable or just leave out that sample size variable?Thanks in advance",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-11T11:17:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nGoogle Groups are reserved for general product discussion, StackOverflow for technical questions whereas Issue Tracker for product bugs (unexpected behaviors) and feature requests. To get a better support you should post to the relevant forum, thus please read the Community Support article for better understanding."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How does google cloud speech to text api deals with invalid inputs ?",
        "Question_creation_date":"2022-09-25T10:32:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-does-google-cloud-speech-to-text-api-deals-with-invalid\/td-p\/470810\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":59.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I am using google cloud stream(AsyncStreamingRecognize) for speech to text conversion in my applications. I have gone through the below link to understand the structure of response returned by the apis :StreamingRecognizeResponse  I can have various scenarios where I can end up with various invalid scenarios and I do not understand what could be the responses. I can invalid scenarios like :- User speaks in a different language than what is passed in configuration .- User does not speak anything \/ no input- Only noise gets passed \/ Data lossIs there any parameter inside my response which can point to above scenarios ?",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-27T14:56:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"1.- If a user speaks a different language you can use language recognition in audio requests. Speech-to-Text supports alternative language codes for all speech recognition methods. Also, one good practice is to show a phrase that can be used or advice on what language you select to be recognized by Speech-to-Text.\u00a0\n\n2.- There are multiple ways that Speech to text can return an empty response. The source of the problem could be the RecognitionConfig\u00a0or the audio itself.\n\n3.-To avoid that only the noise gets passed and the data is lost you can pre-process the audio just as the best practices doc\u00a0mentions.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-09-27T14:56:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"1.- If a user speaks a different language you can use language recognition in audio requests. Speech-to-Text supports alternative language codes for all speech recognition methods. Also, one good practice is to show a phrase that can be used or advice on what language you select to be recognized by Speech-to-Text.\u00a0\n\n2.- There are multiple ways that Speech to text can return an empty response. The source of the problem could be the RecognitionConfig\u00a0or the audio itself.\n\n3.-To avoid that only the noise gets passed and the data is lost you can pre-process the audio just as the best practices doc\u00a0mentions."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"GCP Idle Model Charging",
        "Question_creation_date":"2022-11-07T04:10:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/GCP-Idle-Model-Charging\/td-p\/486604\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML",
            "Cloud TPU",
            "Contact Center AI"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":113.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello!\nI would like to deploy the ML Model into GCP.Most of the time the model will be sleeping. Sometimes I should use it through Endpoint for some seconds.\nI don't want to pay for full-time GPU instance and I need fast responses at the same time, without deployment from scratch everytime I need it.Is this possible in GCP ?",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-08T15:02:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"According to the Pricing for AutoML models documentation:\n\nPricing for AutoML models\n\nFor Vertex AI AutoML models, you pay for three main activities:\n\nTraining the model\nDeploying the model to an endpoint\nUsing the model to make predictions\n\nVertex AI uses predefined machine configurations for Vertex AutoML models, and the hourly rate for these activities reflects the resource usage. ... You pay for each model deployed to an endpoint, even if no prediction is made. You must undeploy your model to stop incurring further charges. Models that are not deployed or have failed to deploy are not charged.\n\nYou pay only for compute hours used; if training fails for any reason other than a user-initiated cancellation, you are not billed for the time. You are charged for training time if you cancel the operation.\n\nCustom-trained models\nTraining\n\nThe tables Machine types and Accelerators provide the approximate price per hour of various training configurations. You can choose a custom configuration of selected machine types. To calculate pricing, sum the costs of the virtual machines you use.\n\nIf you use Compute Engine machine types and attach accelerators, the cost of the accelerators is separate. To calculate this cost, multiply the prices in the table of accelerators below by how many machine hours of each type of accelerator you use.\n\nFor further information about pricing, please refer to the Vertex AI pricing documentation, or you can connect with our sales team to get a custom quote."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How can I use this specific voice? (English (en-gb-x-gbg-network)",
        "Question_creation_date":"2022-01-20T22:56:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-can-I-use-this-specific-voice-English-en-gb-x-gbg-network\/td-p\/184984\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text",
            "Text-to-Speech"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":169.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Goal: Given text, generate mp3 files using Google Cloud tts servicesProblem: Unable to find specific voice I am used to hearing English (en-gb-x-gbg-network). Other info: I've been using this tts app on android in which I can select the aforementioned Voice Type from the Google TTS engine on android. I have since created a Google Cloud account, and followed the tutorial to setup a project to which I can use their selection of voices. However, when I went through the list of voice that I can use, the en-gb-x-gbg-network was not available to use. AFAIK, en-gb-x-gbg-network is not a premium WaveNet voice type. I suspect it has something to do with android but I can't not see why I can't use this voice on the Google Cloud Platform. Many thanks for any helpful info or any nudge that can point me to the right directionCheers, Welp",
        "Answers":[
            {
                "Answer_creation_date":"2022-01-24T07:14:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello Welp,\n\nI will like to point you to this article[0] that highlights the supported voices and languages available in Cloud Text-to-Speech on GCP.\n\nApparently, while there are other en-gb voices supported, the en-gb-x-gbg-network is not supported at this time. This explains why you could not find this specific voice[en-gb-x-gbg-network] on your GCP project because it seems unsupported at this time.\n\nPerhaps you can go through the supported voices and the samples provided on the link[0] to check for other alternatives?\n\n[0]https:\/\/cloud.google.com\/text-to-speech\/docs\/voices"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Authentication for the Document AI",
        "Question_creation_date":"2022-06-03T10:29:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Authentication-for-the-Document-AI\/td-p\/428530\/jump-to\/first-unread-message",
        "Question_topic":[
            "Document AI"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":60.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"First off, please be kind, as I'm not a developer and may struggle with some basics concepts.\n\nI'm trying to build a AI Invoice reader to collect invoice data in a spreadsheet, using Integromat \/ make.com (no-code platform) and Google Cloud Services.\nUsually, there are integrations for what I need in Integromat or I use simple REST calls. \n\nWith the Document AI, afaik I have to use OAuth. I have my \"processor\" and the I've been searching the Google Cloud documentation for a while, but for a non-dev it's quite confusing. Where can I find the two URLs needed?\n\nThank you very much for your help!",
        "Answers":[
            {
                "Answer_creation_date":"2022-06-10T14:17:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You can see this post[1] you can see here how they get the environment endpoint that I think that what you mean by Authorize URI also here is a step on how to get the Access Token (Token URI) additionally the step to get the access token is here in the documentation[2] you have to use the Cloud SDK and use the following command:\n\n\u00a0 \u00a0 - gcloud auth application-default print-access-token\n\n[1]https:\/\/clincher.medium.com\/create-a-document-ai-service-rest-api-processor-in-google-cloud-2710f583...\u00a0\n\n[2]https:\/\/cloud.google.com\/document-ai\/docs\/setup#auth-test"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"A100 ram limitations",
        "Question_creation_date":"2022-07-07T10:22:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/A100-ram-limitations\/td-p\/439296\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":71.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Can someone please help me understand why the best GPUs google offer (A100) have a fixed CPU RAM of 85GB (only 2x that of the GRAM) and all the other poorer GPU options can go over 300GB. It's terribly frustrating for large dataset training pipelines. Especially when mmdetection libraries don't work well on mutiple GPUs and would rather just use the 1",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-13T15:06:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The NVIDIA A100 GPU must use the a2 Machine series, the lower CPU that a `a2 Machine` is 85GB and the highest a2 machine memory is 1360GB.\n\nAlso, You can attach up to 257 TB of local storage to these machine types in this series for applications that require higher storage performance.\n\nYou can also use Optional local SSD support: you can get up to 3 TB of Local SSD with `a2 machine` types. This can be used as fast scratch disks or for feeding data into the A100 GPUs while preventing I\/O bottlenecks.\n\nYou can see further details about the `a2 Machine` series here."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Google Vision release notes",
        "Question_creation_date":"2022-06-14T00:05:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Vision-release-notes\/td-p\/431130\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":65.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"From here https:\/\/cloud.google.com\/vision\/docs\/release-notes it says that there was an upgrade on OCR model for TEXT_DETECTION and DOCUMENT_TEXT_DETECTION. What is the recent model improvement compare to legacy model (is there some metrics used)?",
        "Answers":[
            {
                "Answer_creation_date":"2022-06-21T15:42:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"As part of the best effort, can I make a suggestion for you on modifying the model field of Feature object into either \"builtin\/legacy\" or \"builtin\/latest\". Though the OCR model will automatically be upgraded to the new model when there's an update on \"builtin\/stable\" (default). This means that google implemented the newest versions of TEXT_DETECTION and DOCUMENT_TEXT_DETECTION to work without a problem for future updates"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Vertex AI image classification models lose accuracy when being placed in a python dictionary",
        "Question_creation_date":"2022-10-26T10:13:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-image-classification-models-lose-accuracy-when-being\/td-p\/482475\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML",
            "Cloud TPU",
            "Vertex AI Model Registry"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":106.0,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"I have made a  model using vertex AI's image classification. Exported as EdgeTPU tflite model to my Raspberry pi 4 with Coral USB accelerator. When I used the Pycoral's example code https:\/\/github.com\/google-coral\/pycoral\/blob\/master\/examples\/classify_image.py  to run my model, I get a perfect prediction result. But when I passed them to a python dictionary in my script, the prediction accuracy is way off. https:\/\/github.com\/hillyuyichu\/Pycoral-python-API\/blob\/main\/pycoral_classification.py   Here is a screenshot of the prediction results on my python classification.py:The label in row 1 is always the most active. The one in the last rows are the least active and most inaccurate.ex: In picture 2, the label empty_pan barely ever cross 0.10 mark when it should have been more than 0.50",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-31T12:54:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"It seems Vertex AI is not supposed to be placed in a Python directory.\n\nIf this is impacting your application or your business, you can file a feature request using the following link. File the feature request, and they could assist you with the feature you are trying to implement."
            },
            {
                "Answer_creation_date":"2022-11-02T09:30:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Comaro!\n\nThanks for the reply! I was able to find a way to work around it."
            },
            {
                "Answer_creation_date":"2022-11-02T11:46:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Could you share the workaround, Hillyu?"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Join us on August 4! Machine Learning Day on Google Open Source Live",
        "Question_creation_date":"2022-07-28T06:53:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Join-us-on-August-4-Machine-Learning-Day-on-Google-Open-Source\/td-p\/447714\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_tag":null,
        "Question_upvote_count":3.0,
        "Question_view_count":93.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-16T20:51:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello @Lauren_vdv\u00a0\n\nThank you for the post, can I register on demand??"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Vertex AI deploy custom model error - Model server terminated: model server container terminated:",
        "Question_creation_date":"2022-11-18T05:47:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-deploy-custom-model-error-Model-server-terminated\/td-p\/490796\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "Vertex AI Model Registry"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":50.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi, I'm stuck at following error message when I try to deploy custom model to vertex-ai endpoint.Command:  ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-21T21:34:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You may check here some things you can check further when deploying your model. If this does not work, it would be helpful to file a 1:1 support case since they can check your internal resources."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Imbalance DataSet for Tabular AutoML",
        "Question_creation_date":"2022-04-18T10:26:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Imbalance-DataSet-for-Tabular-AutoML\/td-p\/414630\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":182.0,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi, I would like to know if in case of having a tabular database,  with binary data (class 0 and Class 1), that has an imbalance between class 0 and class 1, as it occurs in scenarios of fraud in financial transactions.Does AutoML solves automatically the imbalance situation? Or is it possible to add SMOTE or ADASYN to the AutoML model?  Any comments to advice more than appreciated",
        "Answers":[
            {
                "Answer_creation_date":"2022-04-21T09:42:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"There are several ways of handling imbalanced datasets:\n\nUpsampling and\/or Downsampling: In case of Upsampling, instances from the minority classes are duplicated in the training dataset at random. In case of Downsampling, certain instances of the majority classes are randomly left out of the training dataset. Upsampling of minority class and downsampling of the majority class can be done at the same time.\n\n\nUpweighting and\/or Downweighting: In Upweighting, sample weight greater than 1 is given to instances from the minority classes. In case of Downweighting, sample weight less than 1 is given to instances from the majority classes. The sample weights are taken into account when computing the loss function. Upweighting and Downweighting can be used together.\n\n\nData Augmentation: In this approach, data augmentation techniques are used to generate synthetic instances of the minority class to better balance the training dataset."
            },
            {
                "Answer_creation_date":"2022-05-02T06:46:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Jos\u00e9 hi, thanks for your answer but is not very clear.....\n\nThe question is if I can upload a data set with imbalance situation to AutoML or I need to fix somehow the situation before uploading the data into AutoML or AutoML can handle in very good way Imbalance data sets?"
            },
            {
                "Answer_creation_date":"2022-05-20T04:14:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I am also interested in the same question."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"DTMF working in dialogflow cx telephony gateway",
        "Question_creation_date":"2022-01-05T22:56:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/DTMF-working-in-dialogflow-cx-telephony-gateway\/td-p\/182110\/jump-to\/first-unread-message",
        "Question_topic":[
            "Contact Center AI",
            "Dialogflow CX"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":235.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\nI want to know that whether we can integrate  bot to Dialogflow CX Phone Gateway and then we can make something like press 1 for this and press 2 for this? and then that bot should work on numbers entered by user? Actually i have done a research regarding this and found that we have dtmf option which let us take input from the user but that is not working , so can you please let me know if something like this is supported?",
        "Answers":[
            {
                "Answer_creation_date":"2022-01-10T17:58:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, I would recommend you to have clarification for the issue and give a detailed use case with any documentation that you are following.\n\nGoogle Groups are reserved for general product discussion, StackOverflow for technical questions whereas Issue Tracker for product issues (unexpected behaviors) and feature requests.\n\nAs this is quite a technical question I would recommend you using the StackOverflow channel, the scope of the questions reach a greater tech community so they are likely to be answered faster.\n\nPlease read the Community Support article [1] for better understanding.\n\n[1] https:\/\/cloud.google.com\/support\/docs\/community"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Batch prediction on custom model",
        "Question_creation_date":"2022-07-13T11:39:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Batch-prediction-on-custom-model\/td-p\/442147\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "Vertex AI Model Registry"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":439.0,
        "Question_answer_count":4,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,I used custom containers for training and prediction to create a model on Vertex AI. Now I want to run batch prediction against it but get error message that says \"Unable to start batch prediction job due to the following error: A model using a third-party image must specify PredictRoute and HealthRoute in ContainerSpec.\"I checked documentation, AIP_HEALTH_ROUTE = \/v1\/endpoints\/ENDPOINT\/deployedModels\/DEPLOYED_MODELDoes this mean that the model has to be deployed to an endpoint in order to generate the value of the AIP_ENDPOINT_ID variable?However, the documentation \u201cGet batch predictions\u201d says \u201cRequesting a batch prediction is an asynchronous request (as opposed to online prediction, which is a synchronous request). You request batch predictions directly from the model resource; you don't need to deploy the model to an endpoint.I am confused whether in my situation, the model has to be deployed first. Also, is there any resources regarding hosting custom models for batch predictions?",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-18T11:47:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"If you are using a custom container, you can read this information about how to use a custom container for prediction.\n\nAbout your confusion, if you are using an API to create batch prediction, you need to send the request to a\u00a0 service endpoint.\n\n\u00a0\u201cTo create batch predictions, we recommend that you select input and output locations that are in the same region as your model. If you use the API to create batch predictions, send requests to a service endpoint (such as https:\/\/us-central1-aiplatform.googleapis.com) that is in the same region or geographically close to your input and output locations.\u201d"
            },
            {
                "Answer_creation_date":"2022-07-19T10:00:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for the reply. The\u00a0custom\u00a0container link you shared is about using a custom container for (online) prediction. Now my confusion is that, if I only want the model to be trained to serve batch predictions rather than online predictions, do I still need a custom prediction container. Would a deployed model with only training container suffice?"
            },
            {
                "Answer_creation_date":"2022-08-03T12:19:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You can upload your models in two ways:\n\n1. With a pre-build container (supported TensorFlow, XGBoost, scikit-learn)\n2. With a custom container\n\nBoth options support batch predictions. With batch predictions, you don't need to deploy your model to an endpoint. Uploading it to Vertex AI is enough.\u00a0\n\nA custom container is only needed if you use another ML framework that is not supported with the pre-build containers. Or you need additional logic as part of your prediction like pre or post processing for example."
            },
            {
                "Answer_creation_date":"2022-09-08T05:30:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I don't know if u have solved your probem but hopefully this helps. I can see how this is confusing, it was the same for me. So batch prediction under the hood is similar to vertex ai endpoint prediction. When you start a batch job a\u00a0a model endpoint to serve model predictions, and a Dataflow job to fetch the data is created, This is then split it into batches, get predictions from the endpoint, and return the results to GCS or BigQuery. All of this is done in a Google-managed project, so you won\u2019t see the model endpoint or the Dataflow job in your own project. So in the custom container you will need to have your model server code that runs your model. You can build your own model server using flask or Fastapi. Or you can also use custom prediction routines which does all that for you and u can focus only on the model logic. So to answer your question for the predict route and health route u need to mention '\/predict' and '\/health' or whatever name you are giving your routes. I am also working on this currently. So if I am wrong about anything I have told above pls correct me."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Need help for compute engine pricing",
        "Question_creation_date":"2022-09-06T05:11:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Need-help-for-compute-engine-pricing\/td-p\/463295\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":36.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"GPU: nvidia-a100-80gb has no pricing but  nvidia-tesla-a100 has",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-06T05:11:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"GPU:\u00a0nvidia-a100-80gb has no pricing but\u00a0\u00a0nvidia-tesla-a100 has"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Working with Context for different intent",
        "Question_creation_date":"2022-09-19T10:24:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Working-with-Context-for-different-intent\/td-p\/468253\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":138.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,\ni'm really new in DialogFlow and would like to dig deep my knowledge about this topic.\nMy question right now is about context. So for my case, i build a Conversational Bot for a Fitness Center and trying to create intent related to an individual's program goal\n\nSo for the training phrases would be\"i want to get ideal weight\"\n\"i want to build muscle\"\n\"i want to be more healthy\"\n\"i want to lose weight\"\n\"i want to gain weight\"\n\nI Called the entity \"Individual-goal\"\nTha Output Context for this is \"Fitness-Goal\"Now for my question:\ni would like to segment OR create the \"Sub-Context\" for this Fitness Goal, in following category:\nHealth - Gain Weight\nHealth - Lose Weight\nHealth - General\nFitness - Muscle Building\nFitness - General\n\nFor this case:\n1. Is it better for me to create multiple Intent ?\n2. Is there a way to put a context based on the response, like \"IF Individual goal contain 'gain weight' then Output Context set to \"Health - Gain Weight\"\n\nWhats the best scenario for this ?",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-28T11:00:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"It is better to create separate intents as shown in the examples of this documentation."
            },
            {
                "Answer_creation_date":"2022-10-21T08:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Its a while since you asked this so you may have already worked it out. You probably need to create an intent for each category like 'gain weight; so another one for 'fitness building'.\n\nAs CX is a 'state machine' (think of it this as lots of rooms off a corridor) the conversation depends what room your in. So if your in a 'lose weight room' your intent keyword of 'weight' will mean 'lose weight in that room'. But in a 'gain weight' room any conversation around weight will pick up trained phrases that interpret this in a way that relates to adding on weight.\u00a0\n\nHence you need to chose how many separate 'rooms' (different topics) you need and build the dialog specific to each room through intent to get you in there, and then build up your fulfilment from it too. Each room is standalone really. CX only finds the trained answers for that specific room when it is in it. This is the 'state machine' in action.\n\nFrom that map of rooms you then link your rooms together through pages \/ routes.\u00a0\n\nThe map starts in the 'default start page' so all rooms connected to start page ('routed') lead off it like a big entrance hall. User initially chatting 'gain weight' will be taken into that room (state) by CX. Once in there, unless you build a route directly from the gain weight room to the lose weight room, the visitor won't be able to access lose weight. They'd have to go back to the entrance hall to have a door into lose weight.\n\nSo you'll need to build a network of rooms through intent and pages, route them off a central entrance hallway and if you want them to interconnect you'll have to build a route network between them too.\n\nIt can get messy but it's genius when you get your head round it. Do the logical design first or frankly it can hurt"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB",
        "Question_creation_date":"2022-08-04T06:52:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/WARN-DAGScheduler-Broadcasting-large-task-binary-with-size-2-2\/td-p\/450466\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":794.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi there.\nThere were quite a number of such warnings as the model was getting trained.May I know if we are safe to ignore them?\nWhat does it mean actually?\nThanks in advance.",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-15T12:03:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"There is a limit of MB while broadcasting a task (10 MB), while using your VM that has enough resources if you don\u2019t pass this limit its going to be OK, but if your VM has low resources this could create a timeout.\n\nYou can mitigate it by reducing the task size => reduce the data its handling\n\nFirst, check number of partitions in dataframe via df.rdd.getNumPartitions() After, increase partitions: df.repartition(100)"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"BatchAnnotateImagesResponse images info (context support) for web based images",
        "Question_creation_date":"2021-12-23T01:21:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/BatchAnnotateImagesResponse-images-info-context-support-for-web\/td-p\/181129\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":128.0,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi all. How could one know in what exact web based image the text was detected when multiple web based images are sent to the cloud vision api in a single request using BatchAnnotateImagesRequest? BatchAnnotateImagesResponse doesn't return that information which is kinda odd... It has ImageAnnotationContext, which holds image details, but it's reserved only for files and not web based images.\n\nIs there some way to do this? Maybe like preserving order of images in request \/ response or something down that line.",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-27T13:12:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nlooking to our documentation [1] the batch annotation images response return an Individual responses to image annotation requests within the batch as AnnotateImageResponse [2].\n\nImageAnnotationContext, if present, contextual information is needed to understand where this image comes from.[1]https:\/\/cloud.google.com\/vision\/docs\/reference\/rpc\/google.cloud.vision.v1#batchannotateimagesrespons...\n[2]https:\/\/cloud.google.com\/vision\/docs\/reference\/rpc\/google.cloud.vision.v1#annotateimageresponse"
            },
            {
                "Answer_creation_date":"2022-01-11T00:30:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, abdelilahf\n\nSorry to see response a bit late. I was on vacation.\nAs I wrote, last time we checked, contextual information was just implemented to return image information about file based images, not web based images, and we only can check batches of images fetched from image service via api \"on the fly\".\n\nDo you maybe know if this will be implemented any time soon for web images? Is there some way to request this feature from Google? Also, is there some workaround in the meantime to cover our use case?"
            },
            {
                "Answer_creation_date":"2022-01-18T06:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Solved with this answer. Thanks!"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Vertex AI Custom Training Job Container not finding my module: Error while finding module for '...'",
        "Question_creation_date":"2022-04-25T02:48:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-Custom-Training-Job-Container-not-finding-my-module\/td-p\/416620\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":152.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,I have a PyTorch training job that I am packaging in a Python software distribution (.tar.gz file). I upload the sdist to a GCS bucket and run it in a container using the gcloud ai custom-jobs create CLI.Up until a couple of weeks ago this worked fine but in recent days my jobs consistently fail with messages like these appearing in their logs:Running command: python3 -m MyPackage.MyModule --job-dir=gs:\/\/my-bucket\/my-job\/model --model-name=my-model\n\n\/opt\/conda\/bin\/python3: Error while finding module specification for 'MyPackage.MyModule' (ModuleNotFoundError: No module named 'MyPackage.MyModule') MyPackage.MyModule is my module where my training code runs, naturally.As I've mentioned above the same procedure worked until recently. There have not been any changes to it and I can clearly see that MyModule.py is located under MyPackage in my .tar.gz file.The container image that I am using is us-docker.pkg.dev\/vertex-ai\/training\/pytorch-gpu.1-9:latest and from what I can tell it has not changed since the time I successfully used it before.Why is the Vertex AI container not finding my training module? How can I further debug and fix this?",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-06T15:03:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Check this documentation[1] to see how to fix ModuleNotFoundError.\n\n[1] https:\/\/towardsdatascience.com\/how-to-fix-modulenotfounderror-and-importerror-248ce5b69b1c"
            },
            {
                "Answer_creation_date":"2022-05-08T05:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Jose,\n\nThank you for trying to help. Alas, I've already followed all suggestions in the linked article, to no avail. There is something funky going on between the Vertex AI python code that looks for my module and the way I structured my .tar.gz. At this point, without being able to access the Vertex AI code, I don't see how to debug this."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Artificial Intelligence - list of APIs",
        "Question_creation_date":"2021-07-23T18:30:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Artificial-Intelligence-list-of-APIs\/td-p\/164618\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "Document AI",
            "Speech-to-Text",
            "Text-to-Speech"
        ],
        "Question_tag":null,
        "Question_upvote_count":1.0,
        "Question_view_count":485.0,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"Good day.Is it possible to list the Google APIs in the Artificial Intelligence, especially in the Voice recognitions, comparison, analytics etc? Thank you.",
        "Answers":[
            {
                "Answer_creation_date":"2021-07-25T12:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Let's try this link for a start ...\nhttps:\/\/cloud.google.com\/products\/ai\n\nThis appears to list all the various GCP products related to AI and, if one were to delve into each product, one would find the corresponding APIs."
            },
            {
                "Answer_creation_date":"2021-08-02T03:27:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"And take a look at the \"Google Cloud in\u00a0 Words\" cheat sheet\n\nhttps:\/\/github.com\/gregsramblings\/google-cloud-4-words\/blob\/master\/Brochure.pdf"
            },
            {
                "Answer_creation_date":"2021-08-22T20:43:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"@pascal_reddig\u00a0wrote: mcdvoice\n\n\nAnd take a look at the \"Google Cloud in\u00a0 Words\" cheat sheet\n\nhttps:\/\/github.com\/gregsramblings\/google-cloud-4-words\/blob\/master\/Brochure.pdf\n\nCarry on, don\u2019t stop posting like this"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Pipeline failed to deploy model: \"service_account cannot be specified for deploying AutoML models\"",
        "Question_creation_date":"2022-04-11T12:05:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Pipeline-failed-to-deploy-model-quot-service-account-cannot-be\/td-p\/412645\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":92.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I made a pipeline that almost mirrors step 6 of Intro to Vertex Pipelines which has managed to get past every step up until the model deployment side of things. The code snippet for my model deploy op is here:   And the associated error message in the logs for the deployment part of the pipeline was:RuntimeError: Failed to create the resource. Error: {'code': 400, 'message': 'service_account cannot be specified for deploying AutoML Models.', 'status': 'FAILED_PRECONDITION'} Does it have to do with a specific permission I need to give my service account? I don't know how to interpret this error.  ",
        "Answers":[
            {
                "Answer_creation_date":"2022-04-18T14:14:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You are sure you can specify a service account here like this? Do you have any reference that uses service account here?\n\n[1] https:\/\/cloud.google.com\/blog\/topics\/developers-practitioners\/use-vertex-pipelines-build-automl-..."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Getting Error Deadline Exceeded when deploying model from Cloud Firestoer functions",
        "Question_creation_date":"2021-12-03T11:17:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Getting-Error-Deadline-Exceeded-when-deploying-model-from-Cloud\/td-p\/177128\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":1.0,
        "Question_view_count":860.0,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,I currently have a firebase function that is set to deploy my AutoML tables model everyday at 5am. This has been working fine for the past month, up until the last week. I have been getting the following error below when the function attempts to deploy the model.I watched a google tutorial and it recommend to return a promise from my cloud function. That seemed to work for 1 day, but I received the error again this morning.I am going to try to implement a retry function, but I figured I would ask on here as well. Also, I am thinking that moving from autoML to VertexAI might help alleviate my issues. Any guidance here is helpful.See below for my deploy model code:  ",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-03T12:46:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Is deploying the model fails via Cloud Functions only, or does it also fail when the model is deployed manually, or by any other means?"
            },
            {
                "Answer_creation_date":"2021-12-03T15:00:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Manually (through the cloud console) it usually works. I have been testing using an http call in Firebase functions. Sometimes (not consistantly) that fails if I have recently undeployed the model. Although, I do not get any type of error notification, I just know it fails by checking the cloud console.\n\nThe deploy model function only runs once a day though, and the model has typically been undeployed for at least 20 hours before that, so I don't think I am getting that error because I am calling it too often."
            },
            {
                "Answer_creation_date":"2021-12-09T10:39:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"So after further investigation it looks like the model is failing when I am requesting predictions through firebase functions. I get the same error \"DEADLINE_EXCEEDED\". This is not consistent though, it worked for the previous 2 days before this and today failed again. I haven't changed anything.\n\nI have 2 questions:\n\n1) is it possible that congestion on the network is causing these to fail? Would it help if I moved the prediction to a different time? Currently I have it set at 6am PST.\n\n2) Since autoML is beta, would it help if I moved the model to VertexAI? I can make that move if it helps"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Error while trying to get explanation from (custom container) model deployed on Vertex AI",
        "Question_creation_date":"2022-07-26T01:38:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Error-while-trying-to-get-explanation-from-custom-container\/td-p\/446817\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "Vertex AI Model Registry"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":166.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,I created a custom docker container to deploy my model on Vertex AI. The model uses LightGBM, so I can't use the pre-built container images available for TF\/SKL\/XGBoost. I was able to deploy the model and get predictions, but I get errors while trying to get explainable predictions from the model. I have tried to follow the Vertex AI guidelines to configure the model for explanations.\nThe example below shows a simplified version of the model that still reproduces the issue, with only two input features 'A' and 'B'.Please take a look and tell me if the explanation metadata is supposed to be set differently, or if there is something wrong with this approach.https:\/\/cloud.google.com\/vertex-ai\/docs\/explainable-ai\/configuring-explanations#custom-container(Model output is unkeyed. The Vertex AI guide suggests using any memorable string for output key.)",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-26T01:38:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nI created a custom docker container to deploy my model on Vertex AI. The model uses LightGBM, so I can't use the pre-built container images available for TF\/SKL\/XGBoost. I was able to deploy the model and get predictions, but I get errors while trying to get\u00a0explainable\u00a0predictions from the model. I have tried to follow the Vertex AI guidelines to configure the model for explanations.\nThe example below shows a simplified version of the model that still reproduces the issue, with only two input features 'A' and 'B'.\n\nPlease take a look and tell me if the explanation metadata is supposed to be set differently, or if there is something wrong with this approach.\n\nEnvironment details\nGoogle Cloud Notebook\nPython version: 3.7.12\npip version: 21.3.1\ngoogle-cloud-aiplatform\u00a0version: 1.15.0\nReference\n\nhttps:\/\/cloud.google.com\/vertex-ai\/docs\/explainable-ai\/configuring-explanations#custom-container\n\nexplanation-metadata.json\n\n(Model output is unkeyed. The Vertex AI guide suggests using any memorable string for output key.)\n\n{\n    \"inputs\": {\n        \"A\": {},\n        \"B\": {}\n    },\n    \"outputs\": {\n        \"Y\": {}\n    }\n}\nModel upload with explanation parameters and metadata\n! gcloud ai models upload \\\n  --region=$REGION \\\n  --display-name=$MODEL_NAME \\\n  --container-image-uri=$PRED_IMAGE_URI \\\n  --artifact-uri=$ARTIFACT_LOCATION_GCS \\\n  --explanation-method=sampled-shapley \\\n  --explanation-path-count=10 \\\n  --explanation-metadata-file=explanation-metadata.json\nPrediction\/Explanation Input\ninstances = [{\"A\": 1.1, \"B\": 20}, {\"A\": 2.2, \"B\": 21}]\n# Prediction (works fine):\nendpoint.predict(instances=instances)\n# Prediction output: predictions=[0, 1], deployed_model_id='<>', model_version_id='', model_resource_name='<>', explanations=None\nendpoint.explain(instances=instances) # Returns error (1) shown in stack trace below\n\n# Another example\ninstances_2 = [[1.1,20], [2.2,21]]\n# Prediction (works fine):\nendpoint.predict(instances=instances_2)\n# Prediction output: predictions=[0, 1], deployed_model_id='<>', model_version_id='', model_resource_name='<>', explanations=None\nendpoint.explain(instances=instances_2) # Returns error\n# Error: Nameless inputs are allowed only if there is a single input in the explanation metadata.\nPrediction Server (Flask)\n# Custom Flask server to serve online predictions\n# Input for prediction\nraw_input = request.get_json()\ninput = raw_input['instances']\ndf = pd.DataFrame(input, columns = ['A', 'B'])\n# Prediction from model (loaded from GCP bucket)\npredictions = model.predict(df).tolist() # [0, 1]\nresponse = jsonify({\"predictions\": predictions})\nreturn response\nStack trace of error (1)\n---------------------------------------------------------------------------\n_InactiveRpcError                         Traceback (most recent call last)\n\/opt\/conda\/lib\/python3.7\/site-packages\/google\/api_core\/grpc_helpers.py in error_remapped_callable(*args, **kwargs)\n     49         try:\n---> 50             return callable_(*args, **kwargs)\n     51         except grpc.RpcError as exc:\n\n\/opt\/conda\/lib\/python3.7\/site-packages\/grpc\/_channel.py in __call__(self, request, timeout, metadata, credentials, wait_for_ready, compression)\n    945                                       wait_for_ready, compression)\n--> 946         return _end_unary_response_blocking(state, call, False, None)\n    947 \n\n\/opt\/conda\/lib\/python3.7\/site-packages\/grpc\/_channel.py in _end_unary_response_blocking(state, call, with_call, deadline)\n    848     else:\n--> 849         raise _InactiveRpcError(state)\n    850 \n\n_InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"{\"error\": \"Unable to explain the requested instance(s) because: Invalid response from prediction server - the response field predictions is missing. Response: {'error': '400 Bad Request: The browser (or proxy) sent a request that this server could not understand.'}\"}\"\n\tdebug_error_string = \"{\"created\":\"@1658310559.755090975\",\"description\":\"Error received from peer ipv4:74.125.133.95:443\",\"file\":\"src\/core\/lib\/surface\/call.cc\",\"file_line\":1069,\"grpc_message\":\"{\"error\": \"Unable to explain the requested instance(s) because: Invalid response from prediction server - the response field predictions is missing. Response: {'error': '400 Bad Request: The browser (or proxy) sent a request that this server could not understand.'}\"}\",\"grpc_status\":3}\"\n>\n\nThe above exception was the direct cause of the following exception:\n\nInvalidArgument                           Traceback (most recent call last)\n\/tmp\/ipykernel_2590\/4024017963.py in <module>\n----> 3 print(endpoint.explain(instances=instances, parameters={}))\n\n~\/.local\/lib\/python3.7\/site-packages\/google\/cloud\/aiplatform\/models.py in explain(self, instances, parameters, deployed_model_id, timeout)\n   1563             parameters=parameters,\n   1564             deployed_model_id=deployed_model_id,\n-> 1565             timeout=timeout,\n   1566         )\n   1567 \n\n~\/.local\/lib\/python3.7\/site-packages\/google\/cloud\/aiplatform_v1\/services\/prediction_service\/client.py in explain(self, request, endpoint, instances, parameters, deployed_model_id, retry, timeout, metadata)\n    917             retry=retry,\n    918             timeout=timeout,\n--> 919             metadata=metadata,\n    920         )\n    921 \n\n\/opt\/conda\/lib\/python3.7\/site-packages\/google\/api_core\/gapic_v1\/method.py in __call__(self, timeout, retry, *args, **kwargs)\n    152             kwargs[\"metadata\"] = metadata\n    153 \n--> 154         return wrapped_func(*args, **kwargs)\n    155 \n    156 \n\n\/opt\/conda\/lib\/python3.7\/site-packages\/google\/api_core\/grpc_helpers.py in error_remapped_callable(*args, **kwargs)\n     50             return callable_(*args, **kwargs)\n     51         except grpc.RpcError as exc:\n---> 52             raise exceptions.from_grpc_error(exc) from exc\n     53 \n     54     return error_remapped_callable\n\nInvalidArgument: 400 {\"error\": \"Unable to explain the requested instance(s) because: Invalid response from prediction server - the response field predictions is missing. Response: {'error': '400 Bad Request: The browser (or proxy) sent a request that this server could not understand.'}\"}\n---------------------------------------------------------------------------\n# https:\/\/github.com\/googleapis\/python-aiplatform\/issues\/1526"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Cloud Translation Permission",
        "Question_creation_date":"2022-11-15T07:38:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Cloud-Translation-Permission\/td-p\/489632\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":53.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"So I'm pulling my hair out over this and reaching out here for help. I'm trying to set up a service account with Cloud Translation, and Text-to-speech enabled, but we keep getting this response:I have confirmed that the service account has the \"cloudtranslate.generalModels.predict\" permission, and showing the \"Cloud Translation API User\" role. We've also confirmed that it works with a different Service account that my colleague set up in his personal Google console profile. But, we need this setup with an account through our org. I did verify that the service account has the permission from the https:\/\/console.cloud.google.com\/iam-admin\/troubleshooter so and that my organization's admin sees that the service account is granted access through ancestor policies.  So what else can we check? ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-15T08:30:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Ok, turned out we had a hard-coded value for resource location, which was set to the wrong project. So of course it was coming back as permission denied.\u00a0\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-11-15T08:30:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Ok, turned out we had a hard-coded value for resource location, which was set to the wrong project. So of course it was coming back as permission denied."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Dialogflow should have its own official facebook app for integration",
        "Question_creation_date":"2022-10-13T21:27:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Dialogflow-should-have-its-own-official-facebook-app-for\/td-p\/477998\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":32.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Current dialogflow integration is sensible, however it was very tedious for anyone to must become facebook developer and create their own facebook app. While most of the page's owner are not developer and just want to link some of their page to dialogflowI want to propose that dialogflow should have facebook app with `manage_pages` permission. Have button for oauth with facebook for integration. And just allow user to choose some of their pages to link with dialogflow project. Then all the process in the guideline can be automated. Dialogflow could also config the settings for Webhooks channels it needI want to comment that this was a very roadblock that I have faced when I try to start integrate facebook. The message was not get to dialogflow properly and I don't know I also need `messaging_postbacks` channel, not only `messages`. If Dialogflow app will manage these for us it will be the far much better integration experienceps. Please also add label `Dialogflow` and `Dialogflow ES` to the available label",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-13T21:27:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Current dialogflow integration is sensible, however it was very tedious for anyone to must become facebook developer and create their own facebook app. While most of the page's owner are not developer and just want to link some of their page to dialogflow\n\nI want to propose that dialogflow should have facebook app with `manage_pages` permission. Have button for oauth with facebook for integration. And just allow user to choose some of their pages to link with dialogflow project. Then all the process in the guideline can be automated. Dialogflow could also config the\u00a0settings for\u00a0Webhooks channels it need\n\nI want to comment that this was a very roadblock that I have faced when I try to start integrate facebook. The message was not get to dialogflow properly and I don't know I also need `messaging_postbacks` channel, not only `messages`. If Dialogflow app will manage these for us it will be the far much better integration experience\n\nps. Please also add label `Dialogflow` and `Dialogflow ES` to the available label"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"computational instances at the tool Vertex AI",
        "Question_creation_date":"2022-08-18T04:02:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/computational-instances-at-the-tool-Vertex-AI\/td-p\/455213\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":37.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,\nI have a question about the computational instances at the tool Vertex AI in the field of image classification. What are the underlying instances of the process or where can I find out? I'm looking for Information comparable to these syntax for example: Virtual Machine (CPU: Intel Xeon E5-2690 v3, 6 vCPUs, GPU: NVIDIA Tesla K80, 56 GB RAM, 380 GB SSD)\nThanks\nArndt",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You could look at this comparison table\u00a0of machine types, I think the machine types you are looking for are the N1+GPU and the A2 since these two are the VMs that supports GPU and that can be used for Vertex.\n\nAdditionally check the GPUs document\u00a0to see the details of every GPU."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"deploying model on vertex ai deploymentResourcePool to an endpoint located in another project.",
        "Question_creation_date":"2022-10-26T00:12:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/deploying-model-on-vertex-ai-deploymentResourcePool-to-an\/td-p\/482309\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":91.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I'am trying to deploy a custom trained model to a deployment resource pool that is located in project-1 to an endpoint located in project-2 , I have granted the editor role for project-1 to user account (u1) which also has editor role in project-2. when I try to deploy the model from user account (u1) ,I get the following error:grpc_message:\"DeploymentResourcePool 'projects\/{project-1}\/locations\/us-central1\/deploymentResourcePools\/drlpool' does not exist.*the deployment resource pool (drlpool) exists and also deploys successfully if the endpoint and the deployment Resource Pool are in the same project.",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-27T14:40:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Could you please check the roles granted to your service account as advised in this Stack Overflow question:\n\nFor example you have Project A and Project B, assuming that Project A hosts the model.\n\nAdd service account of Project B in Project A and provide at least roles\/aiplatform.user predefined role. See predefined roles and look for roles\/aiplatform.user to see complete roles it contains.\n\nThis role contains aiplatform.endpoints.* and aiplatform.batchPredictionJobs.* as these are the roles needed to run predictions.\n\nSee IAM permissions for Vertex AI\n\n|Resource|Operation|Permissions needed| |---|---|---| |batchPredictionJobs|Create a batchPredictionJob|aiplatform.batchPredictionJobs.create (permission needed on the parent resource)| |endpoints|Predict an endpoint|aiplatform.endpoints.predict (permission needed on the endpoint resource)|\n\nWith this set up, Project B will be able to use the model in Project A to run predictions.\n\nNote: Just make sure that the script of Project B points to the resources in Project A like project_id and endpoint_id.\n\nIf after that are you still having issuesIf after that you are still having issues it would be better to export the model from project-1 and import into project-2, as shown in the documentation:\n\nThe Model and Endpoint components expose the functionalities of the Vertex AI endpoint and model resources. You can import existing model resources that you've trained outside of Vertex AI, or that you've trained using Vertex AI and exported. After you import your model, this resource is available in Vertex AI. You can deploy this model to an endpoint and then send prediction requests to this resource."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Strange behaviour of ARIMA model",
        "Question_creation_date":"2022-07-22T08:30:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Strange-behaviour-of-ARIMA-model\/td-p\/445988\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":70.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi guys, I'm working with ARIMA Model and I found a strange behaviour.I have two dataset called Then I create two model in this waysample_10_arimasample_11_arimaThen I call the ML.FORECAST function for both in that wayResult for sample_10:Result for sample_11:In the first case sample_10_arima the standard_error is low (around 2.8) but in the sample_11_arima the standard_error is high (between 60 and 101). Why this difference occour? The time series are very similarThanks, Marcello",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-29T14:45:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Can you please file an issue\u00a0 at issue tracker according to this behavior shown?"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"NLP is hard",
        "Question_creation_date":"2021-08-15T22:44:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/NLP-is-hard\/td-p\/167242\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "Cloud Natural Language API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":328.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Who else thinks NLP is the hardest subset of AI to build?",
        "Answers":[
            {
                "Answer_creation_date":"2021-08-15T22:44:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Who else thinks NLP is the hardest subset of AI to build?"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Translate service error - Unsupported language pair",
        "Question_creation_date":"2022-08-25T04:38:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Translate-service-error-Unsupported-language-pair\/td-p\/459774\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_tag":null,
        "Question_upvote_count":3.0,
        "Question_view_count":526.0,
        "Question_answer_count":13,
        "Question_has_accepted_answer":false,
        "Question_body":"Our application started to have some strange error from 25th of August which was working properly until today. Some very basic translation requests get the \"Status(StatusCode=\"InvalidArgument\", Detail=\"Unsupported language pair.\" error. For example the words \"loan\", \"excellent\", \"wonderful\" get the errors from service. I checked the release notes of the service but found nothing. Could you please help about the issue?",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-25T05:20:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"We get the same error for order numbers ABC123 for example will return \"Unsupported language pair.\" But\u00a0ABC1234 works, ABC12 works, ABC123 return error, ABC1233 return error."
            },
            {
                "Answer_creation_date":"2022-08-25T23:49:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Our company also has the same problem unfortunately, one of our internal tools basically cannot be used at all since yesterday."
            },
            {
                "Answer_creation_date":"2022-08-26T00:51:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"We have a similar problem\n\ncode = InvalidArgument desc = Unsupported language pair."
            },
            {
                "Answer_creation_date":"2022-08-26T06:57:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"We are having similar problems with specific language pairs."
            },
            {
                "Answer_creation_date":"2022-08-26T09:45:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"We're having this issue since August, 24 at 01:07 AM.\n\nGoogle.GoogleApiException: Google.Apis.Requests.RequestError\nBad language pair: {0} [400]\nErrors [\n    Message[Bad language pair: {0}] Location[ - ] Reason[badRequest] Domain[global]\n]\nat Google.Apis.Requests.ClientServiceRequest`1.ParseResponse(HttpResponseMessage response)\nat Google.Apis.Requests.ClientServiceRequest`1.ExecuteAsync(CancellationToken cancellationToken)\nat Google.Cloud.Translation.V2.TranslationClientImpl.TranslateHtmlAsync(IEnumerable`1 htmlItems, String targetLanguage, String sourceLanguage, Nullable`1 model, CancellationToken cancellationToken)"
            },
            {
                "Answer_creation_date":"2022-08-29T12:37:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Has this been corrected?"
            },
            {
                "Answer_creation_date":"2022-08-29T22:04:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I believe so, I tested yesterday and had no issues."
            },
            {
                "Answer_creation_date":"2022-09-01T03:19:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The same error!\n\nExample of translated text: \"\u041c\u0430\u0441\u043b\u043e MITASU 5W30 PLATINUM PAO SN Dexos2 1L\"\n\nTranslation to Romanian from autodetect using NeuralMachineTranslation.\n\nif the word \"PAO\" is removed, it translate ok."
            },
            {
                "Answer_creation_date":"2022-09-07T06:40:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"It has been fixed. Thanks"
            },
            {
                "Answer_creation_date":"2022-09-07T21:17:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Issue still exist for English to Romanian translation. appreciate any thoughts."
            },
            {
                "Answer_creation_date":"2022-09-09T01:47:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Unfortunately we started to get same exception (Unsupported language pair.)\u00a0 with the following inputs while translating to English (en-US) Is there any new deployment to the service? Could you please check?\n\nSome Sample Problematic Inputs :\u00a0\"Ok\" , \"1000\", \"wonderful\""
            },
            {
                "Answer_creation_date":"2022-09-09T12:24:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Unclear if it's related, but a well known Trados plug-in for Google AutoML machine translation engine is also failing with the same error and this is also new.\u00a0 See\u00a0https:\/\/community.rws.com\/product-groups\/trados-portfolio\/rws-appstore\/f\/rws-appstore\/43110\/mt-enhan....\u00a0 \u00a0This is with V3 Advanced API, but looks like what is reported her is happening with V2 Basic API."
            },
            {
                "Answer_creation_date":"2022-09-13T13:47:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"We found a solution for this issue.\n\nFor OpenSay, when we used Cloud Translation's REST API's analyzeText method with an English content and a target language type 'en-US' it failed with \"Unsupported language pair.\".\u00a0\n\nIt took some tinkering, but eventually we changed the 'en-US' to 'en' and it worked."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Changing the service account for an endpoint",
        "Question_creation_date":"2022-11-21T01:37:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Changing-the-service-account-for-an-endpoint\/td-p\/491278\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":28.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi, I have deployed a Vertex AI model that was created using a custom image. However, when I tried deploying to an endpoint, it fails when it tries to run this line:In the logs, there was an error message that readsIt appears that the endpoint has been assigned a service account that is not associated with my account. From this documentation (https:\/\/cloud.google.com\/ai-platform\/prediction\/docs\/custom-service-account), it appears that a service account managed by AI Platform Prediction is being used when a custom container is being used. However, my account does not have the permissions to create another custom service account, as it is being managed by my client. I came across this solution (https:\/\/stackoverflow.com\/questions\/68456262\/gcp-vertex-ai-model-access-gcs-failed) where the user had the exact same problem and solved it by changing the service account used at the endpoint. As such, I would like to ask how it will be possible for me to change the service account used by the endpoint without having to create a new service account?Thank you.",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-21T01:37:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, I have deployed a Vertex AI model that was created using a custom image. However, when I tried deploying to an endpoint, it fails when it tries to run this line:\n\nbucket = client.get_bucket(\"my-project-id\")\n\nIn the logs, there was an error message that reads\n\ngoogle.api_core.exceptions.Forbidden: 403 GET https:\/\/storage.googleapis.com\/storage\/v1\/b\/{my project ID}?projection=noAcl&prettyPrint=false: custom-online-prediction@{some random numbers}-tp.iam.gserviceaccount.com does not have storage.buckets.get access to the Google Cloud Storage bucket. Permission 'storage.buckets.get' denied on resource (or it may not exist).\n\nIt appears that the endpoint has been assigned a service account that is not associated with my account. From this documentation (https:\/\/cloud.google.com\/ai-platform\/prediction\/docs\/custom-service-account), it appears that a\u00a0service account managed by AI Platform Prediction is being used when a custom container is being used. However, my account does not have the permissions\u00a0to create another custom service account, as it is being managed by my client.\u00a0\n\nI came across this solution (https:\/\/stackoverflow.com\/questions\/68456262\/gcp-vertex-ai-model-access-gcs-failed) where the user had the exact same problem and solved it by changing the service account used at the endpoint. As such, I would like to ask how it will be possible for me to change the service account used by the endpoint without having to create a new service account?\n\nThank you."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Dialogflow CX Intergration with Messenger from Facebook",
        "Question_creation_date":"2022-11-15T20:29:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Dialogflow-CX-Intergration-with-Messenger-from-Facebook\/td-p\/489873\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":39.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi, I have some issue when I integrate dialogflow cx with messenger. \nThe issue is I didn't get response from my bot, I have a suspect that dialogflow failed to send message to user on messenger.\nSo, my problem now is how to check sending message process in dialogflow to get the detail of error?Thanks",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-17T09:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"To see logs for DialogFlow, you would need to enable Cloud Logging\u00a0in your agent\u2019s general settings. After enabling logging, you\u2019d be able to see DialogFlow logs for requests and responses (including for webhooks). Let me know if you have additional questions."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Google assistant and cloud speech API not working",
        "Question_creation_date":"2022-04-06T04:59:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-assistant-and-cloud-speech-API-not-working\/td-p\/410871\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text",
            "Text-to-Speech"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":94.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am having problem using Google cloud platform.I bought Google AIY voice kit from AliExpress.com. I discovered it was an old version. Two weeks ago, I used Etcher to flash aiyprojects-2021-04-02.img.xz from GitHub on an SD card and set up my voice kit. Hardware testing was good. I then created a project, named \u201cVoice Kit\u201d, on google cloud following directions given on \"aiyprojects.withgoogle.com\/voice-v1\/\". I had the following experience:It would be appreciated if I could be educated on the following:",
        "Answers":[
            {
                "Answer_creation_date":"2022-04-20T18:11:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nI see you have concerns relating to the Google AIY Projects and your configurations. I think your Questions will be better supported by the Google AIY Support team[0]. The help page[1] also includes help links on various forums that may have the type of information that you need. For example, your Question about your Question 2, you explained that you are unsure which of the Cloud Speech APIs to use. Whether the Cloud speech-to-text API or the Cloud text-to speech API? Well, the help page seems to include an hyperlink[2] for the Cloud Speech API to use.\n\nAgain, I think your Questions will be better supported by the Google AIY Support team.\n\nI hope this information helps.\n\n[0]support-aiyprojects@google.com.\n[1]https:\/\/aiyprojects.withgoogle.com\/help\/\n[2]https:\/\/cloud.google.com\/speech-to-text\/docs\/"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Google Cloud AutoML Vision annotation stopped working",
        "Question_creation_date":"2022-11-18T13:16:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Cloud-AutoML-Vision-annotation-stopped-working\/td-p\/490920\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":55.0,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"Has anyone encountered the issue where the AutoML Vision annotations for datasets stopped working. This includes not being able to change labels anymore, not being able delete created labels or not save create labels. The annotations were working as expected last week, but for some reason they stopped working this week.",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-21T22:46:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Can you share the screenshot?"
            },
            {
                "Answer_creation_date":"2022-11-22T07:47:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Here is a screenshot of one of the images in my dataset. I can add annotations of the default label type, but cannot change the type of label afterwards. As you can see the default is all cropland labels but since I cannot change the label type, all of them are stuck as \"cropland\"(even though there are 3 labels available for this dataset).\n\n\u00a0The labels behaves as if they are a regular text instead of a dropdown list.\n\nAlso the delete button for each of the labels do not work, as it appears but nothing happens when you click it. Moreover, the cancel button at the bottom of the screen is clickable but does not do anything either."
            },
            {
                "Answer_creation_date":"2022-11-22T08:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for sharing\u00a0@akanel, since this seems to be an issue specific to your project, you may raise a 1:1 GCP support. This kind of support has access to your internal resources and may check your issue in a more comprehensive way."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Auto ML edge training failure",
        "Question_creation_date":"2022-10-30T16:14:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Auto-ML-edge-training-failure\/td-p\/483746\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":36.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am training an edge model in vertex AI. It is failing after a few hours. Details in the screenshot below. Tried 4 times and failed all 4 times. I cannot see to see any detail at all on the error. Can someone from Vertex AI please help? Training fails after about 3 hours if I pick the highest accuracy option but seems to process if I pick the 'best trade-off' options.  Screenshot of the of the failed jobs below.Screenshot upload fails just like getting any support from Google.  The training pipeline id is 2116799302125748224",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-01T15:06:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"For this type of inquiry the appropriate support channel would be creating a support case\u00a0directly with Google Cloud. This would enable support to directly work with you and your project for solutions, specially when logs are not available for the community in this forum."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"No results with is_final true for single utterance set to true",
        "Question_creation_date":"2022-10-11T06:18:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/No-results-with-is-final-true-for-single-utterance-set-to-true\/td-p\/476809\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":72.0,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"I am using below configuration to identify my voice input stream (Hindi language)  :",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-12T09:20:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Have you confirmed whether changing the set_interim_results()\u00a0property to `false` changes the output result? Based on the documentation, using false\u00a0as the argument will only return results with is_final=true."
            },
            {
                "Answer_creation_date":"2022-10-13T06:25:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for your response.\n\nI do not get any results if I change set_interim_results() property to false.\u00a0\n\nI did get some interim results when the property was set to true and\u00a0\n\nspeech_event_type() did return 1. Usually, I get response with is_final set to true, but this does not happen in this case . Below is the log from my application when\u00a0set_interim_results() is set to true\u00a0:\n\n\u00a0\n\n\u00a0\n\n\u00a0\n\nhlpr_start_stream() ----> !!!!!!!!!!!!!! Vaibhav :: single_utternace :  ======== : 0\n\n2022-10-11 09:24:15:824114 [INFO]    hlpr_start_stream() --> printing results : 0.900000\n\n2022-10-11 09:24:15:824126 [INFO]   hlpr_start_stream() ---> !!!!!!!!!!!!!! inside 2nd if -------------------------------------\n\n2022-10-11 09:24:15:824132 [INFO]    ########## hlpr_start_stream() printing interim results transcript  #####: \u0907\u0938\n\n2022-10-11 09:24:15:824139 [INFO]    hlpr_start_stream() -----Vaibhav :: time_since_epoch() = 0 \n\n2022-10-11 09:24:18:257357 [INFO]   hlpr_start_stream() ----> !!!!!!!!!!!!!! Vaibhav :: single_utternace :  ======== : 1\n\n\u00a0\n\nMy application keeps on waiting for response till I close the stream."
            },
            {
                "Answer_creation_date":"2022-10-17T13:31:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"As your application remains waiting until you close the stream, have you verified that the final result of the transcription is not merely taking additional time? As an example, this issue\u00a0shows similar behavior involving not receiving the final transcription quickly, depending on the language. Are you experiencing the same behavior even when using a different language?"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Commercial usage of Google Cloud TTS",
        "Question_creation_date":"2022-08-21T18:48:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Commercial-usage-of-Google-Cloud-TTS\/td-p\/458420\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_tag":null,
        "Question_upvote_count":2.0,
        "Question_view_count":117.0,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,I wish to use Google cloud's Wavenet TTS (TextToSpeech) for commercial use for my company. Can anyone please confirm whether it is allowed or not?RegardsUtkarsh Dubey",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-21T22:59:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I am sure its not allowed, you can use it only if you choose to use for informative or project purpose, if you wanna use it for commercial purpose get it by being in touch with google cloud partner coordinator here.\u00a0\u00a0Enroll and proceed with further steps.\n\n- Nihal"
            },
            {
                "Answer_creation_date":"2022-08-22T00:04:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"What is covered under informative\/project use?\nBy commercial use, i meant we will be using it to develop voice-over for our videos. The videos will be used in marketing. Need confirmation on wether it allowed or not."
            },
            {
                "Answer_creation_date":"2022-08-30T10:54:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I actually have this exact same question. Someone from chat support was meant to get back to me but I never heard back"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Model Selection \/ Feature Engineering",
        "Question_creation_date":"2022-08-02T05:27:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Model-Selection-Feature-Engineering\/td-p\/449387\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":40.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hey There,I am writing my Master Thesis at the moment. I am comparing AutoML products for image classification. There I compare the product Vertex AI with to Azure. However, I can't find the concrete methods of feature engineering and model selection from the documentation.Thanks a lot!",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-03T14:14:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Using Vertex Ai You can train models on Vertex AI by using AutoML, or if you need the wider range of customization options available in AI Platform Training, use custom training.\n\nIn custom training, you can select from among many different machine types to power your training jobs, enable distributed training, use hyperparameter tuning, and accelerate with GPUs. See the full custom training documentation here.\u00a0\n\nAdditionally there are 4 other models:\n\nImage Data.\nTabular Data.\nText Data.\nVideo Data."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Google Cloud Translation language support for bcp-47",
        "Question_creation_date":"2022-07-20T20:15:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Cloud-Translation-language-support-for-bcp-47\/td-p\/445359\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":73.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Google Speech to Text supports languages using bcp 47 codes like es-MX for mexican spanish and pt-BR for Brazilian Portugese.I am using transcription and translation in a pipeline.Is there any support for bcp 47 languages in Google Cloud Translation. ",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-25T15:24:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Any BCP47 input or most legacy versions language codes should just work and there is no need to convert to a particular standard.\nAdditionally you can see here the full list of particular ISO languages codes.\n\nNote that ISO 639-1 on its own isn't sufficient to differentiate between written languages; mix up zh-CH and zh-TW ."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Google Translate Cloud API",
        "Question_creation_date":"2021-12-06T05:03:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-Translate-Cloud-API\/td-p\/177308\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Natural Language API",
            "Text-to-Speech"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":208.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi All,I have recently started using Google cloud translate API with python. M having trouble converting this word in the Telugu language which is written in English \"parishkaram chesamu\".  In general internet or mobile the application google translate which we use is giving correctly. But API is returning the same word again.Google Cloud translate API:Input text: parishkaram chesamuOutput text: parishkaram chesamuparameters : text ='''parishkaram chesamu'''\ntarget = \"en\"\noutput = translate_client.translate(text)print(output) --> {'translatedText': 'parishkaram chesamu', 'detectedSourceLanguage': 'te', 'input': 'parishkaram chesamu'}================================Mobile or Internet google translate:Input text : parishkaram chesamuOutput text: We have solved",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-28T14:01:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Aditya,\n\nYou are writing Telugu language in English \"parishkaram chesamu\" instead of \"\u0c2a\u0c30\u0c3f\u0c37\u0c4d\u0c15\u0c3e\u0c30\u0c02 \u0c1a\u0c47\u0c38\u0c3e\u0c2e\u0c41\"\n\nCurrently the Translate app has the \"Spell check feature\" that responds with both the \"Did you mean\" phrase identified and the corresponding translated result, as oppose to the Translation API.\n\nThe \"did you mean\" text comes from Google's spell check API (the same one that suggests alternative searches when using Google search). When you use the translate API directly you are skipping the spell checking, and that's why you don't get a translation.\n\nThere's already a feature request\u00a0to have a spell check feature in the Translation API response."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Google translator is free or has any kind of pricing?",
        "Question_creation_date":"2022-09-05T23:52:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-translator-is-free-or-has-any-kind-of-pricing\/td-p\/463225\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":64.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I'm using this code for translating my website in my angular project. I'm not using translate API provided by google cloud. So, I just need to confirm that the source I'm using is paid for publicly available (free)?",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-15T11:47:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"TRANSLATION is a basic free Google service for users to translate their website content on the web browser side. There are some disadvantages using this such as the Search Engine Optimization and there are limits while using it."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Error uploading csv file to Vertex DataSets",
        "Question_creation_date":"2022-06-17T09:23:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Error-uploading-csv-file-to-Vertex-DataSets\/td-p\/432499\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":66.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi to allTrying to upload a .csv file to AutoMl for training.Not sure what Im doing wrong, I save the file as csv encode utf 8 and values separated by comma and with both cases getting the error that you will find in the next image.Do I need to upload the files to Cloud Storage or Google BigQuery before using them for training? When trying to create and train the model got the warning from the next image:",
        "Answers":[
            {
                "Answer_creation_date":"2022-06-27T14:15:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"This could be occurring because you have formatting errors in your dataset, could you trim newlines and extra white spaces\u00a0on your dataset, remember that Vertex wants the text inside of your CSV to look like the examples I'm sharing.\n\n\"this is a sentence, with a comma\", 0\n\nAlso which dataframe are you using? Are you for any chance using Pandas?"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Cloud Vision API in Vertex AI?",
        "Question_creation_date":"2022-11-28T02:59:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Cloud-Vision-API-in-Vertex-AI\/td-p\/493648\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "Cloud Vision API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":22.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"  Hi,I am a newbie in Google Cloud and i have an elementary conceptual question about the dependency between Cloud Vision API and Vertex AI or the recently launched Vertex Vision AI.I have an app that makes predictions on images using Google Vision AI API ImageAnnotatorClient() Is this API going to be part of  Vertex AI  or Vertex Vision AI?Or in other words, should I modify the below code to make it part of Vertex AI\/Vertex Vision AI?          ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-28T02:59:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nI am a newbie in Google Cloud and i have an elementary conceptual question about the dependency between\u00a0Cloud Vision API and Vertex AI or the recently launched Vertex Vision AI.\n\nI have an app that makes predictions on images using Google Vision AI API\u00a0ImageAnnotatorClient()\u00a0\n\nIs this API going to be part of\u00a0 Vertex AI\u00a0 or Vertex Vision AI?\n\nOr in other words, should I modify the below code to make it part of Vertex AI\/Vertex Vision AI?\n\n\u00a0\n\nfrom google.cloud import vision\n\ndef detect_labels_uri(uri):\n    client = vision.ImageAnnotatorClient()\n    image = vision.Image()\n    image.source.image_uri = uri\n\n    response = client.label_detection(image=image)\n    labels = response.label_annotations\n    return(labels)"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Mount gcsfuse in gcloud ai custom-jobs local-run",
        "Question_creation_date":"2022-09-28T00:51:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Mount-gcsfuse-in-gcloud-ai-custom-jobs-local-run\/td-p\/471834\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":96.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"When locally testing my custom-job through \"gcloud ai custom-jobs local-run\" command, I would like to have access to a bucket mounted though gcsFuse as it happens when I launch the same containerized job from GCloud console. Is there the option to have the same access locally?Thank you for helping",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-30T08:43:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"What you could do is use cloud storage as a file system within ai training, since while using fuse your training jobs on both of the platforms can access your data that is stored on Cloud Storage as files on your local file system, also the documentation I shared provides you useful information as the problems you might encounter, permissions, a brief description of cloud storage fuse, performance related information, the restrictions this method has and also how you can make use of the logs.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-09-30T08:43:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"What you could do is use cloud storage as a file system within ai training, since while using fuse your training jobs on both of the platforms can access your data that is stored on Cloud Storage as files on your local file system, also the documentation I shared provides you useful information as the problems you might encounter, permissions, a brief description of cloud storage fuse, performance related information, the restrictions this method has and also how you can make use of the logs."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"speech-to-text improvements",
        "Question_creation_date":"2021-11-01T09:36:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/speech-to-text-improvements\/td-p\/174445\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":331.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Good afternoon!I am a user of Speech-to-Text. I use it in order to get a written text from the interviews and courses I shoot myself. After that I correct the text manually.So, in Russian it works fine, however, 30-40 percents of the words are incorrect. Moreover, there are no Russian punctuation at all.  So I get the speech-to-text transcript, then I create the perfect transcript out of this with correct words and punctuations.All I want to know is how I can improve Speech-to-Text by using the perfect transcript I have already corrected? Where I can send that data to?P.S. Sorry for my English. I hope You can understand me",
        "Answers":[
            {
                "Answer_creation_date":"2021-11-05T07:50:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\u00a0\n\nIf you're using the Google Cloud Speech-to-Text API [1] and encounter text quality problem, I would suggest that you can report the issue at the Issue Tracker [2] with the reproduction details for the support to further look into issue with you to improve the quality.\u00a0\n\n[1]\u00a0https:\/\/cloud.google.com\/speech-to-text\n[2]\u00a0https:\/\/cloud.google.com\/support\/docs\/issue-trackers"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Dialogflow cx v3 DetectIntentRequest returning no-match",
        "Question_creation_date":"2022-10-26T13:55:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Dialogflow-cx-v3-DetectIntentRequest-returning-no-match\/td-p\/482545\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":32.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am trying to create and manage agents using exclusively the api.  I have created an agent with one intent only:name: \"projects\/???\/locations\/global\/agents\/1828e34b-78bc-48f5-9212-6dd83497d409\/intents\/b9e91883-f358-46ea-9661-a8a39c7d2557\"\ndisplay_name: \"test-age\"\ntraining_phrases {\nparts {\ntext: \" I am \"\n}\nparts {\ntext: \" 23 \"\nparameter_id: \"p0\"\n}\nrepeat_count: 1\n}\ntraining_phrases {\nparts {\ntext: \" my age is \"\n}\nparts {\ntext: \" 68 \"\nparameter_id: \"p1\"\n}\nrepeat_count: 1\n}\ntraining_phrases {\nparts {\ntext: \" I am \"\n}\nparts {\ntext: \" 44 \"\nparameter_id: \"p2\"\n}\nrepeat_count: 1\n}\ntraining_phrases {\nparts {\ntext: \" age \"\n}\nparts {\ntext: \" 81 \"\nparameter_id: \"p3\"\n}\nrepeat_count: 1\n}\ntraining_phrases {\nparts {\ntext: \" age is \"\n}\nparts {\ntext: \" 35 \"\nparameter_id: \"p4\"\n}\nrepeat_count: 1\n}\ntraining_phrases {\nparts {\ntext: \" the age is \"\n}\nparts {\ntext: \" 29 \"\nparameter_id: \"p5\"\n}\nrepeat_count: 1\n}\ntraining_phrases {\nparts {\ntext: \" 37 \"\nparameter_id: \"p6\"\n}\nparts {\ntext: \" years of age \"\n}\nrepeat_count: 1\n}\ntraining_phrases {\nparts {\ntext: \" 45 \"\nparameter_id: \"p7\"\n}\nparts {\ntext: \" years \"\n}\nrepeat_count: 1\n}\ntraining_phrases {\nparts {\ntext: \" 52 \"\nparameter_id: \"p8\"\n}\nparts {\ntext: \" years old \"\n}\nrepeat_count: 1\n}\nparameters {\nid: \"p0\"\nentity_type: \"projects\/-\/locations\/-\/agents\/-\/entityTypes\/sys.number-integer\"\n}\nparameters {\nid: \"p1\"\nentity_type: \"projects\/-\/locations\/-\/agents\/-\/entityTypes\/sys.number-integer\"\n}\nparameters {\nid: \"p2\"\nentity_type: \"projects\/-\/locations\/-\/agents\/-\/entityTypes\/sys.number-integer\"\n}\nparameters {\nid: \"p3\"\nentity_type: \"projects\/-\/locations\/-\/agents\/-\/entityTypes\/sys.number-integer\"\n}\nparameters {\nid: \"p4\"\nentity_type: \"projects\/-\/locations\/-\/agents\/-\/entityTypes\/sys.number-integer\"\n}\nparameters {\nid: \"p5\"\nentity_type: \"projects\/-\/locations\/-\/agents\/-\/entityTypes\/sys.number-integer\"\n}\nparameters {\nid: \"p6\"\nentity_type: \"projects\/-\/locations\/-\/agents\/-\/entityTypes\/sys.number-integer\"\n}\nparameters {\nid: \"p7\"\nentity_type: \"projects\/-\/locations\/-\/agents\/-\/entityTypes\/sys.number-integer\"\n}\nparameters {\nid: \"p8\"\nentity_type: \"projects\/-\/locations\/-\/agents\/-\/entityTypes\/sys.number-integer\"\n}\npriority: 500000However, when I try to detect that intent using the DetectIntentRequest as shown in the github samples I keep getting no-match results:====================\nQuery Text: ' I am 55 '\nDetected Intent: text: \" I am 55 \"\nlanguage_code: \"en\"\nresponse_messages {\ntext {\ntext: \"Sorry, could you say that again?\"\n}\n}\ncurrent_page {\nname: \"projects\/???\/locations\/global\/agents\/1828e34b-78bc-48f5-9212-6dd83497d409\/flows\/00000000-0000-0000-0000-000000000000\/pages\/START_PAGE\"\ndisplay_name: \"Start Page\"\n}\nintent_detection_confidence: 0.3\ndiagnostic_info {\nfields {\nkey: \"Alternative Matched Intents\"\nvalue {\nlist_value {\n}\n}\n}I did train the agent in advance. Appreciate any help",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-27T10:17:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, mihai527,\n\nI understand that you are experiencing the issue with the transcription which is not responding as expected, and this is a transient issue. Instead of identifying the user age, it is Invoking the No-Match event. Please let me know if I have misunderstood.\n\nHere it seems like an issue with the speech adaption. In regards to that, can you please Enable speech adaptation? The auto speech adaptation feature improves the speech recognition accuracy of your agent by automatically using conversation state to pass relevant entities and training phrases as speech context hints for all detect intent requests. This feature is disabled by default.\n\nYou may follow this doc\u00a0to achieve this. Please let me know if this resolves your issue or not. Also, you may follow this doc, which talks about Voice agent design best practices.\n\nPlease let me know if you have any questions regarding the information provided above. I will be happy to assist you.\n\nI will be looking forward to your response."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Will Google provide MTQP in Cloud Translation API?",
        "Question_creation_date":"2022-10-25T12:27:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Will-Google-provide-MTQP-in-Cloud-Translation-API\/td-p\/482115\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":41.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi, I discovered with interest that your Google Translation Hub advanced tier offers document post-editing features, and, as part of that, includes an MTQP quality prediction score on a segment by segment basis. \n\nThis would be a very interesting feature to include in Cloud Translation API, particularly for TMS and CAT tools like Trados\/MemoQ\/Memsource that could then provide that information to the translator, similar to what a fuzzy match is for traditional Translation Memory technology.\n\nIt could also be very useful to decide whether a raw machine translation process (without review) is suitable for a document, or to identify the few segments that absolutely must go through human editing depending on your acceptable quality profile.So my question is whether Google is looking at making this available in the API, or whether Google is treating that as proprietary information that you guys do not want to make available outside of your Google Translation Hub?  I really hope the answer is the former, not the latter...\n\nThank you.\n\nMichel Farhi\nPrincipal Localization Engineer\nNI (formerly National Instruments)",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-25T12:27:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\u00a0\n\nI discovered with interest that your Google Translation Hub advanced tier offers document post-editing features, and, as part of that, includes an MTQP quality prediction score on a segment by segment basis.\u00a0\n\nThis would be a very interesting feature to include in Cloud Translation API, particularly for TMS and CAT tools like Trados\/MemoQ\/Memsource that could then provide that information to the translator, similar to what a fuzzy match is for traditional Translation Memory technology.\n\nIt could also be very useful to decide whether a raw machine translation process (without review) is suitable for a document, or to identify the few segments that absolutely must go through human editing depending on your acceptable quality profile.\n\nSo my question is whether Google is looking at making this available in the API, or whether Google is treating that as proprietary information that you guys do not want to make available outside of your Google Translation Hub?\u00a0 I really hope the answer is the former, not the latter...\n\nThank you.\n\nMichel Farhi\nPrincipal Localization Engineer\nNI (formerly National Instruments)"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Google ML kit",
        "Question_creation_date":"2022-08-10T08:12:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Google-ML-kit\/td-p\/452579\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "Video Intelligence API"
        ],
        "Question_tag":null,
        "Question_upvote_count":1.0,
        "Question_view_count":106.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"I know Google provides an ML kit supported by android that we can integrate into an app. The ML Kit provides many Vision and NLP APIs that can help us make our own Google-like Lens.Anyone can give me more information on how to get the ML kit?I am the CEO and I am looking for a CTO to my company, must be good in Python, A.I., Machine Learning, IoT and Robotics.",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-15T10:45:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"ML Kit is a mobile SDK that brings Google's on-device machine learning expertise to Android and iOS apps. To use ML Kit on Android you\u2019ll need to add the libraries to your module's app-level gradle file. To use on Ios you need to include the ML Kit pods in your Podfile.\n\nYou can use this document\u00a0to see the whole product's quickstarts.\n\nAdditionally see the left menu guides\u00a0for each product and how to use it on Ios or Android."
            },
            {
                "Answer_creation_date":"2022-08-16T20:54:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello\n\nThank you for the information."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Total Novice",
        "Question_creation_date":"2022-05-10T19:42:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Total-Novice\/td-p\/421957\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":41.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Friends,Can I submit a file for conversion from speech to text without having to learn computer coding - even if it is at a very simple level? Can I just submit the file somewhere for transcription?Thank You,Just, simply, a consumer",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Yes you can and I would also appreciate help.\n\nMake a bucket, go through the settings and be sure it's a private bucket.\n\nSearch up text to speech in the main screen. It's probably one audio channel and for hz you can either open the audio file with alt + enter to see if it shows you what the Hz is or use audacity audio software and load the file into audacity.\n\nAs someone who doesn't understand anything about code, my problem is that my audio files are and should all be contained individually, each in one file."
            },
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi ,\n\nYes you can do that. Just upload your audio file\u00a0 , click button and download your transcript audio file.\n\nhttps:\/\/cloud.google.com\/speech-to-text"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Vertex AI explain with a custom trained scikit-learn classification model",
        "Question_creation_date":"2022-06-30T09:32:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-explain-with-a-custom-trained-scikit-learn\/td-p\/436711\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":1.0,
        "Question_view_count":282.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi Google Community,I was wondering, has anyone been able to successfully train and deploy a custom trained scikit-learn classification model and deploy it to a vertex endpoint with the feature attribution through the explain endpoint working?Every time i define my instances, predictions and explanation_spec while uploading my model, i get errors on the endpoint for the :explain method. Specifically, i get '400 bad request' with no information on why it was a bad request.I am using the v1beta1 ai platform python SDK and also am using a custom basic serving container. The custom container works for :predict but :explain does not work. Is there some example code out there? Is scikit-learn not supported for feature attribution? Thanks! Ryan",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-14T16:51:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"For anyone looking back on this, i was able to use the following notebook to solve my problem. It seems we need to use encoding BAG_OF_FEATURES. I am not to sure why this is required, but it seems to have done the trick for me.\n\nhttps:\/\/github.com\/GoogleCloudPlatform\/vertex-ai-samples\/blob\/main\/notebooks\/community\/ml_ops\/stage4...\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-07-06T13:32:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"The easiest (and recommended) way to create a training application package uses gcloud to package and upload the application when you submit your training job.\n\nHere\u00a0you can see documentation that will guide you through all of the steps that you need to follow to implement your scikit trained model."
            },
            {
                "Answer_creation_date":"2022-07-14T16:51:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"For anyone looking back on this, i was able to use the following notebook to solve my problem. It seems we need to use encoding BAG_OF_FEATURES. I am not to sure why this is required, but it seems to have done the trick for me.\n\nhttps:\/\/github.com\/GoogleCloudPlatform\/vertex-ai-samples\/blob\/main\/notebooks\/community\/ml_ops\/stage4..."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Model adaptation - Speech-to-Text - GA?",
        "Question_creation_date":"2021-10-19T08:44:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Model-adaptation-Speech-to-Text-GA\/td-p\/173368\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":365.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,I'd like to know if Model adaptation feature is ready to use in production (custom classes, phrase sets, etc). Official web documentation (https:\/\/cloud.google.com\/speech-to-text\/docs\/model-adaptation) says it is a preview feature (Pre-GA). Also, REST resources are inside namespace v1p1beta1 (https:\/\/cloud.google.com\/speech-to-text\/docs\/reference\/rest).On the other hand, release notes web page (https:\/\/cloud.google.com\/speech-to-text\/docs\/release-notes#May_07_2021) says \"The Speech-to-Text model adaptation  feature is now a GA feature\".Thank you very much,Pablo Gomez",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello Pablo\n\nThe documentation [1] was just updated 2021-10-27 UTC, and there is no 'preview feature' mentioned in it.\n\nAlso release notes are always more reliable source of information regarding feature updates for Google Cloud Platform\n\nBest Regards,\nKailong\nGoogle Cloud Platform Support, Montreal\n\n[1] https:\/\/cloud.google.com\/speech-to-text\/docs\/model-adaptation"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Error in GCP Doc AI project",
        "Question_creation_date":"2022-11-09T03:59:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Error-in-GCP-Doc-AI-project\/td-p\/487561\/jump-to\/first-unread-message",
        "Question_topic":[
            "Document AI"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":40.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Good evening . My peer while try to access Document AI page is getting the below error . Facing this issue from 2 PM yesterday. We are working for a POC project from LTI organization. Basically, it should show some processors or specialized processors. Please can you guide us.Regards,Vamsi ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-10T13:50:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"For this kind of issue, please contact Google Cloud support.\n\nFile a support case"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Idle shutdown for user-managed notebook (vertex-AI)",
        "Question_creation_date":"2022-06-02T07:10:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Idle-shutdown-for-user-managed-notebook-vertex-AI\/td-p\/428171\/jump-to\/first-unread-message",
        "Question_topic":[
            "Vertex AI Model Registry"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":188.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"There are two types of notebooks in Vertex-AI1) managed notebook: https:\/\/cloud.google.com\/vertex-ai\/docs\/workbench\/managed\/introduction2) user-managed notebook: https:\/\/cloud.google.com\/vertex-ai\/docs\/workbench\/user-managed\/introductionI see that the former has a useful function called \"idle shutdown\" that help manage costs: managed notebooks instances shut down after being idle for a specific time period by default.Why we didn't make it available for user-managed notebook as well? Thanks",
        "Answers":[
            {
                "Answer_creation_date":"2022-06-02T22:36:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for the feedback here. We are aware of the request and this is further to prioritize this work. Happy to get back when we have a concrete plan for this feature."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How would you model a list of an unknown number of items in DialogFlow CX?",
        "Question_creation_date":"2022-11-21T19:25:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-would-you-model-a-list-of-an-unknown-number-of-items-in\/td-p\/491605\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":35.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,Taking from the example at Dialogflow CX: Build a retail virtual agent , if you were to build a shopping cart where users could add unlimited items to purchase. How would you model a solution for this?That is, instead of having:Can we have something equivalent to:How?",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-22T10:23:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nYou might want to see this example where the user created a shopping cart based using Dialogflow CX."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"vertex AI Workbench is hanging with error \"Opening notebook with JupyterLab\" for more than a day",
        "Question_creation_date":"2022-09-08T08:12:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/vertex-AI-Workbench-is-hanging-with-error-quot-Opening-notebook\/td-p\/464300\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":112.0,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"I am trying to follow instructions in https:\/\/cloud.google.com\/vertex-ai\/docs\/tutorials\/jupyter-notebooks (vertex AI Jupyter Notebooks tutorials). Steps done1. For the first notebook \"Text Classification model\" I have clicked on \"Vertex AI Workbench\". It takes me to GCP console & workbench.2. I am supposed to click on the \"Create\" button, which I did.3. THen the message \"Opening notebook with JupyterLab\" will come. But it is there for past 1 day, and still it hasn't finished creating. So I canceled the same. I tried once more the same thing happens. Not sure why?I have screen shots, but can't see anywhere to attach.Have anyone tried this tutorial, especially in workbench? Thanks,",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-08T22:12:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\u00a0\n\nAnybody active on these forums?\n\nIdeally some GCP reps should be there. Especially with newer offering like vertexAI - fundamental issues should be easy to solve!!"
            },
            {
                "Answer_creation_date":"2022-09-09T00:01:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Today I have retried the same. It worked at least creation of notebook.\n\nBut when executing step\n\nInstall additional packages\n\nInstall the following packages for executing this notebook.\n\nI am getting error:\n\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-recommendations-ai 0.2.0 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.8.1 which is incompatible.\napache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\napache-beam 2.40.0 requires pyarrow<8.0.0,>=0.15.1, but you have pyarrow 9.0.0 which is incompatible.\n\n\u00a0\n\nAny help?"
            },
            {
                "Answer_creation_date":"2022-09-20T14:32:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"After searching for a solution for your case, it seems to be more an issue of the package version.\n\nI found a GitHub repository dealing with a similar problem to yours; there, you will likely find solutions to resolve it."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Fast Start GPU for AI training",
        "Question_creation_date":"2021-09-02T02:41:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Fast-Start-GPU-for-AI-training\/td-p\/168768\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":1.0,
        "Question_view_count":341.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Is there a way to fast start-up GPU (like Cloud RUN) if there is training request come-in?Due to GPU cost is high, turn-on 24 hours\/day does not make sense.Pre-empted GPU cloud be another option but offer only 1st minute free.",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I made a 4000-word guide for people looking to build Nvidia Ampere prosumer workstations and servers, including:\n\n\u00a0\n\nDifferent budget tiers\n\nWhere to place them, home, office, data center, etc.\n\nConstraints with consumer GPUs\n\n\u00a0\n\nMy CC Pay"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"The kernel for MyTest.ipynb appears to have died. It will restart automatically.",
        "Question_creation_date":"2022-11-24T11:01:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/The-kernel-for-MyTest-ipynb-appears-to-have-died-It-will-restart\/td-p\/492715\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":33.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,I'm trying to run a test jupyter notebook of a LSTM model running tensorflow. I have tried setting the GPU memory limit like suggested here. But still the I get the error mentioned above. I can not find anything realted to GC vertex AI and everyone suggest setting the gpu memory in case of such errors. For reference I have tried to run this as well on my Vertex AI jupyter lab and it crashes as well. The only thing I added was this:gpus = tf.config.list_physical_devices('GPU')\nif gpus:\ntf.config.set_logical_device_configuration(\ngpus[0],\n[tf.config.LogicalDeviceConfiguration(memory_limit=12288)]\n)logical_gpus = tf.config.list_logical_devices('GPU')\nprint(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")On my personal computer it runs just fine, but it would take 13 hours to train which is not a option for me at the moment.Any help would be appriciated. Barnabas.",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-28T12:08:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, can you share the error you encountered?"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"VertexAI- Auto ML training model failed without giving the reason",
        "Question_creation_date":"2022-07-21T00:13:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/VertexAI-Auto-ML-training-model-failed-without-giving-the-reason\/td-p\/445439\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":1.0,
        "Question_view_count":110.0,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"After an hour of training Auto ML with Vertex AI, it failed without mentioning the reason. I have received the following email;\n\"Due to an error, Vertex AI was unable to train model \"some_model\".\nAdditional Details:\nOperation State: Failed with errors\nResource Name: \nprojects\/xxxxxxxxxxxxxxx\/locations\/region\/trainingPipelines\/xxxxxxxxxxxxxxxxxxxxxxxx\nError Messages: Internal error occurred. Please retry in a few minutes. If \nyou still experience errors, contact Vertex AI.\"Would you please help me with it?\nThanks",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-27T10:26:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"There was an issue with Europe West 2 Servers during that day, does your training model was in that region?\nIs this still an issue or is it fixed now?"
            },
            {
                "Answer_creation_date":"2022-07-28T06:20:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Not at that region and still the same error."
            },
            {
                "Answer_creation_date":"2022-07-28T13:26:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"What could be happening is due to a permission error.\n\nFix custom training permission issues.\n1. use default compute account of model preprocessing tenant projects to run training jobs\n2. Grant default compute account storage.admin role to batch prediction\/prediction\/training tps during provisioning"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Translation of MySQL data in 6 different language",
        "Question_creation_date":"2022-08-17T02:00:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Translation-of-MySQL-data-in-6-different-language\/td-p\/454758\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":77.0,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"I have 20K record in 1 Table of MySQL DBThis table is having a Description column and 6 different columns as TLang1, TLang2, Tlang3....I have to translate the data in Description column in 6 Different Languages and insert them in TLang1, TLang2, Tlang3.... columns in the same row.What approach I can use to do this since the current approach is taking too long.",
        "Answers":[
            {
                "Answer_creation_date":"2022-08-24T09:24:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"What is your current approach?"
            },
            {
                "Answer_creation_date":"2022-08-26T02:57:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I am taking 1 row at a time and calling the translate API 6 times to get 6 different text translations and then updating the row."
            },
            {
                "Answer_creation_date":"2022-08-29T09:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You could do a Program that uses a Loop to translate each record and keep it in a Dataframe and then update the fields or replace the Table. There could be a case that you'll need to do this by parts by the Limits that Translation API have."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Importing to Vertex dataset does not import labels.",
        "Question_creation_date":"2022-11-02T04:12:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Importing-to-Vertex-dataset-does-not-import-labels\/td-p\/484912\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML",
            "Vertex AI Model Registry"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":220.0,
        "Question_answer_count":5,
        "Question_has_accepted_answer":false,
        "Question_body":"In Vertex AI I am updating an image dataset, thus:the images are uploaded to the dataset but their labels are ignored and they are classed as Unlabeled. What am I doing wrong? TIA!\n\nPS they are in a csv, like:which worked fine for the dataset creation. ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-03T17:01:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You could check this sample code to Import data for image classification single label:\n\n\u00a0\n\nfrom google.cloud import aiplatform\n\n\ndef import_data_image_classification_single_label_sample(\n    project: str,\n    dataset_id: str,\n    gcs_source_uri: str,\n    location: str = \"us-central1\",\n    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n    timeout: int = 1800,\n):\n    # The AI Platform services require regional API endpoints.\n    client_options = {\"api_endpoint\": api_endpoint}\n    # Initialize client that will be used to create and send requests.\n    # This client only needs to be created once, and can be reused for multiple requests.\n    client = aiplatform.gapic.DatasetServiceClient(client_options=client_options)\n    import_configs = [\n        {\n            \"gcs_source\": {\"uris\": [gcs_source_uri]},\n            \"import_schema_uri\": \"gs:\/\/google-cloud-aiplatform\/schema\/dataset\/ioformat\/image_classification_single_label_io_format_1.0.0.yaml\",\n        }\n    ]\n    name = client.dataset_path(project=project, location=location, dataset=dataset_id)\n    response = client.import_data(name=name, import_configs=import_configs)\n    print(\"Long running operation:\", response.operation.name)\n    import_data_response = response.result(timeout=timeout)\n    print(\"import_data_response:\", import_data_response)"
            },
            {
                "Answer_creation_date":"2022-11-04T07:25:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks, but exactly the same result."
            },
            {
                "Answer_creation_date":"2022-11-14T13:38:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"From this Tensorflow blog post:\n\nIn addition to image files, we've provided a CSV file (all_data.csv) containing the image URIs and labels. We randomly split this data into two files, train_set.csv and eval_set.csv, with 90% data for training and 10% for eval, respectively.\n\ngs:\/\/cloud-ml-data\/img\/flower_photos\/dandelion\/17388674711_6dca8a2e8b_n.jpg,dandelion\ngs:\/\/cloud-ml-data\/img\/flower_photos\/sunflowers\/9555824387_32b151e9b0_m.jpg,sunflowers\ngs:\/\/cloud-ml-data\/img\/flower_photos\/daisy\/14523675369_97c31d0b5b.jpg,daisy\ngs:\/\/cloud-ml-data\/img\/flower_photos\/roses\/512578026_f6e6f2ad26.jpg,roses\ngs:\/\/cloud-ml-data\/img\/flower_photos\/tulips\/497305666_b5d4348826_n.jpg,tulips\n\n\nWe also need a text file containing all the labels (dict.txt), which is used to sequentially map labels to internally used IDs. In this case, daisy would become ID 0 and tulips would become 4. If the label isn't in the file, it will be ignored from preprocessing and training.\n\ndaisy \ndandelion \nroses \nsunflowers \ntulips \n\n\nTherefore, you need to create the dict.txt file which will have the all the labels used as shown above.\n\nSee also:\n\nHow to classify images with TensorFlow using Google Cloud Machine Learning and Cloud Dataflow"
            },
            {
                "Answer_creation_date":"2022-11-15T03:26:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thanks but that is six years old and not a Vertex AI dataset."
            },
            {
                "Answer_creation_date":"2022-11-18T10:55:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Could you please raise a private thread in the issue tracker (referencing this question, as stated in the template) with the project ID, job ID and a sample data of your input CSV file (Don't want the entire file or any PII)?"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Do Training Jobs Run in Parallel? (VERTEX AI)",
        "Question_creation_date":"2022-11-15T07:56:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Do-Training-Jobs-Run-in-Parallel-VERTEX-AI\/td-p\/489639\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML",
            "Vertex AI Model Registry"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":70.0,
        "Question_answer_count":3,
        "Question_has_accepted_answer":true,
        "Question_body":"I am wondering if training jobs on vertex AI run in parallel, based on my tests it seems they do but wondering if anyone can confirm this is true as the number of concurrent jobs grows past say 1000. Thanks! ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-15T11:57:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Yes training jobs run in parallel but the concurrency is subject to quota. See Vertex AI quota document.\n\nView solution in original post"
            },
            {
                "Answer_creation_date":"2022-11-15T11:57:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Yes training jobs run in parallel but the concurrency is subject to quota. See Vertex AI quota document."
            },
            {
                "Answer_creation_date":"2022-11-16T06:58:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Cool thanks,\n\nAre those quotas liftable or are they the hard cap.\n\n\u00a0\n\nThanks!"
            },
            {
                "Answer_creation_date":"2022-11-16T09:06:00",
                "Answer_accepted":true,
                "Answer_upvote_count":0,
                "Answer_body":"Yes it is possible but is subject to approval. Kindly see this document on how to request a quota increase."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Triton on Vertex AI does not support multiple models?",
        "Question_creation_date":"2022-08-25T07:15:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Triton-on-Vertex-AI-does-not-support-multiple-models\/td-p\/459822\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "Vertex AI Model Registry"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":107.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Currently, I want to deploy a Triton server to Vertex AI endpoint. However I received this error message.\"failed to start Vertex AI service: Invalid argument - Expect the model repository contains only a single model if default model is not specified\"Is this mean that the Triton server deploy only support one model? It is different from what I have read in this document about concurrent model executionhttps:\/\/cloud.google.com\/vertex-ai\/docs\/predictions\/using-nvidia-triton",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-07T13:44:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The error message suggest that you haven't selected a default model."
            },
            {
                "Answer_creation_date":"2022-10-17T07:18:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, I have the same issue and I couldn't find how to set a default model. Could you please link a guide about it or explain how to do that? Thanks"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Does Vertex AI support labels for counting?",
        "Question_creation_date":"2021-10-25T08:47:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Does-Vertex-AI-support-labels-for-counting\/td-p\/173840\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":404.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I have an image where I have to do a multi-label classification and additionally count the number of a specific item in each image. I'm trying to setup a labeling task so I can enter a continuous number (0-100 for example), but there doesn't seem to be support for it.  Additionally, does the labeling have capabilities to pre-choose a \"default\"  value? Does anyone have an idea?",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nAs you have rightly mentioned, Vertex AI does not presently support object counting in an image. Please feel free to reach out to submit a feature request via the issue tracker link[0] to the Vertex AI product team about such implementations.\n\nAs mentioned in this article[1], there are only three ways to assign labels to your training data items:\n\n-- Add the data items to your dataset with their labels already assigned, for example using a commercially available dataset\n-- Assign labels to the data items using the Cloud Console\n-- Request to have human labelers add labels to the data items\n\nAt this time, none of these options provide ways to pre-choose a \"default\" value. May be there may be workarounds to explore using your own human labelers via your instructions.\n\n\n[0]https:\/\/developers.google.com\/issue-tracker\/#public_users\n[1]https:\/\/cloud.google.com\/vertex-ai\/docs\/datasets\/data-labeling-job"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Python Code example to transcribe 2 audio inputs into speech at the same time",
        "Question_creation_date":"2021-12-21T00:07:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Python-Code-example-to-transcribe-2-audio-inputs-into-speech-at\/td-p\/180446\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":105.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"I'm trying to create a piece of python code that can take 2 audio inputs, 1. from my microphone2. virtual input from zoomat the same timehowever, i am not sure how to transcribe them simultaneously.any help would be appreciated, thank you!",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-21T17:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nThe following doc [1]\u00a0describes how to use Speech-to-Text to transcribe audio files that include more than one channel. Multi-channel recognition is available for most, but not all, audio encodings supported by Speech-to-Text.\n\nI hope this would help, thanks.\n\n[1]https:\/\/cloud.google.com\/speech-to-text\/docs\/multi-channel#speech_transcribe_multichannel_gcs-python"
            },
            {
                "Answer_creation_date":"2021-12-21T19:53:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thank you for the reply, but if I am not wrong, this only applies to 1 audio input\/audio file. Or could this code be modified to use 2 audio streams?"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Authenticating to Vertex AI deployed endpoints",
        "Question_creation_date":"2022-11-10T13:57:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Authenticating-to-Vertex-AI-deployed-endpoints\/td-p\/488229\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":97.0,
        "Question_answer_count":4,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello, I am a new user of Vertex AI.  I have trained and deployed a tabular data categorization model to an Vertex AI hosted endpoint.  I have successfully called it from a program running on my laptop where the \"gcloud\" cli is installed.  If I want to run this not from my desktop but have it called from another service, how do I authenticate ?  I have created a service account but I am not sure 1) what roles would need to be attached to that account and 2) how I would provide the service account credentials given that I don't have much control over how the service that will call my model is started (i.e. I can't control its environment vars).  Any help would be appreciated! ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-11T22:35:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, for starters, you may read the basic concepts of IAM and\u00a0service accounts\u00a0\n\nYou may check this\u00a0pre-defined roles\u00a0for Vertex AI that you can attach on your service account depending on the level of permission you want to give.\u00a0\n\nFor the second question, you need to be a Service Account Admin as per this official\u00a0GCP Documentation\u00a0for you to manage a service account."
            },
            {
                "Answer_creation_date":"2022-11-21T07:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Thank you for the response.\u00a0 Now I know I need ServiceAccountAdmin.\u00a0 The thing I'm still not clear on is whether there is some way to provide the service account credentials without referencing a file on the file system.\u00a0 For example, if I'm accessing the service from a client to whose file system I have no access, what are my options ?"
            },
            {
                "Answer_creation_date":"2022-11-21T09:25:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"If this is a file from a service you have no control of, the permission should be given on the side of that service."
            },
            {
                "Answer_creation_date":"2022-11-21T13:15:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"This is custom code that is deployed to an app server like environment. I can deploy code and config to the app server but I don't control the environment variables that the app servers starts up with and I don't control the file system.\u00a0 I'd like to deploy code to the app server that accesses Google hosted model endpoints.\u00a0 Is there some way to do to authenticate to Google Cloud other than setting an environment variable that points to credentials on the file system ?"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Can Google Cloud Vision work as fast as Google lens for OCR?",
        "Question_creation_date":"2021-12-29T12:05:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Can-Google-Cloud-Vision-work-as-fast-as-Google-lens-for-OCR\/td-p\/181569\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Vision API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":474.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello, I am using Google Cloud Vision for text recognition, but the processing speed is quite slow (5 to 15 seconds). I would like to know how does Google lens work so fast and if there's any way to make Google Vision as fast.Edit: My photos that go through Vision are stored in Firebase Storage. (As I've read in some posts this is the quickest way to process them). Thanks in advance!",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-30T11:55:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"=> For uploading\u00a0 images to Google Cloud\u00a0 Vision you can use one of the following options:\n\n1) Directly upload the image as binary (is the slowest)\n\n2) Upload the image as base64 encoded (is ~25% faster)\n\n3) Use a pre-uploaded image stored on Google Cloud Storage [1] (is the fastest)\n\n- Please refer to the documentation [2] for best practices for Cloud Vision API\n\n- Also, the response time of Vision API depends on the resource status or network latency.\u00a0 (network IO, file transfer to Vision API, etc).\u00a0\n\n[1] https:\/\/cloud.google.com\/storage\/\n\n\u00a0[2] https:\/\/cloud.google.com\/vision\/docs\/supported-files"
            },
            {
                "Answer_creation_date":"2022-01-03T02:21:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Google Cloud Vision API work? Google image recognition API\u00a0will identify images from pre-trained models on large datasets of images and then it classifies the images into thousands of categories to detect the objects, places, people and faces in the images.\n\n\u00a0\n\nMyAccountAccess"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Save audio file from speech to text stream",
        "Question_creation_date":"2022-03-03T07:35:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Save-audio-file-from-speech-to-text-stream\/td-p\/398993\/jump-to\/first-unread-message",
        "Question_topic":[
            "Speech-to-Text",
            "Text-to-Speech"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":57.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am using @Google-cloud\/speech for streaming audio from the browser to my nodejs backend.\nI would like to save the recorded audio.\nI see no option to do so. Any suggestions? Thanks.",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-08T13:17:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hey,\u00a0\n\nYou shall probably use other packages for recording such as recordrtc as mentioned at [1].\u00a0\u00a0\n\n[1]\u00a0https:\/\/www.leeboonstra.dev\/chatbots\/building-your-own-voice-ai-3\/"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"3D object detection using mobile camera or 3D scanner using cloud vision",
        "Question_creation_date":"2021-11-23T00:44:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/3D-object-detection-using-mobile-camera-or-3D-scanner-using\/td-p\/176320\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform",
            "AutoML",
            "Cloud Vision API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":58.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"The use case is, I want detect the 3d model through mobile camera or 3d scanner with dimensions to verify the scanned model is available or not in cloud storage. If model is not available it should list the model with approx model with percentage. ",
        "Answers":[
            {
                "Answer_creation_date":"2021-12-01T07:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi\n\nHere is a general guide on training Edge models, that you can export to Edge devices, for on-prem use.\n\nI also found this list of more detailed guides on training, and deploying the model either on an Edge device, or online. It includes this page which talks about training Edge exportable models."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to set multiple series identifier columns on tabular forecast?",
        "Question_creation_date":"2021-08-11T22:44:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-set-multiple-series-identifier-columns-on-tabular\/td-p\/166959\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":108.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,I tried BigQuery ML's ARIMA+ to predict sales data, but the results were not particularly good.So, I wanted to try adding weather as a feature to the dataset. This requires the use of Vertex AI Tabular forecast (AutoML).The dataset looks like this.When using ARIMA+, multiple columns can be specified by using the following statement. How to set multiple series identifier columns on AutoML? Should I consider merging the store and product columns into one column(eg: tokyo_pixel6)?",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-14T15:06:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I found this section of the documentation, which might be helpful:\u00a0\n\nOne of your columns in your training data for a forecasting model must be specified as the time series identifier. Forecasting training data usually includes multiple time series, and the identifier tells Vertex AI which time series a given observation in the training data is part of. All of the rows in a given time series have the same value in the time series identifier column.\n\nSome common time series identifiers might be the product ID, a store ID, or a region. When you have multiple time series in your training data, there should be a specific column that differentiates them.\n\nYou can train a forecasting model on a single time series (in other words, the time series identifier column contains the same value for all rows). However, Vertex AI is a better fit for training data that contains two or more time series. For best results, you should have at least 10 time series for every column used to train the model."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Using other API to translate PDF documents",
        "Question_creation_date":"2022-11-01T23:17:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Using-other-API-to-translate-PDF-documents\/td-p\/484845\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML",
            "Cloud Translation API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":45.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello all, \n\nI am trying to find a way to translate English PDF documents to a target language(Korean) without messing up the original PDF page format(pictures, headers, tables, etc.)\n\nThe only problem with the default google translation is that many of the words that appear in the document are very industry-specific and need to be translated accordingly through AutoML translation. \n\nHowever, we'd like to use our own language model (i.e. fine-tuned GPT3) to translate just the text and feed the translated text to the output stream to get the final pdf output.\n\nI'm yet to see any other company that maintains PDF formatting as well as Google while translating, so I'd really like to use Cloud Translation API with our own translation module for optimal accuracy.\n\nIs there a way to do this? I've tried reaching out to the local Google branch to no avail. Please help!",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-03T15:52:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"It is possible to use a glossary\u00a0in Cloud Translation to provide the API with custom translations for terms that appear in texts. This would help when industry-specific terminology needs to be translated in a specific way.\n\nAs for using a custom language recognition model, you would be able to create a Feature Request for Cloud Translate API\u00a0in Google\u2019s public issue tracker."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Dialogflow CX logs sink to BigQuery. sink error - field: value is not a record",
        "Question_creation_date":"2022-11-16T07:48:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Dialogflow-CX-logs-sink-to-BigQuery-sink-error-field-value-is\/td-p\/490079\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":260.0,
        "Question_answer_count":4,
        "Question_has_accepted_answer":false,
        "Question_body":"I am using google cloud logging to sink Dialogflow CX requests data to big query. BigQuery tables are auto generated when you create the sink via Google Logging.We keep getting a sink error - field: value is not a record.This is because pageInfo\/formInfo\/parameterInfo\/value is of type String in BigQuery BUT there are values that are records, not strings. One example is @sys.date-timeHow do we fix this?We have not tried anything at this point since the BigQuery dataset is auto created via a Logging Filter. We cannot modify the logs and if we could modify the table schema, what would we change it to since most of the time \"Value\" is a String but other times it is a Record",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-18T10:14:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Currently working with your question."
            },
            {
                "Answer_creation_date":"2022-11-18T16:13:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"With the information you shared, I\u2019m afraid it\u2019s not possible to provide a good solution.\n\nPlease include sufficient code and any guides you followed or your process so that we can analyze the issue."
            },
            {
                "Answer_creation_date":"2022-11-19T04:54:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"This is an article that explains how to set up the logging to BigQuery:\u00a0https:\/\/medium.com\/google-cloud\/dialogflow-cx-response-logging-e1b77d7a9fc6\n\nThere is no code, just create a simple agent in Dialogflow CX and set up at least one parameter with entity type\u00a0@sys.date-time, turn on logging, create BigQuery sink, then test the agent a few times and you should get the error notice that the sink has been disabled.\n\nThe financial services example agent would probably show the same bug if you triggered the \"Investigate charges\" intent"
            },
            {
                "Answer_creation_date":"2022-11-28T13:56:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"With the information you provided from your project, I would highly recommend you to review this Troubleshooting routing and sinks documentation.\n\nAdditionally, you can actually create a PIT (Public Issue Tracker - Dialogflow CX), or please engage GCP Support if you're paying or if you're interested in starting to pay for a Support Package. Please be aware that from these 2 options, the second one is the fastest."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Use GCP Endpoints as reverse proxy for Vertex Ai Endpoint",
        "Question_creation_date":"2022-02-24T08:55:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Use-GCP-Endpoints-as-reverse-proxy-for-Vertex-Ai-Endpoint\/td-p\/396912\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":343.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am using GCP Endpoints to work as a reverse proxy to a Vertex Ai Endpoint. I can authenticate to GCP Endpoints with api keys, service account... but I get the following error code. Yet, am able to get a successful response from Vertex Ai Endpoint directly. # Error code when requesting to GCP Endpoints (API is authenticated)   Even using the flag \"--allow-unauthenticated\" when setting up ESPv2 still fails. The request   openapi.json (host and address removed for privacy)   Any help would be greatly appreciated",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-01T07:37:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nCould be for different reasons:\n\nFor testing purposes, grant the service account the \u2018owner\u2019 role as advice in [1] document, and see if you still get the error.\u00a0\nIf everything was working fine before, please try to generate another <access_token> for your service account as mentioned in [2].\nMake sure you followed all the steps form document [3]\n\nThank you\n\n[1]: https:\/\/cloud.google.com\/vertex-ai\/docs\/tutorials\/image-recognition-automl#before_you_begin\n\n[2] https:\/\/developers.google.com\/identity\/protocols\/oauth2#5.-refresh-the-access-token,-if-necessary.\n\n[3]: https:\/\/cloud.google.com\/vertex-ai\/docs\/general\/custom-service-account"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to use ARIMA coefficients from BigQuery",
        "Question_creation_date":"2022-09-19T12:20:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/How-to-use-ARIMA-coefficients-from-BigQuery\/td-p\/468311\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":48.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am trying to use Auto ARIMA from BigQuery and I just want to understand the results. That's what BigQuery is giving me:Store ACoeficients from Store AI trained the model using weekly incomeHow to fit this information in an equation?",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-23T13:50:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"All I could find is this documentation that explains how to properly use the arima coefficient function on BigQuery."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Custom container in vertex workbench",
        "Question_creation_date":"2022-06-10T10:25:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Custom-container-in-vertex-workbench\/td-p\/430464\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":236.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I noticed that you can use a custom container from the container registry when creating user-managed notebook, but I couldn't find any documentation on the required configuration\/dockerfile specs for it to work with jupyterlab in a similar fashion to launcing a regular workbench environment (e.g. python 3). Should I open default jupyter lab port? anything else?",
        "Answers":[
            {
                "Answer_creation_date":"",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"1. Create the initial Dockerfile and run modification commands.\n\u00a0 To start, you create a Deep Learning Containers container using one of the available image types. Then use conda, pip, or Jupyter commands to modify the\u00a0 \u00a0container image for your needs, you can add extra packages when you create your custom container.\n\nFROM gcr.io\/deeplearning-platform-release\/tf-gpu:latest\nRUN pip install -y tensorflow\u00a0\n\n\u00a0 \u00a02.Build and push the container image.\n\u00a0 \u00a0Build the container image, and then push it to somewhere that is accessible to your Compute Engine service account.\n\nexport PROJECT=$(gcloud config list project --format \"value(core.project)\")\ndocker build . -f Dockerfile.example -t \"gcr.io\/${PROJECT}\/tf-custom:latest\"\ndocker push \"gcr.io\/${PROJECT}\/tf-custom:latest\"\n\n\n\nSpecify the container when launching the execution Custom container."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Tabular Forecasting Model in Vertex AI - Cannot deploy model to endpoint",
        "Question_creation_date":"2022-10-08T03:38:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Tabular-Forecasting-Model-in-Vertex-AI-Cannot-deploy-model-to\/td-p\/475893\/jump-to\/first-unread-message",
        "Question_topic":[
            "Vertex AI Model Registry"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":45.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I'm getting started with Vertex AI, and the model I'd like to use is a Tabular Forecasting Model. After spending hours tweaking the model that I wanted to deploy, I came across this error message. \"The default version cannot be deployed\". I can deploy a normal Tabular model to an endpoint, but not the Tabular Forecasting model. Does anyone know if there is a way to deploy a Tabular Forecasting Model? If not, is Google planning on adding this functionality anytime soon? Thanks in advance.",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-10T14:39:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You are able to use Tabular Forecasting on Vertex AI the issue you are facing might be occurring since it was omitted one step from the guide that google offers. I recommend you to check the hyperlink I attached since it outlines how to properly achieve this.\n\nAlso a couple of points that you might want to be aware of are the next ones:\n\nYou can export AutoML tabular classification and regression models only. Exporting AutoML tabular forecasting models is not supported.\nVertex Explainable AI is not available using exported tabular models. If you need to use Vertex Explainable AI, you must serve predictions from a model hosted by Vertex AI.\nThe exported tabular model can run only on x86 architecture CPUs that support Advanced Vector Extensions (AVX) instruction sets."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Vertex AI video action recognition - can it return action timeframes instead of a timestamps?",
        "Question_creation_date":"2022-11-20T13:47:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-video-action-recognition-can-it-return-action\/td-p\/491200\/jump-to\/first-unread-message",
        "Question_topic":[
            "AutoML",
            "Video Intelligence API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":131.0,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"My problem is that my usecase requires the AI engine I use to provide predictions with the entire duration of the action. It seems to me that vertex AI picks a random frame in the span of the action and return it as the same start\/end values. Here's an excerpt from an actual response Can I make it work the way I need it to? Maybe I'm annotating in a wrong manner?Here's a mockup of what I need. Notice how timeSegmentStart and timeSegmentEnd represent a duration now:",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-21T11:38:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nHaving the equal values for timeSegmentStart and timeSegmentEnd is an expected behavior as seen in this sample prediction response.\n\nWhat I could suggest is to create a feature request in GCPs\u00a0public issue tracker regarding your request.\u00a0Please keep in mind that when you create the feature request, it still needs to be analyzed and considered by the product team and a definite ETA is not guaranteed."
            },
            {
                "Answer_creation_date":"2022-11-23T00:51:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"@ricconoel\u00a0thanks for your reply. I agree that according to the sample this behavior is expected, however i wanted to know if it can be altered or configured. Looks weird to me that action recognition AI would stop at giving an arbitrary timestamp and not the whole duration of the action. Is there a way to find out if this feature is *already* implemented?"
            },
            {
                "Answer_creation_date":"2022-11-23T07:56:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Unfortunately it cannot be altered or configured as of now. Hence my suggestion to create a feature request."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"When will Hebrew language be available in Text-To-Speech API?",
        "Question_creation_date":"2022-05-18T06:14:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/When-will-Hebrew-language-be-available-in-Text-To-Speech-API\/td-p\/424088\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":111.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"",
        "Answers":[
            {
                "Answer_creation_date":"2022-05-19T08:46:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"There is no information about when Hebrew will be available in Cloud Text-to-Speech you can file a feature request in Issue Tracker[1].\n\n[1] https:\/\/issuetracker.google.com\/issues\/new?component=451645&template=1161363"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Vertex AI quota policy exceed when training custom model",
        "Question_creation_date":"2022-09-26T02:38:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-quota-policy-exceed-when-training-custom-model\/td-p\/470907\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "AutoML",
            "Vertex AI Model Registry"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":169.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello team,Can anyone please help me with this,I have been trying to run the custom model training in vertex ai and gives an error saying\"Training pipeline failed with error message: The following quota metrics exceed quota limits: aiplatform.googleapis.com\/custom_model_training_cpus\"Followed the below steps to solve it but didn't help me at all,1. Changed the region (As it mentioned in one comment of Stack Overflow for this error)2. Increased CPU instances in the work pool as well as notebooks but didn't help me at all.I have gone through the IAM & API Services, and then when I checked the quotas for the Vertex AI API for all resources in it, none of them had exceeded the quota limit. I'm still confused as to why it was showing a quota exceed error when I was training the custom model.Please help me on this issue, how to solve it.",
        "Answers":[
            {
                "Answer_creation_date":"2022-09-27T11:22:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"You need to contact Billing Support."
            },
            {
                "Answer_creation_date":"2022-10-30T14:02:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"I have the same problem, can you tell me how solved it??\u00a0@Praneeth5533"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Vertex AI Batch Predictions: Bigquery format must be used as input and output simultaneously",
        "Question_creation_date":"2022-11-01T15:58:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Vertex-AI-Batch-Predictions-Bigquery-format-must-be-used-as\/td-p\/484734\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI Platform",
            "Vertex AI Model Registry"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":70.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"I'm encountering an error when I try to create a batch prediction job with a bigquery table as my input, and a JSONL output in a GCS bucket. The documentation for batch predictions seems to indicate that I can do so, but I still see an error.I'm trying to create a batch prediction job on the Vertex AI console, and I see this error. ",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-02T16:33:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"The documentation does seem unclear about this error, do you see the same issue if you test selecting a different output format, for instance CSV? This so I can investigate further and contact the appropriate teams with this inquiry."
            },
            {
                "Answer_creation_date":"2022-11-10T08:29:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"If you use BigQuery as your batch prediction input you only can store the batch prediction results in BigQuery (input and output has to be the same)"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Glossary not found.; Failed to initialize a glossary.",
        "Question_creation_date":"2022-11-17T20:30:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Glossary-not-found-Failed-to-initialize-a-glossary\/td-p\/490677\/jump-to\/first-unread-message",
        "Question_topic":[
            "Cloud Translation API"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":42.0,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I have created glossary to translate text using Cloud Translation API. it shows me status as running-\n\"name\": \"projects\/xxx\/locations\/us-central1\/operations\/xxx\",\n\"metadata\": {\n\"@type\": \"type.googleapis.com\/google.cloud.translation.v3.CreateGlossaryMetadata\",\n\"name\": \"projects\/xxx\/locations\/us-central1\/glossaries\/xxx\",\n\"state\": \"RUNNING\",\n\"submitTime\": \"2022-11-18T03:59:51.876209069Z\"\n}\n}but when I am trying to use this Glossary for translation api, it shows me error as-\n\"Glossary not found.; Failed to initialize a glossary\".\nEven when I tried listing my Glossary, it doesn't show.Not sure what is the issue. Console activity dashboard shows activity as created Glossary.",
        "Answers":[
            {
                "Answer_creation_date":"2022-11-22T09:59:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Make sure that all permissions are appropriately established.\n\n\u00a0\n\nIn order to make sure you see it, I would suggest listing your glossaries. If you don't, at least you are aware of the problem.\n\nFurthermore, I don't believe that this is a permissions issue. Explicit permission errors ought to be returned if there is a permission problem.\n\nI advise beginning with the create glossary sample and then attempting to access the same resource using the example code you're using in order to troubleshoot."
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"VM Ram vs Google Colab Ram",
        "Question_creation_date":"2022-07-27T12:51:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/VM-Ram-vs-Google-Colab-Ram\/td-p\/447466\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AI Platform"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":61.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi, @Eduardo_Ortiz  @josegutierrez sorry to bother but I`m completely lostDays a go I bought a VM that has the next configurations, when I connect to the VM with Google Colab get the next results as you can see in the next image.VM Configuration : GPUs1 x NVIDIA Tesla V100  +  n1-highmem-8 (vCPUs: 8, RAM: 52GB)Ram obtained in Google Colab from the VM: 1.31 Gb \/ 51.01 Gb Disc 43.79 \/ 186.52As you realized,  althoug I have buy a better configuration than Google Coalb Pro+ Im getting fewer RAM from the VM instance....What could be the error or situation? How can I get into colab the real VM capacity bought? Or which configuration do I need in order to have better performance than Google Colab pro+?In the next screen shot the ram and disck that I got from Google Colab:Thanks a lot for any help ",
        "Answers":[
            {
                "Answer_creation_date":"2022-07-27T12:51:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi, @Eduardo_Ortiz\u00a0 @josegutierrez\u00a0sorry to bother but I`m completely lost\n\nDays a go I bought a VM that has the next configurations, when I connect to the VM with Google Colab get the next results as you can see in the next image.\n\nVM Configuration : GPUs1 x NVIDIA Tesla V100\u00a0 +\u00a0\u00a0n1-highmem-8 (vCPUs: 8, RAM: 52GB)\n\nRam obtained in Google Colab from the VM: 1.31 Gb \/ 51.01 Gb Disc 43.79 \/ 186.52\n\nAs you realized,\u00a0 althoug I have buy a better configuration than Google Coalb Pro+ Im getting fewer RAM from the VM instance....\n\nWhat could be the error or situation? How can I get into colab the real VM capacity bought? Or which configuration do I need in order to have better performance than Google Colab pro+?\n\nIn the next screen shot the ram and disck that I got from Google Colab:\n\nThanks a lot for any help"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Endpoint in GCP",
        "Question_creation_date":"2022-10-14T12:37:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Endpoint-in-GCP\/td-p\/478360\/jump-to\/first-unread-message",
        "Question_topic":[
            "AI ML General",
            "AutoML",
            "Vertex AI Model Registry"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":77.0,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"In GCP I was deploying a model which obtain from training a dataset and after success full Vertex AI Model Registry. It takes too much time around 10 min to create endpoint for model. How can I reduce creation time when creating endpoints on GCP? What factors affected endpoint creation ?",
        "Answers":[
            {
                "Answer_creation_date":"2022-10-20T16:06:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"This video would be a good starting point:\n\nDeploying quick, cost-effective ML models with Vertex AI\n\nManaged notebook environments make it easier, faster, and more cost-effective to get high-quality models into production without having to set up infrastructure or install libraries. In this session, we\u2019ll demo how to use Vertex AI to get batch and online predictions and use the Vertex AI Python SDK to upload models to Vertex AI Model Registry and deploy to an endpoint with little code."
            },
            {
                "Answer_creation_date":"2022-11-04T04:47:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"thanks for\u00a0 reply but given resource does not work for me !!!"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Removed voices from German standard text to speech (tts)",
        "Question_creation_date":"2022-02-17T06:05:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Removed-voices-from-German-standard-text-to-speech-tts\/td-p\/394397\/jump-to\/first-unread-message",
        "Question_topic":[
            "Text-to-Speech"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":124.0,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"We have a problem related to the Cloud text to speech API.\nWe develop an AI based chatbot system, and we have lot of different chatbot which speak in English and German also.\nWe are using two different voices 'de-DE-Standard-B' (male) and 'de-DE-Standard-C' (female) in the case of German bots, but both bots speak in same vois at now.\nWe detected the problem at 2022-02-16.Could you give me some information about this problem?",
        "Answers":[
            {
                "Answer_creation_date":"2022-02-22T12:06:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nI understand you have selected 2 different German Language voices[ 'de-DE-Standard-B' (male) and 'de-DE-Standard-C' (female) ] from the list of available voices[0] that can be used for synthetic speech, however both voices are coming out the same.\n\nAs you have rightly indicated, these voices are different. However, it will be nice to understand how you are creating the voice audio files[1]. As indicated in the article[1], it is not only possible selecting a unique voice, you can also make certain modifications depending on your implementation. For example, you can modulate the output in pitch, volume, speaking rate, and sample rate. If you are using SSML in your audio synthesis, you would even have a finer-grain control over how the audio output.\n\nSo, please give more insight to your setup and how these voices are selected.\n\n\u00a0\n\n[0]https:\/\/cloud.google.com\/text-to-speech\/docs\/voices\n\n[1]https:\/\/cloud.google.com\/text-to-speech\/docs\/create-audio#text-to-speech-ssml-java"
            },
            {
                "Answer_creation_date":"2022-04-21T14:27:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hi Oakinlaja - There seem to be an issue when using SSML to read date using the German langauge. It plays randomly different message. Please help. This is the below request to Google speech to text.\n\n\u00a0\n\nTTS Request JSON :: {\"voice\":{\"ssmlGender\":\"MALE\",\"name\":\"de-DE-Wavenet-E\",\"languageCode\":\"de-DE\"},\"input\":{\"ssml\":\"<speak><say-as interpret-as=\\\"date\\\" format=\\\"yyyymmdd\\\"> 20220506<\\\/say-as><\\\/speak>\"},\"audioConfig\":{\"sampleRateHertz\":8000,\"volumeGainDb\":0,\"speakingRate\":1,\"audioEncoding\":\"LINEAR16\",\"pitch\":0,\"effectsProfileId\":[\"telephony-class-application\"]}}"
            },
            {
                "Answer_creation_date":"2022-04-21T14:34:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"In English it works correctly. For english , i pass languageCode : En-US"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Dialogflow quota reset",
        "Question_creation_date":"2022-03-02T01:15:00",
        "Question_link":"https:\/\/www.googlecloudcommunity.com\/gc\/AI-ML\/Dialogflow-quota-reset\/td-p\/398513\/jump-to\/first-unread-message",
        "Question_topic":[
            "Dialogflow CX"
        ],
        "Question_tag":null,
        "Question_upvote_count":0.0,
        "Question_view_count":42.0,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,I have a Dialogflow ES agent, and I'm sending a few thousand (~5k) DetectIntent requests asynchronously. Our quota is 9k requests per minute, so it shouldn't be a problem. However what I'm seeing is that even after waiting for 10 minutes or more, when I run another batch (also ~5k), I get a resource exhausted error. If the quota is 9k per minute, why is the resource still exhausted after 10 minutes? And is there a way to know by what time I should try again?",
        "Answers":[
            {
                "Answer_creation_date":"2022-03-02T01:15:00",
                "Answer_accepted":false,
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nI have a Dialogflow ES agent, and I'm sending a few thousand (~5k) DetectIntent requests asynchronously. Our quota is 9k requests per minute, so it shouldn't be a problem. However what I'm seeing is that even after waiting for 10 minutes or more, when I run another batch (also ~5k), I get a resource exhausted error. If the quota is 9k per minute, why is the resource still exhausted after 10 minutes? And is there a way to know by what time I should try again?"
            }
        ],
        "Tool":"Vertex AI",
        "Question_comment_count":null,
        "Question_follower_count":null,
        "Question_converted_from_issue":null
    }
]