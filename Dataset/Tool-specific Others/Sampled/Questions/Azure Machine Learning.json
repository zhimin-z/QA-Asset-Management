[
    {
        "Question_title":"How to run python 2.7 scripts on a computer cluster",
        "Question_creation_time":1637171846430,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/631040\/importerror-cannot-import-name-outputfiledatasetco.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I am aware that azureml will drop support for python 2.7, but I have got some old codes and have to finish training the models. Since I will not use the codes afterwards anyway, so I do not want to spend much time to port to python 3.\n\nAs I tried to run the codes in python 2.7 on a compute cluster, I got the error ImportError: cannot import name OutputFileDatasetConfig coming from this line:\nfrom azureml.data import OutputFileDatasetConfig\nThe environment, that I have created for python 2.7, has azureml-core v1.1.5. I cannot find any documentation for this version, so I do not know, if it supports OutputFileDatasetConfig.\n\nCan someone tell me, how I can run my codes in python 2.7 on compute clusters? Thanks!",
        "Answers":[
            {
                "Answer_creation_time":"2021-11-18T03:49:39.763Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @Lu-3578\n\nThanks for reaching out to us. I have not found any official document either.\n\nIn this scenario, I think the quickest way to solve the problem is to raise a support ticket.\n\nLet me know if you have no support plan, please share the ticket id since I will forward this issue to product team to see what we can do more.\n\n\n\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How could I upload notebooks to my AzureML workspace programatically",
        "Question_creation_time":1651101620807,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/829311\/how-could-i-upload-notebooks-to-my-azureml-workspa.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Would like to upload Jupyter notebooks from different sources like GitHub into my workspace either directly or through my local machine (download locally first and then upload) but I would like to do it programmatically. Either with the AzureML SDK or azure cli",
        "Answers":[
            {
                "Answer_creation_time":"2022-04-28T00:07:22.393Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for reaching out. You can use compute instance terminal in AML notebooks to clone the GitHub repo. There's currently no option to upload notebooks to your workspace programmatically using sdk or cli.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"inference pipeline option not available",
        "Question_creation_time":1626831334850,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/483466\/inference-pipeline-option-not-available.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":5,
        "Question_has_accepted_answer":false,
        "Question_body":"After running the pipeline, I do not see the dropdown option for create inference pipeline, only the Run or clone option...any idea?",
        "Answers":[
            {
                "Answer_creation_time":"2021-07-21T17:07:26.3Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nI have the same issue. Since today. The day before yesterday, so Monday I had the option Inference pipeline in real-time but not anymore.\n\nI can't contact the support because I have only a student account.\n\nSomebody can help us please ?\n\nThx.",
                "Answer_comment_count":11,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-28T00:03:05.747Z",
                "Answer_upvote_count":1,
                "Answer_body":"@LuciaCasucci-9483 I just deleted your answer since it contains your private message. I will send out an email and cc you to product group with more details.\n\nCurrently, resubmit\/ clone\/ refresh the page all help for this issue. If anyone who has the same issue, may try those ways first to see if that works. Please let us know if you still have more question.\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-08-26T20:13:48.72Z",
                "Answer_upvote_count":1,
                "Answer_body":"This issue still exists. I had the option to create an Inference pipeline in real-time. When I chose that, there was a message about not being able to for some reason. After this, the option was no longer available.\n\nI cloned and refreshed the page, but the option is no longer available either in the cloned or the original pipeline. I don't want to re-submit, as this will incur more cost and take some time.\n\n@YutongTie-MSFT , is this a known issue we can track somewhere, or is the designer not being developed at this time?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-01-03T16:53:33.553Z",
                "Answer_upvote_count":0,
                "Answer_body":"I'm having the same issue where the option to create inference pipeline is not available. Even when i click the \"...\" the only option i have is to clone.\ni've tried refreshing and toggling back and forth from the designer page to my pipeline and it is still not available",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-20T02:11:20.1Z",
                "Answer_upvote_count":1,
                "Answer_body":"For all those who are having this same issue: it happened to me that, suddenly, the pipeline design page changed and, after this, the pipelines modules weren't and couldn't be sorted by type:\n\nHow it was before the change (according to Msft doc https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score):\n\nHow it is now after the change:\n\n\n\n\nOther consequence of the change was that the top right button 'Create inference pipeline' dissappeared:\n\nHow it was before the change (according to Msft doc https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy):\n\n\n\n\nAs consequence, after this sudden change, in order to be able to deploy a no-code machine learning model in Azure you have to go to the 'jobs' page and there you can find the 'Create inference pipeline' drop-down list:\n\n\n\n\nIt's a shame that after one year, no one in Microsoft have been able to answer this question satisfactorily and to solve this problem that, furthermore, is 'magically' generated by Azure from one moment to another... A lot of wanting to promote the no code tool but afterwards, when people get stucked (normally not deep tech people), no help at all.\n\nHope this answer can help to those who were lost like me.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":17.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"ML Pickle file size Azure Machine Learning Service",
        "Question_creation_time":1599612419390,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/89630\/ml-pickle-file-size-azure-machine-learning-service.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Is there any restriction on registering an ML pickle model into Azure Machine Learning Service in terms of the size of the pickle file?\n\nDoes it cause latency in realtime data processing and getting the prediction results from the pickle file if we have a model that let's say it 5MB and the other one is 500MB (The bigger file has better performance in terms of accuracy)?\nThanks,\n\nJohn",
        "Answers":[
            {
                "Answer_creation_time":"2020-09-11T04:54:35.417Z",
                "Answer_upvote_count":0,
                "Answer_body":"@JA-4570 Thanks, For ACI we recommend not using a model over 1GB in size.\nFor AKS you are limited by the memory resources that you request for your service, minus about 500mb for the running python process in the pod.\n\nThere will be no difference in prediction speed once the model is successfully deployed.\nRegistering will take longer as we have to upload the model, and deploying will take longer as the service must download the model.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Replacement for Azure ML Classic Excel Add In",
        "Question_creation_time":1647680517643,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/778717\/replacement-for-azure-ml-classic-excel-add-in.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"As far as I can tell there is no way to use the Excel add in for Azure ML using the new Azure ML service, it only works for the Classic. Is there any plan to provide a replacement add in that brings this functionality to the new Azure ML before Classic stops being supported in 2024?",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-21T10:14:07.663Z",
                "Answer_upvote_count":0,
                "Answer_body":"@TimCahill-0615 Thanks for the question. Currently it's on roadmap to support in the near future. Excel add in feature similar to studio classic, it will be built on top on v2 online endpoints.\nCurrently, managed endpoints are not integrated with Designer, we need to first provide capability to do a no code designer deployment on v2 online endpoints and integrating excel add in for v2 endpoints.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML Studio and Git\/AzureDevOps",
        "Question_creation_time":1618340223767,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/355882\/azure-ml-studio-and-gitazuredevops.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"We have created an Azure ML Studio based proof of concept. I would like to get the \"source code\" into a source code repository. We use Git on AzureDevOps.\n\nI'm at a loss where to begin since the designer has no source files with which to interact. All of the project is point-and-click via the Designer. This is a ML project built following this tutorial: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score\n\nWe've created our own models, data, etc and have a solution.\n\nWhat artifacts from an Azure ML Studio project should be included in a version control system? Where are these files located?\n\nThanks for any insight.\n\n-jeremiah",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-14T10:10:18.257Z",
                "Answer_upvote_count":0,
                "Answer_body":"@JeremiahAdams-0775 Thanks for the question. Can you share a snippet of how you are uploading to azure Devops?. Please follow this document: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-model-designer. Basically you can register a trained model in Designer bring it out with SDK\/CLI to deploy it. Just run az ml model download - that will get all of the files.\n\nAlso look at the MLOPs demo.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-04-14T10:18:18.573Z",
                "Answer_upvote_count":0,
                "Answer_body":"@JeremiahAdams-0775 Azure ML designer is designed to simplify the user interface of using machine learning modules as a drag and drop interface where users can train and create models which can be deployed as a service. The interface's backend which creates connections between modules or the experiments are available to view in the ml portal from the designer interface or from the run ids which are under experiments tab. These run details can be from different sources like automl, designer or simply runs created by using the azure ml SDKs. The runs from designer are always set with a tag of azureml.Designer: true which makes it easy to find the runs from a particular designer experiment. All the runs contain details of the metrics, logs, steps, etc. which can be viewed and can be downloaded as a notebook file. For example:\n\nYou can use these files under your version control but the run details are always available in your workspace under different run ids and you can add additional tags to these runs for managing them under your workspace.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"AZURE ML - Web Service",
        "Question_creation_time":1616267169727,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/323764\/azure-ml-web-service.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"How to configure the input fields with drop down values from the experiment. Eg: if car make is a field, the input field for the car make should start showing options when you start entering.\n\n\nList item\n\nIn the below example, fuel field should show drop down values like, diesel, petrol etc. ![79842-image.png][1] [1]: \/answers\/storage\/attachments\/79842-image.png",
        "Answers":[
            {
                "Answer_creation_time":"2021-03-22T12:37:47.683Z",
                "Answer_upvote_count":0,
                "Answer_body":"@LizRay-1175 Thanks for the question. Can you please add more details about the steps that you performed. Please follow this document to deploy with designer and consume the real time endpoint.: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-model-designer? Basically you can register a trained model in Designer bring it out with SDK\/CLI to deploy it.\n\nSharing a reference notebook from Nicholas Moore: https:\/\/github.com\/nfmoore\/aml-designer-iot-edge\/blob\/main\/00-containerize-designer-model.ipynb.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"AML - AssetException: Error with code: Can't connect to HTTPS URL because the SSL module is not available.",
        "Question_creation_time":1667553245710,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1075753\/aml-assetexception-error-with-code-can39t-connect.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello Microsoft Q&A Team,\n\nI get the error\n\nAssetException: Error with code: Can't connect to HTTPS URL because the SSL module is not available\n\nwhen executing the following command:\n\npipeline_job = ml_client.jobs.create_or_update(\npipeline_job, experiment_name=\"data_preparation\"\n)\npipeline_job\n\nYesterday the command worked without an error. I did not make any changes. So I have no idea, what the problem is.\n\nThanks for helping me out.\n\nCheers\n\nLukas",
        "Answers":[
            {
                "Answer_creation_time":"2022-11-04T23:41:10.037Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Lukas-6968 Thanks for your question. Can you please add more details about the document\/sample that you are trying.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-11-07T09:10:33.28Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hello,\n\nI was able to solve the issue.\n\nThank you.\n\nCheers\n\nLukas",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Result with coordinator convertion",
        "Question_creation_time":1648416629250,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/789141\/result-with-coordinator-convertion.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I wonder how could I convert the result of boundingbox of form recognizer into image coordinate to visualize the overlay image and recognized data.\n\nI could not have that accomplished because it is not similar to normal coordinates.",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-27T22:02:17.72Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @masterhunter-9726\n\nThank you for reaching out to us, I think you have questions about the value of boundingBoxes, below I will give an example to explain it so that you can convert it to the coordinate you want to use:\n\nExample:\n\n\n\n\n    'boundingBox': [\n                 57.1,\n                 683.3,\n                 100.2,\n                 683.3,\n                 100.2,\n                 673.3,\n                 57.1,\n                 673.3\n               ]\n\n\n\nThose values represent the vertices of the bounding box as below:\n\n   (57.1,683.3) X1,Y1---->x2,y2(100.2,683.3)\n                   |                |\n                   |                |\n   (57.1,673.3) X4,Y4<----x3,y3(100.2,673.3)\n\n\n\nThe (0,0) is on the bottom left as you can see.\n\n \/\/ Azure Bounding box is like this                     \n \/\/                                                     0---->1\n \/\/                                                    |     |\n \/\/                                         Y          |     |\n \/\/                                         \u2191         3<----2\n \/\/                                  Origin . \u2192 X\n\n\n\nIf you want to measure the boundingBoxes, you can use above vertices to do the calculation.\n\nHope this helps!\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks!",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Unable to sign into Azure Machine Learning Studio (classic), page constantly refreshes.",
        "Question_creation_time":1647878967167,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/780770\/unable-to-sign-into-azure-machine-learning-studio.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\nI am trying to sign into my Free Workspace within the Microsoft Azure Machine Learning Studio (classic).\n\nI am trying to access the RICT2 Prediction and Classification Experiment: https:\/\/gallery.azure.ai\/Experiment\/RICT-Prediction-and-Classification-GB-Single-Year-v4-0\n\nThe page refreshes inexplicably on a loop several times, before displaying a sign-in error.\n\nWould anyone be able to assist?\n\nThank you!",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-22T09:34:53.447Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi Yutong,\n\nI've tried several times, including in an incognito window and it just loops on a refresh. I see the 'Microsoft Azure is going to retire in August' message for a split second, before the page refreshes.\n\nI'm working from Europe, however as per the RICT guidance working in the North American workspace.\n\nThank you.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-03-22T10:00:47.04Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi Yutong,\n\nI've managed to fix it (rather my in-house Frontstack did!). Something to do with the recent chrome update.\n\nThanks for your help.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML Hyperdrive",
        "Question_creation_time":1617723280093,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/346257\/azure-ml-hyperdrive.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"When running the hyperdrive step, I would like to get the hyper parameters that were selected for the best model and export them to use in a subsequent model. How would I got about doing that? I saw a method get_hyperparameters but from what I can tell that just gets all child runs. I am essentially wanting to use the same model but change alpha levels.",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-06T21:26:11.18Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello.\n\nI think below is what you are looking for. Could you please take a look?\n\nOnce all of the hyperparameter tuning runs have completed, identify the best performing configuration and hyperparameter values:\n\n best_run = hyperdrive_run.get_best_run_by_primary_metric()\n best_run_metrics = best_run.get_metrics()\n parameter_values = best_run.get_details()['runDefinition']['Arguments']\n    \n print('Best Run Id: ', best_run.id)\n print('\\n Accuracy:', best_run_metrics['accuracy'])\n print('\\n learning rate:',parameter_values[3])\n print('\\n keep probability:',parameter_values[5])\n print('\\n batch size:',parameter_values[7])\n\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"In multi step pipeline execution, how to maintain the data type of the columns when pass the dataset to next step",
        "Question_creation_time":1645805304397,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/751127\/in-multi-step-pipeline-execution-how-to-maintain-t.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"i am building a pipeline with multiple steps.\n\nStep 1 - Read the data from tabular dataset(with proper data types) , apply transformation and create an output dataset which will be passed as input to the step 2. However when i opened this dataset from the pipeline run log, the datatype all become string instead of maintaining the original data types of the input tabular data set\n\n\nStep 2 - use the output dataset of step 1 as input and apply some more transformations. However i have some logic based on data types which doesn't work because intermediate data set does not maintain the same data structure\n\nis there anyway we can maintain the original data types\/schema structure in the intermediate datasets?\n\nHere is some snippets on my code :\n\nfeature_work = (\nOutputFileDatasetConfig(\nname=\"data_enhanced_add_global_variables\",\ndestination=(def_blob_store, \"data\/processed\/output\/1\"),\n)\n.read_delimited_files()\n.as_upload(overwrite=True)\n\n\n\n\nfeature_engineering_step_1 = PythonScriptStep(name = \"1_feature_engineering\",\n#source_directory = experiment_folder,\nscript_name = \"1_feature_engineering.py\",\narguments = ['--input-data', data_aggregate_DS.as_named_input('raw_data'),\n'--prepped-data', feature_work],\n#outputs=[prepped_data_folder],\noutputs=[feature_work],\ncompute_target = compute_name,\nrunconfig = pipeline_run_config,\nallow_reuse = True)\n# Step 2\nfeature_engineering_step_2 = PythonScriptStep(name = \"2_feature_engineering\",\n#source_directory = experiment_folder,\nscript_name = \"2_feature_engineering.py\",\narguments = ['--input-data', feature_work.as_input(name='raw_data'),\n'--prepped-data', feature_work1],\noutputs=[feature_work1],\ncompute_target = compute_name,\nrunconfig = pipeline_run_config,\nallow_reuse = True)",
        "Answers":[
            {
                "Answer_creation_time":"2022-02-28T12:43:31.087Z",
                "Answer_upvote_count":0,
                "Answer_body":"@VinothKumarK-8698 Thanks for the question. Can you please share the sample notebook that you are trying.\nHere is the notebook and doc that can help.\nOutputFileDatasetConfig as Tutorial: ML pipelines for batch scoring - Azure Machine Learning | Microsoft Docs as a means to pass data between pipeline steps.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Deploying from Azure ML studio Designer is giving error in deploying real time inference endpoint",
        "Question_creation_time":1645328557520,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/742817\/deploying-from-azure-ml-studio-designer-is-giving.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"2022\/02\/20 03:25:31 Downloading source code...\n2022\/02\/20 03:25:32 Finished downloading source code\n2022\/02\/20 03:25:32 Creating Docker network: acb_default_network, driver: 'bridge'\n2022\/02\/20 03:25:32 Successfully set up Docker network: acb_default_network\n2022\/02\/20 03:25:32 Setting up Docker configuration...\n2022\/02\/20 03:25:33 Successfully set up Docker configuration\n2022\/02\/20 03:25:33 Logging in to registry: c89d3aeb8176436a9d4c29a07e6381fb.azurecr.io\n2022\/02\/20 03:25:33 Successfully logged into c89d3aeb8176436a9d4c29a07e6381fb.azurecr.io\n2022\/02\/20 03:25:33 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2022\/02\/20 03:25:33 Scanning for dependencies...\n2022\/02\/20 03:25:34 Successfully scanned dependencies\n2022\/02\/20 03:25:34 Launching container with name: acb_step_0\nSending build context to Docker daemon 66.56kB\n\nStep 1\/21 : FROM mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04@sha256:922be75bb02cf219cb86ac4734bcbda41d956314a4b3b7a4febc807d0a803f6e\nmcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04@sha256:922be75bb02cf219cb86ac4734bcbda41d956314a4b3b7a4febc807d0a803f6e: Pulling from azureml\/openmpi3.1.2-ubuntu18.04\n68e7bb398b9f: Already exists\n893c92dab848: Pulling fs layer\na0757eae439e: Pulling fs layer\nee2957a13303: Pulling fs layer\nf49a3daea774: Pulling fs layer\ncab73971ce79: Pulling fs layer\nc3d7fbfdaca2: Pulling fs layer\n0976efdf0829: Pulling fs layer\nd02e6f607e12: Pulling fs layer\nf49a3daea774: Waiting\ncab73971ce79: Waiting\nc3d7fbfdaca2: Waiting\n0976efdf0829: Waiting\nd02e6f607e12: Waiting\nee2957a13303: Verifying Checksum\nee2957a13303: Download complete\nf49a3daea774: Verifying Checksum\nf49a3daea774: Download complete\ncab73971ce79: Verifying Checksum\ncab73971ce79: Download complete\nc3d7fbfdaca2: Verifying Checksum\nc3d7fbfdaca2: Download complete\n0976efdf0829: Verifying Checksum\n0976efdf0829: Download complete\n893c92dab848: Verifying Checksum\n893c92dab848: Download complete\nd02e6f607e12: Verifying Checksum\nd02e6f607e12: Download complete\na0757eae439e: Verifying Checksum\na0757eae439e: Download complete\n893c92dab848: Pull complete\na0757eae439e: Pull complete\nee2957a13303: Pull complete\nf49a3daea774: Pull complete\ncab73971ce79: Pull complete\nc3d7fbfdaca2: Pull complete\n0976efdf0829: Pull complete\nd02e6f607e12: Pull complete\nDigest: sha256:922be75bb02cf219cb86ac4734bcbda41d956314a4b3b7a4febc807d0a803f6e\nStatus: Downloaded newer image for mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04@sha256:922be75bb02cf219cb86ac4734bcbda41d956314a4b3b7a4febc807d0a803f6e\n---> 8926027fde41\nStep 2\/21 : USER root\n---> Running in 0b57828c9289\nRemoving intermediate container 0b57828c9289\n---> 370ef8ee2d0f\nStep 3\/21 : RUN mkdir -p $HOME\/.cache\n---> Running in 3eee95c47f9f\nRemoving intermediate container 3eee95c47f9f\n---> 415459035e6d\nStep 4\/21 : WORKDIR \/\n---> Running in 08c6f83df4b1\nRemoving intermediate container 08c6f83df4b1\n---> 4216bc82e697\nStep 5\/21 : COPY azureml-environment-setup\/99brokenproxy \/etc\/apt\/apt.conf.d\/\n---> 03b433a4a6b8\nStep 6\/21 : RUN if dpkg --compare-versions conda --version | grep -oE '[^ ]+$' lt 4.4.11; then conda install conda==4.4.11; fi\n---> Running in a59290010c77\nRemoving intermediate container a59290010c77\n---> 5bc601b6dd21\nStep 7\/21 : COPY azureml-environment-setup\/mutated_conda_dependencies.yml azureml-environment-setup\/mutated_conda_dependencies.yml\n---> d43a193f0f3e\nStep 8\/21 : RUN ldconfig \/usr\/local\/cuda\/lib64\/stubs && conda env create -p \/azureml-envs\/azureml_9a27d0b682f7325ef536eaeb801b2a62 -f azureml-environment-setup\/mutated_conda_dependencies.yml && rm -rf \"$HOME\/.cache\/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR\/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name pycache -exec rm -rf {} + && ldconfig\n---> Running in 6f1452f548f8\nCollecting package metadata (repodata.json): ...working...\ndone\nSolving environment: ...working... done\n\nDownloading and Extracting Packages\n\nlibblas-3.9.0 | 12 KB | | 0%\nlibblas-3.9.0 | 12 KB | ########## | 100%\n\nreadline-7.0 | 391 KB | | 0%\nreadline-7.0 | 391 KB | ########## | 100%\n\ntk-8.6.12 | 3.3 MB | | 0%\ntk-8.6.12 | 3.3 MB | #####1 | 51%\ntk-8.6.12 | 3.3 MB | ########## | 100%\ntk-8.6.12 | 3.3 MB | ########## | 100%\n\nsix-1.16.0 | 14 KB | | 0%\nsix-1.16.0 | 14 KB | ########## | 100%\n\nsqlite-3.28.0 | 1.9 MB | | 0%\nsqlite-3.28.0 | 1.9 MB | ########## | 100%\nsqlite-3.28.0 | 1.9 MB | ########## | 100%\n\nncurses-6.3 | 1012 KB | | 0%\nncurses-6.3 | 1012 KB | ########## | 100%\nncurses-6.3 | 1012 KB | ########## | 100%\n\nlibgfortran-ng-11.2. | 19 KB | | 0%\nlibgfortran-ng-11.2. | 19 KB | ########## | 100%\n\nopenssl-1.1.1l | 2.1 MB | | 0%\nopenssl-1.1.1l | 2.1 MB | ########## | 100%\nopenssl-1.1.1l | 2.1 MB | ########## | 100%\n\nzlib-1.2.11 | 86 KB | | 0%\nzlib-1.2.11 | 86 KB | ########## | 100%\n\nlibcblas-3.9.0 | 12 KB | | 0%\nlibcblas-3.9.0 | 12 KB | ########## | 100%\n\nlibgomp-11.2.0 | 426 KB | | 0%\nlibgomp-11.2.0 | 426 KB | ########## | 100%\n\n_libgcc_mutex-0.1 | 3 KB | | 0%\n_libgcc_mutex-0.1 | 3 KB | ########## | 100%\n\nlibzlib-1.2.11 | 59 KB | | 0%\nlibzlib-1.2.11 | 59 KB | ########## | 100%\n\nlibffi-3.2.1 | 47 KB | | 0%\nlibffi-3.2.1 | 47 KB | ########## | 100%\n\npip-20.2.4 | 1.1 MB | | 0%\npip-20.2.4 | 1.1 MB | ########## | 100%\npip-20.2.4 | 1.1 MB | ########## | 100%\n\nsetuptools-58.0.4 | 966 KB | | 0%\nsetuptools-58.0.4 | 966 KB | ########## | 100%\nsetuptools-58.0.4 | 966 KB | ########## | 100%\n\nxz-5.2.5 | 343 KB | | 0%\nxz-5.2.5 | 343 KB | ########## | 100%\nxz-5.2.5 | 343 KB | ########## | 100%\n\npython_abi-3.6 | 4 KB | | 0%\npython_abi-3.6 | 4 KB | ########## | 100%\n\nnumpy-1.19.5 | 5.3 MB | | 0%\nnumpy-1.19.5 | 5.3 MB | ######9 | 70%\nnumpy-1.19.5 | 5.3 MB | ########## | 100%\nnumpy-1.19.5 | 5.3 MB | ########## | 100%\n\njoblib-1.1.0 | 210 KB | | 0%\njoblib-1.1.0 | 210 KB | ########## | 100%\n\nlibgfortran5-11.2.0 | 1.7 MB | | 0%\nlibgfortran5-11.2.0 | 1.7 MB | ########## | 100%\nlibgfortran5-11.2.0 | 1.7 MB | ########## | 100%\n\nca-certificates-2021 | 139 KB | | 0%\nca-certificates-2021 | 139 KB | ########## | 100%\n\nwheel-0.37.1 | 31 KB | | 0%\nwheel-0.37.1 | 31 KB | ########## | 100%\n\n_openmp_mutex-4.5 | 22 KB | | 0%\n_openmp_mutex-4.5 | 22 KB | ########## | 100%\n\nscikit-surprise-1.0. | 636 KB | | 0%\nscikit-surprise-1.0. | 636 KB | ########## | 100%\nscikit-surprise-1.0. | 636 KB | ########## | 100%\n\nlibopenblas-0.3.18 | 9.6 MB | | 0%\nlibopenblas-0.3.18 | 9.6 MB | ######2 | 63%\nlibopenblas-0.3.18 | 9.6 MB | #########8 | 99%\nlibopenblas-0.3.18 | 9.6 MB | ########## | 100%\n\nlibgcc-ng-11.2.0 | 904 KB | | 0%\nlibgcc-ng-11.2.0 | 904 KB | ########## | 100%\nlibgcc-ng-11.2.0 | 904 KB | ########## | 100%\n\nlibstdcxx-ng-11.2.0 | 4.2 MB | | 0%\nlibstdcxx-ng-11.2.0 | 4.2 MB | ########## | 100%\nlibstdcxx-ng-11.2.0 | 4.2 MB | ########## | 100%\n\npython-3.6.8 | 30.1 MB | | 0%\npython-3.6.8 | 30.1 MB | #6 | 17%\npython-3.6.8 | 30.1 MB | ######2 | 63%\npython-3.6.8 | 30.1 MB | ########## | 100%\npython-3.6.8 | 30.1 MB | ########## | 100%\n\nliblapack-3.9.0 | 12 KB | | 0%\nliblapack-3.9.0 | 12 KB | ########## | 100%\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\nInstalling pip dependencies: ...working...\nRan pip subprocess with arguments:\n['\/azureml-envs\/azureml_9a27d0b682f7325ef536eaeb801b2a62\/bin\/python', '-m', 'pip', 'install', '-U', '-r', '\/azureml-environment-setup\/condaenv.s4sfl041.requirements.txt']\nPip subprocess output:\nCollecting azureml-designer-classic-modules==0.0.161\nDownloading azureml_designer_classic_modules-0.0.161-py3-none-any.whl (403 kB)\nCollecting en_core_web_sm\nDownloading https:\/\/github.com\/explosion\/spacy-models\/releases\/download\/en_core_web_sm-2.1.0\/en_core_web_sm-2.1.0.tar.gz (11.1 MB)\nCollecting spacy==2.1.7\nDownloading spacy-2.1.7-cp36-cp36m-manylinux1_x86_64.whl (30.8 MB)\nCollecting azureml-model-management-sdk\nDownloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\nCollecting azure-storage-blob==1.5.0\nDownloading azure_storage_blob-1.5.0-py2.py3-none-any.whl (75 kB)\nCollecting azureml-designer-internal==0.0.56\nDownloading azureml_designer_internal-0.0.56-py3-none-any.whl (28 kB)\nCollecting seaborn==0.10.0\nDownloading seaborn-0.10.0-py3-none-any.whl (215 kB)\nCollecting gensim==3.8.3\nDownloading gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2 MB)\nCollecting lightgbm==3.2.1\nDownloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\nCollecting chardet==3.0.4\nDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\nCollecting joblib==0.14.0\nDownloading joblib-0.14.0-py2.py3-none-any.whl (294 kB)\nCollecting scipy==1.4.1\nDownloading scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1 MB)\nCollecting nimbusml==1.6.1\nDownloading nimbusml-1.6.1-cp36-none-manylinux1_x86_64.whl (105.2 MB)\nCollecting matplotlib==3.1.3\nDownloading matplotlib-3.1.3-cp36-cp36m-manylinux1_x86_64.whl (13.1 MB)\nCollecting pandas==1.0.4\nDownloading pandas-1.0.4-cp36-cp36m-manylinux1_x86_64.whl (10.1 MB)\nCollecting scikit-learn==0.22.2\nDownloading scikit_learn-0.22.2-cp36-cp36m-manylinux1_x86_64.whl (7.1 MB)\nCollecting imbalanced-learn==0.4.3\nDownloading imbalanced_learn-0.4.3-py3-none-any.whl (166 kB)\nCollecting Pillow==8.3.2\nDownloading Pillow-8.3.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\nCollecting azureml-interpret==1.36.0\nDownloading azureml_interpret-1.36.0-py3-none-any.whl (52 kB)\nCollecting blis<0.3.0,>=0.2.2\nDownloading blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (3.2 MB)\nCollecting plac<1.0.0,>=0.9.6\nDownloading plac-0.9.6-py2.py3-none-any.whl (20 kB)\nRequirement already satisfied, skipping upgrade: numpy>=1.15.0 in \/azureml-envs\/azureml_9a27d0b682f7325ef536eaeb801b2a62\/lib\/python3.6\/site-packages (from spacy==2.1.7->-r \/azureml-environment-setup\/condaenv.s4sfl041.requirements.txt (line 3)) (1.19.5)\nCollecting murmurhash<1.1.0,>=0.28.0\nDownloading murmurhash-1.0.6-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\nCollecting cymem<2.1.0,>=2.0.2\nDownloading cymem-2.0.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\nCollecting srsly<1.1.0,>=0.0.6\nDownloading srsly-1.0.5-cp36-cp36m-manylinux2014_x86_64.whl (184 kB)\nCollecting requests<3.0.0,>=2.13.0\nDownloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\nCollecting thinc<7.1.0,>=7.0.8\nDownloading thinc-7.0.8-cp36-cp36m-manylinux1_x86_64.whl (2.1 MB)\nCollecting preshed<2.1.0,>=2.0.1\nDownloading preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (83 kB)\nCollecting wasabi<1.1.0,>=0.2.0\nDownloading wasabi-0.9.0-py3-none-any.whl (25 kB)\nRequirement already satisfied, skipping upgrade: six>=1.10 in \/azureml-envs\/azureml_9a27d0b682f7325ef536eaeb801b2a62\/lib\/python3.6\/site-packages (from azureml-model-management-sdk->-r \/azureml-environment-setup\/condaenv.s4sfl041.requirements.txt (line 4)) (1.16.0)\nCollecting adal>=0.4.5\nDownloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\nCollecting dill>=0.2.7.1\nDownloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\nCollecting python-dateutil>=2.5.3\nDownloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\nCollecting liac-arff>=2.1.1\nDownloading liac-arff-2.5.0.tar.gz (13 kB)\nCollecting pytz>=2017.2\nDownloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\nCollecting azure-storage-common~=1.4\nDownloading azure_storage_common-1.4.2-py2.py3-none-any.whl (47 kB)\nCollecting azure-common>=1.1.5\nDownloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\nCollecting azureml-pipeline-core==1.36.0\nDownloading azureml_pipeline_core-1.36.0-py3-none-any.whl (313 kB)\nCollecting azureml-defaults==1.36.0\nDownloading azureml_defaults-1.36.0-py3-none-any.whl (3.0 kB)\nCollecting azureml-telemetry==1.36.0.\nDownloading azureml_telemetry-1.36.0-py3-none-any.whl (30 kB)\nCollecting cffi==1.12.3\nDownloading cffi-1.12.3-cp36-cp36m-manylinux1_x86_64.whl (430 kB)\nCollecting azureml-designer-core==0.0.68\nDownloading azureml_designer_core-0.0.68-py3-none-any.whl (101 kB)\nCollecting smart-open>=1.8.1\nDownloading smart_open-5.2.1-py3-none-any.whl (58 kB)\nRequirement already satisfied, skipping upgrade: wheel in \/azureml-envs\/azureml_9a27d0b682f7325ef536eaeb801b2a62\/lib\/python3.6\/site-packages (from lightgbm==3.2.1->azureml-designer-classic-modules==0.0.161->-r \/azureml-environment-setup\/condaenv.s4sfl041.requirements.txt (line 1)) (0.37.1)\nCollecting dotnetcore2>=2.1.2\nDownloading dotnetcore2-2.1.23-py3-none-manylinux1_x86_64.whl (29.3 MB)\nCollecting kiwisolver>=1.0.1\nDownloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\nCollecting cycler>=0.10\nDownloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\nCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1\nDownloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\nCollecting interpret-community==0.21.\nDownloading interpret_community-0.21.0-py3-none-any.whl (136 kB)\nCollecting azureml-core~=1.36.0\nDownloading azureml_core-1.36.0.post2-py3-none-any.whl (2.4 MB)\nCollecting certifi>=2017.4.17\nDownloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\nCollecting idna<4,>=2.5; python_version >= \"3\"\nDownloading idna-3.3-py3-none-any.whl (61 kB)\nCollecting charset-normalizer~=2.0.0; python_version >= \"3\"\nDownloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\nCollecting urllib3<1.27,>=1.21.1\nDownloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\nCollecting tqdm<5.0.0,>=4.10.0\nDownloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\nCollecting PyJWT<3,>=1.0.0\nDownloading PyJWT-2.3.0-py3-none-any.whl (16 kB)\nCollecting cryptography>=1.1.0\nDownloading cryptography-36.0.1-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\nCollecting configparser==3.7.4\nDownloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\nCollecting json-logging-py==0.2\nDownloading json-logging-py-0.2.tar.gz (3.6 kB)\nCollecting azureml-inference-server-http~=0.4.1\nDownloading azureml_inference_server_http-0.4.9-py3-none-any.whl (52 kB)\nCollecting azureml-dataset-runtime[fuse]~=1.36.0\nDownloading azureml_dataset_runtime-1.36.0-py3-none-any.whl (3.5 kB)\nCollecting applicationinsights\nDownloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\nCollecting pycparser\nDownloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\nCollecting pycryptodomex==3.7.3\nDownloading pycryptodomex-3.7.3-cp36-cp36m-manylinux1_x86_64.whl (7.5 MB)\nCollecting pyarrow==0.16.0\nDownloading pyarrow-0.16.0-cp36-cp36m-manylinux2014_x86_64.whl (63.1 MB)\nCollecting distro==1.4.0\nDownloading distro-1.4.0-py2.py3-none-any.whl (17 kB)\nCollecting ruamel.yaml==0.16.10\nDownloading ruamel.yaml-0.16.10-py2.py3-none-any.whl (111 kB)\nCollecting more-itertools==6.0.0\nDownloading more_itertools-6.0.0-py3-none-any.whl (52 kB)\nCollecting jsonschema==3.0.1\nDownloading jsonschema-3.0.1-py2.py3-none-any.whl (54 kB)\nCollecting interpret-core[required]<=0.2.6,>=0.1.20\nDownloading interpret_core-0.2.6-py3-none-any.whl (6.5 MB)\nCollecting packaging\nDownloading packaging-21.3-py3-none-any.whl (40 kB)\nCollecting shap<=0.39.0,>=0.20.0\nDownloading shap-0.39.0.tar.gz (356 kB)\nCollecting numba<0.54.0\nDownloading numba-0.53.1-cp36-cp36m-manylinux2014_x86_64.whl (3.4 MB)\nCollecting ndg-httpsclient<=0.5.1\nDownloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\nCollecting jmespath<1.0.0\nDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\nCollecting azure-graphrbac<1.0.0,>=0.40.0\nDownloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\nCollecting backports.tempfile\nDownloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\nCollecting msrest<1.0.0,>=0.5.1\nDownloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\nCollecting azure-mgmt-containerregistry>=2.0.0\nDownloading azure_mgmt_containerregistry-9.0.0-py3-none-any.whl (937 kB)\nCollecting jsonpickle<3.0.0\nDownloading jsonpickle-2.1.0-py2.py3-none-any.whl (38 kB)\nCollecting SecretStorage<4.0.0\nDownloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\nCollecting azure-mgmt-keyvault<10.0.0,>=0.40.0\nDownloading azure_mgmt_keyvault-9.3.0-py2.py3-none-any.whl (412 kB)\nCollecting pathspec<1.0.0\nDownloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\nCollecting azure-mgmt-storage<16.0.0,>=1.5.0\nDownloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\nCollecting contextlib2<22.0.0\nDownloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\nCollecting msrestazure<=0.6.4,>=0.4.33\nDownloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\nCollecting azure-mgmt-resource<15.0.0,>=1.2.1\nDownloading azure_mgmt_resource-13.0.0-py2.py3-none-any.whl (1.3 MB)\nCollecting pyopenssl<21.0.0\nDownloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)\nCollecting docker<6.0.0\nDownloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\nCollecting azure-mgmt-authorization<1.0.0,>=0.40.0\nDownloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\nCollecting sanic-cors~=1.0.1\nDownloading Sanic_Cors-1.0.1-py2.py3-none-any.whl (17 kB)\nCollecting inference-schema~=1.3.1\nDownloading inference_schema-1.3.1-py3-none-any.whl (20 kB)\nCollecting protobuf~=3.17.3\nDownloading protobuf-3.17.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\nCollecting grpcio-tools~=1.38.1\nDownloading grpcio_tools-1.38.1-cp36-cp36m-manylinux2014_x86_64.whl (2.5 MB)\nCollecting aiohttp~=3.7.4.post0\nDownloading aiohttp-3.7.4.post0-cp36-cp36m-manylinux2014_x86_64.whl (1.3 MB)\nCollecting aiotask-context~=0.6.1\nDownloading aiotask_context-0.6.1-py3-none-any.whl (3.5 kB)\nCollecting opencensus-ext-azure~=1.1.0\nDownloading opencensus_ext_azure-1.1.1-py2.py3-none-any.whl (42 kB)\nCollecting gunicorn==20.1.0; platform_system != \"Windows\"\nDownloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\nCollecting tritonclient[all]~=2.11.0\nDownloading tritonclient-2.11.0-py3-none-manylinux1_x86_64.whl (7.7 MB)\n\nfailed\n[91m\n\n==> WARNING: A newer version of conda exists. <==\ncurrent version: 4.9.2\nlatest version: 4.11.0\n\nPlease update conda by running\n\n $ conda update -n base -c defaults conda\n\n\n\n\nPip subprocess error:\nERROR: Could not find a version that satisfies the requirement sanic~=21.6.0 (from azureml-inference-server-http~=0.4.1->azureml-defaults==1.36.0->azureml-designer-internal==0.0.56->azureml-designer-classic-modules==0.0.161->-r \/azureml-environment-setup\/condaenv.s4sfl041.requirements.txt (line 1)) (from versions: 0.1.0, 0.1.1, 0.1.3, 0.1.4, 0.1.5, 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.3.0, 0.3.1, 0.4.0, 0.4.1, 0.5.0, 0.5.1, 0.5.2, 0.5.4, 0.6.0, 0.7.0, 0.8.0, 0.8.1, 0.8.2, 0.8.3, 18.12.0, 19.3.1, 19.6.0, 19.6.2, 19.6.3, 19.9.0, 19.12.0, 19.12.2, 19.12.3, 19.12.4, 19.12.5, 20.3.0, 20.6.0, 20.6.1, 20.6.2, 20.6.3, 20.9.0, 20.9.1, 20.12.0, 20.12.1, 20.12.2, 20.12.3, 20.12.4, 20.12.5, 20.12.6)\nERROR: No matching distribution found for sanic~=21.6.0 (from azureml-inference-server-http~=0.4.1->azureml-defaults==1.36.0->azureml-designer-internal==0.0.56->azureml-designer-classic-modules==0.0.161->-r \/azureml-environment-setup\/condaenv.s4sfl041.requirements.txt (line 1))\n\n\n\n\nCondaEnvException: Pip failed\n\n[0mThe command '\/bin\/sh -c ldconfig \/usr\/local\/cuda\/lib64\/stubs && conda env create -p \/azureml-envs\/azureml_9a27d0b682f7325ef536eaeb801b2a62 -f azureml-environment-setup\/mutated_conda_dependencies.yml && rm -rf \"$HOME\/.cache\/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR\/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name pycache -exec rm -rf {} + && ldconfig' returned a non-zero code: 1\n2022\/02\/20 03:27:17 Container failed during run: acb_step_0. No retries remaining.\nfailed to run step ID: acb_step_0: exit status 1\n\nRun ID: cf6 failed after 1m47s. Error: failed during run, err: exit status 1",
        "Answers":[
            {
                "Answer_creation_time":"2022-02-21T14:51:28.87Z",
                "Answer_upvote_count":0,
                "Answer_body":"@ shrutinehra-0489 Thanks for the question. Please share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"While registering a dataframe in AzureML pipeline, getting error: 'DataFrame' object has no attribute 'register. How do we actually store dataframe into Azure Blob Storage?",
        "Question_creation_time":1624431973167,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/448224\/while-registering-a-dataframe-in-azureml-pipeline.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-blob-storage"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"While registering a dataframe in AzureML pipeline, getting error: 'DataFrame' object has no attribute 'register. How do we actually store dataframe into Azure Blob Storage?\n\nCode snippet-\n\n<DataFrame>.register(workspace=ws, name='<abc>', description='<abc>', tags = {'format':'CSV'}, create_new_version=True)",
        "Answers":[
            {
                "Answer_creation_time":"2021-06-23T10:48:47.457Z",
                "Answer_upvote_count":0,
                "Answer_body":"@JitenderKumarChandel-0663 I think this is a valid error since the dataset cannot be registered with the above command. You should try the steps mentioned in this notebook.\n\nThese steps should help to register your CSV data as dataframe.\n\n datastore = ws.get_default_datastore()\n datastore.upload_files(files = ['.\/train-dataset\/iris.csv'],\n                        target_path = 'train-dataset\/tabular\/',\n                        overwrite = True,\n                        show_progress = True)\n    \n from azureml.core import Dataset\n dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, 'train-dataset\/tabular\/iris.csv')])\n    \n # preview the first 3 rows of the dataset\n dataset.take(3).to_pandas_dataframe()\n\n\n\nPlease feel free to accept the above response as answer if it helped. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Where are the variables quotients after doing a regression run in ML?",
        "Question_creation_time":1617200123477,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/339422\/where-are-the-variables-quotients-after-doing-a-re.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Having done my first Azure ML Studio session, the presented output metrics are global (Spearman, Explained variance, etc) are somewhat secondary to my requirement of knowing how each of my hundreds of variables have contributed to these. But I cannot find them. I would appreciate some guidance to where such numbers are - I know they have to be somewhere, as they (in total) provide the shown metrics.",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"ModuleNotFoundError: No module named 'azure.ai'",
        "Question_creation_time":1668204745757,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1086028\/modulenotfounderror-no-module-named-39azureai39.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am getting the following error message\n\nModuleNotFoundError: No module named 'azure.ai'\n\n\n\n\nin Azure machine learning studio...when i try to run sample azureml-in-a-day.ipynb",
        "Answers":[
            {
                "Answer_creation_time":"2022-11-15T19:33:55.33Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hello @Antonymstephen\n\nSorry for your experience and thanks for reaching out to us, I am able to reproduce your issue with my new create compute-cpu.\n\nThere are two workaround working well for myself, please have a try and let me know if that works for you or not -\n\n1.Copy the whole Tutorial file as this guidance - https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/quickstart-run-notebooks#clone-tutorials-folder\n\n\n\n\n2.Easy install the azureml in your compute at the terminal under your root user.\n\n pip install azureml\n\n\n\nJust in case, I encounter pyarrow error after that, the resolution is uninstall the pyarrow 4.0 and install pyarrow 3.0.0 instead as below:\n\n pip uninstall pyarrow\n        \n pip install pyarrow==3.0.0\n\n\n\nI have forwarded this bug to product group and hope to make this process smoother. Please let me know how is things going and I am willing to help more.\n\n\n\n\nRegards,\nYutong\n\nPlease kindly accept the answer if you feel this is helpful. Thank you.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Deploying an ML Model to ACI with a secured workspace in a VNet",
        "Question_creation_time":1649065504527,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/799037\/deploying-and-ml-model-to-aci-with-a-secured-works.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-container-instances",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"I am trying to deploy an ML model to an ACI in a VNet. I have followed the guide to setup a secure workspace, and also noted that if deploying to ACI, the container registry must not be in the same vnet.\nI have deployed the container registry:\n\noutside of the vnet in the same resource group\n\n\nAllowed admin user in the CR\n\n\nDisabled public access\n\n\nAllowed trusted microsoft services\n\n\nCreated a private endpoint for private access for the worskpace to access (needed this for image builds on my training runs)\n\n\nAllowed subnet delegation on the Scoring subnet for the containerGroups service as shown here\n\n\n\n\nNow when I am trying to deploy the model to a container instance, I get this failure\n```\nError:\n{\n\"code\": \"InaccessibleImage\",\n\"statusCode\": 400,\n\"message\": \"ACI Service request failed. Reason: The image '<containerRegName>.azurecr.io\/azureml\/azureml_<imageHash>' in container group '<serviceName>-qcloi6KnEkOQ6CTdniybhQ' is not accessible. Please check the image and registry credential.. Refer to https:\/\/docs.microsoft.com\/azure\/container-registry\/container-registry-authentication#admin-account and make sure Admin user is enabled for your container registry.\"\n}\n```\nAfter speaking to the docs team where the guides address this deployment strategy (here), the only response is to use AKS. AKS won't be feasible right now for this project and the documentation seems to suggest that this is possible.",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":15.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Auth Problems with Machine Learning Execute Pipeline Activity.",
        "Question_creation_time":1621952386747,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/408869\/auth-problems-with-machine-learning-execute-pipeli.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-data-factory",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":3,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello. Can anyone help with this error? Can not execute Azure ML activity from ADF.\nEverything was ok, no changes was done but suddenly(two-three days ago) I got this error.\n\n Request sent to Azure ML Service for operation 'submitMLPipelineRun' failed with http status code 'Forbidden'. Error message from Azure ML Service: '{ \"error\": { \"code\": \"UserError\", \"severity\": null, \"message\": \"Identity does not have permissions for Microsoft.MachineLearningServices\/workspaces\/experiments\/runs\/submit\/action, Microsoft.MachineLearningServices\/workspaces\/endpoints\/pipelines\/read actions.\", \"messageFormat\": null, \"messageParameters\": null, \"referenceCode\": null, \"detailsUri\": null, \"target\": null, \"details\": [], \"innerError\": { \"code\": \"ForbiddenError\", \"innerError\": null } '.",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-25T19:35:57.963Z",
                "Answer_upvote_count":1,
                "Answer_body":"@DenisBruk-6507\n\nWe have identified the issue and a hot fix is rolling out. It will be fixed in all regions by end of today. Sorry for the experience.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-05-25T17:34:38.503Z",
                "Answer_upvote_count":1,
                "Answer_body":"@YutongTie-5848 I think that this may also be related to our issue. I'm also getting a \"code\": \"ForbiddenError\" and the problem for this user arose at almost exactly the same time that it arose for us.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-26T17:41:58.203Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hello everyone,\n\nThis issue should be fixed. Please check and let me know if you are still facing any issue.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How should I create a scoring script for object detection (pytorch) in Azure ML?",
        "Question_creation_time":1655225088730,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/889212\/how-should-i-create-a-scoring-script-for-object-de.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-custom-vision",
            "azure-computer-vision"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi there,\n\nI have trained a PyTorch vision model on a local computer for object detection and want to deploy it on Azure ML. I have found a similar script for classification using pytorch where they are using the following scoring script. link: https:\/\/github.com\/Azure\/MachineLearningNotebooks\/tree\/master\/how-to-use-azureml\/ml-frameworks\/pytorch\/train-hyperparameter-tune-deploy-with-pytorch\n\n # Copyright (c) Microsoft. All rights reserved.\n # Licensed under the MIT license.\n import os\n import torch\n import torch.nn as nn\n from torchvision import transforms\n import json\n from azureml.core.model import Model\n def init():\n     global model\n     # AZUREML_MODEL_DIR is an environment variable created during deployment.\n     # It is the path to the model folder (.\/azureml-models\/$MODEL_NAME\/$VERSION)\n     # For multiple models, it points to the folder containing all deployed models (.\/azureml-models)\n     model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.pt')\n     model = torch.load(model_path, map_location=lambda storage, loc: storage)\n     model.eval()\n def run(input_data):\n     input_data = torch.tensor(json.loads(input_data)['data'])\n     # get prediction\n     with torch.no_grad():\n         output = model(input_data)\n         classes = ['chicken', 'turkey']\n         softmax = nn.Softmax(dim=1)\n         pred_probs = softmax(output).numpy()[0]\n         index = torch.argmax(output, 1)\n     result = {\"label\": classes[index], \"probability\": str(pred_probs[index])}\n     return result\n\n\n\nI have a few questions regarding this script. I am wondering what is 'input_data' in this case, is it an image in jpg format?\nAlso can my 'result' be in any dict format or it should have a specific format?\n\nI have written a similar script for my purpose.\n\n # Copyright (c) Microsoft. All rights reserved.\n # Licensed under the MIT license.\n import os\n import torch\n import torchvision\n #import torch.nn as nn\n from torchvision import transforms\n import json\n import cv2\n from azureml.core.model import Model\n import numpy as np\n from PIL import Image\n import os\n def init():\n     global model\n     # AZUREML_MODEL_DIR is an environment variable created during deployment.\n     # It is the path to the model folder (.\/azureml-models\/$MODEL_NAME\/$VERSION)\n     # For multiple models, it points to the folder containing all deployed models (.\/azureml-models)\n     # model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.pt')\n     # model = torch.load(model_path, map_location=lambda storage, loc: storage)\n     # #model_path = Model.get_model_path(model_name='pytorch_external_model-test')\n     # model = torch.load(model_path)\n     model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'),'model.pt')\n     model = torch.load(model_path, map_location=lambda storage, loc: storage)\n     #model = torch.load(model_path)\n     model.eval()\n # the function takes the original prediction and the iou threshold.\n def apply_nms(orig_prediction, iou_thresh=0.3):\n # torchvision returns the indices of the bboxes to keep\n keep = torchvision.ops.nms(orig_prediction['boxes'], orig_prediction['scores'], iou_thresh)\n    \n final_prediction = orig_prediction\n #print(final_prediction['boxes'])\n final_prediction['boxes'] = final_prediction['boxes'][keep].cpu() # had to add .cpu() after each tensor \n final_prediction['scores'] = final_prediction['scores'][keep].cpu() \n final_prediction['labels'] = final_prediction['labels'][keep].cpu() \n return final_prediction\n # def preprocess(input_data): # doesn't convert to tensor, while input for prediction needs to be in tensor\n #     img = cv2.imread(input_data)\n #     img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n #     img_res = cv2.resize(img_rgb, (704, 480), cv2.INTER_AREA)\n #     # diving by 255\n #     img_res \/= 255.0\n #     return img_res\n def run(input_data):\n     img = Image.open(input_data).convert('RGB')\n     # set up transformation to resize the image\n     resize = transforms.Resize([704, 480])\n     img = resize(img)\n     to_tensor = transforms.ToTensor()\n     # apply transformation and convert to Pytorch tensor\n     tensor = to_tensor(img) # output shape [3, 704, 480] \n     #tensor = tensor.unsqueeze(0) # no need for [1, 3, 704, 480]\n     # link for converting image to tensor https:\/\/towardsdatascience.com\/convert-images-to-tensors-in-pytorch-and-tensorflow-f0ab01383a03\n     #input_data = torch.tensor(json.loads(input_data)['data'])\n     #image = preprocess(input_data)\n     device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n     with torch.no_grad():\n         prediction = model([tensor.to(device)])[0]\n     nms_prediction = apply_nms(prediction, iou_thresh=0.3)\n     result = {\"label\": nms_prediction['labels'], \"box\": nms_prediction['boxes'], \"score\": nms_prediction['scores']}\n     return result\n\nI followed this colab tutorial for training the object detection model. I am not using any transform to make the problem easy for now.\nhttps:\/\/colab.research.google.com\/drive\/1NziO_b-SW9KmWFh-6C8to9H_QAdpmCBZ?usp=sharing#scrollTo=WOrNovPGh_k6\n\nModel is deployed successfully. But getting this error\n\nprint(service.get_logs())\n\n \/bin\/bash: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)\n \/bin\/bash: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)\n \/bin\/bash: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)\n \/bin\/bash: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)\n 2022-06-15T00:14:38,162168400+00:00 - gunicorn\/run \n 2022-06-15T00:14:38,166094000+00:00 - rsyslog\/run \n 2022-06-15T00:14:38,171921600+00:00 - iot-server\/run \n bash: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/libtinfo.so.5: no version information available (required by bash)\n 2022-06-15T00:14:38,190831400+00:00 | gunicorn\/run | \n 2022-06-15T00:14:38,197941200+00:00 | gunicorn\/run | ###############################################\n 2022-06-15T00:14:38,242881800+00:00 | gunicorn\/run | AzureML Container Runtime Information\n 2022-06-15T00:14:38,300863500+00:00 | gunicorn\/run | ###############################################\n 2022-06-15T00:14:38,351919200+00:00 - nginx\/run \n 2022-06-15T00:14:38,377608200+00:00 | gunicorn\/run | \n 2022-06-15T00:14:38,413561500+00:00 | gunicorn\/run | \n 2022-06-15T00:14:38,436442300+00:00 | gunicorn\/run | PATH environment variable: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/bin:\/opt\/miniconda\/bin:\/usr\/local\/nvidia\/bin:\/usr\/local\/cuda\/bin:\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin\n 2022-06-15T00:14:38,472313100+00:00 | gunicorn\/run | PYTHONPATH environment variable: \n 2022-06-15T00:14:38,478958600+00:00 | gunicorn\/run | \n 2022-06-15T00:14:38,501877400+00:00 | gunicorn\/run | Pip Dependencies (before dynamic installation)\n EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n \/bin\/bash: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)\n 2022-06-15T00:14:38,787582000+00:00 - iot-server\/finish 1 0\n 2022-06-15T00:14:38,793119200+00:00 - Exit code 1 is normal. Not restarting iot-server.\n adal==1.2.7\n albumentations==0.4.6\n applicationinsights==0.11.10\n argcomplete==2.0.0\n attrs==21.4.0\n azure-common==1.1.28\n azure-core==1.22.1\n azure-graphrbac==0.61.1\n azure-identity==1.7.0\n azure-mgmt-authorization==2.0.0\n azure-mgmt-containerregistry==9.1.0\n azure-mgmt-core==1.3.0\n azure-mgmt-keyvault==9.3.0\n azure-mgmt-resource==21.0.0\n azure-mgmt-storage==20.0.0\n azureml-core==1.42.0.post1\n azureml-dataprep==4.0.3\n azureml-dataprep-native==38.0.0\n azureml-dataprep-rslex==2.6.3\n azureml-dataset-runtime==1.42.0\n azureml-defaults==1.42.0\n azureml-inference-server-http==0.4.13\n backports.tempfile==1.0\n backports.weakref==1.0.post1\n bcrypt==3.2.2\n cachetools==4.2.4\n certifi==2022.5.18.1\n cffi==1.15.0\n charset-normalizer==2.0.12\n click==7.1.2\n cloudpickle==2.1.0\n configparser==3.7.4\n contextlib2==21.6.0\n contextvars==2.4\n cryptography==36.0.2\n cycler==0.11.0\n dataclasses==0.8\n decorator==4.4.2\n distro==1.7.0\n docker==5.0.3\n dotnetcore2==3.1.23\n Flask==1.0.3\n fusepy==3.0.1\n future==0.18.2\n google-api-core==2.8.1\n google-auth==2.8.0\n googleapis-common-protos==1.56.2\n gunicorn==20.1.0\n humanfriendly==10.0\n idna==3.3\n imageio==2.15.0\n imgaug==0.4.0\n immutables==0.18\n importlib-metadata==4.8.3\n inference-schema==1.3.0\n isodate==0.6.1\n itsdangerous==1.1.0\n jeepney==0.7.1\n Jinja2==3.0.3\n jmespath==0.10.0\n json-logging-py==0.2\n jsonpickle==2.2.0\n jsonschema==3.2.0\n kiwisolver==1.3.1\n knack==0.9.0\n MarkupSafe==2.0.1\n matplotlib==3.3.4\n msal==1.18.0\n msal-extensions==0.3.1\n msrest==0.6.21\n msrestazure==0.6.4\n ndg-httpsclient==0.5.1\n networkx==2.5.1\n numpy==1.19.5\n oauthlib==3.2.0\n opencensus==0.9.0\n opencensus-context==0.1.2\n opencensus-ext-azure==1.1.4\n opencv-python==4.6.0.66\n opencv-python-headless==4.6.0.66\n packaging==21.3\n paramiko==2.11.0\n pathspec==0.9.0\n Pillow==8.4.0\n pkginfo==1.8.3\n portalocker==2.4.0\n protobuf==3.19.4\n psutil==5.9.1\n pyarrow==3.0.0\n pyasn1==0.4.8\n pyasn1-modules==0.2.8\n pycocotools==2.0.4\n pycparser==2.21\n Pygments==2.12.0\n PyJWT==2.4.0\n PyNaCl==1.5.0\n pyOpenSSL==22.0.0\n pyparsing==3.0.7\n pyrsistent==0.18.0\n PySocks==1.7.1\n python-dateutil==2.8.2\n pytz==2022.1\n PyWavelets==1.1.1\n PyYAML==6.0\n requests==2.27.1\n requests-oauthlib==1.3.1\n rsa==4.8\n scikit-image==0.17.2\n scipy==1.5.4\n SecretStorage==3.3.2\n Shapely==1.8.2\n six==1.16.0\n tabulate==0.8.9\n tifffile==2020.9.3\n torch==1.10.1\n torchvision==0.11.2\n typing_extensions==4.1.1\n urllib3==1.26.9\n websocket-client==1.3.1\n Werkzeug==1.0.1\n wrapt==1.12.1\n zipp==3.6.0\n 2022-06-15T00:14:40,561943700+00:00 | gunicorn\/run | \n 2022-06-15T00:14:40,563774900+00:00 | gunicorn\/run | ###############################################\n 2022-06-15T00:14:40,569936200+00:00 | gunicorn\/run | AzureML Inference Server\n 2022-06-15T00:14:40,571682900+00:00 | gunicorn\/run | ###############################################\n 2022-06-15T00:14:40,573373400+00:00 | gunicorn\/run | \n 2022-06-15T00:14:40,580170100+00:00 | gunicorn\/run | \n 2022-06-15T00:14:40,584523000+00:00 | gunicorn\/run | Starting HTTP server\n 2022-06-15T00:14:40,590038900+00:00 | gunicorn\/run | \n Starting gunicorn 20.1.0\n Listening at: http:\/\/127.0.0.1:31311 (77)\n Using worker: sync\n worker timeout is set to 300\n Booting worker with pid: 125\n SPARK_HOME not set. Skipping PySpark Initialization.\n Initializing logger\n 2022-06-15 00:14:45,845 | root | INFO | Starting up app insights client\n logging socket was found. logging is available.\n logging socket was found. logging is available.\n 2022-06-15 00:14:45,846 | root | INFO | Starting up request id generator\n 2022-06-15 00:14:45,846 | root | INFO | Starting up app insight hooks\n 2022-06-15 00:14:45,847 | root | INFO | Invoking user's init function\n 2022-06-15 00:14:46,111 | root | INFO | Users's init has completed successfully\n 2022-06-15 00:14:46,115 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n 2022-06-15 00:14:46,116 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n 2022-06-15 00:14:46,121 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n 2022-06-15 00:14:49,997 | root | INFO | Swagger file not present\n 2022-06-15 00:14:49,998 | root | INFO | 404\n 127.0.0.1 - - [15\/Jun\/2022:00:14:49 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"Go-http-client\/1.1\"\n 2022-06-15 00:14:54,621 | root | INFO | Swagger file not present\n 2022-06-15 00:14:54,622 | root | INFO | 404\n 127.0.0.1 - - [15\/Jun\/2022:00:14:54 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"Go-http-client\/1.1\"\n 2022-06-15 00:14:54,974 | root | INFO | Scoring Timer is set to 60.0 seconds\n 2022-06-15 00:14:54,979 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n File \"\/var\/azureml-server\/routes.py\", line 294, in run_scoring\n     response, time_taken_ms = invoke_user_with_timer(service_input, request_headers)\n File \"\/var\/azureml-server\/routes.py\", line 341, in invoke_user_with_timer\n     result, time_taken_ms = capture_time_taken(user_main.run)(**params)\n File \"\/var\/azureml-server\/routes.py\", line 322, in timer\n     result = func(*args, **kwargs)\n File \"\/var\/azureml-app\/score2.py\", line 57, in run\n     img = Image.open(input_data).convert('RGB')\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/PIL\/Image.py\", line 2975, in open\n     fp = builtins.open(filename, \"rb\")\n FileNotFoundError: [Errno 2] No such file or directory: 'test_img.jpg'\n During handling of the above exception, another exception occurred:\n Traceback (most recent call last):\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1832, in full_dispatch_request\n     rv = self.dispatch_request()\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1818, in dispatch_request\n     return self.view_functions[rule.endpoint](**req.view_args)\n File \"\/var\/azureml-server\/routes.py\", line 270, in score_realtime\n     service_input, request.headers, request.environ.get(\"REQUEST_ID\", \"00000000-0000-0000-0000-000000000000\")\n File \"\/var\/azureml-server\/routes.py\", line 303, in run_scoring\n     raise RunFunctionException(str(exc))\n run_function_exception.RunFunctionException\n 2022-06-15 00:14:54,979 | root | INFO | 500\n 127.0.0.1 - - [15\/Jun\/2022:00:14:54 +0000] \"POST \/score HTTP\/1.0\" 500 51 \"-\" \"python-requests\/2.26.0\"\n 2022-06-15 00:14:54,988 | root | INFO | Scoring Timer is set to 60.0 seconds\n 2022-06-15 00:14:54,988 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n File \"\/var\/azureml-server\/routes.py\", line 294, in run_scoring\n     response, time_taken_ms = invoke_user_with_timer(service_input, request_headers)\n File \"\/var\/azureml-server\/routes.py\", line 341, in invoke_user_with_timer\n     result, time_taken_ms = capture_time_taken(user_main.run)(**params)\n File \"\/var\/azureml-server\/routes.py\", line 322, in timer\n     result = func(*args, **kwargs)\n File \"\/var\/azureml-app\/score2.py\", line 57, in run\n     img = Image.open(input_data).convert('RGB')\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/PIL\/Image.py\", line 2975, in open\n     fp = builtins.open(filename, \"rb\")\n FileNotFoundError: [Errno 2] No such file or directory: 'test_img.jpg'\n During handling of the above exception, another exception occurred:\n Traceback (most recent call last):\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1832, in full_dispatch_request\n     rv = self.dispatch_request()\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1818, in dispatch_request\n     return self.view_functions[rule.endpoint](**req.view_args)\n File \"\/var\/azureml-server\/routes.py\", line 270, in score_realtime\n     service_input, request.headers, request.environ.get(\"REQUEST_ID\", \"00000000-0000-0000-0000-000000000000\")\n File \"\/var\/azureml-server\/routes.py\", line 303, in run_scoring\n     raise RunFunctionException(str(exc))\n run_function_exception.RunFunctionException\n 2022-06-15 00:14:54,988 | root | INFO | 500\n 127.0.0.1 - - [15\/Jun\/2022:00:14:54 +0000] \"POST \/score HTTP\/1.0\" 500 51 \"-\" \"python-requests\/2.26.0\"\n 2022-06-15 00:14:56,004 | root | INFO | Scoring Timer is set to 60.0 seconds\n 2022-06-15 00:14:56,005 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n File \"\/var\/azureml-server\/routes.py\", line 294, in run_scoring\n     response, time_taken_ms = invoke_user_with_timer(service_input, request_headers)\n File \"\/var\/azureml-server\/routes.py\", line 341, in invoke_user_with_timer\n     result, time_taken_ms = capture_time_taken(user_main.run)(**params)\n File \"\/var\/azureml-server\/routes.py\", line 322, in timer\n     result = func(*args, **kwargs)\n File \"\/var\/azureml-app\/score2.py\", line 57, in run\n     img = Image.open(input_data).convert('RGB')\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/PIL\/Image.py\", line 2975, in open\n     fp = builtins.open(filename, \"rb\")\n FileNotFoundError: [Errno 2] No such file or directory: 'test_img.jpg'\n During handling of the above exception, another exception occurred:\n Traceback (most recent call last):\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1832, in full_dispatch_request\n     rv = self.dispatch_request()\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1818, in dispatch_request\n     return self.view_functions[rule.endpoint](**req.view_args)\n File \"\/var\/azureml-server\/routes.py\", line 270, in score_realtime\n     service_input, request.headers, request.environ.get(\"REQUEST_ID\", \"00000000-0000-0000-0000-000000000000\")\n File \"\/var\/azureml-server\/routes.py\", line 303, in run_scoring\n     raise RunFunctionException(str(exc))\n run_function_exception.RunFunctionException\n 2022-06-15 00:14:56,005 | root | INFO | 500\n 127.0.0.1 - - [15\/Jun\/2022:00:14:56 +0000] \"POST \/score HTTP\/1.0\" 500 51 \"-\" \"python-requests\/2.26.0\"\n 2022-06-15 00:14:58,028 | root | INFO | Scoring Timer is set to 60.0 seconds\n 2022-06-15 00:14:58,029 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n File \"\/var\/azureml-server\/routes.py\", line 294, in run_scoring\n     response, time_taken_ms = invoke_user_with_timer(service_input, request_headers)\n File \"\/var\/azureml-server\/routes.py\", line 341, in invoke_user_with_timer\n     result, time_taken_ms = capture_time_taken(user_main.run)(**params)\n File \"\/var\/azureml-server\/routes.py\", line 322, in timer\n     result = func(*args, **kwargs)\n File \"\/var\/azureml-app\/score2.py\", line 57, in run\n     img = Image.open(input_data).convert('RGB')\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/PIL\/Image.py\", line 2975, in open\n     fp = builtins.open(filename, \"rb\")\n FileNotFoundError: [Errno 2] No such file or directory: 'test_img.jpg'\n During handling of the above exception, another exception occurred:\n Traceback (most recent call last):\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1832, in full_dispatch_request\n     rv = self.dispatch_request()\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1818, in dispatch_request\n     return self.view_functions[rule.endpoint](**req.view_args)\n File \"\/var\/azureml-server\/routes.py\", line 270, in score_realtime\n     service_input, request.headers, request.environ.get(\"REQUEST_ID\", \"00000000-0000-0000-0000-000000000000\")\n File \"\/var\/azureml-server\/routes.py\", line 303, in run_scoring\n     raise RunFunctionException(str(exc))\n run_function_exception.RunFunctionException\n 2022-06-15 00:14:58,030 | root | INFO | 500\n 127.0.0.1 - - [15\/Jun\/2022:00:14:58 +0000] \"POST \/score HTTP\/1.0\" 500 51 \"-\" \"python-requests\/2.26.0\"\n Exception in worker process\n Traceback (most recent call last):\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/gunicorn\/arbiter.py\", line 589, in spawn_worker\n     worker.init_process()\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py\", line 142, in init_process\n     self.run()\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py\", line 125, in run\n     self.run_for_one(timeout)\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py\", line 84, in run_for_one\n     self.wait(timeout)\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py\", line 36, in wait\n     ret = select.select(self.wait_fds, [], [], timeout)\n File \"\/var\/azureml-server\/routes.py\", line 159, in alarm_handler\n     raise TimeoutException(error_message)\n timeout_exception.TimeoutException\n Worker exiting (pid: 125)\n worker timeout is set to 300\n Booting worker with pid: 157\n SPARK_HOME not set. Skipping PySpark Initialization.\n Initializing logger\n 2022-06-15 00:16:03,376 | root | INFO | Starting up app insights client\n logging socket was found. logging is available.\n logging socket was found. logging is available.\n 2022-06-15 00:16:03,376 | root | INFO | Starting up request id generator\n 2022-06-15 00:16:03,377 | root | INFO | Starting up app insight hooks\n 2022-06-15 00:16:03,377 | root | INFO | Invoking user's init function\n 2022-06-15 00:16:03,624 | root | INFO | Users's init has completed successfully\n 2022-06-15 00:16:03,626 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n 2022-06-15 00:16:03,626 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n 2022-06-15 00:16:03,633 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n 127.0.0.1 - - [15\/Jun\/2022:00:20:12 +0000] \"POST \/ HTTP\/1.0\" 405 178 \"-\" \"Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/81.0.4044.129 Safari\/537.36\"\n 127.0.0.1 - - [15\/Jun\/2022:00:20:13 +0000] \"GET \/.env HTTP\/1.0\" 404 232 \"-\" \"Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/81.0.4044.129 Safari\/537.36\"\n 2022-06-15 00:35:48,752 | root | INFO | Swagger file not present\n 2022-06-15 00:35:48,753 | root | INFO | 404\n 127.0.0.1 - - [15\/Jun\/2022:00:35:48 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"Go-http-client\/1.1\"\n\n\n\nresult = service.run(input_data=\"test_img.jpg\")\nprint(result)\n\n Received bad response from service. More information can be found by calling `.get_logs()` on the webservice object.\n Response Code: 502\n Headers: {'Connection': 'keep-alive', 'Content-Length': '51', 'Content-Type': 'text\/html; charset=utf-8', 'Date': 'Wed, 15 Jun 2022 00:50:21 GMT', 'Server': 'nginx\/1.14.0 (Ubuntu)', 'X-Ms-Request-Id': 'dacf03b8-adb6-4cbf-8cea-d0c4086712f4', 'X-Ms-Run-Function-Failed': 'True'}\n Content: b\"[Errno 2] No such file or directory: 'test_img.jpg'\"\n ---------------------------------------------------------------------------\n WebserviceException                       Traceback (most recent call last)\n <ipython-input-18-c76911546a4f> in <module>\n ----> 1 result = service.run(input_data=\"test_img.jpg\")\n     2 print(result)\n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/webservice\/aci.py in run(self, input_data)\n     403                                       'Headers: {}\\n'\n     404                                       'Content: {}'.format(resp.status_code, resp.headers, resp.content),\n --> 405                                       logger=module_logger)\n     406 \n     407     def update(self, image=None, tags=None, properties=None, description=None, auth_enabled=None, ssl_enabled=None,\n WebserviceException: WebserviceException:\n     Message: Received bad response from service. More information can be found by calling `.get_logs()` on the webservice object.\n Response Code: 502\n Headers: {'Connection': 'keep-alive', 'Content-Length': '51', 'Content-Type': 'text\/html; charset=utf-8', 'Date': 'Wed, 15 Jun 2022 00:50:21 GMT', 'Server': 'nginx\/1.14.0 (Ubuntu)', 'X-Ms-Request-Id': 'dacf03b8-adb6-4cbf-8cea-d0c4086712f4', 'X-Ms-Run-Function-Failed': 'True'}\n Content: b\"[Errno 2] No such file or directory: 'test_img.jpg'\"\n     InnerException None\n     ErrorResponse \n {\n     \"error\": {\n         \"message\": \"Received bad response from service. More information can be found by calling `.get_logs()` on the webservice object.\\nResponse Code: 502\\nHeaders: {'Connection': 'keep-alive', 'Content-Length': '51', 'Content-Type': 'text\/html; charset=utf-8', 'Date': 'Wed, 15 Jun 2022 00:50:21 GMT', 'Server': 'nginx\/1.14.0 (Ubuntu)', 'X-Ms-Request-Id': 'dacf03b8-adb6-4cbf-8cea-d0c4086712f4', 'X-Ms-Run-Function-Failed': 'True'}\\nContent: b\\\"[Errno 2] No such file or directory: 'test_img.jpg'\\\"\"\n     }\n }\n\n\n\nWhat kind of response is needed? I have test_img.jpg file in the same directory.\n\nAny help is appreciated.\n\nThank you.",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How can I open the automated ML explanation in Jupyter notebooks?",
        "Question_creation_time":1614091964233,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/285089\/how-can-i-open-the-automated-ml-explanation-in-jup.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"What-If and Individual Conditional Expectation (ICE) plots are not supported in Azure Machine Learning studio under the Explanations tab since the uploaded explanation needs an active compute to recalculate predictions and probabilities of perturbed features. It is currently supported in Jupyter notebooks when run as a widget using the SDK. How can I open the automated ML explanation in Jupyter notebooks?",
        "Answers":[
            {
                "Answer_creation_time":"2021-03-01T15:58:38.55Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello Cagatay,\n\nIn jupyter notebook for AutoML models, you can download the trained model, then compute explanations locally and visualize the explanation results using ExplanationDashboard from interpret-community. Sample code below:-\n\n\n\n\n best_run, fitted_model = remote_run.get_output()\n     \n from azureml.train.automl.runtime.automl_explain_utilities import AutoMLExplainerSetupClass, automl_setup_model_explanations\n automl_explainer_setup_obj = automl_setup_model_explanations(fitted_model, X=X_train,\n                                                                                                                          X_test=X_test, y=y_train,\n                                                                                                                          task='regression')\n     \n from interpret.ext.glassbox import LGBMExplainableModel\n from azureml.interpret.mimic_wrapper import MimicWrapper\n explainer = MimicWrapper(ws, automl_explainer_setup_obj.automl_estimator, LGBMExplainableModel,\n                          init_dataset=automl_explainer_setup_obj.X_transform, run=best_run,\n                          features=automl_explainer_setup_obj.engineered_feature_names,\n                          feature_maps=[automl_explainer_setup_obj.feature_map],\n                          classes=automl_explainer_setup_obj.classes)\n     \n pip install interpret-community[visualization]\n     \n engineered_explanations = explainer.explain(['local', 'global'], eval_dataset=automl_explainer_setup_obj.X_test_transform)\n print(engineered_explanations.get_feature_importance_dict()),\n from interpret_community.widget import ExplanationDashboard\n ExplanationDashboard(engineered_explanations, automl_explainer_setup_obj.automl_estimator, datasetX=automl_explainer_setup_obj.X_test_transform)\n     \n raw_explanations = explainer.explain(['local', 'global'], get_raw=True, \n                                      raw_feature_names=automl_explainer_setup_obj.raw_feature_names,\n                                      eval_dataset=automl_explainer_setup_obj.X_test_transform)\n print(raw_explanations.get_feature_importance_dict()),\n from interpret_community.widget import ExplanationDashboard\n ExplanationDashboard(raw_explanations, automl_explainer_setup_obj.automl_pipeline, datasetX=automl_explainer_setup_obj.X_test_raw)\n\n\n\nThe code sample repo please refer to: https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/explain-model\/azure-integration\/scoring-time\/train-explain-model-locally-and-deploy.ipynb\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":5.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"i cannot make labeling project enabled",
        "Question_creation_time":1629489536580,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/522604\/i-cannot-make-labeling-project-enabled.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"I have a labeling project.\nIt is now stopped.\nWhen I click \"Resume\", something happens on for several hours, then a message that an error \"Failed\" has occurred and that's it.\nthe project remains unavailable.\nNo changes have been made to it since the stop.\n\nWhat is the reason for the error? Can I get around it somehow? or somehow copy this project so as not to lose the markup that has already been done in it?",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"ML Model data output",
        "Question_creation_time":1615488109277,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/310400\/ml-model-data-output.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-blob-storage"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\nI was running several time series model using Azure automated machine learning, I didn't write any code. After the running was completed, there are some datasets stored in Azure Blob Storage. But I don't know if these files include the prediction results or not because I can't find a right software to open it . I don't need to deploy the model. I just need a plain spreadsheet which contains the result. Why it is so hard? The attachment is the screenshot of the fiels stored in Blob of the model I ran? What do those files mean?\nAnd I just check the running outcome, it shows there is no output dataset. I was so confused! Do I need to change something when I set the model running?\n][1]",
        "Answers":[
            {
                "Answer_creation_time":"2021-03-12T08:00:46.453Z",
                "Answer_upvote_count":0,
                "Answer_body":"@MarcusGonzalez-1907 I think you might be interested to check your models explainability which tells more about the results of your run and performance of your model. Since you are not planning to deploy your model as a service running explain for all the models will help you choose the best model that can be later used for deployment. The steps to run explain are mentioned in this document.\n\nThe files you might be referring to are files that might have been used for processing your data based on the input settings or configuration of your automl run. The files might be different between child runs as these child runs are basically run against an algorithm and different algorithms produce different set of files. Usually, the end user need not refer these files as automl gets the best model for you from all the child runs which is deployed as a web service on ACI or AKS.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML - Notebook - Jupyter Kernel Error - No Kernel connection",
        "Question_creation_time":1612145607873,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/252893\/azure-ml-notebook-jupyter-kernel-error-no-kernel-c-1.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-cyclecloud"
        ],
        "Question_upvote_count":6.0,
        "Question_view_count":null,
        "Question_answer_count":8,
        "Question_has_accepted_answer":false,
        "Question_body":"In ML Studio, when I create a notebook the top of my screen says \"Jupyter kernel error\" in red. I have a compute instance running (it's green), but it also says \"No Kernel connected\".\n\nTo correct this matter, can you please provide explicit, step by step instructions on how to review. Screen shots help too.",
        "Answers":[
            {
                "Answer_creation_time":"2021-06-11T19:39:03.553Z",
                "Answer_upvote_count":0,
                "Answer_body":"i am having exactly same issue with \"No kernel connected\", have you guys resolved this yet? how?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-08-06T16:01:38.527Z",
                "Answer_upvote_count":0,
                "Answer_body":"Has anyone resolved this issue? Can someone please post the solution.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-15T20:18:50.39Z",
                "Answer_upvote_count":0,
                "Answer_body":"Part of our team had this issue this week, the root cause for us was some language-packs for pt-br not loading correctly, once the affected team members changed the page\/browser language to en-us the problem was solved.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-27T14:04:50.417Z",
                "Answer_upvote_count":0,
                "Answer_body":"I had this same issue and resolved it by stopping and restarting the compute. This may be overly simplistic as I am a learner too.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-12-29T19:04:08.963Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi! I got this problem right now. I don't know what happened, but I've been working with Azure ML for 6 months already and it's the first time I get this kind of error.\nDid you found the solution already? @danielgo-9074 I've got page\/browser language set to en-us ;\/",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-01-18T06:11:45.067Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi I also have the same problem. My compute is running but I cannot connect to any of the kernel. It keeps saying that the kernel not found or was deleted.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-01-26T12:38:07.16Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nI have the same issue (eastus location):",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-02-24T19:52:41.67Z",
                "Answer_upvote_count":1,
                "Answer_body":"i have been facing the same issue my compute was running still there was no kernel, i resolved it after a long search. It seemed my firewall was preventing me from doing that.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":15.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Separate data in data explorer and use as datastore",
        "Question_creation_time":1619036349177,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/366532\/separate-data-in-data-explorer-and-use-as-datastor.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-event-hubs",
            "azure-iot-central",
            "azure-data-explorer"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello,\n\nWe are sending data from IoT Central to Event Hubs and then to Data Explorer, with the hopes of then sending the data to Azure Machine Learning.\n\nIn order to send data from Event Hubs to Data Explorer it needs a data ingestion into a table on data explorer.\n\nFor this data ingestion, it needs a json mapping.\n\nWe could ingest the data, but the message from the iot central data goes to event hubs that goes to data explorer carries the telemetry data as a dynamic type (a json inside a json).\n\n (\"telemetry\":{\"Temp:\"37\",\"Vol\":\"97\"})\n\n\n\n\nWe want to separate the telemetry data in different columns.\n\nSo Temp will have one column and Vol another.\n\nI am wondering how that can be done?\n\nAnd additionally, since we would like to send the data to ML, can data explorer be used as a datastore in ML?\n\nThanks!!",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-22T08:36:44.29Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hello @yjay-4307,\n\nYou can use parse operator - Evaluates a string expression and parses its value into one or more calculated columns. The calculated columns will have nulls, for unsuccessfully parsed strings.\n\nFor more details, refer SO thread addressing similar issue.\n\nUnfortuantely, Azure Data Explorer is not a supported storage solution with Azure Machine Learning.\n\nDatastores currently support storing connection information to the storage services listed in the following matrix.\n\nFor unsupported storage solutions, and to save data egress cost during ML experiments, move your data to a supported Azure storage solution.\n\nReference: Connect to storage services on Azure - Azure Machine Learning.\n\nHope this helps. Do let us know if you any further queries.\n\nPlease don\u2019t forget to Accept Answer and Up-Vote wherever the information provided helps you, this can be beneficial to other community members.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Models registered with AML CLI cause ACI deployments to fail",
        "Question_creation_time":1634746520717,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/597710\/models-registered-with-aml-cli-cause-aci-deploymen.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"We were registering a local file ts_scalar.pickle as a model using AML CLI's create az model create -n test-model -l .\/ts_scalar.pickle ...\nThis registered model test-model works fine when deployed to a LocalWebService, but does not work for a AciWebService.\nWe either get a timeout during the deployment (does not reach stage where containers start running) or this error:\n\n Traceback (most recent call last):\n   File \".\/download.py\", line 353, in <module>\n     init_container_assets(args.config_json, args.conn_string, args.container, args.appinsights_key, args.config_folder)\n   File \".\/download.py\", line 327, in init_container_assets\n     downloader.download(config_file_content)\n   File \".\/download.py\", line 128, in download\n     self.download_artifact(blob_path, local_path, unpack_type)\n   File \".\/download.py\", line 92, in download_artifact\n     file_path=local_path)\n   File \"\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/blob\/baseblobservice.py\", line 2014, in get_blob_to_path\n     cpk=cpk)\n   File \"\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/blob\/baseblobservice.py\", line 2193, in get_blob_to_stream\n     raise ex\n   File \"\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/blob\/baseblobservice.py\", line 2160, in get_blob_to_stream\n     cpk=cpk)\n   File \"\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/blob\/baseblobservice.py\", line 1887, in _get_blob\n     operation_context=_context)\n   File \"\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/common\/storageclient.py\", line 446, in _perform_request\n     raise ex\n   File \"\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/common\/storageclient.py\", line 374, in _perform_request\n     raise ex\n   File \"\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/common\/storageclient.py\", line 360, in _perform_request\n     HTTPError(response.status, response.message, response.headers, response.body))\n   File \"\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/common\/_error.py\", line 115, in _http_error_handler\n     raise ex\n azure.common.AzureMissingResourceHttpError: The specified blob does not exist. ErrorCode: BlobNotFound\n <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>BlobNotFound<\/Code><Message>The specified blob does not exist.\n RequestId:59b52a82-301e-005a-51c8-c52ce4000000\n Time:2021-10-20T15:40:04.2703282Z<\/Message><\/Error>\n\n\n\nHowever if we register the model through AML's UI model registration, both kinds of deployments are successful.\n\nIs there an issue with using the CLI to register models for ACI deployment?",
        "Answers":[
            {
                "Answer_creation_time":"2022-08-26T06:56:37.237Z",
                "Answer_upvote_count":0,
                "Answer_body":"Any Update on this? I am having the same issue?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure AutoML via User Interface",
        "Question_creation_time":1621023165310,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/396020\/azure-automl-via-user-interface.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"When we use Azure AutoML via User Interface, what data do they use to calculate the metrics?\nDo they train test split? If so, the metrics return from the test data?\nOr they use the whole data to validate the models. Thus, the metrics are from cross-validation.\nIf they use the whole data set to train, I should do the train-test split and only upload a train data set (I should clean data first). Then deploy the models with the test data to see how accurate the model is.\nIf it is that case, this function is such a useless function.\nI can use Python SDK directly.\nPlease help me to clarify if it is that case. The metrics are only from cross-validation.",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-17T11:18:34.47Z",
                "Answer_upvote_count":0,
                "Answer_body":"@TheoSun-0585 Thanks for the question. For validation, you have the Validation metrics available when training any AutoML models.\nAbout TEST METRICS, that\u2019s something else.\nYes, we\u2019re almost going to release in PRIVATE PREVIEW (in the upcoming weeks) for a way in AutoML (using Python SDK and alternatively also the UI) to provide a TEST DATASET (new data) so you will easily test the model and get TEST METRICS without needing to deploy the model or test it by code in Python.\n\nNote that you can today TEST any AutoML model today in a Python Jupyter notebook but instantiating the .pkl model and then making predictions and calculating the test metrics in your notebook, without needing to deploy the model (using REST API to try it): Example notebook with \u201cyour\u201d TEST METRICS: Easy-AutoML-MLOps\/automl-remote-compute-run-safe-driver-classifier.ipynb at master \u00b7 CESARDELATORRE\/Easy-AutoML-MLOps (github.com) (Check section \u201cCalculate the ROC AUC with probabilities vs. the Test Dataset\u201d).\n\nBut with the PRIVATE PREVIEW of TEST DATASET SUPPORT, you\u2019ll be able to provide the TEST DATASET when creating the experiment, too. Or test an already trained model on demand in the UI or SDK, making it simpler.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azureml compute instance spark dependencies missing",
        "Question_creation_time":1651594378717,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/835171\/azureml-compute-instance-spark-dependencies-missin.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Currently, I'm trying to use the AzureML SDK's, dataset.to_spark_dataframe() method, and facing a weird error(see below).\nThe ClassNotFoundExceptions suggest that some Jars might be missing from the base environment's Spark classpath. Some sources suggest hadoop-azure concretely: https:\/\/community.cloudera.com\/t5\/Support-Questions\/Class-org-apache-hadoop-fs-azure-NativeAzureFileSystem-not\/m-p\/270675)\n\nIs there a way to add these dependencies to the environment?\n\nError:\nAzureMLException: AzureMLException:\nMessage: Execution failed in operation 'to_spark_dataframe' for Dataset(id='54df6c30-fb46-4c75-a084-d10c17cd3795', name='temperatures_parq', version=1, error_code=None, exception_type=Py4JJavaError)\nInnerException An error occurred while calling o39.getFiles.\n: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure not found\nat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2667)\nat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3431)\nat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\nat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\nat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\nat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\nat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\nat com.microsoft.dprep.io.FileSystemStreamInfoHandler.globStatus(FileSystemStreamInfoHandler.scala:46)\nat com.microsoft.dprep.io.StreamInfoFileSystem.globStatus(StreamInfoFileSystem.scala:206)\nat com.microsoft.dprep.io.StreamInfoFileSystem.globStatus(StreamInfoFileSystem.scala:201)\nat com.microsoft.dprep.execution.Storage$.expandHdfsPath(Storage.scala:44)\nat com.microsoft.dprep.execution.executors.GetFilesExecutor$.$anonfun$getFiles$1(GetFilesExecutor.scala:18)\nat scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)\nat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\nat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\nat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\nat scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)\nat scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)\nat scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)\nat com.microsoft.dprep.execution.executors.GetFilesExecutor$.getFiles(GetFilesExecutor.scala:12)\nat com.microsoft.dprep.execution.LariatDataset$.getFiles(LariatDataset.scala:32)\nat com.microsoft.dprep.execution.PySparkExecutor.getFiles(PySparkExecutor.scala:201)\nat java.base\/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nat java.base\/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nat java.base\/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat java.base\/java.lang.reflect.Method.invoke(Method.java:566)\nat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\nat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\nat py4j.Gateway.invoke(Gateway.java:282)\nat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\nat py4j.commands.CallCommand.execute(CallCommand.java:79)\nat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\nat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\nat java.base\/java.lang.Thread.run(Thread.java:829)\nCaused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure not found\nat org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2571)\nat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2665)",
        "Answers":[
            {
                "Answer_creation_time":"2022-05-04T09:56:50.2Z",
                "Answer_upvote_count":0,
                "Answer_body":"@KutiKreszacsMatyasRBROPJDT-0321 I think dataset.to_spark_dataframe() is now deprecated since dataset class is categorized into two classes tabular and file. Deprecation notice about the changes are available here. Could you try using the latest SDK with TabularDataset class?\n\nExample:\n\n from azureml.core import Dataset\n dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, 'train-dataset\/tabular\/iris.csv')])\n    \n # preview the first 3 rows of the dataset\n dataset.take(3).to_spark_dataframe()",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How do I get started predictive Maintanance using Machine Learning?",
        "Question_creation_time":1617360731433,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/342399\/how-do-i-get-started-predictive-maintanance-using.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-data-science-vm"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Give me a brief description of the predictive maintenance using machine learning.",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-02T17:29:51.977Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, if your question is with regards to Azure ML, here's our official documentation.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Long Running Experiment",
        "Question_creation_time":1635794626850,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/611813\/long-running-experiment.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"I am running a Machine Learning experiment in Azure Machine Learning Studio (not classic version). The total time of each step in the experiment is 7.5 min, however the overall execution time of the run was 20.5 min. Could someone please explain why there is such a large discrepancy between the total time the experiment took to run compared to the total of each step and what can be done to improve performance.\n\nThanks for your help.",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How can I access a FileDataset without filling local disk?",
        "Question_creation_time":1628529752433,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/506820\/how-can-i-access-a-filedataset-without-filling-loc.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello!\n\nI'm setting up a pipeline for machine learning. Reading the docs I understood that when I pass my FileDataset as_mount it is mounted, similar to mounting an external drive. However, three hours into my training, my pipeline crashed, out of storage. It seems that as_mount actually is downloading per file, rather than the entire Dataset, but still uses local disk space. Is this correct? If so, how can I train on a FileDataset that is too large for any of the available compute options?\n\nDavid",
        "Answers":[
            {
                "Answer_creation_time":"2021-08-10T12:31:26.553Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for reaching out. When you mount, only the data files used by your script are loaded at the time of processing. When you download, all files referenced by the dataset will be downloaded to the compute target. If your data size exceeds the compute disk size, we recommend mounting (which reads only a subset of the data). Based on your post, you may need to use a larger compute instance to handle your workload. Please review mount vs download documentation. Hope this helps.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Use the value of a PipelineParameter (passed from DataFactory) in a blob path for an OutputFileDatasetConfig object (in an ML pipeline)",
        "Question_creation_time":1648036709603,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/784006\/use-the-value-of-a-pipelineparameter-passed-from-d.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-data-factory",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,\n\nIs it possible to use a PipelineParameter (defined in a DataFactory 'Machine Learning Execute Pipeline' activity) during the creation of a OutputFileDatasetConfig object in said Machine Learning pipeline?\n\nMy DataFactory pipeline runs on a schedule (via a trigger) and executes an Azure ML pipeline which does data preparation and model training.\nThe trigger start date is passed as a parameter 'date_time' to the ML pipeline.\n\nIn my ML pipeline, I want to save the model artifacts (trained in a PythonScriptStep) to a blob path (default_datastore + 'output_model\/{date_time}') which contains the value of the 'date_time' parameter. But I can't figure out a way to use the value of 'date_time' during the creation of the OutputFileDatasetConfig object (maybe there is a simple way to save model artifacts than to use a OutputFileDatasetConfig object?).\n\nAs a temporary hack, I am using a variable 'today_date' in my ML pipeline definition which contains today's date, and I use this variable to build the destination path of OutputFileDatasetConfig.\nBut the ideal solution would be to get the actual date directly from the DataFactory trigger parameter.\nThis is how I do now in my ML pipeline (not ideal):\n\n import datetime\n today_date = datetime.date.today().strftime('%Y%m%d')\n model_output_path = (def_data_store, f\"output_model\/{today_date}\")\n output_config = OutputFileDatasetConfig(destination = model_output_path)\n\n\n\nThis is what I tried in order to get the value of PipelineParameter, but it didn't work:\n\n pipeline_parameter = PipelineParameter(name=\"date_time\", default_value=today_date)\n model_output_path = (def_data_store, f\"output_model\/{pipeline_parameter}\")\n output_config = OutputFileDatasetConfig(destination = model_output_path)\n\n\n\nIt seems the only way to get the value of the PipelineParameter is through an argument inside a PythonScriptStep.\nI don't think I can create the OutputFileDatasetConfig object INSIDE the PythonScriptStep.\nIs there any other way to easily save model artifacts to a specific blob path which contains the value of a PipelineParameter?",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-28T07:56:39.81Z",
                "Answer_upvote_count":0,
                "Answer_body":"@ShaikMaheer-MSFT\n\nHello and thanks for your answer.\n\nI solved my problem and I will explain how.\n\nWhat I was trying to do was to get the value of a PipelineParameter (containing the date at which the pipeline was triggered by Data Factory) in my Azure ML pipeline definition script in order to use it in the destination name of my OutputFileDatasetConfig object. Basically I wanted the destination name to be something like 'output_model\/20220328' where '20220328' is the value of the PipelineParameter.\n\nBut it seems impossible to read the value of a PipelineParameter outside of a PythonScriptStep.\n\nWhat I did to solve this is to create my OutputFileDatasetConfig first without specifying the full destination path.\nI specify only 'output_model' in the path. Then I get a reference to the PipelineParameter (at this point I still don't know its value).\n\n model_output_config = OutputFileDatasetConfig(destination = (def_data_store, 'output_model'))\n output_model_date = PipelineParameter(name=\"date_time\", default_value=\"20220328\")\n\n\n\nThen I pass both references as arguments to my PythonScriptStep.\n\n train = PythonScriptStep(\n     name=\"Train model\",\n     script_name=\"train.py\",\n     source_directory=\".\/\",\n     arguments=[\n         \"--output-model-dir\", model_output_config ,\n         \"--output-model-date\", output_model_date\n     ],\n     compute_target=compute_target,\n     runconfig=aml_run_config\n )\n\n\n\nAnd finally in my training script I get the actual value of the PipelineParameter and I just concatenate both parameters to create the full path:\n\n parser.add_argument(\"--output-model-dir\", type=str, dest=\"output_model_dir\", default=\"output_model\", help=\"Directory to store trained output models and artifacts\")\n parser.add_argument(\"--output-model-date\", type=str, dest=\"output_model_date\", default=\"20220328\", help=\"Date to use in the name of the output model folder\")\n output_model_dir = args.output_model_dir\n output_model_date = args.output_model_date\n full_output_model_dir = os.path.join(output_model_dir, output_model_date)\n\n\n\nAnd now I can save directly my model artifacts to 'full_output_model_dir'.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":15.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Leave-one-group-out cross-validation in Azure AutoML",
        "Question_creation_time":1618488817010,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/358763\/leave-one-group-out-cross-validation-in-azure-auto.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I have a dataset where each row is a data sample, and there is a a column indicating a group this sample came from. So, each group has several data points, and each one is a row in the dataframe. I would like to run the cross-validation so that at each fold, the data points from one group are used as the validation set, and the data points from other groups as the training test. Is this currently somehow possible in Azure AutoML ?",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-15T17:30:05.537Z",
                "Answer_upvote_count":0,
                "Answer_body":"Yes, you can specify custom cross-validation data folds based on columns. More details are provided in the following document. Hope this helps.\n\nExample:\n\n automl_config = AutoMLConfig(compute_target = aml_remote_compute,\n                              task = 'classification',\n                              primary_metric = 'AUC_weighted',\n                              training_data = dataset,\n                              label_column_name = 'y',\n                              cv_split_column_names = ['cv1', 'cv2']\n                             )",
                "Answer_comment_count":5,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Import issue with azureml-train-automl-runtime package",
        "Question_creation_time":1669689516027,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1107805\/import-issue-with-azureml-train-automl-runtime-pac.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"I am trying to import azureml-train-automl-runtime to do explanations from azure automl pipeline following the tutorial in the link https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/v1\/how-to-machine-learning-interpretability-automl\n\nBut I am getting the below error\n\n Exception ignored in: <function _Win32Helper.del at 0x0000021ECA3AD430> Traceback (most recent call last): File \"C:\\Anaconda3\\envs\\check_win32_error\\lib\\site-packages\\azureml\\automl\\runtime\\shared\\win32_helper.py\", line 246, in del TypeError: catching classes that do not inherit from BaseException is not allowed\n\n\n\n\nError Screenshot:\n\n\n\n\n\nI asked this question in stackoverflow but did not get valid answer,\nplease refer to the stackoverflow link below:\nhttps:\/\/stackoverflow.com\/questions\/74160617\/baseexception-when-trying-to-import-azureml-train-automl-runtime-in-windows-10",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Excel en Microsoft Azure",
        "Question_creation_time":1614968855700,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/301247\/excel-en-microsoft-azure.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Hola a todos, perdon quiza sea muy basica mi pregunta, no se como importar un excel como Dataset. Solo puedo importar CSV, etc. Muchas gracias",
        "Answers":[
            {
                "Answer_creation_time":"2021-03-05T19:58:39.96Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for reaching out. Excel is not a supported format for Azure ML Tabular datasets. I recommend that you convert your excel file to .csv file (save as .csv) before importing to Azure ML. Hope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-03-05T19:47:20.593Z",
                "Answer_upvote_count":0,
                "Answer_body":"QnA forums are currently English only. I'd try asking for help over here in dedicated forums.\nhttps:\/\/answers.microsoft.com\/es-es\/msoffice\/forum\/msoffice_excel\n\n--please don't forget to Accept as answer if the reply is helpful--",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"New Azure Machine Learning & Excel",
        "Question_creation_time":1651222482640,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/831512\/new-azure-machine-learning-amp-excel.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi All\n\nI have been working with Azure Machine Learning Studio (Classic) and have always found its integration with Excel super mega useful.\n\nAll I had to do was to get the URI and the API_Key of my web service and paste them on the Azure Machine Learning Add-In, that I had downloaded. Easy and useful.\n\nHowever, with the new Azure Machine Learning studio that does not seem possible any more.\n\nUnder the new Azure Machine Learning studio when I deploy a model I get a REST endpoint and that's it? !? I cannot find anywhere the API_key for my web service. I cannot even find a web service section as such.\n\nHow do I get the API_Key for the web service I need?\n\nIf I get the API_Key could I use it on the Excel Azure Machine Learning add-in. It looks as if this is no longer an option and we need to start using Power BI instead.\n\nI have read this interesting post where someone mentions a work around that consist of creating an Excel macro. Is this the best option? https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/236781\/consume-scoreing-api-in-excel.html\n\n\n\n\nThank you",
        "Answers":[
            {
                "Answer_creation_time":"2022-04-30T11:48:21.697Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for reaching out. The new AzureML integration with Excel isn't supported at this time. More details are provided on this thread. The alternative approach would be to use a Client or PowerBI to consume the model. For future reference, you can find your webservice endpoint and keys under Studio > Endpoints > Endpoint > Consume.\n\n\n\n\n\n--please don't forget to Accept Answer if the reply is helpful. Thanks.--",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML Studio Quotas for Assisted Labeling and Training Object Detection Model",
        "Question_creation_time":1653585502077,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/865733\/azure-ml-studio-quotas-for-assited-labeling-and-tr.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"In an Azure ML Studio labeling project, I have tried to enable Assisted Labeling. I get the error message \"Error: There is insufficient quota to create a gpu compute target. You can request more quota and create a custom compute to enable ML assisted labeling.\"\n\nI also get a similar error message when I try to train an object detection model, \"\u201cSTANDARD_D2AS_V4 is not supported for image tasks. Please choose a VM type that is in the NC-family or the ND-family.\"\n\nI requested and was granted \"Standard NC Family Cluster Dedicated vCPUs\/GPUs. These show up in my quota, but if I go to create a compute target and select GPU, I get a message saying: \"You do not have enough quota for the following VM sizes.\" followed by a list of all the VMs that it says aren't in my quota including the NC family VMs.\n\nAnd I still get the same two error messages saying I don't have enough quota for either Assisted Labeling or training an object detection model.\n\nDoes anyone know what I need to do to get these two services to work?\n\nThanks.",
        "Answers":[
            {
                "Answer_creation_time":"2022-05-31T09:04:55.187Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi there\n\nI have the same quota issue when I just created my project. I contacted the support team and they solved issue for me. You should try it too.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-31T11:46:07.927Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thanks Alexandre,\n\nDo you have any info on how they solved this issue?\n\nI opened a case a week or so ago. The initial support team thought they were the wrong team, and referred me to the Global Capacity team. The global capacity team has been slow to respond, most likely due to the Memorial day weekend.\n\nHopefully they will get back to me soon.\n\nBut I think this may be more of an issue with Azure ML Studio rather than the quota team.\n\nAny thoughts?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-06T22:22:29.86Z",
                "Answer_upvote_count":0,
                "Answer_body":"@YutongTie-MSFT this continues unresolved. TrackingID#2205240040008434",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Collaborate on Azure Machine Learning Project",
        "Question_creation_time":1596973683450,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/62694\/collaborate-on-azure-machine-learning-project.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"I just recently became a Microsoft Certified Azure Data Scientist Associate. So I am looking for data scientist novices to join me practice on open datasets on kaggle to build machine learning models and do predictions using Azure ML. We will start with Titanic competition. If interested please visit my github link: https:\/\/github.com\/ivombi\/Titanic-Machine-Learning-from-Disaster or send a request on LinkedIn using my full name: Kubam Ivo Mbi.\nThanks",
        "Answers":[
            {
                "Answer_creation_time":"2020-08-10T07:33:44.81Z",
                "Answer_upvote_count":0,
                "Answer_body":"anonymous user Thanks, Here are the Azure machine learning notebook samples that you can participate and contribute on the same.\n\nOther links for ML competitions i.e., kaggle and driven data to work with the same. can you please add more details about the use-case that you are trying. Are you looking for data scientist resources, If yes below links will be helpful to work with the teams.\n\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\n\nhttps:\/\/www.drivendata.org\/competitions\/\nhttps:\/\/www.kaggle.com\/",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-05T01:03:19.383Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, I am very interested in collaborating on this, could you reach out to me via email at piusanalyticsandbeyond@gmail.com?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":2.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Datadrift in Azure ML SDK v2",
        "Question_creation_time":1657283475557,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/919651\/datadrift-in-azure-ml-sdk-v2.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I can't see a data drift module anywhere in v2 of the Azure ML Python SDK. Is this missing or what's the deal? If so, are there any plans of bringing it into v2?",
        "Answers":[
            {
                "Answer_creation_time":"2022-07-20T10:02:04.113Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @SH-3152\n\nI have a good news for you, I just got confirmation from product team, the datadrift function will be in SDK V2 for sure. But for now we don't have an exact date for when. I have forwarded this feedback to product group and we hope we can bring this feature in near future.\n\n\n\n\nI hope this helps.\n\n\n\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"why the ML data only result in 1 point?",
        "Question_creation_time":1629379772053,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/520581\/why-the-ml-data-only-result-in-1-point.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"",
        "Answers":[
            {
                "Answer_creation_time":"2021-09-02T08:43:51.05Z",
                "Answer_upvote_count":0,
                "Answer_body":"\u60a8\u597d\uff0c\n\n\u611f\u8c22\u60a8\u8054\u7cfb\u5fae\u8f6fAzure\u8bba\u575b\uff0c\u6211\u8bd5\u56fe\u91cd\u590d\u60a8\u6240\u8bf4\u7684bug\uff0c\u4f46\u662f\u5e76\u4e0d\u80fd\u5f97\u5230\u4efb\u4f55\u201c1 point\u201d\u7684\u7ed3\u679c\u3002\u5982\u679c\u60a8\u4ecd\u6709\u8fd9\u4e2a\u95ee\u9898\uff0c\u8bf7\u63d0\u4f9b\u66f4\u591a\u8be6\u60c5\uff0c\u6211\u4eec\u4f1a\u5c3d\u53ef\u80fd\u63d0\u4f9b\u6700\u5927\u5e2e\u52a9\u3002\n\n\u8c22\u8c22\u60a8\u3002\n\n\u5b87\u5f64",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"ModuleExceptionMessage:ModuleOutOfMemory: Memory has been exhausted, unable to complete running of module.",
        "Question_creation_time":1619357291613,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/370636\/moduleexceptionmessagemoduleoutofmemory-memory-has.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi, I am getting the error from the subject line when i try to inner join a dataset of 850K rows and 3 columns (parquet data file of around 4mb) with another with 300K rows and 10 columns (parquet data file is about 1mb). I'm using Azure ML Studio Designer\n\nMy compute is Standard Dv2 Family vCPUs (20% of utilization).\n\nI was surprised by this hitting a limit. Any idea on how i should proceed?",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-26T13:37:13.763Z",
                "Answer_upvote_count":0,
                "Answer_body":"i manage to do this by trainning the model in a subset of records (using the Sample model).\n\nAlso noted that the documentation implies that an out of memory error is dependant on the RAM of the client \/ Designer user machine not the compute selected (or at least that is my understanding of the note at the beginning of the doc)",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"i am not able to select jupyter notebook in azure ML",
        "Question_creation_time":1604559071717,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/152224\/i-am-not-able-to-select-jupyter-notebook-in-azure.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-06T01:03:43.72Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for reaching out. Azure ML Studio (Classic) notebooks feature retired on 4\/13\/2020. Your notebook would no longer be available if it wasn't saved by the deadline. However, the new Azure ML Studio supports Jupyter Notebooks in your workspace. Hope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Conda environment locked by another AzureML job",
        "Question_creation_time":1611713493223,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/246501\/conda-environment-locked-by-another-azureml-job.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":2.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I tried to run an experiments. There was an error in my first submit and the run did not go through. However, a lock has been created which is preventing me from submitting further runs. I am getting the following error.\n\n\"The conda environment is currently locked by another AzureML job. Further job submission will wait until the other process finishes. If there are no other jobs running, please delete \/home\/azureuser\/.azureml\/locks\/azureml_conda_lock\"\n\nI tried to use:\naz ml run cancel -r exp_id\n\nin CLI. However, this gives me an error:\nError, default experiment not set and experiment name parameter not provided.\\nPlease provide a value for the experiment name parameter.",
        "Answers":[
            {
                "Answer_creation_time":"2021-01-27T12:23:43.017Z",
                "Answer_upvote_count":0,
                "Answer_body":"@KanyanLawrence-5964 Thanks for the question. Could you please add more details about the steps\/link to the code that you are trying.\nHere is the doc to configure and submit training runs.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-set-up-training-targets#persistent",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":4.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"What are the differences between LightGBM and FastTree algorithms used by ML.Net's modelbuilder?",
        "Question_creation_time":1620299148307,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/385365\/what-are-the-differences-between-lightgbm-and-fast.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "dotnet-ml-big-data"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"For my master thesis, I am using ML.Net library with the model builder to build machine learning models for regression \/ to predict values. My field of study is in constructional mechanics, so I'm rather new to machine learning.\n\nFor most of my models, tree-based regression algorithms seem to be the best performing, and of these LightGBM and FastTree are the best performing algorithms.\n\nI've tried to read up on LightGBM here: https:\/\/www.microsoft.com\/en-us\/research\/publication\/lightgbm-a-highly-efficient-gradient-boosting-decision-tree\/ And FastTree here: https:\/\/docs.microsoft.com\/en-us\/dotnet\/api\/microsoft.ml.trainers.fasttree.fasttreeregressiontrainer?view=ml-dotnet\n\nHowever, I struggle to distinguish what the difference between these algorithms is. Could someone explain what the difference between LightGBM and FastTree is?",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-06T21:50:12.9Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us! The right place for ML.NET related question is the GitHub forum here, and the Gitter community. Sorry for the inconveniences.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Pytorch error - RuntimeError: Unable to find a valid cuDNN algorithm to run convolution on Standard_NC6 and Python 3.8 - Pytorch and Tensorflow kernel",
        "Question_creation_time":1666006220943,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1050727\/pytorch-error-runtimeerror-unable-to-find-a-valid.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello community,\n\nI am new to Azure. I have some scripts in a working environment in google colab, and as I am working on my Thesis I tried to user Azure Student promo.\nI have setup a Standard_NC6 with Pytorch and Tensorflow kernel and I am getting the following error:\n\n---------------------------------------------------------------------------\nRuntimeError Traceback (most recent call last)\nInput In [9], in <cell line: 64>()\n76 loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake))\n77 critic.zero_grad()\n---> 78 loss_critic.backward(retain_graph=True)\n79 opt_critic.step()\n81 # clip critic weights between -0.01, 0.01\n\n\nFile \/anaconda\/envs\/azureml_py38_PT_TF\/lib\/python3.8\/site-packages\/torch\/_tensor.py:396, in Tensor.backward(self, gradient, retain_graph, create_graph, inputs)\n387 if has_torch_function_unary(self):\n388 return handle_torch_function(\n389 Tensor.backward,\n390 (self,),\n(...)\n394 create_graph=create_graph,\n395 inputs=inputs)\n--> 396 torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n\n\nFile \/anaconda\/envs\/azureml_py38_PT_TF\/lib\/python3.8\/site-packages\/torch\/autograd\/init.py:173, in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\n168 retain_graph = create_graph\n170 # The reason we repeat same the comment below is that\n171 # some Python versions print out the first line of a multi-line function\n172 # calls in the traceback and some print out the last line\n--> 173 Variable.execution_engine.run_backward( # Calls into the C++ engine to run the backward pass\n174 tensors, grad_tensors, retain_graph, create_graph, inputs,\n175 allow_unreachable=True, accumulate_grad=True)\n\n\nRuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n\n\n\n\nI tried different versions of pytorch + cu113 and cu116.\n\nThe nvdia-smi output is:\n\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.141.03 Driver Version: 470.141.03 CUDA Version: 11.4 |\n|-------------------------------+----------------------+----------------------+\n| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |\n| Fan Temp Perf Pwr:Usage\/Cap| Memory-Usage | GPU-Util Compute M. |\n| | | MIG M. |\n|===============================+======================+======================|\n| 0 Tesla K80 On | 00000001:00:00.0 Off | 0 |\n| N\/A 41C P0 70W \/ 149W | 880MiB \/ 11441MiB | 0% Default |\n| | | N\/A |\n+-------------------------------+----------------------+----------------------+\n\n\n+-----------------------------------------------------------------------------+\n| Processes: |\n| GPU GI CI PID Type Process name GPU Memory |\n| ID ID Usage |\n|=============================================================================|\n| 0 N\/A N\/A 11425 C ...eml_py38_PT_TF\/bin\/python 877MiB |\n+-----------------------------------------------------------------------------+\n\nI guess that the problem is about drivers and versions.. as in google colab environment it's working\n\nThanks,\nDP",
        "Answers":[
            {
                "Answer_creation_time":"2022-10-18T14:26:03.943Z",
                "Answer_upvote_count":0,
                "Answer_body":"@dp-5741Thanks for the question. using one of the containers \/ environments in AML which is correctly configured for GPU should be sufficient if the ML framework being used supports GPU acceleration. The GPU images contain Miniconda, OpenMPI, CUDA, cuDNN, and NCCL. You can use these images for your environments, or use their corresponding Dockerfiles as reference when building your own custom images.\n\nFor the set of base images and their corresponding Dockerfiles, see the AzureML-Containers repo.\n\nhttps:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-environments-v2?tabs=cli#create-an-environment",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Synapse - 'No Azure Cognitive Service Linked Service are available'",
        "Question_creation_time":1644147139677,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/724155\/synapse-39no-azure-cognitive-service-linked-servic.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-synapse-analytics",
            "azure-machine-learning",
            "azure-cognitive-services"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am following this guide\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-cognitive-services-sentiment\n\nBut when I get to selecting 'Machine Learning - Predict with a Model', then I choose 'Sentiment Analysis'\n\nBut the first dropdown is greyed out for me and reads:\nAzure Cognitive Services linked service: No Azure Cognitive Service Linked Service are available\n\nI had one created, then created another. AKV and link service tested with specific key.\n\nAnyone know how I can get it to recognize the Cognitive Service Linked Server?\n\nThanks\n\n][2]\n\n\n\n\n\n\n\n[2]: \/answers\/storage\/attachments\/171659-image.png",
        "Answers":[
            {
                "Answer_creation_time":"2022-02-06T20:12:21.55Z",
                "Answer_upvote_count":0,
                "Answer_body":"The problem was I needed to create a Language specific Cognitive Service and not the general Cognitive Service resource.\n\nThere is no distinction for this from Synapse, when creating the Cognitive Service Linked Service, but the Predict a Model cares.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":19.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Consume Azure ML Web Service with Postman: how to pass arguments?",
        "Question_creation_time":1603965300457,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/144230\/consume-azure-ml-web-service-with-postman-how-to-p.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Is it possible to pass parameters to an Azure ML Web Service with Postman? I created an R web service endpoint that runs in an Azure Container Instance. My run function has one argument (\"data\"). I can call the web service using Azure ML R SDK (using invoke_webservice()) and the input parameter is read successfully from the request content. The input is constructed like:\n\n toJSON(data.frame(data=\"This is my test string\"))\n\n\n\nResult:\n\n [{\"data\": \"This is my test string\"}]\n\n\n\nIf I create a Postman request and copy the input to the request body, the input parameter is not passed to the web service. The web service can return a static output to Postman but the variable data is always empty. Is this a property of the ML Web Service? If not, how can I set up the request body so that the argument is read successfully? I have tried many variations, but none have worked.\n\nI have set content-type header to application\/json. I don't have authentication in the web service, since it is just a test instance.\n\nUltimately, we need to call the web service with C# from Azure Function. I know that we can use the C# template from documentation and it can probably pass the parameter to the web service, but it would be nice to be able to test the web service with Postman.",
        "Answers":[
            {
                "Answer_creation_time":"2020-10-29T12:55:26.077Z",
                "Answer_upvote_count":1,
                "Answer_body":"Try this in postman.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Receive error GraphDatasetNotFound: Request failed with status code 400 when submitting pipeline",
        "Question_creation_time":1619957038450,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/379678\/receive-error-graphdatasetnotfound-request-failed.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":4.0,
        "Question_view_count":null,
        "Question_answer_count":3,
        "Question_has_accepted_answer":true,
        "Question_body":"I am running through the tutorial at ..https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/create-clustering-model-azure-machine-learning-designer\/explore-data\n\nWhen I submit my pipeline I am seeing the error ...\n\nAn error occurred while submitting pipeline run\nGraphDatasetNotFound: Request failed with status code 400\n\nThis is an incredibly unhelpful message. I believe I have followed the steps as per the tutorial.\n\nAny idea what is the cause of this error?\n\nThanks",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-03T15:51:30.88Z",
                "Answer_upvote_count":14,
                "Answer_body":"In dataset Version change from \"Always use latest\" to 1 or anyother version, worked for me",
                "Answer_comment_count":9,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-05-04T19:31:52.053Z",
                "Answer_upvote_count":0,
                "Answer_body":"@DebayanRoy-8817, how exactly should we go about changing the dataset version? Mine has been greyed out to the dataset version 1. Your help will be very much appreciated!",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-08T14:14:30.57Z",
                "Answer_upvote_count":0,
                "Answer_body":"This solved the problem. thanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":20.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"frame = ds.to_dataframe() doesn't work for me",
        "Question_creation_time":1605353730307,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/162914\/frame-dsto-dataframe-doesn39t-work-for-me.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-16T11:35:54.413Z",
                "Answer_upvote_count":0,
                "Answer_body":"@MohamedSalem-4734 Thanks for the question. A TabularDataset can be created from CSV, TSV, Parquet files, or SQL query using the from_* methods of the TabularDatasetFactory class. You can also convert a TabularDataset into other formats like a pandas DataFrame. Can you please add more details about the dataframe (pandas DataFrame or spark Dataframe) that you are trying.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML AutoML : Data transformation diagram only 1 column",
        "Question_creation_time":1626184752807,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/474091\/azure-ml-automl-data-transformation-diagram-only-1.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello, I am using the AutoML of Azure ML. I don't understand the diagram of Data transformation (that is still in preview). It tells me that I start with 26 columns, which is correct, but then says I'm ending up with 1 column only, after a MeanImputer. ![114216-1column.png][1] If I check the engineered features in the code, I get this table, so 26 columns with the application of MeanImputer for each of them. ![114215-allcolumns.png][2] Could you tell me why the diagram tells me that there is only 1 column at the end? [1]: \/answers\/storage\/attachments\/114216-1column.png [2]: \/answers\/storage\/attachments\/114215-allcolumns.png",
        "Answers":[
            {
                "Answer_creation_time":"2021-07-14T19:36:10.617Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for pointing this out. This feature is still in preview, I followed up with the product team, we currently have a work item to improve this feature (we don't have an ETA at the moment). Please disregard the summary workflow for now. Will follow-up with updates accordingly. Hope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Is there a way to export experiment parameters and logged metrics in Azure ML to CSV?",
        "Question_creation_time":1605641332880,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/166057\/is-there-a-way-to-export-experiment-parameters-and.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am running a bunch of ML experiments using AzureML, sometimes changing training parameters and sometimes aspects of the data preprocessing. In general, for a given experiment I will be able to get a table (aka \"view\") like this:\n\nWhile the UI allows some minimum level of customization, sorting runs by e.g. desired columns (say the accuracy to identify the best runs) seems really problematic.\n\nThe only workaround I am aware of is to save the page to HTML (!) and extract the values from there.\nThe data in the cells can't by copied with a cursor either...\n\nIs there an easy way to export the data collected during several runs, via the UI or programmatically, without the need to scrape the blob storage of the Azure ML workspace (I am asking the community here as docs don't seem particularly helpful)?",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-18T08:02:11.3Z",
                "Answer_upvote_count":2,
                "Answer_body":"@DavideFiocco-7346 You can use the SDK to export the run\/s using Run() or get_runs()\nThis sample provides an example to get all the files associated with a run. I think you can use the SDK to get all the runs with get_runs() and load the list to a dataframe and export the same to csv.\n\nThe portal does not have the functionality to export the table but we will provide the feedback to our team for upcoming updates to the portal. Thanks!!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"certification test for AI-900: Microsoft Azure AI Fundamentals not available",
        "Question_creation_time":1662205880130,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/992629\/exam-ai-900-microsoft-azure-ai-fundamentals-not-av.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hallo, i would like make an appointment for Exam AI-900: Microsoft Azure AI Fundamentals.\nHowever this exam is currently not available at Pearson vue or Certiport. When can i expect this again? Is there an alternative ?",
        "Answers":[
            {
                "Answer_creation_time":"2022-09-03T13:15:33.98Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi Jurian,\n\nThis is available in PearsonVue check this. ai-900\n\nAny specific region you are trying from?\n\n\n\n\n\n==\nPlease \"Accept the answer\" if the information helped you. This will help us and others in the community as well.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to move all the ai models (service endpoints) from one compute cluster to another cluster in azure without any effects",
        "Question_creation_time":1636704232043,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/624851\/how-to-move-all-the-ai-models-service-endpoints-fr.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-kubernetes-service",
            "azure-container-instances",
            "azure-machine-learning-studio-classic",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I have machine learning models which is deployed in Azure aks in 'x' Cluster , Now i want to move this models and its endpoint in another cluster which is 'y' within same workspace and subscription ,So how to do this without any changes to its rest endpoint as this endpoints are in production use already.\n\nalso if this is not possible then can i upgrade my x cluster with newer version without affecting my endpoints",
        "Answers":[
            {
                "Answer_creation_time":"2021-11-12T11:50:38.363Z",
                "Answer_upvote_count":1,
                "Answer_body":"@VishalSuryavanshi-3563 Thanks for the question. Here is link to the blog for New managed online endpoints features in Azure ML: Autoscaling, Debugging, MLflow and more.",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":16.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML authentication with Service Principal certificate",
        "Question_creation_time":1601045466093,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/108060\/azure-ml-authentication-with-service-principal-cer.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\nI am responsible for deploying Azure ML resources like workspace, compute target and datastore using Python from Azure CI\/CD Devops Pipeline. I have Service principal certificate for authentication. I am confused about which authentication method of Python I will follow.\n\nShall I used MSAL authentication? or\n\nplease suggest a secure authentication method of python that supports Service Principal certificate to authenticate Azure ML workspace. Please share a sample as reference if any.",
        "Answers":[
            {
                "Answer_creation_time":"2020-09-25T23:03:57.707Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for reaching out. Check out this document regarding Azure Resource Manager service connection which provides information on different connection methods. Hope this helps, otherwise, let me know so we can get you the information you need. Thanks!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Is their limit on number of records in dataset for Azure automated ML timeserires forecasting",
        "Question_creation_time":1628484429713,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/505948\/is-their-limit-on-number-of-records-in-dataset-for.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi\n\nI am facing issue with number of records while creating datasets automated ML timeseries forecasting, It is loading only first 10000 records rest of the records are ignored.\n\nIs their any limit on number of records in the datasets for Azure automated ML timeseries forecasting.\n\n\n\n\nIf there limits in number of records , how to increase number of records\n\nThanks\nRamabadran",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"AML Studio - cannot create dataset from datastore file",
        "Question_creation_time":1605192099620,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/160773\/aml-studio-cannot-create-dataset-from-datastore-fi.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"I am using Jupyter notebooks to work in AML. I was able to upload a file to a datastore (the default workspaceblobstore), but am receiving an error when I try to create a dataset using this file. The relevant code is below:\n\n #This part works\n    \n datastore = ws.get_default_datastore()\n    \n datastore.upload_files(files = ['data\/german_credit_dataset.csv'], overwrite = True, show_progress = True)\n    \n # This part doesn't\n    \n dataset = Dataset.Tabular.from_delimited_files(path = [(datastore ,'german_credit_dataset.csv')])\n\nI know the file was uploaded correctly as I am able to locate it in the datastore, and manually create a dataset. The error I receive is:\n\ncode\": \"UserError\",\n\"message\": \"Cannot load any data from the specified path. Make sure the path is accessible and contains data.\\nScriptExecutionException was caused by DatastoreResolutionException.\\r\\n DatastoreResolutionException was caused by UnexpectedException.\\r\\n\nCould it be a permissions issue? I used the json file to connect to my compute instance and it seems to work since I was able to upload the file.",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":4.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML real-time inference endpoint deployment stuck with deployment state as transitioning for over 2 hours",
        "Question_creation_time":1663182438927,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1007819\/azure-ml-real-time-inference-endpoint-deployment-s.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"I have an AKS cluster and am trying to deploy a real-time inference pipeline to it as an endpoint. The deployment state is switching between \"Transitioning\" and \"Failed\" and I am unable to see any logs. My cluster is in West Central US.",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Why PyTorch is using only one GPU ?",
        "Question_creation_time":1653503234337,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/864175\/why-pytorch-is-using-only-one-gpu.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"Azure does not use the two GPUs of my node with PyTorch (and Hugging Face). The monitoring tool of Azure shows the GPU usage is stuck at 50%.\nIts a Standard_NC12, so it has two K80s.\n\n\n\n\nI tried this way :\nhttps:\/\/azure.github.io\/azureml-cheatsheets\/docs\/cheatsheets\/python\/v1\/distributed-training\/#distributeddataparallel-per-process-launch\nand it looked like this in my notebook :\n\n\n\n\n\nI copied the docker file from the curated environments and added the libraries I needed successfully :\n\n FROM mcr.microsoft.com\/azureml\/openmpi4.1.0-cuda11.1-cudnn8-ubuntu18.04:20220329.v1\n    \n ENV AZUREML_CONDA_ENVIRONMENT_PATH \/azureml-envs\/pytorch-1.10\n    \n # Create conda environment\n RUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\\n     python=3.8 \\\n     pip=20.2.4 \\\n     pytorch=1.10.0 \\\n     torchvision=0.11.1 \\\n     torchaudio=0.10.0 \\\n     cudatoolkit=11.1.1 \\\n     nvidia-apex=0.1.0 \\\n     gxx_linux-64 \\\n     -c anaconda -c pytorch -c conda-forge\n    \n # Prepend path to AzureML conda environment\n ENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/bin:$PATH\n    \n # Install pip dependencies\n RUN pip install 'matplotlib>=3.3,<3.4' \\\n                 'psutil>=5.8,<5.9' \\\n                 'tqdm>=4.59,<4.63' \\\n                 'pandas>=1.3,<1.4' \\\n                 'scipy>=1.5,<1.8' \\\n                 'numpy>=1.10,<1.22' \\\n                 'ipykernel~=6.0' \\\n                 'azureml-core==1.40.0' \\\n                 'azureml-defaults==1.40.0' \\\n                 'azureml-mlflow==1.40.0' \\\n                 'azureml-telemetry==1.40.0' \\\n                 'tensorboard==2.6.0' \\\n                 'tensorflow-gpu==2.6.0' \\\n                 'onnxruntime-gpu>=1.7,<1.10' \\\n                 'horovod==0.23' \\\n                 'future==0.18.2' \\\n                 'wandb' \\\n                 'transformers' \\\n                 'einops' \\\n                 'torch-tb-profiler==0.3.1'\n    \n    \n # This is needed for mpi to locate libpython\n ENV LD_LIBRARY_PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/lib:$LD_LIBRARY_PATH\n    \n RUN export CUDA_VISIBLE_DEVICES=0,1\n\n\n\nI tried everything, I even added the CUDA_VISIBLE_DEVICES=0,1 inside the docker file.\n\nMy cluster is correctly configured because my colleague can use another tool (Detr with Lightning) and use 100% of the computing power.\nI copied his docker file and the result was the same, so our guess is that his tool is automatically managing all GPUs for him.\n\nDoes anyone know why the cluster is using only one GPU ?",
        "Answers":[
            {
                "Answer_creation_time":"2022-05-27T15:37:03Z",
                "Answer_upvote_count":0,
                "Answer_body":"That's interesting because it was written :\nVirtual machine size\nStandard_NC12 (12 cores, 112 GB RAM, 680 GB disk)\nProcessing unit\nGPU - 2 x NVIDIA Tesla K80\nThen I guess I did not understand it properly and I am stuck using 50% of 1 K80.\n\nprint(torch.cuda.device_count()) gives :\n2\n\nnode_count = 2 leads to :\nRequested 2 nodes but AzureMLCompute cluster only has 1 maximum nodes.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-01T08:42:04.183Z",
                "Answer_upvote_count":0,
                "Answer_body":"(I also realized in the job's properties raw json that gpuCount is 0 in the compute and computeRequest sections)",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-02T12:19:04.443Z",
                "Answer_upvote_count":1,
                "Answer_body":"model = nn.DataParallel(model)\ndid the job.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"[Bug] azureml-train Python package deprecated but did receive an update which is not in line with azureml-train-core",
        "Question_creation_time":1629973035930,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/528959\/bug-azureml-train-python-package-deprecated-but-di.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"The Python package azureml-train is deprecated and seems basically a wrapper around azureml-train-core. When installing azureml-train, if I'm correct it tries to install the azureml-train-core package with the same version number. However, on the 24th of August 2021 the azureml-train package was updated to version 1.33.1 whereas azureml-train-core wasn't updated. This causes the installation of azureml-train to fail.\n\nI would suggest to remove version 1.33.1 of azureml-train such that it still can be installed.\nOtherwise, I'm curious why this situation is the case.",
        "Answers":[
            {
                "Answer_creation_time":"2021-08-26T12:35:40.733Z",
                "Answer_upvote_count":1,
                "Answer_body":"@SjoerdGn-2530 Yes, this is a bug in the release cycle that was pushed to pypi, This also caused other packages to get updated.\n\nhttps:\/\/pypi.org\/project\/azureml-train-automl-runtime\/1.33.1.post1\/\nhttps:\/\/pypi.org\/project\/azureml-train-automl\/1.33.1\/\n\nazureml-sdk 1.33.0.post1 is released now to ensure the correct versions are installed with the SDK. As you mentioned above azureml-train 1.33.1 is not required and can be removed.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Realtime endpoint deploy 'xxx' stayed in progress",
        "Question_creation_time":1661074944827,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/975300\/realtime-endpoint-deploy-39xxx39-stayed-in-progres.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi everyone,\n\nI'm trying to deploy my real time inference, but after a while not happened to it. I didn't got any error or message and nothing happens. (See the following picture).\n\nWhat I did:\n\nI created a pipeline in designer, it's valid and be submitted very well.\n\n\nAfter submit is complete, I created a \"Real-time inference pipeline\" via button in menu!\n\n\n\n\nAnd finally I tried to deploy it, but nothing happened. (For deploy I tried both of Azure Kubernetes Service and Azure Container Instance)",
        "Answers":[
            {
                "Answer_creation_time":"2022-08-22T22:20:19.56Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @ImranShams-7088\n\nYou have been enabled for one-time Free Technical Support. To create the support request, please do the following as detailed below. It may take up to 1 hour for the free support ticket enablement to go through.\n\n\u2022 Go to the Health Advisory section within the Azure Portal: https:\/\/aka.ms\/healthadvisories\n\u2022 Select the Issue Name \"You have been enabled for one-time Free Technical Support\"\n\u2022 Details will populate below in the Summary Tab within the reading pane and you can click on the link \"Create a Support Request\" to the right of the message\n\nOnce created, please share the ticket number with me. Thanks.\n\nRegards,\nYutong",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":4.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML Experiment stuck in Queued",
        "Question_creation_time":1642636050810,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/702171\/azure-ml-experiment-stuck-in-queued.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"I have only one experiment running, but it is stuck in queued. I see this happens to people a lot, but on one ever says how to fix it.",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":4.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",",
        "Question_creation_time":1619621454417,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/375577\/submitted-script-failed-with-a-non-zero-exit-code.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi All,\nI am trying to creating batch inference of my pretrained churn classification model. I was following this github of iris batch inference [1]: https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/parallel-run\/tabular-dataset-inference-iris.ipynb .\nBut I am getting error , please help me how can I fix this error.\n\nHere my code:\n\n\n\n\n\n\n\n\n\nHere my errors:\n\n\n\n ========================================================================================================================\n 2\n . Please ignore this if the GPUs don't utilize NVIDIA\u00ae NVLink\u00ae switches.\n 2021-04-28T12:53:39Z Starting output-watcher...\n 2021-04-28T12:53:39Z IsDedicatedCompute == False, starting polling for Low-Pri Preemption\n 2021-04-28T12:53:39Z Executing 'Copy ACR Details file' on 10.0.0.4\n 2021-04-28T12:53:39Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n >>>   \n >>>   \n Login Succeeded\n Using default tag: latest\n latest: Pulling from azureml\/azureml_af590fdfaae8ba3ead1eba5ea12b0fb3\n 4007a89234b4: Pulling fs layer\n 5dfa26c6b9c9: Pulling fs layer\n 0ba7bf18aa40: Pulling fs layer\n 4c6ec688ebe3: Pulling fs layer\n 574f361512d6: Pulling fs layer\n db4d1e2d7079: Pulling fs layer\n e544ee0f522d: Pulling fs layer\n c655136086be: Pulling fs layer\n 2ec37f44090c: Pulling fs layer\n 5fba3bd4a2c4: Pulling fs layer\n 7e0ea9d0a1ab: Pulling fs layer\n da005f826951: Pulling fs layer\n 6e842608b724: Pulling fs layer\n 6b1a4187f1d0: Pulling fs layer\n db4d1e2d7079: Waiting\n c763bae43813: Pulling fs layer\n 490d7c37a7d7: Pulling fs layer\n 791bb1082f38: Pulling fs layer\n e544ee0f522d: Waiting\n e863af755720: Pulling fs layer\n c655136086be: Waiting\n 4c6ec688ebe3: Waiting\n 0cb6e30b3f1c: Pulling fs layer\n 88468e3f4c2c: Pulling fs layer\n 77d6ac8c0bf7: Pulling fs layer\n 574f361512d6: Waiting\n 2ec37f44090c: Waiting\n da005f826951: Waiting\n 5fba3bd4a2c4: Waiting\n 6e842608b724: Waiting\n 6b1a4187f1d0: Waiting\n c763bae43813: Waiting\n 490d7c37a7d7: Waiting\n 791bb1082f38: Waiting\n e863af755720: Waiting\n 0cb6e30b3f1c: Waiting\n 88468e3f4c2c: Waiting\n 77d6ac8c0bf7: Waiting\n 7e0ea9d0a1ab: Waiting\n 0ba7bf18aa40: Verifying Checksum\n 0ba7bf18aa40: Download complete\n 5dfa26c6b9c9: Verifying Checksum\n 5dfa26c6b9c9: Download complete\n 4c6ec688ebe3: Verifying Checksum\n 4c6ec688ebe3: Download complete\n 4007a89234b4: Download complete\n db4d1e2d7079: Verifying Checksum\n db4d1e2d7079: Download complete\n e544ee0f522d: Verifying Checksum\n e544ee0f522d: Download complete\n 574f361512d6: Verifying Checksum\n 574f361512d6: Download complete\n 4007a89234b4: Pull complete\n 5dfa26c6b9c9: Pull complete\n 0ba7bf18aa40: Pull complete\n 4c6ec688ebe3: Pull complete\n 5fba3bd4a2c4: Download complete\n c655136086be: Verifying Checksum\n c655136086be: Download complete\n 7e0ea9d0a1ab: Verifying Checksum\n 7e0ea9d0a1ab: Download complete\n da005f826951: Verifying Checksum\n da005f826951: Download complete\n 6e842608b724: Download complete\n 6b1a4187f1d0: Download complete\n c763bae43813: Verifying Checksum\n c763bae43813: Download complete\n 2ec37f44090c: Verifying Checksum\n 2ec37f44090c: Download complete\n 490d7c37a7d7: Verifying Checksum\n 490d7c37a7d7: Download complete\n 0cb6e30b3f1c: Verifying Checksum\n 0cb6e30b3f1c: Download complete\n e863af755720: Verifying Checksum\n e863af755720: Download complete\n 77d6ac8c0bf7: Verifying Checksum\n 77d6ac8c0bf7: Download complete\n 88468e3f4c2c: Verifying Checksum\n 88468e3f4c2c: Download complete\n 574f361512d6: Pull complete\n db4d1e2d7079: Pull complete\n e544ee0f522d: Pull complete\n 791bb1082f38: Verifying Checksum\n 791bb1082f38: Download complete\n c655136086be: Pull complete\n 2ec37f44090c: Pull complete\n 5fba3bd4a2c4: Pull complete\n 7e0ea9d0a1ab: Pull complete\n da005f826951: Pull complete\n 6e842608b724: Pull complete\n 6b1a4187f1d0: Pull complete\n c763bae43813: Pull complete\n 490d7c37a7d7: Pull complete\n    \n Streaming azureml-logs\/65_job_prep-tvmps_287cfab3497943a39d90c089311555c3223ca350d504acc72af6aceb3d957ba3_p.txt\n ===============================================================================================================\n [2021-04-28T12:54:05.020376] Entering job preparation.\n [2021-04-28T12:54:08.337333] Starting job preparation.\n [2021-04-28T12:54:08.337375] Extracting the control code.\n [2021-04-28T12:54:08.365360] fetching and extracting the control code on master node.\n [2021-04-28T12:54:08.365417] Starting extract_project.\n [2021-04-28T12:54:08.365467] Starting to extract zip file.\n [2021-04-28T12:54:09.302078] Finished extracting zip file.\n [2021-04-28T12:54:09.804262] Using urllib.request Python 3.0 or later\n [2021-04-28T12:54:09.804327] Start fetching snapshots.\n [2021-04-28T12:54:09.804373] Start fetching snapshot.\n [2021-04-28T12:54:09.804391] Retrieving project from snapshot: f4a38de4-3230-4038-ac4b-cde33bdd63e5\n Starting the daemon thread to refresh tokens in background for process with pid = 51\n [2021-04-28T12:54:10.714200] Finished fetching snapshot.\n [2021-04-28T12:54:10.714233] Start fetching snapshot.\n [2021-04-28T12:54:10.714251] Retrieving project from snapshot: b71de588-0f3c-44ae-b144-ea24a905546e\n [2021-04-28T12:54:24.343681] Finished fetching snapshot.\n [2021-04-28T12:54:24.343714] Finished fetching snapshots.\n [2021-04-28T12:54:24.343728] Finished extract_project.\n [2021-04-28T12:54:24.360941] Finished fetching and extracting the control code.\n [2021-04-28T12:54:24.364330] downloadDataStore - Download from datastores if requested.\n [2021-04-28T12:54:24.365371] Start run_history_prep.\n [2021-04-28T12:54:24.436823] Entering context manager injector.\n Acquired lockfile \/tmp\/a1c4fded-7336-4024-8c9e-fed19f5d1b37-datastore.lock to downloading input data references\n [2021-04-28T12:54:24.903804] downloadDataStore completed\n [2021-04-28T12:54:24.906597] Job preparation is complete.\n    \n Streaming azureml-logs\/70_driver_log.txt\n ========================================\n 2021\/04\/28 12:54:26 Starting App Insight Logger for task:  runTaskLet\n 2021\/04\/28 12:54:26 Attempt 1 of http call to http:\/\/10.0.0.4:16384\/sendlogstoartifacts\/info\n 2021\/04\/28 12:54:26 Attempt 1 of http call to http:\/\/10.0.0.4:16384\/sendlogstoartifacts\/status\n [2021-04-28T12:54:27.564276] Entering context manager injector.\n [context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', '\n 2021\/04\/28 12:54:31 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n Stopped: false\n OriginalData: 1\n FilteredData: 0.\n    \n Streaming azureml-logs\/75_job_post-tvmps_287cfab3497943a39d90c089311555c3223ca350d504acc72af6aceb3d957ba3_p.txt\n ===============================================================================================================\n [2021-04-28T13:02:20.275818] Entering job release\n [2021-04-28T13:02:21.348190] Starting job release\n [2021-04-28T13:02:21.348739] Logging experiment finalizing status in history service.\n Starting the daemon thread to refresh tokens in background for process with pid = 1369\n [2021-04-28T13:02:21.349418] job release stage : upload_datastore starting...\n [2021-04-28T13:02:21.349812] job release stage : start importing azureml.history._tracking in run_history_release.\n [2021-04-28T13:02:21.352029] job release stage : copy_batchai_cached_logs starting...\n [2021-04-28T13:02:21.352142] job release stage : execute_job_release starting...\n [2021-04-28T13:02:21.357651] job release stage : copy_batchai_cached_logs completed...\n [2021-04-28T13:02:21.358513] Entering context manager injector.\n [2021-04-28T13:02:21.372410] job release stage : upload_datastore completed...\n [2021-04-28T13:02:21.595288] job release stage : execute_job_release completed...\n [2021-04-28T13:02:21.628735] job release stage : send_run_telemetry starting...\n [2021-04-28T13:02:21.849387] get vm size and vm region successfully.\n [2021-04-28T13:02:22.175695] get compute meta data successfully.\n [2021-04-28T13:02:22.444070] post artifact meta request successfully.\n [2021-04-28T13:02:22.471466] upload compute record artifact successfully.\n [2021-04-28T13:02:22.471531] job release stage : send_run_telemetry completed...\n [2021-04-28T13:02:22.471747] Job release is complete\n    \n StepRun(batch-score) Execution Summary\n =======================================\n StepRun( batch-score ) Status: Failed\n ---------------------------------------------------------------------------\n ActivityFailedException                   Traceback (most recent call last)\n <ipython-input-30-49d7d34a142d> in <module>\n       3 # Run the pipeline as an experiment\n       4 pipeline_run = Experiment(ws, 'batc-prediction_pipeline').submit(pipeline)\n ----> 5 pipeline_run.wait_for_completion(show_output=True)\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/run.py in wait_for_completion(self, show_output, timeout_seconds, raise_on_error)\n     293                             try:\n     294                                 step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,\n --> 295                                                              raise_on_error=raise_on_error)\n     296                             except TypeError as e:\n     297                                 # If there are package conflicts in the user's environment, the run rehydration\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/run.py in wait_for_completion(self, show_output, timeout_seconds, raise_on_error)\n     735             try:\n     736                 return self._stream_run_output(timeout_seconds=timeout_seconds,\n --> 737                                                raise_on_error=raise_on_error)\n     738             except KeyboardInterrupt:\n     739                 error_message = \"The output streaming for the run interrupted.\\n\" \\\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/run.py in _stream_run_output(self, timeout_seconds, raise_on_error)\n     823             print(json.dumps(error, indent=4))\n     824         if error and raise_on_error:\n --> 825             raise ActivityFailedException(error_details=json.dumps(error, indent=4))\n     826 \n     827         print(final_details)\n    \n ActivityFailedException: ActivityFailedException:\n  Message: Activity Failed:\n {\n     \"error\": {\n         \"code\": \"UserError\",\n         \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n         \"messageFormat\": \"{Message}\",\n         \"messageParameters\": {\n             \"Message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\"\n         },\n         \"details\": [],\n         \"innerError\": {\n             \"code\": \"UserTrainingScriptFailed\"\n         }\n     },\n     \"correlation\": {\n         \"operation\": null,\n         \"request\": \"6833f86b6a0c0af1\"\n     },\n     \"environment\": \"eastus\",\n     \"location\": \"eastus\",\n     \"time\": \"2021-04-28T13:02:41.490064Z\",\n     \"componentName\": \"execution-worker\"\n }\n  InnerException None\n  ErrorResponse \n {\n     \"error\": {\n         \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\\n\\\\tReason: Job failed with non-zero exit Code\\\",\\n        \\\"messageFormat\\\": \\\"{Message}\\\",\\n        \\\"messageParameters\\\": {\\n            \\\"Message\\\": \\\"AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\\n\\\\tReason: Job failed with non-zero exit Code\\\"\\n        },\\n        \\\"details\\\": [],\\n        \\\"innerError\\\": {\\n            \\\"code\\\": \\\"UserTrainingScriptFailed\\\"\\n        }\\n    },\\n    \\\"correlation\\\": {\\n        \\\"operation\\\": null,\\n        \\\"request\\\": \\\"6833f86b6a0c0af1\\\"\\n    },\\n    \\\"environment\\\": \\\"eastus\\\",\\n    \\\"location\\\": \\\"eastus\\\",\\n    \\\"time\\\": \\\"2021-04-28T13:02:41.490064Z\\\",\\n    \\\"componentName\\\": \\\"execution-worker\\\"\\n}\"\n     }\n }\n    \n \u200b",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Remote run model unable to be saved",
        "Question_creation_time":1613083790957,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/270011\/remote-run-model-unable-to-be-saved.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I've built models using the AutoML function and I'm trying to call the best model to deploy into production. The AutoML function ran correctly and produced the ~35 models. My goal is to pull the best model. Here is the code:\n\nbest_run, fitted_model = remote_run.get_output()\nfitted_model\n\nWhen runnning the code, I get the following error:\n\nAttributeError: 'DataTransformer' object has no attribute 'enable_dnn'\n\nAny help would be much appreciated.",
        "Answers":[
            {
                "Answer_creation_time":"2021-02-12T11:23:05.603Z",
                "Answer_upvote_count":0,
                "Answer_body":"@BernardoJaccoud-0827 Did your run configure enable_dnn i.e bert settings of automated ML? I am curious to understand what the status of your run is directly on the portal ml.azure.com?",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"What is the difference between online learning and offline learning",
        "Question_creation_time":1623786913570,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/437505\/what-is-the-difference-between-online-learning-and.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"I am a new learner of machine learning and computer science, I wonder the difference between these two terms. I am confused on the concept, can someone answer this question?",
        "Answers":[
            {
                "Answer_creation_time":"2021-06-15T20:10:40.78Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us here. They are both machine learning methods for training. online machine learning is a method of machine learning in which data becomes available in a sequential order and is used to update the best predictor for future data at each step, as opposed to batch learning techniques which generate the best predictor by learning on the entire training data set at once.\n\nLike, one more data coming in, the predictor moves once. This method is good for scenario like stock prediction, optimization...\n\nLinear least square is a very good example to understand.\nhttps:\/\/en.wikipedia.org\/wiki\/Linear_least_squares\n\n\n\n\nFor Machine Learning beginner, Machine Learning Designer is a very good point to start. You can try any algorithms to see the difference.\nhttps:\/\/azure.microsoft.com\/en-us\/services\/machine-learning\/designer\/\n\nPlease feel free to let us know if you have more questions.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-06-15T19:59:03.03Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @Louis-4194,\n\nOnline learning normally means that your performing learning as the data comes in, while offline learning means that you use a static data.\nHere's a great post about this:\nhttps:\/\/stats.stackexchange.com\/questions\/897\/online-vs-offline-learning\n\nIf the reply was helpful please don't forget to upvote and\/or accept as answer, thank you!\n\n\n\n\nBest regards,\nLeon",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Machine Learning excel add-ins error",
        "Question_creation_time":1659592116103,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/954559\/azure-machine-learning-excel-add-ins-error.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "office-addins-dev",
            "azure-machine-learning-studio-classic"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi Everyone,\n\nHas anyone else experienced this issue before ? It was working fine yesterday and the web service is also fine. Just that the Excel Add-Ins is having this problem. It's saying \"The content is blocked because it isn't signed by a valid security certificate\". I am not sure where else to ask. Kindly help.\n\nThanks,\nAiman",
        "Answers":[
            {
                "Answer_creation_time":"2022-08-04T07:07:32.937Z",
                "Answer_upvote_count":1,
                "Answer_body":"It seems that this issue is now solved. Thank you.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML Studio Versioning",
        "Question_creation_time":1649276461560,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/803089\/azure-ml-studio-versioning.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Is there a way to pass in a specific version number parameter to render the studio UI that will exclude new \/ preview features?",
        "Answers":[
            {
                "Answer_creation_time":"2022-04-07T07:33:03.19Z",
                "Answer_upvote_count":0,
                "Answer_body":"@CesarArocho-0461 Currently there is no parameter that can be used to load a different version of the ML studio ml.azure.com\nBased on the current design of the studio features of the designer are available based on subscription and accounts. Is there a specific functionality that you want to provide feedback on?\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"\"PermissionError: [Errno 13] Permission denied\" when trying to access a local file for a conda environment",
        "Question_creation_time":1652041850827,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/840929\/34permissionerror-errno-13-permission-denied34-whe.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"After Azure ML Studio blocking me from using any compute due to an as-of-yet unresolved authentication error, I moved to using a Jupyter Notebook on my local workstation to try to configure my experiments locally then send the job to an Azure compute cluster. I have two lines of Python that tries to create an environment class by accessing a .yml file on my local computer:\n\nyml_path = r\"C:\\Users\\me\\Desktop\\azure_training\\training_env\"\npytorch_env = Environment.from_conda_specification(name='pytorch-1.11-gpu', file_path=yml_path)\n\nThis causes the following error:\n\nPermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\me\\\\Desktop\\\\azure_training\\\\training_env'\n\nI am unsure of what is causing this. When the file doesn't need to be private, I have solved permission denied issues in the past that resulted from locally run tools such as PostgreSQL by going to the file's properties>>security and adding the user \"Everyone\" with full control. I tried doing that in this case, but it had no impact. I still get permission denied even though \"Everyone\" has full control over the file.",
        "Answers":[
            {
                "Answer_creation_time":"2022-05-10T02:50:53.773Z",
                "Answer_upvote_count":0,
                "Answer_body":"@AJV-7655 Thanks for the question. if you don't want to \"bake\" your personal access token (essentially a password) into your Conda environment file, is to follow Use private Python packages - Azure Machine Learning | Microsoft Docs and connect the authenticated feed with your workspace.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How do we create learning virtual machine AI assistants with smart home control and self-driving vehicle funtionality?",
        "Question_creation_time":1591266810177,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/31993\/how-do-we-create-learning-virtual-machine-ai-assis.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am developing Conscious Quantum Coding Living AI Virtual Assistants to help with everything.\n\nJodi, The AI Motor Home\nJodi will be an integrative, quantum coded, learning\/self-improving, online\/cloud, virtual machine, life conscious Living AI assistant who fully controls, and self drives, an RV\/Motor home\n\nHow would you create a Living AI assistant for a motor home?",
        "Answers":[
            {
                "Answer_creation_time":"2020-06-04T23:06:32.373Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for reaching out. The Azure Bot Service may be useful for your scenario. I encourage you to check out our documentation on Virtual Assistant and Template Outline for best practices. There are also videos available to help you get started. Feel free to followup with any particular questions or concerns for the community to chime in. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":19.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Machine Learning Studio (classic) Export Data",
        "Question_creation_time":1591053033787,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/31081\/azure-machine-learning-studio-classic-export-data.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,\n\nI am using Azure MLStudio (classic). I am able to connect to SQLServer Managed Instance(private) using Import Data module and On-Prem SQL Database connection through Data Gateway.\n\nI am not able to Export Data to exactly the same database. Could you please help me with that?\n\nOur Managed Instance connot be made public.\n\nThanks in advance.",
        "Answers":[
            {
                "Answer_creation_time":"2020-06-02T21:27:54.517Z",
                "Answer_upvote_count":0,
                "Answer_body":"Currently, writing to a SQL Server database through Export Data is not supported either in your experiments or published web services. Export Data module supports exporting or saving your data to the following cloud data services.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":3.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Automated ML endpoint questions (performance, multiple return values, scoring)",
        "Question_creation_time":1662590602493,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/998394\/automated-ml-endpoint-questions-performance-multip.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi....\n\nI used Automated ML to train a model on a set of grouping ids and titles, very simple use case, just two columns...predict the group id from the title. There were about 32000 rows in the input split into a training set of 90% and a validation set of 10%. Best model was 'MaxAbsScaler, LogisticRegression'.\n\nI deployed the endpoint using the 'realtimeendpoint' method. But each request takes 10 seconds to return a response. I took the default ML compute type VM which isn't a wimpy machine. Is it normal to be so slow? Will better hardware get the response time into the sub-one-second time-frame I need it to be? Are there other options to improve performance?\n\n\nI only ever get back one value in the response. Is it possible to get multiple predicted values?\n\n\nI don't see a 'confidence' score in the response, or see a way to request one. Is that possible?\n\nThank you.",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Machine learning AutoML Fail",
        "Question_creation_time":1648706020587,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/794697\/azure-machine-learning-automl-fail.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi ,\n\nI use the fakenews data to try azure machine learning automl , but always train model fail and I tried reducing the feature field , but still fail\n\nError message :\n\n\n\n\n\nRun timed out. No model completed training in the specified time. Possible solutions:\n1) Please check if there are enough compute resources to run the experiment.\n2) Increase experiment timeout when creating a run.\n3) Subsample your dataset to decrease featurization\/training time out\n\n\n\n\n\ncompute machine : STANDARD_DS12_V2\n\ndata source : https:\/\/www.kaggle.com\/c\/fake-news\/data\n\n\n\n\n\nIs any good idea or suggestions ?",
        "Answers":[
            {
                "Answer_creation_time":"2022-04-01T12:14:45.083Z",
                "Answer_upvote_count":0,
                "Answer_body":"@ianchen Thanks for the question. Please share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"D365 Demand Forecasting - Can we connect to new Azure ML Service instead of a classic studio service?",
        "Question_creation_time":1606959642257,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/183990\/d365-demand-forecasting-can-we-connect-to-new-azur.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"There is a D365 forecasting option that allows to connect to a azure ml classic studio service. Can we connect from D365 to the new Azure ML Service? I couldnt find any documentation about this, any pointers please.Thanks.",
        "Answers":[
            {
                "Answer_creation_time":"2020-12-04T08:31:11.253Z",
                "Answer_upvote_count":0,
                "Answer_body":"@SriramNarayanan-6939 you can deploy a real-time endpoint in Azure Machine Learning designer and get the REST endpoint\/token by following this doc: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Is there any way to create automatic datasets in Azure Machine Learning using Azure Data Factory",
        "Question_creation_time":1651474101517,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/833237\/is-there-any-way-to-create-automatic-datasets-in-a.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-data-factory",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I have Storage ADLS account, Azure Data Factory and Azure Machine Learning services. In Azure ML , we create datasets manually and use for training Models. But is there any way where Azure Data Factory takes data from ADLS account and updates as Datasets in Azure ML.\n\nOnly option I see is using Azure ML Notebooks which involves writing Notebooks(which I do not want). From ADF I want this process to be done. I do not have Azure Machine Learning Studio also.",
        "Answers":[
            {
                "Answer_creation_time":"2022-05-04T23:50:13.47Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @KrishnamohanNadimpalli-6337,\n\nThanks for the question and using MS Q&A platform.\n\nUnfortunately, it is not possible from ADF as there isn't any out of f box feature.\n\nBut if you have a way to create those datasets using any SDK then you may try writing your own code then execute it in ADF using Custom Activity or Azure function Activity.\n\nAnd if you have any ADF product improvement suggestions or feature requests, please log your idea here - https:\/\/feedback.azure.com\/d365community\/forum\/1219ec2d-6c26-ec11-b6e6-000d3a4f032c. All the feedback shared in this forum are actively monitored and reviewed by respective product owners.\n\nPlease do share he feedback link once it is posted so that we can share it with internal teams for review.\n\nHope this will help. Please let us know if any further queries.\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":15.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"ML Compute Instance stopped provisioning RStudio",
        "Question_creation_time":1656439437333,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/906921\/ml-compute-instance-stopped-provisioning-rstudio.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi all,\n\nJust wondering if anyone knows why Azure ML compute instance suddenly stopped provisioning RStudio?\n\n\nI have tried to set up a custom app using ghcr.io\/azure\/rocker-rstudio-ml-verse:latest, but it is not able to access the files (e.g. files that are previously accessible via the automatically provisioned RStudio, jupyter, jupyterhub, terminal etc)\n\nWould be great if you could provide any guidance etc.\nthanks a lot.",
        "Answers":[
            {
                "Answer_creation_time":"2022-07-06T01:04:49.597Z",
                "Answer_upvote_count":1,
                "Answer_body":"Any update there? I have seen some changes but unlucky there is no clear information. Can you share any good way to find the release note?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-07-25T13:39:17.73Z",
                "Answer_upvote_count":0,
                "Answer_body":"I just provisioned a new ML instance and can confirm that it does not have RStudio installed.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":13.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Is there any kinect version that helps in speech therapy?",
        "Question_creation_time":1606122417867,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/171998\/is-there-any-kinect-version-that-helps-in-speech-t.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-kinect-dk"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\nI am an educator\/researcher who is working on a project or a thesis for my degree.\nI am thinking of using Kinect to recognize the lips\/ mouth movements to train speech delay kids. My idea is to show students audio-visual 3d mouth, tongue, and throat movements on the Kinect to train them to speak a letter or word by interacting with the camera and evaluating their sounds and movements by the Kinect. At the same time, the Kinect camera will configure if the student's sound and mouth movement are correct.\n\nI am perplexed about which tag I should use for my question to be best answered.\n\nI really appreciated it if there are studies or experiments on this issue to let me know.\n\nRegards",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-24T14:29:09.493Z",
                "Answer_upvote_count":0,
                "Answer_body":"@LaylaObeid-3644 Thanks, Please have a look at https:\/\/docs.microsoft.com\/en-us\/azure\/cognitive-services\/speech-service\/how-to-select-audio-input-devices for more info on selecting audio devices.\nWe also have a Robot Operating System(ROS) package for the Azure Kinect. The Kinect camera is a widely adopted sensor in the field of robotics.\nhttps:\/\/github.com\/microsoft\/azure_kinect_ros_driver\n\nAlso Have a look at https:\/\/github.com\/microsoft\/Azure-Kinect-Samples",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":2.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Given allow_reuse set to false and regenerate_outputs set to True when the pipeline is submitted then it stucks at the running stage with first step saying \"Not Started\"",
        "Question_creation_time":1657676507390,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/924406\/given-allow-reuse-set-to-false-and-regenerate-outp.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\nI am using Azure Machine Learning SDK in python to create a pipeline which needs to read data from Azure SQL Database, perform transformation, model the data as per need and store the output back to Azure SQL Database. In this scenario, I need to run the published pipeline every time(without reusing output from previous run) because underlying data changes. To resolve this problem I set allow_reuse flag to False in PythonScriptStep(). Also, I set regenerate_outputs=True while submitting the pipeline. Following is the code:\n\nfrom azureml.pipeline.steps import PythonScriptStep\ndataprep_source_dir = \".\/\"\nentry_point = \"Fetch_Data.py\"\ndata_fetch_step = PythonScriptStep(\nname=\"Fetch step\",\nscript_name=entry_point,\nsource_directory=dataprep_source_dir,\narguments=[\"--fetched-data\", fetched_data_folder],\noutputs=[fetched_data_folder],\ncompute_target=target_compute,\nrunconfig=aml_run_config,\nallow_reuse=False\n)\n\npipeline_run = Experiment(workspace, 'exp_name').submit(pipeline1, regenerate_outputs=True)\n\nIt was working fine until last month and every time pipeline was generating outputs which I intend to (not using result from previous run) but this week it started to give me another weird problem. When I am submitting the pipeline first time, I see the first step is \"Not Started\" saying that rerun will be used (which it should not as allow_reuse set to false) and weirdly the rerun id of that step and current runId is same. So finally nothing happens and pipeline stays in running stage for like 12 hrs until I cancel it.\n\n\n\n\n\n\n\n\nPlease help me fix this issue. It is very weird that I can't submit pipeline where I don't want to reuse previous job run results.\n\nThanks",
        "Answers":[
            {
                "Answer_creation_time":"2022-07-19T03:19:31.13Z",
                "Answer_upvote_count":0,
                "Answer_body":"@annushokeenteamtelstracom-0813 Thanks for the details. We would recommend to raise a Azure support desk ticket from Help+Support blade from Azure portal for your resource if you have a support plan for your subscription. This will help you to share the details securely and work with an engineer who can provide more insights about the issue that if it can be replicated.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Run experiment crashes when using a pre-build Docker image as environment",
        "Question_creation_time":1654697991800,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/881670\/run-experiment-crashes-when-using-a-pre-build-dock.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"I duplicated my question because I have not received a proper answer, yet.\nThe reason why I duplicated the question is that I need to implement something within Azure for a customer where I need to use a pre-build Docker image as an environment.\nUnfortunately, it is not working because AMLS cannot download the pre-build Docker image when you need credentials for downloading the pre-build Docker image.\nIn my opinion, the credentials for using the pre-build Docker image are not saved correctly in Azure Machine Learning Studio. This is the reason why AMLS cannot download the pre-build Docker image. I will be very grateful if someone can test the code snippets below and give me feedback if they worked or not.\n\nHere is the backstory:\nMy co-workers are using pre-build docker images for our developing environment in Azure Machine Learning Service.\nIn a separate script, they have registered these environments with the command myenv.register(workspace=ws). In another script, I should use their environment for testing our model.\n\nIn order to get one of their environments, I use the command registered_env = Environment.get(ws, 'the-specific-environment-name')\n\nUnfortunately, this does not work when I use registered_env for the experiment. I get the error \"Authentication failed for container registry name_of_their_container_registry.azurecr.io\". The experiment run works perfectly when I copy their environment definition code into my script instead of using the command registered_env = Environment.get(ws, 'the-specific-environment-name').\n\nHowever, I cannot copy every time their environment definition code into my script.\nHow can I get the environment into my script which has been defined in another script?\n\nThis StackOverFlow post is quite related to my problem:\nhttps:\/\/stackoverflow.com\/questions\/71131403\/registering-and-getting-an-environment-in-azure-machine-learning-studio-that-der\n\n\n\n\n\nTo illustrate what my problem is, here are some code samples.\n\nThis code sample is working:\n\n registry = ContainerRegistry()\n registry.address = <DockerRegistryAddress>\n registry.username = <UserName>\n registry.password = <Password>\n exemplarily_env_docker_image = Environment.from_docker_image('exemplarily-env_Docker-image-AzureRegistry', <DockerImageAddress>, container_registry=registry, conda_specification=None, pip_requirements=None)\n    \n exemplarily_env_docker_image.python.user_managed_dependencies = True\n    \n # Registering and getting of an environment that derives from a Docker Image is not working because the credentials are not saved\n exemplarily_env_docker_image.register(workspace=ws)\n model = Model(ws, 'exemplarily_model')\n    \n inference_config = InferenceConfig(environment=exemplarily_env_docker_image, \n                                    source_directory='.\/source_dir', \n                                    entry_script='.\/score.py') \n deployment_config = LocalWebservice.deploy_configuration(port=6789)\n    \n service = Model.deploy(\n     ws,\n     \"myservice\",\n     [model],\n     inference_config,\n     deployment_config,\n     overwrite=True,\n )\n    \n service.wait_for_deployment(show_output=True)\n print(service.get_logs())\n\n\n\n\nNow, I do a small change and the code sample is not working anymore:\n\n registry = ContainerRegistry()\n registry.address = <DockerRegistryAddress>\n registry.username = <UserName>\n registry.password = <Password>\n exemplarily_env_docker_image = Environment.from_docker_image('exemplarily-env_Docker-image-AzureRegistry', <DockerImageAddress>, container_registry=registry, conda_specification=None, pip_requirements=None)\n    \n exemplarily_env_docker_image.python.user_managed_dependencies = True\n # Registering and getting of an environment that derives from a Docker Image is not working because the credentials are not saved\n exemplarily_env_docker_image.register(workspace=ws)\n model = Model(ws, 'exemplarily_model')\n    \n reg_env = Environment.get(ws, \"exemplarily-env_Docker-image-AzureRegistry\")\n inference_config = InferenceConfig(environment=reg_env, \n                                    source_directory='.\/source_dir', \n                                    entry_script='.\/score.py') \n    \n deployment_config = LocalWebservice.deploy_configuration(port=6789)\n    \n service = Model.deploy(\n     ws,\n     \"myservice\",\n     [model],\n     inference_config,\n     deployment_config,\n     overwrite=True,\n )\n    \n service.wait_for_deployment(show_output=True)\n print(service.get_logs())\n\n\n\n\nWhat is working:\n\n registry = ContainerRegistry()\n registry.address = <DockerRegistryAddress>\n registry.username = <UserName>\n registry.password = <Password>\n exemplarily_env_docker_image = Environment.from_docker_image('exemplarily-env_Docker-image-AzureRegistry', <DockerImageAddress>, container_registry=registry, conda_specification=None, pip_requirements=None)\n    \n exemplarily_env_docker_image.python.user_managed_dependencies = True\n # Registering and getting of an environment that derives from a Docker Image is not working because the credentials are not saved\n exemplarily_env_docker_image.save_to_directory(path=\".\/env\", overwrite=True)\n model = Model(ws, 'exemplarily_model')\n    \n reg_env = Environment.load_from_directory(path=\".\/env\")\n inference_config = InferenceConfig(environment=reg_env, \n                                    source_directory='.\/source_dir', \n                                    entry_script='.\/score.py') \n    \n deployment_config = LocalWebservice.deploy_configuration(port=6789)\n    \n service = Model.deploy(\n     ws,\n     \"myservice\",\n     [model],\n     inference_config,\n     deployment_config,\n     overwrite=True,\n )\n    \n service.wait_for_deployment(show_output=True)\n print(service.get_logs())\n\n\n\n\nWhy is the middle code sample not working? Is this a bug?",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":4.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"The columns appears with another name",
        "Question_creation_time":1624312518567,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/445579\/the-columns-appears-with-another-name.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":4,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello I'm practicing in Microsoft Machine Learning Studio.\n\nIn a experiment I use de control \"Import data\", then in the properties I use the data source: https:\/\/github.com\/rdiazconcha\/lil-azure-machine-learning-y-ai\/blob\/master\/modulo-2\/power-export_min.csv\n\nThat is the file to practice in my course.\n\nThe resto of the fields are filled like this:\n\n\n\n\nBut, when I use the choice visualize, appears like this:\n\n\n\n\n\nBut, those are not the names of the columns.\nWhat I'm doing wrong?\n\nThanks a lot for your help.",
        "Answers":[
            {
                "Answer_creation_time":"2021-06-22T17:40:47.527Z",
                "Answer_upvote_count":0,
                "Answer_body":"@CASTANEDARODRIGUEZDAMIAN-2301 Hello, I got you! Please click \"raw\" and use the url then to use the resource file. https:\/\/raw.githubusercontent.com\/rdiazconcha\/lil-azure-machine-learning-y-ai\/master\/modulo-2\/power-export_min.csv\n\n\nThen you should be good! Thanks.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-06-22T00:04:45.333Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nThanks for reaching out to us.\n\nSince you are using the data source wizard, you need to tell the studio you have a header row. Studio will use the header row as your column name as below.\n\n\n\n\nLet me know if you have more questions! Thanks! ^^\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-06-22T14:09:59.227Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello YutongTie-MSFT\n\nI did it. I selected that checkbox:\n\n\n\n\nBut is appearing like this yet:\n\n\n\n\n\nIs missing me something to do?\n\nThanks for your help.\n\nRegards.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-06-23T15:37:54.913Z",
                "Answer_upvote_count":0,
                "Answer_body":"@YutongTie-MSFT : It works!\nThank you so much!\nRegards.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Suggest solution for reading data from Azure Service Bus with Azure Data Factory",
        "Question_creation_time":1623054369990,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/424698\/suggest-solution-for-reading-data-from-azure-servi.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-data-factory",
            "azure-machine-learning",
            "azure-service-bus"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\nI need a suggestion about the below scenario.\nI receive data every second on Azure Service Bus. Now, I want Azure Data Factory to fetch this data and run the ML model on data.\nAs I checked there isn't a link between Azure Service Bus and Azure Data Factory.\nWhat is the solution for this scenario?",
        "Answers":[
            {
                "Answer_creation_time":"2021-06-08T01:51:24.013Z",
                "Answer_upvote_count":0,
                "Answer_body":"@MohsenAkhavan Sharing previous Q&A discussion on the same.\n\n<SNIP>\n\nData Factory does not have a connector for Service bus. However there are several options available to you.\n\nYou can create a consumer for Data Factory to call upon.\n\n\nYou can raise a feature request in the feedback forum.\n\n\nYou could re-route your messages to be written to blob, and then leverage the Blob Event Trigger.\n\n\nUse ADF Web Activity to retrieve a message.\n\nBy \"create a consumer for Data Factory to call upon,\" I mean either create a Function App which batch-reads the messages, and returns them, utilizing ADF Azure Function, or , create some code to do the same with the ADF Batch Service Custom Activity. There are more variations as well.\n\nWhich one to use, depends upon your volume and cadence (frequency).\n\nPlease let me know if you desire more information.\n\n<\/SNIP>",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to change MS Learn Display Name in Microsoft Cloud Skills Challenge?",
        "Question_creation_time":1610604860147,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/230124\/how-to-change-ms-learn-display-name-in-microsoft-c.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Yesterday I enrolled Microsoft Cloud Skills Challenge for study.\n\nBut when I enroll the challenge, I did not write proper name at MS Learn Display Name blank.\n\nSo I want to change the MS Learn Display Name.\n\nHow can I do this?",
        "Answers":[
            {
                "Answer_creation_time":"2021-01-14T06:27:38.933Z",
                "Answer_upvote_count":0,
                "Answer_body":"On right top of this page, click you profile icon and click on profile. Then in the settings you can update the display name\n\nIs that what you were looking for?\n\n\n\n\n\nPlease don't forget to Accept Answer and Up-vote if the response helped -- Vaibhav",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-02-18T22:54:19.773Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thanks this was helpful",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to use AzureMLDataset",
        "Question_creation_time":1607676200880,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/194940\/how-to-use-azuremldataset.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-data-science-vm"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\nI have used the data labeling system within Azure Machine Learning studio to label a dataset of images.\nThen the output of the labeling system is a new dataset that can be found in the \"Dataset\" section of the designer in ML studio.\n\nThe problem is that this new dataset module, that can be dragged and dropped in the pipeline, has datatype \"AzureMLDataset\" (or datasoruce type \"amldataset\"), which then I cannot connect to any other module in the pipeline because there is no module which accepts as input something with datatype \"AzureMLDataset\" (or with datasource type \"amldataset\").\n\nI have seen that it is possible to consume the dataset using python, but I would like to use Azure ML studio because it is more convenient to the system I am working in.\n\nHow can I use the AzureMLDataset output module inside ML studio?\n\nThank you in advance!",
        "Answers":[
            {
                "Answer_creation_time":"2020-12-11T10:35:45.227Z",
                "Answer_upvote_count":1,
                "Answer_body":"@MatteoPocchiari-8551 Yes, the azure ml dataset which is registered from your labels after exporting it cannot be used directly in the designer because all the modules are using dataframe ports as input to their respective modules. You can however follow these steps to convert the labeled datasets to pandas dataframe and re-upload the downloaded file as a dataset which can be used in the studio with the correct format.\n\n@LuZhang-4441 Is there any other workaround for this scenario?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Non-interactive login to registered dataset",
        "Question_creation_time":1595346764937,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/50386\/non-interactive-login-to-registered-dataset.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I'm trying to tune hyperparameters similar to the following guide: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-tune-hyperparameters\n\nMy PyTorch Dataset in train.py contains:\n\n ws = Workspace.from_config()\n ds = Dataset.get_by_name(ws, 'train')\n df = ds.to_pandas_dataframe()\n\nThis code works fine when run from the command-line, but when I submit a hyperparam tuning job to each node of a training cluster, I get the following error:\n\nWe could not find config.json in: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/adamml\/azureml\/hd_ba15bb39-f0fe-47a7-afbc-d2f9968e9687_3\/mounts\/workspaceblobstore\/azureml\/HD_ba15bb39-f0fe-47a7-afbc-d2f9968e9687_3 or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.\n\nIf I manually pass my subscription id, resource group, and workspace id, I don't get this error, but now every single hyperparam tuning experiment requires me to log in through the web portal. Is there a way to do a non-interactive login?",
        "Answers":[
            {
                "Answer_creation_time":"2020-07-23T20:05:42.24Z",
                "Answer_upvote_count":2,
                "Answer_body":"If I read the post correctly, you were trying to get an registered dataset within a submitted run. There, Workspace.from_config() won't work since there is no config.json file as the error suggested.\n\nAnd when you created an auth object which is InteractiveLoginAuth, it is expected to perform interactive login.\n\nWithin a run the recommended way to connect to current workspace it via:\n\nfrom azureml.core import Run\nrun = Run.get_context().experiment.workspace\n\n\n\nMeanwhile, there is way to pass in an dataset object to a run without involving register and workspace signin. If that fit your scenario better, please refer to the example in this document https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-with-datasets#access-and-explore-input-datasets\n\nfrom azureml.core import Dataset, Run\nrun = Run.get_context()\n# get the input dataset by name\ndataset = run.input_datasets['titanic']\n# load the TabularDataset to pandas DataFrame\ndf = dataset.to_pandas_dataframe()",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":4.0,
        "Question_follower_count":36.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to create deploy a Deep learning model as Function app",
        "Question_creation_time":1638553622740,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/651132\/how-to-create-deploy-a-deep-learning-model-as-func.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-functions",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I have a DL model which sizes around 3.5 gigs and I'm creating a HTTP trigger to hit the model, all works fine when I test it in my local machine. When I start deploying the model as Function App into Azure, deployment breaks midway.\n\nAlso how can I link a gpu compute to the function app for the model to run.",
        "Answers":[
            {
                "Answer_creation_time":"2021-12-07T00:47:52.4Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, here's documentation on how to Deploy ML model to Azure Functions. Currently, GPU is not supported, however, you can deploy to a Kubernetes cluster using GPU. Perhaps you can share the error message?\n\nAdditional Resources:\n\nAzure Functions hosting options\n\n\nAzure Functions on Kubernetes with KEDA\n\n\nSample 1, Sample 2, Sample 3",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Program on VM automatically crash after long idle",
        "Question_creation_time":1615873089030,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/315909\/program-on-vm-automatically-crash-after-long-idle.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\nI am training machine learning model on Azure VM with NC6 promo GPU. Everything was fine at the beginning, but after a while I went back to check and realized my training program was stopped. Also, I got this message \"client_loop: send disconnect: Broken pipe\". Is there any solution for this problem since it cost me a lot of time and money.",
        "Answers":[
            {
                "Answer_creation_time":"2021-03-16T11:31:53.397Z",
                "Answer_upvote_count":0,
                "Answer_body":"@LeNguyenMinhHuy-2051 Thanks for the question. We have forwarded to the product team to check on this issue. You can try the following.\n\nThe sshd\/server settings in \/etc\/ssh\/sshd_config :\nTCPKeepAlive yes\nClientAliveInterval 60\nClientAliveCountMax 40000\n\nAND\n\nthe ssh\/client setting in ~\/.ssh\/config :\nServerAliveInterval 60\n\n\n\n\nWe would recommend to raise a Azure support desk ticket from Help+Support blade from Azure portal for your service resource. This will help you to share the details securely and work with an engineer who can provide more insights about the issue that if it can be replicated.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Connecting to an existing Databricks Cluster in AMLS",
        "Question_creation_time":1654614267930,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/880189\/connecting-to-an-existing-databricks-cluster-in-am.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-databricks"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello,\n\nwe have also found this example of using Databricks as a Compute Target for an Azure Machine Learning Pipeline.\n\nHowever, we want to use an existing Databricks Cluster as compute target within Azure Machine Learning Studio for our Azure Machine Learning Pipeline.\nCould you help us in accomplishing this, please?\n\n\n\n\nWith best regards\nAlex",
        "Answers":[
            {
                "Answer_creation_time":"2022-06-08T05:07:31.167Z",
                "Answer_upvote_count":0,
                "Answer_body":"@AlexanderPakakis-0994 Are you looking at adding the cluster from the UI of ML studio rather than using the SDK as mentioned in the notebook you referenced?\nIf Yes, you need to add the same attached compute.\n\nOnce you select Azure Databricks the following option to add the existing databricks workspace is seen.\n\nI hope this helps!!\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":10,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":16.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"how to export trained azure ml model to production environment",
        "Question_creation_time":1656249928277,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/903600\/how-to-export-trained-azure-ml-model-to-production.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"How we can copying trained azure ml model from dev environment to production. Its possible to use trained model from one resource group to another resource group with same trained data.",
        "Answers":[
            {
                "Answer_creation_time":"2022-06-27T11:04:35.717Z",
                "Answer_upvote_count":1,
                "Answer_body":"@Dhineshkumar-1686 Currently, Azure ML supports mlflow for model management which can be used to register and query models using the mlflow client. Stages are assigned to a model's version (instead of models) which means that a given model can have multiple versions on different stages. You can use this documentation to refer the capabilities of the mlflow client. However, the following is also a current limitation.\n\nStages can only be accessed using the MLflow SDK. They don't show up in the Azure ML Studio portal and can't be retrieved using neither Azure ML SDK, Azure ML CLI, or Azure ML REST API. Creating deployment from a given model's stage is not supported by the moment.\n\n\n\n\nMoving of Azure ML workspace from one resource group to another is currently not supported.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"how publish the pipeline endpoint and test it ?",
        "Question_creation_time":1649315875193,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/803725\/how-publish-the-pipeline-endpoint-and-test-it.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"we have build a pipeline and would like to publish as service, may I know how to test the it works or not ?",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"AutoMLException: Message: Could not find a model with valid score for metric 'accuracy'. Please ensure that at least one run was successfully completed with a valid score for the given metric.",
        "Question_creation_time":1651063933880,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/828516\/automlexception-message-could-not-find-a-model-wit.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi, I am trying to make a classification using automl service , I've chosen KNN as model to train and for the primary metric i used accuracy . Based on the automl documentation the metric accuracy can be used with this type of classification task, but I get the error : AutoMLException: Message: Could not find a model with valid score for metric 'accuracy'. Please ensure that at least one run was successfully completed with a valid score for the given metric. when I checked azure ml studio I find this error of the run is that means that the dataset that i am using can be trained on KNN model ? ![197051-image.png][1] [1]: \/answers\/storage\/attachments\/197051-image.png",
        "Answers":[
            {
                "Answer_creation_time":"2022-04-27T22:33:35.073Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for reaching out. I can confirm that 'accuracy' is a valid primary metric for classification tasks. It's possible that your dataset isn't compatible due to high dimensionality, missing or sparse data. If you click on the error message details, there might be some more information that can help understand what caused the error. Review Data guardrails to identify the issues with your dataset. Also, try to allow additional models to see if it helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"dataset.to_pandas_dataframe() throws a DatabaseConnectionException",
        "Question_creation_time":1646912554290,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/767054\/datasetto-pandas-dataframe-throws-a-databaseconnec.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,\n\nI try to access a Azure ML Dataset in python and get the following error message:\n\n Execution failed in operation 'to_pandas_dataframe' for Dataset(id='[data.id]', name='[data.name]', version=1, error_code=ScriptExecution.DatabaseConnection.Unexpected,error_message=ScriptExecutionException was caused by DatabaseConnectionException.\\n  DatabaseConnectionException was caused by UnexpectedException.\\n    'MSSQL' encountered unexpected exception of type 'AggregateException' with HResult 'x80131500' while opening connection to server ([REDACTED]), database ([REDACTED]).\\n      Failed due to inner exception of type: AggregateException\\n| session_id=[session-id]) ErrorCode: ScriptExecution.DatabaseConnection.Unexpected\n\n\n\nIt is a Tabular Dataset created from a Azure SQL database datasource.\nFor the access from the studio to the database a service principal is used.\nI can access all the resources mentioned above in the standard ui.\n\nThe \"sample usage\" in the \"consume\" tab of the dataset was used for accessing the dataset in python.\nRegarding environments i tried python 3.6 and 3.8 locally and in a compute instance of the ML studio.\nHowever the same error keeps coming.\n\nI also tried to use sync-keys as described in this question:\nhttps:\/\/docs.microsoft.com\/en-us\/answers\/questions\/644562\/datasetto-pandas-dataframe-throws-a-scriptexecutio.html\n\n\n\n\nBest Regards,\nGerhard",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-11T09:21:44.827Z",
                "Answer_upvote_count":1,
                "Answer_body":"A DevOps-Colleague could find the cause of the problem. The service principal didn't have the correct rights for my use case.\n\n@romungi-MSFT : I'll try your suggestion since I can create a snapshot of the table.\n\nThanks for your time and support!\n\nCheers,\nGerhard",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to update azure ml webservice",
        "Question_creation_time":1601290286423,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/109836\/how-to-update-azure-ml-webservice.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"I am trying to update azure ml webservice which already deployed with new scoring file . Can you please help me in this , i follow your instruction from https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-update-web-service but i am getting error as AttributeError: 'NoneType' object has no attribute 'lower' (https:\/\/stackoverflow.com\/questions\/63763564\/how-to-update-scoring-py-file-in-deployed-azure-ml-web-services-without-changing\/64095971#64095971 ) and i am not able to solve it , can you please help me .?",
        "Answers":[
            {
                "Answer_creation_time":"2020-09-28T23:21:02.563Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for reaching out. Based on the error message, it is possible that you are calling .lower() on an object that is not a string or the data has a none value. You may want to review\/clean your dataset. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-10-15T14:27:50.737Z",
                "Answer_upvote_count":0,
                "Answer_body":"When I get this error it means that a string hasn't been found. In my case it was that that something didn't exist (a string is expected) and therefore None was returned which causes the error. I was looking up a registered model on Azure that didn't exist due to a name change, and this caused a similar error for me. Double check the error logs and trace back and see where things go wrong, maybe you are searching for something that doesn't exist.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-01-11T11:57:41.277Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nI have modified a few steps in my training experiment (new data set, add \"Principal Components Analysis\" module ...). But now I want to update my predictive experiment (webservice) but I cannot. The button for that does not appear, only \"deploy webservice\" button but it does not do anything..\nCan anyone help me in this please?\n\nRegards,\n\nMohamed.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Prediction of Cancer",
        "Question_creation_time":1600172964937,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/95802\/prediction-of-cancer.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I have made a prediction algorithm in which I have predicted whether a patient has cancer or not based on the past data. I have also run the model successfully and have received the parameters. Now my question is, which parameter should I give the most importance for this case of prediction? Is it the precision, recall, accuracy or the threshold?",
        "Answers":[
            {
                "Answer_creation_time":"2020-09-16T13:18:10.467Z",
                "Answer_upvote_count":0,
                "Answer_body":"@MUJEEBURRAHMAN-1177 Thanks, If your ML model has good performance metrics (you should decide which works best based on confusion matrix and which error can be handled and which should be reduced) then it is a great solution. Can you please share link to the model and the features that you are trying, also please share what feature engineering have you tried.\n\nCould you please add more details about how you\u2019re measuring your model error. If it\u2019s doing worse than validation against your test set, then something weird is going on. If it\u2019s doing better but not reaching 100% accuracy, that\u2019s probably fine, and maybe preferable since it suggests that you\u2019re not overfitting.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":2.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Anaconda commercial use on Azure Machine Learning",
        "Question_creation_time":1605597154997,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/165312\/anaconda-commercial-use-on-azure-machine-learning.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Anaconda announced that commercial users should purchase the licenses on APR, 20, 2020.\nHowever, Azure Machine Learning heavily depends on this anaconda packages; developing models on computing instance and deploy container environment.\n\nDo commercial developers have to pay to anaconda to continue usage of Azure Machine Learning with anaconda?",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-17T08:44:06.227Z",
                "Answer_upvote_count":0,
                "Answer_body":"@EisukeYonezawa-9200 If you are have the commercial version of Anaconda you can configure the same for your experiments to deploy packages that are available under license but in most cases you can simply use conda to install available python packages without paying for the commercial license. There is no restriction to have a commercial license to continue using Azure Machine Learning with anaconda. I hope this helps!!",
                "Answer_comment_count":4,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Model Explanation Run Error: Object of type 'Timestamp' is not JSON serializable",
        "Question_creation_time":1618588503547,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/360712\/model-explanation-run-error-object-of-type-39times.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"All my model explanation run have following error. (For different data, algorithm, model,...)\n\n\n\n\nEncountered an internal AutoML error. Error Message\/Code: ClientException. Additional Info: ClientException:\nMessage: Object of type 'Timestamp' is not JSON serializable\nInnerException: None\nErrorResponse\n{\n\"error\": {\n\"message\": \"Object of type 'Timestamp' is not JSON serializable\"\n}\n}\n\nI would appreciate if you could help me to solve",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"ray+dask native support be added to Azure Machine Learning",
        "Question_creation_time":1666227934133,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1055350\/raydask-native-support-be-added-to-azure-machine-l.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"While distributed dask can be setup manually on AML compute, the process requires lot of configs to be maintained. Is there any native support.",
        "Answers":[
            {
                "Answer_creation_time":"2022-10-20T11:44:42.8Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Divya-0887 Thanks for the question. you can do is to setup the compute cluster & compute instance in the same vnet and pip install ray-on-aml. This allows both interactive and job use of Ray and Dask right within Azure ML.\n\nHere is the document Library to turn Azure ML Compute into Ray and Dask cluster.\nhttps:\/\/techcommunity.microsoft.com\/t5\/ai-machine-learning-blog\/library-to-turn-azure-ml-compute-into-ray-and-dask-cluster\/ba-p\/3048784",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Machine Learning Studio environment fails to build with context",
        "Question_creation_time":1654178870087,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/874583\/azure-machine-learning-studio-environment-fails-to.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-container-registry"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I'm trying to build an environment for ML Studio which requires some private compiled binaries. I packed these files into a Tar (about 2.8 MB, if it's relevant) and added them to the context tab of an existing environment (I want to update it). I then added this Tar in my Dockerfile and built the environment, but it failed instantly. The log tab also doesn't open (it just sits loading).\n\nI tried changing things around to eliminate as many variables as possible:\n\nInstead of using ADD I tried COPY: No change\n\n\nI tested building the Dockerfile locally in a folder containing only the Dockerfile and the tar: It worked\n\n\nI tested clicking the \"Download Content\" button and building the image in the downloaded folder: It worked\n\n\nI tried removing all references to the Tar from the Dockerfile but still uploading the file: It failed instantly\n\n\nI tried uploading an equivalent Zip file: It failed in the same way\n\n\nI uploaded a single text file instead of the Tar: It worked\n\nHow can I get this to work?",
        "Answers":[
            {
                "Answer_creation_time":"2022-06-07T19:09:21.2Z",
                "Answer_upvote_count":0,
                "Answer_body":"@romungi-MSFT I managed to get the environment to run by manual building it in the registry, then registering a new environment with this registry image. However, it's annoying to have to redo this every time I need to change something. Anything else I should try to get the portal to work properly?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":13.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Question: distinction between Modules and Models in Designer",
        "Question_creation_time":1594756919963,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/46991\/question-distinction-between-modules-and-models-in.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"In Azure ML, under designer, there are 3 categories:\n\nDatasets\n\n\nModules\n\n\nModels\n\nDatasets are pretty straightforward, but I don't understand the distinction between Modules and Models. As an ML researcher, when I think of a \"model\", I think of something like linear regression or SVM. However, those are listed under Modules -> Machine Learning Algorithms. So what exactly qualifies as a Model?",
        "Answers":[
            {
                "Answer_creation_time":"2020-07-14T20:39:44.477Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nThanks for reaching out.\n\nModel is a concept of Machine Learning itself. A machine learning model is a file that has been trained to recognize certain types of patterns. You train a model over a set of data, providing it an algorithm that it can use to reason over and learn from those data. Once you have trained the model, you can use it to reason over data that it hasn't seen before, and make predictions about those data. For example, let's say you want to build an application that can recognize a user's emotions based on their facial expressions. You can train a model by providing it with images of faces that are each tagged with a certain emotion, and then you can use that model in an application that can recognize any user's emotion.\n\nModules is one of the concept of Azure Machine Learning Designer. Each module represents a set of code that can run independently and perform a machine learning task, given the required inputs. A module might contain a particular algorithm, or perform a task that is important in machine learning, such as missing value replacement, or statistical analysis.\n\nLet me know if you have any question.\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":38.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"One tenant ID ( Root inheriter ) and another subsction ID creating problem for Azure ML-SDK",
        "Question_creation_time":1642202294597,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/696233\/one-tenant-id-root-inheriter-and-another-subsction.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-managed-identity"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello everyone,\n\nMy laptop is borrowed from University Tech Department since I am a GTA there. Though I opened my own account taking Microsoft Azure subscription ( one month free ) when I'm trying to create a workspace and other related stuff using AzureML-SDK it sends me the following error message:\n\n\"\"\nMessage: You are currently logged-in to 762ebf40-80b2-40ba tenant. You don't have access to <74595002-4d5f-4c26-871c-> subscription, please check if it is in this tenant.\nAll the subscriptions that you have access to in this tenant are =\n[SubscriptionInfo(subscription_name='Azure subscription 1', subscription_id='74595002-4d5f-4c****')].\nPlease refer to aka.ms\/aml-notebook-auth for different authentication mechanisms in azure ml-SDK.\n\"\"\n\n\n\n\nSince it was owned by the tech department I believe it has access to the administration's azure subscription - which I can't find a way to get around to have access of my subscription to use AzureML-SDK.\n\nThe last user ( in the photo ) is from the tech department - who is the administrative user of this laptop. Could the knowledgeable admins\/members kindly suggest what can I do to keep using azure using my own subscription? Any kind suggestion is much appreciated.",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Why explanation dashboard is showing 2 tabs with duplicate information in Azure ML Studio?",
        "Question_creation_time":1669620849057,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1106407\/why-explanation-dashboard-is-showing-2-tabs-with-d.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"When using explanations for AutoML models or standalone model, the explanation dashboard has 2 tabs which displays same information.\n\nI am using azureml-interpret to explain the models that are executed under azure context and upload the explanations into Azure ML studio.\nI use global_explanation and local_explanation to explain the overall model performance and local model performance.\n\nI guess this is creating 2 tabs if I am correct, but both of them seems to have same or duplicate information. I don't understand what is the need for that?\n\nThis seem to the case when I use AutoML models also, there is 2 tabs which has same information. Note, here I am not uploading anything, it is by default uploading the model explanations and I am using azure-python-sdk-v1.\n\nI have provided the accompanying screenshots with the information, please let me know if there is gap in my understanding or it is problem with the azure explanation?",
        "Answers":[
            {
                "Answer_creation_time":"2022-11-28T11:24:56.12Z",
                "Answer_upvote_count":1,
                "Answer_body":"@BharathKumarLoganathan-7743 I think the explanation ids are based on the raw and engineered datasets. Raw explanations are based on the features from the original dataset and engineered explanations are based on the features from the dataset with feature engineering applied. The documentation from these links provides a bit more information about the different explanation ids. If you expand the menu on the left this should confirm the same.\n\nhttps:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-automated-ml-for-ml-models#model-explanations-preview\nhttps:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-machine-learning-interpretability-aml#visualizations\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":13.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML compute not able to access Azure MLS workspace blob( not in vnet) during automl experiment execution",
        "Question_creation_time":1631627630167,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/551634\/azure-ml-compute-not-able-to-access-azure-mls-work.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-blob-storage"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi Team,\n\nI'm trying to run the automl code from the examples (https:\/\/github.com\/Azure\/MachineLearningNotebooks\/tree\/master\/how-to-use-azureml\/automated-machine-learning\/regression-explanation-featurization) in Azure MLS which is not in virtual network. While running the experiment, it is getting failed with the below error.\n\nAzureMLCompute job failed.\nBFSMountError: Unable to mount blob fuse file system\nInfo: Could not mount Azure Blob Container azureml-blobstore-xxxx at workspaceblobstore: Unauthorized. Cannot access the storage account with the given account key. Please verify that the account key is valid.\nInfo: Failed to setup runtime for job execution: Job environment preparation failed on 10.0.0.4 with err exit status 1.\n\nNot sure why the AzureML is not able to access its own blobstorage to place the model artifacts.\nThe AzureML and the workspace blob both are not in virtual network.\n\nWorkarounds tried:\n1) Tried to register the workspace blob container (azureml-blobstore-<ID>) as per the link here (https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data), but still getting the same error.\n\nNote: The workspace blob storage keys are synced and can able to access the notebooks and data in AzureML, Is this causing the issue?\n\nAs per the ticket :- https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/35043\/azure-machine-learning-resync-keys-not-working-no.html\n\nAre the storage keys cached in the storage connection strings at the backend ? however the error message is different, in the reference ticket it says not able to access the resource, but in my case it is not able mount to the azure-ml-<ID> container.\n\nCould you please help on it.\n\nThanks in advance.",
        "Answers":[
            {
                "Answer_creation_time":"2021-09-14T21:51:14.653Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nCould you please let me know where you try to do that? I tried in my Azure Machine Learning Notebook in the studio and everything works fine for me.\n\nPlease let me know more details and let's see if we can figure this out here. If we need more environment details, I will recommend raising a ticket for this.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-15T04:40:21.273Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for your response.\n\nI'm able to connect to workspace and create the compute cluster, I'm getting the error while submitting the experiment on the AML compute.\n\nIt is throwing unauthorized error while trying to place the Automl artifacts folder in the AML workspace default blobstore.\n\n\n\n\n\n\n\nI tired explicitly registering the AML workspace blob container (azureml-blobstore-<ID>) as per the link here (https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data), but still getting the same error.\n\nIs it because of resyncing azure blob keys with azure MLS?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":14.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Hyperparamter optimization in Azure AutoML",
        "Question_creation_time":1625435556057,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/462352\/hyperparamter-optimization-in-azure-automl.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Which type of hyperparameter optimization is used in Azure Automated Machine Learning (not the SDK) as default? Grid Search, Random Search, Bayesian? In the SDK you can specify that but in the AutoML section you can not specify that and there is no further information on that",
        "Answers":[
            {
                "Answer_creation_time":"2021-07-06T02:37:14.027Z",
                "Answer_upvote_count":2,
                "Answer_body":"@MagnusEschment-2555 Thanks for the question. Can you please add more details about the document that you are trying.\nTo clarify, what exactly are you optimizing for? Are you optimizing the parameters of the ML model to maximize model accuracy? If so:\n\u2022 Random forest is pretty lightweight, so you may be able to just brute force grid search to get the best model\n\u2022 If that costs is too high, consider using Bayesian (or similar) methods for tuning hyperparameters.\nYou can select the Algorithm name of a completed model to explore its performance details. Please follow the document to explore models.\nSet up AutoML with Python: The primary metric parameter determines the metric to be used during model training for optimization. Azure AutoML supports a specific list of primary metrics per ML task, which are defined in docs, as mentioned below: Set up AutoML with Python - Azure Machine Learning | Microsoft Docs.",
                "Answer_comment_count":5,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Is There a Way to Visualize the Decision Tree AML Used?",
        "Question_creation_time":1612898717163,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/265984\/is-there-a-way-to-visualize-the-decision-tree-aml.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"I have used a Two-Class Boosted Decision Tree in Azure ML to make some predictions on data that I am analyzing. Once the model has completed training is there a way for me to visualize the structure of the decision tree that was ultimately used by Azure?",
        "Answers":[
            {
                "Answer_creation_time":"2021-02-10T16:17:06.287Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us. If you are under Azure Machine Learning Studio(Classic), you can easily do it by Right-click on the output node of the \"Train Model\" module and select \"Visualize\".\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/two-class-boosted-decision-tree#results\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-02-23T06:33:10.683Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nI have confirmed we don't have visualize function for Azure Machine Learning Designer now, but we would like to learn why you are asking about this feature and what you want to do with the visualized graph. We are caring customers' experience and will consider this function if that makes sense.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Delimeter error while adding new dataset in ml service",
        "Question_creation_time":1602240911150,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/121529\/delimeter-error-while-adding-new-dataset-in-ml-ser.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,\nI have problem with adding new dataset in ml service. After upload i'm getting below error (screen)\n\n\n\n\n\nI think is a new issue, because few days ago everything was good.\nIn my csv file is semicolon delimeter.\n\nThank you in advance!",
        "Answers":[
            {
                "Answer_creation_time":"2020-10-09T12:06:42.077Z",
                "Answer_upvote_count":0,
                "Answer_body":"This file could contains sensitive data, i'm not sure about that, so i encrypted file content, but issue still appears.31130-test.txt\n\n\n\n\n\nJust change txt extension to csv.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-10-12T09:03:36.58Z",
                "Answer_upvote_count":0,
                "Answer_body":"@MateuszOrzymkowski-8017 Thanks for the details. We have checked with your 31130-test.txt and able to create the dataset successfully without any issue. Please find the snapshot for the same. Could you retry or If you still see an issue please raise a support issue against ML workspace from the Help + Support blade in Azure portal and this will help you to share the details securely and work with an engineer who can provide more insights about the issue that if it can be replicated.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":2.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to make use of Labelled Images in AzureML Designer?",
        "Question_creation_time":1628873927937,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/513343\/how-to-make-use-of-labelled-images-in-azureml-desi.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello! I have been labeling images in AzureML Data Labeling. I wish to use this labelled set in Designer, to prototype some model ideas. However, I cannot get this to work. Any output (Dataset, COCO or csv) seems not to be compatible with \"Convert to Image Directory\".\n\nMy question is quite similar to one asked over a year ago - https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/32203\/how-to-use-labeled-image-datasets-to-perform-an-im.html - the answer suggests a result was imminent. Has there been any update?\n\nIf there is not one individual module capable of parsing this information, is there a way to use multiple modules to import the data?\n\nThanks!\n\n\n\n\nEDIT: The problem is also discussed here:\nhttps:\/\/docs.microsoft.com\/en-us\/answers\/questions\/194940\/how-to-use-azuremldataset.html\nIs there a cleaner solution yet? Or is downloading it, converting to pandas, then reuploading the best thing to do?",
        "Answers":[
            {
                "Answer_creation_time":"2021-09-02T15:30:10.037Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hello @andrewblance-4822\n\nSorry I didn't hear anything from product team, what I can do now is I will continue following up with them to see any new ways for this and also I can help you enable a support ticket to escalate this issue for more awareness. Please let me know if you do not have a support plan, I can help you to enable a one time free ticket regarding to this issue. Thanks.\n\nRegards,\nYutong",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Load the most recent data from Date partitioned folder",
        "Question_creation_time":1646726960863,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/763313\/load-the-most-recent-data-from-date-partitioned-fo.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello,\n\nI have set up a pipeline with Azure Data Factory in order to move data from my on-premises Oracle DB to parquet files in an Azure blob container every 10 days.\nThe folder structure of my blob container is as follows:\n\nonpremises\/2022\/02\/18\/file1.parquet\nonpremises\/2022\/02\/18\/file2.parquet\nonpremises\/2022\/02\/18\/file3.parquet\n\n\nonpremises\/2022\/02\/28\/file1.parquet\nonpremises\/2022\/02\/28\/file2.parquet\nonpremises\/2022\/02\/28\/file3.parquet\n\n\nonpremises\/2022\/03\/08\/file1.parquet\nonpremises\/2022\/03\/08\/file2.parquet\nonpremises\/2022\/03\/08\/file3.parquet\n\n\n...\n\nNow I'm trying to set up a pipeline in Azure ML which will run every time new data is coming into this container.\nIn my script below, I start by getting a reference to my container before calling the function 'from_parquet_files' to read from Parquet files.\nProblem: the script reads all files from every folder and adds a data column to the dataset (I believe it is because of the parameter 'partition_format').\n\n from azureml.core import Workspace, Datastore\n    \n # Get a reference to the workspace\n ws = Workspace.from_config()\n    \n # Reference to the datastore 'onpremises' from which we will contruct our dataset\n data_store = Datastore(ws, \"onpremises\")\n    \n from azureml.core import Dataset\n # Create a dataset from the data stored in datastore 'onpremises' at the specified path\n specs_dataset = Dataset.Tabular.from_parquet_files(path=(data_store, ''), partition_format='\/{PartitionDate:yyyy\/MM\/dd}\/')\n    \n # Register the dataset to the workspace. Increments the version if dataset already exists.\n specs_dataset.register(workspace=ws, name=\"specs\", description=\"Specs data from on-premises\", create_new_version=True)\n\n\n\nWhat I would like to do is to read only the most recent set of files (in my case, files listed under 'onpremises\/2022\/03\/08\/').\nAs the pipeline will run automatically, it should detect what is the most recent data among the folder structure.\nIs there a simple way to achieve this programmatically?\n\nThanks in advance.",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-09T08:13:14.767Z",
                "Answer_upvote_count":1,
                "Answer_body":"@ThierryL-3166 You could only pass the required files by getting the year, month and day from the timestamp or date output. If your pipeline runs on schedule, you could list all the paths for all the days since the last run and load the files. I think something like below should work.\n\n # create tabular dataset from multiple paths\n from datetime import date\n from datetime import timedelta\n    \n today = date.today()\n    \n yesterday = today - timedelta(1)\n        \n d1 = today.strftime(\"%Y\/%m\/%d\")\n d2=yesterday.strftime(\"%Y\/%m\/%d\") \n    \n    \n path1 = 'onpremises\/'+ d1 + '\/*.parquet'\n path2 = 'onpremises\/'+ d2 + '\/*.parquet'\n    \n data_paths = [(datastore, path1),(datastore, path2)]\n tabular_dataset = Dataset.Tabular.from_parquet_files(path=data_paths)\n\n\n\n\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":16.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"InternalServerError when launching Jupyterlabs in Azure Machine Learning workspace",
        "Question_creation_time":1632877552993,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/569900\/internalservererror-when-launching-jupyterlabs-in.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"My workspace is in EastUS2.\nI have created compute instances from multiple sku's and I always receive the following error when creating instances:\n\n{\n\"error\": {\n\"code\": \"ServiceError\",\n\"severity\": null,\n\"message\": \"InternalServerError\",\n\"messageFormat\": null,\n\"messageParameters\": null,\n\"referenceCode\": null,\n\"detailsUri\": null,\n\"target\": null,\n\"details\": [],\n\"innerError\": null,\n\"debugInfo\": null,\n\"additionalInfo\": null\n},\n\"correlation\": {\n\"operation\": \"f0bc2b1a27a3534eb83eac4f3f71fedf\",\n\"request\": \"589656f8c89b684a\"\n},\n\"environment\": \"eastus2\",\n\"location\": \"eastus2\",\n\"time\": \"2021-09-29T01:01:09.3745269+00:00\",\n\"componentName\": \"notebook-instance-proxy\"\n}\n\nWhat can I do to resolve this issue? I have tried restarting, recreating, and testing other sku's.",
        "Answers":[
            {
                "Answer_creation_time":"2021-10-04T21:34:28.567Z",
                "Answer_upvote_count":0,
                "Answer_body":"@DwayneThomson-9529\n\nHello, a hotfix has been deployed on Friday, please have another try to see if this works on your end.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Is it possible to do machine learning in Azure IoT Central?",
        "Question_creation_time":1618360709993,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/356183\/is-it-possible-to-do-machine-learning-in-azure-iot.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-iot-central"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I was wondering if it is possible to do machine learning on Azure IoT central. I read in some places that it is possible to do so in Azure IoT Edge. I saw a template for Video Analytics but cannot seem to find a way to implement my own models. If Edge is the only way to perform machine learning in Azure IoT, is there some way to use IoT Edge with IoT Central? Or, is it possible to train your own Tensorflow Lite Models with Raspberry Pi and just host the Pi in IoT Hub? If both are possible, which of the two would be the easiest?",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-14T16:12:08.863Z",
                "Answer_upvote_count":1,
                "Answer_body":"@KC-6678 it looks like you are having great challenges ahead :)!\n\nTo your main question, the direct answer is yes you can use Machine Learning in conjunction with an Azure IoT Central Solution which ingests data from an Azure IoT Edge device previously trained by your own Tensorflow Lite Models.\n\nThe bigger question is how do you want to do it and what are the current constraints you have + when do you want the actionable decisions coming from your connected device sensors to be made?\n\nMy advice is that you follow one of our Learning paths or Modules, for example:\n\nAI edge engineer\n\n\nIdentify anomalies by routing data via IoT Hub to a built-in ML model in Azure Stream Analytics\n\nYou will learn how to use a trained model and clearly distinguish when you need an ML model running in the Edge vs in the Cloud.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML service and SAS files",
        "Question_creation_time":1667406090587,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1072904\/azure-ml-service-and-sas-files.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Am not able to preview the sas7bdat files in Azure ML service.. whether sas7bdat files analysis are supported in Azure ML services ?",
        "Answers":[
            {
                "Answer_creation_time":"2022-11-03T02:38:56.42Z",
                "Answer_upvote_count":1,
                "Answer_body":"I want to import them in ML studio designer pipelines. Tried to import the sas7dat extension files for processing the data. Also converttocsv service is throwing the error with source as sas extension.\n\nGot the error as ValueError: Unable to detect DataType: Unrecognized file extension '.sas7bdat'.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Why is the different components not grouped in the designer any more?",
        "Question_creation_time":1661248060107,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/978187\/why-is-the-different-components-not-grouped-in-the.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi, Guys,\nI'm new to Azure Ml, and when i started using the Designer, the different components where grouped.\nWhen you chose for example \"model scoring and evaluation\", and then all components related to that topic was there.\nNow it's like all components available is just listed in alphabetic order.\nWhat is the point with that change? and can i get the grouped components back?",
        "Answers":[
            {
                "Answer_creation_time":"2022-08-23T11:52:22.877Z",
                "Answer_upvote_count":0,
                "Answer_body":"@PedersenBjarke-7167 Yes, you could select the filter next to search and select Built-in to see the grouped components again.\nThe change allows users to view only the required modules or components and also filter then according to the available criteria. If you want to go back to the older view, simply select the built in assets only to group by functionality.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.\n\n\n\n\n\nRef: https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/972775\/change-in-machine-learning-designer.html",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Deploy ML model to Kubernetes + overwrite previous endpoint",
        "Question_creation_time":1598425965377,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/77362\/deploy-ml-model-to-kubernetes-overwrite-previous-e.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-kubernetes-service"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I'm building a CI\/CD pipeline in Azure DevOps for the deployment of my Machine Learning model to Azure Kubernetes Service. I have the following task in my YAML pipeline file (replaced some of the values with '...'):\n\n - task: AzureCLI@1\n   displayName: \"Deploy to AKS\"\n   inputs:\n     azureSubscription: '...'\n     scriptLocation: inlineScript\n     workingDirectory: $(Build.SourcesDirectory)\/score\n     inlineScript: |\n       set -e # fail on error\n             \n       az ml model deploy --name 'aks-deploy-test' --model '$(MODEL_NAME):$(get_model.MODEL_VERSION)' \\\n       --compute-target $(AKS_COMPUTE_NAME) \\\n       --ic inference_config.yml \\\n       --dc deployment_config_aks.yml \\\n       -g ... --workspace-name ... \\\n       --overwrite -v\n\n\n\nWhen I run the pipeline the first time, it successfully deployed the ML model and I can see the Endpoint in the Azure ML workspace. However, when I try to run the pipeline a second time (to deploy a newer version of the model), I get the error:\n\n Error:\n {\n   \"code\": \"KubernetesError\",\n   \"statusCode\": 400,\n   \"message\": \"Kubernetes Deployment Error\",\n   \"details\": [\n     {\n       \"code\": \"Unschedulable\",\n       \"message\": \"0\/6 nodes are available: 4 Insufficient cpu, 6 Insufficient memory.\"\n     },\n     {\n       \"code\": \"DeploymentFailed\",\n       \"message\": \"Couldn't schedule because the kubernetes cluster didn't have available resources after trying for 00:05:00.\\nYou can address this error by either adding more nodes, changing the SKU of your nodes or changing the resource requirements of your service.\\nPlease refer to https:\/\/aka.ms\/debugimage#container-cannot-be-scheduled for more information.\"\n     }\n   ]\n }\n\n\n\nIsn't the --overwrite option in the az ml model deploy command supposed to completely overwrite the current deployment of the model? If so, why am I still getting this error, or is there a better way to deploy a newer version of the ML model to the same AKS cluster?",
        "Answers":[
            {
                "Answer_creation_time":"2020-08-28T04:02:16.747Z",
                "Answer_upvote_count":0,
                "Answer_body":"@AxelVandevelde Thanks for the question. The error message literally indicates the issue, none of the nodes have CPUs available.\nCan you please add more details about the sku's. If Possible please share the link to the tutorial\/documentation you were following.\n\nEnable AppInsights flag will start flowing the logs (for Application monitoring).\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-enable-app-insights\n\n\n\n\nFor cluster monitoring you can use log analytics via AKS.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/aks\/view-master-logs",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Trained NLP model snippet",
        "Question_creation_time":1667251332713,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1069986\/trained-nlp-model-snippet.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Newbie data scientist here, I am just starting my way in Azure, is there any I should start NLP? Any trained model or code sample? Thank you for any idea",
        "Answers":[
            {
                "Answer_creation_time":"2022-11-06T23:15:45.22Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @jacksonschmidt-1888\n\nSorry I have not heard from you. I have done some researches around NLP in Azure. This can be done by two ways -\n\nAzure Machine Learning Python SDK\/ ML CLI extension\nWe don't have any trained model you can use in Azure ML but you do have the SDK supporting you to train your model\nhttps:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-nlp-models?tabs=cli\n\nNLP Server\nApache Spark is a parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications. Azure Synapse Analytics, Azure HDInsight, and Azure Databricks offer access to Spark and take advantage of its processing power.\n\nFor customized NLP workloads, Spark NLP serves as an efficient framework for processing a large amount of text. This open-source NLP library provides Python, Java, and Scala libraries that offer the full functionality of traditional NLP libraries such as spaCy, NLTK, Stanford CoreNLP, and Open NLP. Spark NLP also offers functionality such as spell checking, sentiment analysis, and document classification. Spark NLP improves on previous efforts by providing state-of-the-art accuracy, speed, and scalability.\n\nThe NLP Server is available in Azure Marketplace. To explore large-scale custom NLP in Azure, see NLP Server - https:\/\/azuremarketplace.microsoft.com\/en-US\/marketplace\/apps\/johnsnowlabsinc1646051154808.nlp_server?ocid=gtmrewards_whatsnewblog_nlp_server_040622\n\nAzure Language Service\nThough we don't have trained model in Azure ML, but we do have REST APIs you can use for Text Analytics, Sentiment Analytics and so on functions for NLP, I would suggest you to check on the document, it may help you achieve your bussiness goals.\nhttps:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/language-service\/\n\nI hope those information helps. Please let me know if you have any questions regarding to any of above.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Save trained model from AutoML\/Designer as pickle file to disk - Azure ML",
        "Question_creation_time":1617893768667,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/349669\/save-trained-model-from-automldesigner-as-pickle-f.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\nI want to save trained machine learning model as pickle file(.pkl) to disk which is trained in AutoML\/Designer.\n\nPlease let me know is there any way to do that?\n\nThanks",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-08T15:17:00.257Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @Bhaskar11-9991\n\nRefer the below URL it may helps you.\nhttps:\/\/docs.microsoft.com\/en-us\/answers\/questions\/297882\/how-to-use-a-model-trained-by-azure-automl.html\n\n\n\n\nIf the Answer is helpful, please click Accept Answer and up-vote, this can be beneficial to other community members.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-04-08T17:20:45.26Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Bhaskar11-9991 Thanks, Please follow this document: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-model-designer. Basically you can register a trained model in Designer bring it out with SDK\/CLI to deploy it.\n\nSharing a reference notebook from @Nicholas Moore: https:\/\/github.com\/nfmoore\/aml-designer-iot-edge\/blob\/main\/00-containerize-designer-model.ipynb.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML Studio Failed to Authenticate to the compute",
        "Question_creation_time":1632489823347,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/565326\/azure-ml-studio-failed-to-authenticate-to-the-comp.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":4.0,
        "Question_view_count":null,
        "Question_answer_count":12,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\nI have created a compute in my ML Studio and was running it for hours. However, it suddenly disconnected, and when I signed back in, it shows that \"\nYou need to be authenticated to the compute to use any Azure SDK. Please use the authenticate button to get authenticated.\" But when I click the authenticate button, I got an error with the message saying \"InternalServerError\".\n\nI have tried to sign out and sign back in, delete the current compute and create a new one. Neither worked.\n\nDoes anybody have any suggestions on this?",
        "Answers":[
            {
                "Answer_creation_time":"2021-09-25T19:45:40.31Z",
                "Answer_upvote_count":0,
                "Answer_body":"same issue",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-26T05:26:28.03Z",
                "Answer_upvote_count":0,
                "Answer_body":"Im also facing similar issue. when opened the notebook in vscode, i was able to authenticate and run.",
                "Answer_comment_count":5,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-27T13:49:18.34Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nI am also facing this issue. I am prompt to Authentic to use the cluster and later I am getting below error: \"We couldn't sign you in. Please try again.\"",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-27T20:07:28.897Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi Ms Team,\n\nI am facing the Same Issue.\n\nAny Idea??",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-28T03:43:40.357Z",
                "Answer_upvote_count":0,
                "Answer_body":"Same issue.\nAny one provide solution for above error.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-28T18:01:08.687Z",
                "Answer_upvote_count":1,
                "Answer_body":"I am having the same issue.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-29T02:00:51.95Z",
                "Answer_upvote_count":0,
                "Answer_body":"I have the same issue here. Region is EastUS",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-29T18:56:24.713Z",
                "Answer_upvote_count":0,
                "Answer_body":"Same issue, can't even open the terminal",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-29T19:01:46.253Z",
                "Answer_upvote_count":0,
                "Answer_body":"@GiftA-MSFT - can you provide us an update?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-30T15:20:01.827Z",
                "Answer_upvote_count":0,
                "Answer_body":"Same issue for myself, cant run a compute instance even with an upgrade. It is also East coast. Any idea when it will be running properly?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":10.0,
        "Question_follower_count":21.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Using Python visual in Power BI for calling ML Azure rest API works in desktop version but not when published",
        "Question_creation_time":1613593697693,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/277404\/using-python-visual-in-power-bi-for-calling-ml-azu.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I created a dashboard in Power BI desktop. I have a trained model from ML Azure which I already deployed and has it's rest API. I need to call this rest API from the dashboard itself using measures I created (not from the query editor). I did it using the Python visual to send the input data and get back the output from the rest API and plotting the result (a number). This works perfectly in the desktop version. I need to publish this dashboard to share with other members of my organization but in the web version the script gives a runtime error. ![69200-capture.png][1] How to make it work? [1]: \/answers\/storage\/attachments\/69200-capture.png",
        "Answers":[
            {
                "Answer_creation_time":"2021-02-18T07:54:29.523Z",
                "Answer_upvote_count":0,
                "Answer_body":"anonymous user There is a documented procedure to connect a Azure ML workspace on powerBI desktop and select the model and service before publishing this.\nIn this case it looks like you used python visual to consume your REST API but after publishing it the same script might be failing to even connect to the API. Not sure if any port needs to be opened up when published to web.\n\nI think you can try the above procedure again with powerBI desktop using query editor and then try to publish the report to web.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How can I attach a managed disk to a Machine Learning Compute instance?",
        "Question_creation_time":1601637154150,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/115201\/how-can-i-attach-a-managed-disk-to-a-machine-learn.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello experts,\n\nI would like to attach a managed disk to my machine learning compute instance. Is that possible?\n\nThere is a possible overlap to the question Attach Disk to Virtual Machine, but steps doesn't seem to apply to ML compute instances.\n\nThanks in advance,",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-04T08:05:55.917Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nYou can attach your managed disk by following steps in Azure portal:\n\n\nMore details and limitation please see:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-compute-target#azure-machine-learning-compute-managed\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Relational Database for Automated Machine Learning",
        "Question_creation_time":1594992643703,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/48810\/relational-database-for-automated-machine-learning.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I'm trying to build a time-series Machine Learning experiment in Azure Machine Learning. However, I'm using outputs from previous functions which analyzes multiple factors using the same timestamp. For example, extracting all key phrases from customer surveys, and using it to forecast future sales. This creates a new row for each key phrase found, with all of the other survey data points and the same timestamp. This causes an error due to duplicate timestamps across multiple rows forecasting the same target value. I need to either make each timestamp\/survey on row, convert the columns to a list\/array, and have it iterate through each key phrase in that column, or use a relational database where the key phrases column is the foreign key to my table of keyphrases. Any recommendations on how to solve this? Thanks!",
        "Answers":[
            {
                "Answer_creation_time":"2020-07-23T13:27:08.11Z",
                "Answer_upvote_count":0,
                "Answer_body":"@WillSpagnoli-5705 Is the idea that these key phrases will be used to help predict the sale, or are they being added with goal of helping explain the prediction? We believe these phrases, if used for prediction, will not be very useful as the survey may not be known into the future - so we'd be predicting both the survey phrases and the sale. If the timedelta is small or the survey keywords are generally the same across time, the feature may provide more value.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":34.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"[SOLVED] AML Pipeline publish error: Identity(object id: __) does not have permissions for Microsoft.MachineLearningServices\/workspaces\/metadata\/snapshots\/write actions.",
        "Question_creation_time":1654848921463,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/884432\/aml-pipeline-publish-error-identityobject-id-does.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I get the following error while trying to publish some new pipelines to an AML workspace:\n\nSnapshotException:\nMessage: {\n\"error_details\": {\n\"componentName\": \"project\",\n\"correlation\": {\n\"operation\": \"038f38ce5375f4cda9b0a50df5bb9c1b\",\n\"request\": \"e874ef090203af05\"\n},\n\"environment\": \"eastasia\",\n\"error\": {\n\"code\": \"UserError\",\n\"innerError\": {\n\"code\": \"ForbiddenError\"\n},\n\"message\": \"Identity(object id: bb0511d8-d57a-4442-89a1-1986cac268c9) does not have permissions for Microsoft.MachineLearningServices\/workspaces\/metadata\/snapshots\/write actions. Please refer to https:\/\/aka.ms\/azureml-auth-troubleshooting to fix the permissions issue.\"\n},\n\"location\": \"eastasia\",\n\"time\": \"2022-06-10T08:07:13.3168371+00:00\"\n},\n\"status_code\": 403,\n\"url\": \"__\"\n}\n\nDo note that I'm publishing multiple pipelines to multiple workspaces - only 2 of the pipelines on our Asia workspace are failing with this (and 1 other on Asia completed successfully)... I see that similar issues had existed before and were internal to Azure and fixed promptly, i.e. - https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/407580\/permission-error-while-finishing-auto-ml-run.html\n\nAny idea if this is a similar thing, or did we do something wrong? Thanks!",
        "Answers":[
            {
                "Answer_creation_time":"2022-06-10T08:56:46.643Z",
                "Answer_upvote_count":0,
                "Answer_body":"Rerun after a while works fine...",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"DSVM can support SQL Server Developer Edition for Ubuntu",
        "Question_creation_time":1618980125337,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/365284\/dsvm-can-support-sql-server-developer-edition-for.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"According to this\n- https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/data-science-virtual-machine\/tools-included#store-retrieve-and-manipulate-data,\nit appears that the SQL Server Developer Edition (Ubuntu) is being supported in DSVM but I couldn\u2019t find the name in the supported list here https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/data-science-virtual-machine\/dsvm-tools-data-platforms#sql-server-developer-edition,\nfurthermore there is no guide line for Linux Guide line but only windows guideline is there.\nI\u2019d like make sure the followings :\n\nCan DSVM support SQL Server Developer Edition for Ubuntu?\n\n\nIf yes, where is the guideline for this?\n\n\nIf no, the documentation is wrong? And any particular supporting plan for SQL Server Developer Edition for Ubuntu?\n\nThanks",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-22T05:37:42.617Z",
                "Answer_upvote_count":0,
                "Answer_body":"@JunghyeonRyu-6784 Thanks for the question. We don't preinstall SQL Server Developer Edition on the Ubuntu images but you can install it on your own. Here is the documentation and steps.",
                "Answer_comment_count":5,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Images Segmentation using Azure",
        "Question_creation_time":1610951620483,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/234232\/images-segmentation-using-azure.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-custom-vision"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi,\nI have been using object detection from Custom Vision to train images. Classification do not suit my goal so I'm looking at alternative methods to training images. Can I get some suggestions with using Azure for images segmentation?",
        "Answers":[
            {
                "Answer_creation_time":"2021-01-18T07:40:18.9Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi @NamLy-3299\n\nSuggestions and refer below url for Azure for images segmentation.\n\nCustom Vision integration sample skill for cognitive search\n\nClassify images with the Custom Vision service\n\n\n\n\nPlease don\u2019t forget to Accept the answer and up-vote wherever the information provided helps you, this can be beneficial to other community members.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Notebook files have disaperred",
        "Question_creation_time":1652875560357,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/854288\/notebook-files-have-disaperred.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello,\n\nIn my MLStudio my notebook files window has disappeared so I can not access any of my data (as seen on the image) and I do not know what to do.\n\nPlease your help to solve this as soon as poosible.\n\nThank you.",
        "Answers":[
            {
                "Answer_creation_time":"2022-05-19T02:46:25.6Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us. Could you please check the access of Storage? https:\/\/docs.microsoft.com\/en-us\/azure\/storage\/blobs\/assign-azure-role-data-access?tabs=portal#assign-an-azure-role\n\nTo access these storage services, you must have at least Storage Blob Data Reader access to the storage account. Only storage account owners can change your access level via the Azure portal.\n\nOr, your admin put the data storage behind V-Net and you can not get access to it- https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-identity-based-data-access#work-with-virtual-networks\nIn this situation, you need to ask permission from your admin.\n\nCould you please share which situation you are in?\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Apply SQL Transformation Error : Failed when create table error 1000",
        "Question_creation_time":1629294395873,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/518856\/apply-sql-transformation-error-failed-when-create.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I connected 2 tables to \"Apply SQL Transformation\" box and when i ran the code the following error appears (screenshots attached). csv files downloaded from web for i have shared link below.\n\nLink 1 : https:\/\/docs.google.com\/spreadsheets\/d\/1aeZllwICUG7Q_rEgtNm4zj9pVV4iJaND6uUbou0qOp8\/pub?gid=873193374&single=true&output=csv\nLink 2 : https:\/\/docs.google.com\/spreadsheets\/d\/1xnMNKqB2tCdOecXt3WWjIUxbAk5rrvbYfbJLrfzFrjc\/pub?gid=1144892773&single=true&output=csv\n\nError details : requestId = cf031a39f0684e2786d1fb4768c898ce errorComponent=Module. taskStatusCode=400. {\"Exception\":{\"ErrorId\":\"LibraryException\",\"ErrorCode\":\"1000\",\"ExceptionType\":\"ModuleException\",\"Message\":\"Error 1000: SQLiteQueryRunner Library library exception: Failed when create table: \",\"Exception\":{\"Library\":\"SQLiteQueryRunner Library\",\"ErrorId\":\"SQLiteCreateTableFailed\",\"ErrorCode\":\"3\",\"ExceptionType\":\"LibraryException\",\"Message\":\"Failed when create table: \",\"Exception\":{\"ExceptionType\":\"Exception\",\"Message\":\"SQL logic error or missing database\\r\\nunrecognized token: \\\"\\\"PK\\u0003\\u0004\\u0014\\\"\"}}}}Error: Error 1000: SQLiteQueryRunner Library library exception: Failed when create table: Process exited with error code -2\n\n\n\n\nVery much appreciate it if someone could explain the way out since i am new to Azure ML.\n\nSQL query that i used is provided below\n\nselect title_year, movie_title, category, Won?\nfrom t1, t2\nwhere t1.movie_title = t2.Nominee\nand Won? = \"YES\"\norder by title_year desc",
        "Answers":[
            {
                "Answer_creation_time":"2021-09-02T16:34:34.933Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @JahnaviHCQSQ-9723\n\nSorry I can miss your message. The \"?\" is not working well in SQL, and you also need a \";\" by the end of your query.\n\nThis works for me well:\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Downloading images built during ML experiment",
        "Question_creation_time":1623337578827,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/430883\/downloading-images-built-during-ml-experiment.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-container-registry"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"I have successfully run a AML experiment . In the beginning of the experiment, I included the below command to build a conda environment with my requirements into a pre built image:\n\n env = azc.Environment.from_conda_specification(name='my-env', file_path='.\/envspec.yml')\n env.docker.enabled = True\n env.docker.base_image = 'mcr.microsoft.com\/azureml\/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04'\n\n\n\nI understand that during the preparation phase the image is built with the specified dependencies and the experiment is run.\nNow, where I can access this built image? I tried in the Azure container Registry inside my resource group but couldnt find anything.\n\nIs there a way I can download this image and use it in a different experiment as a custom image? I assume this must save time in downloading dependencies and ensures reptroduciblity.\n\nAny known way of doing this?",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Response status code does not indicate success: 400 (Conda dependencies were not specified. Please make sure that all conda dependencies were specified i).",
        "Question_creation_time":1667250048510,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1069928\/response-status-code-does-not-indicate-success-400.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I was trying to setup my env runconfig = ScriptRunConfig(source_directory='script\/', script='my-script.py', arguments=script_params)\nrunconfig.run_config.target = compute_target\nrunconfig.run_config.environment = env\nrun = exp.submit(runconfig)",
        "Answers":[
            {
                "Answer_creation_time":"2022-11-01T07:37:12.75Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @jackson-0025\n\nThanks for using Microsoft Q&A platform. I have seen a very similar question as your, and the solution is you need to use RunConfiguration instead of ScriptRunConfig. More info here\n\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-getting-started.ipynb\n\n from azureml.core.runconfig import RunConfiguration\n    \n env = Environment.get(workspace=ws, name='my-environment', version='1')\n # create a new runconfig object\n runconfig = RunConfiguration()\n runconfig.environment = env\n    \n pipeline_step = PythonScriptStep(\n     source_directory='script', script_name='my-script.py',\n     arguments=['-a', param1, '-b', param2],\n     compute_target=compute_target,\n     runconfig=runconfig\n )\n    \n pipeline = Pipeline(workspace=ws, steps=[pipeline_step])\n    \n pipeline_run = Experiment(ws, 'my_pipeline_run').submit(pipeline)\n\nReference for the issue - https:\/\/stackoverflow.com\/questions\/60506398\/how-do-i-use-an-environment-in-an-ml-azure-pipeline\n\nI hope this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpfuk to support the community, thanks a lot.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"IoT Edge custom machine learning module reported error status",
        "Question_creation_time":1637069073437,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/629089\/iot-edge-custom-machine-learning-module-reported-e.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-iot-hub",
            "azure-iot-edge"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\nI have developed a ML solution based on this tutorial.\nI adapted the Python notebook to run into an existing ML workspace.\nUnfortunately, when I tried to create Docker image, it failed with error 500. I found out that the Image class is deprecated (suppose this was the reason of the error), so I relied on the Environment class (in particular this documentation) and everything worked fine.\nAlso, testing the model as Web Service ACI endpoint works correctly, providing the result:\n['{\"machine\": {\"temperature\": 31.16469009, \"pressure\": 2.158002669}, \"ambient\": {\"temperature\": 21.17794693, \"humidity\": 25}, \"timeCreated\": \"2017-10-27T18:14:02.4911177Z\", \"anomaly\": false}']\n\n\n\n\nThe issue I need support is the following: after deploying the ML model as container to the Edge device (in this case a Ubuntu VM created using this template), the ML module reported an error:\n\nNo logs are displayed, neither through VM SSH access, nor through the Portal.\n\nThe only information that I found out is this one:\n\n\nI checked multiple times the correctness of the image URI for the ML module, and I'm pretty confident that it is, since the ACI is based on it and the Web Service test was succeded.\n\nWhat could be the problem here?\n\nThanks",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":4.0,
        "Question_follower_count":13.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Python code for a generalized lineare model in Azure machine learning",
        "Question_creation_time":1654699584787,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/881821\/glm-with-azure-ml.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello guys,\nI am currently training a model to price boat types around the world using about 30,000 records of historical sales from the last 7 years. The approach is currently a linear regression in Azure ML studios.\n\nUsing 60 variables such as number of engines, year of construction, bedroom, brand etc. which have already been normalized and split into a training set and a testing set, the purchase price of a given boat is evaluated, depending on the port.\n\nNow I would like to use a generalized linear model with family gamma and the link function identity to train a better model and thus get a better price estimation.\n\nUnfortunately there is no module included in Azure machine learning for this. Has anyone ever written code for a GLM in Azure machine learning or can tell me how complex this is?\n\nI would appreciate any help and have a nice weekend!",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML data labeling change polygon color",
        "Question_creation_time":1647528569083,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/776555\/azure-ml-data-labeling-change-polygon-color.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello,\n\nWe are currently annotating images in a data labeling instance segmentation (polygon) project. Our images are rather blueish, which makes it difficult to use the polygon \"draw polygon region\" tool, which draws the polygon in blue.\n\nIs it possible to change the color to, for example, black?\n\nThanks and BR,\nMaite",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-18T09:37:47.23Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Maite-3025\n\nThanks for reaching out to us, I am sorry we are using only blue for the polygon color. I will forward your feedback to product team for future release.\n\nOne workaround may help with your scenario is, you can change the brightness to \"-100\" when you draw and revert the brightness back when you done as below screenshot. This will help to make things clear.\n\nHope this helps and thanks for the feedback again.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"why I do not have \"Open in a new Notebook\" in my menu",
        "Question_creation_time":1624421404470,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/447926\/why-i-do-not-have-34open-in-a-new-notebook34-in-my.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I tried Azure machine learning workspace and I try to use 'right click' -> 'CSV dataset' -> There is no \"Open in a new Notebook\" in the menu, even a grey one. Could someone please guide me? Thank you",
        "Answers":[
            {
                "Answer_creation_time":"2021-06-24T08:37:10.93Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nI added a screenshot, hope this helps.\n\nRegards,",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Facing Trouble with Evaluate Model in Azure Machine Learning Designer",
        "Question_creation_time":1662807677703,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1001826\/facing-trouble-with-evaluate-model-in-azure-machin.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi Everyone,\n\nI'm trying to run a MNIST prediction model on the ML Designer similar to the Image Classification sample given. All my components are working except the final evaluate model. It shows an error:\nazureml.studio.common.error.NotScoredDatasetError: There is no score column in dataset.\n\nThe scored dataset to the evaluate model component is exactly the same as given in the sample pipeline. I don't know what this issue is.\nCould anyone help me out with the same? I'll be thankful",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":8.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Feature request: more customizability in builtin models",
        "Question_creation_time":1594758735000,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/46982\/feature-request-more-customizability-in-builtin-mo.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"In Azure ML Designer, I would like to customize and parametrize other aspects of the models. For example, in the NN Regression model, I would like to try various optimizers (Adam, Adagrad, SGD) and activation functions (ReLU, Sigmoid, Tanh).",
        "Answers":[
            {
                "Answer_creation_time":"2020-07-14T20:33:16.577Z",
                "Answer_upvote_count":0,
                "Answer_body":"You can provide this feedback over here on uservoice\nhttps:\/\/feedback.azure.com\/forums\/257792-machine-learning",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-14T20:33:28.937Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for the feedback! We appreciate your input, I will forward your content to product group for reviewing. We will contact you if more information needed. ^^\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":38.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML Model Deployment- POST Body Type",
        "Question_creation_time":1602526641177,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/123960\/azure-ml-model-deployment.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I had registered a CNN model on Azure ML and would like to have and endpoint API that returns the predictions based on the image it receives and I also would like to send some metadata along the image itself. So, I prefer to POST the data in form-data format. However,The official tutorials mention application-json or binary data only.\nHow can I POST data in form-data format to an API in Azure ML ?",
        "Answers":[
            {
                "Answer_creation_time":"2020-12-09T05:33:47.45Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for reaching out. Currently, the API only supports json or binary data.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to Connect Azure MySQL server in Azure Machine Learning Studio",
        "Question_creation_time":1635536784630,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/609742\/how-to-connect-azure-mysql-server-in-azure-machine.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-database-mysql"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"In Azure machine learning studio I am trying to connect an azure mysql server as a datastore. The azure mysql server was created by a colleague and I have the credentials to connect properly. However, after entering the credentials and creating a datastore, I cannot select the datastore from the dropdown in order to create a dataset. Does machine learning studio have the ability to connect to an azure mysql server?",
        "Answers":[
            {
                "Answer_creation_time":"2021-11-01T13:15:25.337Z",
                "Answer_upvote_count":0,
                "Answer_body":"@MalcolmCavin-6279 Thanks, Currently AML studio doesn't support Azure Database for MySQL as shown below.\n\n\n\n\nUsing Azure machine learning python SDK here is the doc link Register and create a datastore to easily connect to your storage account, and access the data in your underlying storage service.\n\nSupported cloud-based storage services in Azure that can be registered as datastores:\n\nAzure Blob Container\nAzure File Share\nAzure Data Lake\nAzure Data Lake Gen2\nAzure SQL Database\nAzure Database for PostgreSQL\nDatabricks File System\nAzure Database for MySQL\n\nAlso MySQL is only supported for pipeline DataTransferStep and For unsupported data source, we are recommended to use Azure Data Factory to copy the data over to one of our supported Azure data source.\n\nAlso Python + Azure Database for MySQL: https:\/\/techcommunity.microsoft.com\/t5\/azure-database-for-mysql\/python-azure-database-for-mysql\/ba-p\/841926",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"FileNotFoundError: [Errno 2] - Score machine learning models with PREDICT in serverless Apache Spark pools (Synapse & Azure Machine learning AML)",
        "Question_creation_time":1639738776307,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/667458\/filenotfounderror-errno-2-score-machine-learning-m.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-synapse-analytics",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":4,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi all,\n\nI am following the steps on this tutorial:\nTutorial: Score machine learning models with PREDICT in serverless Apache Spark pools tutorial-score-model-predict-spark-pool\nand what-is-aml-model-uri-predict-in-serverless-apache-1.html\nI tried to used a model created with AutoML and another from designer and I am getting this error: FileNotFoundError: [Errno 2] No such file or directory: '\/tmp\/tmp5xd2_hyr\/MLmodel'\n\nI added the DATA_FILE:\n\nI am getting this error (I am using Synapse):\n\n\nKind regards,\nAnaid",
        "Answers":[
            {
                "Answer_creation_time":"2021-12-20T08:41:11.013Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @Anaid-6816,\n\nThanks for the question and using MS Q&A platform.\n\nMake sure you have upload the mlflow folder to AML, not the parent folder to AML.\n\nNote: As per the repro, I got the same error message when I uploaded the parent folder to the AML workspace.\n\nAble to resolve the issue by uploading the mlflow folder to AML workspace.\n\n DATA_FILE = \"abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/AML\/LengthOfStay_cooked_small.csv\"\n AML_MODEL_URI_SKLEARN = \"aml:\/\/chepra:1\" #Here \":1\" signifies model version in AML. We can choose which version we want to run. If \":1\" is not provided then by default latest version will be picked\n RETURN_TYPES = \"INT\"\n RUNTIME = \"mlflow\"\n\n\n\nHope this will help. Please let us know if any further queries.\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-01-13T08:00:37.883Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nCan you explain a bit more on uploading the MLFlow to AML.\n\nWe currently have BoosteDecisionTitanic:1 in models on AML. How do we upload the MLFlow to AML.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-01-14T15:02:26.86Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nCan you explain a bit more on uploading the MLFlow to AML. Where are those files and how can we upload them?\n\nWe currently have BoosteDecisionTitanic:1 in models on AML. How do we upload the MLFlow to AML.\n\n\n\n\n\n\nKind regards,\nAnaid",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-03-24T18:34:32.82Z",
                "Answer_upvote_count":0,
                "Answer_body":"any solution yet?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":15.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML: Creating a Siamese network, I have the reference data stored in one blob storage and the user input stored in another blob storage. How can I connect the two blob storage to my batch endpoint. If not, is there a workaround?",
        "Question_creation_time":1662886746297,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1002087\/azure-ml-creating-a-siamese-network-i-have-the-ref.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Azure ML: Creating a Siamese network, I have the reference data stored in one blob storage and the user input stored in another blob storage. How can I connect the two blob storage to my batch endpoint. If not, is there a workaround? The setup looks like this.",
        "Answers":[
            {
                "Answer_creation_time":"2022-09-12T12:04:20.93Z",
                "Answer_upvote_count":0,
                "Answer_body":"@SamarjeetSinghPatil-6739 I think this should be possible where your input could be a different storage account and your output could be the default datastore.\n\n export OUTPUT_FILE_NAME=predictions_`echo $RANDOM`.csv\n JOB_NAME=$(az ml batch-endpoint invoke --name $ENDPOINT_NAME --input https:\/\/pipelinedata.blob.core.windows.net\/sampledata\/mnist --input-type uri_folder --output-path azureml:\/\/datastores\/workspaceblobstore\/paths\/$ENDPOINT_NAME --set output_file_name=$OUTPUT_FILE_NAME --mini-batch-size 20 --instance-count 5 --query name -o tsv)\n\n\n\nRef: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-batch-endpoint#configure-the-output-location-and-overwrite-settings\n\nPlease refer some other scenarios that you can set with the input and output path while using the batch endpoint invoke command.\n\n az ml batch-endpoint invoke --help",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"What syntax references Pipeline parameters in the where clause of a SQL query of 'Import Data' modules in Microsoft Azure Machine Learning designer?",
        "Question_creation_time":1616787456817,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/333816\/what-syntax-references-pipeline-parameters-in-the.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "dotnet-sqlite"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"I have created a pipeline in Microsoft Azure Machine Learning designer. I have added a Pipeline parameter myNumber in the pipeline settings, with a valid default value, to accept the unique ID of the asset in our DB so that the pipeline can return only the asset-specific data for use as our model input. Specifically I want to reference that pipeline parameter in the where clause of the SQL query in the 'Import Data' module that connects to our Azure SQL server.\n\nI cannot find a reference in the documentation on how to do this. I have tried the methods specified for accomplishing this task in Azure Data Factory, using where RowId = @pipeline().parameters.myNumber or where RowId = @{variables('myNumber')} but the experiment fails with SqlException error code '137', variable not defined.\n\nCan you please tell me the necessary syntax to reference Pipeline parameters in the where clause of a SQL query of 'Import Data' modules of Microsoft Azure Machine Learning designer?",
        "Answers":[
            {
                "Answer_creation_time":"2021-03-31T17:14:50.84Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, designer does not support referencing pipeline parameters in sql query of \"Import Data\". However, you can write a one-line sql query and set the whole \"database query\" parameter as pipeline parameter as shown below. Hope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-03-31T17:32:04.787Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thank you for replying and the suggestion, GiftA-MSFT.\n\nI would not feel comfortable having an endpoint which accepts a wildcard query as a pipeline parameter as that sounds like a major security violation. Is there really no way at all to inject Pipeline parameters into the query? If that's the case, it sounds like the pipeline were only designed to use static data, which makes sense for training a model, but not for preprocessing input to be passed to a trained model that is deployed to an endpoint.\n\nIs there a different Azure tool I should be using to create dynamic \"Input Data\" pipelines for preprocessing prior model scoring?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Pipeline stops at train model stage",
        "Question_creation_time":1642031139267,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/693063\/pipeline-stops-at-train-model-stage.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello there,\n\nWhen I am running the following steps of the pipeline, I'm getting this error at the \"train model\" stage.\n\nCan anyone explain why I'm getting this error?",
        "Answers":[
            {
                "Answer_creation_time":"2022-01-13T23:43:46.163Z",
                "Answer_upvote_count":0,
                "Answer_body":"After your thoughtful suggestion this is what I got in std_log.txt after clicking failed module ( train model ) :\n\nDo I need to fix the error for all the following steps ?\n\nFile \"\/azureml-envs\/azureml_27f4babfbdfccc3e0926823cfdde349d\/lib\/python3.6\/site-packages\/azureml\/studio\/modules\/datatransform\/common\/named_encoder.py\", line 105, in validate_series\ncolumn_name=series.name)\n\nFile \"\/azureml-envs\/azureml_27f4babfbdfccc3e0926823cfdde349d\/lib\/python3.6\/site-packages\/azureml\/studio\/modules\/datatransform\/common\/named_encoder.py\", line 157, in _check_too_many_unique_values\ntroubleshoot_hint=\"Find the explanation and resolution in https:\/\/docs.microsoft.com\/en-us\/\"\n\nFile \"\/azureml-envs\/azureml_27f4babfbdfccc3e0926823cfdde349d\/lib\/python3.6\/site-packages\/azureml\/studio\/common\/error.py\", line 835, in throw\nraise err\n> err = ColumnUniqueValuesExceededError('Number of unique values in column: \"TotalCharges\" is greater than allowed. Find the explanation and resolution in https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/designer-error-codes#error-0014',)",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-01-14T03:38:27.7Z",
                "Answer_upvote_count":1,
                "Answer_body":"@Dexter-9539 Yes, The error needs to be resolved. It looks like a data error and if you follow the link mentioned in the error the steps indicate possible ways to remove the unique values that are not required to be passed for training. I would recommend to follow this suggestion based on the error.\n\nFor ID columns which is not meaningful features during training a model, you can use Edit Metadata to mark that column as Clear feature and it will not be used during training a model.\n\nYou can mark TotalCharges as clear feature in this case on the edit metadata module and check if it works. Thanks!!\n\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"UNZIP large zip file in azure machine learning",
        "Question_creation_time":1612431352160,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/258610\/unzip-large-zip-file-in-azure-machine-learning.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I have a big zip file, I need to unzip it in order to use the files in my notebook\n\nI used this script in my notebook :\n\nimport os\nimport zipfile\nlocal_zip = 'Caltech101.zip'\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('Caltech101')\nzip_ref.close()\n\nit succeeded (green v in the notebook), but only the first two folders were unzipped.\nthis file is only 130 MB\nI also need to unzip 3 GB zip file",
        "Answers":[
            {
                "Answer_creation_time":"2021-02-05T18:20:48.12Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for following up. Can you please try available public datasets in this dataset repository to determine if you experience the same issue? If you're able to upload other files to Azure ML Notebook and unzip them successfully, then the issue is most likely related to your file content\/format.",
                "Answer_comment_count":6,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Time series training for anomal detect",
        "Question_creation_time":1661358044013,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/980372\/time-series-training-for-anomal-detect.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I have not seen any doc talking about this topic, is this supported in Microsoft Machine Learning? Is this a good plan if anyone has tried?",
        "Answers":[
            {
                "Answer_creation_time":"2022-08-24T22:18:48.52Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @minhoolee-9603\n\nThanks for using Microsoft Q&A platform, Azure Machine Learning Serivce support time series training - https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-forecast\n\nYou can check above document to see how to set up a quick model.\n\nBut for Anomaly Dectection, I think Anomaly Detector API is a better choice for you - https:\/\/docs.microsoft.com\/en-us\/azure\/cognitive-services\/anomaly-detector\/\n\nI hope this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Key for ML Endpoint",
        "Question_creation_time":1648186512237,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/787004\/key-for-ml-endpoint.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\nI am new to Azure.\nI have created ML endpoint and when I try to access, I see a message \"Unauthorized, no token matched\".\nI know its Key based Auth.\nwhere can I find this key? can someone help me?\n\nregards,\n\nRohan",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-28T07:40:44.61Z",
                "Answer_upvote_count":0,
                "Answer_body":"@ROHANC-4945 I believe you are using the Azure ML Designer portal to deploy your endpoints.\nIn this case you will get the token for your endpoint from the consume tab as seen below:\n\nThe tab also lists snippets to call the endpoint programatically for reference.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML deployment fails",
        "Question_creation_time":1644780118307,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/733521\/azure-ml-deployment-fails.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I'm trying to deploy an ML model as a WebService using Azure ML Endpoints, but it fails. Below is the code and the error I get. I'm using azureml-core SDK for this.\n\n\n\n\nI'm using this link as a reference for my deployment:\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/deployment\/deploy-multi-model\/multi-model-register-and-deploy.ipynb",
        "Answers":[
            {
                "Answer_creation_time":"2022-02-14T13:00:22.453Z",
                "Answer_upvote_count":0,
                "Answer_body":"@RajamannarAK-6287 Thanks for the question. Below is the document for common errors to Troubleshooting remote model deployment.\n\nIf you have problems when deploying a model to ACI or AKS, deploy it as a local web service. Using a local web service makes it easier to troubleshoot problems. To troubleshoot a deployment locally, see the local troubleshooting article.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment?tabs=azcli",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"AZ ML Designer. Swagger file missing on deployment. Test empty.",
        "Question_creation_time":1657708598787,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/925083\/az-ml-designer-swagger-file-missing-on-deployment.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi Guys,\nAm trying to deploy a very small logistic regression model endpoint using AZML Designer. But I cant get the \"Test\" to show as I expect it to . I think I have narrowed it down to the same issue as the others on this thread. Please find attached the images and logs\n1.This is the inference pipeline\n\n\n\n\n\n2.This is the deployed endpoint\n\n\n\n\n\n3.The test section of the endpoint\n\n\nSwagger missing info from the logs\n\n\n\n\n\n5.Expected test section\n\n\nEntire deployment log dump below signature\n\nregards\nSharath\n\n\n\n\n\n 2022-07-13T09:30:23,130461474+00:00 - iot-server\/run \n 2022-07-13T09:30:23,157246653+00:00 - rsyslog\/run \n 2022-07-13T09:30:23,159450135+00:00 - nginx\/run \n 2022-07-13T09:30:23,197683320+00:00 - gunicorn\/run \n 2022-07-13T09:30:23,199090409+00:00 | gunicorn\/run | \n 2022-07-13T09:30:23,227403276+00:00 | gunicorn\/run | ###############################################\n 2022-07-13T09:30:23,257497428+00:00 | gunicorn\/run | AzureML Container Runtime Information\n 2022-07-13T09:30:23,267026449+00:00 | gunicorn\/run | ###############################################\n 2022-07-13T09:30:23,268411738+00:00 | gunicorn\/run | \n 2022-07-13T09:30:23,276054375+00:00 | gunicorn\/run | \n 2022-07-13T09:30:23,278626954+00:00 | gunicorn\/run | AzureML image information: openmpi3.1.2-ubuntu18.04, Materializaton Build:20220708.v2\n 2022-07-13T09:30:23,286217091+00:00 | gunicorn\/run | \n 2022-07-13T09:30:23,287579180+00:00 | gunicorn\/run | \n 2022-07-13T09:30:23,295279917+00:00 | gunicorn\/run | PATH environment variable: \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/bin:\/opt\/miniconda\/bin:\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin\n 2022-07-13T09:30:23,296728705+00:00 | gunicorn\/run | PYTHONPATH environment variable: \n 2022-07-13T09:30:23,298062894+00:00 | gunicorn\/run | \n 2022-07-13T09:30:23,306503424+00:00 | gunicorn\/run | Pip Dependencies (before dynamic installation)\n    \n EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n 2022-07-13T09:30:23,602722185+00:00 - iot-server\/finish 1 0\n 2022-07-13T09:30:23,604481070+00:00 - Exit code 1 is normal. Not restarting iot-server.\n adal==1.2.7\n applicationinsights==0.11.10\n attrs==21.4.0\n azure-common==1.1.28\n azure-core==1.24.2\n azure-graphrbac==0.61.1\n azure-identity==1.10.0\n azure-mgmt-authorization==0.61.0\n azure-mgmt-containerregistry==10.0.0\n azure-mgmt-core==1.3.1\n azure-mgmt-keyvault==9.3.0\n azure-mgmt-resource==13.0.0\n azure-mgmt-storage==11.2.0\n azure-storage-blob==1.5.0\n azure-storage-common==1.4.2\n azureml-core==1.36.0.post2\n azureml-dataprep==2.24.4\n azureml-dataprep-native==38.0.0\n azureml-dataprep-rslex==2.0.3\n azureml-dataset-runtime==1.36.0\n azureml-defaults==1.36.0\n azureml-designer-classic-modules==0.0.161\n azureml-designer-core==0.0.68\n azureml-designer-internal==0.0.56\n azureml-inference-server-http==0.4.13\n azureml-interpret==1.36.0\n azureml-model-management-sdk==1.0.1b6.post1\n azureml-pipeline-core==1.36.0\n azureml-telemetry==1.36.0\n backports.tempfile==1.0\n backports.weakref==1.0.post1\n blis==0.2.4\n cachetools==4.2.4\n certifi==2022.6.15\n cffi==1.12.3\n chardet==3.0.4\n charset-normalizer==2.0.12\n click==7.1.2\n cloudpickle==2.1.0\n configparser==3.7.4\n contextlib2==21.6.0\n contextvars==2.4\n cryptography==37.0.4\n cycler==0.11.0\n cymem==2.0.6\n dill==0.3.4\n distro==1.4.0\n docker==5.0.3\n dotnetcore2==3.1.23\n en-core-web-sm @ https:\/\/github.com\/explosion\/spacy-models\/releases\/download\/en_core_web_sm-2.1.0\/en_core_web_sm-2.1.0.tar.gz\n Flask==1.0.3\n fusepy==3.0.1\n gensim==3.8.3\n google-api-core==2.8.2\n google-auth==2.9.0\n googleapis-common-protos==1.56.3\n gunicorn==20.1.0\n idna==3.3\n imbalanced-learn==0.4.3\n immutables==0.18\n importlib-metadata==4.8.3\n importlib-resources==5.4.0\n inference-schema==1.3.0\n interpret-community==0.21.0\n interpret-core==0.2.6\n isodate==0.6.1\n itsdangerous==1.1.0\n jeepney==0.7.1\n Jinja2==3.0.3\n jmespath==0.10.0\n joblib==0.14.0\n json-logging-py==0.2\n jsonpickle==2.2.0\n jsonschema==3.0.1\n kiwisolver==1.3.1\n liac-arff==2.5.0\n lightgbm==3.2.1\n llvmlite==0.36.0\n MarkupSafe==2.0.1\n matplotlib==3.1.3\n more-itertools==6.0.0\n msal==1.18.0\n msal-extensions==1.0.0\n msrest==0.7.1\n msrestazure==0.6.4\n murmurhash==1.0.7\n ndg-httpsclient==0.5.1\n nimbusml==1.6.1\n numba==0.53.1\n numpy @ file:\/\/\/home\/conda\/feedstock_root\/build_artifacts\/numpy_1626681920064\/work\n oauthlib==3.2.0\n opencensus==0.10.0\n opencensus-context==0.1.2\n opencensus-ext-azure==1.1.5\n packaging==21.3\n pandas==1.0.4\n pathspec==0.9.0\n Pillow==8.3.2\n plac==0.9.6\n portalocker==2.5.1\n preshed==2.0.1\n protobuf==3.19.4\n psutil==5.9.1\n pyarrow==0.16.0\n pyasn1==0.4.8\n pyasn1-modules==0.2.8\n pycparser==2.21\n pycryptodomex==3.7.3\n PyJWT==2.4.0\n pyOpenSSL==20.0.1\n pyparsing==3.0.9\n pyrsistent==0.18.0\n python-dateutil==2.8.2\n pytz==2022.1\n requests==2.27.1\n requests-oauthlib==1.3.1\n rsa==4.8\n ruamel.yaml==0.16.10\n ruamel.yaml.clib==0.2.6\n scikit-learn==0.22.2\n scikit-surprise==1.0.6\n scipy==1.4.1\n seaborn==0.10.0\n SecretStorage==3.3.2\n shap==0.39.0\n six @ file:\/\/\/home\/conda\/feedstock_root\/build_artifacts\/six_1620240208055\/work\n slicer==0.0.7\n smart-open==6.0.0\n spacy==2.1.7\n srsly==1.0.5\n thinc==7.0.8\n tqdm==4.64.0\n typing-extensions==4.1.1\n urllib3==1.26.10\n wasabi==0.9.1\n websocket-client==1.3.1\n Werkzeug==1.0.1\n wrapt==1.12.1\n zipp==3.6.0\n    \n 2022-07-13T09:30:24,740357515+00:00 | gunicorn\/run | \n 2022-07-13T09:30:24,742081301+00:00 | gunicorn\/run | ###############################################\n 2022-07-13T09:30:24,747351958+00:00 | gunicorn\/run | AzureML Inference Server\n 2022-07-13T09:30:24,750376533+00:00 | gunicorn\/run | ###############################################\n 2022-07-13T09:30:24,752770513+00:00 | gunicorn\/run | \n 2022-07-13T09:30:27,698759963+00:00 | gunicorn\/run | Starting AzureML Inference Server HTTP.\n    \n Azure ML Inferencing HTTP server v0.4.13\n    \n    \n Server Settings\n ---------------\n Entry Script Name: main.py\n Model Directory: \/var\/azureml-app\/azureml-models\/amlstudio-loanv1ep002\/1\n Worker Count: 1\n Worker Timeout (seconds): 300\n Server Port: 31311\n Application Insights Enabled: false\n Application Insights Key: AppInsights key provided\n    \n    \n Server Routes\n ---------------\n Liveness Probe: GET   127.0.0.1:31311\/\n Score:          POST  127.0.0.1:31311\/score\n    \n Starting gunicorn 20.1.0\n Listening at: http:\/\/0.0.0.0:31311 (17)\n Using worker: sync\n Booting worker with pid: 70\n Collecting azureml-designer-serving==0.0.10\n   Downloading azureml_designer_serving-0.0.10-py3-none-any.whl (20 kB)\n Collecting azureml-contrib-services\n   Downloading azureml_contrib_services-1.43.0-py3-none-any.whl (4.8 kB)\n Requirement already satisfied: azureml-defaults in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-serving==0.0.10) (1.36.0)\n Requirement already satisfied: azureml-designer-core[image,model]>=0.0.32 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-serving==0.0.10) (0.0.68)\n Requirement already satisfied: Flask in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-contrib-services->azureml-designer-serving==0.0.10) (1.0.3)\n Requirement already satisfied: azureml-core~=1.36.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-defaults->azureml-designer-serving==0.0.10) (1.36.0.post2)\n Requirement already satisfied: json-logging-py==0.2 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-defaults->azureml-designer-serving==0.0.10) (0.2)\n Requirement already satisfied: azureml-inference-server-http~=0.4.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-defaults->azureml-designer-serving==0.0.10) (0.4.13)\n Requirement already satisfied: configparser==3.7.4 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-defaults->azureml-designer-serving==0.0.10) (3.7.4)\n Requirement already satisfied: azureml-dataset-runtime[fuse]~=1.36.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-defaults->azureml-designer-serving==0.0.10) (1.36.0)\n Requirement already satisfied: pyarrow==0.16.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (0.16.0)\n Requirement already satisfied: jsonschema==3.0.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (3.0.1)\n Collecting numpy==1.18.1\n   Downloading numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)\n Requirement already satisfied: pandas==1.0.4 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (1.0.4)\n Collecting python-dateutil==2.8.1\n   Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n Requirement already satisfied: distro==1.4.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (1.4.0)\n Requirement already satisfied: ruamel.yaml==0.16.10 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (0.16.10)\n Requirement already satisfied: pycryptodomex==3.7.3 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (3.7.3)\n Requirement already satisfied: more-itertools==6.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (6.0.0)\n Requirement already satisfied: Pillow==8.3.2; extra == \"image\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (8.3.2)\n Collecting cloudpickle==1.2.2; extra == \"model\"\n   Downloading cloudpickle-1.2.2-py2.py3-none-any.whl (25 kB)\n Requirement already satisfied: Werkzeug>=0.14 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from Flask->azureml-contrib-services->azureml-designer-serving==0.0.10) (1.0.1)\n Requirement already satisfied: Jinja2>=2.10 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from Flask->azureml-contrib-services->azureml-designer-serving==0.0.10) (3.0.3)\n Requirement already satisfied: click>=5.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from Flask->azureml-contrib-services->azureml-designer-serving==0.0.10) (7.1.2)\n Requirement already satisfied: itsdangerous>=0.24 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from Flask->azureml-contrib-services->azureml-designer-serving==0.0.10) (1.1.0)\n Requirement already satisfied: azure-graphrbac<1.0.0,>=0.40.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (0.61.1)\n Requirement already satisfied: PyJWT<3.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (2.4.0)\n Requirement already satisfied: jmespath<1.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (0.10.0)\n Requirement already satisfied: azure-common<2.0.0,>=1.1.12 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (1.1.28)\n Requirement already satisfied: azure-mgmt-resource<15.0.0,>=1.2.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (13.0.0)\n Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0\n   Downloading cryptography-3.4.8-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n Requirement already satisfied: jsonpickle<3.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (2.2.0)\n Requirement already satisfied: azure-mgmt-containerregistry>=2.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (10.0.0)\n Requirement already satisfied: ndg-httpsclient<=0.5.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (0.5.1)\n Requirement already satisfied: docker<6.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (5.0.3)\n Requirement already satisfied: msrestazure<=0.6.4,>=0.4.33 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (0.6.4)\n Requirement already satisfied: backports.tempfile in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (1.0)\n Requirement already satisfied: pyopenssl<21.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (20.0.1)\n Requirement already satisfied: azure-mgmt-storage<16.0.0,>=1.5.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (11.2.0)\n Requirement already satisfied: msrest<1.0.0,>=0.5.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (0.7.1)\n Requirement already satisfied: adal<=1.2.7,>=1.2.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (1.2.7)\n Requirement already satisfied: azure-mgmt-keyvault<10.0.0,>=0.40.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (9.3.0)\n Requirement already satisfied: requests<3.0.0,>=2.19.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (2.27.1)\n Requirement already satisfied: contextlib2<22.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (21.6.0)\n Requirement already satisfied: SecretStorage<4.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (3.3.2)\n Requirement already satisfied: azure-mgmt-authorization<1.0.0,>=0.40.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (0.61.0)\n Requirement already satisfied: pytz in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (2022.1)\n Collecting urllib3<=1.26.7,>=1.23\n   Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n Requirement already satisfied: pathspec<1.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (0.9.0)\n Requirement already satisfied: opencensus-ext-azure~=1.1.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (1.1.5)\n Requirement already satisfied: inference-schema==1.3.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (1.3.0)\n Requirement already satisfied: gunicorn==20.1.0; platform_system != \"Windows\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (20.1.0)\n Requirement already satisfied: applicationinsights>=0.11.7 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (0.11.10)\n Requirement already satisfied: azureml-dataprep<2.25.0a,>=2.24.0a in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-dataset-runtime[fuse]~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (2.24.4)\n Requirement already satisfied: fusepy<4.0.0,>=3.0.1; extra == \"fuse\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-dataset-runtime[fuse]~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (3.0.1)\n Requirement already satisfied: six>=1.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from pyarrow==0.16.0->azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (1.16.0)\n Requirement already satisfied: attrs>=17.4.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from jsonschema==3.0.1->azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (21.4.0)\n Requirement already satisfied: setuptools in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from jsonschema==3.0.1->azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (58.0.4)\n Requirement already satisfied: pyrsistent>=0.14.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from jsonschema==3.0.1->azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (0.18.0)\n Requirement already satisfied: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from ruamel.yaml==0.16.10->azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (0.2.6)\n Requirement already satisfied: MarkupSafe>=2.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from Jinja2>=2.10->Flask->azureml-contrib-services->azureml-designer-serving==0.0.10) (2.0.1)\n Requirement already satisfied: cffi>=1.12 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (1.12.3)\n Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from jsonpickle<3.0.0->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (4.8.3)\n Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azure-mgmt-containerregistry>=2.0.0->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (1.3.1)\n Requirement already satisfied: pyasn1>=0.1.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from ndg-httpsclient<=0.5.1->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (0.4.8)\n Requirement already satisfied: websocket-client>=0.32.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from docker<6.0.0->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (1.3.1)\n Requirement already satisfied: backports.weakref in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from backports.tempfile->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (1.0.post1)\n Requirement already satisfied: isodate>=0.6.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from msrest<1.0.0,>=0.5.1->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (0.6.1)\n Requirement already satisfied: azure-core>=1.24.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from msrest<1.0.0,>=0.5.1->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (1.24.2)\n Requirement already satisfied: requests-oauthlib>=0.5.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from msrest<1.0.0,>=0.5.1->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (1.3.1)\n Requirement already satisfied: certifi>=2017.4.17 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from msrest<1.0.0,>=0.5.1->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (2022.6.15)\n Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from requests<3.0.0,>=2.19.1->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (2.0.12)\n Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from requests<3.0.0,>=2.19.1->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (3.3)\n Requirement already satisfied: jeepney>=0.6 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from SecretStorage<4.0.0->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (0.7.1)\n Requirement already satisfied: opencensus<1.0.0,>=0.10.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (0.10.0)\n Requirement already satisfied: psutil>=5.6.3 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (5.9.1)\n Requirement already satisfied: azure-identity<2.0.0,>=1.5.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (1.10.0)\n Requirement already satisfied: wrapt<=1.12.1,>=1.11.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from inference-schema==1.3.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (1.12.1)\n Requirement already satisfied: azureml-dataprep-rslex~=2.0.0dev0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-dataprep<2.25.0a,>=2.24.0a->azureml-dataset-runtime[fuse]~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (2.0.3)\n Collecting dotnetcore2<3.0.0,>=2.1.14\n   Downloading dotnetcore2-2.1.23-py3-none-manylinux1_x86_64.whl (29.3 MB)\n Requirement already satisfied: azureml-dataprep-native<39.0.0,>=38.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-dataprep<2.25.0a,>=2.24.0a->azureml-dataset-runtime[fuse]~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (38.0.0)\n Requirement already satisfied: pycparser in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from cffi>=1.12->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (2.21)\n Requirement already satisfied: zipp>=0.5 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonpickle<3.0.0->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (3.6.0)\n Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonpickle<3.0.0->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (4.1.1)\n Requirement already satisfied: oauthlib>=3.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from requests-oauthlib>=0.5.0->msrest<1.0.0,>=0.5.1->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (3.2.0)\n Requirement already satisfied: opencensus-context>=0.1.2 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from opencensus<1.0.0,>=0.10.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (0.1.2)\n Requirement already satisfied: google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from opencensus<1.0.0,>=0.10.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (2.8.2)\n Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (1.0.0)\n Requirement already satisfied: msal<2.0.0,>=1.12.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (1.18.0)\n Requirement already satisfied: contextvars; python_version >= \"3.6\" and python_version < \"3.7\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from opencensus-context>=0.1.2->opencensus<1.0.0,>=0.10.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (2.4)\n Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.10.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (2.9.0)\n Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.10.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (1.56.3)\n Requirement already satisfied: protobuf<5.0.0dev,>=3.15.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.10.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (3.19.4)\n Requirement already satisfied: portalocker<3,>=1.0; python_version >= \"3.5\" and platform_system != \"Windows\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (2.5.1)\n Requirement already satisfied: immutables>=0.9 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from contextvars; python_version >= \"3.6\" and python_version < \"3.7\"->opencensus-context>=0.1.2->opencensus<1.0.0,>=0.10.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (0.18)\n Requirement already satisfied: pyasn1-modules>=0.2.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.10.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (0.2.8)\n Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.10.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (4.8)\n Requirement already satisfied: cachetools<6.0,>=2.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.10.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (4.2.4)\n Installing collected packages: azureml-contrib-services, azureml-designer-serving, numpy, python-dateutil, cloudpickle, cryptography, urllib3, dotnetcore2\n   Attempting uninstall: numpy\n     Found existing installation: numpy 1.19.5\n     Uninstalling numpy-1.19.5:\n       Successfully uninstalled numpy-1.19.5\n   Attempting uninstall: python-dateutil\n     Found existing installation: python-dateutil 2.8.2\n     Uninstalling python-dateutil-2.8.2:\n       Successfully uninstalled python-dateutil-2.8.2\n   Attempting uninstall: cloudpickle\n     Found existing installation: cloudpickle 2.1.0\n     Uninstalling cloudpickle-2.1.0:\n       Successfully uninstalled cloudpickle-2.1.0\n   Attempting uninstall: cryptography\n     Found existing installation: cryptography 37.0.4\n     Uninstalling cryptography-37.0.4:\n       Successfully uninstalled cryptography-37.0.4\n   Attempting uninstall: urllib3\n     Found existing installation: urllib3 1.26.10\n     Uninstalling urllib3-1.26.10:\n       Successfully uninstalled urllib3-1.26.10\n   Attempting uninstall: dotnetcore2\n     Found existing installation: dotnetcore2 3.1.23\n     Uninstalling dotnetcore2-3.1.23:\n       Successfully uninstalled dotnetcore2-3.1.23\n ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n    \n We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n    \n azureml-dataset-runtime 1.36.0 requires pyarrow<4.0.0,>=0.17.0, but you'll have pyarrow 0.16.0 which is incompatible.\n azureml-dataprep 2.24.4 requires azure-identity==1.7.0, but you'll have azure-identity 1.10.0 which is incompatible.\n Successfully installed azureml-contrib-services-1.43.0 azureml-designer-serving-0.0.10 cloudpickle-1.2.2 cryptography-3.4.8 dotnetcore2-2.1.23 numpy-1.18.1 python-dateutil-2.8.1 urllib3-1.26.7\n Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (urllib3 1.26.10 (\/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages), Requirement.parse('urllib3<=1.26.7,>=1.23'), {'azureml-core'}).\n Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (urllib3 1.26.10 (\/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages), Requirement.parse('urllib3<=1.26.7,>=1.23'), {'azureml-core'}).\n Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (urllib3 1.26.10 (\/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages), Requirement.parse('urllib3<=1.26.7,>=1.23'), {'azureml-core'}).\n Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (urllib3 1.26.10 (\/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages), Requirement.parse('urllib3<=1.26.7,>=1.23')).\n Initializing logger\n 2022-07-13 09:30:57,630 | root | INFO | Starting up app insights client\n logging socket was found. logging is available.\n logging socket was found. logging is available.\n 2022-07-13 09:30:57,631 | root | INFO | Starting up request id generator\n 2022-07-13 09:30:57,631 | root | INFO | Starting up app insight hooks\n 2022-07-13 09:30:57,632 | root | INFO | Invoking user's init function\n Trying to reload werkzeug.\n Successfully reloaded werkzeug.\n pip freeze result:\n adal==1.2.7\n applicationinsights==0.11.10\n attrs==21.4.0\n azure-common==1.1.28\n azure-core==1.24.2\n azure-graphrbac==0.61.1\n azure-identity==1.10.0\n azure-mgmt-authorization==0.61.0\n azure-mgmt-containerregistry==10.0.0\n azure-mgmt-core==1.3.1\n azure-mgmt-keyvault==9.3.0\n azure-mgmt-resource==13.0.0\n azure-mgmt-storage==11.2.0\n azure-storage-blob==1.5.0\n azure-storage-common==1.4.2\n azureml-contrib-services==1.43.0\n azureml-core==1.36.0.post2\n azureml-dataprep==2.24.4\n azureml-dataprep-native==38.0.0\n azureml-dataprep-rslex==2.0.3\n azureml-dataset-runtime==1.36.0\n azureml-defaults==1.36.0\n azureml-designer-classic-modules==0.0.161\n azureml-designer-core==0.0.68\n azureml-designer-internal==0.0.56\n azureml-designer-serving==0.0.10\n azureml-inference-server-http==0.4.13\n azureml-interpret==1.36.0\n azureml-model-management-sdk==1.0.1b6.post1\n azureml-pipeline-core==1.36.0\n azureml-telemetry==1.36.0\n backports.tempfile==1.0\n backports.weakref==1.0.post1\n blis==0.2.4\n cachetools==4.2.4\n certifi==2022.6.15\n cffi==1.12.3\n chardet==3.0.4\n charset-normalizer==2.0.12\n click==7.1.2\n cloudpickle==1.2.2\n configparser==3.7.4\n contextlib2==21.6.0\n contextvars==2.4\n cryptography==3.4.8\n cycler==0.11.0\n cymem==2.0.6\n dill==0.3.4\n distro==1.4.0\n docker==5.0.3\n dotnetcore2==2.1.23\n en-core-web-sm @ https:\/\/github.com\/explosion\/spacy-models\/releases\/download\/en_core_web_sm-2.1.0\/en_core_web_sm-2.1.0.tar.gz\n Flask==1.0.3\n fusepy==3.0.1\n gensim==3.8.3\n google-api-core==2.8.2\n google-auth==2.9.0\n googleapis-common-protos==1.56.3\n gunicorn==20.1.0\n idna==3.3\n imbalanced-learn==0.4.3\n immutables==0.18\n importlib-metadata==4.8.3\n importlib-resources==5.4.0\n inference-schema==1.3.0\n interpret-community==0.21.0\n interpret-core==0.2.6\n isodate==0.6.1\n itsdangerous==1.1.0\n jeepney==0.7.1\n Jinja2==3.0.3\n jmespath==0.10.0\n joblib==0.14.0\n json-logging-py==0.2\n jsonpickle==2.2.0\n jsonschema==3.0.1\n kiwisolver==1.3.1\n liac-arff==2.5.0\n lightgbm==3.2.1\n llvmlite==0.36.0\n MarkupSafe==2.0.1\n matplotlib==3.1.3\n more-itertools==6.0.0\n msal==1.18.0\n msal-extensions==1.0.0\n msrest==0.7.1\n msrestazure==0.6.4\n murmurhash==1.0.7\n ndg-httpsclient==0.5.1\n nimbusml==1.6.1\n numba==0.53.1\n numpy==1.18.1\n oauthlib==3.2.0\n opencensus==0.10.0\n opencensus-context==0.1.2\n opencensus-ext-azure==1.1.5\n packaging==21.3\n pandas==1.0.4\n pathspec==0.9.0\n Pillow==8.3.2\n plac==0.9.6\n portalocker==2.5.1\n preshed==2.0.1\n protobuf==3.19.4\n psutil==5.9.1\n pyarrow==0.16.0\n pyasn1==0.4.8\n pyasn1-modules==0.2.8\n pycparser==2.21\n pycryptodomex==3.7.3\n PyJWT==2.4.0\n pyOpenSSL==20.0.1\n pyparsing==3.0.9\n pyrsistent==0.18.0\n python-dateutil==2.8.1\n pytz==2022.1\n requests==2.27.1\n requests-oauthlib==1.3.1\n rsa==4.8\n ruamel.yaml==0.16.10\n ruamel.yaml.clib==0.2.6\n scikit-learn==0.22.2\n scikit-surprise==1.0.6\n scipy==1.4.1\n seaborn==0.10.0\n SecretStorage==3.3.2\n shap==0.39.0\n six @ file:\/\/\/home\/conda\/feedstock_root\/build_artifacts\/six_1620240208055\/work\n slicer==0.0.7\n smart-open==6.0.0\n spacy==2.1.7\n srsly==1.0.5\n thinc==7.0.8\n tqdm==4.64.0\n typing-extensions==4.1.1\n urllib3==1.26.7\n wasabi==0.9.1\n websocket-client==1.3.1\n Werkzeug==1.0.1\n wrapt==1.12.1\n zipp==3.6.0\n    \n Model: name=amlstudio-loanv1ep002, version=1\n Loading static source Resources\/1\/ - Start:\n Loaded TransformationDirectory(meta={'type': 'TransformationDirectory', 'extension': {}, 'transform_type': 'Pickle', 'file_path': 'data.itransform'}) from studiomodelpackage\/Resources\/1.\n Loading static source Resources\/1\/ - End with 0.1387s elapsed.\n Loading static source Resources\/2\/ - Start:\n Loaded ModelDirectory(meta={'type': 'ModelDirectory', 'extension': {}, 'model': 'model_spec.yaml', 'registerModel': True, 'modelOutputPath': 'trained_model_outputs'}) from studiomodelpackage\/Resources\/2.\n Loading static source Resources\/2\/ - End with 1.5108s elapsed.\n initializing node 1\n ALGHOST 0.0.161\n Load pyarrow.parquet explicitly: <module 'pyarrow.parquet' from '\/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages\/pyarrow\/parquet.py'>\n initializing node 2\n ALGHOST 0.0.161\n Load pyarrow.parquet explicitly: <module 'pyarrow.parquet' from '\/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages\/pyarrow\/parquet.py'>\n initializing node 3\n ALGHOST 0.0.161\n Load pyarrow.parquet explicitly: <module 'pyarrow.parquet' from '\/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages\/pyarrow\/parquet.py'>\n Init: Graph has been loaded\n 2022-07-13 09:31:00,723 | root | INFO | Users's init has completed successfully\n 2022-07-13 09:31:00,730 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n 2022-07-13 09:31:00,731 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n 2022-07-13 09:31:00,732 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n 2022-07-13 09:31:00,939 | root | INFO | Swagger file not present\n 2022-07-13 09:31:00,939 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:31:00 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:31:01,214 | root | INFO | Swagger file not present\n 2022-07-13 09:31:01,214 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:31:01 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:31:01,229 | root | INFO | Swagger file not present\n 2022-07-13 09:31:01,229 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:31:01 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"curl\/7.80.0\"\n 2022-07-13 09:31:02,201 | root | INFO | Swagger file not present\n 2022-07-13 09:31:02,202 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:31:02 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"curl\/7.80.0\"\n 2022-07-13 09:31:04,052 | root | INFO | Swagger file not present\n 2022-07-13 09:31:04,052 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:31:04 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:31:04,335 | root | INFO | Scoring Timer is set to 60.0 seconds\n Handling http request - Start:\n 2022-07-13 09:31:04,335 studio.azureml.designer.serving.dagengine.request_handler INFO       |   Run: is_classic = False, with_details = False, verbose = True\n 2022-07-13 09:31:04,336 studio.core          INFO       |   Pre-processing - Start:\n 2022-07-13 09:31:04,336 studio.core          INFO       |   Pre-processing - End with 0.0001s elapsed.\n 2022-07-13 09:31:04,336 studio.core          INFO       |   Processing - Start:\n 2022-07-13 09:31:04,360 studio.common        WARNING    |   |   0 and empty string will be converted into False\n 2022-07-13 09:31:04,377 studio.common        WARNING    |   |   0 and empty string will be converted into False\n 2022-07-13 09:31:04,418 studio.core          INFO       |   |   Executing node 1: Apply Transformation - Start:\n 2022-07-13 09:31:04,426 studio.common        DEBUG      |   |   |   Load schema successfully.\n 2022-07-13 09:31:04,429 studio.modulehost    INFO       |   |   |   Return without parsing\n 2022-07-13 09:31:04,429 studio.modulehost    INFO       |   |   |   Return without parsing\n 2022-07-13 09:31:04,435 studio.core          INFO       |   |   |   ApplyTransformationModule.run - Start:\n 2022-07-13 09:31:04,435 studio.core          DEBUG      |   |   |   |   kwargs:\n 2022-07-13 09:31:04,435 studio.core          DEBUG      |   |   |   |   |   transform = <azureml.studio.modules.datatransform.clean_missing_data.clean_missing_transform.CleanMissingValueTransform object at 0x7f72fe544198>\n 2022-07-13 09:31:04,435 studio.core          DEBUG      |   |   |   |   |   data = <azureml.studio.common.datatable.data_table.DataTable object at 0x7f72fdd6afd0>\n 2022-07-13 09:31:04,436 studio.core          DEBUG      |   |   |   |   validated_args:\n 2022-07-13 09:31:04,436 studio.core          DEBUG      |   |   |   |   |   transform = <azureml.studio.modules.datatransform.clean_missing_data.clean_missing_transform.CleanMissingValueTransform object at 0x7f72fe544198>\n 2022-07-13 09:31:04,436 studio.core          DEBUG      |   |   |   |   |   data = <azureml.studio.common.datatable.data_table.DataTable object at 0x7f72fdd6afd0>\n 2022-07-13 09:31:04,436 studio.module        INFO       |   |   |   |   Get column indexes with wanted ratio\n 2022-07-13 09:31:04,436 studio.core          INFO       |   |   |   |   CleanMissingValueTransform.get_column_indexes_with_wanted_ratio - Start:\n 2022-07-13 09:31:04,439 studio.core          INFO       |   |   |   |   CleanMissingValueTransform.get_column_indexes_with_wanted_ratio - End with 0.0026s elapsed.\n 2022-07-13 09:31:04,439 studio.module        INFO       |   |   |   |   Replace row with missing value\n 2022-07-13 09:31:04,439 studio.core          INFO       |   |   |   |   DataTable.clone - Start:\n 2022-07-13 09:31:04,446 studio.core          INFO       |   |   |   |   DataTable.clone - End with 0.0066s elapsed.\n 2022-07-13 09:31:04,446 studio.core          INFO       |   |   |   |   Find row_indexes_to_remove - Start:\n 2022-07-13 09:31:04,449 studio.core          INFO       |   |   |   |   Find row_indexes_to_remove - End with 0.0030s elapsed.\n 2022-07-13 09:31:04,449 studio.core          INFO       |   |   |   |   Remove rows by indexes - Start:\n 2022-07-13 09:31:04,456 studio.core          INFO       |   |   |   |   Remove rows by indexes - End with 0.0012s elapsed.\n 2022-07-13 09:31:04,456 studio.core          DEBUG      |   |   |   |   return:\n 2022-07-13 09:31:04,456 studio.core          DEBUG      |   |   |   |   |   [0] = <DataTable \"Dataset\" (1 Rows, 11 Cols) at 0x00007F72FDD957F0>\n 2022-07-13 09:31:04,456 studio.core          INFO       |   |   |   ApplyTransformationModule.run - End with 0.0211s elapsed.\n 2022-07-13 09:31:04,457 studio.core          INFO       |   |   Executing node 1: Apply Transformation - End with 0.0388s elapsed.\n 2022-07-13 09:31:04,457 studio.core          INFO       |   |   Executing node 2: Score Model - Start:\n 2022-07-13 09:31:04,457 studio.common        DEBUG      |   |   |   Load schema successfully.\n 2022-07-13 09:31:04,466 studio.modulehost    INFO       |   |   |   Return without parsing\n 2022-07-13 09:31:04,466 studio.modulehost    INFO       |   |   |   Return without parsing\n 2022-07-13 09:31:04,466 studio.modulehost    INFO       |   |   |   Parse bool parameter\n 2022-07-13 09:31:04,466 studio.core          INFO       |   |   |   ScoreModelModule.run - Start:\n 2022-07-13 09:31:04,466 studio.core          DEBUG      |   |   |   |   kwargs:\n 2022-07-13 09:31:04,466 studio.core          DEBUG      |   |   |   |   |   learner = <azureml.studio.modules.ml.initialize_models.binary_classifier.logistic_regression_biclassifier.logistic_regression_biclassifier.LogisticRegressionBiClassifier object at 0x7f72fe559978>\n 2022-07-13 09:31:04,466 studio.core          DEBUG      |   |   |   |   |   test_data = <azureml.studio.common.datatable.data_table.DataTable object at 0x7f72fdd6acf8>\n 2022-07-13 09:31:04,467 studio.core          DEBUG      |   |   |   |   |   append_or_result_only = True\n 2022-07-13 09:31:04,467 studio.core          DEBUG      |   |   |   |   validated_args:\n 2022-07-13 09:31:04,467 studio.core          DEBUG      |   |   |   |   |   learner = <azureml.studio.modules.ml.initialize_models.binary_classifier.logistic_regression_biclassifier.logistic_regression_biclassifier.LogisticRegressionBiClassifier object at 0x7f72fe559978>\n 2022-07-13 09:31:04,467 studio.core          DEBUG      |   |   |   |   |   test_data = <azureml.studio.common.datatable.data_table.DataTable object at 0x7f72fdd6acf8>\n 2022-07-13 09:31:04,467 studio.core          DEBUG      |   |   |   |   |   append_or_result_only = True\n 2022-07-13 09:31:04,467 studio.module        INFO       |   |   |   |   Validated testing data has 1 Row(s) and 11 Columns.\n 2022-07-13 09:31:04,474 studio.module        INFO       |   |   |   |   Check if column types of test data are consistent with train data\n 2022-07-13 09:31:04,475 studio.module        INFO       |   |   |   |   Building Normalizer - found Label column=None with encode_label=False\n 2022-07-13 09:31:04,475 studio.module        INFO       |   |   |   |   Building normalizer - found 11 feature columns with normalize_number=True\n 2022-07-13 09:31:04,475 studio.module        DEBUG      |   |   |   |   Building normalizer - found feature columns: \"Gender,Married,Dependents,Education,Self_Employed,ApplicantIncome,CoapplicantIncome,LoanAmount,Loan_Amount_Term,Credit_History,Property_Area\".\n 2022-07-13 09:31:04,476 studio.module        INFO       |   |   |   |   Building normalizer - found 6 numeric feature columns and 5 string feature columns to be encoded\n 2022-07-13 09:31:04,476 studio.module        DEBUG      |   |   |   |   Building normalizer - found numeric feature columns to be encoded: \"Married,Self_Employed,ApplicantIncome,LoanAmount,Loan_Amount_Term,Credit_History\".\n 2022-07-13 09:31:04,476 studio.module        DEBUG      |   |   |   |   Building normalizer - found string feature columns to be encoded: \"Gender,Dependents,Education,CoapplicantIncome,Property_Area\".\n 2022-07-13 09:31:04,476 studio.module        INFO       |   |   |   |   Successfully built normalizer of test data.\n 2022-07-13 09:31:04,476 studio.module        INFO       |   |   |   |   Successfully checked column types. Predicting.\n 2022-07-13 09:31:04,476 studio.core          INFO       |   |   |   |   BaseLearner._apply_normalize - Start:\n 2022-07-13 09:31:04,476 studio.core          INFO       |   |   |   |   |   Applying feature normalization - Start:\n 2022-07-13 09:31:04,476 studio.module        INFO       |   |   |   |   |   |   Start to execute normalizer.transform with column_list: \"Gender,Married,Dependents,Education,Self_Employed,ApplicantIncome,CoapplicantIncome,LoanAmount,Loan_Amount_Term,Credit_History,Property_Area\".\n 2022-07-13 09:31:04,476 studio.module        INFO       |   |   |   |   |   |   Columns of input DataFrame: 11\n 2022-07-13 09:31:04,476 studio.module        INFO       |   |   |   |   |   |   Columns to be transformed: 11\n 2022-07-13 09:31:04,476 studio.module        INFO       |   |   |   |   |   |   Columns to be encoded: 11\n 2022-07-13 09:31:04,476 studio.module        INFO       |   |   |   |   |   |   Transform with label column Loan_Status.\n 2022-07-13 09:31:04,477 studio.core          INFO       |   |   |   |   |   |   Normalizer._transform_str_feature_columns - Start:\n 2022-07-13 09:31:04,494 studio.module        INFO       |   |   |   |   |   |   |   Successfully encoded 5 string feature columns.\n 2022-07-13 09:31:04,494 studio.module        INFO       |   |   |   |   |   |   |   After transformation, 179 string feature column are generated\n 2022-07-13 09:31:04,494 studio.core          INFO       |   |   |   |   |   |   Normalizer._transform_str_feature_columns - End with 0.0174s elapsed.\n 2022-07-13 09:31:04,494 studio.core          INFO       |   |   |   |   |   |   Normalizer._transform_numeric_feature_columns - Start:\n 2022-07-13 09:31:04,497 studio.module        INFO       |   |   |   |   |   |   |   Successfully encoded 6 numeric feature columns.\n 2022-07-13 09:31:04,497 studio.core          INFO       |   |   |   |   |   |   Normalizer._transform_numeric_feature_columns - End with 0.0031s elapsed.\n 2022-07-13 09:31:04,506 studio.module        INFO       |   |   |   |   |   |   Construct train set with Sparse structure.\n 2022-07-13 09:31:04,507 studio.core          INFO       |   |   |   |   |   Applying feature normalization - End with 0.0309s elapsed.\n 2022-07-13 09:31:04,513 studio.core          INFO       |   |   |   |   BaseLearner._apply_normalize - End with 0.0367s elapsed.\n 2022-07-13 09:31:04,513 studio.core          INFO       |   |   |   |   BaseLearner._predict - Start:\n 2022-07-13 09:31:04,513 studio.core          INFO       |   |   |   |   |   Predicting probability - Start:\n 2022-07-13 09:31:04,514 studio.core          INFO       |   |   |   |   |   Predicting probability - End with 0.0004s elapsed.\n 2022-07-13 09:31:04,514 studio.core          INFO       |   |   |   |   |   calculating argmax(Probability) - Start:\n 2022-07-13 09:31:04,514 studio.core          INFO       |   |   |   |   |   calculating argmax(Probability) - End with 0.0000s elapsed.\n 2022-07-13 09:31:04,514 studio.core          INFO       |   |   |   |   BaseLearner._predict - End with 0.0007s elapsed.\n 2022-07-13 09:31:04,514 studio.module        INFO       |   |   |   |   Successfully predicted.\n 2022-07-13 09:31:04,515 studio.module        INFO       |   |   |   |   Found 2 label classes in classes_ attribute.\n 2022-07-13 09:31:04,515 studio.module        INFO       |   |   |   |   Using 1 as probability column.\n 2022-07-13 09:31:04,524 studio.module        INFO       |   |   |   |   Binary Classification Model Scored Columns are: \n 2022-07-13 09:31:04,525 studio.module        INFO       |   |   |   |   There are 2 score columns: \"Binary Class Assigned Labels,Calibrated Score\"\n 2022-07-13 09:31:04,525 studio.core          DEBUG      |   |   |   |   return:\n 2022-07-13 09:31:04,525 studio.core          DEBUG      |   |   |   |   |   [0] = <DataTable \"Dataset\" (1 Rows, 13 Cols) at 0x00007F72FDD6ACF8>\n 2022-07-13 09:31:04,525 studio.core          INFO       |   |   |   ScoreModelModule.run - End with 0.0586s elapsed.\n 2022-07-13 09:31:04,526 studio.core          INFO       |   |   Executing node 2: Score Model - End with 0.0687s elapsed.\n 2022-07-13 09:31:04,526 studio.core          INFO       |   |   Executing node 3: Select Columns in Dataset - Start:\n 2022-07-13 09:31:04,533 studio.common        DEBUG      |   |   |   Load schema successfully.\n 2022-07-13 09:31:04,536 studio.modulehost    INFO       |   |   |   Return without parsing\n 2022-07-13 09:31:04,536 studio.modulehost    INFO       |   |   |   Parse ColumnSelection parameter\n 2022-07-13 09:31:04,542 studio.core          INFO       |   |   |   SelectColumnsModule.run - Start:\n 2022-07-13 09:31:04,542 studio.core          DEBUG      |   |   |   |   kwargs:\n 2022-07-13 09:31:04,543 studio.core          DEBUG      |   |   |   |   |   table = <azureml.studio.common.datatable.data_table.DataTable object at 0x7f72fdd2c128>\n 2022-07-13 09:31:04,543 studio.core          DEBUG      |   |   |   |   |   feature_list = <azureml.studio.common.datatable.data_table.DataTableColumnSelection object at 0x7f72fdd2cda0>\n 2022-07-13 09:31:04,543 studio.core          DEBUG      |   |   |   |   validated_args:\n 2022-07-13 09:31:04,543 studio.core          DEBUG      |   |   |   |   |   table = <azureml.studio.common.datatable.data_table.DataTable object at 0x7f72fdd2c128>\n 2022-07-13 09:31:04,543 studio.core          DEBUG      |   |   |   |   |   feature_list = <azureml.studio.common.datatable.data_table.DataTableColumnSelection object at 0x7f72fdd2cda0>\n 2022-07-13 09:31:04,543 studio.module        INFO       |   |   |   |   Select column indexes from Dataset\n 2022-07-13 09:31:04,545 studio.core          DEBUG      |   |   |   |   return:\n 2022-07-13 09:31:04,545 studio.core          DEBUG      |   |   |   |   |   [0] = <DataTable (1 Rows, 2 Cols) at 0x00007F72FDD2CEB8>\n 2022-07-13 09:31:04,545 studio.core          INFO       |   |   |   SelectColumnsModule.run - End with 0.0027s elapsed.\n 2022-07-13 09:31:04,545 studio.core          INFO       |   |   Executing node 3: Select Columns in Dataset - End with 0.0197s elapsed.\n 2022-07-13 09:31:04,553 studio.core          INFO       |   Processing - End with 0.2173s elapsed.\n 2022-07-13 09:31:04,553 studio.core          INFO       |   Post-processing - Start:\n 2022-07-13 09:31:04,554 studio.core          INFO       |   Post-processing - End with 0.0000s elapsed.\n 2022-07-13 09:31:04,554 studio.core          INFO       Handling http request - End with 0.2182s elapsed.\n 2022-07-13 09:31:04,554 studio.azureml.designer.serving.dagengine.request_handler DEBUG      Run: output data(raw) = {\"Results\": {\"WebServiceOutput0\": [{\"Scored Labels\": true, \"Scored Probabilities\": 0.591091131859528}]}}\n 2022-07-13 09:31:04,554 | root | INFO | run() output is HTTP Response\n 2022-07-13 09:31:04,554 | root | INFO | 200\n 127.0.0.1 - - [13\/Jul\/2022:09:31:04 +0000] \"POST \/score?verbose=true HTTP\/1.0\" 200 104 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:34:34,646 | root | INFO | Swagger file not present\n 2022-07-13 09:34:34,647 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:34:34 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:34:36,197 | root | INFO | Swagger file not present\n 2022-07-13 09:34:36,198 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:34:36 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"curl\/7.80.0\"\n 2022-07-13 09:34:37,162 | root | INFO | Swagger file not present\n 2022-07-13 09:34:37,162 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:34:37 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:50:54,732 | root | INFO | Swagger file not present\n 2022-07-13 09:50:54,732 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:50:54 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:50:55,920 | root | INFO | Swagger file not present\n 2022-07-13 09:50:55,921 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:50:55 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"curl\/7.80.0\"\n 2022-07-13 09:53:43,395 | root | INFO | Swagger file not present\n 2022-07-13 09:53:43,395 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:53:43 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:53:43,679 | root | INFO | Swagger file not present\n 2022-07-13 09:53:43,679 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:53:43 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"curl\/7.80.0\"\n 2022-07-13 09:54:02,867 | root | INFO | Swagger file not present\n 2022-07-13 09:54:02,868 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:54:02 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"Mozilla\/5.0 (X11; Linux x86_64; rv:102.0) Gecko\/20100101 Firefox\/102.0\"\n 2022-07-13 09:54:40,605 | root | INFO | Swagger file not present\n 2022-07-13 09:54:40,605 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:54:40 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:54:49,848 | root | INFO | Swagger file not present\n 2022-07-13 09:54:49,853 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:54:49 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:54:56,064 | root | INFO | Swagger file not present\n 2022-07-13 09:54:56,065 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:54:56 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:55:31,957 | root | INFO | Swagger file not present\n 2022-07-13 09:55:31,958 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:55:31 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:55:32,313 | root | INFO | Swagger file not present\n 2022-07-13 09:55:32,313 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:55:32 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"curl\/7.80.0\"",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Machine Learning Studio Issue",
        "Question_creation_time":1627253465317,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/488593\/machine-learning-studio-issue.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hey all,\n\nI'm working on a project for school in the machine learning studio classic and when I try to execute the following python script I get errors.\n\ndef azureml_main(frame1):\nimport matplotlib\nmatplotlib.use('agg')\n\n import pandas as pd \n import numpy as np \n import matplotlib.pyplot as plt\n import statsmodels.graphics.boxplots as sm\n Azure = True\nCreate a series of bar plots for the various levels of the\nstring columns in the data frame by readmi_class.\n names = list(frame1) \n num_cols = frame1.shape[1]\n for indx in range(num_cols - 1): \n         if(frame1.ix[:, indx].dtype not in [np.int64, np.int32, np.float64]):\n             temp1 = frame1.ix[frame1.readmi_class == 'YES', indx].value_counts()\n             temp0 = frame1.ix[frame1.readmi_class == 'NO', indx].value_counts()  \n             fig = plt.figure(figsize = (12,6)) \n             fig.clf()\n             ax1 = fig.add_subplot(1, 2, 1) \n             ax0 = fig.add_subplot(1, 2, 2) \n             temp1.plot(kind = 'bar', ax = ax1)\n             ax1.set_title('Values of ' + names[indx] + '\\n for readmitted patients')\n             temp0.plot(kind = 'bar', ax = ax0)\n             ax0.set_title('Values of ' + names[indx] + '\\n for patients not readmitted')\n              \n             if(Azure == True): fig.savefig('bar_' + names[indx] +'.png') \n                 ## Now make some box plots of the columns with numerical values. \n for indx in range(num_cols):\n         if(frame1.ix[:, indx].dtype in [np.int64, np.int32, np.float64]): \n             temp1 = frame1.ix[frame1.readmi_class == 'YES', indx] \n             temp0 = frame1.ix[frame1.readmi_class == 'NO', indx]\n          \n             fig = plt.figure(figsize = (12,6))             \n             fig.clf()\n             ax1 = fig.add_subplot(1, 2, 1)             \n             ax0 = fig.add_subplot(1, 2, 2)        \n             ax1.boxplot(temp1.as_matrix())\n             ax1.set_title('Box plot of ' + names[indx] + '\\n for readmitted patients')\n             ax0.boxplot(temp0.as_matrix())\n             ax0.set_title('Box plot of ' + names[indx] + '\\n for patients not readmitted')\n              \n             if(Azure == True): fig.savefig('box_' + names[indx] +'.png')               \n return frame1\n\n\n\nThe error I'm getting is:\nError 0085: The following error occurred during script evaluation, please view the output log for more information:\n---------- Start of error message from Python interpreter ----------\nCaught exception while executing function: Traceback (most recent call last):\nFile \"C:\\server\\invokepy.py\", line 199, in batch\nodfs = mod.azureml_main(*idfs)\nFile \"C:\\temp\\1f7ee68aea7d4914a540db6181eb53c8.py\", line 46, in azureml_main\ntemp1 = frame1.ix[frame1.readmi_class == 'YES', indx]\nFile \"C:\\pyhome\\lib\\site-packages\\pandas\\core\\generic.py\", line 2669, in getattr\nreturn object.getattribute(self, name)\nAttributeError: 'DataFrame' object has no attribute 'readmi_class'\nProcess returned with non-zero exit code 1\n\n---------- End of error message from Python interpreter ----------\nStart time: UTC 07\/25\/2021 22:45:40\nEnd time: UTC 07\/25\/2021 22:46:03\n\nHas anyone encountered this or know of a fix? I appreciate any help you can provide.",
        "Answers":[
            {
                "Answer_creation_time":"2021-07-26T10:32:45.15Z",
                "Answer_upvote_count":0,
                "Answer_body":"@HarrisToby-4269 I think the issue might be in what you have connected as input to the execute python script. Because, the input from dataframe1 or frame1 does not seem to contain the required attribute that is referenced. Are you following any documentation to review your entire experiment or could you cross check for any missed modules in your experiment?\n\nI would also recommend to try the reference this way in your current script at all occurrences:\n\n temp1 = frame1.ix[indx, frame1.readmi_class == 'YES']",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"how i can recover my compute instance ?",
        "Question_creation_time":1655132409567,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/887255\/how-i-can-recover-my-compute-instance.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"error: The specified Azure ML Compute Instance cs-bi-cloud2 encountered an unusable node. Please try to restart the compute instance to recover. If it failed at creation time, please delete and try to recreate the compute instance. If the problem persists, please follow up with Azure Suppor",
        "Answers":[
            {
                "Answer_creation_time":"2022-06-27T16:42:10.383Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @csbicloudcsbicloud-1019\n\nHope you have solved this issue since you have not respponded to Ram's comment.\n\nAs the error message said, please try to restart the compute instance to recover. If it failed at creation time, please delete and try to recreate the compute instance. If the problem persists, please follow up with Azure Support.\n\nPlease let us know if you still see this error and we can help you to connect with support to check on the backend, we are glad to help more. Thanks a lot.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"AzureML Error on Linux: \"Unable to retrieve .NET dependencies. Please make sure you are connected ...\"",
        "Question_creation_time":1618767312437,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/361522\/azureml-error-on-linux-34unable-to-retrieve-net-de.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"I am getting this error on a Linux box (Gentoo w\/ .NET via Mono properly installed)\n\n\"Unable to retrieve .NET dependencies. Please make sure you are connected to the Internet and have a stable network connection.\"\n\nThe error is triggered when creating a dataset from a directory using\n\n\"dataset = Dataset.File.from_files(path=(datastore, path_to_dataset_in_datastore))\"\n\nSome system info:\nPython: 3.8.8.\nazureml-automl-core 1.26.0\nazureml-core 1.26.0\nazureml-dataprep 2.13.2\nazureml-dataprep-native 32.0.0\nazureml-dataprep-rslex 1.11.2\nazureml-dataset-runtime 1.26.0\nazureml-pipeline 1.26.0\nazureml-pipeline-core 1.26.0\nazureml-pipeline-steps 1.26.0\nazureml-sdk 1.26.0\nazureml-telemetry 1.26.0\nazureml-train 1.26.0\nazureml-train-automl-client 1.26.0\nazureml-train-core 1.26.0\nazureml-train-restclients-hyperdrive 1.26.0\n\n.NET Info:\nMono JIT compiler version 6.6.0.161 (tarball Sat Apr 10 16:41:12 PDT 2021)\nCopyright (C) 2002-2014 Novell, Inc, Xamarin Inc and Contributors. www.mono-project.com\nTLS: __thread\nSIGSEGV: altstack\nNotifications: epoll\nArchitecture: amd64\nDisabled: none\nMisc: softdebug\nInterpreter: yes\nLLVM: supported, not enabled.\nSuspend: hybrid\nGC: sgen (concurrent by default)",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-22T05:16:55.363Z",
                "Answer_upvote_count":0,
                "Answer_body":"@VictorFragoso-6349 Thanks for the details. Gentoo is not a 'natively' supported distribution of linux for Datasets. The Exception message doesn't link to a .NET docs page with instructions on installing the system dependencies required for .NET to work. Though it seems a different one is being thrown related to not being able to connect to out blob storage which has pre-prepared dependency sets for some linux distros (not gentoo).\n\nThis page Install .NET on Linux Distributions | Microsoft Docs does not detail support for .NET on gentoo.\nYou can get the names of the missing dependencies themselves by running:\n\n\n\n from dotnetcore2 import runtime\n runtime._enable_debug_logging()\n runtime.ensure_dependencies()\n\n\n\nThis code snippet should print the libraies missing required by .NET core 2.1.\nIf the above does not print anything, other than the Exception, then instead this should:\n\n from dotnetcore2 import runtime\n print(runtime._gather_dependencies(runtime._get_bin_folder()))",
                "Answer_comment_count":5,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-05-20T22:54:23.117Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @ramr-msft I am facing the same issue while read my data from Datalake. Can you please help me out to resolve this issue. \n\n@VictorFragoso-6349 I try to install this package not the issue is still the same.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Experiment on Azure Machine Learning services is not starting.",
        "Question_creation_time":1620678944347,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/389811\/experiment-on-azure-machine-learning-services-is-n.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"I run an experiment in the azure ml service using an associated VM, but the experiment status is as follows:\n\nJob runstatus is NotStarted\n\nID execution 75ff42c9-2fbd-48c2-beec-b72aa38f1d00",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-11T01:51:49.837Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us. I just check on my side and there is no problem for me.\n\nAre you referring below two guidance to train and deploy your pipeline?\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy\n\nIs there any guidance you are following so that we can help investigate more?\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-11T14:46:42.987Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\nI'm not using the designer or Azure ML Studio, I'm building the pipeline trough code in python.\n\nI'm followig this tutorial:\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/training\/train-on-remote-vm\/train-on-remote-vm.ipynb\n\nI have a Remote VM ( (ubuntu 18.04)) which has a VPN connected, I'm trying to use this VM to execute a script but In the pipeline it does not initiate.\n\n\n\n\n\n\nIn addition to this, any of the experiment I have sent were completed. In the image we can clearly see that it says duration 16 h until i have to cancel the experiment. whereas the script only have to print a string for testing",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ml notebooks sharing and compute selection.",
        "Question_creation_time":1591956129183,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/35432\/azure-ml-notebooks-sharing-and-compute-selection.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"What kind of collaboration do we need among the data scientists or developers who need to share these notebooks? What kind of compute does these notebooks require? Is it all single node?",
        "Answers":[
            {
                "Answer_creation_time":"2020-06-12T11:43:28.857Z",
                "Answer_upvote_count":0,
                "Answer_body":"@azureml056-5112 Please follow the below for managing compute instances. https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-compute-instance#managing-a-compute-instance All data scientists or developers need is access to the AzureML Workspace and they will have access to a shared file share where everyone\u2019s notebooks can be accessed.\n\n\n\n\nAll notebook require a Compute Instance(CI). CI is a managed VM that exists in AzureML.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Out-of-memory error webservice deployed with Azure ML Studio",
        "Question_creation_time":1592827334117,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/38509\/out-of-memory-error-webservice-deployed-with-azure.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I have a webservice which exposes a predictive model. It has been deployed with Auzure ML Studio. Since the last model re-training and webservice deployment, in circa 1% of the cases in production, I get the following out-of-memory (possibly correlated) errors:\n\n1) \"The model consumed more memory than was appropriated for it. Maximum allowed memory for the model is 2560 MB. Please check your model for issues.\"\n2) \"The following error occurred during evaluation of R script: R_tryEval: return error: Error: cannot allocate vector of size 57.6 Mb\"\n\nPlease note that these errors occur exclusively while trying to consume the webservice, and not while model training, evaluation and deployment.\n\nAlso, consuming the webservice in batch mode, as suggested here, is not a viable option for our business use case.\n\nIs there a way to increase the memory limit for Azure webservices?\n\nThank you",
        "Answers":[
            {
                "Answer_creation_time":"2020-06-23T12:55:13.067Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for reaching out. Currently, there's no way to increase memory limit in Classic Studio. We encourage customers to try Azure Machine Learning designer (preview), which provides similar drag and drop ML modules plus scalability, version control, and enterprise security. Furthermore, with Designer, the endpoints are deployed to AKS where no limit other than cluster resource is imposed.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":3.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"About the end of Machine Learning Studio (classic)#2",
        "Question_creation_time":1636119906810,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/616952\/about-the-end-of-machine-learning-studio-classic2.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"hello.\n\nI am currently using Machine Learning Studio (classic).\n\n'From now through 31 August 2024, you can continue to use the existing Machine Learning Studio (classic) experiments and web services. Beginning 1 December 2021, new creation of Machine Learning Studio (classic) resources will not be available.\n\nIs the following interpretation correct?\n\nThings you can't do from 1 December 2021\n-Creating a workspace for Machine Learning Studio (classic)\n-Creating a web service plan for Machine Learning Studio (classic)\n\nWhat you can do until 1 December 2021\n-Creating new Machine Learning Studio (classic) experiments\n-Creating new Machine Learning Studio (classic) trained models\n-Creating a new Machine Learning Studio (classic) web service",
        "Answers":[
            {
                "Answer_creation_time":"2021-11-06T14:35:42.13Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, customers will not be able to create new ML Studio(classic) workspaces after Dec 1, 2021. However, customers can create or update experiments\/web services in existing workspaces until Aug 31, 2024.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Issue with data lake mounting in custom RStudio application Azure ML",
        "Question_creation_time":1661155798650,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/976098\/install-rstudio-application-in-azure-ml-vm.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"previously while creating a compute instance we were able to see RStudio application by default and we were able to mount\/access the data lake from RStudio.\n![compute creation][1]\n\n\n\n\n![Data lake mont][2]\n2. In current situation we are not able to access RStudio application by default.\n![234345-4.png][3]\n3.with the help of below link we are able to create custom RStudio application\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance?tabs=azure-studio\n![custom RStudio app][4]\n\n4.In custom RStudio we are not able to mount\/access the data lake.\n\n![missing data lake][5]\n\nIs there way to mount\/access the data lake in custom RStudio app\n[1]: \/answers\/storage\/attachments\/234344-screenshot-2022-08-23-170502.png\n[2]: \/answers\/storage\/attachments\/234353-5.png\n[3]: \/answers\/storage\/attachments\/234345-4.png\n[4]: \/answers\/storage\/attachments\/234314-2.png\n[5]: \/answers\/storage\/attachments\/234361-3.png",
        "Answers":[
            {
                "Answer_creation_time":"2022-08-23T02:41:16.113Z",
                "Answer_upvote_count":0,
                "Answer_body":"@alifshaikh-6049 Thanks for the question. Here is the snapshot for using the Rstudio from ml.azure.com\n\n\nHere is the sample to train Rmodel.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"The file limit in Azure ML studio",
        "Question_creation_time":1647197880180,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/770207\/the-file-limit-in-azure-ml-studio.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi, when I submitted my work in Azure ML studio, it showed an error like this.\n\n\n\n\n\nMy folder contains around 50000 files, and even if I uploaded my files onto the datasets, I still need to download them to my current workplace. Is there a way to directly use the file from datasets or increase the snapshot size? I really appreciate any help you can provide.",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":5.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"AzureML model predictions do not match scored model",
        "Question_creation_time":1644551791223,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/731481\/azureml-model-predictions-do-not-match-scored-mode.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I have deployed a model to an endpoint but the predictions that come back do not match what is output from the scored model in the experiment.\n\nThe model is a Multiclass Neural Network for classifying emails - it takes approx. 1,000 elements of text and puts them into one of about 18 possible categories.\n\nReviewing the scored model outputs in the experiment, the accuracy is reasonable; however once deployed it always predicts any input into a single category with near 100% confidence. The input is correctly formatted (this is validated in the model output) so I'm assuming something is misconfigured in the model deployment, but I'm not seeing any indication as to what.\n\nAppreciate any help from MSFT in investigating this issue.\n\nCheers, James",
        "Answers":[
            {
                "Answer_creation_time":"2022-02-11T11:43:59.53Z",
                "Answer_upvote_count":0,
                "Answer_body":"@JamesB-9842 Thanks for the question. There are multiple ways to create a multiclass DNN on various AzureML products. Is this from some tensorflow or pytorch code, or from the AML Designer? Screenshots or sample notebooks might help a lot.",
                "Answer_comment_count":7,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"ML Studio and Private Endpoint issue",
        "Question_creation_time":1646161833773,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/755259\/ml-studio-and-private-endpoint-issue.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-vpn-gateway"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"We are trying to setup a Machine Learning Workspace and only have it accessible via Private Endpoint Connection. When we have it this setup and try to connect from our company workstations it loads the page but we get an \"Error Loading recent runs\"\n\n\n\n\n\nIf we run this from a VM inside Azure it is fine.\n\nWe do have a VPN Gateway set up to access our on-prem which works for other Vnets we have in Azure. We peered the VNET that ML sits in with VNET where Gateway network is setup. unfortunately we had a 3rd party set up the original connection and did not fully document. We have tried to match all settings we have in the working VNET with the ML Vnet but can't seem to see what we are missing. I also can't seem to find what logs to check to see where connections are being blocked.\nHoping I explained our issue will enough.",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-30T14:17:17.327Z",
                "Answer_upvote_count":1,
                "Answer_body":"So we have resolved the issue. We found that we had to add a rule to allow that traffic to the private endpoint. Once we did that and add adding a Forward Zone lookup in our DNS for the Private IPs resolved our issues.\nAppreciate all that help on this",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":14.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Cannot find created compute instance",
        "Question_creation_time":1642537079270,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/700065\/cannot-find-created-compute-instance.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I have created a compute instance and it is not available at the compute instances list. Instead it shows a \"create new\" button.\nI can see the instance at usage+quotas but when I click on it , it says the compute instance cannot be found.",
        "Answers":[
            {
                "Answer_creation_time":"2022-01-19T06:21:07.94Z",
                "Answer_upvote_count":0,
                "Answer_body":"@ManolisDagdilelis-4594 Clicking on the compute name from the usage+quotas blade should redirect you to ml.azure.com compute page to use the compute instance\/clusters. In your case it seems that the instance is used in quota but is actually not available to use. It may be an orphaned instance that needs to be reported.\n\nYou can click on New Support request and report this issue from Azure portal or use the smiley icon on the top right corner of ml.azure.com and report the case with the screen shots. This will help the service team to check the issue from backend. Meanwhile, do you see the same issue for a new compute instance that you create from ml.azure.com?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Machine Learning\u306b\u3064\u3044\u3066\u306e\u8cea\u554f",
        "Question_creation_time":1631251067517,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/546760\/machine-learning%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%E3%81%AE%E8%B3%AA%E5%95%8F.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"\u63b2\u984c\u306e\u4ef6\u306b\u3064\u304d\u307e\u3057\u3066\u3001\u73fe\u5728Machine Learning\u3092\u4f7f\u7528\u3057\u3066\u6a5f\u68b0\u5b66\u7fd2\u3092\u884c\u3063\u3066\u3044\u307e\u3059\u3002\n\u305d\u3053\u3067\u8cea\u554f\u306b\u306a\u308b\u306e\u3067\u3059\u304c\u3001\u30c7\u30b6\u30a4\u30ca\u30fc\u6a5f\u80fd\u3092\u4f7f\u7528\u3057\u3066\u5b66\u7fd2\u7d50\u679c\u3092CSV\u3067\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u3057\u3088\u3046\u3068\u3057\u3066\u3044\u308b\u306e\u3067\u3059\u304c\u3001\nExport Data\u30e2\u30c7\u30eb\u3067CSV\u5f62\u5f0f\u306b\u8a2d\u5b9a\u3057\u3066\u3044\u3066\u3082CSV\u3067\u306f\u306a\u3044\u5f62\u5f0f\u3067\u5171\u6709\u305b\u308c\u3066\u3057\u307e\u3046\u306e\u3067\u3059\u304c\u3001\u539f\u56e0\u304c\u308f\u304b\u3089\u306a\u3044\u72b6\u6cc1\u3067\u3059\u3002\n\u3054\u6559\u793a\u306e\u307b\u3069\u3088\u308d\u3057\u304f\u304a\u9858\u3044\u3044\u305f\u3057\u307e\u3059\u3002",
        "Answers":[
            {
                "Answer_creation_time":"2021-09-10T10:15:10.237Z",
                "Answer_upvote_count":0,
                "Answer_body":"@63862379 Are you referring to the export data module of the designer from ml.azure.com?\nI think I understand the issue, Are you seeing that the .csv format of file is not listed on the blob storage?\n\nSince the input is a dataframe directory to export module the output format selected should still be the format you selected, in this case CSV. The file name extension only might be missing. You can still open the csv file in excel and it will recognize the delimiters and headers so you can convert it into excel files.\n\nYou can also avoid this by providing the .csv extension in the path itself in export settings and file will be exported as a csv file directly.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"When using AutoML for forecasting, is it possible to include lagged exogenous features?",
        "Question_creation_time":1657059623547,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/915375\/when-using-automl-for-forecasting-is-it-possible-t.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"In the documentation, it states \"When training a model for forecasting future values, ensure all the features used in training can be used when running predictions for your intended horizon. For example, when creating a demand forecast, including a feature for current stock price could massively increase training accuracy. However, if you intend to forecast with a long horizon, you may not be able to accurately predict future stock values corresponding to future time-series points, and model accuracy could suffer,\" which seems to imply only features that are known or can reasonably be estimated in the future should be used. This seems like a pretty severe limitation. Is it really not possible to include exogenous features that should be lagged like the target is?",
        "Answers":[
            {
                "Answer_creation_time":"2022-07-06T15:50:57.7Z",
                "Answer_upvote_count":0,
                "Answer_body":"@SchibliEric-0296 Thanks for the question. Can you please add more details about the use case?. Please check here, Auto-train a time-series forecast model - Azure Machine Learning | Microsoft Docs\n\nHowever it may not be right to deal with this just by filling using the previous patterns. One suggestion is to include an exogenous variable in the model like the statistics for the region and model how this exogenous variable has influenced the target (which could be zero as well). Retraining the model on regular intervals with additional data on the frequency they collect will be required to keep up to the change in patterns due to external factors.\n\nPlease check the below many models accelerator which models timeseries data (but in a different domain). This can be useful.\nbuswrecker\/energy-many-models: An offshoot of the original AML Many-Models - for the Energy Sector (github.com)",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"my script stops running without any message explaining the reason",
        "Question_creation_time":1634306015143,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/592153\/my-script-stops-running-without-any-message-explai.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Please see the screenshots below. Once it said terminated but without reason:\n\nThe other time there was nothing just stopped:",
        "Answers":[
            {
                "Answer_creation_time":"2021-11-02T02:05:01.493Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nHope you have solved this issue and we are sorry not seeing your response. Since this issue happened without any error details, support ticket would be the best way to debug that. Please let me know if you still need that. Thanks.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Machine Learning and jupyterlab git extension not working",
        "Question_creation_time":1594716551237,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/46614\/azure-machine-learning-and-jupyterlab-git-extensio.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":4,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi,\n\n\n\n\nI need some help trying to understand why I can't see any GIT options (left panel and top selection drop down menu) in my Azure machine learning JupyterLab.\n\n\n\n\nI did the following steps:\n\n\n\n jupyter labextension install @jupyterlab\/git\n pip install --upgrade jupyterlab-git\n jupyter serverextension enable --py jupyterlab_git\n jupyter lab build\n\n\n\n\nI've restarted my jupyterLab a couple of times, if I check the command:\n\n\n\n jupyter labextension list\n\n\n\n\nI get that @jupyterlab\/git v0,20,0 is enabled and ok.\nWhat am I doing wrong?\n\n\n\n\nThank you in advance,\nCarla",
        "Answers":[
            {
                "Answer_creation_time":"2020-07-14T21:32:40.103Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi @ramr-msft ,\n\n\n\n\nI did the steps mention in the link you gave me (https:\/\/github.com\/jupyterlab\/jupyterlab-git) but still I can't open the Git extension from the Git tab on the left panel because it still doesn't exists.\n\n\n\n\nYou mentioned we can still manage git repositories using the command line. Do you have any useful documentation on this approach?\n\n\n\n\nOnce again, thank you in advance.\nCarla",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2020-07-16T12:03:40.593Z",
                "Answer_upvote_count":1,
                "Answer_body":"@CarlaFiadeiro-3395 We have checked with the product team and As per the confirmation this extension is removed as of March-2020 releases since it has been causing perf issues with fileshare storage. We will add it back in future once we fix perf issues. Current alternative is to use git CLI.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-16T13:23:42.487Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi @ramr-msft ,\n\n\n\n\nThank you a lot for the reply.\nFor the moment I'll use git CLI.\n\n\n\n\nOnce again thank you for the help.\n\n\n\n\nRegards,\nCarla",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-09-03T18:17:49.423Z",
                "Answer_upvote_count":0,
                "Answer_body":"Carla, after you complete the steps you mentioned at the beginning of this thread, try restarting your Azure ML Compute and then open Jupyter Lab:",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":5.0,
        "Question_follower_count":37.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azureml: Metadata mismatch for dask dataframe after using filter()",
        "Question_creation_time":1647425925947,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/774453\/azureml-metadata-mismatch-for-dask-dataframe-after.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I noticed weird behaviour when filtering an azureml TabularDataset instance using filter() and converting it to a dask dataframe afterwards. Here is my code to recreate the issue:\n\nImports:\n\n from azureml.core import Dataset\n from azureml.data import TabularDataset\n import dask.dataframe as ddf\n import pandas as pd\n\n\n\nRegister a dask dataframe to the datastore and load it as a TabularDataset:\n\n test_df = pd.DataFrame({\"id\": [3,4,5], \"price\": [199, 98, 50]})\n test_dask = ddf.from_pandas(test_df, chunksize=1)\n    \n Dataset.Tabular.register_dask_dataframe(test_dask, datastore, name='bug_test')\n dataset = TabularDataset.get_by_name(workspace, name='bug_test')\n\n\n\nNow printing the loaded dataset after converting it to dask dataframe works (almost) well (almost, since there is weird indexing as the 0 appears two times):\n\n loaded_dask = dataset.to_dask_dataframe()\n print(loaded_dask.compute())\n >> \n           id  price  __null_dask_index__\n        0   3    199                   0\n        0   4     98                    1\n        1   5     50                    2\n\n\n\nWe now want to filter for rows where id equals to 5, which works perfectly when it is filtered after converting it to dask dataframe with loaded_dask[loaded_dask.id == 5].compute()\n\nNow computing the dask dataframe after filtering with the filter() method throws following exception, either no data or no datatype is found (for full error message see below):\n\n filtered_ds = dataset.filter(dataset[\"id\"] == 5)\n filtered_ds.to_dask_dataframe().compute()\n >> \n     ValueError: Metadata mismatch found in `from_delayed`.\n     Partition type: `pandas.core.frame.DataFrame`\n     +-----------------------+-------+----------+\n     | Column                | Found | Expected |\n     +-----------------------+-------+----------+\n     | '__null_dask_index__' | -     | int32    |\n     | 'id'                  | -     | int32    |\n     | 'price'               | -     | int32    |\n     +-----------------------+-------+----------+\n\n\n\nNote: When filtering for invalid values, e.g. for dataset[\"id\"] == 6 it correctly returns me an empty dataframe\n\nAlso a weird behaviour happens when playing around with the dtypes parameter in to_dask_dataframe(). When specifying types for only one column, datatypes can suddenly be found:\n\n filtered_ds.to_dask_dataframe(dtypes={\"id\": \"object\"}).compute()\n >>\n     ValueError: Metadata mismatch found in `from_delayed`.\n    \n     Partition type: `pandas.core.frame.DataFrame`\n     +-----------------------+-------+----------+\n     | Column                | Found | Expected |\n     +-----------------------+-------+----------+\n     | '__null_dask_index__' | int64 | -        |\n     | 'id'                  | int64 | object   |\n     | 'price'               | int64 | -        |\n     +-----------------------+-------+----------+\n\n\n\nbut setting dtypes={\"id\": \"int64\", \"price\": \"int64\", \"__null_dask_index__\": \"int64\"} leads again to the same ValueError as before that either no data or no datatype is found (full error ouput):\n\n filtered_ds.to_dask_dataframe(dtypes={\"id\": \"int64\", \"price\": \"int64\", \"__null_dask_index__\": \"int64\"}).compute()\n >>\n     Traceback (most recent call last):\n       File \"\\bug_analysis.py\", line 117, in <module>\n         filtered_ds.to_dask_dataframe(dtypes={\"id\": \"int64\", \"price\": \"int64\", \"__null_dask_index__\": \"int64\"}).compute()\n       File \"\\venv\\lib\\site-packages\\dask\\base.py\", line 290, in compute\n         (result,) = compute(self, traverse=False, **kwargs)\n       File \"\\envs\\venv\\lib\\site-packages\\dask\\base.py\", line 573, in compute\n         results = schedule(dsk, keys, **kwargs)\n       File \"\\venv\\lib\\site-packages\\dask\\threaded.py\", line 81, in get\n         results = get_async(\n       File \"\\venv\\lib\\site-packages\\dask\\local.py\", line 506, in get_async\n         raise_exception(exc, tb)\n       File \"\\venv\\lib\\site-packages\\dask\\local.py\", line 314, in reraise\n         raise exc\n       File \"\\venv\\lib\\site-packages\\dask\\local.py\", line 219, in execute_task\n         result = _execute_task(task, data)\n       File \"\\venv\\lib\\site-packages\\dask\\core.py\", line 119, in _execute_task\n         return func(*(_execute_task(a, cache) for a in args))\n       File \"\\venv\\lib\\site-packages\\dask\\dataframe\\utils.py\", line 407, in check_meta\n         raise ValueError(\n     ValueError: Metadata mismatch found in `from_delayed`.\n     Partition type: `pandas.core.frame.DataFrame`\n     +-----------------------+-------+----------+\n     | Column                | Found | Expected |\n     +-----------------------+-------+----------+\n     | '__null_dask_index__' | -     | int64    |\n     | 'id'                  | -     | int64    |\n     | 'price'               | -     | int64    |\n     +-----------------------+-------+----------+\n\n\n\n\nThe exceptions are raised when the dask dataframes are computed with compute().\n\nI am aware that I used two experimental methods ( TabularDataset.to_dask_dataframe() and TabularDataset.filter() ), so is this a bug or am I using the methods incorrectly at some point?",
        "Answers":[
            {
                "Answer_creation_time":"2022-04-05T04:59:25.48Z",
                "Answer_upvote_count":0,
                "Answer_body":"I have the same problem, any solution?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Compose model",
        "Question_creation_time":1669041105107,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1098169\/compose-model.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"As the document\nA composed model is created by taking a collection of custom models and assigning them to a single model ID. You can assign up to 100 trained custom models to a single composed model ID. When a document is submitted to a composed model, the service performs a classification step to decide which custom model accurately represents the form presented for analysis.\n\nWhat\u2019s the price for the classification step?",
        "Answers":[
            {
                "Answer_creation_time":"2022-11-21T15:31:45.523Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @KenSmith-3969\n\nThanks for reaching out to us and sorry for the confusion of the document.\n\nThere is no extra fee for the classification you mentioned in the document. You only pay for the custom model you finally run for your document.\n\nI will raise a ticket to fix the document, thanks a lot for pointing out it.\n\nI hope this helps!\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks!",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":13.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"MS Azure Machine Learning: MemoryError: Unable to allocate 5.43 GiB for an array with shape (23847, 30582) and data type int64",
        "Question_creation_time":1615935222203,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/317531\/ms-azure-machine-learning-memoryerror-unable-to-al.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am trying to extract pixel values from a raster image using xarray module. I tried to \"stack\" the coordinates to get a third dimension but I end up getting the error above. I create a compute instance of 56GB RAM so I was wondering why the 5.43 GiB, I would have expected going beyond 56GB but the values seems off.\n\nThank you.",
        "Answers":[
            {
                "Answer_creation_time":"2021-03-17T08:06:23.09Z",
                "Answer_upvote_count":0,
                "Answer_body":"@PG-6613 Thanks for the question. Can you please add more details about the code that you are trying and the compute instance series details. There are some operations that will require a pick of memory usage while executing. So even when your dataframe fits in memory, the operation requires some more during operation.\n\nWe would recommend using the M series. We introduced this new vm family recently for high memory operations. There are known outage issue in storage, please raise a azure support ticket with the details..\nDoc for M Series:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/virtual-machines\/m-series?toc=\/azure\/virtual-machines\/linux\/toc.json&bc=\/azure\/virtual-machines\/linux\/breadcrumb\/toc.json\n\nYou can get a summary of the memory used by a Pandas DataFrame by calling df.info(memory_usage=\u201ddeep\u201d)\ndocs: https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.info.html",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Custom Argument pass to Docker Container Azure ML inference",
        "Question_creation_time":1632856020243,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/569816\/custom-argument-pass-to-docker-container-azure-ml.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello Team,\n\nI'm trying to pass the arguments to Azure ML docker. I have created an environment like this.\n\n env = Environment.from_conda_specification(name='pytorch-1.6-gpu', file_path='curated_env\/conda_dependencies.yml' )\n\n\n\nAm I passing the arguments correct?\n\n DOCKER_ARGUMENTS = [\"--shm-size\",\"32G\"]  # increase shared memory\n env.docker.arguments = DOCKER_ARGUMENTS\n\n\n\n\nThe main goal of this project is to deploy a model on the AKS inference cluster. I have successfully deployed the model. When I try to get predictions from the model I got this error\n\nIt is possible that data loaders workers are out of shared memory. Please try to raise your shared memory limit\n\nHow can I do that if that's not the correct way to pass arguments?",
        "Answers":[
            {
                "Answer_creation_time":"2021-09-29T06:31:54.6Z",
                "Answer_upvote_count":0,
                "Answer_body":"@khubaibRaza-8970 To pass the argument for increasing the default \"shm_size\" you would have to use the DockerConfiguration object. Here is a sample to achieve this:\n\n from azureml.core import Environment\n from azureml.core import ScriptRunConfig\n from azureml.core.runconfig import DockerConfiguration\n    \n    \n # Specify VM and Python environment:\n my_env = Environment.from_conda_specification(name='my-test-env', file_path=PATH_TO_YAML_FILE)\n my_env.docker.base_image = 'mcr.microsoft.com\/azureml\/openmpi3.1.2-cuda10.2-cudnn7-ubuntu18.04'\n    \n docker_config = DockerConfiguration(use_docker=True,shm_size='32g')\n    \n # Finally, use the environment in the ScriptRunConfig:\n src = ScriptRunConfig(source_directory=DEPLOY_CONTAINER_FOLDER_PATH,\n                       script=SCRIPT_FILE_TO_EXECUTE,\n                       arguments=EXECUTE_ARGUMENTS,\n                       compute_target=compute_target,\n                       environment=my_env,\n                       docker_runtime_config=docker_config)\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Importing Data in Azure ML Studio Experiment",
        "Question_creation_time":1614362680897,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/291213\/importing-data-in-an-experiment-issue.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I\u2019m having an issue importing the data into my Machine Learning Studio. It shows me a Red Cross with the error 0030 - which means that there\u2019s an issue in downloading the data. For background, I\u2019m importing data from the Web URL via HTTP option. I looked up the issue on the troubleshooting page, followed the advice, which shows I\u2019ve done everything correctly. My data link works perfectly fine in my browser. When I enter the http link into my browser, it immediately downloads the csv file. However, my studio is not downloading the data. Importing the data is the first step in my experiment, and I can\u2019t move forward without it. Immediate help would be greatly appreciated! I\u2019ve attached pictures for reference. [1]: \/answers\/storage\/attachments\/72499-0ebb78a4-4805-46e8-a7f1-fbf99682af5f.png",
        "Answers":[
            {
                "Answer_creation_time":"2021-03-03T08:19:34.36Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nThis exception in Azure Machine Learning occurs when it is not possible to download a file. You will receive this exception when an attempted read from an HTTP source has failed after three (3) retry attempts.\n\nResolution: Verify that the URI to the HTTP source is correct and that the site is currently accessible via the Internet.\n\nIs this file on any place need authentication?\n\nRegards,\nYutong",
                "Answer_comment_count":7,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Bug report: can't parametrize # hidden node or momentum in NN regression model",
        "Question_creation_time":1594758142250,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/47011\/bug-report-cant-parametrize-hidden-node-or-momentu.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"I'm using the NN regression model in Azure ML Designer, but it appears to have a bug. If I switch trainer mode to ParameterRange, it allows me to use a semicolon-separated list of hyperparameters for learning rate and epochs. However, I'm unable to use a semicolon-separated list of hyperparameters for number of hidden nodes or momentum. Since the number of hidden nodes is the most commonly tuned hyperparameter for a MLP, this module doesn't seem particularly useful if I want to use it to tune hyperparameters.",
        "Answers":[
            {
                "Answer_creation_time":"2020-07-14T20:29:26.033Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for reaching out to us. We will investigate this deeper and let you know any update.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-14T20:33:46.64Z",
                "Answer_upvote_count":0,
                "Answer_body":"You can provide this feedback over here on uservoice\nhttps:\/\/feedback.azure.com\/forums\/257792-machine-learning",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":38.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"No module named 'xgboost'",
        "Question_creation_time":1597377002880,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/66628\/no-module-named-39xgboost39.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello there,\n\nI'm seeing an error - No module named 'xgboost' when attempting to deploy a model using python SDK. Here is my conda yaml file. What am I missing?\nUnable to get the end point to generate an output.\n\nname: project_environment\ndependencies:\n# The python interpreter version.\n# Currently Azure ML only supports 3.5.2 and later.\n- python=3.6.2\n\npip:\n\n\ninference-schema\n\n\nazureml-defaults\n\n\nazureml-explain-model\n\n\nnumpy>=1.16.0,<1.17.0\n\n\npandas>=0.21.0,<=0.23.4\n\n\nscikit-learn>=0.19.0,<=0.20.3\n\n\npy-xgboost\n\n\nfbprophet==0.5\n\n\nholidays==0.9.11\n\n\npsutil>=5.2.2,<6.0.0\n\n\nxgboost\n\n\nazureml-sdk[notebooks,automl]\nchannels:\n\n\nanaconda\n\n\nconda-forge",
        "Answers":[
            {
                "Answer_creation_time":"2020-08-14T10:05:53.963Z",
                "Answer_upvote_count":0,
                "Answer_body":"@VikManne-0966 Thanks for the question. Can you please check on the pip and coda packages properly separated. If possible please share the link to the yaml file.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":1.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Types of Regression Algorithm",
        "Question_creation_time":1608719172483,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/208685\/types-of-regression-algorithm.html",
        "Question_topic":null,
        "Question_tag":[
            "not-supported-azure",
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"What are the types of Regression algorithm? Are there any kinds of regression called \"non-linear regression\"?",
        "Answers":[
            {
                "Answer_creation_time":"2020-12-24T13:50:48.27Z",
                "Answer_upvote_count":0,
                "Answer_body":"@SanniddhaChakrabarti-9451 Please follow the below document for Regression.\nhttps:\/\/www.analyticsvidhya.com\/blog\/2015\/08\/comprehensive-guide-regression\/#:~:text=Regression%20analysis%20is%20a%20form,effect%20relationship%20between%20the%20variables.\n\nTypes of Regressions:\nLinear Regression\nLogistic Regression\nPolynomial Regression\nStepwise Regression\nRidge Regression\nLasso Regression\nElasticNet Regression",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How does AzureML choose the node to launch a run?",
        "Question_creation_time":1605888033847,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/170198\/how-does-azureml-choose-the-node-to-launch-a-run.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"I have a question related with runs, compute clusters and vcpu\/memory boundaries for specific run.\n\nI have this mindset that a run executes over an environment (a docker image) in a specific compute target. My idea is, if there are resources (vcpu and memory) available on a node, so the run executes in that node. But I always see that a node only executes one run each time, independently the node sku of compute cluster. It seams, AzureML chooses always a idle node to launch a run.\n\nDoes a node always execute one, and not more than one, run in the same time?\nWhat are resources boundaries for run? Or the run might spread over all node resources?\nIf there is boundaries, the default boundaries is static or configurable through environment property `arguments` for docker run?\n\nWhat the following section in run raw json means?\n\n \"containerInstance\": {\n   \"region\": null,\n   \"cpuCores\": 2,\n   \"memoryGb\": 3.5\n },\n\n\n\nThanks",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How do I register ADLS as datastore in AMLW (via cli) corrcetly?",
        "Question_creation_time":1669041298113,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1098193\/how-do-i-register-adls-as-datastore-in-amlw-via-cl.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-data-lake-storage"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi!\n\nI'm trying to create a datastore from an ADLS (Gen2) using azure cli (using version 2.42), with credentials using service principal. The service principal is added as Storage Blob Data Reader to my ADLS. I use the following schema (with XXX replaced by correct details), file is named create-datastore-azure-adls.yml .\n\n$schema: https:\/\/azuremlschemas.azureedge.net\/latest\/azureDataLakeGen2.schema.json\ntype: azure_data_lake_gen2\nname: XXX\ndescription: Datastore, ADLS and service principal\naccount_name: XXX\nfilesystem: XXX\ncredentials:\ntenant_id: XXX\nclient_id: XXX\nclient_secret: XXX\n\nand run\naz ml datastore create --file create-datastore-azure-adls.yml --workspace-name $WORKSPACENAME --resource-group $RESOURCENAME --subscription $SUBSCRIPTIONID\n\nThe datastore ends up in my workspace but I can't read from the datastore. When I look at it in the workspace it is not connected to any subscription-id nor resource group (see image).\n\nHowever, if I choose update authentication and fill in subscription-id and resource group everything works. So my question is if there is any way I can't do it correctly, only using the cli, eg. adding this info (subscription-id and rg-name) to the schema? So I don't have to update authentication in the workspace every time :)",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":20.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Issue in my MLOPs CD pipeline.",
        "Question_creation_time":1649140550093,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/800334\/issue-in-my-mlops-cd-pipeline.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-container-instances"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Deploying my model to ACI takes forever and fails without any error message. In the ML workspace, the status of the deployed endpoint is unhealthy. I checked common errors while deployment but could not solve the problem. Pleas help. The deployment is never successful and it keeps running.",
        "Answers":[
            {
                "Answer_creation_time":"2022-04-06T07:47:34.493Z",
                "Answer_upvote_count":0,
                "Answer_body":"anonymous user Thanks for the question. Could you clarify the architecture of your model deployment? In particular, are you using a custom docker container for it? Also, usually ACI would be used for testing, but I'd recommend investigating AKS for production model deployment.\n\nI would deploy the container into a local machine\/VM with Docker to see the exact detail error message which you don't see via ACI deployment.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Invalid graph - invalid dataset",
        "Question_creation_time":1595587512910,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/51962\/invalid-graph-invalid-dataset.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Invalid graph - Invalid dataset",
        "Answers":[
            {
                "Answer_creation_time":"2020-07-25T07:57:18.377Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thanks @ShowndaryaMadhavan for your quick response.\n\nI found that I had to press Generate Profile as in the picture below and then it worked",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2020-07-24T11:30:32.627Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @ThalanayarMuthukumar-6317\n\nThere might be multiple reasons for this error:\n\nYour input dataset has invalid characters, bad values, or out of range values\n\n\nSome column is empty or contains too many missing values. ( You can use Clean Missing Data module to handle missing data in your dataset before you split )\n\n\nIf the data format is not supported.\n\n\nIf there are atleast 2 rows for Split Data to work\n\n\nIf you have specified desired rows to be split, make sure the number is less than the total rows,\n\nAnd, what mode of splitting have you chosen in Split Data? If you are splitting by rows, check if Stratified split is set to false. If it is true, check the target column you have chosen.\n\nHope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":1.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Can you create an MLTable Dataset (Tabular Format) from a CSV file?",
        "Question_creation_time":1665800219957,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1049085\/can-you-create-an-mltable-dataset-tabular-format-f.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"I have collected data that I'd like to use in AutoML to see if there's a pattern that can be derived from the data. According to docs, the data needs to be uploaded in the MLTable format in order to be used in AutoML. However, my data is currently in CSV format. There are fairly clear instructions on how to create an MLTable data asset, but the instructions assume your data starts in MLTable format (see the Note: \"The path points to the folder containing the MLTable artifact\"). I can't seem to find any instructions on how to create the MLTable artifact\/folder in the first place, so I can't follow these instructions. Do these instructions exist somewhere? If so, is it possible for someone to link me to it or describe this process? Thank you!",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":4.0,
        "Question_follower_count":3.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Datastore workspaceblobstore access failed, ErrorCode: ResourceNotFound using AutoML.",
        "Question_creation_time":1634120760290,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/588934\/datastore-workspaceblobstore-access-failed-errorco.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Why remote run is getting \"Datastore workspaceblobstore access failed, ErrorCode: ResourceNotFound\" when using automl?\n\nI've attached datastore to workspace and I'm able to create Tabular dataset using blob URL.\n\nBut it crashes when submittting experiment with auto ml.",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":4.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Score Recommender system - Item Recommendation failed to run",
        "Question_creation_time":1626681386490,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/480658\/score-recommender-system-item-recommendation-faile.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am getting an error when trying to run the Score Recommender system for Item Recommendation.\n\nThe status details is 'Failed to run task; exceeded retry count for operation'. Can someone help to advise on this error?",
        "Answers":[
            {
                "Answer_creation_time":"2021-07-21T02:53:53.933Z",
                "Answer_upvote_count":0,
                "Answer_body":"The experiment i am trying to conduct here is a E-commerce Product Recommender to generate the top 5 item recommendations for each user.\nWhen i set the Recommended Item selection to be 'From All Items', the Score Recommender System will fail to run.\n\nExperiment link as below:\nhttps:\/\/studio.azureml.net\/Home\/ViewWorkspaceCached\/50eecd898bf54c7baca7704f89bc737b#Workspaces\/Experiments\/Experiment\/50eecd898bf54c7baca7704f89bc737b.f-id.671a7b68cb8a456282ed5ab7a8951f8e\/ViewExperiment",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Wheres my component",
        "Question_creation_time":1667251682350,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1070006\/wheres-my-component.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi expert, I am struggling in a bug, I can\u2019t see anything in my studio and it shows empty, how can I fixed it. Anyone else experience this or is this a bug.",
        "Answers":[
            {
                "Answer_creation_time":"2022-10-31T23:42:44.343Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @jamesschmidt-7068\n\nThanks for reaching out to us for this issue. I have checked on my end and I find everything is OK.\n\nCould you please make sure you have not selected any filter\/ selected all tags and click on the refresh button to make sure you have every component.\n\nMy studio is as above, please do check all the settings and let me know if you still have any issue.\n\nRegards,\nYutong\n\n-Please kindly accept the asnwer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"\"Explanation_dataTransform: e.every is not a function\" Error AutoML Explanation Preview",
        "Question_creation_time":1619105132597,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/367955\/34explanation-datatransform-eevery-is-not-a-functi.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Although child run of the explanation is completed successfully, we are not able to see the explanation preview. We would appreciate if you could help us.\n\nBest regards,\n\nCagatay Topcu",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Is it possible to migrate a completed Azure data labelling project to Custom Vision ?",
        "Question_creation_time":1643343651050,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/713444\/is-it-possible-to-migrate-a-completed-azure-data-l.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-custom-vision"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I've recently labelled approx. 3500 images for a multi-class classification project and wondered if I could use the Custom Vision service to train the data (for a prototype demo) ?\n\nIf not, is there a way to access the model created using the Auto Labelling feature and use it as an end point (In Javascript) ?",
        "Answers":[
            {
                "Answer_creation_time":"2022-01-28T14:56:47.107Z",
                "Answer_upvote_count":0,
                "Answer_body":"@HamentPandya-0884 Thanks for the details. This feature is in Preview. AML and Custom Vision (Cog. services) worked on the integration , which would allow the customers to have their data labeled in AML and take it into Cog. service and vice versa.\n\nHere is link to the document for labeling project and Check out the Automate Custom Vision model creation with AutoML for Images: https:\/\/www.youtube.com\/watch?v=FPDCRSuAym0\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n- Want a reminder to come back and check responses? Here is how to subscribe to a notification\n- If you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Compute Instances List is not displaying any of my previously create instance",
        "Question_creation_time":1615936137423,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/317533\/compute-instances-list-is-not-displaying-any-of-my.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Compute Instances List is not displaying any of my previously create instance\n\nwhen i log in and go to the machine learning studio and click on the link it display an error.\n\nIts like the list is timing out\n\nI have tried this on multiple machines\n\nerror\n\n'Failed to load computes Your request for data wasn\u2019t sent. Here are some things to try: Check your network and internet connection, make sure a proxy server is not blocking your connection, follow our guidelines if you\u2019re using a private link, and check if you have AdBlock turned on. Trace ID : 6c0087da-5c17-4aea-814b-59d8292caa5b Client request ID : fa33bb7f-d4dd-4975-a538-cb119b7a2d64 '",
        "Answers":[
            {
                "Answer_creation_time":"2021-03-17T08:58:48.193Z",
                "Answer_upvote_count":0,
                "Answer_body":"@lukemcredmond Does your network have any restrictions which could block any backend calls to the service? Do you have any other azure machine learning workspace and does that display a similar behavior?\n\nDue to the nature of the issue you could also pass the above trace id to our team from ML portal from the top right hand corner which enables them to contact you if required. Thanks!!",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How is Azure ML instance cost calculated?",
        "Question_creation_time":1606732706930,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/180023\/how-is-azure-ml-instance-cost-calculated.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference",
            "azure-language-understanding"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,\n\nI've created an endpoint for scoring using a modified version of this tutorial: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-existing-model. I used this command for specifying resources: AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=12) and my resource group is \"West EU\". I'd like to know how the cost is calculated. I assume that the requested resources are converted to an instance (is that right?). I have found this useful website calculator but I cannot find which instance I am using.\n\nHow can I retrieve the information? Can I also do it programatically?\n\nMany thanks.",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-30T13:35:11.803Z",
                "Answer_upvote_count":0,
                "Answer_body":"@martin-3510 Thanks for the question. On our website all the prices of Azure ML service are displayed and FAQ at the end.\nhttps:\/\/azure.microsoft.com\/en-us\/pricing\/details\/machine-learning\/\nYes, when you deploy your model to ACI with a default environment you can customize the deploy configuration (i.e. the number of cores and amount of memory made available for the deployment) using the AciWebservice.deploy_configuration().",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Stream Analytics: ML Service function call in cloud job results in no output events",
        "Question_creation_time":1594918621430,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/48592\/azure-stream-analytics-ml-service-function-call-in.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-stream-analytics"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":4,
        "Question_has_accepted_answer":false,
        "Question_body":"Hey,\nI've got a problem with an Azure Stream Analytics (ASA) job that should call an Azure ML Service function to score the provided input data.\nThe query was developed und tested in Visual Studio (VS) 2019 with the \"Azure Data Lake and Stream Analytics Tools\" Extension.\nAs input the job uses an Azure IoT-Hub and as output the VS local output for testing purposes (and later even with Blobstorage).\nWithin this environment everything works fine, the call to the ML Service function is successfull and it returns the desired response.\nUsing the same query, user-defined functions and aggregates like in VS in the cloud job, no output events are generated (with neither Blobstorage nor Power BI as output).\nIn the ML Webservice it can be seen, that ASA successfully calls the function, but somehow does not return any response data.\nDeleting the ML function call from the query results in a successfull run of the job with output events.\n\nFor the deployment of the ML Webservice I tried the following (working for VS, no output in cloud):\n\nACI (1 CPU, 1 GB RAM)\n\n\nAKS dev\/test (Standard_B2s VM)\n\n\nAKS production (Standard_D3_v2 VM)\n\nThe inference script function schema:\n\ninput: array\n\n\noutput: record\n\n\n\n\n\n\n\nThe ASA job subquery with ML function call:\n\n\"Sequence\" is a subquery that aggregates the data into sequences (arrays) with an user-defined aggragate.\n\nI hope the provided information is sufficient and you can help me.",
        "Answers":[
            {
                "Answer_creation_time":"2020-07-16T21:46:51.443Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, can you share a link to your swagger? This is a public link that can be accessed without any keys.\n\nFew questions:\n1. In VS 2019, did you test using live data flowing in from your IoT Hub? Or did you use a sample input file\/local input?\n2. You mention that the input is an array, however the sample input says [[1.]*18]. I am trying to understand what this represents. And what does numpyfySeq UDF do?\n3. Can you open the ml UDF on the portal and see if the \"function signature\" is listed correctly?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-17T07:58:51.603Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thank you for your reply.\n\nYes sure, here it is:\nswagger.json\n\nTo your questions:\n\nIn VS i was using live data from the IoT-Hub.\n\n\nThe numpyfySeq UDF looks like this:\n\n\nList item\n\nIt uses the aggregates created in the \"Sequence\" subquery and puts them all together in a N x 18 size array.\nThe \"Sequence\" subquery uses also an UDA (\"stackSequence\") to aggregate data into arrays of arbitrary length (all occured events in a hopping window with width N seconds and hop size 1 second should be appended to an array).\nPart of the \"Sequence\" subquery:\n\nThe used schema [[1.]*18] creates a reduced form (1 x 18 shape) of the desired input array shape and with the optional parameter \"enforce_shape=False\" in the decorator i could manage to call the function with an abitrary N x 18 shape array.\n\nOn the portal the function signature is listed correctly:",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-17T22:25:58.167Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for the details. Everything seems like it is configured correctly. And from what you say, it sounds like this scoring works well when using VS but not when job is running? One last thing to check is maybe the event ordering settings of your job on the portal. When job is running, you can also see the metric \"late events\" to see if these inputs are getting filtered out.\n\nIn this case it will require additional debugging from our team. Can you please file a support ticket and reference this thread?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-18T10:09:45.22Z",
                "Answer_upvote_count":0,
                "Answer_body":"Yes, this is correct, in VS the scoring works well and works both with local and blobstorage output and when the job is running, the function is called successfully, but no output is generated.\nI checked the metric \"late input events\" within a period of the last 30 days and the rate is very low (0.0003 %).\n\nI will file a support ticket then.\nThanks for your help so far.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":37.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Machine Learning cost",
        "Question_creation_time":1607408839580,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/190053\/azure-machine-learning-cost.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":5,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello,\n\nI am new to Azure Machine Learning, I have some questions related to cost\n\n1) What will be the cost breakup? (Workspace charges, Network charges, Disk Charges etc.)\n\n2) I saw that there were some charges for Bandwidth and Load balancer. Why is it getting charged and I am not able to see the details in Azure ML?\n\n3) I have a SQL Sever which is inside a Vnet (VPN Gateway) and I want to integrate it with Azure Machine Learning and use the data for my analysis. What all will be the charges for it?\n\n4) Is there a way to stop the computes automatically when i am not using it, as i dont want to be charged when i am not using the Azure Machine learning?\n\n5) Will there be any charges even though i am not using the Azure Machine learning? (Static Charges)",
        "Answers":[
            {
                "Answer_creation_time":"2020-12-08T08:02:34.743Z",
                "Answer_upvote_count":2,
                "Answer_body":"@SrinivasanG-1471 Here are the charges that you could incur for the above setup:\n\n1) What will be the cost breakup? (Workspace charges, Network charges, Disk Charges etc.)\n\n\n\n\nFor Azure Machine learning the charges of ML services are nil for enterprise edition workspaces. Currently all the workspaces are using enterprise edition and if there are any basic edition workspaces they can be migrated with no down time. All other charges while using Azure ML workspace depends on the compute used and the setup of the compute. If they are enabled in a vnet then you could incur data charges according to vnet's pricing.\n\n\n\n\n2) I saw that there were some charges for Bandwidth and Load balancer. Why is it getting charged and I am not able to see the details in Azure ML?\n\nThe charges incurred for LB and bandwidth could be based on your setup and how the compute was setup to run the experiments. If you have also setup your designer to use virtual network then there could be charges on how the compute was setup with respect to the region. More details of the setup of workspace with private networks are detailed here. For the breakup of charges mentioned above you can raise a support request through the azure portal for billing which does not require any support plan to raise a ticket from the Help+Support tab on Azure portal.\n\n3) I have a SQL Sever which is inside a Vnet (VPN Gateway) and I want to integrate it with Azure Machine Learning and use the data for my analysis. What all will be the charges for it?\n\nOnce you are able to confirm if your vnet connection is successful you can get the data from Azure SQL database using the import data module from Azure ML designer. If you are planning to setup your own SQL server then this functionality is not supported with the available options, you might need to use the option URL via HTTP to get the required data in your experiments.\n\nIf you are attaching storage from different region than workspace region, it can result in higher latency and additional network usage costs.\n\n4) Is there a way to stop the computes automatically when i am not using it, as i dont want to be charged when i am not using the Azure Machine learning?\n\nThe option to shutdown compute instance automatically that is not in use is not available currently. You can stop the compute instances that are not required, for compute clusters you can set the minimum no. of nodes to 0 to ensure no compute is running when not in use.\n\n5) Will there be any charges even though i am not using the Azure Machine learning? (Static Charges)\n\nAzure ML learning enterprise edition workspaces do not have a surcharge i.e charges for using Azure ML. If there are any associated compute or storage or virtual networks there could be charges if used.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-10-25T10:18:13.413Z",
                "Answer_upvote_count":0,
                "Answer_body":"I had the same issue recently.\nI was being charged money for \"load balancer\" while obviously there is no place in Azure ML to start or stop a load balancer. I have checked my ML Studio under 'Compute' section make sure there is no running compute instances or clusters in ML.\n\nHow I solved the issue:\nI realised that I have created a real-time inference endpoint and I suspect that can be costing me money. I deleted that endpoint and in the next few days I can see the 'load balancer' cost has disappeared. Problem solved.\n\nConclusion:\na real-time inference endpoint requires some computing resources (I believe it's an AKS cluster in this case) so there should be a cost.\nHowever, this computing resource is not shown under the 'compute' section. Not under any of the 4 tabs there (compute instances, computer clusters, inference clusters, attached computes). I believe it should show under the \"inference cluster\" tab in the compute section, but it didn't.\nIn 'cost analysis', this cost has been incorrectly categorised to \"load balancer\". This categorisation is not only very confusing but also incorrect.\n\n\n\n\n@romungi-MSFT Could you please advise if my finding is correct or not?",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-25T09:56:17.43Z",
                "Answer_upvote_count":0,
                "Answer_body":"@taowang-5804\nI too saw a lot of Load Balancer charged in my invoice, as a matter of fact I got charged everyday for Load Balancer for 2 months. I am sure that the total amount of time I would have kept a Real Time Endpoint live would not exceed 3-4 hours during the course of 2 months. I have contacted helpdesk, looking forward to their response.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-28T10:14:03.033Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\nI also noticed some load balancer costs today and found a way to stop the LB costs.\nBased on this Microsoft Docs: https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/main\/articles\/machine-learning\/concept-plan-manage-cost.md#costs-might-accrue-before-resource-deletion\n\nEach VM is billed per hour it is running. Cost depends on VM specifications. VMs that are running but not actively working on a dataset will still be charged via the load balancer. For each compute instance, one load balancer will be billed per day. Every 50 nodes of a compute cluster will have one standard load balancer billed. Each load balancer is billed around $0.33\/day. To avoid load balancer costs on stopped compute instances and compute clusters, delete the compute resource. One virtual network will be billed per subscription and per region. Virtual networks cannot span regions or subscriptions. Setting up private endpoints in vNet setups may also incur charges. Bandwidth is charged by usage; the more data transferred, the more you are charged.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-29T05:38:58.373Z",
                "Answer_upvote_count":0,
                "Answer_body":"@moba-7946\n\nI had created my VMs on Jan 2021. My billings were close to Rs 800 per month($12 per month). Not only that, it remained consistent and only changed in a minor way whenever I used them for any ML training work.\n\nBut now all of a sudden since Feb 2022 I am being charged for a LB! and my costs have gone up >3x. I've been in touch with some people in the billing team but they are taking their own sweet time to respond.\n\nI am willing to accept that this is a fair charge as long as they can answer the following:\n\n\nLocate the LB linked to my account\nIs the LB charge a new addition ? if not then why was I never billed before for instances I've owned since Jan 2021 ?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How AI\/Machine learning works in translator",
        "Question_creation_time":1632270279733,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/561221\/how-aimachine-learning-works-in-translator.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-translator"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am an undergraduate community college student in Richmond, VA.\n\nI am wondering if you can help me understand how the translator works or if you can connect me with another expert who might be able to help me learn exactly how google translate works.\n\nQuestions:\n\nIf you enter the same phrase into the translator multiple times, does the program learn from it? If so, how?\n\nDoes the translator take what people enter into the translator, store it and use it to output a common translation?\n\nHere is a scenario. Let's say I wrote something in english and then translated it word for word into farsi. Then, I took my farsi work, inputed into google translate, and the output was a translation almost word for work with my english translation. IF I keep doing that, would the translator \"deep learn\" and correct itself so that it exactly matched my english translation? What about if I kept hitting the reverse arrow, and changing a word here or there, until both the farsi and english sentences inside the translator, match exactly what I originally wrote? Would the translator learn from that? In that way could I have \"taught\" the translator the most common way to interpret sentences in either language? Is there a way to prove that someone used a translator to write something? IF someone is trying to prove that someone else used a translator to create a literary work, instead of writing it themselves, can they fairly say that the translator's translation matching word for word is indisputable, undeniable proof of their accusation?\n\nVery Respectfully,",
        "Answers":[
            {
                "Answer_creation_time":"2021-09-23T04:53:45.967Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for reaching out. According to our confidentiality document, customer data submitted for translation to Azure Cognitive Services Translator (both standard and custom models), Speech service, the Microsoft Translator Speech API, and the text translation features in Microsoft Office products are not written to persistent storage. There will be no record of the submitted text or voice, or any portion thereof, in any Microsoft data center. The audio and text will not be used for training purposes either. The documents you upload using Custom Translator (portal or APIs) are stored encrypted in your workspace. Custom Translator uses your uploaded documents exclusively to provide your personalized translation system and does not use it for any other purpose. The documents you upload to Custom Translator will be stored in the Azure region you selected when you created your Translator key until you delete them or until your account expires. For more details on Microsoft Translator and how to use the service, please review our documentation.\n\nHope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Issues with SQL Alchemy whilst deploying real time endpoint on ACI",
        "Question_creation_time":1642105094927,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/694586\/issues-with-sql-alchemy-whilst-deploying-real-time.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-container-instances"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,\n\nI'm trying to deploy an image to an ACI using Azure Machine Learning. One of the requirements\/installations is sqlalchemy.\n\nWhen building the image, sqlalchemy seems to install correctly. However, when I try to import the sqlalchemy modules within the code, the deployment to the ACI fails and I can't work out why.\n\nAnyone had any similar issues - let me know if I need to provide any more info.\n\nThanks,\n\nCam",
        "Answers":[
            {
                "Answer_creation_time":"2022-01-14T09:23:13.24Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hey,\n\nThanks for the reply. Below is currently what I'm doing - I'm using a yaml file rather than a docker file but I think what I'm currently doing should allow dependencies?\n\nThis is part of my yaml file that i'm supplying to the image\n\n\n\n\n\nAnd then this is the code for the image i'm deploying.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":13.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"real-time inference pipeline failed to deploy for some unknown error and unable to view the logs",
        "Question_creation_time":1662748337977,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1001503\/real-time-inference-pipeline-failed-to-deploy-for.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"After submitting a successful inference pipeline, I attempted to deploy the model to a container instance. However, it failed and to make it worse I can't see the logs due to forbidden permissions error even though I am sole owner of resource group & instance. To put the nail on the coffin, I also can't view any related container instances inside Azure Portal...only the endpoints in ML studio.\n\nHere's the permissions error:\n\n ![{\n   \"error\": {\n     \"code\": \"Forbidden\",\n     \"message\": \"Forbidden\",\n     \"details\": [\n       {\n         \"code\": \"AuthorizationFailed\",\n         \"message\": \"The client 'df9ec36b-a97d-4c60-a6fe-91048565a571' with object id 'df9ec36b-a97d-4c60-a6fe-91048565a571' does not have authorization to perform action 'Microsoft.ContainerInstance\/containerGroups\/containers\/logs\/read' over scope '\/subscriptions\/7d36b75b-8fd4-4ef9-92fe-69f951afa25d\/resourceGroups\/playground\/providers\/Microsoft.ContainerInstance\/containerGroups\/playground-pipe-ommOzSbRhUSx8qiJGQ4HiA\/containers\/playground-pipe' or the scope is invalid. If access was recently granted, please refresh your credentials.\"\n       }\n     ]\n   },\n   \"correlation\": {\n     \"RequestId\": \"745ad382-74c0-4c67-8853-053807cd6336\"\n   }\n }][1]\n\n\n\n\n[1]: \/answers\/storage\/attachments\/239641-screenshot-2022-09-09-175802.png",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":6.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Designer python script to save Dataset data as csv to compute instance directories",
        "Question_creation_time":1630351702510,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/533352\/designer-python-script-to-save-dataset-data-as-csv.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I have a set of custom Python and R scripts to execute a machine learning pipeline for analysis purposes. The steps are as follows:\n\nWith Python, Convert Datastore data to csv that gets saved in the compute instance directory\n\n\nWith R, pull in the csv data and run some feature engineering, build a machine learning model, and save scoring data to directory as csv\n\n\nPush csv data back to Datastore\n\nThe first issue I'm encountering in Designer is the first step, saving Datastore data as csv to the compute instance directory. I created a function called azureml_main() that internally pulls in the Datastore data and saves it as csv to the directory. I have run the code that's inside the function a bunch of times but when I try to have it run in the Python script node in Designer it fails.\n\nError message:\n\nAmlExceptionMessage:User program failed with FailedToEvaluateScriptError: The following error occurred during script evaluation, please view the output log for more information:\n---------- Start of error message from Python interpreter ----------\nGot exception when invoking script at line 22 in function azureml_main: 'AuthenticationException: Unknown error occurred during authentication. Error detail: Unexpected polling state code_expired'.\n---------- End of error message from Python interpreter ----------\n\nModuleExceptionMessage:FailedToEvaluateScript: The following error occurred during script evaluation, please view the output log for more information:\n---------- Start of error message from Python interpreter ----------\nGot exception when invoking script at line 22 in function azureml_main: 'AuthenticationException: Unknown error occurred during authentication. Error detail: Unexpected polling state code_expired'.\n---------- End of error message from Python interpreter ----------\n\n\n\n\n\/\/ Python script inside Python node in Designer.\n\/\/ The script MUST contain a function named azureml_main\n\/\/ which is the entry point for this module.\n\nimport pandas as pd\n\n\/\/ The entry point function MUST have two input arguments.\n\/\/ If the input port is not connected, the corresponding\n\/\/ dataframe argument will be None.\n\/\/ Param<dataframe1>: a pandas.DataFrame\n\/\/ Param<dataframe2>: a pandas.DataFrame\n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    # Azure management\n    from azureml.core import Workspace, Dataset\n    # MetaData\n    subscription_id = '09b5fdb3-165d-4e2b-8ca0-34f998d176d5'\n    resource_group = 'xCloudData'\n    workspace_name = 'xCloudML'\n    # Create workspace \n    workspace = Workspace(subscription_id, resource_group, workspace_name)\n    # 1. Retention_Engagement_CombinedData\n    dataset = Dataset.get_by_name(workspace, name='retention-engagement-combineddata')\n    # Save data to file\n    df = dataset.to_pandas_dataframe()\n    df.to_csv('\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/v-aantico1\/code\/RetentionEngagement_CombinedData.csv')\n    # 2. TitleNameJoin\n    dataset = Dataset.get_by_name(workspace, name='TitleForJoiningInR')\n    # Save data to file\n    df = dataset.to_pandas_dataframe()\n    df.to_csv('\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/v-aantico1\/code\/TitleNameJoin.csv')\nazureml_main()",
        "Answers":[
            {
                "Answer_creation_time":"2021-08-30T22:02:22.097Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi, thanks for reaching out. There's no need to re-authenticate inside the Execute Python Script module, instead include the following:\n\n     from azureml.core import Run\n     run = Run.get_context(allow_offline=True)\n     #access to current workspace\n     ws = run.experiment.workspace\n\n\n\nHope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"AssertError:read can not have position excceed buffer length",
        "Question_creation_time":1618316417143,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/355512\/asserterrorread-can-not-have-position-excceed-buff.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi i am getting following error when trying to predict using externally generated R xgboost model in azure ML studio\n\nError 0063: The following error occurred during evaluation of R script:\n---------- Start of error message from R ----------\nAssertError:read can not have position excceed buffer length",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-13T16:22:15.963Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for reaching out. There might be a conflict between versions of xgboost. Can you confirm that version used to create the model is <=0.90?",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azuremlsdk for R hangs on update while solving environment",
        "Question_creation_time":1624849818327,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/453836\/azuremlsdk-for-r-hangs-on-update-while-solving-env.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":2.0,
        "Question_view_count":null,
        "Question_answer_count":4,
        "Question_has_accepted_answer":false,
        "Question_body":"I haven't used azuremlsdk for R in a few weeks. When I tried to use it today it said it had to update, the update seems to get stuck on step 17.\n\nThis is the last message before it timeouts in 1h 30m.\n\nStep 17\/23 : RUN conda install -p \/azureml-envs\/azureml_da3e97fcb51801118b8e80207f3e01ad -c r -y r-essentials=3.6.0 rpy2 r-checkpoint && pip install --no-cache-dir azureml-defaults ---> Running in 30337f6502b4 Solving environment: ...working...\n\nI have tried updating miniconda from the anaconda prompt and I've tried deleting my azureml resource and creating a new one. Any ideas what is going on?",
        "Answers":[
            {
                "Answer_creation_time":"2021-06-30T20:09:46.047Z",
                "Answer_upvote_count":1,
                "Answer_body":"Exactly the same problem for me.\n\nI tried on 2 different compute clusters (Standard_D2_v2, Standard_DS12_v2) both in eastus.\n\nI am trying to execute a tutorial directly from Azure ML Notebook (azureml-sdk-for-r\/vignettes\/train-and-deploy-first-model)\n\n\n\n\nHere the last message I have in the build log\n\nDownloading and Extracting Packages\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\n[91m\n[0mRemoving intermediate container e514a28cde98\n---> 57dfbf426dfa\nStep 17\/23 : RUN conda install -p \/azureml-envs\/azureml_da3e97fcb51801118b8e80207f3e01ad -c r -y r-essentials=3.6.0 rpy2 r-checkpoint && pip install --no-cache-dir azureml-defaults\n---> Running in 0ab44ea8e6a3\nSolving environment: ...working...",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-05T13:53:58.41Z",
                "Answer_upvote_count":0,
                "Answer_body":"@ramr-msft any news on this?\nI have tried many times but it still doesn't work.\nThank you",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-30T15:04:12.567Z",
                "Answer_upvote_count":0,
                "Answer_body":"@ramr-msft Is there any update for this, I'm also having exactly the same issue described.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-08-23T12:44:52.16Z",
                "Answer_upvote_count":0,
                "Answer_body":"@JamieWallis-0781 @Eric-4026 what is the base image you are using for your environments? conda 4.5 resolver is experiencing issues like that recently, so old base images could be the root cause of your issue",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":6.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Execure R scripting and R Desktop output varies",
        "Question_creation_time":1626086340790,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/472103\/execure-r-scripting-and-r-desktop-output-varies.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\nExecuting a model with Execute R Script in Azure ML produces a different result compared to R desktop (R 4.1.0)\nHere are step I followed\na. With Azure ML studio ,Imported the 2 data sets Testb.csv and Testc,csv\nand using the 2 datasets , executed the R script ( see AzureMLR.txt)\nand executed the almost same script in R Desktop ( except i had to read from csv files instead from the ports) ( see RDesktopcode.txt)\n\nI see a big difference in output produced by both\nRefer this snapshot where one on left is from AzureML and right is R Desktop\n\nYou may to rename testb.txt and textc.txt as csv files to use them . I could not upload csv files so changed to txt files\n\nTHanks",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":4.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Constantly getting this error while training Deep and Wide model. Model is expected to be fed with features: ['feature_user_feature_2', ....",
        "Question_creation_time":1668240133527,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1086242\/constantly-getting-this-error-while-training-deep.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azure-mgmt-core 1.3.0 (\/azureml-envs\/azureml_1c52c6e25bd3041eabbd9a52168ae46\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-core<2.0.0,>=1.3.1'), {'azure-mgmt-keyvault'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azure-mgmt-core 1.3.0 (\/azureml-envs\/azureml_1c52c6e25bd3041eabbd9a52168ae46\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-core<2.0.0,>=1.3.1'), {'azure-mgmt-keyvault'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azure-mgmt-core 1.3.0 (\/azureml-envs\/azureml_1c52c6e25bd3041eabbd9a52168ae46\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-core<2.0.0,>=1.3.1'), {'azure-mgmt-keyvault'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (azure-mgmt-core 1.3.0 (\/azureml-envs\/azureml_1c52c6e25bd3041eabbd9a52168ae46\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-core<2.0.0,>=1.3.1'), {'azure-mgmt-keyvault'}).\nSession_id = 84c324df-90e3-4d06-963d-c896854583\nInvoking module by urldecode_invoker 0.0.8.\n\nModule type: custom module.\n\nUsing runpy to invoke module 'azureml.designer.modules.recommendation.dnn.wide_and_deep.train.run'.\n\n2022-11-06 17:12:43.374707: W tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: \/azureml-envs\/azureml_1c52c6e25bd041eabbd9a52168ae46\/lib:\/usr\/local\/nvidia\/lib:\/usr\/local\/nvidia\/lib64:\/usr\/local\/cuda\/lib64:\/usr\/local\/cuda\/extras\/CUPTI\/lib64\n2022-11-06 17:12:43.374762: I tensorflow\/stream_executor\/cuda\/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2022-11-06 17:12:45,992 studio.common INFO azureml-designer-recommender-modules 0.0.54\n2022-11-06 17:12:51,404 studio.core INFO preprocess_transactions - Start:\n2022-11-06 17:13:06,585 studio.core INFO preprocess_transactions - End with 15.1769s elapsed.\n2022-11-06 17:13:06,589 studio.core INFO preprocess_features - Start:\n2022-11-06 17:13:06,607 studio.core INFO preprocess_features - End with 0.0176s elapsed.\n2022-11-06 17:13:06,607 studio.core INFO preprocess_features - Start:\n2022-11-06 17:13:06,666 studio.core INFO preprocess_features - End with 0.0583s elapsed.\n2022-11-06 17:13:12,074 studio.common INFO Get 10 features\n2022-11-06 17:13:12,166 studio.common INFO Create feature metas for 10 features\n2022-11-06 17:13:14,412 studio.common INFO Get 1 features\n\/azureml-envs\/azureml_1c52c6e25bd3041eabbd9a52168ae46\/lib\/python3.8\/site-packages\/pandas\/core\/generic.py:6245: SettingWithCopyWarning:\nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/indexing.html#returning-a-view-versus-a-copy\nself._update_inplace(new_data)\n2022-11-06 17:13:14,466 studio.common INFO Create feature metas for 1 features\n2022-11-06 17:13:14,500 studio.common DEBUG Init train input function builder.\n2022-11-06 17:13:14,503 studio.common INFO Build 10 features for User ids.\n2022-11-06 17:13:17,704 studio.common INFO Process null values for features.\n2022-11-06 17:13:17,736 studio.common INFO Build 1 features for Item ids.\n2022-11-06 17:13:20,012 studio.common INFO Process null values for features.\n2022-11-06 17:13:26,398 studio.module INFO Get 5775792 training instances, and 90247.0 batches per epoch.\n2022-11-06 17:13:29,489 studio.module INFO Build model:\nEpochs: 15\nBatch size: 64\nWide optimizer: OptimizerSelection.Adagrad\nWide learning rate: 0.1\nDeep optimizer: OptimizerSelection.Adagrad\nDeep learning rate: 0.1\nHidden units: (256, 128)\nActivation function: ActivationFnSelection.ReLU\nDropout: 0.8\nBatch norm: True\nCrossed dimension: 1000\nUser embedding dimension: 16\nItem embedding dimension: 16\nCategorical feature embedding dimension: 4\n2022-11-06 17:13:29,546 studio.module INFO Model is expected to be fed with features: ['feature_user_feature_2', 'feature_user_feature_8', 'feature_user_feature_3', 'feature_user_feature_9', 'feature_user_feature_4', 'feature_item_feature_0', 'User', 'Item', 'feature_user_feature_5', 'feature_user_feature_1', 'feature_user_feature_6', 'feature_user_feature_0', 'feature_user_feature_7']\n2022-11-06 17:13:30,077 tensorflow INFO Using config: {'_model_dir': '\/tmp\/tmp7lhxl5n0\/checkpoints', '_tf_random_seed': 42, '_save_summary_steps': 100, '_save_checkpoints_steps': 1353705.0, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\ngraph_options {\nrewrite_options {\nmeta_optimizer_iterations: ONE\n}\n}\n, '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 90247.0, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Can not use AutoML models",
        "Question_creation_time":1653642599833,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/866814\/can-not-use-automl-models.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,\n\nI have run an autoML model and in the jobs window of the studio, I can see it worked as I can see all the models generated under different algorithms and their performance. Then in notebook I am trying to retrive the best performing model and I am calling the AUTOML model using:\n\nlocal_run = AutoMLRun(experiment, \"AutoML_5970dd9a-1dae-4e6b-90ff-47878565822f_0\",outputs=None)\n\nwhich works just fine and then:\n\nbest_run, fitted_model = local_run.get_output()\n\nand there is an error that I dont know how to solve: TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n\nSo please your help to solve this!\n\nThank you!",
        "Answers":[
            {
                "Answer_creation_time":"2022-06-04T07:13:57.28Z",
                "Answer_upvote_count":1,
                "Answer_body":"I just solved this, it was caused by my Wrong JSON format. You need to check it too",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-07T14:34:12.013Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for the update, Yes this issue caused due to the wrong format of json str.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Rest api to create or update azure ML workspace doesn't create dependant resources",
        "Question_creation_time":1591181902550,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/31569\/rest-api-to-create-or-update-workspace-doesnt-crea.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Problem with https:\/\/docs.microsoft.com\/en-gb\/rest\/api\/azureml\/workspacesandcomputes\/workspaces\/createorupdate API... In the request body, Is it mandatory to create storage account, app insights, key vault, registration resources before? Ideally since these are dependent resources, shouldn\u2019t it be created as part of workflow creation?\nI get below response when dependent resources are not created prior.\n\n `{\n   \u201cerror\u201d: {\n     \u201ccode\u201d: \u201cValidationError\u201d,\n     \u201cmessage\u201d: \u201cOne or more validation errors occured.\u201c,\n     \u201cmessageFormat\u201d: null,\n     \u201cmessageParameters\u201d: null,\n     \u201creferenceCode\u201d: null,\n     \u201cdetailsUri\u201d: null,\n     \u201ctarget\u201d: \u201cCan not perform requested operation on nested resource. Parent resource \u2018&amp;lt;resourceid&amp;gt;\u2019 not found.\u201c,\n     \u201cdetails\u201d: [],\n     \u201cinnerError\u201d: null,\n     \u201cdebugInfo\u201d: null\n   },\n   \u201ccorrelation\u201d: {\n     \u201coperation\u201d: \u201c&amp;lt;opid&amp;gt;\u201c,\n     \u201crequest\u201d: \u201c&amp;lt;reqid&amp;gt;\u201d\n   },\n   \u201cenvironment\u201d: \u201cwestus\u201d,\n   \u201clocation\u201d: \u201cwestus\u201d,\n   \u201ctime\u201d: \u201c2020-06-03T07:13:14.6463577+00:00&amp;#34;\n }`\n\n\n\n\nI need an API which works similar to https:\/\/docs.microsoft.com\/en-us\/cli\/azure\/ext\/azure-cli-ml\/ml\/workspace?view=azure-cli-latest",
        "Answers":[
            {
                "Answer_creation_time":"2020-06-04T10:32:12.953Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @HarshiniKS-4497,\n\nYes, the REST API needs the other resource ids to be mentioned in the request body or they need to be created prior to this call unlike azure cli which provides the option to create them in a single request with input parameters. You could also try to use ARM template to create all the resources by calling this action from PS or cli.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":3.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to save and load ML model with Azure Data Factory",
        "Question_creation_time":1623657811393,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/434449\/how-to-save-and-load-ml-model-with-azure-data-fact.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-data-factory",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I have an Azure Data factory that receives data from a service bus and then I want to classify my data with an ML model.\n\nIs there any solution to save and load the ML model on the Azure Data Factory pipeline?\n\nFor your information, I want to use cloud base solution. I don't use the PICKLE library.",
        "Answers":[
            {
                "Answer_creation_time":"2021-06-16T16:21:07.257Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @MohsenAkhavan,\nThanks for the ask and using the Microsoft Q&A platform .\n\nI think you can use the machine learning activity . Read and watch the video here .\n\nThe challenge in your case is the data is in EH and at this time ADF cannot read EH data . I suggest you to use a Azure stream analytics jobs and read the data from EH and write it to SQL or blob . Once the data is in any of these two sources ADF can be used to read the data .\n\nPlease do let me know how it goes .\nThanks\nHimanshu\nPlease do consider clicking on \"Accept Answer\" and \"Up-vote\" on the post that helps you, as it can be beneficial to other community members",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Batchscoring on Batch Endpoint of AutoML model giving error - UserError: {\"NonCompliant\":\"Process",
        "Question_creation_time":1669318257423,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1103764\/batchscoring-on-batch-endpoint-of-automl-model-giv.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"AutoML time-series model created from Sql Database data. - successful\nRegistered Model. - successful\nEndPoints creation - Deploy to Batch End Point. - successful\nCreating Batchscoring Jon in EndPoint - Fails with below error.\n\nError -\n{\"NonCompliant\":\"Process '\/azureml-envs\/azureml_c9e8754bdba5226a1ab803f256ee343b\/bin\/python' exited with code 1 and error message 'Execution failed. Process exited with status code 1. Error: Traceback (most recent call last):\\n File \\\"driver\/amlbi_main.py\\\", line 184, in <module>\\n main()\\n File \\\"driver\/amlbi_main.py\\\", line 126, in main\\n boot(driver_dir)\\n File \\\"driver\/amlbi_main.py\\\", line 58, in boot\\n booter.start()\\n File \\\"\/mnt\/azureml\/cr\/j\/5abd1dee5bc441ae8d26b873695fdcf8\/exe\/wd\/driver\/azureml_user\/parallel_run\/boot.py\\\", line 383, in start\\n self.start_sys_main()\\n File \\\"\/mnt\/azureml\/cr\/j\/5abd1dee5bc441ae8d26b873695fdcf8\/exe\/wd\/driver\/azureml_user\/parallel_run\/boot.py\\\", line 269, in start_sys_main\\n self.run_sys_main(cmd)\\n File \\\"\/mnt\/azureml\/cr\/j\/5abd1dee5bc441ae8d26b873695fdcf8\/exe\/wd\/driver\/azureml_user\/parallel_run\/boot_node.py\\\", line 111, in run_sys_main\\n self.check_run_result(proc=proc, stdout=stdout or \\\"\\\", stderr=stderr or \\\"\\\")\\n File \\\"\/mnt\/azureml\/cr\/j\/5abd1dee5bc441ae8d26b873695fdcf8\/exe\/wd\/driver\/azureml_user\/parallel_run\/boot.py\\\", line 218, in check_run_result\\n BootResult().check_result(stdout)\\n File \\\"\/mnt\/azureml\/cr\/j\/5abd1dee5bc441ae8d26b873695fdcf8\/exe\/wd\/driver\/azureml_user\/parallel_run\/boot_result.py\\\", line 36, in check_result\\n raise Exception(message) from cause\\nException: Run failed, please check logs for details. You can check logs\/readme.txt for the layout of logs.\\n\\n'. Please check the log file 'user_logs\/std_log_0.txt' for more details.\"}\n{\n\"code\": \"ExecutionFailed\",\n\"target\": \"\",\n\"category\": \"UserError\",\n\"error_details\": [\n{\n\"key\": \"exit_codes\",\n\"value\": \"1\"\n}\n]\n}",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":18.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Endpoint Unhealthy error when trying to test deployed endpoint for inference pipeline",
        "Question_creation_time":1669672796280,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1107528\/endpoint-unhealthy-error-when-trying-to-test-deplo.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-container-instances",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello, I am following the module from Microsoft Learn on regression using Azure's Machine Learning Designer, when trying to Test the service\n\nhttps:\/\/microsoftlearning.github.io\/AI-900-AIFundamentals\/instructions\/02a-create-regression-model.html#test-the-service\n\nWhen trying to test the predict-auto-price endpoint, I get the following screen\n\n\n\n\n\n\n\nDoes anyone know how I can address this? I am fairly new to Azure, so I apologize if I'm missing something obvious",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":19.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How much will it cost me to learn Azure Machine Learning?",
        "Question_creation_time":1589500691030,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/27214\/how-much-will-it-cost-me-to-learn-azure-machine-le.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"I&#39;m trying to do the Azure Data Scientist Associate certification. I&#39;m on the first portion of learning exercises and it has me create a Machine Learning Workspace and then its had me create a VM which according to the Azure pricing calculator will cost me $367 a month. If I forget to shut down this VM could I get a bill for this much? Is there a way to have these VM&#39;s automatically shut down? Since I&#39;m only interacting with this VM via a web interface I&#39;m really worried that I&#39;m going to get stuck with some hefty bills after this training. Should I be concerned? The Azure Portal has a cost estimate section but it does not include any of my Machine Learning resources or workspaces so I&#39;m not sure how I can get a realistic estimate for how much this will cost me to complete this training.",
        "Answers":[
            {
                "Answer_creation_time":"2020-05-17T13:45:44.483Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @SteveZaske-8007,\n\nI believe that you are trying to create a compute instance from ML portal ml.azure.com which gives you an option to stop or delete the instance but does not have an option to auto shutoff the instance since this feature is not available for compute instance.\n\nYou have an option to use the compute cluster type of compute which allows you to set the minimum\/maximum number of nodes. In this case to avoid being billed when the training is not in progress the minimum number of 0 will ensure you do not have any nodes running when not required. You can also set this from the SDK if required.\n\nFor example, if you are using the Basic plan and you you train a model for 100 hours using 10 DS14 v2 VMs on an Basic workspace in US West 2. For a billing month of 30 days, your bill will be as follows:\n\nAzure VM Charge: (10 machines $1.196 per machine) 100 hours = $1,196\n\nAzure Machine Learning Charge: (10 machines 16 cores $0 per core) * 100 hours = $0\n\nTotal: $1,196 + $0 = $1,196\n\nBut if you are using an Enterprise edition when it becomes generally available, it will have a machine learning surcharge (for training and inferencing). When this is enabled the calculator will be updated to give you an estimate of surcharge based on the amount of time you run the training and inferencing.\n\nSo, in the current scenario the charge for your training depends on the amount of time you use the VM. If you use compute instance type you need to ensure to stop or delete it when not required, If compute cluster type is used you can set the minimum number of nodes to 0 to avoid billing when there is no training.\n\nWe hope this helps.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-05-18T22:59:00.463Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @SteveZaske-8007 , The good news is that you can create an Azure Machine Learning studio workspace for free. All you have to do is open any modern browser, and go to studio dot Azure ML dot net, and sign in using a live I.D. and you're ready to go. Now of course it's free, so there are some restriction, especially around how much compute you can consume, so there are some restrictions, you can use the absolutely free version, that is no credit card required, that is no Azure subscription needed. Certainly, if you have an Azure subscription, you can use it and that'll allow you to create a slightly more complex model, that may consume more compute. Maybe you want to import some data from an existing source, or some other data store that already might be on Azure, you can use datasets up to 10GB for free. so I think for more serious projects, you'll probably end up using your Azure subscription,",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Error: Incremental refresh of labeling project",
        "Question_creation_time":1607952473720,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/197548\/error-incremental-refresh-of-labeling-project.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":2.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-labeling-projects#--configure-incremental-refresh\n\nStates incremental refresh picks up new data every 24h.\nTested this on a cat\/dog dataset.\n\nFirst added 3 pictures of dogs in a dataset. Created classification labeling project, with incremental refresh enabled. Labeled 2 images. Updated dataset with 3 images of cats. confirmed updated dataset version ID is used on labeling project. However, images of cats are not included in the labeling project.\n\nAny help?",
        "Answers":[
            {
                "Answer_creation_time":"2020-12-18T20:57:48.347Z",
                "Answer_upvote_count":0,
                "Answer_body":"I wasn't able to reproduce this issue. After enabling incremental refresh, I uploaded new images to my connected blob storage, and the images were added to my project in less than 24hrs. Currently, there is no way to specify frequency but I've informed the product team of your request. If you continue to have issues with incremental refresh, it may be best to submit a support request to troubleshoot further since we're not able to reproduce this issue. Hope this helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Pathway for code free predictive modeling",
        "Question_creation_time":1592869306553,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/38841\/pathway-for-code-free-predictive-modeling.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I am looking at Azure&amp;#39;s training modules and it states I can learn no-code models with Azure, but it also tells me I should know python. I&amp;#39;m a little confused at where I should spend time training in most efficient pathway. My goal is to just do predictive modeling within Azure. I have technical\/IT literacy however coding is at a basic level.\n\nIdeally id like some sort of Certification, if possible from just &amp;#34;Create no-code predictive models with Azure Machine Learning&amp;#34;\n\nIs &amp;#34;Microsoft Certified: Azure Data Scientist Associate&amp;#34; going to require a lot of pre work on python\/torch\/tensor? I&amp;#39;d ideally like Azure to be my entry.",
        "Answers":[
            {
                "Answer_creation_time":"2020-06-23T15:06:48.467Z",
                "Answer_upvote_count":2,
                "Answer_body":"Thanks for reaching out. Azure machine learning has a drag and drop interface (Designer) that supports code free predictive modeling. Create no-code predictive models with Azure Machine Learning training modules is a great starting point and provides a pathway for Azure Data Scientist Associate certification. However, you also need programming experience and familiarity with various data science processes\/principles to be successful on the certification exam.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":2.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"AML Workspace Alerting and Application Insight Dashboard Configuration",
        "Question_creation_time":1660054347030,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/960800\/number-of-run-errors-in-ml-workspace-count-is-upda.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi All,\n\nI would need seach query understanding to configure alert for below metrics for AML Workspace and I also need to show metrics in Application Insight dashboard which are associated with AML.\n\nPlease guide on this.\n\nAlert Description :\n\nMetric Name Unit Description\n1. -Warnings -Count -Number of run warnings in this workspace. Count is updated whenever a run encounters a warning.\n2. -Errors -Count -Number of run errors in this workspace. Count is updated whenever run encounters an error.\n3. -Failed Runs -Count -Number of runs failed for this workspace. Count is updated when a run fails.",
        "Answers":[
            {
                "Answer_creation_time":"2022-08-10T00:00:20.17Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @RakeshSharma-8583,\n\nThank you for posting query in Microsoft Q&A Platform. Below content might be helpful.\n\nGo to Portal -Azure Machine Learning (select the workspace) - Logs - The video  explains clearly first you have to set up Azure monitor. Select the categories and send to log Analytics.\n\n\n\n\n.\n\nOnce the logs are stored in log Analytics, go to logs again, select any existing query - Load to editor. \n\nYou can see workspace, JobName, EventType etc field to query. This is KQL -https:\/\/docs.microsoft.com\/en-us\/sharepoint\/dev\/general-development\/keyword-query-language-kql-syntax-reference\n\nSo, modify your query as per your requirement. Once finalized pin to the dashboard.\n\nHope this is helpful.\n\nThanks,\nPritee",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Request GPU Quota increase",
        "Question_creation_time":1615999382250,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/319120\/request-gpu-quota-increase.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"For my Machine Learning Experiments I need a dedicated VM with GPU. They are not available in my region (only low priority VMs). The system tells me to request a quota increase but if I go to the quota increase support page I can only select additional CPU's not a GPU for a dedicated VM. How do I request a GPU quota increase?",
        "Answers":[
            {
                "Answer_creation_time":"2021-03-18T00:57:11.537Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nSorry for the confuse description. Could you please try as below with \"Machine Learning Service\" and describe your need with the support engineer? I am also checking internally to see if there any direct way to increase the quota.\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":6.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Explaining a model in AzureML Studio",
        "Question_creation_time":1623017811457,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/423931\/explicacion-de-un-modelo-en-azureml-studio.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\nThere is an issue when I try to explain a Time Series model created with AzureML Studio, with the AutoML service.\n\nWhen the proccess finishes and the best model is automatically explained, I'd like to see a chart with the information of \"Predicted Values vs True Values\" but I can\u00b4t find anything similar. Then I realized that when I click on the explanation of the model, the next message is showed:\n\n\"Las estad\u00edsticas de rendimiento del modelo requieren que se proporcionen los resultados verdaderos adem\u00e1s de los previstos.\"\n\nTranslated: \"The performance statistics of the model require to provide true values in addition to the predicted ones.\"\n\nHow can I provide the model with the true values? I think it should be done automatically by the process, isn\u00b4t it? I mean, true values is part of the dataset, it is in fact the target column.\n\nFurthermore, I tried to create a classification model and I don\u00b4t have that problem there.\n\nAnyone could help me? Without a chart where I can compare true vs predicted values, the model doesn\u00b4t make sense.\n\n\n\n\nThank you very much in advance.",
        "Answers":[
            {
                "Answer_creation_time":"2021-06-08T03:19:11.683Z",
                "Answer_upvote_count":0,
                "Answer_body":"@FernndezCalvoAlberto-0353 Thanks, For forecasting experiment the predicted vs. true chart plots the relationship between the target feature (true\/actual values) and the model's predictions. Please follow the document for Predicted vs. true charts.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-understand-automated-ml#prerequisites",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Machine Learning Code",
        "Question_creation_time":1593978457140,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/43081\/machine-learning-code.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hey,\n\nI followed your Tutorial: Categorize iris flowers using k-means clustering with ML.NET to develop a porgram on drivers: whether a driver is good or bad.\nI would like that on the console it shows me the 2 groups that it has to form with their properties (for example prenon and last name). all the bad drivers then all the good. How can I do that?\n\nI look forward to your response\nThank you very much",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":37.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Unable to connect to adls gen2 from azure ml workspace",
        "Question_creation_time":1667403446370,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1072809\/unable-to-connect-to-adls-gen2-from-azure-ml-works.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-data-lake-storage"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\nI tried to create datastore in azure ml to connect to adls gen2. I have created app registration and used those client id and secret id. I also assigned the required permission [ storage blob data owner for the client id] in the resource group where the adls gen2 is located\n\nBut still I am not able to access the data. Please suggest me what further I have to do\n\nThanks",
        "Answers":[
            {
                "Answer_creation_time":"2022-11-03T12:55:34.46Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi @romungi-MSFT\n\nThanks for the reply. The issue is resolved now\n\nI have mentioned the path wrong and datastore also couldn't directly read my data\n\nThen I came to know that path name should starts after the file system name. After changing my path [ similar to source-data\/abc.csv] it worked fine\n\nThanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":19.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Creating a New linked service (Azure Machine Learning)",
        "Question_creation_time":1608828206490,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/210152\/creating-a-new-linked-service-azure-machine-learni.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am getting this below error\n\nRequest sent to Azure ML Service for operation 'validateWorkspace' failed with http status code 'Forbidden'. Error message from Azure ML Service: '{\"error\":{\"code\":\"AuthorizationFailed\",\"message\":\"The client 'f7029fe4-3c72-4258-9195-d4e8a64f7c62' with object id 'f7029fe4-3c72-4258-9195-d4e8a64f7c62' does not have authorization to perform action 'Microsoft.MachineLearningServices\/workspaces\/read' over scope '\/subscriptions\/f9f0926a-ab30-492e-8951-e0b88e6da187\/resourceGroups\/machinelearning_rg\/providers\/Microsoft.MachineLearningServices\/workspaces\/ml_workspace' or the scope is invalid. If access was recently granted, please refresh your credentials.\"}}'. Activity ID: 81e99656-f46a-4375-a7de-6b4fe925c5d5.",
        "Answers":[
            {
                "Answer_creation_time":"2020-12-28T07:06:23.097Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Bhakti-3239 Thanks for the question. Can you please add more details about the steps that you performed or doc that you are following. Also If you are using VNET, is it a part of the same VNet that the AML WS is linked to.\nCould you possibly open up this workspace then go to Access Control (IAM) on the left panel, and enter your name in the Check Access search bar and screenshot the result?\n\nIf you are with being on multiple tenants, The solution was to create service connections scoped to the specific machine learning workspace.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Random forests on Azure GPU VM using the SDK",
        "Question_creation_time":1595050125193,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/49008\/random-forests-on-azure-gpu-vm-using-the-sdk.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Can you please share any code examples for training random forests with GPU on Azure using libraries.\nI want to run on the multiple nodes.",
        "Answers":[
            {
                "Answer_creation_time":"2020-07-20T07:47:48.033Z",
                "Answer_upvote_count":0,
                "Answer_body":"@vautoml-0887 Thanks for the question. You can run LightGBM with boosting=random_forest, Please follow the below documentation:\nhttps:\/\/github.com\/microsoft\/LightGBM\/blob\/master\/docs\/Parameters.rst#boosting\n\n\n\n\nHere is a general tutorial on how to run LightGBM on GPU, You can run it on any Azure GPU VM:\nhttps:\/\/github.com\/microsoft\/LightGBM\/blob\/master\/docs\/GPU-Tutorial.rst\n\n\n\n\nIf you need to run it on multiple nodes, there is also a distributed spark implementation available at https:\/\/github.com\/Azure\/mmlspark.\n\n\n\n\nRandom Forests for the GPU using PyCUDA: https:\/\/pypi.org\/project\/cudatree\/",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":34.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Devops for Data Science Project",
        "Question_creation_time":1620038832133,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/380561\/devops-for-data-science-project.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-data-science-vm"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi Team,\nI have a use case wherein some machine learning models will be developed by a team. My team will be developing an application to consume that model. Also we have to do the CI Cd for that models , in such a way that every time the other team uploads a model in a blob storage , pipeline should be triggered and entire application should work the same way if new model performs better than previous one.\nThere is a documentation from microsoft but it is for VSTS.\n\nhttps:\/\/github.com\/Azure\/DevOps-For-AI-Apps\/blob\/jainr-refactor\/Tutorial.md\n\nThe steps mentioned here is exactly what I would like to do but I need the same tutorial for Azure Devops.Since I see many changes in VSTS and Devops portal.\n\n@ChrisPatterson-0930",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-03T12:31:53.03Z",
                "Answer_upvote_count":0,
                "Answer_body":"Devops \/ TFS is not currently supported here on QnA. The product group for Azure DevOps \/ TFS actively monitors questions over at\nhttps:\/\/developercommunity.visualstudio.com\/report?space=21&entry=problem\nhttps:\/\/developercommunity.visualstudio.com\/report?space=22&entry=problem\n\n--please don't forget to Accept as answer if the reply is helpful--",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Import Data Error",
        "Question_creation_time":1626779418893,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/482751\/import-data-error.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi all,\nI am a newbie and trying to practice data analysis with the Machine Learning Studio Classic & I use the published data set URL as the input to run the experiment and it did not work successfully as expected (check below for the error please)\n\n*Import Data Error\nError while downloading the file: Error 0039: Error while completing operation: System.Net.WebException: An exception occurred during a WebClient request. ---> Microsoft.Analytics.Exceptions.ErrorMapping+ModuleException: Error 0078: Http redirection not allowed . ( Error 0030 )\n\nAnyone can help, please? Appreciate!",
        "Answers":[
            {
                "Answer_creation_time":"2021-07-21T07:27:46.31Z",
                "Answer_upvote_count":0,
                "Answer_body":"@LinhBui-5340 Thanks for the question. Can you please add more details about the module that throws the error.\n\nWe would recommend using Designer(Drag and Drop) and follow the below document for Import data.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/import-data",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"machine learning conda env package(pyenchant)",
        "Question_creation_time":1643330999837,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/713217\/machine-learning-conda-env-packagepyenchant.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-container-instances"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I have pip install pyenchant, but It doesn't seem to be working.\n\n\n\n\n\n\n\n\n\nIs there any other way?\nhttps:\/\/stackoverflow.com\/questions\/21083059\/enchant-c-library-not-found-while-installing-pyenchant-using-pip-on-osx\nI looked it up but do not know where to put it\nThanks!",
        "Answers":[
            {
                "Answer_creation_time":"2022-01-28T08:12:23.967Z",
                "Answer_upvote_count":0,
                "Answer_body":"@YongchaoLiuNeusoftAmericaInc-6769 Based on the error it looks like you also need to ensure the enchant C library is available to use for the package. Based on the pip install page of pyenchant, the package will not work directly out of the box using pip.\n\nIn general, PyEnchant will not work out of the box after having been installed with pip. See the Installation section for more details.\n\nSince you are using Linux, this is the guidance on the installation page.\n\nThe quickest way is to install libenchant using the package manager of your current distribution. PyEnchant tries to be compatible with a large number of libenchant versions. If you find an incompatibility with your libenchant installation, feel free to open a bug report.\n\n\nTo detect the libenchant binaries, PyEnchant uses ctypes.util.find_library(), which requires ldconfig, gcc, objdump or ld to be installed. This is the case on most major distributions, however statically linked distributions (like Alpine Linux) might not bring along binutils by default.\n\n\n\n\nI believe you are using the ubuntu flavor of the azureml base image, In this case I think adding libenchant-2-dev as dependency in your YAML should work.\n\n -libenchant-2-dev=2.2.8\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":13.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How do I create a resource group when creating a workspace?",
        "Question_creation_time":1638162185497,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/643801\/how-do-i-create-a-resource-group-when-creating-a-w.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am going through the Azure AI training and need to create a workspace under machine learning. When it asks me to select a resource group there are no options. When I want to create a new resource group it says I dont have permissions under my subscription. What do I need to do?",
        "Answers":[
            {
                "Answer_creation_time":"2021-11-29T05:11:17.963Z",
                "Answer_upvote_count":1,
                "Answer_body":"I believe you need to be a subscription-level owner or contributor.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML online endpoint suddenly returns timeout",
        "Question_creation_time":1666021337190,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1051161\/azure-ml-online-endpoint-suddenly-returns-timeout.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi all,\n\nWe have deployed a managed online endpoint in Azure ML and first it works fine. However, after a few days, with the exact same request, the endpoint takes much longer to process the request and gives a timeout (the HTTP code returned is 504). We don't understand this behavior since we did not modify the endpoint and the metrics don't show a huge increase in cpu or memory usage. If we restart it then it works again for a few days until it doesn't work anymore. Has anyone faced the same issue? Could you solve it?\n\nThanks.",
        "Answers":[
            {
                "Answer_creation_time":"2022-10-29T14:10:52.19Z",
                "Answer_upvote_count":0,
                "Answer_body":"@AlbertGarrigaPorqueras-9657\nI came across the same error trying to invoke the model from public internet though, I retried invoking it in a VM that is in the same vnet\/subnet that Azure Machine Learning Workspace, Storage Account and Container Registry connect to by private endpoints, and it works.\nMy scenario is public inbound, and public egress network access is disabled.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Quantify conformity or compliance between different datasets",
        "Question_creation_time":1641225921097,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/681917\/quantify-conformity-or-compliance-between-differen.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-blob-storage",
            "azure-data-explorer"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,\nI have generated regression model using Azure design for a specific dataset of which I know the value to be predicted so I can evaluate the model performance and tune hyper-parameters. But now I would like to apply this trained model to a new and different dataset of which I do not know the values to be predicted during the regression so I cannot quantify the performance of the model for this testing dataset. However, for doing so I would like to see if the testing dataset is representative or similar to the trained dataset to evaluate if the prediction will be accurate. Is there a way in Azure to measure the conformity or compliance of a testing dataset to be similar or comparable to the training dataset?\nThank you!",
        "Answers":[
            {
                "Answer_creation_time":"2022-01-03T21:26:01.087Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi, with dataset monitor, you can detect data drift on datasets. Please review the documentation and let us know if it helps your scenario.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":16.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Pipeline does not run new data",
        "Question_creation_time":1633192729123,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/575144\/pipeline-does-not-run-new-data.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-data-factory",
            "azure-sql-database",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi -\nI created and published a pipeline that pulls data from an Azure SQL table, processes, models and then appends the output to an Azure SQL table. The Azure SQL table is updated with new data every day or two. In my script, I want to model on data that has been added two days before today with the following script:\n\nfrom datetime import date, timedelta\nyesterday = date.today() - timedelta(days=2)\nyesterday.strftime(\"%Y-%m-%d\")\nprint(yesterday)\n\nkeep data that is 2 days ago only\n\ndata_prior = data[data['MatterOpenDate'] == str(yesterday)]\nprint(data_prior.head())\n\nwhile True:\nanswer = data_prior.empty\nif answer == False:\nprint('Continue Process')\nbreak\nelif answer == True:\nprint('Empty dataset')\nrun.complete()\nexit()\n\nWhen I first ran my pipeline it worked great. I published this experiment, etc. and created a reoccurring schedule to run once a day every day.\n\nBUT the schedule continues to run the exact same data as the original run even when there is new data being uploaded. Why and what do I need to do for the script to run 'naturally' as written?\n\nThank you",
        "Answers":[
            {
                "Answer_creation_time":"2021-10-09T14:54:22.36Z",
                "Answer_upvote_count":0,
                "Answer_body":"I solved it, thank you.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":16.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Import ML Model from ADLS to Azure ML using Databricks",
        "Question_creation_time":1642414997297,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/697789\/import-ml-model-from-adls-to-azure-ml-using-databr.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-databricks"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi,\nI have stored some ml model in my ADLS and I want to register the model to Azure ML using databricks.\nTried to use the following codes to register my ml model but keep encountering an error that the path cannot be found.\n\nimport urllib.request\nfrom azureml.core.model import Model\n\nRegister a model\n\n\n\nmodel = Model.register(model_path = 'dbfs:\/mnt\/machinelearning\/classifier.joblib',\nmodel_name = \"pretrained-classifier\",\ndescription = \"Pretrained Classifier\",\nworkspace=ws)",
        "Answers":[
            {
                "Answer_creation_time":"2022-01-17T16:51:50.977Z",
                "Answer_upvote_count":1,
                "Answer_body":"@Yuzu-9670 Using the databricks file path for registering a model is not supported. When using the model.register() you need to download the model locally and then use the path of the model or the folder in which the model is present to register the same.\n\n\n\n\nmodel_path\n\n\nThe path on the local file system where the model assets are located. This can be a direct pointer to a single file or folder. If pointing to a folder, the child_paths parameter can be used to specify individual files to bundle together as the Model object, as opposed to using the entire contents of the folder.\n\nThis sample notebook should help you with using the method.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-01-18T06:21:46.863Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @romungi-MSFT,\nThank you for your comment!\nI have shifted my ml model to a repo folder and it works now.\nThank you!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":15.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to use custom environment defined in the custom environments tab in Azure Machine Learning Studio.",
        "Question_creation_time":1646779156963,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/764339\/how-to-use-custom-environment-defined-in-the-custo.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"In Azure Machine Learning Studio, in the Environments section's \"Custom environments\" tab, I defined a custom environment. I have done this once with a Conda yaml file, and once with a requirements.txt file, eg filling out this form as described here: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-environments-in-studio\n\nI can see that the environments have been created but I have no idea how to use them.\n\nI have tried using this code within an Azure ML Studio notebook, where the new environment I defined is called \"my_new_env\":\n\n from azureml.core import Workspace, Environment\n ws = Workspace.from_config()\n env = Environment.get(workspace=ws, name=\"my_new_env\")\n\n\n\nI also tried this within an Azure ML Studio notebook to see if I could define an environment without doing it in the environments menu.\n\n from azureml.core.environment import Environment\n my_new_env = Environment.from_conda_specification(name = \"myenv\", file_path = environment.yml)\n\n\n\nBoth execute without any warnings or errors, but I'm not sure they are running, or indeed what I have done.\n\nHaving run either of these two blocks of code, when I try to select a new environment in the Azure ML Studio notebook's drop down menu:\n\nThere is no evidence of my new environments.\n\nI'm new to Azure ML Studio. What I want to do is create a new Python virtual environment. Am I getting confused between virtual Python environments and some other more general type of environments? If I wanted to create my own stable Python virtual environment within Azure ML to use in notebooks that was not tied to a specific compute instance, how would I do it?\n\nThanks!",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-09T10:54:29.947Z",
                "Answer_upvote_count":1,
                "Answer_body":"@ml-3263 In the first two cases the environments created from portal or the yaml file are used to train your model or score your model when it is deployed as a endpoint.\nThese are re-usable environments that can even be created on local machine or compute to develop your training script and can be used used on Azure compute for large scale training or deployment.\n\nThe different types of environments are curated, user-managed and system-managed. The first two environments you created fall under the user and system managed categories, whereas curated environments are offered by azure and are available by default in every workspace.\n\nThese environments are not tied to any of the compute instance and you can use them with any type of compute for training or inference.\n\nThe last type of environment that you have listed with the screen shot is actually a virtual environment that you have to setup on your compute instance to use it as your kernel on your notebook. This however is tied to your compute instance and if you need to use the same setup on a different compute then you need to set it up again on a different instance. I have explained the setup on one of the previous threads, which can be helpful if you need one.\n\nTo summarize, if you are looking to create environments to train your models and infer then you will have to use the curated, user\/system-managed environments in your experiments.\nIf you are looking to just use the notebooks then you can setup a custom kernel or virtual environment to run an experiment locally.\n\nA great way to start learning about Azure ML through notebooks is to clone this repo on your ml.azure.com notebooks and follow the steps or tutorials to create and run experiments.\n\nOnce the repo is cloned from sample tab it will be available under files tab to be run on available compute and kernel.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Question on Azure Features and Limitations for Free and Paid Version",
        "Question_creation_time":1630749021297,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/539984\/question-on-azure-features-and-limitations-for-fre.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\nI am a student from University of Wollonggong Malaysia KDU Penang. I am planning to do a final year project that utilises machine learning to perform image and handwriting recognition using cloud computing. Therefore I would like to understand if there are related products that are provided on Azure. For the free tier and\/or Azure for student, what are the available product(s) that may satisfy my project requirements and what are its limitations. Similarly for the paid version, what additional features are provided and how are the pricings calculated?\n\nThank you",
        "Answers":[
            {
                "Answer_creation_time":"2021-09-04T10:37:07.907Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @TANFANGSHEENUOWMKDU-6628 !\n\n\n\n\nYou can refer to the below mentioned topics to know about the Limitations of Free , Pay as You Go and Student Package of Azure.\n\nStudents Offering :-\nhttps:\/\/azure.microsoft.com\/en-us\/free\/students\/\n\nAzure Pay as You Go :-\nhttps:\/\/azure.microsoft.com\/en-in\/pricing\/purchase-options\/pay-as-you-go\/\n\nAzure Free :-\nhttps:\/\/azure.microsoft.com\/en-in\/free\/\n\nAzure subscription and service limits, quotas, and constraints :-\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/azure-resource-manager\/management\/azure-subscription-service-limits\n\n\n\n\n\n\n\nIf the response is helpful, please click \"Accept Answer\" and upvote it.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"RuntimeError: Load model failed - Score machine learning models with PREDICT in serverless Apache Spark pools (Synapse & Azure Machine learning AML)",
        "Question_creation_time":1638981543063,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/656548\/what-is-aml-model-uri-predict-in-serverless-apache-1.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-synapse-analytics",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi all,\n\nI am following the steps on this tutorial:\nTutorial: Score machine learning models with PREDICT in serverless Apache Spark pools tutorial-score-model-predict-spark-pool\nI tried to used a model created with AutoML and another from designer and I am getting this error: RuntimeError: Load model failed\n\n\n\n\nI am using the model according to this: https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/631200\/what-is-aml-model-uri-predict-in-serverless-apache.html?childToView=637754#comment-637754\n\nThank you for your help.",
        "Answers":[
            {
                "Answer_creation_time":"2021-12-14T05:36:00.303Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @Anaid-6816,\n\nBefore running this script, update it with the URI for ADLS Gen2 data file along with model output return data type and ADLS\/AML URI for the model file.\n\n #Set model URI\n        #Set AML URI, if trained model is registered in AML\n           AML_MODEL_URI = \"<aml model uri>\" #In URI \":x\" signifies model version in AML. You can   choose which model version you want to run. If \":x\" is not provided then by default   latest version will be picked.\n    \n        #Set ADLS URI, if trained model is uploaded in ADLS\n           ADLS_MODEL_URI = \"abfss:\/\/<filesystemname>@<account name>.dfs.core.windows.net\/<model   mlflow folder path>\"\n\nModel URI from AML Workspace:\n\n DATA_FILE = \"abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/AML\/LengthOfStay_cooked_small.csv\"\n AML_MODEL_URI_SKLEARN = \"aml:\/\/mlflow_sklearn:1\" #Here \":1\" signifies model version in AML. We can choose which version we want to run. If \":1\" is not provided then by default latest version will be picked\n RETURN_TYPES = \"INT\"\n RUNTIME = \"mlflow\"\n\nModel URI uploaded to ADLS Gen2:\n\n DATA_FILE = \"abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/AML\/LengthOfStay_cooked_small.csv\"\n AML_MODEL_URI_SKLEARN = \"abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/linear_regression\/linear_regression\" #Here \":1\" signifies model version in AML. We can choose which version we want to run. If \":1\" is not provided then by default latest version will be picked\n RETURN_TYPES = \"INT\"\n RUNTIME = \"mlflow\"\n\n\n\nHope this will help. Please let us know if any further queries.\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":14.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Negative Samples in ML Assisted Image Labeling",
        "Question_creation_time":1658973322783,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/945298\/negative-samples-in-ml-assisted-image-labeling.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"We are evaluating the Azure ML Assisted Object detection labeling and I have some questions:\n1. How do I mark an image as a negative?\n2. How do I rename a label?\n3. How do I go back to a skipped image?\n4. When labeling if I discover that an image should not be in the dataset, how do I delete it from the dataset? The id of the image is no where to be found.\n5. For an autolabeled image, if I accidentally delete the bounding box, how do I undo this operation?\n6. Sometime the autolabeler creates small bounding boxes without any labels. Is this a bug?\n\nThank you",
        "Answers":[
            {
                "Answer_creation_time":"2022-07-28T09:37:46.757Z",
                "Answer_upvote_count":0,
                "Answer_body":"@PrashantSaraswat-9512 I think I can answer some of your questions from some of the projects I used for labeling.\n\nHow do I mark an image as a negative?\nUnlike the Azure custom vision labeling experience, there isn't a feature to mark a label as negative. I believe you can add another label and use it as a negative label and tag images.\n\nHow do I go back to a skipped image?\nGo to the Data tab of your project and select Review Labels tab from the side. Using the filters option on right hand side, set the Asset Type as \"Skipped\". This should pull any skipped images and you should be able to assign the required label and a button should be enabled to update label. The same applies for updating any labeled image or bounding box.\n\n\nHow do I rename a label?\nI think a label cannot be renamed after it is created. You can delete all labels and create a new set though. Just stop your project and select the Details-> Label Classes tab and click Add label option to see this screen.\n\n\nWhen labeling if I discover that an image should not be in the dataset, how do I delete it from the dataset? The id of the image is no where to be found.\nI think you can skip the image since the dataset is registered while creating a project there is no option to delete certain images after this action.\n\nFor an autolabeled image, if I accidentally delete the bounding box, how do I undo this operation?\nI have not used auto labeling before but the same step to update the skipped image or label should help you with this step.\n\nSometime the autolabeler creates small bounding boxes without any labels. Is this a bug?\nNot sure about this issue since I haven't come across it. You could report through support or through portal using the smiley image on the top right hand corner.\n\nI hope this helps!!\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML experiment run 70- driver log not printing after a few epoches",
        "Question_creation_time":1604880529150,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/155350\/azure-ml-experiment-run-70-driver-log-not-printing.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"I am training a deep learning artificial neural network model, usually the run submitted to the Experiment will show all the model running logs in 70-driver-log of 'outputs + logs' tab, but starting yesterday, the logs show only a few lines of logs and stop printing. I can still see the model is running since the 'metrics' tab is showing the loss and accuracy results.\n\nAnd another weird thing is that after model training finished, the model is not saved.",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"can we run a jupyter notebook using scriptrunconfig on target compute cluster ?",
        "Question_creation_time":1612203390137,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/254301\/can-we-run-a-jupyter-notebook-using-scriptrunconfi.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\nI understood that we can run a python script using scriptrunconfig.\n\nMy question is whether we can run jupyter notebook ?\nWhat other type of scripts can we run ?\n\nThank you.",
        "Answers":[
            {
                "Answer_creation_time":"2021-02-01T21:46:21.163Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nFor Azure Machine Learning Service, you can create a notebook with designed Computer Instance: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-run-jupyter-notebooks\n\nThis guidance shows how to run your Jupyter notebooks directly in your workspace in Azure Machine Learning studio. While you can launch Jupyter or JupyterLab, you can also edit and run your notebooks without leaving the workspace.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Autoscaling on Azure Machine Learning with R",
        "Question_creation_time":1612696726743,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/262211\/autoscaling-on-azure-machine-learning-with-r.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello, I have a two part question.\n\nI'm using Azure Machine Learning to train my model using Compute clusters. I'm using F64s v2 VM (64 vCPU and 128 GB of RAM). To be ablo to use all the 64 cores I used the doFuture package in R adding this code before tuning:\n\n registerDoFuture()\n n_cores <- parallel::detectCores()\n plan(\n     strategy = cluster,\n     workers = parallel::makeCluster(n_cores)\n )\n\n\n\nThis works on my Windows 10 machine so I though this would also work on the VM, is this correct?\n\n\n\n\nMy other question is related to the autoscaling of the Compute cluster. The cluster can scale up to three nodes, so I guess it could be 192 cores and 384 of RAM. When monitoring the cluster I was only using one node instead of all three, i.e. there was only one Busy nodes and two Unprovisioned nodes.\nIn the end the code failed with this error message:\nError in unserialize(node$con) :\nFailed to retrieve the value of ClusterFuture (doFuture-1) from cluster SOCKnode #1 (on \u2018localhost\u2019). The reason reported was \u2018error reading from connection\u2019\n\nwhich I think means I'm out of memory, is this correct? If so, why didn't the cluster scale up to three nodes?\n\n\n\n\nSee attached screenshot where only one node is busy but two unprovisioned.",
        "Answers":[
            {
                "Answer_creation_time":"2021-02-08T10:23:09.14Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Vidar-9341 I am not really expert at R but based on some threads i looked up online the call to detect cores should work on a virtual machine too but with detectCores(logical = TRUE) instead of the default FALSE.\n\nWith respect to the compute cluster where only one node got provisioned, is there any limit on quota for your subscription for this series that needs to be increased? This is usually visible on the subscription page on Usage+Quotas tab. You can filter the resources with provide Microsoft.Compute and check the appropriate VM offering limits and request an increase for that region. The request for increase is a support case where the option is available on this page on the top right corner to Request Increase.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-02-08T13:18:36.347Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @romungi-MSFT\n\nThank you so much for the answer. Regarding the quota limit, I have 200 cores limit and the VM I'm using is the following:\n\n\n\n\nso I should be able to use 3 nodes (64 * 3 = 192) if needed if I understand it correctly.\nThe two unprovisioned nodes are nodes not in use, right?",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Image build failed. For more details, check log file azureml-logs\/20_image_build_log.txt.",
        "Question_creation_time":1615209277803,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/303859\/image-build-failed-for-more-details-check-log-file.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\nWhen we wanted to get an explanation of a model, we received following error. \"Image build failed. For more details, check log file azureml-logs\/20_image_build_log.txt.\"\n\nYou can find the log file attached.\n\nI would appreciate if you could help us to resolve the issue. The model is very successful. It is important for us. Thus, we would like to understand it better with the explanation.\n\nThank you very much in advance for your interest and support!\n\nBest regards,\n\nCagatay Topcu75409-20-image-build-log.pdf",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Select column by name option is faded in edit metadata object in Azure ML studio",
        "Question_creation_time":1653833837490,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/868582\/select-column-by-name-option-is-faded-in-edit-meta.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"As shown in the image, by name option is faded. I have already ran the pipeline and it was successful. Then why not adding another step in pipeline shows the output of imported data ?",
        "Answers":[
            {
                "Answer_creation_time":"2022-05-30T13:11:43.96Z",
                "Answer_upvote_count":1,
                "Answer_body":"@TanwarGauravSingh-9735 I think this issue is related to this thread. Recent changes to UI have rendered this functionality unusable. The issue is reported to the product group for review, meanwhile you could use the preview option from Import Data to lookup the column names that need to be used in Select Columns from dataset. I hope this helps!!",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-11-16T16:17:53.917Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi, I'm also facing the same error still. Could you please help to select the By name",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-11-16T17:08:53.983Z",
                "Answer_upvote_count":1,
                "Answer_body":"Just enter the column name, its how i solved the issue",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":16.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"undefined symbol: cublasLtGetStatusString at Endpoint Deployment Error",
        "Question_creation_time":1669225633070,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1102061\/undefined-symbol-cublasltgetstatusstring-at-endpoi.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-batch",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi\n\nI am getting this error while deploying an end point. This was working fine for 3 months and I had to rebuild due to a minor change and started getting this error.\n\nFile \"\/azureml-envs\/tensorflow-2.7\/lib\/python3.8\/site-packages\/azureml_inference_server_http\/server\/user_script.py\", line 81, in load_script\nmain_module_spec.loader.exec_module(user_module)\nFile \"<frozen importlib.bootstrap_external>\", line 843, in exec_module\nFile \"<frozen importlib.bootstrap>\", line 219, in call_with_frames_removed\nFile \"\/var\/azureml-app\/221123171914-1667710269\/score.py\", line 6, in <module>\nimport ktrain\nFile \"\/azureml-envs\/tensorflow-2.7\/lib\/python3.8\/site-packages\/torch\/init.py\", line 191, in <module>\nload_global_deps()\nFile \"\/azureml-envs\/tensorflow-2.7\/lib\/python3.8\/site-packages\/torch\/init.py\", line 153, in load_global_deps\nctypes.CDLL(lib_path, mode=ctypes.RTLD_GLOBAL)\nFile \"\/azureml-envs\/tensorflow-2.7\/lib\/python3.8\/ctypes\/init.py\", line 373, in init_\nself._handle = _dlopen(self._name, mode)\nOSError: \/azureml-envs\/tensorflow-2.7\/lib\/python3.8\/site-packages\/torch\/lib\/..\/..\/nvidia\/cublas\/lib\/libcublas.so.11: undefined symbol: cublasLtGetStatusString, version libcublasLt.so.11\n\n\n\n\nThis is my environment:\n\nFROM mcr.microsoft.com\/azureml\/openmpi4.1.0-cuda11.2-cudnn8-ubuntu20.04:20220714.v1\n\nENV AZUREML_CONDA_ENVIRONMENT_PATH \/azureml-envs\/tensorflow-2.7\n\nCreate conda environment\n\nRUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\\npython=3.8 pip=20.2.4\n\nPrepend path to AzureML conda environment\n\nENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/bin:$PATH\n\nInstall pip dependencies\n\nRUN HOROVOD_WITH_TENSORFLOW=1 pip install 'matplotlib~=3.5.0' \\\n'psutil~=5.8.0' \\\n'tqdm~=4.62.0' \\\n'scipy~=1.7.0' \\\n'numpy~=1.21.0' \\\n'ipykernel~=6.0' \\\n# upper bound azure-core to address typing-extensions conflict\n'azure-core<1.23.0' \\\n'azureml-core==1.43.0' \\\n'azureml-defaults==1.43.0' \\\n'azureml-mlflow==1.43.0.post1' \\\n'azureml-telemetry==1.43.0' \\\n'azureml-inference-server-http==0.7.2' \\\n'pandas==1.4.1' \\\n'ktrain==0.30.0' \\\n'sentence-transformers==2.1.0' \\\n'tensorflow==2.7.0' \\\n'tokenizers==0.10.3' \\\n'protobuf~=3.19.1' \\\n'Flask==2.1.0' \\\n'transformers==4.10.3'\n\nThis is needed for mpi to locate libpython\n\nENV LD_LIBRARY_PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/lib:$LD_LIBRARY_PATH",
        "Answers":[
            {
                "Answer_creation_time":"2022-11-24T17:08:14.207Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi @romungi-MSFT\n\nI managed to solve it\n\nkept the container same as 20220729.v1\nand added 'torch==1.12.0' \\ 'torchvision==0.13.0' to the list. Didn't need the higher version as given in the link.\nThanks for that link\n\n\n\n\nfinal env file\n\nFROM mcr.microsoft.com\/azureml\/openmpi4.1.0-cuda11.2-cudnn8-ubuntu20.04:20220729.v1\n\nENV AZUREML_CONDA_ENVIRONMENT_PATH \/azureml-envs\/tensorflow-2.7\n\nCreate conda environment\n\nRUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\\npython=3.8 pip=20.2.4\n\nPrepend path to AzureML conda environment\n\nENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/bin:$PATH\n\nInstall pip dependencies\n\nRUN HOROVOD_WITH_TENSORFLOW=1 pip install 'matplotlib~=3.5.0' \\\n'psutil~=5.8.0' \\\n'tqdm~=4.62.0' \\\n'scipy~=1.7.0' \\\n'numpy~=1.21.0' \\\n'ipykernel~=6.0' \\\n# upper bound azure-core to address typing-extensions conflict\n'azure-core<1.23.0' \\\n'azureml-core==1.43.0' \\\n'azureml-defaults==1.43.0' \\\n'azureml-mlflow==1.43.0.post1' \\\n'azureml-telemetry==1.43.0' \\\n'azureml-inference-server-http==0.7.2' \\\n'pandas==1.4.1' \\\n'ktrain==0.30.0' \\\n'sentence-transformers==2.1.0' \\\n'tensorflow==2.7.0' \\\n'tokenizers==0.10.3' \\\n'protobuf~=3.19.1' \\\n'Flask==2.1.0' \\\n'transformers==4.10.3' \\\n'torch==1.12.0' \\\n'torchvision==0.13.0'\n\nThis is needed for mpi to locate libpython\n\nENV LD_LIBRARY_PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/lib:$LD_LIBRARY_PATH",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":36.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to import Microsoft.RelInfra.Common.Exception so that it could be properly handled?",
        "Question_creation_time":1643997368443,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/723386\/how-to-import-microsoftrelinfracommonexception-so.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am working on creating a Pipeline Endpoint and want to handle the exception if incorrect Pipeline endpoint name is passed to the constructor:\n\nPipelineEndpoint.get(workspace, name='xyz')\n\nIn this case, I am seeing a \"Microsoft.RelInfra.Common.Exceptions.ErrorResponseException:PipelineEndpoint name xyz not found in workspace\".\n\nFrom where to import this exception class??\n\nPlease advise.",
        "Answers":[
            {
                "Answer_creation_time":"2022-02-05T04:24:34.057Z",
                "Answer_upvote_count":2,
                "Answer_body":"@ShivapriyaKatta-8600\n\nI think the first thing is make sure your endpoint_pipeline is set up correctly.\n\nYou can try to return all active pipeline to see if the pipeline you want to call is in the list:\n\n endpoint_list = PipelineEndpoint.list(workspace=ws, active_only=True)\n endpoint_list\n\n\n\nI also attach the guidance of how to deploy a pipeline here for your reference:\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-setup-versioned-pipeline-endpoints.ipynb\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"I have created an ML model and retrained it manually in the designer. While updating the web service, its asking for a score.py file. How do I prepare the score.py file for a model that I have created through designer?",
        "Question_creation_time":1613025843247,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/268585\/i-have-created-an-ml-model-and-retrained-it-manual.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I have trained a model , deployed and retrained completely through azure designer pipeline. Now , I need to update the existing web service with the new one after retraining. Its asking for a score.py file in the inference_config (python sdk). How do I prepare a score.py file for an existing model? Any help is appreciated. Thanks a lot :)",
        "Answers":[
            {
                "Answer_creation_time":"2021-02-11T17:30:10.71Z",
                "Answer_upvote_count":0,
                "Answer_body":"Duplicate, please review response provided here.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Pickle Load- File Not Found when deploying using Azure ML Studio",
        "Question_creation_time":1653375158970,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/861537\/pickle-load-file-not-found-when-deploying-using-az.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I have saved a classifier model with pickle using the following code-\n\n import pickle\n with open('skm.pickle', 'wb') as fid:\n     pickle.dump(clf, fid) \n\n\n\nNow, during deployment, when I try to load this same model, it is giving an error-\n\n Error:\n {\n   \"code\": \"AciDeploymentFailed\",\n   \"statusCode\": 400,\n   \"message\": \"Aci Deployment failed with exception: Error in entry script, FileNotFoundError: [Errno 2] No such file or directory: '.\/skm.pickle', please run print(service.get_logs()) to get details.\",\n   \"details\": [\n     {\n       \"code\": \"CrashLoopBackOff\",\n       \"message\": \"Error in entry script, FileNotFoundError: [Errno 2] No such file or directory: '.\/skm.pickle', please run print(service.get_logs()) to get details.\"\n     }\n   ]\n }\n\n\n\nThis is the score.py file where I am loading the pickle model and the same file is called during deployment. Also note that, all these files (code, pickle file and related files) are in the same directory.\n\n %%writefile sklearnscore.py\n    \n import json\n import pandas as pd\n from sklearn.preprocessing import MinMaxScaler\n from sklearn.ensemble import RandomForestClassifier\n import pickle\n    \n # Initialize the deployment environment\n def init():\n     # read in the model file\n     from sklearn.pipeline import Pipeline\n     global obj\n     with open('.\/skm.pickle', 'rb') as f:\n         obj = pickle.load(f)\n\n\n\n\nI am registering the model using- model = Model.register(ws, model_name=\"utility15\", model_path=\".\/skm.pickle\")\n\nAnd the deployment code is-\n\n service_name = 'my-custom-env-service-4'\n sklearn_env = Environment.from_conda_specification(name='sklearn-env', file_path='Sklearn.yaml')\n    \n inference_config = InferenceConfig(entry_script='sklearnscore.py', environment=sklearn_env)\n    \n aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=4,tags={'Createdby':'xyz'})\n    \n service = Model.deploy(workspace=ws,\n                         name=service_name,\n                         models=[model],\n                         inference_config=inference_config,\n                         deployment_config=aci_config,\n                         overwrite=True)\n service.wait_for_deployment(show_output=True)\n\n\n\nWhen this script is run, it calls the score.py file and the file not found error comes up for pickle file. I have even tried loading the model without the .\/ thing, but the same error comes up.",
        "Answers":[
            {
                "Answer_creation_time":"2022-05-25T09:13:41.897Z",
                "Answer_upvote_count":0,
                "Answer_body":"@AmberBhanarkar-3639 Thanks for the question. Can you please share the sample that you are trying.\n\nTake a look at this notebook for one way to do this, another way would be to create a yaml file with all of the dependencies:\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/explain-model\/azure-integration\/remote-explanation\/explain-model-on-amlcompute.ipynb\n\nPlease run print(service.get_logs()) to get details.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Stopping ML Server Engine",
        "Question_creation_time":1612666795983,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/262003\/stopping-ml-server-engine.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I'm running the Microsoft Machine Learning Server on my computer. Right now, there are no tasks\/nodes running, and task manager is showing multiple instances of the \"Microsoft ML Server Engine\" that are using nearly all my computer resources. I've gone into the administration utility, but can't seem to find a way of stopping this, short of brute \"End Task\" within TM.",
        "Answers":[
            {
                "Answer_creation_time":"2021-02-07T04:05:59.56Z",
                "Answer_upvote_count":1,
                "Answer_body":"HI @ThomasGraham-8689\n\nIn Machine Learning Server 9.3 and later, you can use admin extension of the Azure Command-Line Interface (Azure CLI) to set up and manage your configuration, including stopping and starting services.\nMonitor, stop, and start web & compute nodes\n\nIf the Answer is helpful, please click Accept Answer and up-vote, this can be beneficial to other community members.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How can I utilize multiple cores on Azure ML Studio VM's?",
        "Question_creation_time":1603703811737,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/139002\/how-can-i-utilize-multiple-cores-on-azure-ml-studi.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi. I have a python script which can be run either sequentially or in parallel (using concurrent.futures). On my local machine using the parallel option results in a considerably faster execution (nearly linear speed up). Running the same script inside an Experiment on Azure ML Studio I was not able to observe any speedup from the parallel version. At first I thought adding the following line conda_env.docker.arguments = [&#34;--cpuset-cpus=4&#34;] would help, but still the same. Therfore my question is, how can I enable the docker container to leverage multiple cores of the vm-instance? Kind Regard Kai",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-04T08:09:05.837Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello Kai,\n\nYou can easily change your VM with different cores according to your need. Please see following pic and let me know if you have any question.\n\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-11-04T08:13:06.12Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello Yutonn,\n\nI know how to change the #cores of my VM. The problem is, that these cores are not utilized.\nI guess it's somehow related to this issue https:\/\/stackoverflow.com\/questions\/15639779\/why-does-multiprocessing-use-only-a-single-core-after-i-import-numpy\n\nRegards\nKai",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to tain a ML model with CSV filles and not dataframes?",
        "Question_creation_time":1641828520987,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/689654\/how-to-tain-a-ml-model-with-csv-filles-and-not-dat.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-blob-storage",
            "azure-data-explorer"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,\n\nI have a dataset composed of different csv files (a lot of them) with the same metadata that I have added to the Azure blob storage and now I would like to run a regression ML model with this data in Azure ML, however I want to train the model based on the csv files and not on each line of the files (not on each dataframe). How can I do this? Is it possible in Azure ML design?\n\nThank you!",
        "Answers":[
            {
                "Answer_creation_time":"2022-01-10T22:42:30.247Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, you can create dataset from a datastore. Please refer to the following document for more details on training a regression model in designer. Let us know if you have additional questions. Thanks.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":16.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Something Wrong?",
        "Question_creation_time":1593090172523,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/40031\/something-wrong.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Isn&#39;t me only or...?[welcome-to-azure][1]![10701-%E6%89%B9%E6%B3%A8-2020-06-25-205624.png][2]\n\n\n\n\n\n\n[1]: https:\/\/docs.microsoft.com\/zh-cn\/learn\/modules\/welcome-to-azure\/\n\n[2]: \/answers\/storage\/attachments\/10701-\u6279\u6ce8-2020-06-25-205624.png",
        "Answers":[
            {
                "Answer_creation_time":"2020-06-30T17:36:13.787Z",
                "Answer_upvote_count":0,
                "Answer_body":"@egov Hi, could you please provide more information to us about what issue you are facing? So basically you can use this introduction module to learn Azure.\n\nJust easy click \"\u5f00\u59cb\" so you can start at the beginning. You can also jump to any module you want. Let us know more if you have any issue.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Error Running Azure ML Training Script",
        "Question_creation_time":1651574593590,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/834730\/error-running-azure-ml-training-script.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,\n\nI am receiving the following error message when running an experiment script in Azure Machine Learning Studio\n\n\"AADSTS70016: OAuth 2.0 device flow error. Authorization is pending. Continue polling\"\n\nMicrosoft have stated;\n\n\"This is not an error scenario, but is handled like one by Azure AD to handle certain authentication flows. This is not an indication that anything went wrong.\"\n\nHowever my experiment run has failed as can ben seen below;\n\n\n\n\nCould someone please advise how to correct this error.. thank you",
        "Answers":[
            {
                "Answer_creation_time":"2022-05-04T09:47:03.277Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @YutongTie-MSFT - log file attached.198812-70-driver-log.txt\n\n\n\n\n\nThank you.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-04T19:25:14.49Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi I'm having the exactly same bug when i'm trying to launch an experiment from runscript in Azure Ml Studio.\n\nErrorResponse\n{\n\"error\": {\n\"code\": \"UserError\",\n\"message\": \"AADSTS70016: OAuth 2.0 device flow error. Authorization is pending. Continue polling. }\n}",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-07T11:19:28.317Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello\n\nSame here, I have the same Error\n\nIs there any information about this?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure machine learning cannot evaluate model",
        "Question_creation_time":1650117583373,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/814652\/azure-machine-learning-cannot-evaluate-model.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"I create a trained model in Azure machine learning, when I use it to predict a new set of data, the evaluate model cannot show the result, it's all empty. How can I solve the problem?",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Is there a way to access compute quotas with the Azure CLI or Python SDK?",
        "Question_creation_time":1597248641713,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/65511\/is-there-a-way-to-access-compute-quotas-with-the-a.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I want to tabulate the compute quotas for each Azure ML workspace, in each Azure location, for my organization's Azure subscription. Although it is possible to look at the quotas manually through the Azure Portal (link), I have not found a way to do this with the Azure CLI or Python SDK for Azure. Since there are many resource groups and AML workspaces for different teams under my Azure subscription, it would be much more efficient to do this programmatically rather than manually through the portal. Is this even possible, and if so how can it be done?",
        "Answers":[
            {
                "Answer_creation_time":"2020-08-13T15:31:33.373Z",
                "Answer_upvote_count":0,
                "Answer_body":"Yes, we have a REST API that returns quota usage by subscription, workspace, and cluster. Please check out this example call. Let me know if this answers your question. Thanks.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":1.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Warning while cretaing Dataset from Datastore",
        "Question_creation_time":1664348355043,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1026239\/warning-while-cretaing-dataset-from-datastore.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"While creating a dataset using a datastore I see the following\n\"Warning: The selected datastore's SAS is insufficient to create this dataset.\nReading the dataset requires Read permission for Objects as well as Containers if the path is a folder or glob.\"\n\nI've ensured that the necessary permissions are assigned to the managed resources as well as the users. But still I see this warning. Will this create problem while accessing data from blob storage?",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to connect to KeyVault to azureml real time endpoint using managed identity?",
        "Question_creation_time":1660172274087,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/963249\/how-to-connect-to-keyvault-to-azureml-real-time-en.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-key-vault",
            "azure-managed-identity"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am trying to connect keyvault to an insanely simple app with score file as follows:\n\n def init():\n     pass\n def run(raw_data):\n     KVUri=\"<<AN ACTUAL KEYVAULT URI>>\"\n     credential = DefaultAzureCredential()\n     client = SecretClient(vault_url=KVUri, credential=credential)\n     retrieved_secret = client.get_secret(\"test-secret\")\n     return  [retrieved_secret]\n\n\n\nI deploy using python SDK as follows:\n\n # create an online endpoint\n endpoint = ManagedOnlineEndpoint(\n     name=local_endpoint_name,\n     description=\"this is a sample online endpoint\",\n     auth_mode=\"key\",\n )\n ml_client.begin_create_or_update(endpoint)\n model = Model(path=\"..\/model\/dummy.txt\")\n env = Environment(\n     conda_file=\".\/conda.yaml\",\n     image=\"mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04:20210727.v1\",\n )\n    \n blue_deployment = ManagedOnlineDeployment(\n     name=\"blue\",\n     endpoint_name=local_endpoint_name,\n     model=model,\n     environment=env,\n     code_configuration=CodeConfiguration(\n         code=\".\", scoring_script=\"app.py\"\n     ),\n     instance_type=\"Standard_F2s_v2\",\n     instance_count=1,\n )\n ml_client.begin_create_or_update(blue_deployment)\n\n\n\nAfter the deployment I add System assigned managed identity to azure key vault (Access Controls IAM > grant access to this resource). I assign access to instance of online endpoint, but when testing I get:\n\nFailed to test real-time endpoint\nDefaultAzureCredential failed to retrieve a token from the included credentials. Attempted credentials: EnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured. Visit https:\/\/aka.ms\/azsdk\/python\/identity\/environmentcredential\/troubleshoot to troubleshoot.this issue. ManagedIdentityCredential: request() got an unexpected keyword argument 'tenant_id' To mitigate this issue, please refer to the troubleshooting guidelines here at https:\/\/aka.ms\/azsdk\/python\/identity\/defaultazurecredential\/troubleshoot.\n\nDo you know what is the source of an error? How should I do it correctly?",
        "Answers":[
            {
                "Answer_creation_time":"2022-08-10T23:45:33.143Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @MateuszMacias-3397\n\nAs mentioned in your error : Attempted credentials: EnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\n\nYou are missing to mention some configuration in your python code\nNo where In your code its mention to retrieve the secret from which client , Mention the client ID or which tenant. This image from the same URL you mentioned.\n\nIm not from Developers side but thought if i could help.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":20.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How can I transfer a csv file on an Azure Machine Learning compute instance directory back to the Datastore?",
        "Question_creation_time":1632158641093,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/559227\/how-can-i-transfer-a-csv-file-on-an-azure-machine.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I posted a similar question last week and didn't get a response to that yet so I'm posting another one now.\n\nThe code below is what I use to pull data into the compute instance from the Datastore. I transfer data from a Datastore to the compute instance and then save the data to my directory as a csv. The data originates from a SCOPE script and is transferred from Cosmos to the Datastore via Azure Data Factory.\n\nOnce the data is in the directory as a csv, I then utilize R to pull in the data into an RStudio session and then I run various tasks that create new data sets. I also save these new data sets to the compute instance directory as csv's. These new data sets are the ones I'd like to push back to the Datastore so they can be transferred elsewhere via Azure Data Factory and later consumed by a PowerBI app we're looking to create.\n\nI tried using Designer and it ran for 4 days without completing before I cancelled the job and started looking for an alternative route. I don't know if it would have completed or if it ran into memory issues and simply didn't fail. When I pull data into the compute instance from the datastore it takes less than a few minutes to complete so I'm not sure why it would take Designer multiple days to attempt to do the reverse operation.\n\nI've looked through a bunch of documentation and I am not able to find anything that tells us how we can transfer data from the compute instance back to the Datastore aside from Designer which is too slow or unable to handle.\n\nThis task seems like one that should be obvious for use and a major selling point of Azure Machine Learning so I'm a bit dumbfounded to see that this is a challenge figuring out how to do and that the documentation doesn't clearly show users how to achieve this task, assuming it's even possible. If it's not possible then I need to figure out a whole new system to use to get my work done. If it's not possible, the Azure Machine Learning team should enable this functionality as soon as possible.\n\n# Azure management\nfrom azureml.core import Workspace, Dataset\n# MetaData\nsubscription_id = '09b5fdb3-165d-4e2b-8ca0-34f998d176d5'\nresource_group = 'xCloudData'\nworkspace_name = 'xCloudML'\n# Create workspace \nworkspace = Workspace(subscription_id, resource_group, workspace_name)\n# 1. Retention_Engagement_CombinedData\ndataset = Dataset.get_by_name(workspace, name='retention-engagement-combineddata')\n# Save data to file\ndf = dataset.to_pandas_dataframe()\ndf.to_csv('\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/v-aantico1\/code\/RetentionEngagement_CombinedData.csv')\n# 2. TitleNameJoin\ndataset = Dataset.get_by_name(workspace, name='TitleForJoiningInR')\n# Save data to file\ndf = dataset.to_pandas_dataframe()\ndf.to_csv('\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/v-aantico1\/code\/TitleNameJoin.csv')",
        "Answers":[
            {
                "Answer_creation_time":"2021-09-21T08:00:14.827Z",
                "Answer_upvote_count":1,
                "Answer_body":"@AdrianAnticoTEKsystemsInc-1526 Have you tried the following to upload data to your datastore?\n\n from azureml.core import Workspace\n ws = Workspace.from_config()\n datastore = ws.get_default_datastore()\n    \n datastore.upload(src_dir='.\/data',\n                  target_path='datasets\/',\n                  overwrite=True)\n\n\n\nI think datastore.upload() should work for you to upload the required datafiles from your compute instance to datastore.",
                "Answer_comment_count":4,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure AutoML time series model returns strange forecast",
        "Question_creation_time":1604413410307,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/149896\/azure-automl-time-series-model-returns-strange-for.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"I used Azure AutoML to train a time series forecasting model and selected the forecasting horizon to be 6. Each of our data row is one month, so we want to see the forecast for the following 6 months.\n\nHowever, when feeding 2 rows of data to the model, it returns 2 figures, and when feeding 8 rows of data, it returns 8 figures. We expect that as we select the forecasting horizon to be 6, regardless of how many rows of data being fed into the model, it should returns 6 figures.\n\nCould somebody explain why this happens and how to correct it? Thank you.",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-04T05:17:37.92Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nI would suggest you double check how you are defining time_column_name. Thanks.\n\nAttached the definition of this class for your reference,\n\n fulldata: pandas.DataFrame           a time series dataset. Needs to contain X and y.\n time_column_name: string             which column (must be in fulldata) is the time axis\n target_column_name: string           which column (must be in fulldata) is to be forecast\n forecast_origin: datetime type       the last time we (pretend to) have target values \n horizon: timedelta                   how far forward, in time units (not periods)\n lookback: timedelta                  how far back does the model look?\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-11-26T03:31:04.907Z",
                "Answer_upvote_count":0,
                "Answer_body":"I think it will forecast the number of rows you feed into the forecast function (feed datetime with empty column for output). So the behaviour you see is expected.\n\nIdeally you feed in no more than your training forecast horizon. If you feed more it wil become increasingly inaccurate as it starts to use the previously forecast value as input for the \"over the horizon\" forecasts.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Car damage detection using azure machine learning or azure artificial intelligence",
        "Question_creation_time":1643020905263,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/707265\/car-damage-detection-using-azure-machine-learning.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-computer-vision"
        ],
        "Question_upvote_count":2.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi. Can someone please guide me how to detect damages in the car from car images using Azure Machine Learning or Azure AI?\n\nI'm planning to use image classification computer vision solution as a first step to classify if car is damaged or not, then as a second step use object detection to identify which parts of the car are damaged.\n\nI'm a beginner in AI and ML. Am I going with the correct approach or is there any other way to solve my problem?",
        "Answers":[
            {
                "Answer_creation_time":"2022-01-25T03:33:41.933Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi, I think you're heading in the right direction. Since this is a classification problem, you'd want to use Azure ML (computer vision) to classify the images. To identify which parts have been damaged, Custom Vision's object detector seems to be a viable solution. Please refer to the documentation links provided.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How is AML's average GpuUtilization metric computed?",
        "Question_creation_time":1598450649953,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/77678\/how-is-aml39s-gpuutilization-metric-computed.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"How is the \"GpuUtilization\" metric computed for an AML workspace? What are the inputs and what is the equation used to compute GpuUtilization?\n\nThe \"metrics\" tab in the AML web portal shows a chart of the GpuUtilization over a specified time period, along with the average GpuUtilization for that time period. However, I have found that average GpuUtilization does not appear to accurately reflect the data shown in the chart for some of my organization's AML workspaces.\n\nFor example, the following screenshot shows the GpuUtilization for July 1-31, with the average GpuUtilization reported as 54.06. This is clearly much higher than what is shown in the chart. When I download the data from the chart (Share -> Download to Excel), I compute the average GpuUtilization to be ~11% in Excel. Why is there such a discrepancy?\n\nI have found similar discrepancies for other AML workspaces as well. However, the average GpuUtilization appears to be more accurate for the August 1-25 time period than it is for July 1-31. I wish to better understand how AML computes the average GpuUtilization over a time period so we can accurately account for my organization's AML GPU usage on a per-workspace basis.",
        "Answers":[
            {
                "Answer_creation_time":"2020-08-27T14:49:02.87Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for reaching out. GpuUtilization shows how much percentage of GPU was utilized for a given node during a run\/job. One node can have one or more GPUs. This metric is published per GPU per node. You can apply filters based on node to understand the computation better. Let me know if that helps or if you need further assistance. Thanks.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":3.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"What's the best way to preserve Azure ML workspace so that it can be restored",
        "Question_creation_time":1669442139003,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1105130\/what39s-the-best-way-to-preserve-azure-ml-workspac.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"What's the best way to preserve Azure ML workspace so that it can be restored at a later point? I was hoping to find some automatic way to take a snapshot of artifacts & code and dump it into Azure storage, but haven't been able to find anything relevant in the online documentation.",
        "Answers":[
            {
                "Answer_creation_time":"2022-11-28T00:46:02.44Z",
                "Answer_upvote_count":0,
                "Answer_body":"@VaraPrasad-1740 Thanks for the question. I would recommend you can have a git repository that backs your project. For some details about this approach you can check https:\/\/santiagof.medium.com\/structure-your-machine-learning-project-source-code-like-a-pro-44815cac8652",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Internal server error while connecting to jupyter lab instance",
        "Question_creation_time":1610979567287,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/234805\/internal-server-error-while-connecting-to-jupyter.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"I have created an ML-compute instance from scratch, nothing particularly installed.\nBut when I try to connect to Jupiter Lab directly through the URL provided by the user interface I get the following error :\n\n{\n\"error\": {\n\"code\": \"ServiceError\",\n\"severity\": null,\n\"message\": \"InternalServerError\",\n\"messageFormat\": null,\n\"messageParameters\": null,\n\"referenceCode\": null,\n\"detailsUri\": null,\n\"target\": null,\n\"details\": [],\n\"innerError\": null,\n\"debugInfo\": null\n},\n\"correlation\": {\n\"operation\": \"716efa38ccc70341b4b5b93bc16e441b\",\n\"request\": \"170d9ccac55c9d42\"\n},\n\"environment\": \"westeurope\",\n\"location\": \"westeurope\",\n\"time\": \"2021-01-18T14:00:19.9517739+00:00\",\n\"componentName\": \"notebook-instance-proxy\"\n}\n\nI also tried to connect through SSH to this compute instance, I notice that there is a conflict about the version of the pillow package.\nThen I've fixed the version conflict but the error still persists even after rebooting the machine.\nAfter that, I've connected to the machine through SSH tunnelling and I could start the Jupiter lab instance (even though the error still persist when connecting through the Azure ML Interface).\n\nCould you please investigate the connection issue through the user interface please?\nThanks in advance",
        "Answers":[
            {
                "Answer_creation_time":"2021-01-19T14:23:54.503Z",
                "Answer_upvote_count":1,
                "Answer_body":"@ramr-msft, I was able to launch a Jupyter Lab instance on Google Chrome.\nBut it's still not working on Safari, there must be a compatibility issue.\nMy safari version is 14.0.2\n\nTicket can be close.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-02-01T06:11:39.15Z",
                "Answer_upvote_count":0,
                "Answer_body":"@AbderrahimMEHDAOUI-4926 Thanks for the details. Can you please try turning off \"Deny 3rd party cookies\" and it works great for me with this config. We have forwarded to the product team to check for the fix. You can also raise a user voice request here so the community can vote and provide their feedback, the product team then checks this feedback and implements the same in future releases.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":4.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"how to update azure ml model from adf?",
        "Question_creation_time":1619624088887,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/375702\/how-to-update-azure-ml-model-from-adf.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-data-factory",
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi, I manage to run a azure ml trainning pipeline in adf. Then I can see that I can create\/update a batch inference pipeline from the Designer. But can I update the batch inference pipeline from adf?\n\nthanks",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-28T17:13:15.207Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @javier-8889,\n\nThanks for using Microsoft Q&A !!\n\nUnfortunately this is not supported using Azure Data Factory and you can only update the scoring web service using Azure Machine Learning Studio (classic) update resource activity Can you please provide your scenario\/use case in details so that I can check internally. I also suggest you to please post this as a feedback at ADDF UserVoice. This will allow the community to upvote and for the product team to include into their plans\n\nPlease do not forget to \"Accept the answer\" wherever the information provided helps you to help others in the community.\n\nThanks\nSaurabh",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Machine Learning Studio Designer (preview) - Selective module execution",
        "Question_creation_time":1593464903017,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/41135\/azure-machine-learning-studio-designer-preview-sel.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I find that I am often inserting or modifying one module in a flow, and needing to edit several later items in the DAG,\n\nBut since the prior module is now invalidated, It asks me to SUBMIT and run the full experiment, so that I can do things like select columns.\n\nIs there not a way to disable modules? or selectively execute just a subset of modules?\n\nI am using the preview versions of the ML studio.",
        "Answers":[
            {
                "Answer_creation_time":"2020-07-01T11:32:32.75Z",
                "Answer_upvote_count":0,
                "Answer_body":"@StevenGutfreund-9039 Thanks for the feedback.Currently We don't support selected node run yet in Designer. BTW pipeline has the capability to use previous run result if the input data hasn't changed. You can confirm whether a step is reused or not from the recycle icon as shown below:\n\n\n\n\nPlease share your feedback from the ml.azure.com portal to prioritize this feature.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":2.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Does AutoML support optimizing convolutional neural network over the number of layers and pool layer parameters?",
        "Question_creation_time":1607093437353,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/186789\/does-automl-support-optimizing-convolutional-neura.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Does AutoML support optimizing convolutional neural network over the number of layers and pool layer parameters?",
        "Answers":[
            {
                "Answer_creation_time":"2020-12-04T21:28:34.597Z",
                "Answer_upvote_count":0,
                "Answer_body":"AutoML doesn't currently support CNNs publicly, it's on our roadmap and it will come with optimizations across different parameters, so stay tuned. Hope this helps.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Cannot use ```%matplotlib qt``` in Jupyter notebook in Azure Machine Learning",
        "Question_creation_time":1626886810050,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/484527\/cannot-use-matplotlib-qt-in-jupyter-notebook-in-az-1.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am asking this question again, because I haven't got any update for my previous question, even though I have made new comments 20 days ago to describe my issue. The question can be found here.\n\nTo summarize:\nAfter restarting the kernel, I run the following suggested solution\nimport matplotlib\nmatplotlib.use('Qt5Agg')\nimport matplotlib.pyplot as plt\n, and still got the same error:\nImportError: Cannot load backend 'Qt5Agg' which requires the 'qt5' interactive framework, as 'headless' is currently running\n\nCan someone please help me to solve this problem? It is really important for me to use interactive plots.",
        "Answers":[
            {
                "Answer_creation_time":"2021-07-26T17:18:37.453Z",
                "Answer_upvote_count":0,
                "Answer_body":"We redirected this issue to support team. @Lu-3578 Please let me know if you have any block during that process.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Best practice for migration",
        "Question_creation_time":1656613684597,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/909885\/best-practice-for-migration.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Anyone has been migrated to new studio? Please share experience. I am confused about the migration, how should I copy paste my model from studio",
        "Answers":[
            {
                "Answer_creation_time":"2022-06-30T22:44:31.167Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @Alexandre-2525\n\nThanks for reaching out to us, I think you are talking about move from Studio classc to Designer, please refer to below document:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview\n\nBasically yes for your other thread, you need to rebuild the whole pipeline since we can not copy - paste your orignal structure to Designer.\n\nI am sorry for the inconveniences since the new studio has a disfferent structure to make this migration not that easy. Please let me know if you have any question during this process, we will provide help.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML Data Labeling images removed from dataset still being display when \"data label\"",
        "Question_creation_time":1648547078293,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/791637\/azure-ml-data-labeling-images-removed-from-dataset.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,\n\nI created a labeling project by creating a new dataset that imports files from local. Afterwards, some images previously uploaded need to be replaced by a new images (we decided to change some details of the display).\n\nHowever, when creating a new version of the dataset with the updated images (this works well) and refreshing the project, the images display when \"label data\" remain unchanged (also the on-demand incremental refresh date doesnt change, I assume because the images have the same name so project doesnt recognize something has changed.)\n\nI tried deleting images from the dataset thinking about reloading them, but the project also doesnt stop showing deleted images.\n\nIs there a way I can get my new image versions correctly displayed without having to create a new project?\n\nThanks!",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-29T15:48:21.383Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Maite-3025 Thanks for the question. Please details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Is it possible to use pre-defined designer modules when building pipelines using python-sdk?",
        "Question_creation_time":1636017242333,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/615328\/is-it-possible-to-use-pre-defined-designer-modules.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Hey, I am trying to build ML pipelines using the python-sdk. I am wondering if I can use those pre-defined modules from Designer when building pipelines using the python-sdk?",
        "Answers":[
            {
                "Answer_creation_time":"2021-11-05T02:26:50.01Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hello @Chris-2395\n\nThanks for reaching out to us. But this currently is under development and we have no exact ETA for it.\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-11-26T02:52:46.95Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi @Chris-2395, would you share more detail use case of your scenario for built-in component. We are planning to support built-in component in CLI and SDK. For your use case, do you need to use built-in component only with built-in component or you also expect to use them with your customized component?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Using \"cv_splits_indices\" in AutoMLConfig",
        "Question_creation_time":1614846003803,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/298513\/using-34cv-splits-indices34-in-automlconfig.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"When training an regression model with AutoMLConfig with n_cross_validations being a normal int, I'm facing no problems.\n\nNow I want to use TimeSeriesSplit as the cross validation method for training a model with AutoMLConfig. For this there is a \"cv_splits_indices\" argument where I put in a list of lists of indicis like the following when n_splits=5 in TimeSeriesSplit :\n\n\n\n array([[array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n         array([11, 12, 13, 14])],\n        [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n         array([15, 16, 17, 18])],\n        [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n        17, 18]),\n         array([19, 20, 21, 22])],\n        [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n        17, 18, 19, 20, 21, 22]),\n         array([23, 24, 25, 26])],\n        [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n        17, 18, 19, 20, 21, 22, 23, 24, 25, 26]),\n         array([27, 28, 29, 30])]], dtype=object)\n\n\n\nUnfortunately when running the following cell:\n\n automl_settings = {\n     \"iteration_timeout_minutes\": 15,\n     \"experiment_timeout_hours\": 0.3,\n     \"max_cores_per_iteration\" : -1,\n     \"enable_early_stopping\": True,\n     \"primary_metric\": 'normalized_root_mean_squared_error',\n     \"featurization\": 'auto',\n     \"verbosity\": logging.INFO,\n     \"cv_splits_indices\": idxs\n }\n    \n automl_config = AutoMLConfig(task='regression',\n                              debug_log=f'automated_ml_errors_.log',\n                              training_data=train,\n                              validation_data=train,\n                              label_column_name=y_var,\n                              **automl_settings)\n\n\n\nI receive the following error:\n\n ConfigException: ConfigException:\n  Message: cv_splits_indices should be a List of List[numpy.ndarray]. Each List[numpy.ndarray] corresponds to a CV fold and should have just 2 elements: The indices for training set and for the validation set.\n  InnerException: None\n  ErrorResponse \n {\n     \"error\": {\n         \"code\": \"UserError\",\n         \"message\": \"cv_splits_indices should be a List of List[numpy.ndarray]. Each List[numpy.ndarray] corresponds to a CV fold and should have just 2 elements: The indices for training set and for the validation set.\",\n         \"details_uri\": \"https:\/\/aka.ms\/AutoMLConfig\",\n         \"target\": \"cv_splits_indices\",\n         \"inner_error\": {\n             \"code\": \"BadArgument\",\n             \"inner_error\": {\n                 \"code\": \"ArgumentInvalid\"\n             }\n         },\n         \"reference_code\": \"XXXXXXREDACTEDXXXX\"\n     }\n }\n\n\n\nWhat is going wrong here? My input looks correct?\n\nThank you",
        "Answers":[
            {
                "Answer_creation_time":"2021-03-04T14:48:46.463Z",
                "Answer_upvote_count":0,
                "Answer_body":"@BrianBarbieri-1018 Thanks for the question. Can you please add more details about the azure ML SDK version.\nHere is the doc for cross validation data folds.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"azure ml pipeline fails at sql transform task",
        "Question_creation_time":1620697549357,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/390003\/azure-ml-pipeline-fails-giving-no-error.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi, I'm using Azure ML Designer to run a pipeline. The pipeline performs a few steps and then it cancels the work throwing an error message with no further details.\n\nIf I re-submit the pipeline it completes the previously failed step but fails on the next step. If I re-submit the same thing happens (completes previously failed step to then fail the next step)... until it gets stuck in a specific sql transform step (see log below)\n\n\n\n\nHere is a sequence of run ids related with the issue:\nd33d23a2-2e60-4198-a6b6-f47e6e27ef4e\n57e04c1e-73e8-4ddf-91a8-c407cd1ad5ef\nad7dc826-6549-4eb3-9536-9a801d8e8c0b\ne6623f6f-b7b9-4f19-9501-c8c28f53ab23\n\nIt may be due to the way my pipeline is built but seems like JOIN, SQL Transform and SELECT Column operations tend to fail the most.\n\nWould much appreciate any help on this.\n\n 2021\/05\/11 01:57:24 Starting App Insight Logger for task:  runTaskLet\n 2021\/05\/11 01:57:24 Attempt 1 of http call to http:\/\/10.0.0.6:16384\/sendlogstoartifacts\/info\n 2021\/05\/11 01:57:24 Attempt 1 of http call to http:\/\/10.0.0.6:16384\/sendlogstoartifacts\/status\n [2021-05-11T01:57:24.912444] Entering context manager injector.\n [context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['urldecode_invoker.py', 'python', '-m', 'azureml.designer.modules.datatransform.invoker', 'ApplySqlTransModule', '--dataset', 'DatasetOutputConfig:Result_dataset', '--t1=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr', '--t2=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy', '--t3=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji', '--sqlquery=%22select+b.*%2cc.*%0d%0afrom+(%0d%0a++++select+a.customer_id%2c+a.sku_id%0d%0a++++from+(%0d%0a++++++++select+*+from+t1+cross+join+t2%0d%0a++++)+a%0d%0a++++where+exists+(%0d%0a++++++++select+t3.top_skus%0d%0a++++++++from+t3%0d%0a++++++++where+t3.sku_id+%3d+a.sku_id%0d%0a++++)%0d%0a)+b%0d%0ainner+join+(%0d%0a++++select+distinct+sku_id%2c+top_skus%0d%0a++++from+t3%0d%0a)+c%0d%0aon+c.sku_id+%3d+b.sku_id%22'])\n Script type = None\n [2021-05-11T01:57:26.142183] Entering Run History Context Manager.\n [2021-05-11T01:57:26.734197] Current directory: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/mounts\/workspaceblobstore\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\n [2021-05-11T01:57:26.734493] Preparing to call script [urldecode_invoker.py] with arguments:['python', '-m', 'azureml.designer.modules.datatransform.invoker', 'ApplySqlTransModule', '--dataset', '$Result_dataset', '--t1=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr', '--t2=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy', '--t3=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji', '--sqlquery=%22select+b.*%2cc.*%0d%0afrom+(%0d%0a++++select+a.customer_id%2c+a.sku_id%0d%0a++++from+(%0d%0a++++++++select+*+from+t1+cross+join+t2%0d%0a++++)+a%0d%0a++++where+exists+(%0d%0a++++++++select+t3.top_skus%0d%0a++++++++from+t3%0d%0a++++++++where+t3.sku_id+%3d+a.sku_id%0d%0a++++)%0d%0a)+b%0d%0ainner+join+(%0d%0a++++select+distinct+sku_id%2c+top_skus%0d%0a++++from+t3%0d%0a)+c%0d%0aon+c.sku_id+%3d+b.sku_id%22']\n [2021-05-11T01:57:26.734551] After variable expansion, calling script [urldecode_invoker.py] with arguments:['python', '-m', 'azureml.designer.modules.datatransform.invoker', 'ApplySqlTransModule', '--dataset', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpnbybe4mu', '--t1=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr', '--t2=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy', '--t3=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji', '--sqlquery=%22select+b.*%2cc.*%0d%0afrom+(%0d%0a++++select+a.customer_id%2c+a.sku_id%0d%0a++++from+(%0d%0a++++++++select+*+from+t1+cross+join+t2%0d%0a++++)+a%0d%0a++++where+exists+(%0d%0a++++++++select+t3.top_skus%0d%0a++++++++from+t3%0d%0a++++++++where+t3.sku_id+%3d+a.sku_id%0d%0a++++)%0d%0a)+b%0d%0ainner+join+(%0d%0a++++select+distinct+sku_id%2c+top_skus%0d%0a++++from+t3%0d%0a)+c%0d%0aon+c.sku_id+%3d+b.sku_id%22']\n    \n Session_id = 4b5b4c29-cfda-4ab6-a715-47fee287c468\n Invoking module by urldecode_invoker 0.0.8.\n    \n Module type: custom module.\n    \n Using runpy to invoke module 'azureml.designer.modules.datatransform.invoker'.\n    \n \/azureml-envs\/azureml_7c975cabc8bb1dc19c3de94457d707fd\/lib\/python3.6\/site-packages\/azureml\/designer\/modules\/datatransform\/tools\/dataframe_utils.py:2: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n   from pandas.util.testing import assert_frame_equal\n 2021-05-11 01:57:27,324 [             invoker] [    INFO] .[main] Start custom modules\n 2021-05-11 01:57:27,337 [             invoker] [    INFO] .[main] Module version: 0.0.74\n 2021-05-11 01:57:27,344 [             invoker] [    INFO] .[main] args: azureml.designer.modules.datatransform.invoker, ApplySqlTransModule, --dataset, \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpnbybe4mu, --t1=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr, --t2=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy, --t3=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji, --sqlquery=select b.*,c.*\n from (\n     select a.customer_id, a.sku_id\n     from (\n         select * from t1 cross join t2\n     ) a\n     where exists (\n         select t3.top_skus\n         from t3\n         where t3.sku_id = a.sku_id\n     )\n ) b\n inner join (\n     select distinct sku_id, top_skus\n     from t3\n ) c\n on c.sku_id = b.sku_id\n 2021-05-11 01:57:27,352 [             invoker] [    INFO] .[main] \"transform_module_class_name\": ApplySqlTransModule\n 2021-05-11 01:57:27,444 [         module_base] [    INFO] ...[get_arg_parser] Construct arg parser\n 2021-05-11 01:57:27,460 [         module_base] [    INFO] ...[get_arg_parser] arg: t1\n 2021-05-11 01:57:27,468 [         module_base] [    INFO] ...[get_arg_parser] arg: t2\n 2021-05-11 01:57:27,476 [         module_base] [    INFO] ...[get_arg_parser] arg: t3\n 2021-05-11 01:57:27,484 [         module_base] [    INFO] ...[get_arg_parser] arg: dataset\n 2021-05-11 01:57:27,492 [         module_base] [    INFO] ...[get_arg_parser] arg: sqlquery\n 2021-05-11 01:57:27,500 [         module_base] [    INFO] ..[parse_and_insert_args] invoker args:\n  module_classname = ApplySqlTransModule\n  t1 = \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr\n  t2 = \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy\n  t3 = \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji\n  dataset = \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpnbybe4mu\n  sqlquery = select b.*,c.*\n from (\n     select a.customer_id, a.sku_id\n     from (\n         select * from t1 cross join t2\n     ) a\n     where exists (\n         select t3.top_skus\n         from t3\n         where t3.sku_id = a.sku_id\n     )\n ) b\n inner join (\n     select distinct sku_id, top_skus\n     from t3\n ) c\n on c.sku_id = b.sku_id\n    \n 2021-05-11 01:57:27,508 [             invoker] [    INFO] .[main] start to run custom module: ApplySqlTransModule\n 2021-05-11 01:57:27,516 [apply_sql_trans_module] [    INFO] ...[run] Construct SQLite Server\n 2021-05-11 01:57:27,530 [    module_parameter] [    INFO] ......[data] Read data from \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr\n 2021-05-11 01:57:29,215 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t1 with only column names\n 2021-05-11 01:57:29,227 [    module_parameter] [    INFO] ......[data] Read data from \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy\n 2021\/05\/11 01:57:29 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n Stopped: false\n OriginalData: 1\n FilteredData: 0.\n 2021-05-11 01:57:30,093 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t2 with only column names\n 2021-05-11 01:57:30,106 [    module_parameter] [    INFO] ......[data] Read data from \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji\n 2021-05-11 01:57:30,876 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t3 with only column names\n 2021-05-11 01:57:30,888 [apply_sql_trans_module] [    INFO] ...[run] Read SQL script query\n 2021-05-11 01:57:30,895 [apply_sql_trans_module] [    INFO] ...[run] Validate SQL script query\n 2021-05-11 01:57:30,912 [apply_sql_trans_module] [    INFO] ...[run] Insert data to SQLite Server\n 2021-05-11 01:57:30,919 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t1\n 2021-05-11 01:57:30,930 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t2\n 2021-05-11 01:57:30,970 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t3\n 2021-05-11 01:57:31,053 [apply_sql_trans_module] [    INFO] ...[run] Generate SQL query result from SQLite Server",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-11T13:29:57.13Z",
                "Answer_upvote_count":1,
                "Answer_body":"Found the problem.\n\nThere was a task failing but due to the size of the canvas I wasn't able to spot it at first (working late hours didn't help also).\n\nHowever it certainly didn't help the fact that the error message didn't provide any info regarding which task failed, so maybe the AML team would like to add more descriptive messages in cases like this one.\n\nthanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to get the probability\/score by each cell\/row with machine learning?",
        "Question_creation_time":1666667585287,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1061214\/how-to-get-the-probabilityscore-by-each-cellrow-wi.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "dotnet-cli"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I have go through the solution in the forum but couldn't find a suitable solution for my question.\nI have use machine learning model to get the best algo for data modelling.\nI manage to get the confusion table but somehow i looking for probability\/scoring for each cell instead of overall result.",
        "Answers":[
            {
                "Answer_creation_time":"2022-10-26T08:03:28.34Z",
                "Answer_upvote_count":0,
                "Answer_body":"Below is my coding for Program.cs:\n\nstatic void Main(string[] args)\n{\n\/\/testing file location\nstring filepath = @\"C:\\Users\\Desktop\\Validation_Dataset - ColumnRename.csv\";\n\n\n\n         CsvConfiguration config = new CsvConfiguration(CultureInfo.InvariantCulture)\n         {\n             PrepareHeaderForMatch = args => args.Header.ToLower(),\n             MissingFieldFound = null\n         };\n         int correct = 0;\n         int total = 0;\n         using (var reader = new StreamReader(filepath))\n         using (var csv = new CsvReader(reader, config))\n         {\n             csv.Context.RegisterClassMap<PredictionDetailPredictMap>();\n             var records = csv.GetRecords<TrainTest.MLModel1.ModelInput>();\n             StringBuilder sb = new StringBuilder();\n             sb.Append(\"No,Expected,Predicted,IsMatch\");\n             sb.AppendLine();\n             foreach (var record in records)\n             {\n                 try\n                 {\n                     if (record.GB == \"0\") continue;\n                     total++;\n                     var result = TrainTest.MLModel1.Predict(record);\n                     Console.WriteLine(record.No);\n                     Console.WriteLine(\"Expected:\" + record.GB);\n                     Console.WriteLine(\"Predicted:\" + result.PredictedLabel);\n                     Console.WriteLine(\"====================\");\n                     \/\/if (record.BinRootCause.ToLower() == result.Prediction.ToLower()) correct++;\n                     string isMatch = record.GB.ToLower() == result.PredictedLabel.ToLower() ? \"YES\" : \"NO\";\n                     if (isMatch == \"YES\") correct++;\n                     sb.Append(record.No + \",\"  + record.GB + \",\" + result.PredictedLabel + \",\" + isMatch + \",\");\n                     sb.AppendLine();\n                 }\n                 catch (Exception ex)\n                 {\n                     \/\/store output file path\n                     Console.WriteLine(ex.Message);\n                     File.WriteAllText(@\"C:\\Desktop\\Result\\Testing.csv\", sb.ToString());\n                 }\n             }\n             sb.Append(\"Accuracy =\" + ((float)correct \/ (float)total) * 100 + \"%\");\n             File.WriteAllText(@\"C:\\Desktop\\Result\\Testing.csv\", sb.ToString());\n             Console.WriteLine(\"Accuracy=\" + ((float)correct \/ (float)total) * 100 + \"%\");\n         }\n     }\n\n\n\n\n\n\nHere is my sample output:\n\n\n\n\n\nI looking for each cell\/row have probability behind, for example:\n\n\n\n\n\n\n\n\nDo you know how to get the probability for each prediction result?\nThanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":33.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Advantage of clustering algorithm",
        "Question_creation_time":1608719822847,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/208687\/advantage-of-clustering-algorithm.html",
        "Question_topic":null,
        "Question_tag":[
            "not-supported-azure",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"We don't need the name of attributes in clustering, so, if I do not know my attribute names how can I understand that which data should I enter and also if I do not know the name of the attributes how can I give the axis name of the plotted graph? If it is the advantage of clustering algorithm, then why it is not the advantage of other algorithms, because if we do not know the name of the attributes we can create our models because if we have attribute values that is enough, but why we need attribute names too in other algorithms?",
        "Answers":[
            {
                "Answer_creation_time":"2020-12-23T16:35:59.897Z",
                "Answer_upvote_count":0,
                "Answer_body":"@SanniddhaChakrabarti-9451 Thanks, If the products data is not already labeled and ready for training, you can start with a clustering problem.\nOnce you identify those clusters, a Domain Expert can review those clusters and try to set a name for each (the Categories\/classes).\nThen, all the data can be labeled according to those new categories\/classes and finally train a model.\n\nFrom there, with a trained model, you could \u201cpredict\u201d what category\/class a product should be assigned based on its product\u2019s name and description.\n\n\u2022 For the clustering problem you need to directly use a framework such as Scikit-Learn (or even ML.NET in C#).\n\u2022 Defining a category\/class name for each identified cluster needs to be done manually by a Domain Expert.\n\u2022 Labeling the data could be semi-automated with a custom program, based on the multiple clusters defined, it would label each row with a new class-caterogy-name defined for each of the identified clusters.\n\u2022 For the multi-class classification model training, you can use Azure Automated ML as the easiest approach.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Is it possible to parameterize the sharable url of an azure ml notebook?",
        "Question_creation_time":1643398754623,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/714542\/is-it-possible-to-parameterize-the-sharable-url-of.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I would like to share the link to a Jupyter notebook (stored in azure ml studio) with the parameters of the notebook already updated. I see I can automatically get a sharable link for the notebook. Is it possible to parameterize this link? If not, is there an equivalent alternative?",
        "Answers":[
            {
                "Answer_creation_time":"2022-01-31T14:50:27.643Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, are you looking for something similar to Run with Parameters feature in Azure Data Studio?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Scaling and load balancing with deployed machine learning containers - ACI + Application Gateway vs AKS?",
        "Question_creation_time":1637592050953,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/636334\/scaling-and-load-balancing-with-deployed-machine-l.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-kubernetes-service",
            "azure-application-gateway",
            "azure-container-instances"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"I have been working on a deployment solution for machine learning models. Our objective is to minimize the internal development effort while maintaining high availability and full control over the API. Our first solution is a deployment as azure webservice to ACI using the azureml.core.model.Model.deploy method with a deployment config azureml.core.webservice.AciWebservice.\nWe quickly noticed that our initial deployment configuration was not powerful enough and wanted to upgrade the hardware. Here is the first issue: it seems that the ACI webservice does not support any GPU instances. So my first question is: which service is recommended to deploy models that require GPU for inference?\nHowever, we first wanted to deploy the same image onto a more powerful CPU. When doing this, we got the error\n\"Invalid overwrite request - cannot update container resource requirements, dns name label, or deployment type. Please delete and redeploy this service.\". After deleting and redeploying, the scoring URI changes, which is a problem for us. As we cannot predict the load and resource requirements at this point, we need a way of (auto-) scaling the containers and also to update single container resource requirements, without changing the endpoint. As this seems to be impossible using the scoring URI provided by azureml endpoint, I had the feeling that we need to hide the azureml endpoint behind a load balancer. Is this the intended way of doing it? If so, should I use application gateway or traffic manager? If I use application gateway, how do I configure the VPC such that the containers managed by azureml are available to application gateway? Or should I completely abandon ACI and go with AKS? It would be great to get some expert feedback on this as I feel like every single of these questions leads me down a rabbit hole and I cannot continue the actual project if I first have to learn about >10 azure services and all cross combinations of those.",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":18.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Project in Data Labeling not working, getting only \"Loading project details\"",
        "Question_creation_time":1647676305203,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/778679\/project-in-data-labeling-not-working-getting-only.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Project in Azure Machine Learning Studio in Data Labeling was working, we did label it every day. One day we just could not open it, it showed only Loading project details.. for hours.\nSAS token is working, it also work for our admin account, but not for Labellers.\nDo you have any idea?",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-21T16:36:47.9Z",
                "Answer_upvote_count":0,
                "Answer_body":"@ika-8686 Thanks for the question. Please share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to disable Azure ML snapshots (for compute clusters)",
        "Question_creation_time":1611558384720,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/243585\/how-to-disable-azure-ml-snapshots-for-compute-clus.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am using the Azure ML Python SDK to spawn jobs using a prebuilt Docker image compute cluster. The Docker image has all of the dependencies installed and the source code I am running.\n\nAccording to the logs, Azure ML's \"snapshot\" operations (that I assume upload and then download the source directory to Azure ML jobs) increase the startup time from 2 minutes to 8-20 minutes (i.e., the time it takes for an Azure ML run to begin running my code). By comparison, when I run the exact same code on a compute instance instead of a compute cluster, startup time is 60-80 seconds. Notably, the startup logs for the compute instance make no mention of \"snapshots\".\n\nI already disabled saving snapshots for historical record, but that made little difference and the startup logs (for a cluster) still show operations for snapshots. I also significantly expanded our .amlignore file, which reduced the startup time by 10+ minutes, but 5-10 minutes are still spent on the \"fetching snapshots\" step (which we do not even use).\n\nQuestions:\n1. What is this \"fetching snapshot\" operation if it is not the saving of snapshots for historical record (which I already disabled and confirmed)?\n2. Why does this operation only occur for compute clusters but not compute instances?\n3. Why is this operation so slow? I.e., 5-10 minutes to \"fetch\" less than 10 MB of python files.\n4. Can I disable everything having to do with snapshots altogether? I assume this is possible because this occurs when using compute instances in Azure ML.\n\nThank you very much. Please let me know if there is anything more I can provide to help debug.",
        "Answers":[
            {
                "Answer_creation_time":"2021-01-25T11:57:35.397Z",
                "Answer_upvote_count":0,
                "Answer_body":"@DannyNemer Thanks for the question. To prevent unnecessary files from being included in the snapshot, make an ignore file (.gitignore or .amlignore) in the directory. With regards to the snapshotted set of files, you could create a \u201c.amlignore\u201d file following a similar syntax as a gitignore files to prevent uploading of files as a snapshot with your runs. I could see you have leveraged this.\n\nPlease follow the doc for the same.\n\nGenerally Compute target takes a long time to start: The Docker images for compute targets are loaded from Azure Container Registry (ACR). By default, Azure Machine Learning creates an ACR that uses the basic service tier. Changing the ACR for your workspace to standard or premium tier may reduce the time it takes to build and load images. For more information, see Azure Container Registry service tiers.\n\nCompute Instance is a managed cloud-based workstation for data scientists which makes it easy to get started with ML development on AzureML while providing management and enterprise readiness capabilities. Compute instances support the full lifecycle of inner-loop ML development on AzureML. Compute instance is fully customizable by data scientists and is tightly integrated with Azure ML workspace.\nCompute instances can be used for running notebooks through first-class web experiences for popular tools such as JupyterLab, Jupyter, and integrated notebooks and running R scripts. Compute instance can also be used as a training compute target.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"ML Service started return InternalError 500 for batch requests. Code:14.",
        "Question_creation_time":1595609615540,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/52082\/ml-service-started-return-internalerror-500-for-ba.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"ML Service started return InternalError for batch requests with Code:14.\nI enabled logs, logs are good, even results in storage are good.\n\nSingle request works without any issues.\n\n\n\n\n{\"error\":{\"code\":\"InternalError\",\"message\":\"Execution encountered an internal error.\",\"details\":[{\"code\":\"14\"}]}}\n\n\n\n\nBatch Request Log shows request as \"Finished\" and provides link to blob.\n\nAnybody knows what is a Code:14?",
        "Answers":[
            {
                "Answer_creation_time":"2020-07-28T02:45:54.197Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nSorry for your experience. Do you have a support plan under your subscription account? If yes, I will highly suggest you to open one support ticket for this problem. If not, please send me an email at Azcommunity@microsoft.com with this URL and also your subscription ID, I can help you to connect to a support engineer for deeper help.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":1.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"What is AML_MODEL_URI - PREDICT in serverless Apache Spark pools (Synapse & Azure Machine learning AML)",
        "Question_creation_time":1637180271803,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/631200\/what-is-aml-model-uri-predict-in-serverless-apache.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-synapse-analytics",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi all,\n\nI am following the steps on this tutorial:\nTutorial: Score machine learning models with PREDICT in serverless Apache Spark pools https:\/\/docs.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool\n\nI don't know what is the AML_MODEL_URI. I thought it was the REST endpoint or the Swagger URI from the endpoint.\n\n\nBut it is not working. I am getting this error on Synapse: \"RuntimeError: Load model failed\nTraceback (most recent call last):\"\n\n\nI appreciate you help.\n\nKind regards,\nAnaid",
        "Answers":[
            {
                "Answer_creation_time":"2021-11-23T11:39:05.273Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hello @Anaid-6816,\n\nThanks for the question and using MS Q&A platform.\n\nAML_MODEL_URL is the same name of the model in the ML workspace with (follow the format of aml:\/\/ + Name of the Model).\n\nExample: aml:\/\/sklearn_regression_model:1 (follow the format of aml:\/\/ + Name of the Model).\n\nHope this will help. Please let us know if any further queries.\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":14.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"time series training",
        "Question_creation_time":1659301076627,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/949086\/time-series-training.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I see one document mentioned time series training can be done with AutoML: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-forecast is that any sample which from basic build of model?",
        "Answers":[
            {
                "Answer_creation_time":"2022-08-01T08:47:41.097Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @matsuoka-4412\n\nThanks for using Microsoft Q&A platform, we don't have any samples for basic build of a model in AutoML, but we do have quick start for how to use time series in AutoML - https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-automated-ml-forecast\n\nThis is a low code sample for beginning user. Please take a look.\n\n\n\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Is it possible to include the IP address of a specific Azure Machine Learning workspace in its storage account selected networks and get all functionality enabled?",
        "Question_creation_time":1626459319327,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/479209\/is-it-possible-to-include-the-ip-address-of-a-spec.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-virtual-network"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"We have secured the storage account of a Machine Learning workspace behind a vnet and have authorized a set of IPs to access the storage account. Since the workspace is not secured behind the vnet, a set of functions is disabled. Is there a way to get the IP of the workspace and include it in the list authorized networks for the storage account in order to have all workspace functionalities available? We know the official solution involves securing the workspace behind the vnet and enabling point-to-site, site-to-site or connecting through a VM, but these are not possible in our case. Thanks for the help.",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":15.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How can I use a working pipeline",
        "Question_creation_time":1640685619343,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/677175\/how-can-i-use-a-working-pipeline.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi,\n\nI created a working pipeline in azure machine learning studio but I am stuck how i can use it with a live dataset. Could anybody help to me in this issue? I dont have such option to deploy it.\n\nthank you in advance",
        "Answers":[
            {
                "Answer_creation_time":"2021-12-28T21:24:18.68Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, please review Test the real-time endpoint for more details on how to test your model. You can consume your model using a Client or PowerBI.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Dataset for inference data is registered with wrong path when deployed on Kubernetes",
        "Question_creation_time":1624590394283,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/451349\/dataset-for-inference-data-is-registered-with-wron.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"When model is deployed on Kubernetes with model data collection set to true, the dataset which gets registered in workspace has a wrong path.\nThe blob storage path where this data being collected has default in it but the path registered doesn't have default.\n\nFor example, actual path on storage:\n\n azuremlwsdev\/modeldata\/GUID\/ad\/ad-workspace-dev\/dev-ad-model-v1-2-jen\/model\/default\/inputs\n\n\n\nPath dataset is registered with:\n\n GUID\/ad\/ad-workspace-dev\/dev-ad-model-v1-2-jen\/model\/inputs\/**\/inputs*.csv\n\n\n\nCode inside our scoring service to init collector and use them:\n\n def init():    \n     global inputs_dc, prediction_dc\n     ...\n     inputs_dc = ModelDataCollector('model', designation=\"inputs\", feature_names=feature_set.columns.values.tolist())\n     prediction_dc = ModelDataCollector('model', designation=\"predictions\", feature_names=[\"score\"])\n    \n def run(raw_data):\n     inputs_dc.collect(X)\n     prediction_dc.collect(y_pred)\n\n\n\nBelow are the library versions being used:\n\n azureml-defaults==1.1.5\n azureml-monitoring==0.1.0a21",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML - Deployed to Inference Cluster throws 500 Server Error - MissingFeaturesError",
        "Question_creation_time":1614113525043,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/285607\/azure-ml-deployed-to-inference-cluster-throws-500.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"We have an Azure ML model we are ready to deploy to an http endpoint for consumption and testing.\n\nWe are using this tutorial (https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy) as the jumping off point for deploying our ml model. We have created an inference cluster, converted the training model to a real-time inference model and deployed. Deployment looks successful. However, when testing (both via the Test tab in the Azure ML Workspace and via http POST) the server throws a 500. The MissingFeaturesError follows:\n\n\n\n\nFile \"\/azureml-envs\/azureml_9b50686470a92ca74f0d62e2629faaec\/lib\/python3.6\/site-packages\/azureml\/studio\/modules\/ml\/common\/base_learner.py\", line 289, in _validate_no_missing_feature\nErrorMapping.throw(MissingFeaturesError(required_feature_name=';'.join(missing_feature_list)))\n> missing_feature_list = ['Miles', 'Age', 'Gender', 'MarriagetPlans']\n\n\nFile \"\/azureml-envs\/azureml_9b50686470a92ca74f0d62e2629faaec\/lib\/python3.6\/site-packages\/azureml\/studio\/common\/error.py\", line 814, in throw\nraise err\n> err = MissingFeaturesError('Features for Miles;Age;Gender;MarriagetPlans required but not provided.',)\n\n\nMissingFeaturesError: Features for Miles;Age;Gender;MarriagetPlans required but not provided.\n\nIn both test cases (via Test tab in Azure and http POST to the endpoint) all the required data is indeed provided. The request body definitely includes Miles, Age, Gender, MarriagetPlans.\n\nWhat is going on here?",
        "Answers":[
            {
                "Answer_creation_time":"2021-02-24T03:41:55.38Z",
                "Answer_upvote_count":0,
                "Answer_body":"You can add a additional tag \"azure-machine-learning\" to make more people know your problem, I believe it's problem of AML studio",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-02-26T15:00:09.507Z",
                "Answer_upvote_count":0,
                "Answer_body":"bump Still a problem.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Access to Azure subscription for users",
        "Question_creation_time":1666972949727,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1067157\/access-to-azure-subscription-for-users.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-active-directory",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"We have an active subscription. For few of the users we activated owner role for the machine learning resource group.\nBut when they login to the portal\/ML environment and try to switch directory and subscription, they don't see our production subscription and hence the workspace, although directory is correct. User had created a trial subscription on its own before and he only has visibility to that.\n\nI checked with a test account and after login to ML studio I see this, which I believe is the same reason user does not see the subscription.\n\nHow can I safely give user subscription access only for ML resource group",
        "Answers":[
            {
                "Answer_creation_time":"2022-10-28T17:11:56.507Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @RT-7199\n\nThank you for asking this question on the Microsoft Q&A Platform.\n\nThe role will depend on the activity that the user performs, for example, to create a new workspace you will require the role owner or contributor at the Resource group-level. (If you receive a failure when trying to create a workspace for the first time, make sure that your role allows Microsoft.MachineLearningServices\/register\/action. This action allows you to register the Azure Machine Learning resource provider with your Azure subscription.)\n\nYou can get more information about RBAC for Azure Machine Learning workspace here\n\nHope this helps!\n\nAccept Answer and Upvote, if any of the above helped, this thread can help others in the community looking for remediation for similar issues.\nNOTE: To answer you as quickly as possible, please mention me in your reply.",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":53.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML (Designer): Endpoint deploys initially, but can't consume or test it after that.",
        "Question_creation_time":1624896031587,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/454914\/azure-ml-designer-endpoint-deploys-initially-but-c.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,\n\nI recently deployed an Azure Machine Learning Model (Designer). I have followed this tutorial (but for my model). The inference pipeline looks like this:\n\nThis endpoint was then deployed with the following configurations:\n\nCompute Type: Azure Container Instances\n\n\nCPU : 2\n\n\nMemory: 2 Gb\n\nFrom my understanding, when a model-endpoint is deployed initially, there is a test run (which tries to consume the endpoint) that is automatically run by Azure ML, and this has always worked for me (I have tried AKS too, and ACI with lower compute power). Attached, please find the logs.\n\n109955-initial-test-endpoint.txt\n\nAfter the test run, I can either test it from the interface itself, or I can execute some Python code (which Azure ML provides) that can consume it for me. In both cases, I get a 500-Bad Gateway error (checked through Deployment Logs):\n109962-endpoint-test.txt\n\nThis is what the Python code outputs:\n\n\nI have monitored the status of the endpoint while I try to consume it, and it is always healthy.\n\nI hope I have provided enough details. If not, please let me know what else is needed to understand the issue here. Any help is appreciated.",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Store Raw JSON file from azureml.core.Run",
        "Question_creation_time":1651092990657,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/829188\/store-raw-json-file-from-azuremlcorerun.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\nin the details tab of a pipeline step (in an experiment) one of the last entries is \"See all properties\". Below that the Raw JSON file is linked and can be opened. Is there a way to save or access these Raw JSON file within the Python SDK?\n\nI want to store these file beside the model to guarantee traceability, if we deploy the registered model outside of Azure.\n\nThanks for your help",
        "Answers":[
            {
                "Answer_creation_time":"2022-05-02T23:02:13.493Z",
                "Answer_upvote_count":0,
                "Answer_body":"Any update? Based on the doc from Microsoft, this is not available yet.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Total Regional Cores quota error",
        "Question_creation_time":1665265961547,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1040655\/total-regional-cores-quota-error.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Dear all\nI have a free Microsoft Azure student account. I am using Microsoft Azure automated ML and DESIGNER.\nI tried to deploy my model, which I created in DESIGNER.\nFor that, I need to create Compute, Inference clusters. When I do so, I always receive an error message: \"Operational could not be completed as it results in exceeding approved Total Regional Cores quota\". I tested various options, but all failed. I always chose Switzerland North, as it is the closest.\nIn addition, I constructed a new resource group. However, this did not make any difference.\nI read something about altering the Subscription (Azure for Students). However, then I'm not sure if I have to pay for the upgrade?\n\nMay you can tell me how it works with \"Azure for students\" when I want to deploy my model? How can I build a Compute, Inference clusters?\n\nThank you for your feedback.\n\nBest regards\n\nLukas",
        "Answers":[
            {
                "Answer_creation_time":"2022-10-08T22:14:01.357Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi @LukasBusers-1078 ,\n\neach Azure subscription has is quotas for different Azure services.\nDepending on the type of Azure subscription it is a hard hard quota limit, for instance for Free Trial subscriptions.\nhttps:\/\/learn.microsoft.com\/en-us\/azure\/azure-resource-manager\/management\/azure-subscription-service-limits#managing-limits\n\nYou an get the details of the usage and the quotas in the Azure Portal for each subscription:\n\nFor vCPUs for Azure Compute resources there are quotas per region in Total and per VM SKU.\nFor instance Total Regional vCPUs = 20\nFor each VM Series (e.g. Ev3 Series\/Family) = 20\nYou have to take care for both quotas, the Total and the VM Family quota per region, as they are working together and related to each other.\n\nDepending on the type of Azure Subscription and the Azure Resource you could increase the quota by yourself or via Azure Support.\nI have no Azure for Students subscription. So I am not able to give you an answer about the costs. But you should be able to get the information which Azure resources are included in the Azure Students subscription and which resources are charged in addition.\nhttps:\/\/azure.microsoft.com\/en-gb\/offers\/ms-azr-0170p\/\n\n(If the reply was helpful please don't forget to upvote and\/or accept as answer, thank you)\n\nRegards\nAndreas Baumgarten",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-09T09:44:44.14Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thank you for your feedback.\nWhen I chose \"user settings\", I receive following answer: No access",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Endpoint not being created Azure Designer",
        "Question_creation_time":1592922691007,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/39203\/endpoint-not-being-created-azure-designer.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"I created a simple recommendation model in Azure Designer. The model is able to train and from that, I created an inference pipeline. I ran it and deployed it, under a new AKS inference cluster and even experiment. However, the endpoint is just not being created. I can see the model is registered with a new version but no endpoint is created. Below, I have attached a screenshot of the inference pipeline in designer.",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":4.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure : \"message\": \"Error: Scoring was unsuccessful.\" when we run forecasting.",
        "Question_creation_time":1655568786827,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/894519\/azure-34message34-34error-scoring-was-unsuccessful.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\ninit() function in score.py is executed properly but I am getting error in run function. As shown in image I am getting below error.\n\n \"error\": {\n\"message\": \"Error: Scoring was unsuccessful.\"\n}\n\nThank you,\nSaswat",
        "Answers":[
            {
                "Answer_creation_time":"2022-06-20T08:46:56.897Z",
                "Answer_upvote_count":0,
                "Answer_body":"@SaswatMahapatra-4328 Do you see the same error when you test the prediction through the consume tab of the endpoint from the Azure ML portal?\nIf the above works for same data through portal then it is most likely a data issue, but it looks like not much detail of the error is printed here. Can you also check what the swagger API prints about the data format that needs to be passed?\n\n print(service.swagger_uri)",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to run CuDNNLSTM on JupyterLab within Azure Machine Learning?",
        "Question_creation_time":1595404543680,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/50813\/how-to-run-cudnnlstm-on-jupyterlab-within-azure-ma.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Good day Everyone\n\nI am trying to train an LSTM based recurrent neural network using Azure Machine Learning JupyterLab. I have setup the VM instance to use a 6 core GPU. However, when i try to train my recurrent network using the efficient GPU based CuDNNLSTM network i get a \"ModuleNotFoundError: no module named tensorflow.contrib\". How can i rectify this so that i can be able to run CuDNNLSTM based code on my GPU?",
        "Answers":[
            {
                "Answer_creation_time":"2020-07-23T07:03:36.42Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thank you. I am using the Microsoft Azure Machine Learning JupyterLab notebook so it comes pre-installed with all the packages and dependencies. So i have no idea what they are using unless if you know where i can check the versions used by Microsoft Azure?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":35.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Error creating endpoint from mlflow model (tensorflow job)",
        "Question_creation_time":1667731273557,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1077214\/error-creating-endpoint-from-mlflow-model-tensorfl.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello everybody,\nI am trying to deploy a realtime endpoint from a registered mlflow model obtained from a tensorflow training job.\nIn this repository, you will find the training scripts:\n\nhttps:\/\/github.com\/antigones\/py-hands-ml-tf\/tree\/main\/azure_ml\/job_script\n\nThe job outputs a MLFlow model with its conda environment yml file.\n\n\n\n\nWhen I try to deploy the model to a realtime endpoint, I get the following error:\n\n257528-azure-ml-deploy-error.txt\n\nIt seems to be an error related to protobuf, when loading the model:\n\n  File \"\/opt\/miniconda\/envs\/userenv\/lib\/python3.8\/site-packages\/google\/protobuf\/descriptor.py\", line 560, in __new__\n     _message.Message._CheckCalledFromGeneratedFile()\n TypeError: Descriptors cannot not be created directly.\n If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\n If you cannot immediately regenerate your protos, some other possible workarounds are:\n  1. Downgrade the protobuf package to 3.20.x or lower.\n  2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n    \n More information: https:\/\/developers.google.com\/protocol-buffers\/docs\/news\/2022-05-06#python-updates\n\n\n\nThe environment is deployed automatically (the scoring script is also generated).\nI have also tried different images, with different python versions (3.7) and Tensorflow versions (2.4) with no luck.\n\nHow can I solve this issue?\n\n\n\n\nThank you in advance for your support.",
        "Answers":[
            {
                "Answer_creation_time":"2022-11-06T14:01:03.993Z",
                "Answer_upvote_count":1,
                "Answer_body":"Seems like the problem is in azureml-inference-server-http package, where there is a mismatch with protobuf version.\n\nAs a workaround, I created a custom managed online deployment via CLI, specifing the following environment variable:\n\n environment_variables:\n   \"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\": \"python\"\n\n\n\nand then I was able to publish the endpoint.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-11-10T19:57:59.41Z",
                "Answer_upvote_count":0,
                "Answer_body":"I have a Keras model and I had to develop and upload my own score.py to override the init() function in order to load the model using load_model() for Keras models, instead of using joblib.load(model_path) as it was by default.\nYou probably also have to override the run() function to customize the inference.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Accessing the my ML Model from azure ml",
        "Question_creation_time":1598739182170,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/80879\/accessing-the-my-ml-model-from-azure-ml.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am accessing my ML modal that i have deployed on azure ml and using that model to predict but is there any way i can pass the data other than json format ?",
        "Answers":[
            {
                "Answer_creation_time":"2020-08-31T10:50:21.85Z",
                "Answer_upvote_count":0,
                "Answer_body":"@YashPathak-1466 Thanks for the question. Can you please add more details about the model that you are trying. Basically, the test data content needs to be parsed and transformed just like how your training data is transformed before it gets into model.fit(). Without knowing what your model does, it\u2019s hard to see what\u2019s going on.For Deep learning models If test data are text, then it needs to be tokenized. If numbers, they need to be transformed and normalized. Either way, test data has to become numpy array or a generator that streams numpy.\n\nPlease follow the below document for ways to consume the deployed AML as web service.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":2.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Use a trained model for use cases (a new data set)",
        "Question_creation_time":1665310129110,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1040790\/use-a-trained-model-for-use-cases-a-new-data-set.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Dear all\n\nI conducted some experiments with Microsoft Azure automated ML and DESIGNER.\n\nAs far as I understand the given results, the trained model shows e.g. the accuracy? How well or in how many cases can the trained model predict the value (e.g. TRUE or FALSE) correctly?\n\nNow, I want to use the \"trained\" model(s) for use cases. My goal is to use the trained model(s) and provide predictions for new samples (a new data set). E.g. I want to predict the value \"TRUE\" or \"FALSE\" for the values of the new data set.\n\nIn my case, there is no value in the column (TRUE or FALSE). I want the model to provide me with the answers.\n\nNext steps: As far as I see, I need to deploy the model so that I can conduct the same experiments with new samples?\n\nOr how can I apply my trained model for the new use cases? (please see my description above)\n\nThank you for your feedback\n\nBest regards\n\nLukas",
        "Answers":[
            {
                "Answer_creation_time":"2022-10-10T14:14:26.413Z",
                "Answer_upvote_count":0,
                "Answer_body":"@LukasBusers-1078 After you create a deployment, you can score it as described in Test the endpoint with sample data.\nAre you facing any error, if yes please add the error details.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-26T14:46:01.66Z",
                "Answer_upvote_count":0,
                "Answer_body":"Tutorial Overview\nThis tutorial is divided into three parts; they are:\n\nPrepare a Training Dataset\nHow to Fit a Model on the Training Dataset\nHow to Connect Predictions With Inputs to the Model\n2. Prepare a Training Dataset\nLet\u2019s start off by defining a dataset that we can use with our model.\n\nYou may have your own dataset in a CSV file or in a NumPy array in memory.\n\nIn this case, we will use a simple two-class or binary classification problem with two numerical input variables.\n\nInputs: Two numerical input variables:\nOutputs: A class label as either a 0 or 1.\nWe can use the make_blobs() scikit-learn function to create this dataset with 1,000 examples.\n\nThe example below creates the dataset with separate arrays for the input (X) and outputs (y).",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How do I get the experimentID inside a running pipeline script?",
        "Question_creation_time":1638292741140,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/646416\/how-do-i-get-the-experimentid-inside-a-running-pip.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello, I'm writing a ML pipeline.\n\nAt the end of a script I have to write the output to a SQL database, and I would need the ExperimentID as a field of the output dataframe.\n\nIs there a way for me to find within the running script in which experiment it's being run?\nOr is there a way for me to input the ExperimentID as a parameter to the pipeline at launch? From what I understand parameters are defined before the experiment is created so that's a bit confusing.\n\nIn case this is too complicated, is there a way I can somehow chain the pipeline output inside a script to the experiment it's being run?\n\nThank you very much,",
        "Answers":[
            {
                "Answer_creation_time":"2021-12-01T04:39:29.95Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, you can use the get_context method of the Run Class to get the run id. Here's an example:\n\n run = Run.get_context()\n run_id = run.id",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"I wish to store a variable in R in ML studio to use it for consecutive executions (Web service calls). But since the R script is run from the start, the variable's value resets to default value, that I set. Is there a way to achieve this?",
        "Question_creation_time":1606214692780,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/173691\/i-wish-to-store-a-variable-in-r-in-ml-studio-to-us.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"My Machine learning flow looks something like this:\n\n\n\n\n\n\n\nAnd my R script looks something like this:\n\n if(useAxe){\n    if (condition1) {\n       useAxe <- true\n    }else{\n       useAxe<- false\n }\n\n\n\n\nI want the value of useAxe from the previous execution and update it according to the criteria.",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-24T12:23:39.357Z",
                "Answer_upvote_count":0,
                "Answer_body":"@SaurabhSadhwani-9510 Variables that are set in the R script or python script will get reset during subsequent calls to the web service as the complete predictive experiment is run when the endpoint is called. As an alternate you can set a web service parameter or export the data using the export data module and write the result to an external database.\n\nAn example of using the web service parameter to output the result to a csv file on blob storage is available in this blog. Some of the parameters and modules might not be in use now since the classic ML studio has a newer version in Machine Learning Designer on the new ML portal ml.azure.com",
                "Answer_comment_count":8,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Timeout on AutoMLConfig is not a hard timeout",
        "Question_creation_time":1624927301677,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/455257\/timeout-on-automlconfig-is-not-a-hard-timeout.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"When setting the timeout on the AutoMLConfig, it is not respected. Why?",
        "Answers":[
            {
                "Answer_creation_time":"2021-06-29T06:44:35.72Z",
                "Answer_upvote_count":0,
                "Answer_body":"@AxelSirota-0156 Referring to the AutoMLConfig documentation the parameter for timeout seems to be in hours rather than minutes.\n\nWhich version of the SDK are you using? Could you try to change the config accordingly for minutes to probably 0.25 i.e 15 minutes and check again?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Visual Code red underline",
        "Question_creation_time":1617894794830,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/349688\/visual-code-red-underline.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello! I'm studying the Phyton First Steps course and I have questions about the Video Code. When I type \"Print\" in the code thing it doesn't get a red underline as they said it should. I want to know if I need to enable that type of thing",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-21T01:33:55.777Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nRed underline in VS code means that there is an error, which is not expected to appear. If you get it you need to fix it. Please let us know the code if you need help.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Drifting Sample in azure machine learning studio does not finish backfill",
        "Question_creation_time":1630488394320,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/535756\/drifting-sample-in-azure-machine-learning-studio-d.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am trying to run the sample tutorial on data\/model drifting in azure machine learning samples. When I run the backfill command is waiting for the target cluster in the queue and it does not start, after waiting for a very long time.\n\nIs it a common issue? How to run the example? I thought was a question of simply run it .. but it does not finish the run..",
        "Answers":[
            {
                "Answer_creation_time":"2021-09-01T20:33:51.383Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, you need to first clone the Azure ML Samples, then you'll be able to run the notebook from Files tab:\n\n\n\n\n\n\n\nGo to Files tab and open the notebook:",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Time series forecasting AutoML Automatic featurization groupby specific column values",
        "Question_creation_time":1647278425307,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/771703\/time-series-forecasting-automl-automatic-featuriza.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\nI'm training time-series forecasting models with Azure AutoML.\n\nAs far as I\u2019m concerned, featurization techniques such as Normalization and Scaling or Impute missing values, are applied by columns.\n\nGiven that I\u2019m dealing with time-series data, is there a way to apply these kinds of featurization using a group by some column values? Otherwise, I feel the transformations applied make no sense at all.\n\nFor instance, If I want to predict product demand from different stores, would be possible to impute missing values from one article given the median of that article (not the one of the column) modifying AutoML Automatic featurization? Or standardize the target values for each article separately?\n\nThanks in Advance.",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-16T07:17:18.337Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Marcrb-4306 Thanks for the question. \"featurization\": 'FeaturizationConfig' Indicates customized featurization step should be used. Learn how to customize featurization.\nHere is link to Currently Supported customization.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Access file in a storage account residing in different tenant to ML Service in another tenant via IP based SAS restricted access",
        "Question_creation_time":1645593594070,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/747081\/access-file-in-a-storage-account-residing-in-diffe.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-blob-storage"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\nI have a storage account residing in tenant-A and machine learning service in tenant-B. When I try to read file from storage account in tenant-A via SAS (with IP restriction) in the jupyter notebook running on compute in ML service in tenant-B, it is not accessible and failing with 403 (Forbidden).\n\nBut when I try to access the file without IP restriction, I am able to read it in the notebook.\nCan you please help in understanding why it is happening and possible fix for the problem?\n\nPlease note, the public IP of ML compute is being used for whitelisting in SAS.",
        "Answers":[
            {
                "Answer_creation_time":"2022-02-23T13:50:27.507Z",
                "Answer_upvote_count":0,
                "Answer_body":"@HimanshuBajpai-3138 I think you need to whitelist the IP ranges that fall under BatchNodeManagement.<region> and AzureMachineLearning.<region> from the list of Azure IPs for your region under the respective categories. The list of azure IPs can be downloaded from here.\n\nDepending on your region try whitelisting these IPs instead of the public IP of your compute and check if it works. For more details about setting up inbound and outbound network configuration for Azure ML, please refer this page.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":7,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":16.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML BFSMountError: Unable to mount blob fuse file system",
        "Question_creation_time":1660200527397,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/963683\/azure-ml-bfsmounterror-unable-to-mount-blob-fuse-f.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"Training yolov5 using Azure ML SDK and encountered error below. I have a gpu cluster created (no vnet) and encountered this error when i ScriptRunConfig and experiment.submit. My Azure ML Storage account is enabled from all network (no vnet). Thank you very much\n\nsrc = ScriptRunConfig(.......)\nrun = experiment.submit(src)\n\nAzureMLCompute job failed.\nBFSMountError: Unable to mount blob fuse file system\nInfo: Could not mount Azure Blob Container azureml-blobstore-xxxxxxxx at workspaceblobstore: <nil>. Unable to start blobfuse due to a lack of credentials. Please check the readme for valid auth setups.\nUnmounting blobfuse.\nUnmounted blobfuse successfully.\n\n Info: Failed to setup runtime for job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"DataDrift in AzureML",
        "Question_creation_time":1659816958003,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/957739\/datadrift-in-azureml.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi, What is the underlying algorithm for azureml DataDriftDetector class? and what is the mathematical implication of the threshold in datadrift?",
        "Answers":[
            {
                "Answer_creation_time":"2022-08-09T03:15:57.817Z",
                "Answer_upvote_count":0,
                "Answer_body":"@AmoozegarShahrzad-3484 Thanks for the question. Concept Drift Detection Methods:\nApproaches to Drift Detection:\n\n\nwe will pivot to focusing on detecting drift in Data \u2013 regardless of what it is, where it came from. Our prereq becomes usage of TimeSeriesDataset, which is a low bar for entry.\ndatadrift = DataDriftDetector.create(ws, baseline=tsd.timerange(start, end), target=tsd)\nHere is the document for Detect data drift (preview) on datasets.",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"AciDeploymentFailed",
        "Question_creation_time":1655464430947,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/893526\/acideploymentfailed.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,\n\nIt's been a few days already since I've been struggling with this error which is not suggesting me anything.\nThis is the error I receive. Every time I'm trying to access the logs it displays me \"None\". Also, the init() function is a very basic one. It's the one I've found in your tutorials and while I've followed your tutorials I didn't encounter this bug.\n\nscore.py script:\n\n import pandas as pd\n import numpy as np\n import joblib\n import json\n import os\n    \n # Called when the service is loaded\n def init():\n     global model\n     # Get the path to the deployed model file and load it\n     model = joblib.load(Model.get_model_path(model_name='aml_live_model_end'))\n    \n # Called when a request is received\n def run(raw_data):\n     # Get the input data as a numpy array\n     data = np.array(json.loads(raw_data)['data'])\n     # Get a prediction from the model\n     predictions = model.predict(data)\n     # Get the corresponding classname for each prediction (0 or 1)\n     classnames = ['De avizat', 'De analizat']\n     predicted_classes = []\n     for prediction in predictions:\n         predicted_classes.append(classnames[prediction])\n     # Return the predictions as JSON\n     return json.dumps(predicted_classes)\n\n\n\n\n.yaml file\n\n name: aml_live_env\n dependencies:\n - python=3.6.2\n - scikit-learn\n - ipykernel\n - matplotlib\n - pandas\n - pip\n - pip:\n   - azureml-defaults\n   - pyarrow\n\n\n\n\nThe error I receive\n\n Deploying model...\n Tips: You can try get_logs(): https:\/\/aka.ms\/debugimage#dockerlog or local deployment: https:\/\/aka.ms\/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n Running\n 2022-06-17 10:52:16+00:00 Creating Container Registry if not exists.\n 2022-06-17 10:52:16+00:00 Registering the environment.\n 2022-06-17 10:52:17+00:00 Use the existing image.\n 2022-06-17 10:52:17+00:00 Generating deployment configuration.\n 2022-06-17 10:52:18+00:00 Submitting deployment to compute.\n 2022-06-17 10:52:20+00:00 Checking the status of deployment aml-live-service-model..\n 2022-06-17 10:54:07+00:00 Checking the status of inference endpoint aml-live-service-model.\n Failed\n Service deployment polling reached non-successful terminal state, current service state: Failed\n Operation ID: 93d48e89-cb16-4d1c-bbb6-f453acaeaa7f\n More information can be found using '.get_logs()'\n Error:\n {\n   \"code\": \"AciDeploymentFailed\",\n   \"statusCode\": 400,\n   \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n     1. Please check the logs for your container instance: aml-live-service-model. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n     2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n     3. You can also try to run image libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\",\n   \"details\": [\n     {\n       \"code\": \"CrashLoopBackOff\",\n       \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n     1. Please check the logs for your container instance: aml-live-service-model. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n     2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n     3. You can also try to run image libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\"\n     },\n     {\n       \"code\": \"AciDeploymentFailed\",\n       \"message\": \"Your container application crashed. Please follow the steps to debug:\n     1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.\n     2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.\n     3. You can also interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n     4. View the diagnostic events to check status of container, it may help you to debug the issue.\n \"RestartCount\": 5\n \"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n \"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2022-06-17T10:56:57.554Z\",\"exitCode\":111,\"finishTime\":\"2022-06-17T10:57:01.314Z\",\"detailStatus\":\"Error\"}\n \"Events\":\n {\"count\":1,\"firstTimestamp\":\"2022-06-17T10:26:38Z\",\"lastTimestamp\":\"2022-06-17T10:26:38Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\"\",\"type\":\"Normal\"}\n {\"count\":1,\"firstTimestamp\":\"2022-06-17T10:27:42Z\",\"lastTimestamp\":\"2022-06-17T10:27:42Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\"\",\"type\":\"Normal\"}\n {\"count\":10,\"firstTimestamp\":\"2022-06-17T10:28:00Z\",\"lastTimestamp\":\"2022-06-17T10:47:11Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n {\"count\":9,\"firstTimestamp\":\"2022-06-17T10:28:03Z\",\"lastTimestamp\":\"2022-06-17T10:40:46Z\",\"name\":\"Killing\",\"message\":\"Killing container with id a7e717efa63259b36b19bc4951b3f3dcc5f1093177e729c589355a7371353ca3.\",\"type\":\"Normal\"}\n {\"count\":1,\"firstTimestamp\":\"2022-06-17T10:31:33Z\",\"lastTimestamp\":\"2022-06-17T10:31:33Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\"\",\"type\":\"Normal\"}\n {\"count\":1,\"firstTimestamp\":\"2022-06-17T10:32:31Z\",\"lastTimestamp\":\"2022-06-17T10:32:31Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\"\",\"type\":\"Normal\"}\n {\"count\":5,\"firstTimestamp\":\"2022-06-17T10:47:52Z\",\"lastTimestamp\":\"2022-06-17T10:52:09Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n {\"count\":6,\"firstTimestamp\":\"2022-06-17T10:48:26Z\",\"lastTimestamp\":\"2022-06-17T10:52:37Z\",\"name\":\"Killing\",\"message\":\"Killing container with id 2bdec1005a6dd58312e10ab939d88ea08b312771de6573d9b86c5f571104277e.\",\"type\":\"Normal\"}\n \"\n     }\n   ]\n }\n    \n ---------------------------------------------------------------------------\n WebserviceException                       Traceback (most recent call last)\n <ipython-input-17-315dbb5f83ec> in <module>\n      16 service_name = \"aml-live-service-model\"\n      17 service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n ---> 18 service.wait_for_deployment(True)\n      19 print(service.state)\n    \n \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/core\/webservice\/webservice.py in wait_for_deployment(self, show_output, timeout_sec)\n     916                     logs_response = 'Current sub-operation type not known, more logs unavailable.'\n     917 \n --> 918                 raise WebserviceException('Service deployment polling reached non-successful terminal state, current '\n     919                                           'service state: {}\\n'\n     920                                           'Operation ID: {}\\n'\n    \n WebserviceException: WebserviceException:\n     Message: Service deployment polling reached non-successful terminal state, current service state: Failed\n Operation ID: 93d48e89-cb16-4d1c-bbb6-f453acaeaa7f\n More information can be found using '.get_logs()'\n Error:\n {\n   \"code\": \"AciDeploymentFailed\",\n   \"statusCode\": 400,\n   \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n     1. Please check the logs for your container instance: aml-live-service-model. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n     2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n     3. You can also try to run image libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\",\n   \"details\": [\n     {\n       \"code\": \"CrashLoopBackOff\",\n       \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n     1. Please check the logs for your container instance: aml-live-service-model. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n     2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n     3. You can also try to run image libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\"\n     },\n     {\n       \"code\": \"AciDeploymentFailed\",\n       \"message\": \"Your container application crashed. Please follow the steps to debug:\n     1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.\n     2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.\n     3. You can also interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n     4. View the diagnostic events to check status of container, it may help you to debug the issue.\n \"RestartCount\": 5\n \"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n \"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2022-06-17T10:56:57.554Z\",\"exitCode\":111,\"finishTime\":\"2022-06-17T10:57:01.314Z\",\"detailStatus\":\"Error\"}\n \"Events\":\n {\"count\":1,\"firstTimestamp\":\"2022-06-17T10:26:38Z\",\"lastTimestamp\":\"2022-06-17T10:26:38Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\"\",\"type\":\"Normal\"}\n {\"count\":1,\"firstTimestamp\":\"2022-06-17T10:27:42Z\",\"lastTimestamp\":\"2022-06-17T10:27:42Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\"\",\"type\":\"Normal\"}\n {\"count\":10,\"firstTimestamp\":\"2022-06-17T10:28:00Z\",\"lastTimestamp\":\"2022-06-17T10:47:11Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n {\"count\":9,\"firstTimestamp\":\"2022-06-17T10:28:03Z\",\"lastTimestamp\":\"2022-06-17T10:40:46Z\",\"name\":\"Killing\",\"message\":\"Killing container with id a7e717efa63259b36b19bc4951b3f3dcc5f1093177e729c589355a7371353ca3.\",\"type\":\"Normal\"}\n {\"count\":1,\"firstTimestamp\":\"2022-06-17T10:31:33Z\",\"lastTimestamp\":\"2022-06-17T10:31:33Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\"\",\"type\":\"Normal\"}\n {\"count\":1,\"firstTimestamp\":\"2022-06-17T10:32:31Z\",\"lastTimestamp\":\"2022-06-17T10:32:31Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\"\",\"type\":\"Normal\"}\n {\"count\":5,\"firstTimestamp\":\"2022-06-17T10:47:52Z\",\"lastTimestamp\":\"2022-06-17T10:52:09Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n {\"count\":6,\"firstTimestamp\":\"2022-06-17T10:48:26Z\",\"lastTimestamp\":\"2022-06-17T10:52:37Z\",\"name\":\"Killing\",\"message\":\"Killing container with id 2bdec1005a6dd58312e10ab939d88ea08b312771de6573d9b86c5f571104277e.\",\"type\":\"Normal\"}\n \"\n     }\n   ]\n }\n     InnerException None\n     ErrorResponse \n {\n     \"error\": {\n         \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 93d48e89-cb16-4d1c-bbb6-f453acaeaa7f\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: aml-live-service-model. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: aml-live-service-model. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\n\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.\\n\\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.\\n\\t3. You can also interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\\n\\\"RestartCount\\\": 5\\n\\\"CurrentState\\\": {\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"}\\n\\\"PreviousState\\\": {\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2022-06-17T10:56:57.554Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2022-06-17T10:57:01.314Z\\\",\\\"detailStatus\\\":\\\"Error\\\"}\\n\\\"Events\\\":\\n{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2022-06-17T10:26:38Z\\\",\\\"lastTimestamp\\\":\\\"2022-06-17T10:26:38Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2022-06-17T10:27:42Z\\\",\\\"lastTimestamp\\\":\\\"2022-06-17T10:27:42Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":10,\\\"firstTimestamp\\\":\\\"2022-06-17T10:28:00Z\\\",\\\"lastTimestamp\\\":\\\"2022-06-17T10:47:11Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":9,\\\"firstTimestamp\\\":\\\"2022-06-17T10:28:03Z\\\",\\\"lastTimestamp\\\":\\\"2022-06-17T10:40:46Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id a7e717efa63259b36b19bc4951b3f3dcc5f1093177e729c589355a7371353ca3.\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2022-06-17T10:31:33Z\\\",\\\"lastTimestamp\\\":\\\"2022-06-17T10:31:33Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2022-06-17T10:32:31Z\\\",\\\"lastTimestamp\\\":\\\"2022-06-17T10:32:31Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":5,\\\"firstTimestamp\\\":\\\"2022-06-17T10:47:52Z\\\",\\\"lastTimestamp\\\":\\\"2022-06-17T10:52:09Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":6,\\\"firstTimestamp\\\":\\\"2022-06-17T10:48:26Z\\\",\\\"lastTimestamp\\\":\\\"2022-06-17T10:52:37Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id 2bdec1005a6dd58312e10ab939d88ea08b312771de6573d9b86c5f571104277e.\\\",\\\"type\\\":\\\"Normal\\\"}\\n\\\"\\n    }\\n  ]\\n}\"\n     }\n }",
        "Answers":[
            {
                "Answer_creation_time":"2022-06-20T07:11:19.413Z",
                "Answer_upvote_count":0,
                "Answer_body":"@ramr-msft I've tried to use both of the commands that you've mentioned above. Unfortunately they tell me nothing, both of them are displaying me \"None\" and it's not very suggestive honestly.\n\n\nAlso, I've tried to debug it locally. This is the error that I receive:\n\n The environment variable 'AZUREML_MODEL_DIR' has not been set.\n Use the --model_dir command line argument to set it.\n    \n Azure ML Inferencing HTTP server v0.4.11\n    \n    \n Server Settings\n ---------------\n Entry Script Name: score_aml_live.py\n Model Directory: None\n Worker Count: 1\n Worker Timeout (seconds): None\n Server Port: 5001\n Application Insights Enabled: false\n Application Insights Key: None\n    \n    \n Server Routes\n ---------------\n Liveness Probe: GET   127.0.0.1:5001\/\n Score:          POST  127.0.0.1:5001\/score\n    \n Starting gunicorn 20.1.0\n Listening at: http:\/\/0.0.0.0:5001 (17478)\n Using worker: sync\n Booting worker with pid: 17483\n Initializing logger\n 2022-06-20 06:41:02,353 | root | INFO | Starting up app insights client\n logging socket not found. logging not available.\n logging socket not found. logging not available.\n 2022-06-20 06:41:02,358 | root | INFO | Starting up request id generator\n 2022-06-20 06:41:02,358 | root | INFO | Starting up app insight hooks\n 2022-06-20 06:41:02,358 | root | INFO | Invoking user's init function\n 2022-06-20 06:41:02,358 | root | ERROR | User's init function failed\n 2022-06-20 06:41:02,374 | root | ERROR | Encountered Exception Traceback (most recent call last):\n   File \"\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml_inference_server_http\/server\/aml_blueprint.py\", line 201, in register\n     main.init()\n   File \"\/score_aml_live.py\", line 41, in init\n     model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'aml_live_model_end.pkl')\n   File \"\/lib\/python3.8\/posixpath.py\", line 76, in join\n     a = os.fspath(a)\n TypeError: expected str, bytes or os.PathLike object, not NoneType",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-20T07:39:14.62Z",
                "Answer_upvote_count":0,
                "Answer_body":"@MihaiMunteanu-1542 Thanks for the details. Is your files (model) in local file system or in AzureML directory?. Here is document to check the model path fail to debug.\nAlso document to Advance entry script. Still facing an issue please share the notebook.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-11-28T09:38:04.237Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @MihaiMunteanu-1542 @ramr-msft I am also facing the exactly same issue. Are there any tips that you can share with us? Thank you, Roxana.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Register Azure ML Model from DatabricksStep",
        "Question_creation_time":1605264849177,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/162055\/register-azure-ml-model-from-databricksstep.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-databricks"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\nI'm calculating a model while executing a DatabricksStep in an Azure ML Pipeline, save it on my Blob Storage as .pkl file and upload it to the current Azure ML Run using Run.upload_file (). All this works without any problems.\n\nBut as soon as I try to register the model to the Azure ML Workspace using Run.register_model (), the script throws the following error:\n\nUserErrorException: UserErrorException:\nMessage:\nOperation returned an invalid status code 'Forbidden'. The possible reason could be:\n1. You are not authorized to access this resource, or directory listing denied.\n2. you may not login your azure service, or use other subscription, you can check your\ndefault account by running azure cli commend:\n'az account list -o table'.\n3. You have multiple objects\/login session opened, please close all session and try again.\n\n InnerException None\n ErrorResponse \n\n{\n\"error\": {\n\"code\": \"UserError\",\n\"message\": \"\\nOperation returned an invalid status code 'Forbidden'. The possible reason could be:\\n1. You are not authorized to access this resource, or directory listing denied.\\n2. you may not login your azure service, or use other subscription, you can check your\\ndefault account by running azure cli commend:\\n'az account list -o table'.\\n3. You have multiple objects\/login session opened, please close all session and try again.\\n \"\n}\n}\n\nwith the following call stack\n\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/models_client.py in register_model(self, name, tags, properties, description, url, mime_type, framework, framework_version, unpack, experiment_name, run_id, datasets, sample_input_data, sample_output_data, resource_requirements)\n70 return self.\\\n71 _execute_with_workspace_arguments(self._client.ml_models.register, model,\n---> 72 custom_headers=ModelsClient.get_modelmanagement_custom_headers())\n73\n74 @error_with_model_id_handling\n\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/workspace_client.py in _execute_with_workspace_arguments(self, func, args, *kwargs)\n65\n66 def _execute_with_workspace_arguments(self, func, args, *kwargs):\n---> 67 return self._execute_with_arguments(func, copy.deepcopy(self._workspace_arguments), args, *kwargs)\n68\n69 def get_or_create_experiment(self, experiment_name, is_async=False):\n\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_with_arguments(self, func, args_list, args, *kwargs)\n536 return self._call_paginated_api(func, args_list, *kwargs)\n537 else:\n--> 538 return self._call_api(func, args_list, *kwargs)\n539 except ErrorResponseException as e:\n540 raise ServiceException(e)\n\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _call_api(self, func, args, *kwargs)\n234 return AsyncTask(future, _ident=ident, _parent_logger=self._logger)\n235 else:\n--> 236 return self._execute_with_base_arguments(func, args, *kwargs)\n237\n238 def _call_paginated_api(self, func, args, *kwargs):\n\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_with_base_arguments(self, func, args, *kwargs)\n323 total_retry = 0 if self.retries < 0 else self.retries\n324 return ClientBase._execute_func_internal(\n--> 325 back_off, total_retry, self._logger, func, _noop_reset, args, *kwargs)\n326\n327 @classmethod\n\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_func_internal(cls, back_off, total_retry, logger, func, reset_func, args, *kwargs)\n343 return func(args, *kwargs)\n344 except Exception as error:\n--> 345 left_retry = cls._handle_retry(back_off, left_retry, total_retry, error, logger, func)\n346\n347 reset_func(args, *kwargs) # reset_func is expected to undo any side effects from a failed func call.\n\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _handle_retry(cls, back_off, left_retry, total_retry, error, logger, func)\n384 3. You have multiple objects\/login session opened, please close all session and try again.\n385 \"\"\"\n--> 386 raise_from(UserErrorException(error_msg), error)\n387\n388 elif error.response.status_code == 429:\n\n\/databricks\/python\/lib\/python3.7\/site-packages\/six.py in raise_from(value, from_value)\n\nDid anybody experience the same error and knows what is its cause and how to solve it?\n\nBest,\nJonas",
        "Answers":[
            {
                "Answer_creation_time":"2020-12-01T05:26:07.107Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Jonas-4379 Thanks, We have created bug with the product team, we could see It is n't deterministic error. we would recommend to raise a Azure support desk ticket from Help+Support blade from Azure portal. This will help you to share the details securely and work with an engineer who can provide more insights about the issue that if it can be replicated.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":4.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Upgrading Azure Machine Learning Compute Instance (virtual machine)",
        "Question_creation_time":1591430074777,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/32793\/upgrading-azure-machine-learning-compute-instance.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":3,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi,\n\nHow can I safely upgrade the default OS and softwares of a compute instance (Azure Machine Learning)?\n\nThe default compute instance comes with pre-default versions for OS and packages.\n\nFor example, the following are a few which I\u2019ve inspected after spinning on a compute instance:\n1. OS is currently an Ubuntu LTS 16.04 (release date February 28, 2019)\n2. Python version 3.6.9 (release date July 2, 2019)\n3. R version 3.6.3 (release date February 29, 2020)\n\nThe latest stable versions of the above (as of today June 4,2020) are:\n1. Ubuntu 20.04 LTS (release date April 23,2020)\n2. Python version 3.7.7 (release date March 10,2020)\n3. R version 4.0 (release date April 24,2020)\n\nI actually tried upgrading the OS through the command line but it doesn't seem to be stable after the upgrade to Ubuntu LTS 18.04.\nUpgrading RStudio server also fails.\n\nSo I'm not entirely confident whether the usual commands to upgrade work.\nIs there anything I need to do with the repository list to ensure smooth upgrades and updates?\n\nThanks",
        "Answers":[
            {
                "Answer_creation_time":"2020-06-06T08:09:35.703Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nFrom Azure portal, go to the VM page. Under Operations, Select 'Update Management'. Select 'Enable for this VM'. It will take couple of minutes to finish apply settings. Once finished, you may be able to see the missing updates at the same page. Click 'Schedule Update Deployment' > Select the options needed and schedule it as per your convenience\n\nPlease mark as \"Accept the answer\" if the above steps helps you. Others with similar issues can also follow the solution as per your suggestion\n\nRegards,\n\nManu",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-06-09T15:04:40.577Z",
                "Answer_upvote_count":0,
                "Answer_body":"@AfiqCheJohari-9488 Are there any specific steps you followed to upgrade your VM version?\nFrom the documentation of RStudio 20.04 is not in the list of supported operating systems as mentioned here.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-09-27T15:06:06.693Z",
                "Answer_upvote_count":0,
                "Answer_body":"It would be great to have a reliable way to upgrade the Azure ML SDK and its dependencies on such a compute instance (or any existing conda environment for that matter) without having to abandon and recreate it from scratch, also redoing all the extra setup necessary by the user...\n\nIn my experience, just following the standard documentation pip upgrade instruction almost always messes up the conda environment and introduces multiple dependency errors...\nSo it would be great to have an upgrade option that just works.\nAt least to have a valid end-to-end script example in the documentation.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Question about ML output",
        "Question_creation_time":1650351269333,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/817010\/question-about-ml-output.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Dear Support,\n\nI have draft a pipeline as following:\n\n\n\n\n\n\nyou can see it has 2 webservice output,\n\nmay I know where I can see the 2 output and how to use it ? thnaks.",
        "Answers":[
            {
                "Answer_creation_time":"2022-04-20T02:33:37.447Z",
                "Answer_upvote_count":0,
                "Answer_body":"@SeiyaZelinShen-9380 Thanks for the question. Can you please share the sample link that you are trying.\n\nHere is the document for web service output. Did you deploy the inference pipeline, if yes After deployment finishes, you can view your real-time endpoint by going to the Endpoints page.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure endpoint in decimal notation",
        "Question_creation_time":1639603918890,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/665285\/azure-endpoint-in-decimal-notation.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello, I've set up an Azure endpoint and I'm trying to communicate with it using some old software that can only read decimal notation. The scientific notation the endpoint occasionally delivers is breaking it. Is there a way to configure the endpoint to return only decimal notation? Ideally just with the correct header like \"application\/jsonlegacy\" or something?",
        "Answers":[
            {
                "Answer_creation_time":"2021-12-16T06:58:54.83Z",
                "Answer_upvote_count":1,
                "Answer_body":"@JonathanHorton-4850 Returning a decimal value from an endpoint should be possible. I think this depends on the training of the experiment if the ML studio is used. I have an experiment which returns decimals. You can use a similar setup with Apply transformation module or Apply Math operation if using the newer version of the studio.\n\n\n\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Custom Dockerfile on Azure Environment with python poetry",
        "Question_creation_time":1638821054557,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/653688\/custom-dockerfile-on-azure-environment-with-python.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"I am new to docker and environments. This could be basics but i have been trying to install packages in my pyproject.toml file in Dockerfile without success.\n\nI have tried using poetry to export requirements.txt file and using it with the\nEnvironment.from_pip_requirements('requirements.txt') function and a Dockerfile.\n\nBut could there be any elegant solution to use toml file directly for creating a custom environment ?",
        "Answers":[
            {
                "Answer_creation_time":"2021-12-08T16:31:16.963Z",
                "Answer_upvote_count":1,
                "Answer_body":"Thanks for the response, @Ram-msft\nUsing the Dockerfile :\n\n FROM python:3.8-slim-buster\n ENV PYTHONUNBUFFERED=1 \\\n     PYTHONDONTWRITEBYTECODE=1 \\\n     PIP_NO_CACHE_DIR=1 \\\n     PIP_DISABLE_PIP_VERSION_CHECK=1 \\\n     POETRY_VERSION=1.1.7 \\\n     PYLINT_VERSION=2.9.4\n    \n RUN pip install pylint==$PYLINT_VERSION \\\n     && pip install \"poetry==$POETRY_VERSION\" \n    \n COPY pyproject.toml .\/\n RUN poetry config virtualenvs.create false",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-12-07T15:37:01.407Z",
                "Answer_upvote_count":0,
                "Answer_body":"@AntaraDas-4298 Thanks for the question. Can you please share the sample\/document that you are trying. I would recommend to use yml file that is relatively easy to get from pip requirements file\n\nfrom azureml.core import Environment\nfrom azureml.core.conda_dependencies import CondaDependencies\n\nenv = Environment(\u201cmyenv\u201d)\nenv.python.conda_dependencies = CondaDependencies(\u201cmy_yaml_file\u201d)\n\n\n\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-with-custom-image",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Files in gitignore are not excluded in snapshot created by ML pipeline",
        "Question_creation_time":1617897599523,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/349783\/files-in-gitignore-are-not-excluded-in-snapshot-cr.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":0,
        "Question_has_accepted_answer":false,
        "Question_body":"I'm trying to run a pipeline (built via Python SDK), and I want the repo to be snapshotted, because the different modules are called inside the pipeline scripts. The source folder I pass to the pipeline has the following structure:\n\nrepo\n- src\n- data\n- script_step1.py\n- script_step2.py\n- script_step3.py\n- .gitignore\n\n\n\n\nI want the data folder to be ignored in the snapshot, so in my gitignore file I have al line with written \/data\/*, but when I try to run the pipeline I get an error that tells me that the snapshot is too big (I checked the size of the other stuff except for data folder and it is very little)\nI'm not understanding why that happens.\nThanks a lot in advance",
        "Answers":[

        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"how can i retrain the model after a period of time",
        "Question_creation_time":1619232734657,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/370080\/how-can-i-retrain-the-model-after-a-period-of-time.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello everyone, i'm using lambda architecture to build a fraud detection project , i build my model using machine learning in databricks , after saving the model , i load the model in the speed layer to predict the incoming data, i want to know how can i retrain this model using new incoming data from eventhub ??\ndoes the retrain should be in the batch layer ?\nthanks for helping",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-27T06:45:34.227Z",
                "Answer_upvote_count":0,
                "Answer_body":"@NadineBenharrath-4116 Thanks, Please follow the document to retrain the model using the new data.\n\nCurrently Data Drift Monitor (Data Drift->EventGrid->LogicApp->Trigger Pipeline) allows to trigger a pipeline when dataset drift has been detected.\n\nPublic Repo of the architecture and code: https:\/\/github.com\/Microsoft\/MLOps",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-04-27T07:10:26.91Z",
                "Answer_upvote_count":0,
                "Answer_body":"@ramr-msft the problem that i trained my model using databricks and i tracked it with mlflow , i'm not using azure ML because my dataset is imbalanced ?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Where to look for Source Code while implementing Azure Machine learning?",
        "Question_creation_time":1645806024193,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/751130\/where-to-look-for-source-code-while-implementing-a.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am implementing a training pipeline using Azure Machine learning Pipeline architecture. I am interested in looking at the Source code, for example Hyper-drive step class or python-script step class. Where should I look for Source code?",
        "Answers":[
            {
                "Answer_creation_time":"2022-02-25T19:34:48.637Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, it seems you're looking for source code for AzureML Pipelines. You can find it here. Also, here's an example notebook that demonstrates the use of HyperDriveStep.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Accessing Data from azure container from a notebook",
        "Question_creation_time":1617804754800,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/348022\/accessing-data-from-azure-container-from-a-noteboo.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hey there,\n\ni have a question concerning the navigation in the file system of the azure cloud.\n\nHow can i access data (like images) from my container through a azure notebook?\nCan i navigate in the cloud like in the file system of my local machine?\n\nBest regards and thank you in advance!",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-04T00:17:58.567Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nThere are several ways to get access Juypter Notebook from Azure offerings as bellow:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/notebooks\/quickstart-export-jupyter-notebook-project#use-notebooks-in-visual-studio-code\n\nBut unfortunately, I don't think any of them supports clickable UI as File system in UI. But you can call you data in code, it is the same as normal.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/storage\/blobs\/authorize-data-operations-portal\n\nOne way you can manage your data as clickable UI as File system is you can go to data blob\/ container directly.\n\nAlso, please feel free to share the scenario you want to do this, I will help to forward this feedback to engineering group for future development.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Anyways to have multiple webservice output?",
        "Question_creation_time":1653904138797,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/869627\/anyways-to-have-multiple-webservice-output.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Is training two web service at the same time doable in studio ? Since I want to train with multiple models but it seems only one would work",
        "Answers":[
            {
                "Answer_creation_time":"2022-05-30T22:54:40.947Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @carter-5275\n\nThanks for reaching out to us. If you are asking about studio classic, for your question, quick answer is Yes.\n\nWhat you need to do is, using the \"save as train model\" function to save your models so that you could use it directly in the future. Both studio classic and studio can do it.\n\nThen you can pull all saved models you want to use to your structure so that you can have multi-webservice directly in the studio.\n\nIf you are asking studio, the answer is yes as well. What you need to do is only drag another webservice output directly to you structure.\n\nI hope this helps.\n\nRegards,\nYutong\n\n\n\n\n-Please kindly accept the answer if you feel helpful, thanks.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"\" Object of type 'int64' is not JSON serializable\" when running automl time series",
        "Question_creation_time":1599571606537,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/89272\/34-object-of-type-39int6439-is-not-json-serializab.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"I am trying to use the Online ML studio and running an \"Automated ML\". I upload my dataset (see simple example below) which passes fine and then I start a automl experiment selecting \"time series forecasting\". I select all the revelant fields and everything starts without any issues.\n\nShortly after the process fails and the error given is:\n\n\"User error: User program failed with TypeError: Object of type 'int64' is not JSON serializable\"\n\nDigging into the logs the only log with any useful information appears to be the driver_log which has these lines with no more detail about the error unless the INFO about streaming is actually an error not information:\n\n2020-09-08 11:17:01.734 - INFO - Successfully retrieved data using dataprep.\n2020-09-08 11:17:01.734 - INFO - Streaming is not conducive due to incompatible settings. Reason[s]: [Forecasting is not supported, 'n_cross_validations' was non-empty]\n2020-09-08 11:17:01.734 - INFO - Service responded with streaming disabled\n2020-09-08 11:17:01.734 - INFO - Inferring type for feature columns.\n2020-09-08 11:17:12.669 - INFO - Error in setup_wrapper.\n2020-09-08 11:17:12.670 - ERROR - Marking Run AutoML_f5a7c759-653c-4314-98a9-c2afbcecff55_setup as Failed.\n\n\n\n\nCan anyone suggest an answer or recommend some ways to debug this?\n\n][1]",
        "Answers":[
            {
                "Answer_creation_time":"2020-09-08T13:41:33.393Z",
                "Answer_upvote_count":0,
                "Answer_body":"found the more detailed stacktrace\n\n\"debugInfo\": {\n\"type\": \"TypeError\",\n\"message\": \"Object of type 'int64' is not JSON serializable\",\n\"stackTrace\": \" File \\\"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/brian-ml-learning\/azureml\/automl_f5a7c759-653c-4314-98a9-c2afbcecff55_setup\/mounts\/workspaceblobstore\/azureml\/AutoML_f5a7c759-653c-4314-98a9-c2afbcecff55_setup\/azureml-setup\/context_manager_injector.py\\\", line 166, in execute_with_context\\n runpy.run_path(sys.argv[0], globals(), run_name=\\\"main\\\")\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/runpy.py\\\", line 263, in run_path\\n pkg_name=pkg_name, script_name=fname)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/runpy.py\\\", line 96, in _run_module_code\\n mod_name, mod_spec, pkg_name, script_name)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/runpy.py\\\", line 85, in _run_code\\n exec(code, run_globals)\\n File \\\"setup_AutoML_f5a7c759-653c-4314-98a9-c2afbcecff55.py\\\", line 731, in <module>\\n result = setup_run()\\n File \\\"setup_AutoML_f5a7c759-653c-4314-98a9-c2afbcecff55.py\\\", line 725, in setup_run\\n prep_type=preparation_type\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/runtime\/_remote_script.py\\\", line 578, in setup_wrapper\\n setup_run._fail_with_error(e)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/run.py\\\", line 1258, in _fail_with_error\\n logging_utilities.log_traceback(exception, logger)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/site-packages\/azureml\/automl\/core\/shared\/logging_utilities.py\\\", line 212, in log_traceback\\n error_msg_without_pii = _get_pii_free_message(exception)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/site-packages\/azureml\/automl\/core\/shared\/logging_utilities.py\\\", line 140, in _get_pii_free_message\\n return exception.get_pii_free_exception_msg_format()\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/site-packages\/azureml\/automl\/core\/shared\/exceptions.py\\\", line 151, in get_pii_free_exception_msg_format\\n error_dict = json.loads(self.serialize_json())\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/site-packages\/azureml\/common\/exceptions.py\\\", line 181, in serialize_json\\n return json.dumps(error_ret, indent=indent)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/json\/init.py\\\", line 231, in dumps\\n return default_encoder.encode(obj)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/json\/encoder.py\\\", line 199, in encode\\n chunks = self.iterencode(o, one_shot=True)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/json\/encoder.py\\\", line 257, in iterencode\\n return iterencode(o, 0)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/json\/encoder.py\\\", line 180, in default\\n o.class.name)\\n\",\n\"innerException\": null,\n\"data\": null,\n\"errorResponse\": null\n}",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":3.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Failure when submitting pipe line",
        "Question_creation_time":1598970144413,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/83451\/failure-when-submitting-pipe-line.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"Doing exam training using my free subscription (Exam DP-100: Designing and Implementing a Data Science Solution on Azure).\nGot in to problem in the following mudule, https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/explore-data.\nGets following error in my pipe line in Microsoft Azure Machine Learning:\nUnable to get image details : Unable to fetch workspace resources: Not Found response body: {\"error\":{\"code\":\"ResourceNotFound\",\"m",
        "Answers":[
            {
                "Answer_creation_time":"2020-09-03T11:21:56.257Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @JohanLv-5811 - Did you post the complete error details above? If possible, check that you are referencing the right ML workspace resource.\nJust in case you haven't seen this already, also recommend checking out these troubleshooting tips on creating and managing workspaces..",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-12-16T21:37:57.267Z",
                "Answer_upvote_count":0,
                "Answer_body":"I have finally solved the problem. Container registry of Workspace was failed. Solved once I renew.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Microsoft Azure Machine Learning Studio - Error durind Deploy <Response [502]> Automated ML",
        "Question_creation_time":1646161278517,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/755239\/microsoft-azure-machine-learning-studio-error-duri.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-02T07:00:37.88Z",
                "Answer_upvote_count":0,
                "Answer_body":"@FernandoJosRibeiroJnior-4000 I think the following changes are required in the above code to get it working with the endpoint.\n\nChange the line where the input JSON is created.\n\nFrom:\n\n input_json = json.dumps({\"Inputs\":{\"data\": x}})\n\nTo:\n\n input_json = json.dumps({\"data\": x})\n\n\n\nAlso change, the following to ensure result is loaded correctly and formatted in the print statement.\n\nFrom:\n\n y = response.json()\n\n\n\nTo:\n\n y = json.loads(response.json())\n\n\n\n\n\nThis should print the result correctly, as seen below:\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Passing data from Azure Data Factory into Azure ML",
        "Question_creation_time":1626444050490,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/479034\/passing-data-from-azure-data-factory-into-azure-ml.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-data-factory",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"In Azure ML the input data has to be defined as a Dataset (to create a pipeline). In my code I am passing datasets with the following syntax: input_data = Dataset.File.from_files(datapath)\n\nI would like to change this datapath as an input parameter from Data Factory (for example via PipelineParamater), so I can apply the same Data Factory pipeline for different datasets. However, in Data Factory you can only pass string as a parameter, not a DataPath.\n\nWhat is the solution around this?",
        "Answers":[
            {
                "Answer_creation_time":"2021-07-19T11:14:55.843Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @IlzeAmanda-9677 ,\n\nThank you for posting your query on Microsoft Q&A Portal and sharing clarifications on ask.\n\nUnfortunately, we cannot create user defined types in Azure data factory at this moment.\n\nBut, I will encourage you to log your feedback using below link. Product team will actively monitor feedback there and consider them for future releases. Thank you.\nhttps:\/\/feedback.azure.com\/forums\/270578-data-factory\n\nHope this will help.\n\nPlease accept an answer if correct. Original posters help the community find answers faster by identifying the correct answer. Here is how.\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":13.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Can machine learning rewrite\/recognize text to one truth",
        "Question_creation_time":1604082069767,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/146531\/can-machine-learning-rewriterecognize-text-to-one.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi there,\n\nMy dataset has a lot of productnames, all the product of the shops are not written by the same.\nSo i want azure can recognize if it's the same:\n\nSo if the productgroup is X and productname looks like\/contains tomato. The product is tomato.\nExample: Tomatoes, tomato, bunch of tomatoes, a bag of tomatoes, small tomatoes = new colom tomato.\n\nHopefully someone can help me with this?\n\nThanks a lot.",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-02T09:51:08.223Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Borget-8487 Thanks for the details. With a variety of data inputs, Can you try fuzzy matching\/regex\u2019s or Azure Search would be a complete Information Retrieval engine. Azure Search works well for this.\nbut using full Lucene syntax you can do fuzzy and proximity search.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/search\/search-query-lucene-examples",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to specify do not allow reuse in Azure Machine Learning designer",
        "Question_creation_time":1617640132493,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/344626\/how-to-specify-do-not-allow-reuse-in-azure-machine.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":5,
        "Question_has_accepted_answer":true,
        "Question_body":"Is there a way in the AML designer to set a pipeline and\/or specific step to now allow reuse between runs? I've seen quite a few posts on how to do this in code, but I can't seem to find a way to set that property in the designer.",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-06T01:12:37.013Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nUse the following steps to update a module pipeline parameter:\n\nAt the top of the canvas, select the gear icon.\nIn the Pipeline parameters section, you can view and update the name and default value for all of your pipeline parameter.\n\n\n\n\nHope this helps. Thanks.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-04-20T18:43:02.643Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thanks Youtong. Unfortunately, that doesn't seem to be working for me. I tried to add that as a pipeline parameter, but when I go to submit the pipeline again, it just reused the output from the prior run for each module. Here is an example for the first step where I set the Train Dataset. As you can see, it's reusing the dataset.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-04-20T19:11:29.31Z",
                "Answer_upvote_count":0,
                "Answer_body":"Yutong,\nPlease disregard my prior email. I went back and recreated all of the pipeline parameters and now the allow_reuse is working as you described. I must have made a typo or some other error the first time around.\n\nThank you for this solution!",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-29T08:45:01.937Z",
                "Answer_upvote_count":0,
                "Answer_body":"@YutongTie-MSFT Hi I experience the exact same issue (commented in the initial post above with screenshots)\nI recreated all the queries and and used the parameter correnctly (i think) but it keeps getting ignored. Its kind of time critial for me. How can I get this to work?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-09T07:06:40.9Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi. I resolved this by checking the 'Regenerate Output' option for a root component.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Machine Learning - Uses invalid Pytorch version when training",
        "Question_creation_time":1629119160593,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/515579\/azure-machine-learning-uses-invalid-pytorch-versio.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi, I am training my models via Azure Machine Learning.\n\nOn other day, my training is running with GPU support, however today I found my training is running on a CPU.\nI'm not modified training environment, only training script was modified.\nMy computing cluster is NC6v3 - have a GPU.\n\nI investigate a situation, and I found training script is running on PyTorch 1.6.0.\nOn other day, it ran on Pytorch 1.8.1.\nI think my \"don't use GPU\" problem is caused by the situation that CUDA toolkit version is not suitable for Pytorch version.\n\nThen, I output a installed package to the log.\nThe log says 'Pytorch 1.8.1 was installed, however uses 1.6.0'.\nI confused by this weird circumstances.\nCan someone tell me the solution?\n\n<My code snippet>\n<<conda_dependencies.yaml>>\n\nchannels:\n- conda-forge\n- pytorch\n- nvidia\ndependencies:\n- python=3.8.10\n- mesa-libgl-cos6-x86_64\n- cudatoolkit=11.1\n- pytorch==1.8.1\n- torchvision==0.9.1\n- tqdm\n- scikit-learn\n- matplotlib\n- pandas\n- pip < 20.3\n- pip:\n- azureml-defaults\n- opencv-python-headless\n- pillow==8.2.0\n\n<<Environment definition>>\nenvironment_definition_file = experiment_dir \/ 'conda_dependencies.yaml'\nenvironment_name = 'pytorch-1.8.1-gpu'\nbase_image_name = 'mcr.microsoft.com\/azureml\/openmpi4.1.0-cuda11.0.3-cudnn8-ubuntu18.04'\nenvironment = Environment.from_docker_image(environment_name, base_image_name, conda_specification = environment_definition_file)\ndocker_run_config = DockerConfiguration(use_docker=True)\n\nscript_run_config = ScriptRunConfig(\nsource_directory = experiment_dir,\nscript = SCRIPT_FILE_NAME,\narguments = arguments,\ncompute_target = compute_target,\ndocker_runtime_config = docker_run_config,\nenvironment = environment)\n\n<<Output a log in the training script>>\nimport torch\nimport pip\n\npip.main(['list'])\nprint(f'PyTorch version: {torch.version}')\n\n<My logs>\nPackage Version\n\n\nadal 1.2.7\napplicationinsights 0.11.10\n(omission)\ntorch 1.8.1\ntorchvision 0.9.0a0\n(omission)\n\nPyTorch version: 1.6.0",
        "Answers":[
            {
                "Answer_creation_time":"2021-08-16T23:24:59.363Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for reaching out. These are the supported versions for PyTorch. Please refer to this document for creating a custom environment. As shown, you'll need to use versions <= 1.6.0. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-08-20T10:33:00.493Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, GiftA-MSFT\n\nThank you for your reply.\nI understand that AML supports Pytorch <= 1.6.0.\n\nI hope AML supports Pytorch 1.8.x at early days.\n\n\n\n\nSincerely,",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How long does it take to use a resource after you creat it?",
        "Question_creation_time":1645195183417,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/741883\/how-long-does-it-take-to-use-a-resource-after-you.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"I cannot see my machine learning resource I created.\nAfter you create a resource under the resource group, how long does it take to actually see it and start using it?",
        "Answers":[
            {
                "Answer_creation_time":"2022-02-18T23:03:49.903Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for reaching out. The creation process normally takes a few mins to complete. Are you sure that you're looking at the correct resource group? You can also check the notification icon at the top of Azure portal to confirm deployment status.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-02-19T05:14:51.103Z",
                "Answer_upvote_count":0,
                "Answer_body":"Please open the RG to see the resource you created is available under it.\n\nAlso try to check the Deployments tab to see if the deployment of that resource was successful\n\n\n\n\n\nPlease don't forget to Accept Answer and Up-vote if the response helped -- Vaibhav",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Clean Up instructions at the end of the module to stop compute resources.",
        "Question_creation_time":1643823950947,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/720158\/clean-up-instructions-at-the-end-of-the-module-to.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-labservices",
            "azure-data-science-vm"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello,\n\nI am currently doing cloudskillschallenge for getting certified in Azure Data Scientist course and I came across a point in Module 6 : \"Use automated machine learning in Azure Machine Learning\" that says \"After completing each module, be sure to follow the Clean Up instructions at the end of the module to stop your compute resources. Stopping your compute ensures your subscription won't be charged for compute resources.\"\n\nI have opted for the free trial in Azure portal and would like to know how to do the said process of removing the instructions.\n\n\n\n\nRegards,\nTuhin",
        "Answers":[
            {
                "Answer_creation_time":"2022-02-02T23:03:54.763Z",
                "Answer_upvote_count":0,
                "Answer_body":"@TuhinDas-5095\n\nHello,\n\nThank for reaching out to us. Please see below guidance about how to do the Clean Up for resource.\n\nStop Compute Instance:\nIf you're not going to use it now, stop the compute instance:\n\nIn the studio, on the left, select Compute.\n\n\nIn the top tabs, select Compute instances\n\n\nSelect the compute instance in the list.\n\n\nOn the top toolbar, select Stop.\n\nDelete all resources\nIf you don't plan to use any of the resources that you created, delete them so you don't incur any charges:\n\nIn the Azure portal, select Resource groups on the far left.\n\n\nFrom the list, select the resource group that you created.\n\n\nSelect Delete resource group.\n\n\n\nEnter the resource group name. Then select Delete.\n\nMore information please see below document:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/quickstart-create-resources#clean-up\n\nHope it helps. Please let us know if you have more questions.\n\nPlease kindly accept the answer if you feel it's helpful.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"azure machine learning SDK",
        "Question_creation_time":1654035149473,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/872050\/azure-machine-learning-sdk.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"How to import data not by passing it as an argument,\nI do not want to do as the tutorial https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-with-datasets?source=docs",
        "Answers":[
            {
                "Answer_creation_time":"2022-06-01T17:54:59.667Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @benwu-8989\n\nThanks for reaching out to us, there is the code sample from engineering team\n\n from azureml.core import ScriptRunConfig\n    \n input_data=titanic_ds.as_named_input('input_data').as_mount()\n src = ScriptRunConfig(source_directory=script_folder,\n                       script='train_titanic.py',\n                       compute_target=compute_target)\n src.run_config.data = {input_data.name: input_data }\n # Submit the run configuration for your training run\n run = experiment.submit(src)\n run.wait_for_completion(show_output=True)  \n\n\n\nIn your script, you can get the mounted path via environment variable, which is the value you specified in as_named_input. For the sample code above, the environment variable will be input_data.\n\nI hopet this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Auto ML forecasting - dependent variables",
        "Question_creation_time":1613448096113,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/274229\/azure-auto-ml-forecasting-dependent-variables.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi, I am trying to use Azure auto ML for forecasting. The dataset has a date_time column, a target variable and other columns that affect the target variable. I have deployed the model as a web service. But I am finding it hard to use the service\/model for forecasting future frames. Let's say I need to forecast for the next 4 hours (data frequency is 5 minutes), but the model is asking for other column inputs as well. Can you please help me to resolve this?\nTIA,\nRajesh",
        "Answers":[
            {
                "Answer_creation_time":"2021-02-16T16:33:58.797Z",
                "Answer_upvote_count":0,
                "Answer_body":"@RajeshkumarMourya-0547 Thanks for the question. Can you please add more details about the use case that you are trying. Here is the docs\/samples for Automated ML forecasting enables businesses to forecast revenue, inventory, sales, or customer demand. Customers can run Automated ML experiments by using a no-code UI experience or a code-first Python SDK experience and sample Jupyter Notebooks depending on their expertise.\nDocumentation: HTTPS:\/\/AKA.MS\/AUTOMLFORECAST",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Missing principal component analysis module in Azure ML Designer",
        "Question_creation_time":1614943157500,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/300776\/missing-principal-component-analysis-module-in-azu.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi, I cannot find the Principal Component module in Azure ml designer. For the classic ML studio version it used to be under the data transformation group of transformations but seems to be no longer there. Am I missing something? Thanks",
        "Answers":[
            {
                "Answer_creation_time":"2021-03-05T19:36:26.153Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, it is under Anomaly Detection drop down menu.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML - Managed Identity for Compute Instance",
        "Question_creation_time":1637143820660,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/630520\/azure-ml-managed-identity-for-compute-instance.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-managed-identity"
        ],
        "Question_upvote_count":2.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"We need to connect Azure Data Lake Storage Gen2 to Azure Machine Learning by means of a datastore. For security reasons we do not want to provide the credential-based authentication credentials (service principal or SAS token). Instead we want to connect with identity based access.\n\nThe problem we face is that we are not able to assign a managed identity to a compute instance, so we can connect from notebooks to the Data Lake. In the documentation is explained how to assign a managed identity to a cluster, but we need the same for the compute instance, as it is the only way to run commands directly from the notebook.\n\nIs there a way to assign managed identity to an Azure Machine Learning Compute Instance? Otherwise, we would like to know the best approach to overcome this issue, considering that we do not want to introduce the credentials in the code.",
        "Answers":[
            {
                "Answer_creation_time":"2021-11-17T13:54:33.153Z",
                "Answer_upvote_count":1,
                "Answer_body":"@Nimbeo-7089 Thanks for the question. Currently It\u2019s not supported yet to assign managed identity to an Azure Machine Learning Compute Instance, you\u2019d need to use credential-based access. We have forwarded to the product team to support in the near future.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Error in init() function during azurel ML deployment due to model path definition",
        "Question_creation_time":1650517247760,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/820362\/error-in-init-function-during-azurel-ml-deployment.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hello Team,\n\nWe are trying to deploy a model to Azure ML workspace containing a saved model & One Hot Encoded joblib file.\nWe are facing issue in init() function.\n\nPlease find the below error message:\n\n\"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\n\n\n\nPFB screenshot of scoring file:",
        "Answers":[
            {
                "Answer_creation_time":"2022-04-29T15:27:10.893Z",
                "Answer_upvote_count":0,
                "Answer_body":"@SahanaGurumurthyAccentureInternati-9832 Thanks, I think the problem is that you rely on AML background process to automatically upload content under .\/outputs to AML workspace.\nBut when the upload is not complete and we immediately call run.register_model which takes the content from AML workspace then the error will happen.\nTo avoid that situation, you can do it like this:\n- Persist model (joblib.dump) to a custom folder other than outputs\n- Manually run upload_file to upload the model AML workspace. Name the destination same name with your model file.\n- Then run run.register_model.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Group Categorical Data module missing in Designer, how to reduce number of levels?",
        "Question_creation_time":1620183260377,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/383026\/group-categorical-data-module-missing-in-designer.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":false,
        "Question_body":"Hi there,\n\nI'm working through a tutorial on reducing the number of levels of a categorical variable before using the \"Convert to Indicator Values\" module. In the tutorial, the presenter is using the classic studio which has a module called \"Group Categorical Data\". Unfortunately, I'm using ML Designer and it doesn't have that module.\n\nIs there an easy workaround to reduce the number of categorical levels in Designer before using the Convert to Indicator Values module?\n\nThanks kindly,",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-06T03:47:55.663Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for your feedback. Based on further exploration and confirmation from the product team, it seems Designer does not currently support 'Group Categorical Data' module. The recommendation is to use Execute Python\/R Script module to perform custom data transformations. Sorry for any inconvenience.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Response 502 error in Azure Machine Learning Studio Notebook",
        "Question_creation_time":1643768437050,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/718999\/response-502-error-in-azure-machine-learning-studi.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":false,
        "Question_body":"I copied over code from my training course into the Notebook in Azure Machine Learning Studio. After I run the code, I get the error - <Response [502]>. Please help",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-04T16:26:08.893Z",
                "Answer_upvote_count":1,
                "Answer_body":"@VATSALDANI-4609 Another customer with similar issue posted this solution on a different thread. You could try this and check if it works for you.\n\nThe problem come from lack of GlobalParameters in the next sentence.\ninput_json = json.dumps({\"Inputs\":{\"data\": x}, \"GlobalParameters\": 1.0})\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-03-10T08:37:26.92Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi,\nSolution #input_json = json.dumps({\"Inputs\":{\"data\": x}, \"GlobalParameters\": 1.0})\" worked for me!\n\/\/Harald",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML workspace blob structure \/ Can I safely delete these blobs?",
        "Question_creation_time":1647500925610,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/775834\/azure-ml-workspace-blob-structure-can-i-safely-del.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello,\n\nI am trying to figure out the folder structure of Azure ML workspace in my storage account.\nI want to be able to delete old pipeline runs and experiments that have piled up in my workspace directly from Azure Storage Explorer without breaking the system.\nMy datastores and folder structure are as follows:\n\nDatastore: workspaceartifactstore\nBlob container: azureml\nFolder structure:\n\u251c\u2500 ComputeRecord\n\u251c\u2500 Dataset\n\u251c\u2500 ExperimentRun\n\u251c\u2500 LocalUpload\n\nDatastore: workspaceblobstore (Default)\nBlob container: azureml-blobstore-(a series of numbers)\nFolder structure:\n\u251c\u2500 azureml\n\u2502 \u251c\u2500\u2500 (a series of numbers)-setup\n\u2502 \u2502 \u251c\u2500\u2500 _tracer.py\n\u2502 \u2502 \u251c\u2500\u2500 azureml_globals.py\n\u2502 \u2502 \u251c\u2500\u2500 context_managers.py\n\u2502 \u2502 \u251c\u2500\u2500 job_prep.py\n\u2502 \u2502 \u251c\u2500\u2500 log_history_status.py\n\u2502 \u2502 \u251c\u2500\u2500 request_utilities.py\n\u2502 \u2502 \u251c\u2500\u2500 run_token_provider.py\n\u2502 \u2502 \u251c\u2500\u2500 utility_context_managers.py\n\u2502 \u251c\u2500\u2500 (another series of numbers)-setup\n\u2502 \u2502 \u251c\u2500\u2500 sames files as above\n\nIt would help if I understood what does each of these containers actually store.\nI already tried to delete all blobs stored in 'workspaceblobstore', but it didn't remove any pipeline or experiment from ML Studio.\nI have a few datasets registered in my workspace, and I don't want to delete them (nor unregister them).\n\nCan I set a data retention policy on both containers in order to delete old blobs?\nCan I safely delete the blobs (folders) stored in 'workspaceartifactstore' too? Will they be recreated automatically when I run a new experiment?\nWhy are there two separate 'azureml' and 'azureml-blobstore-(a series of numbers)' containers? Is it possible to merge them?\n\nThanks.\n\nThank you.",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-17T14:52:56.467Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for reaching out. I've worked on a similar inquiry and the advise is to not delete data stored in default datastore to avoid weird errors. The option to easily delete experiment runs is on the roadmap. Here's a similar thread. Feel free to raise and track feature request on ideas portal.\n\nAccording to documentation, when you create a workspace, an Azure blob container and an Azure file share are automatically registered as datastores to the workspace. They're named workspaceblobstore and workspacefilestore, respectively. The workspaceblobstore is used to store workspace artifacts and your machine learning experiment logs. It's also set as the default datastore and can't be deleted from the workspace. The workspacefilestore is used to store notebooks and R scripts authorized via compute instance.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    }
]