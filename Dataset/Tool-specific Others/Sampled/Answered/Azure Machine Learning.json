[
    {
        "Question_title":"Cancel all child runs in Azure ML",
        "Question_creation_time":1649253299717,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/802549\/cancel-all-child-runs-in-azure-ml.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"How to I properly cancel all child runs in an Azure ML experiment? When I use the code below as expected from documentation, I get an error. \"RunConfigurationException:\nMessage: Error in deserialization. dict fields don't have list element type information. field=output_data, list_element_type=<class 'azureml.core.runconfig.OutputData'>...} with exception init() missing 2 required positional arguments: 'datastore_name' and 'relative_path'\"\n\nrun = Run.get(ws, 'run-id-123456789')\n\nfor child in run.get_children():\nprint(child.get_details())\ntry:\nchild.cancel()\nexcept Exception as e:\nprint(e)\ncontinue\n\nThe datasets and runs were configured properly because they run just fine.",
        "Answers":[
            {
                "Answer_creation_time":"2022-05-02T15:52:35.547Z",
                "Answer_upvote_count":0,
                "Answer_body":"You should cancel all the children run by canceling the parent.\n\nAny benefit to cancel child once a time? Just curious",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Does the \"Estimated monthly costs\" for Azure Machine Learning in the Price Calculator include all other non-compute \"additional resources\" created in the workspace",
        "Question_creation_time":1609267518950,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/213635\/does-the-34estimated-monthly-costs34-for-azure-mac.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"When trying to use the Azure Pricing estimate in the Azure Pricing Calculator, the \"Estimated monthly costs\" seems to include but also far exceeds the compute cost. Does this Estimated Monthly cost include the other resources that get created?\neg. Azure Container Registry Basic account, Azure Block Blob Storage (general purpose v1), Key Vault\n\nThank you\nPeter",
        "Answers":[
            {
                "Answer_creation_time":"2020-12-29T23:51:49.057Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi Peter.\n\nThanks for reaching out. I tried your selections but I don't have the same service as you. Have you selected other services in you calculator?\n\nFor your question, the estimated price is only for Azure Machine Learning Service. You need to select all services you need in the calculator like below:\n\n\nPlease note I only use random number for the example.\n\nFrom the number I guess you have selected 2 Machine Learning Services and also other services since they added to your basket when you clicked them, you can click the button to see what you have all as below.\n\n\nAlso you are selecting Reservation service, detail: https:\/\/docs.microsoft.com\/en-us\/azure\/cost-management-billing\/reservations\/save-compute-costs-reservations\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-01-07T20:58:48.993Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thank you Yutong.\nI see now that the other services in the calculator caused this discrepency.\n\nthank you so much",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Machine Learning - error during the creation Create a control script",
        "Question_creation_time":1643753509637,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/718873\/azure-machine-learning-error-during-the-creation-c.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello, I am reproducing this tutorial https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-hello-world \/ Create a control script. The next observations appear in the console.\n\nI will thank you if some ideas are shared with me to face this issue.\n\nRegards",
        "Answers":[
            {
                "Answer_creation_time":"2022-02-02T08:04:16.33Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Anth0nyCamp0s I believe the error is because in the config command you are using the script parameter hello.py which is in .\/src directory but because you are already in .\/src directory on the terminal and the source_directory parameter also mentions to use .\/src as the path to the file the following error is indicated in the message.\n\n\n\n\nIf you navigate back to get-started directory in your terminal and run the script run-hello.py your experiment should be created successfully.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"VBA And Azure Machine Learning Excel Add In",
        "Question_creation_time":1610149745593,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/224491\/vba-and-azure-machine-learning-excel-add-in.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi! I wanted to see if VBA and Azure Machine Learning Excel Add In can be connected to each other. Are there any way to code VBA (use VBA) for controlling or altering Azure Machine Learning Excel Add In? I have used Azure Machine Learning to rate candidate feedback as negative or positive, but it has like a 75 -80% success rate - there are still a good chunk of comments that are rated wrong. However, it is still an amazing tool that I want to use v- I was just wondering if I can increase the accuracy of it somehow by creating a VBA code that connects it to Azure Machine Learning where I can add words related to negative responses or vice versa for positive response to increase the accuracy.",
        "Answers":[
            {
                "Answer_creation_time":"2021-01-09T03:09:29.647Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, we currently don't support VBA and Azure ML Excel add-in integration. You'll need to apply ML techniques for improving your model and re-deploy your model.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML pipeline designer export",
        "Question_creation_time":1668149568060,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1085047\/azure-ml-pipeline-designer-export.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hey,\nIs there any way to export the ML Pipeline as Template\/PNG\/Code ?",
        "Answers":[
            {
                "Answer_creation_time":"2022-11-11T08:53:54.877Z",
                "Answer_upvote_count":1,
                "Answer_body":"@its-kumar The designer pipelines cannot be exported to code or a template currently.\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"machine learning server",
        "Question_creation_time":1610574178773,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/229665\/machine-learning-server.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi,\n\nI am not able to use my Jupyterlab and Jupyter Notebook. It cannot connect to a Kernel.\n\nWill this problem be solved when I uninstall Anaconda and install Microsoft Machine Learning Server.\n\nThanks,\n\nNaveen",
        "Answers":[
            {
                "Answer_creation_time":"2021-01-13T23:52:37.883Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi, I'm assuming you're using your own development environment. I found some troubleshooting steps that may be helpful. Furthermore, Azure Machine Learning Server is an enterprise software that provides the tools for performing data science tasks. You can review Azure ML Server and other options to determine which option best suits your data science scenario. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"What is the best way to deploy my machine learning model using GPUs, specifically as a web based API?",
        "Question_creation_time":1630916125883,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/541074\/what-is-a-the-best-way-to-deploy-my-machine-learni.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-functions",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I am trying to find the best way to run my machine learning models on GPUs for inference as an http request. Do Azure functions support GPUs? if not, what are other options I can look into?\n\nnote: I also want to use packaged models, not necessarily ones of my own creation (such as easyOCR for python)",
        "Answers":[
            {
                "Answer_creation_time":"2021-09-06T09:42:39.623Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi,\n\nIf you need GPU support on ML inference the only supported option is the Azure Kubernetes Service as stated in this documentation\n\nFor guidance on deploying an ML model to AKS, please refer to this documenation on deploying to AKS",
                "Answer_comment_count":4,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":14.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Datadrift in Azure ML SDK v2",
        "Question_creation_time":1657283475557,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/919651\/datadrift-in-azure-ml-sdk-v2.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I can't see a data drift module anywhere in v2 of the Azure ML Python SDK. Is this missing or what's the deal? If so, are there any plans of bringing it into v2?",
        "Answers":[
            {
                "Answer_creation_time":"2022-07-20T10:02:04.113Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @SH-3152\n\nI have a good news for you, I just got confirmation from product team, the datadrift function will be in SDK V2 for sure. But for now we don't have an exact date for when. I have forwarded this feedback to product group and we hope we can bring this feature in near future.\n\n\n\n\nI hope this helps.\n\n\n\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Preparing ML object detction dataset for deep learning in PyTorch or similar",
        "Question_creation_time":1607567444300,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/192973\/preparing-ml-object-detction-dataset-for-deep-lear.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":2.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"The intent of what I'm trying to achieve is:\n\nExport data labelling project as a Dataset\n\n\nConsume the Dataset in a notebook (converting to a Pandas dataframe)\n\n\nPerform a custom train \/ test split that maintains particular file groupings\n\n\nRegister the resulting training and testing dataframes as Datasets\n\n\nUse these Datasets to train and test a custom object detection model\n\n\n\n\nI need help in preparing the data for that final step. I'm familiar with different deep learning libraries, but have never implemented them in the Azure environment before. I've managed to complete 1 to 4. For step 4, I ended up writing the data to csv files and uploading these to the datastore.\n\n # define path for training data file and create new delimited file\n train_path = '.\/data\/train.csv'\n train_dataframe.to_csv(train_path, sep = ';', index = False)\n    \n # repeat for testing\n test_path = '.\/data\/test.csv'\n test_dataframe.to_csv(test_path, sep = ';', index = False)\n    \n # get the datastore to upload prepared data\n datastore = Datastore.get(ws, datastore_name='learningdata')\n    \n # upload the local files from src_dir to the target_path in datastore\n datastore.upload(src_dir='data', target_path='train-test', overwrite=True)\n    \n # create and register training dataset from datastore files\n training_ds = Dataset.Tabular.from_delimited_files(path = [(datastore, 'train-test\/train.csv')], separator=';')\n training_ds = training_ds.register(workspace=ws, name = 'train', description = 'training dataset sampled from labelled data', create_new_version=True)\n    \n # create and register testing dataset from datastore files\n testing_ds = Dataset.Tabular.from_delimited_files(path = [(datastore, 'train-test\/test.csv')], separator=';')\n testing_ds = testing_ds.register(workspace=ws, name = 'test', description = 'testing dataset sampled from labelled data', create_new_version=True)\n\n\n\nThe approach I was intending to use for step 5 was to use to_torchvision() to convert it into a Torchvision dataset. This doesn't work, I receive the following error:\n\n UserErrorException: UserErrorException:\n  Message: Cannot perform torchvision conversion on dataset without labeled columns defined\n  InnerException None\n  ErrorResponse \n {\n     \"error\": {\n         \"code\": \"UserError\",\n         \"message\": \"Cannot perform torchvision conversion on dataset without labeled columns defined\"\n     }\n }\n\n\n\nI suspect that the issue has to do with DataTypes. The original Dataset (exported from the data labelling project) has the DataTypes displayed below. By comparison, all column types in the train and test Datasets are parsed as strings. From my understanding, there's no way to convert to these data types.\n\nimage_url = Stream\n\n\nlabel = List\n\n\nlabel_confidence = List\n\nAny advice on how to prepare this dataset for use in PyTorch or recommendation for an alternative approach would be greatly appreciated.\n\n\n\n\n\n\nUpdate as per comment below:\n\nI'm currently mounting the dataframe rather than downloading it due to data size.\n\n\nI can view images from the originally mounted Dataset, but when loading the newly registered training Dataset I can't access images as '\/tmp\/tmpog809x4v\/[...].jpg' is no longer relevant.\n\n\nI can't perform random split because I'm using clustered sampling.\n\n\nI'm working on creating a class object to define the dataset, but I cannot currently create the PIL Image object as required by PyTorch (https:\/\/pytorch.org\/tutorials\/intermediate\/torchvision_tutorial.html#defining-the-dataset)",
        "Answers":[
            {
                "Answer_creation_time":"2020-12-15T22:30:13.793Z",
                "Answer_upvote_count":0,
                "Answer_body":"I modified the methodology and was able to successfully resolve this issue as follows:\n\nExport data labelling project as Dataset\n\n\nConsume the Dataset in the notebook by creating both a PyTorch dataset and a Pandas dataframe\n\n\nUse the Pandas dataframe to determine indices for the train \/ test split based on required sampling\n\n\nUse the indices as an input to torch.utils.data.Subset() to split the PyTorch dataset into train and test",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2020-12-10T13:06:31.287Z",
                "Answer_upvote_count":0,
                "Answer_body":"@JoeDuncan-2610 Thanks for the great question. End-to-end image detection that leverages training\/test datasets created from a Data Labeling project. you are well aware that you can also \u2018solve\u2019 this problem with CustomVision, but I\u2019d like to showcase how a custom vision problem which may not be handle well enough by Custom Vision could be handled easily with Azure ML with full control of the underlying ML algorithms and the power of Data Labeling.\n\nThe best practices to get back to the images referenced by the dataset, i.e. leverage the DataStore \/ StreamInfo from the TabularDataset extracted DataFrame, to prepare the data for a model training.\n\nThis code here that I put together is probably the way to proceed to retrieve the original image assets from a labeled TabularDataset.\n\n # azureml-core of version 1.0.72 or higher is required\n # azureml-contrib-dataset of version 1.0.72 or higher is required\n    \n    \n from azureml.core import Workspace, Dataset, Datastore\n import azureml.contrib.dataset\n import azureml.dataprep.native\n     \n subscription_id = '_set_it_to_yours_'\n resource_group = '_set_it_to_yours_'\n workspace_name = '_set_it_to_yours_'\n     \n workspace = Workspace(subscription_id, resource_group, workspace_name)\n     \n # get dataset and extract as a DataFrame\n ds = Dataset.get_by_name(workspace, name=_set_it_to_yours_')\n df = ds.to_pandas_dataframe()\n     \n # download images\n index = 0\n datastore = None\n while index < len(df):\n     # image_url is a azureml.dataprep.native.StreamInfo object, convert to dict with to_pod()\n     si = df.loc[index].image_url.to_pod()\n     if index == 0:\n         # retrieve datastore based on metadata from first row\n         # assuming all images come from the same store\n         # since they come from a single dataset\n         datastore = Datastore.get(workspace, si['arguments']['datastoreName'])\n     # download image locally\n     datastore.download(target_path='.',prefix=si['resourceIdentifier'],overwrite=True,show_progress=True)\n     index += 1\n     \n # create training, test sets\n [training, test] = ds.random_split(0.8)\n\n\n\nbuild model based on image assets and labels...\nFrom there, build your train_x,y and test_x,y datasets\u2026\n\n\n\n\nWe have checked in a sample notebook about labeled dataset to public github repo. You can find it here:\n\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/work-with-data\/datasets-tutorial\/labeled-datasets\/labeled-datasets.ipynb",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Descriptors cannot not be created",
        "Question_creation_time":1661977116463,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/989409\/descriptors-cannot-not-be-created.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"This error message is super confusing, what does it mean?",
        "Answers":[
            {
                "Answer_creation_time":"2022-08-31T21:19:30.76Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @matsuoka-4412\n\nThanks for using Microsoft Q&A platform. This problem is caused by breaking changes introduced in protobuf 4.0.0. For more information, see https:\/\/developers.google.com\/protocol-buffers\/docs\/news\/2022-05-06#python-updates.\n\nPlease refer to this troubleshooting guidance - https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-protobuf-descriptor-error\n\nI hope it helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to install python package in hardware accelerated GPU spark pool ?",
        "Question_creation_time":1654683175267,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/881432\/how-to-install-python-package-in-hardware-accelera.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-synapse-analytics",
            "azure-machine-learning",
            "azure-analysis-services"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I've a azure synapse analytics workspace in region North Europe, as the region has hardware Accelerated pools, GPU base pools so to say. But i don't see the packages setting.\nhere is the comparison for 2 workspace, 1 in north Europe and other one in West Europe.\n vs \n\nEven the package setting in the Workspace itself is disabled for me: here is the screenshot.\n\n\nI've 2 questions in this reagrd:\n- Am I missing any configuration for the GPU pool or this feature is not released?\n- Is there any alternate way to install a package? pip install or pip3 install are not working.",
        "Answers":[
            {
                "Answer_creation_time":"2022-06-09T10:30:59.817Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hello @PrateekNarula-5198,\n\nThanks for the question and using MS Q&A platform.\n\n(UPDATE:6\/10\/2022): Unfortunately, we do not have Library Management (Package) support for GPU spark pools in Azure Synapse Analytics.\n\nAs per the repro, I had noticed similar behaviour.\n\nLooks like packages are only supported for Node size family: \"Memory Optimized\" - let me get a confirmation from the product team.\n\nWe are reaching out to internal team to get more information related to this issue and will get back to you as soon as we have an update.\n\nHope this will help. Please let us know if any further queries.\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":16.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Convert web service output to a dataset Azure MLS classic",
        "Question_creation_time":1592408319737,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/37214\/convert-web-service-output-to-a-dataset-azure-mls.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Is it possible to convert a web service output as a dataset or a csv file ? I want to consume this in another experiment.",
        "Answers":[
            {
                "Answer_creation_time":"2020-06-17T17:56:25.02Z",
                "Answer_upvote_count":0,
                "Answer_body":"You can delete or export in-product data stored by Azure Machine Learning Studio (classic) by using the Azure portal, the Studio (classic) interface, PowerShell, and authenticated REST APIs. This article tells you how.\n\nTelemetry data can be accessed through the Azure Privacy portal.\n\nMore details please refer to: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/export-delete-personal-data-dsr\n\nAnd also you can use one of the Azure Machine Learning Studio Module - \"Export Data\" to do it : https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/export-data?redirectedfrom=MSDN\n\nLet me know if you have more questions.\n\nRegards,\nYutong",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":3.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to deploy R script web service via Azure CLI",
        "Question_creation_time":1635213453407,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/603664\/how-to-deploy-r-script-web-service-via-azure-cli.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello everyone,\n\nI am tring to deploy R script as a web service using Azure Machine Learning. I created pipeline as below.\n\nI can deploy the model and endpoint from [Deploy] button but I cannot control some properties: i.e. resource name, dns name.\n\nIt seems that the az ml model deploy command can be used to deploy the endpoint.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-container-instance#using-the-azure-cli\n\nI have no information for inferenceconfig.json. How to write score.py to execute R script? Is it any example?",
        "Answers":[
            {
                "Answer_creation_time":"2021-10-26T21:18:18.257Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, the following document describes how to define an inference configuration.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How do I extend the waiting time of Azure speech-to-text API in Python?",
        "Question_creation_time":1649087644937,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/799565\/how-do-i-extend-the-waiting-time-of-azure-speech-t.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-speech"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"When using speech-to-text to transfer audio file to text, I found that the function would stop working if human voices haven't occurred for about 5 seconds. In my case, what I want to transfer is audios of interviews, which would often contain some advertisements or music in the middle of it, and when this happens, the speech-to-text would only transfer the first half of the whole audio, and report an error that \"No speech could be recognized\".\nIn this case, how can I extend the waiting time of that in order to transfer the whole file in Python codes?",
        "Answers":[
            {
                "Answer_creation_time":"2022-04-06T00:32:24.237Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @MuyaoHu-4139\n\nI think there are two solutions you can have a try in Python SDK:\n\nThere is a 'set_property' method on the config to allow you to set parameters to your request, which can change the default silence time:: https:\/\/docs.microsoft.com\/en-us\/python\/api\/azure-cognitiveservices-speech\/azure.cognitiveservices.speech.propertycollection?view=azure-python#azure-cognitiveservices-speech-propertycollection-set-property\n\nThis way you can set the EndSilenceTimeout (PropertyIDs in Pyhton: https:\/\/docs.microsoft.com\/en-us\/python\/api\/azure-cognitiveservices-speech\/azure.cognitiveservices.speech.propertyid?view=azure-python#fields)\n\n\n\n\nPlease notice, the time is as \"ms\". Hope above helps!\n\n\n\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks!",
                "Answer_comment_count":4,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"ray+dask native support be added to Azure Machine Learning",
        "Question_creation_time":1666227934133,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1055350\/raydask-native-support-be-added-to-azure-machine-l.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"While distributed dask can be setup manually on AML compute, the process requires lot of configs to be maintained. Is there any native support.",
        "Answers":[
            {
                "Answer_creation_time":"2022-10-20T11:44:42.8Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Divya-0887 Thanks for the question. you can do is to setup the compute cluster & compute instance in the same vnet and pip install ray-on-aml. This allows both interactive and job use of Ray and Dask right within Azure ML.\n\nHere is the document Library to turn Azure ML Compute into Ray and Dask cluster.\nhttps:\/\/techcommunity.microsoft.com\/t5\/ai-machine-learning-blog\/library-to-turn-azure-ml-compute-into-ray-and-dask-cluster\/ba-p\/3048784",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"No Data being exported from 'Export Data' module in Azure ML",
        "Question_creation_time":1629008927050,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/514067\/no-data-being-exported-from-39export-data39-module.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi,\n\nI am trying to export data from Azure ML to an Azure SQL Database using the 'Export Data' module but the log file contains the following messages and no data is exported to the database.\n\n\"Not exporting to run RunHistory as the exporter is either stopped or there is no data\"\n\n\"Process exiting with code: 0\n\nThere is definitely data flowing to the 'Export Data' module from an 'Execute R Script' module as I have checked the Result dataset.\n\nWould appreciate some assistance.\n\nThank you.",
        "Answers":[
            {
                "Answer_creation_time":"2021-08-16T09:39:07.877Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi,\n\nI have resolved this issue. I had set the export table to be dbo.TestTable rather than just TestTable. As the table dbo.TestTable did not exist the 'Export module' created it in the dbo schema so the table name effectively became dbo.dbo.TestTable.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Anaconda commercial use on Azure Data Science Virtual Machine",
        "Question_creation_time":1614757334137,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/296502\/anaconda-commercial-use-on-azure-data-science-virt.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-data-science-vm"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I would like to know if there is any problem in terms of license if enterprise companies use Anaconda that is preinstalled in Azure Data Science Virtual Machine. In another inquiry, I saw an answer that Anaconda included in Azure Machine Learning service has no problem in terms of the license but I would like to confirm whether DSVM also has a problem or not. https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/165312\/anaconda-commercial-use-on-azure-machine-learning.html",
        "Answers":[
            {
                "Answer_creation_time":"2021-03-03T10:10:34.917Z",
                "Answer_upvote_count":0,
                "Answer_body":"@kenta-takahashi The thread referenced by a user was in a different context who wanted to check if they had to subscribe to commercial license to use Azure ML. In the case of DSVM where anaconda packages are installed they are still configured to use open source packages irrespective of the subscription that spins them up. So, you can definitely use the DSVM for your purposes and configure any license's that were acquired to enhance your usage experience with the tools that have been pre-installed. Thanks!!",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"About creating a computing cluster with Azure Machine Learning",
        "Question_creation_time":1635431417297,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/607903\/about-creating-a-computing-cluster-with-azure-mach.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello.\nYou can only select up to one maximum node when Create an Azure Machine Learning compute cluster. How do I select multiple nodes?",
        "Answers":[
            {
                "Answer_creation_time":"2021-10-28T21:24:17.703Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, you can only select min and max number of nodes that you want to provision. The compute will autoscale to a maximum of this node count when a job is submitted. For more details, review Create an AML Compute Cluster.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Deep learning training on Azure steps and tutorial",
        "Question_creation_time":1605040090287,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/158168\/deep-learning-training-on-azure-steps-and-tutorial.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-virtual-machines",
            "azure-machine-learning",
            "azure-blob-storage",
            "azure-computer-vision"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi MSFT Community,\n\nI followed this guide to set up a GPU: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/data-science-virtual-machine\/dsvm-ubuntu-intro\n\nVM: Standard NC12_Promo, 12 vCPUs, 112 Gib RAM\nOperating System: Linux\nOffer: Ubuntu-1804\n\nI am ready to start deep learning training but I am confused about what to do next. I am doing a medical image classification project. I have 1 millions images store in Azure blob now. Do I need to download them to my VM in order to train? Or is it a better way to access image efficiently?\n\nWhat are some good tutorials to set up the experiments? I've read a lot of documentation but still confused.\n\nThank you very much!\nBest Regards,\nClaire",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-11T01:10:40.68Z",
                "Answer_upvote_count":2,
                "Answer_body":"@gecheng-2063\ncheck on the below AI training modules.\nhttps:\/\/aischool.microsoft.com\/en-us\/services\/learning-paths\n\nAI Lab\nhttps:\/\/www.microsoft.com\/en-us\/ai\/ai-lab-projects\n\nAI module gallery\nhttps:\/\/gallery.azure.ai\/browse\n\n\n\n\nPlease don\u2019t forget to \"Accept the answer\" and \u201cup-vote\u201d wherever the information provided helps you, this can be beneficial to other community members.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML for SAP ERP",
        "Question_creation_time":1664541861543,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1030800\/azure-ml-for-sap-erp.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I am trying to figure out about standard connectors between SAP ERP product and Azure ML especially for NLP scenarios. Can you please suggest on this.",
        "Answers":[
            {
                "Answer_creation_time":"2022-09-30T13:01:37.547Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Divya-0887 Thanks for the question. Here is the blog that could help and nlp recipes.\nhttps:\/\/blogs.sap.com\/2022\/08\/03\/azure-machine-learning-triggering-calculations-ml-in-sap-data-warehouse-cloud\/",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Deployment of Multiple Models to Container Instance Fails in Azure DevOps",
        "Question_creation_time":1592223294357,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/36104\/deployment-of-multiple-models-to-container-instanc.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-container-instances",
            "azure-dev-tool-integrations"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi Team,\n\nI am trying to deploy 2 ML models ( which is registered in Model Registry ) to Azure Container Instance using DevOps Release pipeline using AZ CLI ML extension\n\nMy ACI Configuration is :\n\ncontainerResourceRequirements: cpu: 1 memoryInGB: 4 computeType: ACI\n\nInference Config :\n\nentryScript: score.py runtime: python condaFile: conda_dependencies.yml extraDockerfileSteps: schemaFile: sourceDirectory: enableGpu: False baseImage: baseImageRegistry:\n\nAll score.py, conda_dependencies.yml, aciDeploymentConfig.yml is placed in a flattened directory which is publised in to DevOps pipeline artifcat and looks like\n\n\n\n\n\nDevOps Deploy command looks like\n\naz ml model deploy -g $(ml.resourceGroup) -w $(ml.workspace) --name $(service.name.staging) -f .\/model.json -m \"GloVe:4\" --dc aciDeploymentConfig.yml --ic inferenceConfig.yml --overwrite --debug\n\nAlso i have set the working directory as the folder where all above files are placed. something like\n\n$(System.DefaultWorkingDirectory)\/_Symptom-Code-Indexing\/symptom_model\/a\n\nIts getting in to an exception as\n\n2020-06-08T12:50:27.9202657Z \"error\": {\n2020-06-08T12:50:27.9208361Z \"message\": \"Received bad response from Model Management Service:\\nResponse Code: 400\\nHeaders: {'Date': 'Mon, 08 Jun 2020 12:50:27 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': '823e8483923846b1958c08ffaba074ff', 'x-ms-client-session-id': '62e84a29-b77c-456f-9d91-5ca6be26f79c', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\\nContent: b'{\\\"code\\\":\\\"BadRequest\\\",\\\"statusCode\\\":400,\\\"message\\\":\\\"The request is invalid.\\\",\\\"details\\\":[{\\\"code\\\":\\\"InvalidOverwriteRequest\\\",\\\"message\\\":\\\"Invalid overwrite request - cannot update container resource requirements, dns name label, or deployment type. Please delete and redeploy this service.\\\"}],\\\"correlation\\\":{\\\"RequestId\\\":\\\"823e8483923846b1958c08ffaba074ff\\\"}}'\"\n2020-06-08T12:50:27.9212109Z }\n2020-06-08T12:50:27.9212376Z }}\n2020-06-08T12:50:27.9213437Z {'Azure-cli-ml Version': '1.6.0', 'Error': WebserviceException:\n2020-06-08T12:50:27.9214158Z Message: Received bad response from Model Management Service:\n2020-06-08T12:50:27.9214688Z Response Code: 400\n2020-06-08T12:50:27.9217800Z Headers: {'Date': 'Mon, 08 Jun 2020 12:50:27 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': '823e8483923846b1958c08ffaba074ff', 'x-ms-client-session-id': '62e84a29-b77c-456f-9d91-5ca6be26f79c', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\n2020-06-08T12:50:27.9222115Z Content: b'{\"code\":\"BadRequest\",\"statusCode\":400,\"message\":\"The request is invalid.\",\"details\":[{\"code\":\"InvalidOverwriteRequest\",\"message\":\"Invalid overwrite request - cannot update container resource requirements, dns name label, or deployment type. Please delete and redeploy this service.\"}],\"correlation\":{\"RequestId\":\"823e8483923846b1958c08ffaba074ff\"}}'\n2020-06-08T12:50:27.9223705Z InnerException None\n2020-06-08T12:50:27.9224049Z ErrorResponse\n2020-06-08T12:50:27.9224320Z {\n2020-06-08T12:50:27.9224617Z \"error\": {\n2020-06-08T12:50:27.9229025Z \"message\": \"Received bad response from Model Management Service:\\nResponse Code: 400\\nHeaders: {'Date': 'Mon, 08 Jun 2020 12:50:27 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': '823e8483923846b1958c08ffaba074ff', 'x-ms-client-session-id': '62e84a29-b77c-456f-9d91-5ca6be26f79c', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\\nContent: b'{\\\"code\\\":\\\"BadRequest\\\",\\\"statusCode\\\":400,\\\"message\\\":\\\"The request is invalid.\\\",\\\"details\\\":[{\\\"code\\\":\\\"InvalidOverwriteRequest\\\",\\\"message\\\":\\\"Invalid overwrite request - cannot update container resource requirements, dns name label, or deployment type. Please delete and redeploy this service.\\\"}],\\\"correlation\\\":{\\\"RequestId\\\":\\\"823e8483923846b1958c08ffaba074ff\\\"}}'\"\n2020-06-08T12:50:27.9230782Z }\n2020-06-08T12:50:27.9230908Z }}\n2020-06-08T12:50:27.9231134Z Event: Cli.PostExecute [<function AzCliLogging.deinit_cmd_metadata_logging at 0x7fea2ca1f730>]\n2020-06-08T12:50:27.9231431Z az_command_data_logger : exit code: 1\n2020-06-08T12:50:27.9275693Z telemetry.save : Save telemetry record of length 7390 in cache\n2020-06-08T12:50:27.9280735Z telemetry.check : Negative: The \/home\/vsts\/work\/_temp\/.azclitask\/telemetry.txt was modified at 2020-06-08 12:47:41.161160, which in less than 600.000000 s\n2020-06-08T12:50:27.9290480Z command ran in 55.735 seconds.\n2020-06-08T12:50:28.1525434Z ##[error]Script failed with exit code: 1\n2020-06-08T12:50:28.1536650Z [command]\/opt\/hostedtoolcache\/Python\/3.6.10\/x64\/bin\/az account clear\n2020-06-08T12:50:29.9078943Z ##[section]Finishing: Deploy Model to ACI\n\nBut when i tried to Deploy it using Python SDK it works as well. Is there any permission issues or login to be set before using DevOps Release. I have not done any sort of login in my DevOps Build pipeline.\n\nAny pointers on what is going wrong here ? It would be really helpful.\n\nThanks,\nSrijith",
        "Answers":[
            {
                "Answer_creation_time":"2020-06-15T12:17:00.34Z",
                "Answer_upvote_count":1,
                "Answer_body":"They're actively answering Devops question in dedicated forums here.\n\n\n\n\nhttps:\/\/developercommunity.visualstudio.com\/spaces\/21\/index.html\n\n\n\n\n--please don't forget to Accept as answer if the reply is helpful--\n\nRegards, Dave Patrick ....\nMicrosoft Certified Professional\nMicrosoft MVP [Windows Server] Datacenter Management\n\n\n\n\nDisclaimer: This posting is provided \"AS IS\" with no warranties or guarantees, and confers no rights.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Result with coordinator convertion",
        "Question_creation_time":1648416629250,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/789141\/result-with-coordinator-convertion.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I wonder how could I convert the result of boundingbox of form recognizer into image coordinate to visualize the overlay image and recognized data.\n\nI could not have that accomplished because it is not similar to normal coordinates.",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-27T22:02:17.72Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @masterhunter-9726\n\nThank you for reaching out to us, I think you have questions about the value of boundingBoxes, below I will give an example to explain it so that you can convert it to the coordinate you want to use:\n\nExample:\n\n\n\n\n    'boundingBox': [\n                 57.1,\n                 683.3,\n                 100.2,\n                 683.3,\n                 100.2,\n                 673.3,\n                 57.1,\n                 673.3\n               ]\n\n\n\nThose values represent the vertices of the bounding box as below:\n\n   (57.1,683.3) X1,Y1---->x2,y2(100.2,683.3)\n                   |                |\n                   |                |\n   (57.1,673.3) X4,Y4<----x3,y3(100.2,673.3)\n\n\n\nThe (0,0) is on the bottom left as you can see.\n\n \/\/ Azure Bounding box is like this                     \n \/\/                                                     0---->1\n \/\/                                                    |     |\n \/\/                                         Y          |     |\n \/\/                                         \u2191         3<----2\n \/\/                                  Origin . \u2192 X\n\n\n\nIf you want to measure the boundingBoxes, you can use above vertices to do the calculation.\n\nHope this helps!\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks!",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Retrieve Notebooks Azure Files",
        "Question_creation_time":1615959743450,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/317875\/retrieve-notebooks-azure-files.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Is it possible to retrieve notebooks that were hosted on notebooks.azure.com? If so, how? The service is now discontinued but I would like to retrieve files that were hosted on the service.",
        "Answers":[
            {
                "Answer_creation_time":"2021-03-17T10:07:29.02Z",
                "Answer_upvote_count":1,
                "Answer_body":"@sean-9375 I am afraid that the option to retrieve this data is not possible. Please refer this thread for information and the options that were available before the last day to migrate them. Thanks!!",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to save and load ML model with Azure Data Factory",
        "Question_creation_time":1623657811393,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/434449\/how-to-save-and-load-ml-model-with-azure-data-fact.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-data-factory",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I have an Azure Data factory that receives data from a service bus and then I want to classify my data with an ML model.\n\nIs there any solution to save and load the ML model on the Azure Data Factory pipeline?\n\nFor your information, I want to use cloud base solution. I don't use the PICKLE library.",
        "Answers":[
            {
                "Answer_creation_time":"2021-06-16T16:21:07.257Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @MohsenAkhavan,\nThanks for the ask and using the Microsoft Q&A platform .\n\nI think you can use the machine learning activity . Read and watch the video here .\n\nThe challenge in your case is the data is in EH and at this time ADF cannot read EH data . I suggest you to use a Azure stream analytics jobs and read the data from EH and write it to SQL or blob . Once the data is in any of these two sources ADF can be used to read the data .\n\nPlease do let me know how it goes .\nThanks\nHimanshu\nPlease do consider clicking on \"Accept Answer\" and \"Up-vote\" on the post that helps you, as it can be beneficial to other community members",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Error invoking the azure ML pipeline from Azure Devops",
        "Question_creation_time":1658316045857,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/934296\/error-invoking-the-azure-ml-pipeline-from-azure-de.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"When I tried invoking an Azure ML pipeline from an Azure DevOps pipeline, I keep running into errors, Can you please share any sample that works.",
        "Answers":[
            {
                "Answer_creation_time":"2022-07-20T11:47:28.817Z",
                "Answer_upvote_count":1,
                "Answer_body":"@Srin-4824 Thanks for the question. yes this is possible just use the Azure CLI task - Azure Pipelines step and run command line or Python scripts inside that to submit your pipelines.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure machine learning",
        "Question_creation_time":1656618921300,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/909965\/azure-machine-learning-2.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Is there any way to integrate MS Dynamics Customer Insights with Azure Machine Learning (designer)?I know there is an integration between CI and Azure Machine Learning studio (classic). Please help to integrate these two services.",
        "Answers":[
            {
                "Answer_creation_time":"2022-06-30T23:43:14.977Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @Yasuo-9899\n\nThanks for reaching out to us for this question. Are you looking for this document? https:\/\/docs.microsoft.com\/en-us\/dynamics365\/customer-insights\/azure-machine-learning-experiments\n\nI have found one pic which is described the structure well:\n\n\n\n\n\nAnd also a repo you may want to refer to: https:\/\/github.com\/ArtisConsulting\/customer-insights-azure-data-workshop\/blob\/main\/README.md\n\nPlease let us know more details you are interested in so that we can help. Thanks.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-07-01T22:59:10.557Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @Yasuo-9899 ,\n\nI believe below document will be helpful.\nGeneral Documentation: https:\/\/docs.microsoft.com\/en-us\/dynamics365\/customer-insights\/custom-models\n\nPre-requisites for correct configuration of a pipeline: https:\/\/docs.microsoft.com\/en-us\/dynamics365\/customer-insights\/azure-machine-learning-experiments\n\nTutorial Documentation: https:\/\/github.com\/naravill\/CustomerInsightsML\n\nRegards,\nPritee",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Ambiguous error in Azure Machine Learning Designer 'Evaluate Model' Module",
        "Question_creation_time":1622567822803,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/418016\/ambiguous-error-in-azure-machine-learning-designer.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I am getting the following error from the Evaluate Model module in Azure Machine Learning Designer:\n\n\nWhen I open the Assigned Data to Clusters module everything seems fine. I downloaded the output for Assigned Data to Clusters and played with cluster number 31 and there doesn't seem to be any issue. Additionally, I am using Azure Modules, so I am confused as to why this is failing. Please provide some clarity into this issue. This is a part of my pipeline:\n\nAdditionally, it seems unless I successfully run the Evaluate Model module, I cannot create an inference pipeline. If this is untrue, please help me out here as well. There is no option for me to 'Create an Inference Pipeline' which shown in this tutorial; step 1.\n\nPlease let me know if you need any other information.\n\nThanks in advance.",
        "Answers":[
            {
                "Answer_creation_time":"2021-06-11T22:35:57.477Z",
                "Answer_upvote_count":1,
                "Answer_body":"Can you please check if the Assignment cluster 31 has NaN value? The Assign Data to Clusters leverages SKlearn, and from the error message, seems the Assignment column had NaN value which resulted in an error. If that's the case, let us know, so we can enable Evaluate Module module to deal with NaN values, and in the meantime, here's a short-term workaround:\n\nConnect Clean Missing Data module to Assign Data to Cluster module, to clean the missing values.\n\n\n\nUse Edit Metadata module to convert Assignment to Integer and categorical type, this is because if Assignment column has NaN value before and its column type was double, we need to convert it to integer.\n\n\n\nConnect Edit Metadata to Evaluate Model module.\n\n\n\n\nHope this help!",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How can I use a working pipeline",
        "Question_creation_time":1640685619343,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/677175\/how-can-i-use-a-working-pipeline.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi,\n\nI created a working pipeline in azure machine learning studio but I am stuck how i can use it with a live dataset. Could anybody help to me in this issue? I dont have such option to deploy it.\n\nthank you in advance",
        "Answers":[
            {
                "Answer_creation_time":"2021-12-28T21:24:18.68Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, please review Test the real-time endpoint for more details on how to test your model. You can consume your model using a Client or PowerBI.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How can i access azure ml pipeline parameters from a python script running in designer?",
        "Question_creation_time":1620522230407,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/387875\/how-can-i-access-azure-ml-pipeline-parameters-from.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I would like to perform some data transformations using the Python script module in Designer for which i would need to access some pipeline parameters. How can i get those values?\n\nWhat would be the equivalent for an R script?",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-18T04:06:56.287Z",
                "Answer_upvote_count":0,
                "Answer_body":"@javier-8889 Thanks, Currently passing a pipeline parameter to the script of Execute Python\/R Module is not supported. We have a new feature custom module which is in private preview. you can write your own module and use in Designer. If it's a common case, it might be better to use custom module.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":4.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to deploy ML Designer pipeline as real-time inference pipeline using N-Gram",
        "Question_creation_time":1606307286153,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/175242\/how-to-deploy-ml-designer-pipeline-as-real-time-in.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi,\ni deployed a real-time inference pipeline using ML Designer. Training and deploying works fine. But when I'm consuming\/testing my API it doesn't work. Postman gives me Errorcode 500 and \"Internal Server Error. Run: Server internal error is from Module Extract N-Gram Features from Text\".\n\nThis is my training pipeline:\n\n\nI read this: https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/machine-learning\/algorithm-module-reference\/extract-n-gram-features-from-text.md#score-or-publish-a-model-that-uses-n-grams\n\nBut I don't know how to achieve this.\n\nThanks in advance.",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-26T05:06:13.387Z",
                "Answer_upvote_count":0,
                "Answer_body":"Once you create a real-time inference pipeline, please make the further modifications below:\n\nFind the output Result_vocabulary dataset from Extract N-Gram Features from Text module.\n\n\n\nRegister the dataset as with a name\n\n\n\nUpdate real-time inference pipeline like below:\n\n\n\n\n\nWe will improve the documentation accordingly. Thanks for reporting the issue!",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-04-28T06:35:33.063Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @LuZhang-4441 do not see Output datasets to select for registering them. How should I proceed? I have also attached screenshot.\n\nInput datasets\nNone\n\nOutput datasets\nNone",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML Studio error while testing real-time endpoint - list index out of range",
        "Question_creation_time":1645577589217,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/746784\/azure-ml-studio-error-while-testing-real-time-endp.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":5,
        "Question_has_accepted_answer":true,
        "Question_body":"I am new to the Azure ML Studio and just deployed the bike-rental regression model. When I tried to test it using the built in test tool in the studio, I am getting the attached error. Similar results running the Python code as well. Can someone please help me?",
        "Answers":[
            {
                "Answer_creation_time":"2022-02-24T09:35:29.74Z",
                "Answer_upvote_count":3,
                "Answer_body":"@KumarPriya-6121 Thanks for the question. It's known issue and the product team working on the fix to change in the UI.\n\nWorkaround: As shown below please set the GlobalParameters flag to 1.0 or a float number or remove it.",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-03-01T07:41:18.553Z",
                "Answer_upvote_count":0,
                "Answer_body":"Change GlobalParameters flag value from integer 1 to decimal 1.0 to make it works.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-16T03:22:52.183Z",
                "Answer_upvote_count":0,
                "Answer_body":"What about when making GET requests to the score endpoint or doing a POST? Is there a way of setting the GlobalParameters flag there? I get this just by doing an authorized GET to my endpoint from postman.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-25T21:41:46.547Z",
                "Answer_upvote_count":2,
                "Answer_body":"@FernandoJosRibeiroJnior-4000 I had to modify the notebook as follows to get it to work:\n\n x = [[1,1,2022,1,0,6,0,2,0.344167,0.363625,0.805833,0.160446], \n    \n     [2,1,2022,1,0,0,0,2,0.363478,0.353739,0.696087,0.248539], \n    \n     [3,1,2022,1,0,1,1,1,0.196364,0.189405,0.437273,0.248309], \n    \n     [4,1,2022,1,0,2,1,1,0.2,0.212122,0.590435,0.160296], \n    \n     [5,1,2022,1,0,3,1,1,0.226957,0.22927,0.436957,0.1869]] \n    \n columns = [\"day\",\"mnth\", \"year\", \"season\", \"holiday\", \"weekday\", \"workingday\", \"weathersit\", \"temp\", \"atemp\", \"hum\", \"windspeed\"]\n data = [{columns[i]: v for i, v in enumerate(x_i)} for x_i in x]\n    \n request = {\n   \"Inputs\": {\n     \"data\": data\n   },\n   \"GlobalParameters\": 0.0 # not sure if this value matters\n }\n    \n input_json = json.dumps(request)",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-10T06:25:59.75Z",
                "Answer_upvote_count":0,
                "Answer_body":"Azure ML Studio error while testing real-time endpoint - Input data are inconsistent with schema\n\n\n\n\n\nKindly help me to resolve this issue.\n\n\n\n\nThanks in Advance\n\nRegards,\nPrashanth K",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":4.0,
        "Question_follower_count":13.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Migrate to portal studio",
        "Question_creation_time":1653988049527,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/871064\/migrate-to-portal-studio.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Experts,\n\nI just try studio classic which is good but retired soon\n\nI am moving to the new studio in azure portal. Any guidance for newbie?",
        "Answers":[
            {
                "Answer_creation_time":"2022-05-31T09:15:25.023Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @Alexandre-4252\n\nWelcome to Microsoft Q&A Platform,\n\nI would start checking the docs below:\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/overview-what-is-machine-learning-studio\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/migrate-rebuild-experiment\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/migrate-register-dataset\n\nI hope this helps!\n\nPlease don\u2019t forget to \"Accept the answer\" and \u201cup-vote\u201d wherever the information provided helps you, this can be beneficial to other community members.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-05-31T09:19:47.13Z",
                "Answer_upvote_count":0,
                "Answer_body":"Can data from classic be transferred to new one?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Estimate the cost for Machine learning SDK or UI portal",
        "Question_creation_time":1658729307217,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/940045\/estimate-the-cost-for-machine-learning-sdk-or-ui-p.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello experts, we are working on a medium size solution for our company and we are exploring basic estimate for SDK or studio decision. How I can know?",
        "Answers":[
            {
                "Answer_creation_time":"2022-07-25T13:57:02.623Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @Alexandre-2525\n\nThanks for reachin out to us, the Azure Machine Learnng pricing mainly is consist of CPU pricing and compute pricing, to get a better estimate pricing, a good way to calculate is using the calculator - https:\/\/azure.microsoft.com\/en-us\/pricing\/calculator\/\n\nYou can add your details into it and you will have a general idea about that.\n\nI hope this helps, thank you.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"my script stops running without any message explaining the reason",
        "Question_creation_time":1634306015143,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/592153\/my-script-stops-running-without-any-message-explai.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Please see the screenshots below. Once it said terminated but without reason:\n\nThe other time there was nothing just stopped:",
        "Answers":[
            {
                "Answer_creation_time":"2021-11-02T02:05:01.493Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nHope you have solved this issue and we are sorry not seeing your response. Since this issue happened without any error details, support ticket would be the best way to debug that. Please let me know if you still need that. Thanks.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Clear Feature with Auto ML",
        "Question_creation_time":1627927876257,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/498759\/clear-feature-with-auto-ml.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello, I am trying to add a user Id column to my dataset but I don't want the user Id to impact the results of the ML.\n\nI am using Auto ML on my dataset to generate a model and then deployed the model to an endpoint.\n\nCurrently I am calling the endpoint like:\n\n {\"data\":[\n        {\n           \"TEMP\":\"X\",\n         }\n     ]\n }\n\n\n\nand I would like to call it like:\n\n {\"data\":[\n     {\n       \"TEMP\":\"X\",\n       \"userID\": 5434643\n      }\n   ]}\n\n\n\nI'm wondering if there is a way I can do this? I've seen about using Clear Feature in Edit Metadata for the Designer but I'm wondering if something similar can be done for automated ML?\n\nThanks so much!",
        "Answers":[
            {
                "Answer_creation_time":"2021-08-03T00:16:45.197Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for reaching out. You can customize featurization in automl to only include features relevant for prediction. Here's the documentation. Hope it helps!",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML Designer: Export Code",
        "Question_creation_time":1646150939773,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/755142\/azure-ml-designer-export-code.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Is there an option to export the Azure ML Designer to code so we can copy between workspaces?",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-02T06:20:05.287Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi, this feature is currently not supported as mentioned on this thread. However, it's on the roadmap.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-11-10T18:23:47.713Z",
                "Answer_upvote_count":0,
                "Answer_body":"Is the roadmap public? When is this feature planning on being released?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Images Segmentation using Azure",
        "Question_creation_time":1610951620483,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/234232\/images-segmentation-using-azure.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-custom-vision"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi,\nI have been using object detection from Custom Vision to train images. Classification do not suit my goal so I'm looking at alternative methods to training images. Can I get some suggestions with using Azure for images segmentation?",
        "Answers":[
            {
                "Answer_creation_time":"2021-01-18T07:40:18.9Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi @NamLy-3299\n\nSuggestions and refer below url for Azure for images segmentation.\n\nCustom Vision integration sample skill for cognitive search\n\nClassify images with the Custom Vision service\n\n\n\n\nPlease don\u2019t forget to Accept the answer and up-vote wherever the information provided helps you, this can be beneficial to other community members.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Not able to consume predict-auto-price endpoint",
        "Question_creation_time":1628625065883,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/508671\/not-able-to-consume-predict-auto-price-endpoint.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi,\nI was following Create a Regression Model with Azure Machine Learning Designer\n\nI reached to deploy and created an endpoint for the service. But when I click consume, it keeps on loading and after sometime page become unresponsive. What can be the possible reasons for this?",
        "Answers":[
            {
                "Answer_creation_time":"2021-08-12T05:53:31.667Z",
                "Answer_upvote_count":1,
                "Answer_body":"@devkapilbansal This issue is now fixed. A hotfix was deployed to fix this. Please reload the page and check again.\n\nPlease feel free to accept the same as answer if it helped.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"From AMLS Deploying models in ACI in a vnet",
        "Question_creation_time":1601173833227,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/108659\/from-amls-deploying-models-in-aci-in-a-vnet.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I am facing error when I deploy in ACI. Is there a way to deploy the models when AMLS and vnet are in different resource groups?",
        "Answers":[
            {
                "Answer_creation_time":"2020-09-28T04:03:15.363Z",
                "Answer_upvote_count":1,
                "Answer_body":"@AI866-6821 Thanks, If you are using AMLS SDK, Unfortunately this is a limitation today that we plan to address this in the near future.\nYou can create a pipeline, DevOps or manual process to deploy to any ACI in any VNET\/different subscription\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/container-instances\/container-instances-vnet\n\nPlease follow the below for common troubleshooting issues.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/container-instances\/container-instances-troubleshooting",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Machine Learning: I cannot find experiment's user logs located in logs\/user folder",
        "Question_creation_time":1645621539517,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/747549\/azure-machine-learning-i-cannot-find-experiment39s.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I am running experiments in Azure Machine Learning using ParallelRunStep, and I cannot get the user folder with logs as defined in readme.txt file with the log folder structure.\nI cannot find log\/user folder with \"Logs generated when loading and running user's scripts.\"\n\nreadme.txt file states:\nParallelRunStep has two major parts:\n1. Scheduling, progress tracking and file concatenation for append_row.\n2. Processing mini batch by calling the entry script.\nThe agent manager on each node start agents.\nAn agent gets mini batch and calls the entry script against the mini batch.\n\n The \"logs\" folder has user, sys and perf sub folders.\n The user folder includes messages from the entry script in processing mini batches.\n The sys folder includes messages from #1 and non-entry script log from #2.\n The perf folder includes periodical checking result of resource usage.\n\n\n\nIn majority case, users can find the processing messages from the user folder.\nUsers need to check sys folder for messages beyond processing mini batches.\nlogs\/\nazureml\/: Logs from azureml dependencies. e.g. azureml.dataprep\nuser\/ : Logs generated when loading and running user's scripts.\nerror\/ : Logs of errors encountered while loading and running entry script.\nstderr\/ : stderr output of user's scripts.\nstdout\/ : stdout output of user's scripts.\nentry_script_log\/ : Logs generated by loggers of EntryScript()\n<node seq> :\nprocessNNN.log.txt : Logs generated by loggers of EntryScript() from each process.",
        "Answers":[
            {
                "Answer_creation_time":"2022-02-24T02:37:03.417Z",
                "Answer_upvote_count":0,
                "Answer_body":"@CalabriaMonteroSalvadorSGRESEDFPDC-5704 Thanks for the question. Please follow the doc to view and log files for a run. Interactive logging sessions are typically used in notebook environments. The method Experiment.start_logging() starts an interactive logging session. Any metrics logged during the session are added to the run record in the experiment. The method run.complete() ends the sessions and marks the run as completed.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-log-view-metrics#view-and-download-log-files-for-a-run",
                "Answer_comment_count":4,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Connecting to an existing Databricks Cluster in AMLS",
        "Question_creation_time":1654614267930,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/880189\/connecting-to-an-existing-databricks-cluster-in-am.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-databricks"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello,\n\nwe have also found this example of using Databricks as a Compute Target for an Azure Machine Learning Pipeline.\n\nHowever, we want to use an existing Databricks Cluster as compute target within Azure Machine Learning Studio for our Azure Machine Learning Pipeline.\nCould you help us in accomplishing this, please?\n\n\n\n\nWith best regards\nAlex",
        "Answers":[
            {
                "Answer_creation_time":"2022-06-08T05:07:31.167Z",
                "Answer_upvote_count":0,
                "Answer_body":"@AlexanderPakakis-0994 Are you looking at adding the cluster from the UI of ML studio rather than using the SDK as mentioned in the notebook you referenced?\nIf Yes, you need to add the same attached compute.\n\nOnce you select Azure Databricks the following option to add the existing databricks workspace is seen.\n\nI hope this helps!!\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":10,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":16.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Parallel computing with Python SDK V2",
        "Question_creation_time":1657198500433,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/918129\/parallel-computing-with-python-sdk-v2.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello :)\n\nDo you have any kind of idea when Azure Machine Learning Python SDK V2 could support parallel computing? We are testing things out with the machine learning studio and we are in a bit confusing stage that should we go with the SDK V1 or V2, but seemingly the V2 is not yet supporting multiple nodes in compute clusters.\n\nBest regards,\nTuomas",
        "Answers":[
            {
                "Answer_creation_time":"2022-07-14T04:53:23.743Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @TuomasPartanen-9618\n\nI have a good news for you, we are testing Parallel Run Step NOW in private preview of V2.\n\nFor your scenario, v1 is stable and serving all production customers. v2 (through DPv2) is still in private preview, and there are some dependency on new dataset\/mltable implementation. So if you want to seriously put some production traffic, I suggest guide to v1; but if you just want to have some prototypes, v2 may be better, as v2 is growing but v1 will not. Also, V2 will have the feature you want - Parallel.\n\nThe estimate time is not confirmed but should be around October.\n\nI hope this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"R model deployment with custom Docker image: \"ModuleNotFoundError: No module named 'azureml.api'\"",
        "Question_creation_time":1602855221470,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/129038\/r-model-deployment-with-custom-docker-image-34modu.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-container-instances",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I am trying to deploy an R inference script to Azure ML Service Endpoint as an Azure Container Instance. I have made the following steps:\n\ncreated a custom Docker image from scratch and pushed it to the Azure Container Registry (associated with AML Workspace)\n\n\nregistered a custom environment in AML Workspace, based on the image in ACR\n\n\ndeployed R entry script (just a simple hello world script with init() and run() functions defined)\n\n\nthe inference configuration uses the custom AML environment\n\n\ndeployment is made with Azure ML R SDK\n\nThe container instance is created, but the endpoint startup runs into error. Here is the output from the container instance:\n\n 2020-10-16T12:56:21,639812796+00:00 - gunicorn\/run \n 2020-10-16T12:56:21,639290594+00:00 - iot-server\/run \n 2020-10-16T12:56:21,640405198+00:00 - rsyslog\/run \n 2020-10-16T12:56:21,735291424+00:00 - nginx\/run \n EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n 2020-10-16T12:56:23,736657191+00:00 - iot-server\/finish 1 0\n 2020-10-16T12:56:23,834747728+00:00 - Exit code 1 is normal. Not restarting iot-server.\n Starting gunicorn 20.0.4\n Listening at: http:\/\/127.0.0.1:31311 (11)\n Using worker: sync\n worker timeout is set to 300\n Booting worker with pid: 38\n \/bin\/bash: \/root\/miniconda3\/lib\/libtinfo.so.6: no version information available (required by \/bin\/bash)\n SPARK_HOME not set. Skipping PySpark Initialization.\n Exception in worker process\n Traceback (most recent call last):\n   File \"\/var\/azureml-server\/app.py\", line 43, in <module>\n     from azureml.api.exceptions.ClientSideException import ClientSideException\n ModuleNotFoundError: No module named 'azureml.api'\n    \n During handling of the above exception, another exception occurred:\n    \n Traceback (most recent call last):\n   File \"\/usr\/lib\/python3\/dist-packages\/gunicorn\/arbiter.py\", line 583, in spawn_worker\n     worker.init_process()\n   File \"\/usr\/lib\/python3\/dist-packages\/gunicorn\/workers\/base.py\", line 119, in init_process\n     self.load_wsgi()\n   File \"\/usr\/lib\/python3\/dist-packages\/gunicorn\/workers\/base.py\", line 144, in load_wsgi\n     self.wsgi = self.app.wsgi()\n   File \"\/usr\/lib\/python3\/dist-packages\/gunicorn\/app\/base.py\", line 67, in wsgi\n     self.callable = self.load()\n   File \"\/usr\/lib\/python3\/dist-packages\/gunicorn\/app\/wsgiapp.py\", line 49, in load\n     return self.load_wsgiapp()\n   File \"\/usr\/lib\/python3\/dist-packages\/gunicorn\/app\/wsgiapp.py\", line 39, in load_wsgiapp\n     return util.import_app(self.app_uri)\n   File \"\/usr\/lib\/python3\/dist-packages\/gunicorn\/util.py\", line 383, in import_app\n     mod = importlib.import_module(module)\n   File \"\/usr\/lib\/python3.8\/importlib\/__init__.py\", line 127, in import_module\n     return _bootstrap._gcd_import(name[level:], package, level)\n   File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n   File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n   File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n   File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n   File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n   File \"\/var\/azureml-server\/wsgi.py\", line 1, in <module>\n     import create_app\n   File \"\/var\/azureml-server\/create_app.py\", line 3, in <module>\n     from app import main\n   File \"\/var\/azureml-server\/app.py\", line 45, in <module>\n     from azure.ml.api.exceptions.ClientSideException import ClientSideException\n ModuleNotFoundError: No module named 'azure.ml'\n Worker exiting (pid: 38)\n Shutting down: Master\n Reason: Worker failed to boot.\n 2020-10-16T12:56:39,434787859+00:00 - gunicorn\/finish 3 0\n 2020-10-16T12:56:39,435715063+00:00 - Exit code 3 is not normal. Killing image.\n\n\n\nHow do I install the azureml.api dependency, which can not be found? It doesn't seem to be part of the Azure ML SDK. I have installed the following dependencies in my Dockerfile:\n\n RUN apt-get -y install python3-flask python3-rpy2 python3-azure python3-applicationinsights\n RUN pip install azureml-core\n\n\n\nI also have Miniconda installed. Pip refers to Miniconda's pip.\n\nOr, is this dependency available to install at all? Should I use some pre-defined AML environment as the base Docker image? (Note: I am currently using bare FROM: ubuntu). Suggestions how to find and use the base images are also welcome, since this is not documented very well.",
        "Answers":[
            {
                "Answer_creation_time":"2020-10-19T10:44:00.927Z",
                "Answer_upvote_count":1,
                "Answer_body":"@LauriLehman-8626 Thanks for the question. Here is the document to Create Custom Docker Base Images for Azure Machine Learning Environments for R people.\nWe have used the AzureML RScriptStep pipeline feature which allows you to point to CRAN or Github or custom URLS, but this requires authoring the pipeline in python or YAML.. In R You can also these arguments in the Azuremlsdk R estimator function: https:\/\/azure.github.io\/azureml-sdk-for-r\/reference\/estimator.html\nAnother option that are not available through conda install as part of the R script with install.packages(\u201cpath\/*.tar.gz\u201d, repos=NULL))\n\nOne of the challenges is that the build at runtime can take a while to prepare the environment. R likes to compile packages on Linux environments and a large package could have lots of dependencies which would take a while. This is an R on Linux\/PaaS thing, rather than specific to AzureML\n\nTo make start up fast we created a custom docker image where you can tightly control the image ahead of runtime. If you want to go in this direction you can find an example Dockerfile to get you started here..\nhttps:\/\/github.com\/Azure\/azureml-sdk-for-r\/blob\/master\/.azure-pipelines\/docker\/Dockerfile",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Deployment from Designer fails in every possible way",
        "Question_creation_time":1632862175993,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/569925\/deployment-from-designer-fails-in-every-possible-w.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"I trained a model with Designer, created a real-time inference pipeline which was succesfully submitted. When deploying to either ACI or AKS it fails and I get the error \"ModuleNotFoundError: No module named 'azureml.api'\". I've had no problems deploying this model many times in the past and haven't changed anything. Even if I use one of the sample pipelines (automobiles basic), I get the same error when deploying to real-time.",
        "Answers":[
            {
                "Answer_creation_time":"2021-09-30T02:27:30.12Z",
                "Answer_upvote_count":1,
                "Answer_body":"It's an known issue caused by unexpected module version upgrade. It's been resolved by applying hotfix to all regions. For users, please rerun training pipeline by check on \"Regenerate Output\", and run corresponding inference pipeline and try deployment again.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-10-02T22:50:30.443Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello everyone,\n\nThis issue has been confirmed fixed. Please let us know if you still seeing this issue.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"getting an error when trying to deploy azure ml model",
        "Question_creation_time":1639419111370,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/662007\/getting-an-error-when-trying-to-deploy-azure-ml-mo.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I'm new to Azure ML so I have very little knowledge of this service..\nI've built a dummy regression model using automl package and now I'm trying to deploy it.\nI looked up some docs and followed a tutorial I found to deploy the model and I'm getting some errors..\n <- this is the error I'm currently getting\nI think there is a problem with my score.py so I'm attaching the photo here as well.\n\n\nand this is the output i need to print out through the model..\n\n\nI'd appreciate it much if somebody could give me some help\n\nthank you",
        "Answers":[
            {
                "Answer_creation_time":"2021-12-14T05:30:21.473Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hello,\n\nThanks for reaching out to us. From the above error it looks like the package did not install successfully. A more detailed procedure to install the SDK is available directly in the documentation: https:\/\/docs.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/install?view=azure-ml-py\n\nHow to set up the environment: https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/python-sdk\/tutorials\/automl-with-azureml#3-setup-a-new-conda-environment\n\nYou can test if you have set the env correct by below code:\n\n import azureml.core\n    \n print(\"This notebook was created using version 1.35.0 of the Azure ML SDK.\")\n print(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK.\")\n assert (\n     azureml.core.VERSION >= \"1.35\"\n ), \"Please upgrade the Azure ML SDK by running '!pip install --upgrade azureml-sdk' then restart the kernel.\"\n\n\n\nThere are some prerequisites to deploy models:\n\nAn Azure Machine Learning workspace. For more information, see Create an Azure Machine Learning workspace. https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace\n\n\nA model. The examples in this article use a pre-trained model.\n\n\nThe Azure Machine Learning software development kit (SDK) for Python. https:\/\/docs.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/intro\n\n\nA machine that can run Docker, such as a compute instance. https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance\n\nMore information please refer to https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#prerequisites\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How do I export my project from Azure",
        "Question_creation_time":1654324217247,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/876500\/how-do-i-export-my-project-from-azure.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi\n\nI would like to know how I keep the studio and all the elements I have done in Azure.\n\nI need them for a project but my subscription is expired and I'd like to keep what I've done.\n\nI can't afford paying for a new subscription.",
        "Answers":[
            {
                "Answer_creation_time":"2022-06-06T10:36:08.77Z",
                "Answer_upvote_count":0,
                "Answer_body":"@DavidGORGETTE-3670 You can export and delete your data from Azure using the guidance from this documentation.\nPlease note Azure ML workspace uses resources like storage account, container registry, app insights and key vault to store information related to ML experiments, jobs and environments. Your run history is basically available from the storage containers along with the supporting data. You can download specific models that are required directly from Azure ML portal for easy identification. I hope this helps!!\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Machine Learning Jupyter Lab Git options",
        "Question_creation_time":1594373340610,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/45187\/azure-machine-learning-jupyter-lab-git-options.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi,\nI&#39;m trying to setup an integration between a GITHub repository and my Jupyter Lab but I&#39;m struggling to find the GIT options in my Jupyter Lab application.\n\nI was expecting to see a Git clone button, a Git option on the toolbar and also the same option on the left pane but there is nothing GIT related.\n\nI&#39;ve already installed successfully the following:\n\npip install jupyterlab-git\npip install --upgrade python-gitlab\n\nBut nothing happens.\nWhen I try to clone a GIT repository, I get the folders\/files but then I can&#39;t interact with it. It&#39;s just copying it into my space but then I can&#39;t push\/pull anything.\n\nCan you help me on this?\n\nThank you,\nCarla",
        "Answers":[
            {
                "Answer_creation_time":"2020-07-10T10:56:41.087Z",
                "Answer_upvote_count":1,
                "Answer_body":"I found the answer to my question by following the steps here:\n\nhttps:\/\/www.oreilly.com\/library\/view\/jupyterlab-quick-start\/9781789805543\/94288841-0158-4a98-8151-4a90ea9bf2da.xhtml",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":30.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Does AutoML support optimizing convolutional neural network over the number of layers and pool layer parameters?",
        "Question_creation_time":1607093437353,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/186789\/does-automl-support-optimizing-convolutional-neura.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Does AutoML support optimizing convolutional neural network over the number of layers and pool layer parameters?",
        "Answers":[
            {
                "Answer_creation_time":"2020-12-04T21:28:34.597Z",
                "Answer_upvote_count":0,
                "Answer_body":"AutoML doesn't currently support CNNs publicly, it's on our roadmap and it will come with optimizations across different parameters, so stay tuned. Hope this helps.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Machine Learning\u306b\u3064\u3044\u3066\u306e\u8cea\u554f",
        "Question_creation_time":1631251067517,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/546760\/machine-learning%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%E3%81%AE%E8%B3%AA%E5%95%8F.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"\u63b2\u984c\u306e\u4ef6\u306b\u3064\u304d\u307e\u3057\u3066\u3001\u73fe\u5728Machine Learning\u3092\u4f7f\u7528\u3057\u3066\u6a5f\u68b0\u5b66\u7fd2\u3092\u884c\u3063\u3066\u3044\u307e\u3059\u3002\n\u305d\u3053\u3067\u8cea\u554f\u306b\u306a\u308b\u306e\u3067\u3059\u304c\u3001\u30c7\u30b6\u30a4\u30ca\u30fc\u6a5f\u80fd\u3092\u4f7f\u7528\u3057\u3066\u5b66\u7fd2\u7d50\u679c\u3092CSV\u3067\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u3057\u3088\u3046\u3068\u3057\u3066\u3044\u308b\u306e\u3067\u3059\u304c\u3001\nExport Data\u30e2\u30c7\u30eb\u3067CSV\u5f62\u5f0f\u306b\u8a2d\u5b9a\u3057\u3066\u3044\u3066\u3082CSV\u3067\u306f\u306a\u3044\u5f62\u5f0f\u3067\u5171\u6709\u305b\u308c\u3066\u3057\u307e\u3046\u306e\u3067\u3059\u304c\u3001\u539f\u56e0\u304c\u308f\u304b\u3089\u306a\u3044\u72b6\u6cc1\u3067\u3059\u3002\n\u3054\u6559\u793a\u306e\u307b\u3069\u3088\u308d\u3057\u304f\u304a\u9858\u3044\u3044\u305f\u3057\u307e\u3059\u3002",
        "Answers":[
            {
                "Answer_creation_time":"2021-09-10T10:15:10.237Z",
                "Answer_upvote_count":0,
                "Answer_body":"@63862379 Are you referring to the export data module of the designer from ml.azure.com?\nI think I understand the issue, Are you seeing that the .csv format of file is not listed on the blob storage?\n\nSince the input is a dataframe directory to export module the output format selected should still be the format you selected, in this case CSV. The file name extension only might be missing. You can still open the csv file in excel and it will recognize the delimiters and headers so you can convert it into excel files.\n\nYou can also avoid this by providing the .csv extension in the path itself in export settings and file will be exported as a csv file directly.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"azure cosmos db as a datastore in ml",
        "Question_creation_time":1597331768270,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/66297\/azure-cosmos-db-as-a-datastore-in-ml.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":3,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi, I'm wondering if I can register azure cosmos db as a datastore in azure machine learning?\nFrom your documentation, it seems not https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.datastore%28class%29?view=azure-ml-py\n\nDo you have a plan to implement the feature in near future?\n\n\nAny recommended alternative solutions for now?\n\nThanks.",
        "Answers":[
            {
                "Answer_creation_time":"2020-08-14T22:43:18.18Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for reaching out. Currently, Cosmos DB isn't a supported datasource when using Azure ML datastores. However, the product team are aware of this request and will provide updates accordingly. An alternative for now will be to use Azure ML Studio (Classic) which supports Cosmos DB as data source. You can also try a heuristic approach via Execute Python Script module in Designer to import data using python. Hope this helps.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-10-14T06:27:11.747Z",
                "Answer_upvote_count":2,
                "Answer_body":"Hi, Is there an update on this as a year has passed? For us, Cosmos DB is an important datasource (with no workable workarounds ), and not being able to use it as a datastore in Azure ML is forcing us to make a choice to continue with Azure ML or not.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-20T13:32:02.98Z",
                "Answer_upvote_count":0,
                "Answer_body":"I'm also interested in an update. We're in the process of migrating to azure and have lots of metadata associated with our training set stored in json files. It would be very nice to store it as a Table under our storage account and connect to it from AzureML via a datastore.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Training a TensorFlow model in Azure ML",
        "Question_creation_time":1649367124903,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/804968\/training-a-tensorflow-model-in-azure-ml.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-data-lake-storage",
            "azure-machine-learning-studio-classic",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"I am following the link below for training a TensorFlow model in Azure ML:\n\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/ml-frameworks\/tensorflow\/train-hyperparameter-tune-deploy-with-tensorflow\/train-hyperparameter-tune-deploy-with-tensorflow.ipynb\n\nHowever, as my training dataset is in a container named \"sample-datasets\" in ADLS Gen2, I changed the following code (in the above link) to refer to the paths in my data lake. So I replaced code A (in the link above) with code B (my code)\n\nCode A:\n\nurllib.request.urlretrieve('https:\/\/azureopendatastorage.blob.core.windows.net\/mnist\/train-images-idx3-ubyte.gz', filename=os.path.join(data_folder, 'train-images-idx3-ubyte.gz'))\nurllib.request.urlretrieve('https:\/\/azureopendatastorage.blob.core.windows.net\/mnist\/train-labels-idx1-ubyte.gz',\nfilename=os.path.join(data_folder, 'train-labels-idx1-ubyte.gz'))\nurllib.request.urlretrieve('https:\/\/azureopendatastorage.blob.core.windows.net\/mnist\/t10k-images-idx3-ubyte.gz', filename=os.path.join(data_folder, 't10k-images-idx3-ubyte.gz'))\nurllib.request.urlretrieve('https:\/\/azureopendatastorage.blob.core.windows.net\/mnist\/t10k-labels-idx1-ubyte.gz',\nfilename=os.path.join(data_folder, 't10k-labels-idx1-ubyte.gz'))\n\n\n\n\nCode B:\n\nfrom azureml.core.dataset import Dataset\nurllib.request.urlretrieve('https:\/\/lakehousestgenrichedzone.dfs.core.windows.net\/sample-datasets\/train-images-idx3-ubyte.gz', filename=os.path.join(data_folder, 'train-images-idx3-ubyte.gz'))\nurllib.request.urlretrieve('https:\/\/lakehousestgenrichedzone.dfs.core.windows.net\/sample-datasets\/train-labels-idx1-ubyte.gz', filename=os.path.join(data_folder, 'train-labels-idx1-ubyte.gz'))\nurllib.request.urlretrieve('https:\/\/lakehousestgenrichedzone.dfs.core.windows.net\/sample-datasets\/t10k-images-idx3-ubyte.gz', filename=os.path.join(data_folder, 't10k-images-idx3-ubyte.gz'))\nurllib.request.urlretrieve('https:\/\/lakehousestgenrichedzone.dfs.core.windows.net\/sample-datasets\/t10k-labels-idx1-ubyte.gz', filename=os.path.join(data_folder, 't10k-labels-idx1-ubyte.gz'))\n\nBut I receive the following error:\n\nHTTPError: HTTP Error 401: Server failed to authenticate the request. Please refer to the information in the www-authenticate header.\n\nCan you please let me know how I can train the model using my data which are stored in the data lake? More precisely, how my Python code can copy the training dataset from my data lake into data_folder?\n\nPS: Please note that I have already granted the Blob Storage data Contributor role on my data lake storage account to my Azure ML workspace as a managed identity.",
        "Answers":[
            {
                "Answer_creation_time":"2022-04-08T12:21:38.973Z",
                "Answer_upvote_count":0,
                "Answer_body":"anonymous user I have not worked on ADLS scenarios with Azure ML but I have added the ADLS tag to this thread for others to chip in and add their views.\n\nBased on the documentation for ADLS REST API it supports Azure Active Directory (Azure AD), Shared Key, and shared access signature (SAS) authorization with the APIs that are available to download the files from its storage. So, I think a direct download might not work in this case without authentication.\n\nI think the easiest way to get your files locally from ADLS is to use the python SDK to authenticate using account key or AD as listed here.\n\nIf you have many files that needs to be downloaded and referenced in your ML experiments then you may also consider to use the import data module of designer for designer experiments or register them as dataset from dataset tab of ml.azure.com which can also be referenced using the Azure ML SDK.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-04-19T15:42:44.427Z",
                "Answer_upvote_count":0,
                "Answer_body":"I solved the problem by assigning an user-assigned managed identity to the target compute to access my ASDLS Gen2",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"What is the difference between uri_file and uri_folder in components?",
        "Question_creation_time":1655434518570,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/892897\/what-is-the-difference-between-uri-file-and-uri-fo.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"What is the difference between uri_file and uri_folder in components?\n\nNo matter I specify uri_file or uri_folder in a component input\/output type, in Azure ML Studio jobs it is displayed as uri_folder and I still need to manually append a file name to the path derefernced by uri_file to access a single file. Is there any convenience or difference to specify uri_file if I only intend to access a single file?",
        "Answers":[
            {
                "Answer_creation_time":"2022-06-22T01:30:38.64Z",
                "Answer_upvote_count":1,
                "Answer_body":"Thanks.\nWe are planning for some smart deduction or inheriting the type from component to job runtime, we still have some open questions that need to close.\nAlso, we will add doc\/sample explicitly call out the default type in job level.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-06-20T01:10:08.487Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi @ramr-msft , I am using the YML spec as posted in #893075 Specifying input type as number in ComponentCommand and registing command with Python SDK v2 causes error:\n\nname: stock_pred_data_prep\ndisplay_name: Preprocess data for training\ndescription: reads raw price data, normalize and split the data\n# version: 1 # Not specifying a version will automatically update the version\ntype: command\ninputs:\n  data: {type: uri_folder}\n  test_ratio: {type: number}\n  window: {type: number}\noutputs:\n  scaler: {type: uri_file}\n  train_data_x: {type: uri_file}\n  train_data_y: {type: uri_file}\n  test_data_x: {type: uri_file}\n  test_data_y: {type: uri_file}\ncode: ..\/..\nenvironment:\n  azureml:tensorflow_sklean_cpu:1.0\ncommand: >-\n  PYTHONPATH=$PYTHONPATH:$(pwd) \n  PYTHONPATH=$PYTHONPATH:$(pwd)  python azure_pipeline\/preproc_data\/preproc_data.py \n      --data=${\n                 {inputs.data}} --test_ratio=${\n                 {inputs.test_ratio}} \n      --window=${\n                 {inputs.window}} \n      --scaler=${\n                 {outputs.scaler}} \n      --train_data_x=${\n                 {outputs.train_data_x}} --train_data_y=${\n                 {outputs.train_data_y}} \n      --test_data_x=${\n                 {outputs.test_data_x}} --test_data_y=${\n                 {outputs.test_data_y}}\n\n\n\n\n\nIn Azure ML Studtio, it is displayed correctly as uri_file:\n\n\nHowever, in Data asset, it is displayed as uri_folder, even though uri_file is said to be supported:\n\n\nAnd I need to save data by appending a filename to the input path like this, since the input path is considered a folder by Python:\n\nnp.save(os.path.join(args.train_data_x, 'x_train.npy'), xtrain)",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"NEW Azure ML vs On-Prem SQL",
        "Question_creation_time":1638277834353,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/646058\/new-azure-ml-vs-on-prem-sql.html",
        "Question_topic":null,
        "Question_tag":[
            "sql-server-general",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":4,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello,\n\nI understand there was a process how to connect to on-prem sql db from Azure ML studio, but with the transition to the new UI, I don't see the option to connect to the gateway. I have it successfully installed and registered in MS Azure, but from Studio it simply does not offer it as a dataset type when using the Import Data module.\nI can't find any documentation regarding the new UI nor any useful guides for this.\n\nWould anybody know whether this function is still available in the new studio and if so how can an on-prem gateway be connected?\n\nThank you,\nVS",
        "Answers":[
            {
                "Answer_creation_time":"2021-12-01T09:36:28.393Z",
                "Answer_upvote_count":0,
                "Answer_body":"@sorcrow-1800\n\nThanks for reaching out to us. I just got confirmation from the pm of AML, on-prem SQL is not supported in AML yet, but it's now on our plan.\n\nI will forward your feedback to product team as well.\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-12-01T07:17:41.387Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @sorcrow-1800,\n\n\n\n\nThis is the procedure to connect On-prem SQL\n\n\n\n\n\nIf the answer is the right solution, please click \"Accept Answer\" and kindly upvote it. If you have extra questions about this answer, please click \"Comment\".\n\nNote: Please follow the steps in our documentation to enable e-mail notifications if you want to receive the related email notification for this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-12-01T10:23:32.107Z",
                "Answer_upvote_count":0,
                "Answer_body":"I'm sorry, but are you sure??? Machine learning is obviously fully dependent on data and you are telling me MS just cut off a significant portion of source types and isolated it to cloud only datasets?",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-08T12:20:05.67Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi Yutong\nAny news on the 2022 Q2 release regarding on-prem and Azure ML?\nThanks in advance",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":22.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Subscription Cost",
        "Question_creation_time":1644315390737,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/726898\/azure-subscription-cost.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-monitor",
            "azure-machine-learning",
            "azure-cost-management"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"my azure subscription cost is decreasing everyday. Knowing that i have deleted everything from my workspace and in my azureml workspace don't have any cluster, I don't know why it is still decreasing.",
        "Answers":[
            {
                "Answer_creation_time":"2022-02-08T10:41:29.22Z",
                "Answer_upvote_count":1,
                "Answer_body":"If you want to review your costs and what resources are being charged, then the Cost Analysis blade will allow you to drill down work this out. Please let us know if this helps",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":19.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Unable to use private docker registry with latest Azure ML release",
        "Question_creation_time":1604958506767,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/157021\/unable-to-use-private-docker-registry-with-latest.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Since the latest Azure ML release, we have been unable to submit any job using a private docker registry. Same jobs were working before the new release.\nWe configure the job as follows (all of this is automated and the code has not changed):\n\nbase_image_name = &#39;REDACTED.azurecr.io\/lb\/learning_box_azure_compute:0.1.15_1601582281&#39;\n\n # Set the container registry information\n myenv = Environment(name=&#34;lb&#34;)\n myenv.docker.enabled = True\n myenv.docker.base_image = base_image_name\n myenv.docker.base_image_registry.address = &#39;REDACTED.azurecr.io\/lb\/&#39;\n myenv.docker.base_image_registry.username, myenv.docker.base_image_registry.password = get_docker_secrets()\n myenv.python.user_managed_dependencies = True\n myenv.python.interpreter_path = &#34;\/opt\/miniconda\/bin\/python&#34;\n\n\n\nInstead of successful job submission, we are instead getting:\n{\n&#34;error&#34;: {\n&#34;message&#34;: &#34;Activity Failed:\\n{\\n \\&#34;error\\&#34;: {\\n \\&#34;code\\&#34;: \\&#34;UserError\\&#34;,\\n \\&#34;message\\&#34;: \\&#34;Unable to get image details : Specified base docker image REDACTED.azurecr.io\/lb\/learning_box_azure_compute:0.1.15_16\\&#34;,\\n \\&#34;details\\&#34;: []\\n },\\n \\&#34;correlation\\&#34;: {\\n \\&#34;operation\\&#34;: null,\\n \\&#34;request\\&#34;: \\&#34;c41448d429f9c80b\\&#34;\\n },\\n \\&#34;environment\\&#34;: \\&#34;eastus\\&#34;,\\n \\&#34;location\\&#34;: \\&#34;eastus\\&#34;,\\n \\&#34;time\\&#34;: \\&#34;2020-11-09T21:40:39.699533Z\\&#34;,\\n \\&#34;componentName\\&#34;: \\&#34;execution-worker\\&#34;\\n}&#34;\n}\n}\nThe image has not changed (we tried a few different ones from prior successful jobs) and the use of the SDK has not changed.\nHas anybody else encountered a similar problem since the Nov 5 upgrade (https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/azure-machine-learning-release-notes)?\nThis is a major block as we cannot proceed with any project that depend on Azure ML at this time.",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-10T13:47:09.613Z",
                "Answer_upvote_count":0,
                "Answer_body":"@FabienCampagne-4175 Thanks for the details, with fully qualified base image name you do not need to specify container registry address. container registry address itself should be just a host name.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":4.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Best practice for migration",
        "Question_creation_time":1656613684597,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/909885\/best-practice-for-migration.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Anyone has been migrated to new studio? Please share experience. I am confused about the migration, how should I copy paste my model from studio",
        "Answers":[
            {
                "Answer_creation_time":"2022-06-30T22:44:31.167Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @Alexandre-2525\n\nThanks for reaching out to us, I think you are talking about move from Studio classc to Designer, please refer to below document:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview\n\nBasically yes for your other thread, you need to rebuild the whole pipeline since we can not copy - paste your orignal structure to Designer.\n\nI am sorry for the inconveniences since the new studio has a disfferent structure to make this migration not that easy. Please let me know if you have any question during this process, we will provide help.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure machine learning designer - edit columns stuck on loading",
        "Question_creation_time":1617486098190,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/343332\/azure-machine-learning-designer-edit-columns-stuck.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Azure machine learning designer :\n\nI have a dataset on the designer connected to a Normalize data module but it keeps loading when i try to Edit columns on Normalize data module with no result or errors.\nThe same thing happens with Select columns in dataset module.\n\nI have tried to recreate and restart and even deleted the whole resource group but no luck.\nI tried on both mac and windows with different browsers but still getting stuck on the same place.\n\nany idea on how to solve this issue?\n\nThanks!\n\nScreenshot:\nhttps:\/\/i.imgur.com\/P0oWrGR.png",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-06T12:14:07.023Z",
                "Answer_upvote_count":1,
                "Answer_body":"@AyushBhardwaj-4354 @yazeenjasim-8837 @AnshulSharma-6861 This issue is now fixed in all regions and it does not require an additional parameter to be added to the URL. Please try and let us know if it works fine.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":12.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Is there a cross-sectional, unified security check list for Azure?",
        "Question_creation_time":1638435378937,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/648921\/is-there-a-cross-sectional-unified-security-check.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-data-factory",
            "azure-functions",
            "azure-machine-learning",
            "azure-data-lake-storage",
            "azure-database-mysql"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"I have been used Azure for the first time, and I am overwelmed by the huge quantity of information about Azure.\n\nI think that the information about security on Azure is not unified.\n\nFor example, in Identity Management and access control security best practices page, sometimes there are multiple best practices per one section header.\nHowever, in Security recommendations for Blob storage page,security recommendations are documented in the form of table, one issue per one row.\n\nI wish there was a cross-sectional, unified security check list for Azure as follows.\n\nWe could select Azure services we use.\n\n\nWhen we select the services, the security check list are displayed or could be downloaded as text file.\n\n\nThe security check list are documented so that we can easily understand what we should do. (where on the Azure portal UI, which item, or how to do set the item which is related to security, etc)\n\nI have used Azure services as follows.\n\nAzure Data Factory\n\n\nAzure Data Lake Storage Gen2\n\n\nAzure Functions (App Service)\n\n\nAzure Database for MySQL\n\n\nAzure Machine Learning\n\n\nAzure Monitor (for Application Insights)\n\nEven if I take one service (for example, Azure Data Lake Storage Gen2), I think that I have to check at least two pages (here and here ).\nHowever, I'm not sure if it's covered. Do you have any good ideas?\n\nRegards.",
        "Answers":[
            {
                "Answer_creation_time":"2021-12-03T17:52:59.01Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @makotooda-1289,\n\nThanks for using Microsoft Q&A!!\n\nI do not think that we have a single document which can provide you a consolidated view of security across all Azure services. You may need to go through the documentation available for individual services to get the required information. However, you can try checking - Azure security documentation and Security considerations for Azure Architecture center if this helps you getting anything specific you are looking in Azure at higher level.\n\nHope this helps.\n\nThanks\nSaurabh",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-12-24T07:47:55.087Z",
                "Answer_upvote_count":0,
                "Answer_body":"Recently, I found the Microsoft Security Benchmarks Repository from the Azure security baseline for Azure Data Factory article.\n\nI think that this repository's contents are comprehensive, and this is that which I've been searching. Is it right?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":21.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Kernel not connected",
        "Question_creation_time":1645626985700,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/747823\/kernel-not-connected.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I have an azureml studio with a notebook and suddenly since today, I cant run notebooks cells anymore. It says kernel not connected.\nI cant either open the terminal it never loads.\n\nI restarted the compute instance several time, but that didnt fix the problem",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-01T10:45:52.13Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @levalencia\n\nThere was an issue causing the \"kernal not connected\" issue, but it has been fixed. Please let us know if you are still blocked by this issue. Thanks a lot!\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"update real interference pipeline",
        "Question_creation_time":1615298736310,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/305899\/update-real-interference-pipeline.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"I deployed my Training pipeline and my Real-time inference pipeline.\nWith the REST-Api of my training pipeline I'm able to retrain my ML model. Is it possible to use that retrained model automated in my real inference pipeline?\nWhen i trigger the pipeline in ML studio I have to update my real inference pipeline manually. Since I want to trigger my retraining external that is not possible.\nThanks in advance.",
        "Answers":[
            {
                "Answer_creation_time":"2021-03-12T19:59:09.187Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, here's a reference on which technology to use based on a given scenario. For your scenario, you should be able to create an Azure Machine Learning pipeline using the SDK to trigger a pipeline based on a time\/change based schedule and then update the web service accordingly. Depending on the complexity of your triggers or data prep needs, you can leverage other technologies such as Logic Apps or Azure Data Factory to trigger your Azure Machine Learning pipeline. Currently, you can only use the Azure Machine Learning SDK to automatically update the web service. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-03-09T21:20:25.76Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, when you deploy a web service from designer, you can select to \"deploy as a new real-time endpoint\" or \"replace an existing real-time endpoint\". The option (replace an existing real-time endpoint) enables you to update the previous endpoint. Currently, there's no way to trigger an update to real-time endpoint, it's still a manual process (I will verify and share updates). To programmatically update your web service using Azure ML SDK, please refer to this document.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Replacement for Azure ML Classic Excel Add In",
        "Question_creation_time":1647680517643,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/778717\/replacement-for-azure-ml-classic-excel-add-in.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"As far as I can tell there is no way to use the Excel add in for Azure ML using the new Azure ML service, it only works for the Classic. Is there any plan to provide a replacement add in that brings this functionality to the new Azure ML before Classic stops being supported in 2024?",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-21T10:14:07.663Z",
                "Answer_upvote_count":0,
                "Answer_body":"@TimCahill-0615 Thanks for the question. Currently it's on roadmap to support in the near future. Excel add in feature similar to studio classic, it will be built on top on v2 online endpoints.\nCurrently, managed endpoints are not integrated with Designer, we need to first provide capability to do a no code designer deployment on v2 online endpoints and integrating excel add in for v2 endpoints.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"need guidance to use train models in ML studio",
        "Question_creation_time":1664405211343,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1027872\/need-guidance-to-use-train-models-in-ml-studio.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"hello new to ML studio. We have some trained model already but I want to use the studio for my next step. How should I import my model and retrain them?",
        "Answers":[
            {
                "Answer_creation_time":"2022-09-29T00:12:34.943Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @Manuel-0778\n\nThanks for using Microsoft Q&A platform. Yes you can import your trained model to Azure Machine Learning Studio - https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-models?tabs=use-local\n\nYou can learn how to register a model from different locations, and how to use the Azure Machine Learning SDK, the user interface (UI), and the Azure Machine Learning CLI to manage your models.\n\nPlease check on above article to see how to register your model. I hope it helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Trigger Azure ML Pipeline from Azure Data Factory",
        "Question_creation_time":1645081864137,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/739240\/trigger-azure-ml-pipeline-from-azure-data-factory.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-data-factory",
            "azure-machine-learning"
        ],
        "Question_upvote_count":5.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"I have created and published a Azure ML pipeline. I want to trigger the ML pipeline from Azure Data Factory.\n\nIn ADF, i have chosen Machine learning execute pipeline and created the linked service to azure machine learning and able to choose the published pipeline endpoint. However while running, i am getting the below error. I couldn't find much information how to resolve the error.\n\n\"Convert Failed. The value type 'System.String', in key 'azureCloudType' is not expected type 'Microsoft.DataTransfer.Common.Models.AzureCloudType\"",
        "Answers":[
            {
                "Answer_creation_time":"2022-02-17T15:32:33.53Z",
                "Answer_upvote_count":3,
                "Answer_body":"Hi @VinothKumarK-8698 ,\nWelcome to Microsoft Q&A platform and thankyou for posting your query.\nAs per the details you have shared in the query, it looks like a product bug. I have raised this issue with the internal Product team. Once I hear back from them, I will keep everyone posted on this. Thanks for your patience!",
                "Answer_comment_count":14,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-02-28T10:12:25.843Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi Ahmed,\n\nWorking now :)\nMany thanks.\n\nRegards,\nJos\u00e9.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":10.0,
        "Question_follower_count":30.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Send new data to Deployed model",
        "Question_creation_time":1619546083177,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/374180\/send-new-data-to-deployed-model.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-blob-storage",
            "azure-event-hubs",
            "azure-iot-central",
            "azure-data-explorer"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello,\n\nWe are sending data from a smartwatch -> IoT Central -> Event Hubs -> Data Explorer -> Blob Storage.\n\nWe are then using the blob storage as a datastore in Machine Learning, which we make a dataset of.\n\nWe deployed a model we trained locally to Azure Machine Learning.\n\nWe now want to send new data from the watch to the model to make predictions on.\n\nWe are wondering how we can do this?\n\nDo we just update the dataset the same way we are currently sending the data? and if so, how can we then auto send it to the model?\n\nOr is there another way to send this new data? Can we still send through blob storage? Or should we send the data directly from the watch to the webservice made by the model?\n\nThanks so much!",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-27T22:16:06.013Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hello @yjay-4307 ,\n\nso you get new data from devices and you want to predict using that data?\n\nCheck out Azure Stream Analytics which can ingest messages from the Event Hub.\n\nThen, you can Azure ML as a function on make decisions based on the incoming data using ML.",
                "Answer_comment_count":7,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":16.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Executing pipeline in AML from ADF suddenly stopped working",
        "Question_creation_time":1639398869747,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/661588\/how-to-run-a-pipeline-in-aml-from-adf.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-data-factory",
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"I have a pipeline defined in Azure Machine Learning. It was launched every day with Azure Data Factory with Machine Learning Execute Pipeline activity. This solution worked without any issues for a few weeks, but since 12\/09\/2021 all pipeline runs have failed with error: User starting the run is not an owner or assigned user to the Compute Instance.\nI did not change anything in ADF or AML.\n\nShould I assign compute to ADF? How to do this?",
        "Answers":[
            {
                "Answer_creation_time":"2021-12-16T21:35:37.337Z",
                "Answer_upvote_count":0,
                "Answer_body":"I ran into this same issue in a slightly different context. I didn't manage to figure out the root cause but managed to resolve it in practice by standing up a Compute Cluster instead of a Compute Instance (see https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-attach-compute-cluster?tabs=python)",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-01-14T07:24:35.053Z",
                "Answer_upvote_count":0,
                "Answer_body":"Using compute cluster as compute target fix the issue.\nRoot cause is compute instance is assigned to certain user or team, and service principle or managed identity is not in the assigned user group in compute instance. Compute cluster can be used by multi-users, and other services.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":16.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"azure guidance video out of date in YouTube",
        "Question_creation_time":1659301109740,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/949113\/azure-guidance-video-out-of-date-in-youtube.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"hello, I was doing some search in the internet about azure machine learning, I found videos published in YouTube but out of date. Please update it",
        "Answers":[
            {
                "Answer_creation_time":"2022-08-01T01:19:53.043Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @matsuoka-4412\n\nThanks for the feedback, we are aware of this issue and have forwarded the feedback to product group. Sorry for the experience.\n\nActually some of the videos are for some technicle event, I will suggest content team to deliver the video with more version info so that future audience will not be confused.\n\n\n\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure endpoint in decimal notation",
        "Question_creation_time":1639603918890,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/665285\/azure-endpoint-in-decimal-notation.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello, I've set up an Azure endpoint and I'm trying to communicate with it using some old software that can only read decimal notation. The scientific notation the endpoint occasionally delivers is breaking it. Is there a way to configure the endpoint to return only decimal notation? Ideally just with the correct header like \"application\/jsonlegacy\" or something?",
        "Answers":[
            {
                "Answer_creation_time":"2021-12-16T06:58:54.83Z",
                "Answer_upvote_count":1,
                "Answer_body":"@JonathanHorton-4850 Returning a decimal value from an endpoint should be possible. I think this depends on the training of the experiment if the ML studio is used. I have an experiment which returns decimals. You can use a similar setup with Apply transformation module or Apply Math operation if using the newer version of the studio.\n\n\n\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Attaching local computer to ML Studio and use it with Azure AutoML and Azure Designer",
        "Question_creation_time":1624632132377,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/452250\/attaching-local-computer-to-ml-studio-and-use-it-w.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hey there,\n\nI was wondering, whether it is possible to connect your local computer as a compute target to the workspace and then access it as a compute target for AutoML and the Designer in the ML Studio (instead of a compute cluster)?\nI have read through the documentation and I feel like if this is possible, it is not very well-documented.\n\nThanks in advance!",
        "Answers":[
            {
                "Answer_creation_time":"2021-06-25T20:20:23.443Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for reaching out. You can use local compute for model training\/deployment including automl. However, you cannot attach it directly in Designer or ML Studio interface. You can only attach it from your local environment. Hope this helps!",
                "Answer_comment_count":5,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"AutoML : TensorFlowDNN and TensorFlowLinearRegressor are blacklisted by default",
        "Question_creation_time":1653464529937,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/863297\/automl-tensorflowdnn-and-tensorflowlinearregressor.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello,\n\nI am running an AutoML experiment for a regression task, and looking at the YAML file which is generated it seems that TensorFlowLinearRegressor and TensorFlowDNN models are listed as both 'supported_models' and 'blacklist_algos'.\n\nI tried to deactivate the automatic blacklisting of models by specifying the parameter 'auto_blacklist' to False, and 'blacklist_models' and 'blacklist_algos' parameters to Null, but it doesn't change anything.\n\n automl_settings = {\n     \"primary_metric\": 'normalized_mean_absolute_error',\n     \"featurization\": 'auto',\n     \"verbosity\": logging.INFO,\n     \"n_cross_validations\": 5,\n     \"auto_blacklist\": False,\n     \"blacklist_models\": None,\n     \"blacklist_algos\": None\n }\n run = experiment.submit(automl_config, show_output=True)\n\n\n\nThe generated YAML file (excerpt):\n\n \"whitelist_models\":null,\n \"blacklist_algos\":[\"TensorFlowDNN\",\"TensorFlowLinearRegressor\"],\n \"supported_models\":[\"ElasticNet\",\"GradientBoosting\",\"LightGBM\",\"TensorFlowLinearRegressor\",\"TensorFlowDNN\",\"LassoLars\",\"DecisionTree\",\"RandomForest\",\"FastLinearRegressor\",\"OnlineGradientDescentRegressor\",\"ExtremeRandomTrees\",\"TabnetRegressor\",\"XGBoostRegressor\",\"KNN\",\"SGD\"],\n \"private_models\":[],\n \"auto_blacklist\":false\n\n\n\nMaybe the problem comes from the fact that Deep learning is set to 'Disabled' in the configuration settings, as shown on the following picture:\n\nAre deep learning models not supported anymore by AutoML?",
        "Answers":[
            {
                "Answer_creation_time":"2022-06-03T06:03:46.443Z",
                "Answer_upvote_count":0,
                "Answer_body":"@ThierryL-3166 Thanks for the question.\n\nAs mentioned in the below document The following support models in AutoML TensorFlowDNN, TensorFlowLinearRegressor are deprecated.\nhttps:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-automl-core\/azureml.automl.core.shared.constants.supportedmodels.regression?view=azure-ml-py",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"UserProcessKilledBySystemSignal: Job failed since the user script received system termination signal usually due to out-of-memory or segfault.",
        "Question_creation_time":1620234016640,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/384152\/userprocesskilledbysystemsignal-job-failed-since-t.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi, I am getting this error when scoring a model.\n\nSeems like it is an out-of-memory issue or a segfault issue (no idea what that means).\n\nI'm using Designer while my compute is Standard Dv2 Family vCPUs. Have made no changes to my storage account key.\n\nAny advice on how to debug this one? Many thanks in advance\n\nAzureMLCompute job failed.\nUserProcessKilledBySystemSignal: Job failed since the user script received system termination signal usually due to out-of-memory or segfault.\nReason: Process Killed with either 6:aborted or 9:killed or 11:segment fault. exit code here is from wrapping bash hence 128 + n\nCause: killed\nTaskIndex:\nNodeIp: 10.0.0.5\nNodeId: tvmps_ee452edcf7395836bdf60c0e0cd5f3a6308fafbb41c860c50a47be1367393df6_d\nReason: Job failed with non-zero exit Code",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-05T17:25:17.22Z",
                "Answer_upvote_count":0,
                "Answer_body":"Seems like it was an out-of-memory problem. If I reduce the trainning set, I get no error.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-05-06T21:07:20.663Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for the update the confirmation regarding to this. ^^\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"is move workspace easy?",
        "Question_creation_time":1664405263187,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1027803\/is-move-workspace-easy.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"we are not sure about our location but we do want to start now. If we need to move our workspace, is that possible? easy to accomplishing? Thank you",
        "Answers":[
            {
                "Answer_creation_time":"2022-09-29T02:12:26.213Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @Manuel-0778\n\nThanks for using Microsoft Q&A platform. In my opionion, it depends on your scenario. Please check on this preview feature - https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-move-workspace\n\nAs the document said, there are a lot of limitations -\n\nWorkspace move is not meant for replicating workspaces, or moving individual assets such as models or datasets from one workspace to another.\n\n\nWorkspace move doesn't support migration across Azure regions or Azure Active Directory tenants.\n\n\nThe workspace mustn't be in use during the move operation. Verify that all experiment jobs, data profiling jobs, and labeling projects have completed. Also verify that inference endpoints aren't being invoked.\n\n\nThe workspace will become unavailable during the move.\n\n\nBefore to the move, you must delete or detach computes and inference endpoints from the workspace.\n\n\nDatastores may still show the old subscription information after the move.\n\nEspecially the second point, if you are considering move the region, you may need to be careful. I hope this helps!\n\nLet me know if you have more questions and we are happy to help.\n\n\n\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-09-29T00:25:39.95Z",
                "Answer_upvote_count":0,
                "Answer_body":"Kindly go through the following reference:\n\nMove your workspace",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"how to delete Azure ML real-time endpoints which is in transition state",
        "Question_creation_time":1628858328673,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/513012\/how-to-delete-azure-ml-real-time-endpoints-which-i.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi,\n\nI have made deployment of the model from the AutoML experiment, due to the issue in the resources associated. Deployment has failed.\n\nBut the real-time endpoint has been in the transition state for few hours, I can't delete it and the model registered along with it due to this. How can I force delete in this case. Please provide a solution.\n\nThanks",
        "Answers":[
            {
                "Answer_creation_time":"2021-08-16T11:16:36.937Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thank you for the response @romungi-MSFT. I have left the feedback to the team.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Import ML Model from ADLS to Azure ML using Databricks",
        "Question_creation_time":1642414997297,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/697789\/import-ml-model-from-adls-to-azure-ml-using-databr.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-databricks"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi,\nI have stored some ml model in my ADLS and I want to register the model to Azure ML using databricks.\nTried to use the following codes to register my ml model but keep encountering an error that the path cannot be found.\n\nimport urllib.request\nfrom azureml.core.model import Model\n\nRegister a model\n\n\n\nmodel = Model.register(model_path = 'dbfs:\/mnt\/machinelearning\/classifier.joblib',\nmodel_name = \"pretrained-classifier\",\ndescription = \"Pretrained Classifier\",\nworkspace=ws)",
        "Answers":[
            {
                "Answer_creation_time":"2022-01-17T16:51:50.977Z",
                "Answer_upvote_count":1,
                "Answer_body":"@Yuzu-9670 Using the databricks file path for registering a model is not supported. When using the model.register() you need to download the model locally and then use the path of the model or the folder in which the model is present to register the same.\n\n\n\n\nmodel_path\n\n\nThe path on the local file system where the model assets are located. This can be a direct pointer to a single file or folder. If pointing to a folder, the child_paths parameter can be used to specify individual files to bundle together as the Model object, as opposed to using the entire contents of the folder.\n\nThis sample notebook should help you with using the method.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-01-18T06:21:46.863Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @romungi-MSFT,\nThank you for your comment!\nI have shifted my ml model to a repo folder and it works now.\nThank you!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":15.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Request help with Azure machine learning workspace",
        "Question_creation_time":1655371059130,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/891716\/request-help-with-azure-machine-learning-workspace.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I have enrolled myself in Azure Machine Learning course and the first step there is to create an azure ML workspace with subscription, resource group, region, storage account etc. I am a new joiner and I am doing this for my learning. Not sure which option to select. Is there any guidance or doc to follow? I have checked with my team and they are suggesting to use my personal account to get a demo account and free azure subscription to do the course and not my microsoft credentials. Require assistance in this regard.",
        "Answers":[
            {
                "Answer_creation_time":"2022-06-16T12:53:52.827Z",
                "Answer_upvote_count":0,
                "Answer_body":"@SanjanaDas-0274 Thanks for the question. Here is the document to Create workspace resources you need to get started with Azure Machine Learning. You can use your personal account to get free azure subscription.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/quickstart-create-resources\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Problems connecting to workspace using Azure Machine Learning SDK for Python",
        "Question_creation_time":1606083056563,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/171465\/problems-connecting-to-workspace-using-azure-machi.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "windows-forms"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":5,
        "Question_has_accepted_answer":true,
        "Question_body":"I am trying to connect to my Azure ML workspace using SDK for python, using Virtual Studio Code to do so. After pip installing the needed SDK packages:\npip install azureml-sdk\npip install azureml-sdk[notebooks,automl,explain]\n\nI downloaded the .json configuration file for my workspace, made sure it was in the correct location for the file path and tried the following code (with my subscription id, resource group and workspace name in place of the fillers in this chunk of code):\n\n {\n     \"subscription_id\": \"1234567-abcde-890-fgh...\",\n     \"resource_group\": \"aml-resources\",\n     \"workspace_name\": \"aml-workspace\"\n }\n\n\n\nUpon executing this in my ipy kernel in Virutal Studio Code I got a UserErrorException (see image below, I have blocked out subscription id's and other sensitive information):\n\n\n\n\n\n\nI then tried this alternative way to connect to my workspace using the following code (again with my info filled in instead of the fillers in the code):\nfrom azureml.core import Workspace\n\n from azureml.core import Workspace\n    \n ws = Workspace.get(name='aml-workspace',\n                    subscription_id='1234567-abcde-890-fgh...',\n                    resource_group='aml-resources')\n    \n ws = Workspace.from_config()\n\n\n\nThis produced the same error upon execution. I have tried using different subscriptions with different workspace names and resource groups and it gives me the same error every time. It appears to be telling me I do not have access to the subscription that I am logged in to? I am unsure how to fix this. I am trying to do this as part of the lessons in the Microsoft Azure Data Scientist certification if anyone is familiar with that or has run into the same problem while trying to complete the modules for that certification provided through Microsoft.",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-23T02:07:42.373Z",
                "Answer_upvote_count":3,
                "Answer_body":"can you try using InteractiveLoginAuthentication?\n\nbelow code might help you\n\n from azureml.core.authentication import InteractiveLoginAuthentication\n ia = InteractiveLoginAuthentication(tenant_id='YourTenant id')\n # You can find tenant id under azure active directory->properties\n ws = Workspace.get(name='aml-workspace',\n                     subscription_id='1234567-abcde-890-fgh...',\n                     resource_group='aml-resources',auth=ia)",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2020-12-17T09:25:40.42Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\nI have the same problem. I tried InteractiveLoginAuthentication first but I had this error :\n\n\"error\": {\n\"message\": \"No workspaces found with name=projet7 in subscription=d9b1b5ff-XXX-XXXX-XXXX-XXXXXXXXXXXX\"\n}\n\nia = InteractiveLoginAuthentication(tenant_id='712a4781-YYYY-YYYY-YYYY-YYYYYYYYYYYY')\nws = Workspace.get(name='Projet7',\nsubscription_id='d9b1b5ff-XXX-XXXX-XXXX-XXXXXXXXXXXX',\nresource_group='classroom',auth=ia)\n\nI'm using a virtual machine azure sku='server-2019'; Python 3.6 - AzureML - AutoML",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-12-18T19:46:23.42Z",
                "Answer_upvote_count":0,
                "Answer_body":"I have already created Project7 by portal.\n\nI tried to create a new one.\n\nia = InteractiveLoginAuthentication(tenant_id=\"712a4781-YYYY-YYYY-YYYY-YYYYYYYYYYYY\")\nws = Workspace.create(name='RNN_workspace',\nsubscription_id='\/subscriptions\/d9b1b5ff-XXX-XXXX-XXXX-XXXXXXXXXXXX',\nresource_group='classroom',\ncreate_resource_group=False,\nlocation='West Europe',\nauth=ia\n)\n\nbut I had the same error :\n\nUserErrorException: UserErrorException:\nMessage: You are currently logged-in to 712a4781-YYYY-YYYY-YYYY- tenant. You don't have access to \/subscriptions\/d9b1b5ff-XXX-XXXX-XXXX-XXXXXXXXXXXX subscription, please check if it is in this tenant. All the subscriptions that you have access to in this tenant are =\n[SubscriptionInfo(subscription_name='Microsoft Azure ffffff', subscription_id='d9b1b5ff-XXX-XXXX-XXXX-'), SubscriptionInfo(subscription_name='Lab 2 - Extension name_axtension', subscription_id='59383c45-MMMM-MMMM-')].",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-12-18T20:17:50.353Z",
                "Answer_upvote_count":0,
                "Answer_body":"!az login\n[\n{\n\"cloudName\": \"AzureCloud\",\n\"homeTenantId\": \"712a4781-YYYY-YYYY-YYYY-YYYYYYYYYYYY\",\n\nYou have logged in. Now let us find all the subscriptions to which you have access...\nThe following tenants don't contain accessible subscriptions. Use 'az login --allow-no-subscriptions' to have tenant level access.\nc9587321-JJJJ-JJJJ-JJJJ-JJJJJJJJJJJJ\n\n\n\n \"id\": \"d9b1b5ff-XXX-XXXX-XXXX-XXXXXXXXXXXX\",\n \"isDefault\": true,\n \"managedByTenants\": [],\n \"name\": \"Microsoft Azure MMMM\",\n \"state\": \"Enabled\",\n \"tenantId\": \"712a4781-YYYY-YYYY-YYYY-YYYYYYYYYYYY\",\n \"user\": {\n   \"name\": \"adress\",\n   \"type\": \"user\"\n }\n\n},\n{\n\"cloudName\": \"AzureCloud\",\n\"homeTenantId\": \"712a4781-YYYY-YYYY-YYYY-YYYYYYYYYYYY\",\n\"id\": \"59383c45-RRRR-RRRR-RRRR-RRRRRRRRRRRR\",\n\"isDefault\": false,\n\"managedByTenants\": [],\n\"name\": \"Lab 2 - Extension RRRRR\",\n\"state\": \"Enabled\",\n\"tenantId\": \"712a4781-YYYY-YYYY-YYYY-YYYYYYYYYYYY\",\n\"user\": {\n\"name\": \"adress\",\n\"type\": \"user\"\n}\n}\n]\n\n\n\n\n\n!az account show\n{\n\"environmentName\": \"AzureCloud\",\n\"homeTenantId\": \"712a4781-YYYY-YYYY-YYYY-YYYYYYYYYYYY\",\n\"id\": \"d9b1b5ff-XXX-XXXX-XXXX-XXXXXXXXXXXX\",\n\"isDefault\": true,\n\"managedByTenants\": [],\n\"name\": \"Microsoft Azure MMMM\",\n\"state\": \"Enabled\",\n\"tenantId\": \"712a4781-YYYY-YYYY-YYYY-YYYYYYYYYYYY\",\n\"user\": {\n\"name\": \"adress\",\n\"type\": \"user\"\n}\n}\n\n\n\n\nI don't undestand why my tenant id can't contain accessible subscriptions !!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-02-10T11:40:37.92Z",
                "Answer_upvote_count":0,
                "Answer_body":"I have the same issue and my previous colleague had the same issue in his laptop. My previous colleague called support for help and solved the problem. But the solution MS support provided was not permanent. What MS support provided was to use interactive mode to clear caching and user information. But in the production development environment people cannot use interactive mode all the time to clear caching.\n\nNow I am having the same issue but in production environment. When switching subscriptions, somehow python sdk can not fetch new list of subscription ids. I have been added to this particular subscription for more than a week. Couldnot say my account was added \"recently\".\n\nI feel this is a bug.\n\n ServicePrincipalAuthentication(tenant_id=tenant_id,\n                     service_principal_id=service_principal_id,\n                     service_principal_password=service_principal_password,\n                     _enable_caching=False)\n Workspace.get('workspace',\n                     subscription_id='subscription_id',\n                     resource_group='resource_group',\n                     auth=sp)\n\n\n\n\nI created an issue in the GitHub where azure ml related are discussed.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":13.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML pipeline from an Azure DevOps pipeline",
        "Question_creation_time":1667236694490,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1069739\/azure-ml-pipeline-from-an-azure-devops-pipeline.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Tried invoking an Azure ML pipeline from an Azure DevOps pipeline ? I keep running into errors, so I want to make sure my high level process is correct.",
        "Answers":[
            {
                "Answer_creation_time":"2022-11-01T02:57:49.657Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Srin-4824 Thanks for the question. You can use the Azure CLI task - Azure Pipelines | Microsoft Docs step and run command line or Python scripts inside that to submit your pipelines.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Types of Regression Algorithm",
        "Question_creation_time":1608719172483,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/208685\/types-of-regression-algorithm.html",
        "Question_topic":null,
        "Question_tag":[
            "not-supported-azure",
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"What are the types of Regression algorithm? Are there any kinds of regression called \"non-linear regression\"?",
        "Answers":[
            {
                "Answer_creation_time":"2020-12-24T13:50:48.27Z",
                "Answer_upvote_count":0,
                "Answer_body":"@SanniddhaChakrabarti-9451 Please follow the below document for Regression.\nhttps:\/\/www.analyticsvidhya.com\/blog\/2015\/08\/comprehensive-guide-regression\/#:~:text=Regression%20analysis%20is%20a%20form,effect%20relationship%20between%20the%20variables.\n\nTypes of Regressions:\nLinear Regression\nLogistic Regression\nPolynomial Regression\nStepwise Regression\nRidge Regression\nLasso Regression\nElasticNet Regression",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Problem: AML Designer - Batch Inference Pipeline",
        "Question_creation_time":1639744934170,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/667479\/problem-aml-designer-batch-inference-pipeline.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi Team,\n\nWhen I Submit the Batch Inference Pipeline. It is working.\n\n\n\nAfter submitting, I can see the file:\n\n\nThen when I Publish, the file is not in the Datastore. The file is not generated again. I didn't get an error.\n\nKind regards,\nAnaid",
        "Answers":[
            {
                "Answer_creation_time":"2022-01-19T09:16:36.71Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Anaid-6816\n\nHi,\n\nI\u2019ve enabled one-time Free Technical Support for you. To create the support request, please do the following:\n\n\n\n\n\u2022 Go to the Health Advisory section within the Azure Portal: https:\/\/aka.ms\/healthadvisories\n\u2022 Select the Issue Name \"You have been enabled for one-time Free Technical Support\"\n\u2022 Details will populate below in the Summary Tab within the reading pane and you can click on the link \"Create a Support Request\" to the right of the message\n\nLet me know what your support request number is so that I can keep track of your case. If you run into any issues, feel free to let me know.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure OpenAI advantages",
        "Question_creation_time":1648125540293,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/785866\/azure-openai-advantages.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-openai"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"We have a customer that is interested in the Azure OpenAI Service and had a few question:\n\nWhat are the advantages for using Azure OpenAI vs. OpenAI API.",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-24T14:21:38.047Z",
                "Answer_upvote_count":0,
                "Answer_body":"@App-4824 Thanks for the question. The Azure OpenAI team always works to make the latest models available in Azure as soon as they are available from OpenAI. This is an active area of work for the team to tighten release date for future models.\nThe Azure service is backed by an SLA (which typically a customer's primary need for high availability, low latency), and the support that comes along with Azure services. This is the first commercialized model of its kind from any public cloud provider. This is unique advantage to be first to market and to work closely with customer to adopt\/embrace these models for production use.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Unable to creata a compute instance",
        "Question_creation_time":1616247083753,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/323742\/unable-to-creata-a-compute-instance.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-virtual-machines",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"I'm trying to follow the steps given here - https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/explore-analyze-data-with-python\/2-exercise-explore-data\n\nI've tried regions east us2 and east us for creating the instance but it fails after taking more than half an hour. I tried virtual machine sizes - Standard_DS11_v2 & Standard_DS3_v2.\n\nAny help would be appreciated.\n\nEdit - I don't have any other instances running in my subscription, so it should not be a quota issue. The error message says \"An internal server error occurred.\".",
        "Answers":[
            {
                "Answer_creation_time":"2021-03-20T23:14:19.877Z",
                "Answer_upvote_count":0,
                "Answer_body":"Good day @AatishSuman-7641\n\nDid you read the comment in the compute page?\n\nPlease confirm that you are using an account which fit the limitations\n\nFor more information please check this post:\n\nhttps:\/\/azure.microsoft.com\/en-us\/blog\/update-2-on-microsoft-cloud-services-continuity\/\n\nNote: I followed the tutorial which you provided the link to and it is working well for me. Therefore, I assume the issue is related to the above comment.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-03-20T13:46:48.237Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @AatishSuman-7641\nThank You for posting in Q & A.\n\nPlease verify in azure portal you have Quota available for this virtual machine sizes - Standard_DS11_v2 & Standard_DS3_v2.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/azure-resource-manager\/templates\/error-resource-quota#solution\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/networking\/check-usage-against-limits\n\nCan you share exact error message so that we can have more information to provide a solution.\n\n\n\n\nIf the Answer is helpful, please click Accept Answer and up-vote, this can be beneficial to other community members.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"list of folder names as input for ParallelRunStep-class",
        "Question_creation_time":1647256395817,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/771015\/list-of-folder-names-as-input-for-parallelrunstep.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"In this example, all data files for the parallel run step are stored in one folder.\n\nI also want to create a parallel run step. The task for each of the several folders, in which the multiple data files are stored, is exactly identical.\n\nThe folders:\n\n\n\n\n\nThe content of each folder:\n\n\n\n\n\nHow should I define the ParallelRunStep-class so that the identical task for each folder (here 'a', 'b', 'c', 'd' and 'e') is executed in parallel?\nTwo folders should run simultaneously in parallel.\n\nMoreover, I would like to ask how to get only the stored folder names or folder paths from a given directory path of a blob storage container.",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-21T10:25:43.237Z",
                "Answer_upvote_count":1,
                "Answer_body":"@@AlexanderPakakis-0994 Thanks, An Azure ML dataset is just metadata pointing to a path or collection of paths in an Azure storage account. You should first \"merge\" those datasets into a collection of adjacent folders (e.g. root\/dataset1\/, root\/dataset2\/, ...) and then run PRS against root\/**.",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to specify HTTP response status code in AML R Web Service",
        "Question_creation_time":1612354860267,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/257156\/how-to-specify-http-response-status-code-in-aml-r.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":3,
        "Question_has_accepted_answer":true,
        "Question_body":"Is there any way to return a custom HTTP status code from R Web Service in Azure ML?\n\nAll the examples of entry scripts in documentation return the response body from the scoring function. In Python Web Service, it is possible to return a HTTP response object with a custom status code. However, R's httr library does not seem to have any function to create response objects directly (only via HTTP method objects such as POST, which call a given URL).\n\nI would like to implement a custom exception handling scheme in R Web Service. Is there any way to return a custom HTTP code from the entry script?\n\nEDIT: Found this idea on the feedback forum, which suggests that the option is not available in Python Web Service either:\nhttps:\/\/feedback.azure.com\/forums\/257792-machine-learning\/suggestions\/40122838-make-http-status-codes-controllable-from-your-scor",
        "Answers":[
            {
                "Answer_creation_time":"2021-02-03T23:14:52.687Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello Lauri,\n\nThanks for the feedback. Yes, we have this product idea in our backlog. I will help to bump up this idea to product group again. ^^\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-02-03T19:17:19.37Z",
                "Answer_upvote_count":0,
                "Answer_body":"I found that it is possible to return \"502 Replica failed\" by raising an exception in the entry script. However, it would still be nice to be able to return custom status codes.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-02-05T01:56:45.177Z",
                "Answer_upvote_count":0,
                "Answer_body":"This sample shows how to return custom StatusCode (returns 200 or 500):\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script#binary-data",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Consume Azure ML Web Service with Postman: how to pass arguments?",
        "Question_creation_time":1603965300457,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/144230\/consume-azure-ml-web-service-with-postman-how-to-p.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Is it possible to pass parameters to an Azure ML Web Service with Postman? I created an R web service endpoint that runs in an Azure Container Instance. My run function has one argument (\"data\"). I can call the web service using Azure ML R SDK (using invoke_webservice()) and the input parameter is read successfully from the request content. The input is constructed like:\n\n toJSON(data.frame(data=\"This is my test string\"))\n\n\n\nResult:\n\n [{\"data\": \"This is my test string\"}]\n\n\n\nIf I create a Postman request and copy the input to the request body, the input parameter is not passed to the web service. The web service can return a static output to Postman but the variable data is always empty. Is this a property of the ML Web Service? If not, how can I set up the request body so that the argument is read successfully? I have tried many variations, but none have worked.\n\nI have set content-type header to application\/json. I don't have authentication in the web service, since it is just a test instance.\n\nUltimately, we need to call the web service with C# from Azure Function. I know that we can use the C# template from documentation and it can probably pass the parameter to the web service, but it would be nice to be able to test the web service with Postman.",
        "Answers":[
            {
                "Answer_creation_time":"2020-10-29T12:55:26.077Z",
                "Answer_upvote_count":1,
                "Answer_body":"Try this in postman.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Converting textanalytics result to JSON Format",
        "Question_creation_time":1650967532993,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/826603\/converting-textanalytics-result-to-python.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello,\nI am using the example provided in the Machine Learning Studio Docs for extracting Health Entities from a given string.\nThe code is shown below.\n\nMy question is: what is the easiest way to convert the output result into JSON format?\n\n from azure.core.credentials import AzureKeyCredential\n from azure.ai.textanalytics import TextAnalyticsClient\n import json\n    \n credential = AzureKeyCredential(\"**********************************\")\n endpoint=\"https:\/\/eastus.api.cognitive.microsoft.com\/\"\n    \n text_analytics_client = TextAnalyticsClient(endpoint, credential)\n    \n documents = [\"Subject is taking 100mg of ibuprofen twice daily\"]\n    \n poller = text_analytics_client.begin_analyze_healthcare_entities(documents)\n result = poller.result()\n    \n docs = [doc for doc in result if not doc.is_error]\n    \n print(\"Results of Healthcare Entities Analysis:\")\n for idx, doc in enumerate(docs):\n     for entity in doc.entities:\n         print(\"Entity: {}\".format(entity.text))\n         print(\"...Normalized Text: {}\".format(entity.normalized_text))\n         print(\"...Category: {}\".format(entity.category))\n         print(\"...Subcategory: {}\".format(entity.subcategory))\n         print(\"...Offset: {}\".format(entity.offset))\n         print(\"...Confidence score: {}\".format(entity.confidence_score))\n         if entity.data_sources is not None:\n             print(\"...Data Sources:\")\n             for data_source in entity.data_sources:\n                 print(\"......Entity ID: {}\".format(data_source.entity_id))\n                 print(\"......Name: {}\".format(data_source.name))\n         if entity.assertion is not None:\n             print(\"...Assertion:\")\n             print(\"......Conditionality: {}\".format(entity.assertion.conditionality))\n             print(\"......Certainty: {}\".format(entity.assertion.certainty))\n             print(\"......Association: {}\".format(entity.assertion.association))\n         for relation in doc.entity_relations:\n             print(\"Relation of type: {} has the following roles\".format(relation.relation_type))\n         for role in relation.roles:\n             print(\"...Role '{}' with entity '{}'\".format(role.name, role.entity.text))\n     print(\"------------------------------------------\")",
        "Answers":[
            {
                "Answer_creation_time":"2022-04-26T14:18:10.653Z",
                "Answer_upvote_count":0,
                "Answer_body":"@KamranAli-0346 The result does not seem to be directly serializable to JSON. I found a library JSONS that can do the heavy lifting if you are using python 3.5 or higher.\n\nInstall jsons\n\n pip install jsons\n\n\n\nImport JSONS and using jsons.dump() on docs object.\n\n import jsons #import in the import section\n print(jsons.dump(docs)) #Printing the json after docs is created\n\n\n\nThis should give a file of this format in this case. Uploaded the file in .txt format since JSON files cannot be uploaded on Q&A, download the file and rename it to .json\nI hope this helps!!\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.\n\n\n\n\n196624-health.txt",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"azure ml designer: how to call a pipeline from another pipeline",
        "Question_creation_time":1619288778083,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/370433\/azure-ml-designer-how-to-call-a-pipeline-from-anot.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I'm using ML Designer and i have created a sub-pipeline that i want to use it in other pipelines. how do i call that sub-pipeline from the designer?\n\nThe purpose of the subpipeline is to transform data, so the output is a dataset.",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-26T14:59:45.637Z",
                "Answer_upvote_count":0,
                "Answer_body":"@javier-8889Thanks for the question. Can you please add more details about the pipeline steps. You can implement an AML pipeline with Python code, but also with the new AML designer which under the covers is creating an AML Pipeline defining that \u201cvisual workflow\u201d. Basically you can register a trained model in Designer bring it out with SDK\/CLI to deploy it. Currently only Data Drift Monitor (Data Drift->EventGrid->LogicApp->Trigger Pipeline) allows to trigger a pipeline when dataset drift has been detected.\n\nWhen designing a pipeline in Azure ML Designer, each step or module creates intermediate datasets that can be seen using the UI using Visualize option. Those datasets are persisted in the blob storage.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Cost of running a compute, other tasks",
        "Question_creation_time":1634318912257,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/592299\/cost-of-running-a-compute-other-tasks.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi;\n\nFirst off, where can I find the costs for all the different things I can run in Azure ML? Not just a compute, but editing a notebook, connecting to a datastore, splitting a datastore, etc. Basically where is the price list?\n\nSecond, where can I find what I will be charged for things I ran in the last hour? I want to see what I'm spending before a month is up and the charge is then 100x what I expected (and can afford).\n\nthanks - dave",
        "Answers":[
            {
                "Answer_creation_time":"2021-10-16T01:32:38.867Z",
                "Answer_upvote_count":2,
                "Answer_body":"Hi, you can use Azure Cost Management to manage Azure costs, please review the quickstart document. Also, the following document provides detailed information on how to plan and manage cost for AML.\n\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Remote run model unable to be saved",
        "Question_creation_time":1613083790957,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/270011\/remote-run-model-unable-to-be-saved.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I've built models using the AutoML function and I'm trying to call the best model to deploy into production. The AutoML function ran correctly and produced the ~35 models. My goal is to pull the best model. Here is the code:\n\nbest_run, fitted_model = remote_run.get_output()\nfitted_model\n\nWhen runnning the code, I get the following error:\n\nAttributeError: 'DataTransformer' object has no attribute 'enable_dnn'\n\nAny help would be much appreciated.",
        "Answers":[
            {
                "Answer_creation_time":"2021-02-12T11:23:05.603Z",
                "Answer_upvote_count":0,
                "Answer_body":"@BernardoJaccoud-0827 Did your run configure enable_dnn i.e bert settings of automated ML? I am curious to understand what the status of your run is directly on the portal ml.azure.com?",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Use custom environment in Azure Machine Learning Designer",
        "Question_creation_time":1647597231527,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/777745\/use-custom-environment-in-azure-machine-learning-d.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello,\n\nI would like to know if there is the possibility to use a custom environment (created from the AML portal) for the execution of a Python Script Step in the Azure Machine Learning Designer (only using the designer, not using azureml sdk to publish the pipeline from the code).\n\nThanks,\nG",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-28T19:05:42.677Z",
                "Answer_upvote_count":1,
                "Answer_body":"Thanks for your feedback. Based on your comments above, it seems you want to configure a custom environment in AML designer and install unsupported python libraries. These are the supported Custom Environments. However, in AML designer, the execute python script component enables you to write custom python scripts and install python libraries. This particular document shows how to configure execute python script. You can install packages that aren't in the preinstalled list by using the following command:\n\n import os\n os.system(f\"pip install scikit-misc\")\n\n\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Facing problem in deplying pyhton application from github- unable to load tensorflow saved model in AZURE.",
        "Question_creation_time":1625428420640,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/462250\/facing-problem-in-deplying-pyhton-application-from.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-webapps",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I am trying to deploy a classification TensorFlow model on AZURE from GitHub. It is getting deployed correctly which can be seen from the below logs.\n![111656-image.png][1]\n\n\n\n\nBut I'm getting an OSError on log Stream saying saved model doesn't exist as shown below. The error msg is highlighted in red.\n![111560-image.png][2]\n\nBut this is working correctly on local. This model has been checked locally.\nThe repository for this can be checked at https:\/\/github.com\/Vikeshkr-DSP\/cassava-leaf-disease-prediction.\nThanks in advance for your help.\n[1]: \/answers\/storage\/attachments\/111656-image.png\n[2]: \/answers\/storage\/attachments\/111560-image.png",
        "Answers":[
            {
                "Answer_creation_time":"2021-07-06T14:43:55.013Z",
                "Answer_upvote_count":0,
                "Answer_body":"The above issue on OSError: SavedModel file does not exist at: cassava_leaf.h5\/{saved_model.pbtxt|saved_model.pb} was due to a bit large size of model and we did not provide an absolute path to the model location, the application could not find the same during startup.\n\nThe issue resolved by manually transferring the h5-model file to a location like \/home on the App Service and updated the app.py file to use an absolute path in order to refer the file.\n\nSimilar to: model=load_model('\/home\/cassava_leaf.h5')",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Can I use compressed data on TabularDataset?",
        "Question_creation_time":1638234150553,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/645118\/can-i-use-compressed-data-on-tabulardataset.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-data-lake-storage"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I have a question about the source of TabularDataset on Azure Machine Learnigng.\n\nCan I use compressed data saved Azure Data Lake Storage Gen2 like below on TablarDataset without expansion?\n\ncsv with bzip2(.bz2)\n\n\nparquet with gzip(gz)\n\n\nparquet with snappy",
        "Answers":[
            {
                "Answer_creation_time":"2021-11-30T02:15:20.327Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, tabular dataset does not support compressed files. You'll need to extract the data as shown here for example before creating a tabular dataset. However, file dataset supports any format.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":13.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Tensorflow and Azure machine learning",
        "Question_creation_time":1653989511207,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/871068\/tensorflow-and-azure-machine-learning.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Is azure working well with Tensorflow framework? I don\u2019t see any document about it. Any help is good.",
        "Answers":[
            {
                "Answer_creation_time":"2022-05-31T10:26:09.017Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hello @Chungsun-1776\n\nWelcome to the Microsoft Q&A Platform,\n\nTensorFlow is supported on Azure Machine Learning:\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-tensorflow\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/azure-functions\/functions-machine-learning-tensorflow?tabs=bash\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-keras\n\nI hope this helps!\n\nPlease don\u2019t forget to \"Accept the answer\" and \u201cup-vote\u201d wherever the information provided helps you, this can be beneficial to other community members.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"What's the best way to preserve Azure ML workspace so that it can be restored",
        "Question_creation_time":1669442139003,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1105130\/what39s-the-best-way-to-preserve-azure-ml-workspac.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"What's the best way to preserve Azure ML workspace so that it can be restored at a later point? I was hoping to find some automatic way to take a snapshot of artifacts & code and dump it into Azure storage, but haven't been able to find anything relevant in the online documentation.",
        "Answers":[
            {
                "Answer_creation_time":"2022-11-28T00:46:02.44Z",
                "Answer_upvote_count":0,
                "Answer_body":"@VaraPrasad-1740 Thanks for the question. I would recommend you can have a git repository that backs your project. For some details about this approach you can check https:\/\/santiagof.medium.com\/structure-your-machine-learning-project-source-code-like-a-pro-44815cac8652",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Model file is not found for Registration of model in training Pipeline.",
        "Question_creation_time":1589329342560,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/26470\/model-file-is-not-found-for-registration-of-model.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"&#34;We want the model to automatically register model every time there is a new model. we created the model in the process and write it out to a pipeline data set.To persist it then we upload and read it for registration.\n\nWe are using .\/output to send the file to output. The issue is that it cannot find it in the file path . How can we validate its existence? &#34;\n\n[Note: As we migrate from MSDN, this question has been posted by an\u202fAzure Cloud Engineer\u202fas a frequently asked question] Source: MSDN",
        "Answers":[
            {
                "Answer_creation_time":"2020-05-13T09:04:19.693Z",
                "Answer_upvote_count":0,
                "Answer_body":"Can you verify that the script that is actually writing the model file to the location you expect:\n\n with open(model_name, 'wb') as file:\n        joblib.dump(value = model, filename = os.path.join('.\/outputs\/', model_name))\n\nInside in your train python script, you just need to do something like this:\n\npersist the model to the local machine\n\n\n tf.saved_model.save(model,'.\/outputs\/model\/')\nregister the model with run object\n\n\n run.register_model(model_name,'.\/outputs\/model\/')\n\nSource: MSDN",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Wheres my component",
        "Question_creation_time":1667251682350,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1070006\/wheres-my-component.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi expert, I am struggling in a bug, I can\u2019t see anything in my studio and it shows empty, how can I fixed it. Anyone else experience this or is this a bug.",
        "Answers":[
            {
                "Answer_creation_time":"2022-10-31T23:42:44.343Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @jamesschmidt-7068\n\nThanks for reaching out to us for this issue. I have checked on my end and I find everything is OK.\n\nCould you please make sure you have not selected any filter\/ selected all tags and click on the refresh button to make sure you have every component.\n\nMy studio is as above, please do check all the settings and let me know if you still have any issue.\n\nRegards,\nYutong\n\n-Please kindly accept the asnwer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Error while accessing the dataset from a datastore",
        "Question_creation_time":1619698599813,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/377203\/error-while-accessing-the-dataset-from-a-datastore.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I have tried to read the dataset from datastore. Also tried to create the dataset also.\n\nThe code for reading the dataset is below\n\n from azureml.core import Workspace\n ws = Workspace.from_config()\n datastore = Datastore.get(ws, 'qdataset')\n\n\n\nIt works fine still now.\n\n from azureml.core.dataset import Dataset\n six_dataset = Dataset.get_by_name(workspace=ws, name='combined_classifier')\n\n\n\nAlso i have tried from azureml.core import Dataset\n\nIt shows the following error:\n\n2021-04-29 11:56:47.284077 | ActivityCompleted: Activity=_dataflow, HowEnded=Failure, Duration=0.0 [ms], Info = {'activity_id': 'xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx', 'activity_name': '_dataflow', 'activity_type': 'InternalCall', 'app_name': 'dataset', 'source': 'azureml.dataset', 'version': '1.27.0', 'dataprepVersion': '2.14.2', 'subscription': '', 'run_id': '', 'resource_group': '', 'workspace_name': '', 'experiment_id': '', 'location': '', 'completionStatus': 'Failure', 'durationMs': 962.01}, Exception=AttributeError; module 'azureml.dataprep' has no attribute 'api'\n\n\n\n\nAttributeError Traceback (most recent call last)\n<ipython-input-34-ac7a8d35da4d> in <module>\n1 from azureml.core.dataset import Dataset\n----> 2 six_dataset = Dataset.get_by_name(workspace=ws, name='combined_classifier')\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data_loggerfactory.py in wrapper(args, *kwargs)\n127 with LoggerFactory.track_activity(logger, func.name_, activity_type, custom_dimensions) as al:\n128 try:\n--> 129 return func(args, *kwargs)\n130 except Exception as e:\n131 if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data\\abstract_dataset.py in get_by_name(workspace, name, version)\n87 :rtype: typing.Union[azureml.data.TabularDataset, azureml.data.FileDataset]\n88 \"\"\"\n---> 89 dataset = AbstractDataset._get_by_name(workspace, name, version)\n90 AbstractDataset._track_lineage([dataset])\n91 return dataset\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data\\abstract_dataset.py in _get_by_name(workspace, name, version)\n652 if not success:\n653 raise result\n--> 654 dataset = _dto_to_dataset(workspace, result)\n655 warn_deprecated_blocks(dataset)\n656 return dataset\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data_dataset_rest_helper.py in _dto_to_dataset(workspace, dto)\n93 registration=registration)\n94 if dto.dataset_type == _DATASET_TYPE_FILE:\n---> 95 return FileDataset._create(\n96 definition=dataflow_json,\n97 properties=dto.latest.properties,\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data_loggerfactory.py in wrapper(args, *kwargs)\n127 with LoggerFactory.track_activity(logger, func.name_, activity_type, custom_dimensions) as al:\n128 try:\n--> 129 return func(args, *kwargs)\n130 except Exception as e:\n131 if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data\\abstract_dataset.py in _create(cls, definition, properties, registration, telemetry_info)\n555 from azureml.data._partition_format import parse_partition_format\n556\n--> 557 steps = dataset._dataflow._get_steps()\n558 partition_keys = []\n559 for step in steps:\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data_loggerfactory.py in wrapper(args, *kwargs)\n127 with LoggerFactory.track_activity(logger, func.name_, activity_type, custom_dimensions) as al:\n128 try:\n--> 129 return func(args, *kwargs)\n130 except Exception as e:\n131 if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data\\abstract_dataset.py in _dataflow(self)\n215 raise UserErrorException('Dataset definition is missing. Please check how the dataset is created.')\n216 if self._registration and self._registration.workspace:\n--> 217 dataprep().api._datastore_helper._set_auth_type(self._registration.workspace)\n218 if not isinstance(self._definition, dataprep().Dataflow):\n219 try:\n\nAttributeError: module 'azureml.dataprep' has no attribute 'api'\n\n\n\n\n\nPlease give a solution to solve this",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-29T13:22:51.567Z",
                "Answer_upvote_count":1,
                "Answer_body":"It now worked..\nWe need to install azure-ml-api-sdk using this command\n\npip install azure-ml-api-sdk",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Does Azure AutoML use (or plan to use) FLAML for the hyperparameter tuning?",
        "Question_creation_time":1623298947587,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/429832\/does-azure-automl-use-or-plan-to-use-flaml-for-the.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"FLAML looks like it performs better than Azure AutoML for hyperparameter tuning (based on the benchmarking in the Arxiv paper): https:\/\/arxiv.org\/pdf\/1911.04706v1.pdf\n\nIs it now being used or is there a plan to integrate it for the hyperparameter tuning in Azure Machine Learning Services? If so, when is that expected to become available?",
        "Answers":[
            {
                "Answer_creation_time":"2021-06-11T05:57:12.69Z",
                "Answer_upvote_count":0,
                "Answer_body":"@rainerhillermann Thanks, We are not using the FLAML for Azure AutoML for the hyperparameter tuning, You can raise a user voice request here so the community can vote and provide their feedback, the product team then checks this feedback and implements the feature in future releases.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"machine learning conda env package(pyenchant)",
        "Question_creation_time":1643330999837,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/713217\/machine-learning-conda-env-packagepyenchant.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-container-instances"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I have pip install pyenchant, but It doesn't seem to be working.\n\n\n\n\n\n\n\n\n\nIs there any other way?\nhttps:\/\/stackoverflow.com\/questions\/21083059\/enchant-c-library-not-found-while-installing-pyenchant-using-pip-on-osx\nI looked it up but do not know where to put it\nThanks!",
        "Answers":[
            {
                "Answer_creation_time":"2022-01-28T08:12:23.967Z",
                "Answer_upvote_count":0,
                "Answer_body":"@YongchaoLiuNeusoftAmericaInc-6769 Based on the error it looks like you also need to ensure the enchant C library is available to use for the package. Based on the pip install page of pyenchant, the package will not work directly out of the box using pip.\n\nIn general, PyEnchant will not work out of the box after having been installed with pip. See the Installation section for more details.\n\nSince you are using Linux, this is the guidance on the installation page.\n\nThe quickest way is to install libenchant using the package manager of your current distribution. PyEnchant tries to be compatible with a large number of libenchant versions. If you find an incompatibility with your libenchant installation, feel free to open a bug report.\n\n\nTo detect the libenchant binaries, PyEnchant uses ctypes.util.find_library(), which requires ldconfig, gcc, objdump or ld to be installed. This is the case on most major distributions, however statically linked distributions (like Alpine Linux) might not bring along binutils by default.\n\n\n\n\nI believe you are using the ubuntu flavor of the azureml base image, In this case I think adding libenchant-2-dev as dependency in your YAML should work.\n\n -libenchant-2-dev=2.2.8\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":13.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"ML Pickle file size Azure Machine Learning Service",
        "Question_creation_time":1599612419390,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/89630\/ml-pickle-file-size-azure-machine-learning-service.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Is there any restriction on registering an ML pickle model into Azure Machine Learning Service in terms of the size of the pickle file?\n\nDoes it cause latency in realtime data processing and getting the prediction results from the pickle file if we have a model that let's say it 5MB and the other one is 500MB (The bigger file has better performance in terms of accuracy)?\nThanks,\n\nJohn",
        "Answers":[
            {
                "Answer_creation_time":"2020-09-11T04:54:35.417Z",
                "Answer_upvote_count":0,
                "Answer_body":"@JA-4570 Thanks, For ACI we recommend not using a model over 1GB in size.\nFor AKS you are limited by the memory resources that you request for your service, minus about 500mb for the running python process in the pod.\n\nThere will be no difference in prediction speed once the model is successfully deployed.\nRegistering will take longer as we have to upload the model, and deploying will take longer as the service must download the model.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to configute WebServiceOutput?",
        "Question_creation_time":1606819526077,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/181635\/how-to-configute-webserviceoutput.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi, I trained and deployed a ML model via Auto ML. The result looks like this:\n\"\\\"{\\\\\\\"result\\\\\\\": [\\\\\\\"Test\\\\\\\"]}\\\"\"\n\nOnce I did the same with an endpoint created with the Azure ML Designer my result looks like this:\n\"{\\\"Results\\\": {\\\"WebServiceOutput0\\\": [{\\\"Scored Labels\\\": \\\"Test\\\"}]}}\"\n\n\n\n\nIs there a way to configure the response that it looks similar to the AutoML response?\n\nThanks :)",
        "Answers":[
            {
                "Answer_creation_time":"2020-12-02T12:31:00Z",
                "Answer_upvote_count":1,
                "Answer_body":"@27051995 Unfortunately, AutoML and AML Designer currently generates 2 different swagger format automatically, and there is no way to configure the output format. We are working on to address this inconsistency, and the Designer swagger format will be the converged format. Cheers!",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2020-12-02T10:15:50.67Z",
                "Answer_upvote_count":0,
                "Answer_body":"@27051995 Does your webservice output module connect to score model module? The default configuration for this module contains an option to append score columns to output. You can try to uncheck this option to check if the column name in the output is removed.\n\n\n\n\nOther option is to name your webservice output module to the required name but this field will be displayed for designer for the output module. The end result might not be exactly the same but you can extract the required result based on the result or Results field instead of following a fixed format parsing.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"What does \"local\" mean in compute target?",
        "Question_creation_time":1600495202147,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/99901\/what-does-34local34-mean-in-compute-target.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi guys, I'm new to Azure ML. Following the URL below, I tried to run my python script on local machine. By local, I meant exactly Windows on my local physical machine in my house. But it seems python script 'transform_titanic.py' was executed on Azure.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-set-up-training-targets#local-compute-target\n\nI executed the script below on my local computer, and expected it runs 'transform_titanic.py' on my local computer.\n\nfrom azureml.core import Environment, Experiment, ScriptRunConfig, Workspace\nfrom dotenv import load_dotenv\nload_dotenv()\nws = Workspace(\n    os.environ['SUBSCRIPTION_ID']\n    os.environ['RESOURCE_GROUP']\n    os.environ['WORKSPACE_NAME']\n)\nexp = Experiment(workspace=ws, name='experiment')\nenv = Environment('user-managed-env')\nenv.python.user_managed_dependencies = True\nscript_run_config = ScriptRunConfig(\n    source_directory='src\/transform',\n    script='transform_titanic.py',\n    arguments=['--input_dataset_name1', 'titanic'],\n)\nscript_run_config.run_config.target = 'local'\nscript_run_config.run_config.environment = env\nrun = exp.submit(config=script_run_config)\nprint(run.get_portal_url())\nrun.wait_for_completion()",
        "Answers":[
            {
                "Answer_creation_time":"2020-09-19T06:10:30.72Z",
                "Answer_upvote_count":1,
                "Answer_body":"Sorry, I found it was run on my local computer. Some artifact created in the script was in C:\\Users{username}\\AppData\\Local\\Temp\\azureml_runs\\local_experiment_XXXXXXXXXX",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":3.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Machine Learning Data Labelling - Zoom broken on prelabelled tasks??",
        "Question_creation_time":1616185580847,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/323305\/azure-machine-learning-data-labelling-zoom-broken.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"My dataset now has enough samples to start pre-labeling a set of labels (bounding boxes for image identification).\n\nHowever, rather worryingly this seems fundamentally broken?\nWe appear to have lost the ability to zoom the image (zoom just appears to zoom the bounding boxes, and not the underlying image) which basically makes this entire functionality useless.\n\nAm I missing something or is this feature completely broken?\nI hope the former, as the pre-labeling was a significant factor in choosing this platform.\n\nWe have tried multiple browsers in case this was a browser issue but to no success, they all present the same issue.\n\nIs anyone able to advise??",
        "Answers":[
            {
                "Answer_creation_time":"2021-03-22T07:27:35.64Z",
                "Answer_upvote_count":0,
                "Answer_body":"@ChrisH-5786 Thanks for the question. Can you please share image and snapshot for the same. We are able to zoom the underlying image using the data labeling.\n\nPlease follow the doc to Tag images and specify bounding boxes for object detection.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Automated ML(interface) choosing primary metrics to handle imbalanced data",
        "Question_creation_time":1593398061863,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/40792\/azure-automated-mlinterface-choosing-primary-metri.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I figured out that there are some primary metrics I can choose when I run an automated ML experiment. Yet the number of primary metrics is fewer than the run metrics in the result page. I want to deal with imbalanced data(10:1 or 20:1) and\n\nlooked up the links below:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-manage-ml-pitfalls#identify-models-with-imbalanced-data\nand\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train\n\nIt seems F1 score is recommended to evaluate each model with imbalanced data.\n\nHere are my questions:\n\nIs there any way to set F1 score or multiple measures as a primary metric?\n\n\nIf there is no such way, should I do it manually?\n\n\nOf all the given primary metrics, which primary metric is the most appropriate(to build a Classification model with imbalanced data)?\n\n\n\n\n\nThanks.",
        "Answers":[
            {
                "Answer_creation_time":"2020-06-30T09:20:12.347Z",
                "Answer_upvote_count":0,
                "Answer_body":"For imbalanced data, it is preferred to choose AUC Weighted. Also user should then choose a metric that is appropriate to work well for imbalance. E.g. F1, micro averaged AUC, balanced accuracy for model evaluation. For primary metric (metric used for model optimization) the user should preferably choose AUC Weighted instead of accuracy.\nCurrently from the ml.azure.com the following metrics are supported. To add F1 score metric forwarded to product team to check on this.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train#primary-metric",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":6.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"AML - AssetException: Error with code: Can't connect to HTTPS URL because the SSL module is not available.",
        "Question_creation_time":1667553245710,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1075753\/aml-assetexception-error-with-code-can39t-connect.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello Microsoft Q&A Team,\n\nI get the error\n\nAssetException: Error with code: Can't connect to HTTPS URL because the SSL module is not available\n\nwhen executing the following command:\n\npipeline_job = ml_client.jobs.create_or_update(\npipeline_job, experiment_name=\"data_preparation\"\n)\npipeline_job\n\nYesterday the command worked without an error. I did not make any changes. So I have no idea, what the problem is.\n\nThanks for helping me out.\n\nCheers\n\nLukas",
        "Answers":[
            {
                "Answer_creation_time":"2022-11-04T23:41:10.037Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Lukas-6968 Thanks for your question. Can you please add more details about the document\/sample that you are trying.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-11-07T09:10:33.28Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hello,\n\nI was able to solve the issue.\n\nThank you.\n\nCheers\n\nLukas",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Is Azure supporting distributed GPU?",
        "Question_creation_time":1661977194510,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/989398\/is-azure-supporting-distributed-gpu.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Is there any plan? Any date we can expect?",
        "Answers":[
            {
                "Answer_creation_time":"2022-09-05T02:34:31.897Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @nam-4027\n\nI hope yo are doing well. We have multiple options for Distributed GPU for Azure Machine Learnig for SDK v1 as below -\nMessage Passing Interface (MPI)\nHorovod\nDeepSpeed\nEnvironment variables from Open MPI\nPyTorch\nProcess group initialization\nLaunch options\nDistributedDataParallel (per-process-launch)\nUsing torch.distributed.launch (per-node-launch)\nPyTorch Lightning\nHugging Face Transformers\nTensorFlow\nEnvironment variables for TensorFlow (TF_CONFIG)\nAccelerate GPU training with InfiniBand\n\nFor V2 there should be big change. Please feel free to let us know any problems. Thanks.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-08-31T20:32:46.857Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi Nam,\n\nDo you mean by distributed GPU for ML or specific to Azure ? Here is the link related to Azure GPU - how-to-train-distributed-gpu\n\n\n\n\n\nIf it is something else, please reply so I can have a look.\n\n==\nPlease \"Accept the answer\" if the information helped you. This will help us and others in the community as well.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Machine Learning with on premise SQL Server",
        "Question_creation_time":1592874857830,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/38894\/azure-machine-learning-with-on-premise-sql-server-1.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi is there a way for Azure Machine Learning to be able to perform analytics using data from an on premise SQL Server?\n\nOnly found the below article which is for Azure Machine Learning Studio (classic):\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/use-data-from-an-on-premises-sql-server\n\nThanks.",
        "Answers":[
            {
                "Answer_creation_time":"2020-06-23T08:17:48.573Z",
                "Answer_upvote_count":1,
                "Answer_body":"@conrad Here is the link to connect with the Azure SQL server.\nhttps:\/\/stackoverflow.com\/questions\/61806350\/database-communication-link-error-occurded-on-azure-ml-service-used-azure-sql-s\/61950481#61950481",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2020-06-25T18:27:33.377Z",
                "Answer_upvote_count":0,
                "Answer_body":"Light Servi\u00e7os de Eletricidade",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Submitting a job to Azure ML from Synapse workspace",
        "Question_creation_time":1648588740927,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/792681\/submitting-a-job-to-azure-ml-from-synapse-workspac.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-synapse-analytics",
            "azure-machine-learning",
            "azure-private-link"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Assume a data scientist who is coding inside a Synapse notebook, aims to submit his AutoML job to Azure ML. Also assume that we already created the Azure ML workspace, and linked it to Synapse, and also gave Synapse workspace the contributor access to Azure ML workspace. Also the data scientist has the Azure reader role at the synapse workspace level. Data scientist run the following code according to this link (https:\/\/docs.microsoft.com\/en-us\/azure\/synapse-analytics\/spark\/apache-spark-azure-machine-learning-tutorial)\n\nfrom azureml.core import Workspace\n\nsubscription_id = \"xxxxxx\" #you should be owner or contributor\nresource_group = \"xxxxx\" #you should be owner or contributor\nworkspace_name = \"xxxxx\" #your workspace name\nworkspace_region = \"xxxxx\" #your region\n\nws = Workspace(workspace_name = workspace_name,\nsubscription_id = subscription_id,\nresource_group = resource_group)\n\nHowever, he receives an error that says he does not have the required contributor\/owner roles at the subscription and resource group level. But we (as the synapse administrators) we don't want to give him the contributor\/owner role at the subscription and resource group name\n\nQuestion: How the data scientist can submit his job without letting him to have the required contributor\/owner role. Can he use the managed identity of the Synapse workspace to connect to the Azure ML workspace?\n\nThank you",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-30T06:04:50.573Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hello anonymous user,\n\nThanks for the question and using MS Q&A platform.\n\nMake sure your Service principal or Managed Service Identity (MSI) must have \"Contributor\" access to the AML workspace.\n\nIf the model is registered in Azure Machine Learning, then you can choose either of the following two supported ways of authentication.\n\nThrough service principal: You can use service principal client ID and secret directly to authenticate to AML workspace. Service principal must have \"Contributor\" access to the AML workspace.\n\n\nThrough linked service: You can use linked service to authenticate to AML workspace. Linked service can use \"service principal\" or Synapse workspace's \"Managed Service Identity (MSI)\" for authentication. \"Service principal\" or \"Managed Service Identity (MSI)\" must have \"Contributor\" access to the AML workspace.\n\nHere is the complete walkthrough of authenticating AML workspace with Azure Synapse Analytics:\n\nFor more details, refer to Tutorial: Score machine learning models with PREDICT in serverless Apache Spark pools.\n\nHope this will help. Please let us know if any further queries.\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":17.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"certification test for AI-900: Microsoft Azure AI Fundamentals not available",
        "Question_creation_time":1662205880130,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/992629\/exam-ai-900-microsoft-azure-ai-fundamentals-not-av.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hallo, i would like make an appointment for Exam AI-900: Microsoft Azure AI Fundamentals.\nHowever this exam is currently not available at Pearson vue or Certiport. When can i expect this again? Is there an alternative ?",
        "Answers":[
            {
                "Answer_creation_time":"2022-09-03T13:15:33.98Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi Jurian,\n\nThis is available in PearsonVue check this. ai-900\n\nAny specific region you are trying from?\n\n\n\n\n\n==\nPlease \"Accept the answer\" if the information helped you. This will help us and others in the community as well.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Receive error GraphDatasetNotFound: Request failed with status code 400 when submitting pipeline",
        "Question_creation_time":1619957038450,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/379678\/receive-error-graphdatasetnotfound-request-failed.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":4.0,
        "Question_view_count":null,
        "Question_answer_count":3,
        "Question_has_accepted_answer":true,
        "Question_body":"I am running through the tutorial at ..https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/create-clustering-model-azure-machine-learning-designer\/explore-data\n\nWhen I submit my pipeline I am seeing the error ...\n\nAn error occurred while submitting pipeline run\nGraphDatasetNotFound: Request failed with status code 400\n\nThis is an incredibly unhelpful message. I believe I have followed the steps as per the tutorial.\n\nAny idea what is the cause of this error?\n\nThanks",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-03T15:51:30.88Z",
                "Answer_upvote_count":14,
                "Answer_body":"In dataset Version change from \"Always use latest\" to 1 or anyother version, worked for me",
                "Answer_comment_count":9,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-05-04T19:31:52.053Z",
                "Answer_upvote_count":0,
                "Answer_body":"@DebayanRoy-8817, how exactly should we go about changing the dataset version? Mine has been greyed out to the dataset version 1. Your help will be very much appreciated!",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-08T14:14:30.57Z",
                "Answer_upvote_count":0,
                "Answer_body":"This solved the problem. thanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":20.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How could I upload notebooks to my AzureML workspace programatically",
        "Question_creation_time":1651101620807,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/829311\/how-could-i-upload-notebooks-to-my-azureml-workspa.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Would like to upload Jupyter notebooks from different sources like GitHub into my workspace either directly or through my local machine (download locally first and then upload) but I would like to do it programmatically. Either with the AzureML SDK or azure cli",
        "Answers":[
            {
                "Answer_creation_time":"2022-04-28T00:07:22.393Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for reaching out. You can use compute instance terminal in AML notebooks to clone the GitHub repo. There's currently no option to upload notebooks to your workspace programmatically using sdk or cli.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Accessing different model versions from same endpoint",
        "Question_creation_time":1653539509343,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/864579\/accessing-different-model-versions-from-same-endpo.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I am using model versioning and would like to have different model versions accessible via the same endpoint. Any best practices to access the multiple models from the same endpoint.",
        "Answers":[
            {
                "Answer_creation_time":"2022-05-26T07:43:19.48Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Srin-4824 Thanks, You may deploy \u201clocally\u201d to a Azure Machine Learning compute instance, by specifying different port # for each version. They are converted to a URL according to the format https:\/\/<compute instance\u2019s name>-port.region.instances.azureml.ms\/score\n\nModel v1: service_url = https:\/\/azure-ml-compute-instance-name-8001.westeurope.instances.azureml.ms\/score\nModel v2: service_url = https:\/\/ azure-ml-compute-instance-name-8002.westeurope.instances.azureml.ms\/score\n\nThere\u2019s sample code in documentation. You can specify port to deploy with the following parameter.\ndeployment_config = LocalWebservice.deploy_configuration(port=8001)\n\nWe recommend using the new ML Endpoints (Preview) What are endpoints (preview) - Azure Machine Learning | Microsoft Docs.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Best Practices for Routing Requests within Inference Clusters",
        "Question_creation_time":1601043259400,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/107990\/best-practices-for-routing-requests-within-inferen.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi,\n\nI have a Kubernetes Service attached as an inference cluster to an azure machine learning workspace. I have deployed multiple models to that the AKS service, each with their own endpoints. I plan to configure this such that I just need to send the request to one main endpoint, which after applying some conditions, will redirect the request to one of the endpoints (e.g. redirect the request to the appropriate model). Are there any best practices to approach this problem?\n\nThere seems to be an Azure ML router using azureml-fe that does something similar, but I cannot find any documentation about it.\n\nThanks,\nLawrence",
        "Answers":[
            {
                "Answer_creation_time":"2020-10-05T21:49:22.66Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @LawrenceWong-1664 ,\nWe do have a solution for this in private preview (called Many Models solution accelerator).\nPlease send your email id to AzCommunity[at]microsoft[dot]com). Include title and link to this thread in the email (and reply here once you do for faster response) and we can take the conversation from there.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Access to neural network model",
        "Question_creation_time":1591889003457,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/34890\/access-to-neural-network-model.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"We have built numerous diagnostic models which can be reduced to equations and code that will allow us to repeat the work. We have the code physically available to us, so it can be installed in our own software.\n\nNow I would like to use artificial neural networks to build a prediction model. After I build that model, will I be able to take that model and transfer it to our own software environment? My concern is that the prediction model will just be a black box. Thanks",
        "Answers":[
            {
                "Answer_creation_time":"2020-06-12T08:31:58.437Z",
                "Answer_upvote_count":0,
                "Answer_body":"@OliverBathe-8330 Please follow the below Deployment scenarios. If possible can you please add more details about the use case.\n\n\n\n\nOption A: Use the DevOps pipeline integration to rollout to production Using same approach as in the MLOps repo, set up a release trigger for your DevOps release pipeline listening from your dev workspace model registry but then deploy to your production workspace (requires registering again in Prod model registry, call model.deploy() in the Prod workspace\n\n\n\n\nOption B: Use the AML pipeline to rollout to production Following same example as above, add additional PythonScriptStep in your AML pipeline to register and deploy model in the Production workspace\n\n\n\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Best Approach to Clientside Machine Learning for Text Classification",
        "Question_creation_time":1637112667940,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/629917\/best-approach-to-clientside-machine-learning-for-t.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-text-analytics"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I have approximately 100k rows of text data (initially PDF documents that have been OCR). Most are rows of less than 5000 characters. Each of the source documents are addressed to some department. These are typically in the form of the below examples where the target department would 'Urology' (there are several departments).\n\nUrologly Department\n\n\nUrologly Clinic\n\n\nUrology Out Patients\n\n\nUrology\n\n\nDear urology team\n\nI have read a bit on ML Text Analysis and it seems I should be able to make a pretty good model by reviewing several hundred documents for each department (I have built an App to help me do this) and manually Classifying those documents. Some documents may mention urology but are actually addressed to another department. Typically the addressed department text is at the top third (first 3-7 lines) of the text body.\n\nI cannot use any online tools, i.e. I can't upload any of the Document text to servers to process I need a client side library. I have read and completed several tutorials using the ML.net but these are pretty basic (sentiment, entity detection without any initial training), and read an excellent blog at MonkeyLearn: which seems to acknowledge that can do what I imagine I should be able to do.\n\nSo can anybody point me in the right direction, can I use some offline Microsoft client library to complete my task? Is there some other Open Source client library i should look at. Will I have to learn Go, or python to complete the task (currently a C# dev).\n\nNote: I could get fairly good matches simply using SQL Text search and a bit of C# with plenty of hard coded rules, but I thought I'd try ML -- however its a nest of complications at the moment and i am going around in circles.\n\nMany Thanks\nMike.",
        "Answers":[
            {
                "Answer_creation_time":"2021-11-17T10:19:58.317Z",
                "Answer_upvote_count":0,
                "Answer_body":"@MikeShapleski-3383 I see two possible solutions for your scenario.\n\nExtracting text from your documents using the computer vision API and passing the required text as input to Azure Text Analytics for Health API\n\n\nUsing Azure cognitive search to upload the documents and creating a search service and enabling specific skills on the service to extract PII data or entities\n\nThe first solution can help you achieve this and ensure everything is offline or using docker containers without uploading any of your data to any storage externally. For billing purposes the containers need to connect to a metering endpoint on Azure to bill your usage of both these services(Computer Vision API & Azure text analytics containers). Also, you can use C# client library to call the local endpoint of these containers. The setup could take time to configure docker containers and passing the PDF documents to the computer vision read API to extract text. The extracted text can then be directly used or stored, to call the text analytics for health API.\n\nThe second solution can be used to index all the documents by using the search service by having your data in the cloud or behind a firewall to index the documents and make them searchable. There are some skills that can be enabled on the search service to extract entities and other PII information but this may not extract the same data as text analytics for health. This solution can be faster to setup because you can directly query your data after uploading the documents.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Change in Machine Learning Designer",
        "Question_creation_time":1660839023247,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/972775\/change-in-machine-learning-designer.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I can\u2019t find some of the basic modules from this week. Any significant change about Designer?",
        "Answers":[
            {
                "Answer_creation_time":"2022-08-18T16:58:23.857Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @67603284\n\nThanks for using Microsoft Q&A platform, there is no surprising change in Azure Machine Learning Designer.\n\nBased on my experience, you may use the filter so you can not see some of the modules as below screenshot.\n\n\nIf this is not your case, could you please share which module you have lost? Thanks.\n\nI hope this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azuer ml How can I use model version 1 if I delete model version 1",
        "Question_creation_time":1642560823080,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/700512\/azuer-ml-how-can-i-use-model-version-1-if-i-delete.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I don't know where to find version 1\n\nThanks",
        "Answers":[
            {
                "Answer_creation_time":"2022-01-19T12:48:09.783Z",
                "Answer_upvote_count":0,
                "Answer_body":"@YongchaoLiuNeusoftAmericaInc-6769 Usually if you click on the model the previous versions are available to view and use. If you have deleted the previous versions then I think it is no longer available.\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Customvision run trained tensorflow model in Python: Placeholder:0 refers to a non existing tensor in image classification",
        "Question_creation_time":1621939072900,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/408585\/customvision-run-trained-tensorflow-model-in-pytho.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-custom-vision"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi all,\n\nI have trained an image classifier with the customvision service, which worked as charm. Now I would like to run the model inference locally with a python script on my PC. Therefore I have been following the tutorial on https:\/\/docs.microsoft.com\/en-us\/azure\/cognitive-services\/custom-vision-service\/export-model-python\n\nI am having troubles with sess.graph.get_tensor_by_name('Placeholder:0').shape.as_list()\n\nCould you please provide some information on the system requirements and the python package versions? An openCV 4.5.1 C++ code snippet on how to consume the downloaded model would be also great if possible.\n\nI am using Python 3.8.5\n\nThank you",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-26T07:34:21.963Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thank you, will do.\n\nI have solved the issue with using C++ openCV instead and WinML also helps with rapid prototyping.\n\nThis was a particularly good example I have found:\n\nhttps:\/\/github.com\/Azure-Samples\/cognitive-services-onnx-customvision-sample\n\nWould be great to have more of those.\n\nBest.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"What could I be doing wrong to get this result from Azure AutoML timeseries forecasting?",
        "Question_creation_time":1606359622230,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/176361\/what-could-i-be-doing-wrong-to-get-this-result-fro.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I'm experimenting with Azure AutoML for timeseries forecasting. I have a simple two column training dataset with two years of data at hourly intervals. Column 1 is Date\/Time Column 2 is the variable I want to predict. I've done several runs of Azure AutoML and it seems to complete successfully. However, when I do a forecast and graph it something is obviously wrong. It looks like the forecast is being quantised somehow. The graph below is for the 7 days after the training set. Blue is actual and red is the forecast. This is obviously not right.\n\n\n\n\nHere is my configuration for the training (python):\n\n lags = [1,24,168]\n forecast_horizon = 7 * 24 # 7 days of hourly data\n forecasting_parameters = ForecastingParameters(\n     time_column_name=\"DateTime\",\n     forecast_horizon=forecast_horizon,\n     target_lags=lags,\n     country_or_region_for_holidays='NZ',\n     freq='H',\n     use_stl='season',\n     seasonality='auto'\n )\n automl_config = AutoMLConfig(task='forecasting',\n                              debug_log='automl_forecasting_function.log',\n                              primary_metric='normalized_root_mean_squared_error',\n                              experiment_timeout_hours=1,\n                              experiment_exit_score=0.05, \n                              enable_early_stopping=True,\n                              training_data=train_df,\n                              compute_target=compute,\n                              n_cross_validations=10,\n                              verbosity = logging.INFO,\n                              max_concurrent_iterations=19,\n                              max_cores_per_iteration=19,\n                              label_column_name=\"Output\",\n                              forecasting_parameters=forecasting_parameters,\n                              featurization=\"auto\",\n                              enable_dnn=False)\n\n\n\nThe best model from the run is a VotingEnsemble:\n\n ForecastingPipelineWrapper(pipeline=Pipeline(\n   memory=None,\n   steps=[('timeseriestransformer',\n   TimeSeriesTransformer(\n     featurization_config=None,\n     pipeline_type=<TimeSeriesPipelineType.FULL: 1>)),\n   ('prefittedsoftvotingregressor',\n   PreFittedSoftVotingRegressor(estimators=[('7',\n   Pipeline(memory=None,\n   steps=[('minmaxscaler',\n   MinMaxScaler(copy=True,\n   feature_range=(0,\n   1))...\n   DecisionTreeRegressor(ccp_alpha=0.0,\n   criterion='mse',\n   max_depth=None,\n   max_features=0.5,\n   max_leaf_nodes=None,\n   min_impurity_decrease=0.0,\n   min_impurity_split=None,\n   min_samples_leaf=0.00218714609400816,\n   min_samples_split=0.00630957344480193,\n   min_weight_fraction_leaf=0.0,\n   presort='deprecated',\n   random_state=None,\n   splitter='best'))],\n   verbose=False))],\n   weights=[0.5,\n   0.5]))],\n   verbose=False),\n   stddev=None)",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-26T20:37:59.827Z",
                "Answer_upvote_count":0,
                "Answer_body":"I tried again after turning off early stopping and letting it run for the two hours.... and got this",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Difference in processing time between Azure Machine Learning Studio and Azure Machine Learning Studio (classic)",
        "Question_creation_time":1635432791567,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/607943\/difference-in-processing-time-between-azure-machin.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I used to use Azure Machine Learning Studio (classic).\nCreating the same workout in Azure Machine Learning Studio takes about 20 times longer than classic.\nVirtual machine size is Standard_DS3_v2 (4 core\u300114 GB RAM\u300128 GB disk).\nSteps that have been executed once will be processed quickly from the next time onward, but steps that have been changed even slightly will take 20 times longer than classic.\n\nHow can I process at the same speed as classic?",
        "Answers":[
            {
                "Answer_creation_time":"2021-10-28T22:04:25.073Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for your feedback. AML classic studio appears to be faster in some cases because it uses a Fixed Compute (and always available). However, AML Classic lacks flexibility and scalability that the new platform offers. With designer, you have greater flexibility but depending on the task (e.g. smaller tasks), the processing time may seem longer than classic due to overhead for preparing each step. For smaller tasks, majority of execution time is spent on overhead. Furthermore, when input data changes, it may take longer. If no changes are made, the pipeline would automatically use the cached result of that module, so it should be faster compared to the first run. The product team are aware of this limitation and working to improve the experience. For compute heavy tasks, we recommend you pick a larger VM to improve processing speeds. Please review this document for ways to Optimize Data Processing. Feel free to submit feedback directly to the product team by using the 'smiley' feedback icon in Azure ML Studio. Other Similar Posts: (1), (2).\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Machine Learning ExperimentExecutionException while submitting a distributed training run !",
        "Question_creation_time":1619892981027,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/379458\/azure-machine-learning-experimentexecutionexceptio.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi, here is the details of my issue.\nI want to execute a distributed training run with the Tensorflow framework and Horovod.\nTo do this, I've configured a environment called \"tf_env\" as follow :\n\n # Create the environment : the dependencies are in the .yml file\n tf_env = Environment.from_conda_specification(name=\"tensorflow_environment\", file_path=\"experiments\/package-list.yml\")\n    \n # Register the environment\n tf_env.register(workspace=ws)\n    \n # Specify a GPU base image\n tf_env.docker.enabled = True\n tf_env.docker.base_image = 'mcr.microsoft.com\/azureml\/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04'\n\n\n\nWhere my \"package-list.yml\" contains all the dependencies my \"train_script.py\" requires.\nI've defined my ScriptConfigRun as follow :\n\n arguments = [\n     (... other arguments ...)\n     \"--ds\",  images_ds.as_mount()\n ]\n    \n src = ScriptRunConfig(\n     source_directory=\"experiments\",\n     script='train_script.py',\n     arguments=arguments,\n     compute_target=compute_target,\n     environment=tf_env,\n     distributed_job_config=MpiConfiguration(node_count=2)\n )\n\n\n\nThen, when I want to submit the run :\n\n run = best_model_experiment.submit(config=src)\n\n\n\n... it raises this error I don't understand :\n\n ExperimentExecutionException: ExperimentExecutionException:\n     Message: {\n     \"error_details\": {\n         \"componentName\": \"execution\",\n         \"correlation\": {\n             \"operation\": \"***\",\n             \"request\": \"***\"\n         },\n         \"environment\": \"westeurope\",\n         \"error\": {\n             \"code\": \"UserError\",\n             \"message\": \"Error when parsing request; unable to deserialize request body\"\n         },\n         \"location\": \"westeurope\",\n         \"time\": \"***\"\n     },\n     \"status_code\": 400,\n     \"url\": \"https:\/\/westeurope.experiments.azureml.net\/execution\/v1.0\/subscriptions\/***\/resourceGroups\/***\/providers\/Microsoft.MachineLearningServices\/workspaces\/***\/experiments\/experiment\/snapshotrun?runId=experiment***\"\n }\n     InnerException None\n     ErrorResponse \n {\n     \"error\": {\n         \"message\": \"{\\n    \\\"error_details\\\": {\\n        \\\"componentName\\\": \\\"execution\\\",\\n        \\\"correlation\\\": {\\n            \\\"operation\\\": \\\"***\\\",\\n            \\\"request\\\": \\\"***\\\"\\n        },\\n        \\\"environment\\\": \\\"westeurope\\\",\\n        \\\"error\\\": {\\n            \\\"code\\\": \\\"UserError\\\",\\n            \\\"message\\\": \\\"Error when parsing request; unable to deserialize request body\\\"\\n        },\\n        \\\"location\\\": \\\"westeurope\\\",\\n        \\\"time\\\": \\\"***\\\"\\n    },\\n    \\\"status_code\\\": 400,\\n    \\\"url\\\": \\\"https:\/\/westeurope.experiments.azureml.net\/execution\/v1.0\/subscriptions\/***\/resourceGroups\/***\/providers\/Microsoft.MachineLearningServices\/workspaces\/***\/experiments\/experiment\/snapshotrun?runId=experiment_***\\\"\\n}\"\n     }\n }\n\n\n\n\nCould you please help me decrypt this error ?\nThank you.",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-03T06:48:41.707Z",
                "Answer_upvote_count":0,
                "Answer_body":"Issue solved ! I've given a list in arguments to argparse so it could'nt deserialized the object.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Comment s\u00e9lectionner Standard_DS11_v2",
        "Question_creation_time":1638368598000,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/647767\/comment-selectionner-standard-ds11-v2.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":3,
        "Question_has_accepted_answer":true,
        "Question_body":"Bonjour\nJe suis le cours en ligne concernant l'impl\u00e9mentation d'algorithmes de machine learning\nA l'\u00e9tape Create compute resources\nhttps:\/\/docs.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/create-compute\n\nOn me demande Search for and select Standard_DS11_v2\n\nHors, l'interface me dit que je n'ai pas les quotas disponibles.\nJ'utilise l'offre d'essai \u00e0 200 USD.\nComment faire pour que cela fonctionne ?\nCordialement\nThibaut",
        "Answers":[
            {
                "Answer_creation_time":"2021-12-02T08:09:58.51Z",
                "Answer_upvote_count":0,
                "Answer_body":"@ThibautJacquin-3972 For a free account only 200$ credit is available and not all compute can be created or selected because of this limitation. You can choose a lower priced VM and proceed with the creation of compute or upgrade to a pay-as-you-go account for your subscription and select the required compute type. I hope this helps.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-12-02T10:05:54.843Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nI am not a French speaker, below is my translation from machine:\n\nHello\nI am taking the online course on the implementation of machine learning algorithms\nAt the Create compute resources step\nhttps:\/\/docs.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/create-compute\n\n\nI am asked Search for and select Standard_DS11_v2\n\n\nHowever, the interface tells me that I do not have the quotas available.\nI am using the $ 200 trial offer.\nHow do I make it work?\nRegards\nThibaut\n\nAs the note: \"Compute instances and clusters are based on standard Azure virtual machine images. For this module, the Standard_DS11_v2 image is recommended to achieve the optimal balance of cost and performance. If your subscription has a quota that does not include this image, choose an alternative image; but bear in mind that a larger image may incur higher cost and a smaller image may not be sufficient to complete the tasks. Alternatively, ask your Azure administrator to extend your quota.\"\n\nYou do not need to select Standard_DS11_v2 for this, could you please try other similar image to see if that works( there is no effect for your lab)? There maybe some limitations from your administration.\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-12-02T14:18:35.637Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for you replies !\nIndeed, I can't select another image !\nFrom my understanding I have to ask to expand my quota !",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Help for Azure ML Studio experiment mapping",
        "Question_creation_time":1620716372030,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/390316\/help-for-azure-ml-studio-experiment-mapping.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I am learning Azure ML (Studio) and please help me for below scenarios,\nI have a bank customer data having column labelled as customer age, family members (1,2,3 &4), credit card (Yes \/no) Personal Loan (Yes \/no), education (1. Undergrad 2. Graduate 3. Advanced\/professional).\n\nHow to filter age column and find number of customers less than 45 years in % of total number of customers?\n\n\nAlso need % customers who are having credit card as well Personal loan?\n\n\nwhich education category of customers are more prone to subscribe to personal loan?\n\n\nHow to do visual analysis?\n\n\nHow to calculate correlation between 2 columns?\n\nThanks in advance for your guidance. and incase tag to wrong group please guide to appropriate group",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-11T23:07:34.347Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for reaching out. I am assuming you are using Azure ML Studio Designer to work on this scenario. Please review response below:\n\n\n\n\nHow to filter age column and find number of customers less than 45 years in % of total number of customers? As part of your data preparations step, you can use available data transformation modules such as apply sql transformation and apply math operation to perform data transformations.\n\nAlso need % customers who are having credit card as well Personal loan? Similar to 1 above.\n\nWhich education category of customers are more prone to subscribe to personal loan? This seems to be a multi-classification problem where you'd want to predict several categories. AML Studio has the following modules and algorithms for predicting classes. For future reference, this document helps you identify which algorithm to select based on the ML scenario.\n\nHow to do visual analysis? With Azure ML Designer, you can Right Click on a module and select Visualize to visualize dataset output or results.\n\nHow to calculate correlation between 2 columns? You can use Filter Based Feature Selection to identify the columns in your input dataset that have the greatest predictive power. The module includes correlation methods such as Pearson correlation and Chi-Squared.\n\n\n\n\nAlso, here are some useful resources to help get you started:\n\nAzure Machine Learning Documentation.\n\n\nSample tutorials are available in Designer (newer drag and drop interface. Click Designer, select More Samples) and Classic (older drag and drop interface, via Azure AI Gallery, although some modules may not be available in designer, but a great starting point as well).\n\nHope this helps!",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Can't deploy a VM on the Azure Machine Learning.",
        "Question_creation_time":1623772014863,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/437136\/can39t-deploy-a-vm-on-the-azure-machine-learning.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":4.0,
        "Question_view_count":null,
        "Question_answer_count":6,
        "Question_has_accepted_answer":true,
        "Question_body":"I tried to deploy a VM to Azure Machine Learning, but I get the error message \"You do not have enough quota for the following VM sizes. Click here to view and request quota.\" And the VM cannot be deployed.\n\nBut I have enough quota (24 CPUs).\n\nWhat is causing the problem?\n\nI'm using Azure's Free trial plan.",
        "Answers":[
            {
                "Answer_creation_time":"2021-06-15T16:02:14.643Z",
                "Answer_upvote_count":2,
                "Answer_body":"Hi @Sss-1842 ,\n\nthere are different quotas in Azure:\n\nThere are quotas for vCPUs per Azure Region\n\n\nIn addition there are quotas for vCPUs per VM Series\n\nBoth quotas (for Azure Region and VM Series) must fit the requirements.\n\nIt seems like the quota for vCPUs per region is ok but you haven't enough vCPUs per VM series.\nYou can check your quotas by the link you marked with the red line in your screenshot.\n\n(If the reply was helpful please don't forget to upvote and\/or accept as answer, thank you)\n\nRegards\nAndreas Baumgarten",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-06-16T13:48:30.697Z",
                "Answer_upvote_count":2,
                "Answer_body":"Hi AndreasBaumgarten\n\nYour reply was correct.\nThe problem was \"vCPUs per VM Series\".\n\nThe VM series that can be used differs depending on the region,\nI changed the region to the western United States and it was resolved.\n\nThank you so much.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-12-09T13:20:50.753Z",
                "Answer_upvote_count":0,
                "Answer_body":"I face the same issue as @Sss-1842 All the options seem to be greyed out. I am also going through the MS Azure AI Fundamentals module with the free subscription and cannot create the compute instance. Already changed the region from East US to SouthCentral US, and nothing changes.\n\nAny help would be greatly appreciated.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-12-27T22:36:41.117Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi I tried canadacentral and worked",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-03-31T23:29:07.833Z",
                "Answer_upvote_count":1,
                "Answer_body":"I had the same issue while going through the Azure AI Fundamentals course. And no region change would make it work.\n\nSo I went against what the instructions explicitly say for the settings & checked \"Low priority\" instead of \"Dedicated\" and it immediately resolved the issue.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-06T03:54:36.943Z",
                "Answer_upvote_count":0,
                "Answer_body":"Probe con Australia East y funciono.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":19.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"GPT-3 access",
        "Question_creation_time":1605179070400,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/160489\/gpt-3-access.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-openai"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I'd like to use GPT-3 for my application. I understand MS has licensed GPT-3 from OpenAI, and that there is pricing too. So how do I get to use GPT-3?\n\n\n\n\nChris Powell",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-12T12:05:07.94Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Crispy-1600 Thanks for the question, Innovations from our GPT-3 workstreams will be incorporated in later versions of Azure. In the meantime, If you are interested in participation in the OpenAI GPT-3 and Azure Service partnership please fill out this form to submit a request.\n\nIgnite blog announcement: https:\/\/blogs.microsoft.com\/ai-for-business\/ai-at-scale-ignite\/",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"ClusterIdentityNotFound when submitting experiment.",
        "Question_creation_time":1633943984543,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/585373\/clusteridentitynotfound-when-submitting-experiment.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":3,
        "Question_has_accepted_answer":true,
        "Question_body":"When I'm submitting my experiment fom notebook, experiment is queing for a long time then I get as error:\n\nAzureMLCompute job failed.\nClusterIdentityNotFound: Identity of the specified\nmanaged compute <hidden cluster location> is not found\n\n\n\n\nI've updated all azure ml packages and restarted cluster, deleted, recreating, ... Nothing seems to be working.\n\nWhat Should I do?",
        "Answers":[
            {
                "Answer_creation_time":"2021-10-11T21:32:50.467Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi, are you by any chance using a low priority VM? If so, can you try selecting 'dedicated' as priority to verify? Also, ensure that you are following the steps outlined in this document for creating a compute cluster. In the advanced settings, ensure to assign a managed identity and specify a system-assigned identity or user-assigned identity.\n\n\n\n\n--- Kindly Accept Answer if the information provided helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-10-13T07:35:27.65Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nThank you for you answer.\nIt fixed my issue.\n\nHave a great day. :)\n\n\n\n\nBest regards.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-12-16T10:25:02.78Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for the answer @GiftA-MSFT . May i ask if this problem is happening for both compute clusters and compute instances? We are experiencing the same problem when trying to create an automated regression machine learning experiment by using a compute instance: Virtual machine size\nStandard_DS3_v2 (4 cores, 14 GB RAM, 28 GB disk)\nProcessing unit\nCPU - General purpose\nAny help much appreciated\nKind regards",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Can I add OpenAPI specification to a webservice deployed with AzureML in AKS?",
        "Question_creation_time":1600897231890,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/105437\/can-i-add-openapi-specification-to-a-webservice-de.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-kubernetes-service"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I'd like to deploy a machine learning service using AzureML on AKS. I also need to add some OpenAPI specification for it.\n\nFeatures in https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-kubernetes-service?tabs=python are neat, but that of having API docs\/swagger for the webservice seems missing.\n\nHaving some documentation is useful especially if the model takes in input several features of different type.\n\nTo overcome this, I currently get models trained in AzureML and include them in Docker containers that use the python FastAPI library to build the API and OpenAPI\/Swagger specs, and those are deployed on some host.\n\nCan I do something equivalent to this with AKS in AzureML instead? If so, how?",
        "Answers":[
            {
                "Answer_creation_time":"2020-09-24T06:54:05.547Z",
                "Answer_upvote_count":2,
                "Answer_body":"@DavideFiocco-7346 The deployments of Azure ML provide a swagger specification URI that can be used directly. The documentation of this is available here. You can print your swagger_uri of the web service and check if it confirms with the specifications you are creating currently.\n\nIf the above response helps, please accept the response as answer. Thanks!!",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Machine Learning - Data Labeling - Refresh",
        "Question_creation_time":1636385510357,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/619198\/azure-machine-learning-data-labeling-refresh.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello,\n\nI've started a new Data labeling project in Azure Machine Learning and I configured the incremental refresh.\n\nHow often is the data refreshed? Is it possible to force a refresh manually? Is it possible to execute this command via SDK (Python or PowerShell)?\n\nThanks.\n\nG",
        "Answers":[
            {
                "Answer_creation_time":"2021-11-09T02:24:49.197Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, data is refreshed within 24hrs. Currently, incremental refresh is only enabled using the portal and there's no option to trigger refresh manually.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"azure machine learning SDK",
        "Question_creation_time":1654035149473,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/872050\/azure-machine-learning-sdk.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"How to import data not by passing it as an argument,\nI do not want to do as the tutorial https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-with-datasets?source=docs",
        "Answers":[
            {
                "Answer_creation_time":"2022-06-01T17:54:59.667Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @benwu-8989\n\nThanks for reaching out to us, there is the code sample from engineering team\n\n from azureml.core import ScriptRunConfig\n    \n input_data=titanic_ds.as_named_input('input_data').as_mount()\n src = ScriptRunConfig(source_directory=script_folder,\n                       script='train_titanic.py',\n                       compute_target=compute_target)\n src.run_config.data = {input_data.name: input_data }\n # Submit the run configuration for your training run\n run = experiment.submit(src)\n run.wait_for_completion(show_output=True)  \n\n\n\nIn your script, you can get the mounted path via environment variable, which is the value you specified in as_named_input. For the sample code above, the environment variable will be input_data.\n\nI hopet this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ml notebooks sharing and compute selection.",
        "Question_creation_time":1591956129183,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/35432\/azure-ml-notebooks-sharing-and-compute-selection.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"What kind of collaboration do we need among the data scientists or developers who need to share these notebooks? What kind of compute does these notebooks require? Is it all single node?",
        "Answers":[
            {
                "Answer_creation_time":"2020-06-12T11:43:28.857Z",
                "Answer_upvote_count":0,
                "Answer_body":"@azureml056-5112 Please follow the below for managing compute instances. https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-compute-instance#managing-a-compute-instance All data scientists or developers need is access to the AzureML Workspace and they will have access to a shared file share where everyone\u2019s notebooks can be accessed.\n\n\n\n\nAll notebook require a Compute Instance(CI). CI is a managed VM that exists in AzureML.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Automated ML(interface) how do models created from an Automated ML experiment handle Imbalanced Data?",
        "Question_creation_time":1593407718737,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/40727\/azure-automated-mlinterface-how-do-models-created.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"I have run automated ML experiments with imbalanced data (10:1, 20:1, sometimes 30:1) and deployed the best models which all showed fantastic results.\n\nWhen I looked up the link\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-manage-ml-pitfalls#identify-models-with-imbalanced-data\n, it says Azure automated ML can properly handle imbalance of up to 20:1.\nI started to wonder where the ratio 20:1 came from.\n\nAs far as I understand, Azure automated ML doesn't use upsampling, downsampling or resampling, and is more focused on a column of weights to make a class more or less important, and a performance metric dealing better with imbalanced data.\n\nDoes this 20:1 come from some theory? or from tons of experiments already conducted?\n\n\n\n\n\nAzure automated ML shows the result with warning when I use 30:1(or more) imbalanced data, but I still wonder why it is 20:1.",
        "Answers":[
            {
                "Answer_creation_time":"2020-07-06T10:22:39.317Z",
                "Answer_upvote_count":0,
                "Answer_body":"In AutoML we use 5% minority class as threshold to classify imbalance\/non-imbalance. This is a heuristic, and is one guideline produced in the Guardrails to the question \u201cAt x% threshold level is the dataset balanced?\u201d. Since it is not possible to absolutely classify imbalance in all cases (depending on the dataset and its size and distribution, 5% or 10% or even higher may mean imbalance, whereas for very large datasets the minority class may have sufficient training samples for model to learn and get a reasonable imbalance-appropriate metric such as weighted AUC or balanced accuracy), current Guardrails serve the goal of surfacing \u201csubstantial\u201d imbalance to user so the user can take any of the following measures:\n\n\u2022 When the user knows (either from their knowledge of their own data or from guardrails) that there is imbalance, Automated ML provides an option in the Automated ML config to provide sample weights \u2013 a user-specified weight array where user can specify to weight each sample with a weight. That way they can weigh the minority class more when submitting the data into Automated ML config. We will soon provide weighting option for imbalance classes from within AutoML that will be activated automatically when imbalance is detected.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2020-07-01T06:12:08.183Z",
                "Answer_upvote_count":0,
                "Answer_body":"@JiinJeong-9636 The following is the road-map for this. The ratio for detecting imbalance has been updated to 1:5 rather than 1:20, meaning that AutoML would identify a dataset to have imbalance when the number of samples in the least common class is equal to or fewer than the number of samples in the most common class. This should be available within a week. The reason for doing this is as follows:\nThe ratio of 1:20 only detects very severe imbalance, whereas we've noticed both in our experiments as well as literature & industry practices, that even the treatment of mild imbalance (something like 1:5) could offer better results.\nThe ratio is based on comparing least common to most common as opposed to least common class to all the samples, because the former gives more consistent results empirically.\nThe solution to tackle imbalanced data is to apply weights internally to the dataset in the inverse proportion of the number of samples belonging to a particular class. Here's how we do it:\nIf the 1:5 ratio isn't satisfied, we trigger a message via Guardrails saying that \"PASSED: No Class Imbalance\" If the ratio isn't satisfied, i.e. imbalance is detected, then we run an experiment with sub-sampled data and check if the above solution of \"applying weights for class balancing\" proves to be better.\nIf the experiment is not leading to better results, we don't apply weights, and trigger a message in Guardrails saying that \"ALERT: Class Imbalance is present\" If the experiment does lead to better results, we apply the weights and fix the imbalance, and trigger a message in Guardrails saying that \"DONE: Class Imbalance was fixed\".\nThe documentation update is in-progress for Handling imbalance data of the following document.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Dataset + Preprocessed Text : Parameter \"Stopwords columns\" value should be less than or equal to parameter \"1\" value. . ( Error 0007 )",
        "Question_creation_time":1612874807950,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/265397\/dataset-preprocessed-test-parameter-34stopwords-co.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I encounter the following error :\n\nParameter \"Stopwords columns\" value should be less than or equal to parameter \"1\" value. . ( Error 0007 )\nwhen building a simple pipeline :\n\nwith a .csv Dataset followed by a \"Preprocessed Text\".\n\nNo parameter 'Stopwords columns' is available in the \"Preprocessed Text\" properties !!!",
        "Answers":[
            {
                "Answer_creation_time":"2021-02-09T13:42:08.547Z",
                "Answer_upvote_count":0,
                "Answer_body":"Solved.\n\nThere must be only one connection (left: Dataset) and not 2 connections (left : Dataset + right : Stopwords) from the \"Dataset\" to the \"Preprocessed Text\"",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Is there a way to delete datasets on AzureML?",
        "Question_creation_time":1632745762197,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/567611\/is-there-a-way-to-delete-datasets-on-azureml.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"We have a list of datasets in our AzureML. Is there a way to delete the datasets that we no longer require?",
        "Answers":[
            {
                "Answer_creation_time":"2021-09-27T21:28:04.783Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us. I think you are mentioning how to unregister dataset you do not need at this moment in Machine Learning Studio.\n\nYou can do it by go to your Azure Machine Learning Studio and check the Datasets. Then select the dataset you not longer need and click unregister.\n\nHope this helps.\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure OpenAI service capabilities",
        "Question_creation_time":1663989341807,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1021561\/azure-openai-service-capabilities.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"How do I get access to the Azure OpenAI service to evaluate it's capabilities?",
        "Answers":[
            {
                "Answer_creation_time":"2022-09-24T06:32:47.767Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Srin-4824 Thanks for the question. It is a Limited Access service so you have to apply for it https:\/\/aka.ms\/oai\/access",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Machine Learning studio Data Labeling Dataset",
        "Question_creation_time":1623134368530,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/426209\/machine-learning-studio-data-labeling-dataset.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi ,\n\nI have a have a dataset from the labelled data using the ML Data Labeling tool , my question is how can use the dataset to train a model ? , I tried Automated ML but I cannot make ant connection with the dataset .\n\nThanks for your help.",
        "Answers":[
            {
                "Answer_creation_time":"2021-06-09T12:04:26.353Z",
                "Answer_upvote_count":0,
                "Answer_body":"@hernandoZ-8172 I can confirm that using labeling data in the designer is currently not supported. This is however part of the roadmap in the future releases of designer. You can consume the data with the SDK as mentioned above.",
                "Answer_comment_count":4,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":4.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Deepspeed gpt-2 megatron-LM problems",
        "Question_creation_time":1610037769210,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/222550\/deepspeed-gpt-2-megatron-lm-problems.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-virtual-machines",
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I am trying to make a GPT-2 model with deepspeed on an azure VM. I found ~2 bugs which I was able to patch, but I have stumbled upon a really tough one. You see, it says I need pytorch. No surprise. I install pytorch. It still says I don't have it. I used both pip and pip3 many times. I install pytorch from github and run setup.py. It says I need python 3. When I get python 3 it says the same. When I try google colab it gives me the following error:\nTraceback (most recent call last): File \"pretrain_gpt2.py\", line 709, in <module>\nmain() File \"pretrain_gpt2.py\", line 654, in main\nargs.eod_token = get_train_val_test_data(args) File \"pretrain_gpt2.py\", line 600, in get_train_val_test_data\nargs) File \"\/content\/DeepSpeedExamples\/Megatron-LM\/configure_data.py\", line 34, in apply\nreturn make_loaders(args) File \"\/content\/DeepSpeedExamples\/Megatron-LM\/configure_data.py\", line 170, in make_loaders\ntrain, tokenizer = data_utils.make_dataset(**data_set_args) File \"\/content\/DeepSpeedExamples\/Megatron-LM\/data_utils\/init.py\", line 109, in make_dataset\nds = split_ds(ds, split) File \"\/content\/DeepSpeedExamples\/Megatron-LM\/data_utils\/datasets.py\", line 194, in split_ds\nrtn_ds[i] = SplitDataset(ds, split_inds) File \"\/content\/DeepSpeedExamples\/Megatron-LM\/data_utils\/datasets.py\", line 134, in init\nself.lens = itemgetter(*self.split_inds)(list(self.wrapped_data.lens)) TypeError: itemgetter expected 1 arguments, got 0\n\nHow do I fix both the google colab and the azure VM errors?",
        "Answers":[
            {
                "Answer_creation_time":"2021-01-11T23:51:27.243Z",
                "Answer_upvote_count":1,
                "Answer_body":"@Sammyboy123\nI would start by installing PyTorch via pip. Instructions can be found here. There is also a verification section which will test if you have PyTorch installed correctly. You also might find the DeepSpeed Getting Started page helpful. There are specific tutorials for Azure and also a docker image available.\n\nLet me know if this doesn't work for you or you are still facing issues.\n\n\n\n\nPlease don\u2019t forget to \"Accept the answer\" and \u201cup-vote\u201d wherever the information provided helps you, this can be beneficial to other community members.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"I want to register the model learned by AutoML in Azure Machine learning in ONNX format and call it in Azure Synapse Analitics.",
        "Question_creation_time":1664411309103,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1027830\/i-want-to-register-the-model-learned-by-automl-in.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"I found that I can register the model using Mlflow, but I don't know how to register it in ONNX format.\nI found out that the model is registered using Mlflow.\nBut I don't know how to convert AutoML models to ONNX format and register them with Mlflow.\n\nfrom azure.ai.ml import MLClient\nfrom azure.identity import DefaultAzureCredential\nfrom azureml.train.automl import AutoMLConfig\nfrom azureml.core import Workspace, Dataset\nfrom azureml.core.experiment import Experiment\nfrom azureml.core.model import Model\nfrom azureml.core.authentication import ServicePrincipalAuthentication\nfrom azureml.automl.runtime.onnx_convert import OnnxConverter\nfrom random import random\nfrom mlflow.tracking import MlflowClient\nimport mlflow\nimport mlflow.onnx\nimport os\nimport azureml.mlflow\n\nauth = ServicePrincipalAuthentication(\ntenant_id=\"\",\nservice_principal_id=\"\",\nservice_principal_password=\"\")\n\nsubscription_id = ''\nresource_group = ''\nworkspace_name = ''\n\nml_client = MLClient(credential=auth,\nsubscription_id=subscription_id,\nresource_group_name=resource_group)\n\nazure_mlflow_uri = ml_client.workspaces.get(workspace_name).mlflow_tracking_uri\nmlflow.set_tracking_uri(azure_mlflow_uri)\n\nws = Workspace(subscription_id, resource_group, workspace_name, auth=auth)\n\ntrain_data = Dataset.get_by_name(ws, name='iris')\n\nlabel = \"class\"\n\nautoml_settings = {\n\"primary_metric\": 'AUC_weighted',\n\"n_cross_validations\": 2\n}\n\nautoml_classifier = AutoMLConfig(\ntask='classification',\nblocked_models=['XGBoostClassifier'],\nenable_onnx_compatible_models=True,\nexperiment_timeout_minutes=30,\ntraining_data=train_data,\nlabel_column_name=label,\n**automl_settings\n)\n\nexperiment_name = 'experimetn_with_mlflow'\nmlflow.set_experiment(experiment_name)\nexperiment = Experiment(ws, experiment_name)\n\nwith mlflow.start_run() as mlflow_run:\nmlflow.log_metric(\"iris_metric\", random())\n\n mlflow_run = experiment.submit(automl_classifier, show_output=True)\n description = 'iris_Description'\n model = mlflow_run.register_model(description=description,\n                                model_name='iris_Model')\n best_run, onnx_mdl = mlflow_run.get_output(return_onnx_model=True)\n onnx_fl_path = \".\/best_model.onnx\"\n OnnxConverter.save_onnx_model(onnx_mdl, onnx_fl_path)\n model = Model.register(workspace=ws,\n                     description=description,\n                     model_name='iris_onnx_model',\n                     model_path=onnx_fl_path)\n client = MlflowClient()\n finished_mlflow_run = MlflowClient().get_run(mlflow_run.run_id)\n metrics = finished_mlflow_run.data.metrics\n tags = finished_mlflow_run.data.tags\n params = finished_mlflow_run.data.params\n model_path  = \"best_model\"\n model_uri = 'runs:\/{}\/{}'.format(mlflow_run.run_id, model_path)\n mlflow.register_model(model_uri, 'iris_onnx_mlflow_model')",
        "Answers":[
            {
                "Answer_creation_time":"2022-09-29T12:05:27.3Z",
                "Answer_upvote_count":0,
                "Answer_body":"@10433767 Thanks for the question. Can you please share document\/sample that you are trying. In order to save trained model download (and score) as the ONNX model you have here a few code examples.\nMLflow model registry will enable Synapse to run ONNX models is in preview.\n\nHere is the ONNX prediction section in the sample notebook.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-09-29T13:28:40.59Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thanks for the reply.\nI made it with the code you gave me.\nI was able to save the model in ONNX format in Azure Machine learning(See image file 2) using the following code, but could not reference it from Azure Synapse Analytics. See image file 1.\n\nfrom azureml.automl.runtime.onnx_convert import OnnxConverter\n\nonnx_fl_path = \".\/best_model.onnx\"\nOnnxConverter.save_onnx_model(onnx_mdl, onnx_fl_path)",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Execute R Script in ML Studio",
        "Question_creation_time":1627017183467,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/486775\/execute-r-script-in-ml-studio.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi,\n\nI am trying to runt the following R Script in an 'Execute R Script' module in Machine Learning Studio.\n\ndata.set <- data.frame(installed.packages())\nmaml.mapOutputPort(\"data.set\")\n\nThis script is taken from the 'Get started with Machine Learning Studio (classic)' in R page (https:\/\/docs.microsoft.com\/en-au\/azure\/machine-learning\/classic\/r-get-started#timeseries)\n\nWhilst it works in ML (classic) I receive the following error when running it in Machine Learning Studio;\n\nError in maml.mapOutputPort(\"data.set\"): could not find function \"maml.mapOutputPort\"\n\nWhat additional config settings are needed to enable R scripts in ML Studio?\n\nThank you.",
        "Answers":[
            {
                "Answer_creation_time":"2021-07-23T08:21:10.717Z",
                "Answer_upvote_count":0,
                "Answer_body":"@GrahamBenson-6517 For the designer version of the Azure ML studio you could follow the steps in this document to install the packages and run any R scripts. Unlike the classic version you need to select or create compute for your experiment before the experiment can be submitted.\n\nExample for installing a package:\n\n azureml_main <- function(dataframe1, dataframe2){\n   print(\"R script run.\")\n      \n   if(!require(zoo)) install.packages(\"zoo\",repos = \"http:\/\/cran.us.r-project.org\")\n   library(zoo)\n   # Return datasets as a Named List\n   return(list(dataset1=dataframe1, dataset2=dataframe2))\n }",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Loosen azureml-dataprep requirements to cloudpickle<=2.0.0",
        "Question_creation_time":1637242355487,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/632441\/loosen-azureml-dataprep-requirements-to-cloudpickl.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi,\n\nI couldn\u2019t find a specific github repo for azureml-dataprep so I decided to also write you here. Can you forward it to the devs?\n\n\n\n\nazureml-dataprep (which is a depedency for azureml-dataset-runtime) has requirement cloudpickle<2.0.0 and >=1.1.0. However there is to my knowledage no breaking features going from cloudpickle==1.6.0 to cloudpickle==2.0.0. cloudpickle==2.0.0 introduces some very effective tools for serializing helper scripts which is very helful when working with azureml. So azureml-dataprep should allow cloudpickle<=2.0.0\n\nIntro to new cloudpickle:\nhttps:\/\/github.com\/cloudpipe\/cloudpickle#overriding-pickles-serialization-mechanism-for-importable-constructs\nPR:\nhttps:\/\/github.com\/cloudpipe\/cloudpickle\/pull\/417\nGithub issue:\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1637",
        "Answers":[
            {
                "Answer_creation_time":"2021-11-19T02:48:45.06Z",
                "Answer_upvote_count":0,
                "Answer_body":"@ThomasH-1455\n\nThank you so much for the contribute, I have sent an email to the author for the PR review and merge.\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How can I create a dataset in Azure ML studio (through the GUI) from a parquet file created with Azure Spark",
        "Question_creation_time":1601468116080,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/112778\/how-can-i-create-a-dataset-in-azure-ml-studio-thro.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I'm trying to load files as a dataset in the GUI of Azure ML Studio. These parquet files have been created through Spark.\n\nIn my folder, Spark creates files such as \"_SUCCESS\" or \"_committed_8998000\".\n\nAzure ML Studio is not able to read them or ignore them and tells me:\n\nThe provided file(s) have invalid byte(s) for the specified file encoding.\n{\n  \"message\": \" \"\n}\n\n\n\n\nI selected \"Ignore unmatched files path\" and yet, it still does not work.\n\nIf I remove the \"_SUCCESS\" and other Spark files, it works.\n\nDoes anyone have an idea about a workaround?\n\nThank you.",
        "Answers":[
            {
                "Answer_creation_time":"2020-10-01T06:51:09.84Z",
                "Answer_upvote_count":1,
                "Answer_body":"I used \"path\/\/.parquet\" in the \"Path\" field and now it works.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"After selecting the \"Edit column\" button of the \"Select Columns in Dataset\" module in Designer, it will be stuck in the \"loading\" state.",
        "Question_creation_time":1617523186537,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/343427\/after-selecting-the-34edit-column34-button-of-the.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello everyone!\n\nI am taking the Create a Regression Model with Azure Machine Learning designer course in Microsoft Learn. When I perform the steps in the Explore Data section, after selecting the \"Edit column\" button of the \"Select Columns in Dataset\" module in Designer, it will be stuck in the \"loading\" state. Therefore, I cannot proceed to the next step.\n\n\n\n\n\nThank you very much!\n\nBest regards,\nLing",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-06T12:12:52.38Z",
                "Answer_upvote_count":1,
                "Answer_body":"@KaiXiuGao This issue is now fixed in all regions and it does not require an additional parameter to be added to the URL. Please try and let us know if it works fine.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":7.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML Enpoint deployment failed EAST US region",
        "Question_creation_time":1594945530060,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/48609\/azure-ml-enpoint-deployment-failed-east-us-region.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-kubernetes-service",
            "azure-webapps-content-deployment"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I have an Azure ML Real-time inference endpoint deployed ran for a month till yesterday. Today it is in the state of \"Failed\".\n\nI did create a new compute and did a new deployment in the same region EAST US and it failed again.\n\nWhat's going? Is this just a problem for me or a general issue?\n\nThanks\n-Dali",
        "Answers":[
            {
                "Answer_creation_time":"2020-07-17T02:30:29.753Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi, thanks for reaching out. I successfully deployed in the east us region. Please review the following troubleshooting guidelines. Also check for any service\/resource health issues that could be impacting your service. Let me know if you're still experiencing issues afterwards and please share the logs so we can investigate further. Thanks.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":44.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Is it possible to use pre-defined designer modules when building pipelines using python-sdk?",
        "Question_creation_time":1636017242333,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/615328\/is-it-possible-to-use-pre-defined-designer-modules.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Hey, I am trying to build ML pipelines using the python-sdk. I am wondering if I can use those pre-defined modules from Designer when building pipelines using the python-sdk?",
        "Answers":[
            {
                "Answer_creation_time":"2021-11-05T02:26:50.01Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hello @Chris-2395\n\nThanks for reaching out to us. But this currently is under development and we have no exact ETA for it.\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-11-26T02:52:46.95Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hi @Chris-2395, would you share more detail use case of your scenario for built-in component. We are planning to support built-in component in CLI and SDK. For your use case, do you need to use built-in component only with built-in component or you also expect to use them with your customized component?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"What is the difference between online learning and offline learning",
        "Question_creation_time":1623786913570,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/437505\/what-is-the-difference-between-online-learning-and.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"I am a new learner of machine learning and computer science, I wonder the difference between these two terms. I am confused on the concept, can someone answer this question?",
        "Answers":[
            {
                "Answer_creation_time":"2021-06-15T20:10:40.78Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us here. They are both machine learning methods for training. online machine learning is a method of machine learning in which data becomes available in a sequential order and is used to update the best predictor for future data at each step, as opposed to batch learning techniques which generate the best predictor by learning on the entire training data set at once.\n\nLike, one more data coming in, the predictor moves once. This method is good for scenario like stock prediction, optimization...\n\nLinear least square is a very good example to understand.\nhttps:\/\/en.wikipedia.org\/wiki\/Linear_least_squares\n\n\n\n\nFor Machine Learning beginner, Machine Learning Designer is a very good point to start. You can try any algorithms to see the difference.\nhttps:\/\/azure.microsoft.com\/en-us\/services\/machine-learning\/designer\/\n\nPlease feel free to let us know if you have more questions.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-06-15T19:59:03.03Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @Louis-4194,\n\nOnline learning normally means that your performing learning as the data comes in, while offline learning means that you use a static data.\nHere's a great post about this:\nhttps:\/\/stats.stackexchange.com\/questions\/897\/online-vs-offline-learning\n\nIf the reply was helpful please don't forget to upvote and\/or accept as answer, thank you!\n\n\n\n\nBest regards,\nLeon",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How do I access an input parameter in Azure Machine Learning endpoints?",
        "Question_creation_time":1602485723003,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/123204\/how-do-i-access-an-input-parameter-in-azure-machin.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"I've created an Azure ML Endpoint Pipeline with a single 'Execute Python Script'. From the script, I am looking for a way to access the input 'ParameterAssignments' that I POST to the endpoint to trigger the pipeline. I expected to see them somewhere in Run.get_context(), but I haven't had any luck. I simply need a way to POST arbitrary values that my Python scripts can access. Thank you!",
        "Answers":[
            {
                "Answer_creation_time":"2020-10-19T01:08:06.24Z",
                "Answer_upvote_count":1,
                "Answer_body":"I just confirmed with our engineer that you cannot set up a pipeline parameter and use it without tying it with any of the module parameter. So the workaround is - make the pipeline parameter as one of the inputs (i.e. dataset) to \"Execute Python Script\" module and set it as pipeline parameter. Then you can change it every time when calling the pipeline.",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-05-27T06:21:17.273Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @LuZhangAI-1027, I am finding a way to connect to Postgres in my pipeline. I don't think 'Import Data' supports it, so I am thinking to write my own 'Execute Python Script' to load the data from Postgres. As I don't use 'Import Data', is there another way to access the pipeline parameters inside 'Execute Python Script'?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"YOLO v5 in azure",
        "Question_creation_time":1661985450753,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/989581\/yolo-v5-in-azure.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi, does Azure Machine Learning support YOLOv5? How we can import it?",
        "Answers":[
            {
                "Answer_creation_time":"2022-09-01T17:27:32.523Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @matsuoka-4412\n\nMore info about YOLO v5 could be found here - https:\/\/github.com\/ultralytics\/yolov5\n\nMicrosoft currently has no official docs about YOLO v5 but you can surely use it in Azure environment as guidance above. I will reach out to product team to see how we can leverage YOLO v5 more but please let us know if you have more question during the time you working on your project.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Automated machine learning model deployment issue",
        "Question_creation_time":1627371604967,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/490809\/automated-machine-learning-model-deployment-issue.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"So I'm having an issue with setting up an endpoint for a machine learning model which was trained using Azure AutoML. When I try to test the deployed model, I get an error saying that the service is temporarily unavailable. After looking online, I found that this might happen because of an error in the run() function in the entry script.\n\nWhen I try to test the entry script on a notebook in Azure ML studio, on a fresh compute instance, there are two problems:\nFirst I get the error: AttributeError: 'MSIAuthentication' object has no attribute 'get_token'\nWhich is solved by running: pip install azureml-core\n\nThen I get the error: ModuleNotFoundError: No module named 'azureml.automl.runtime'\nWhich I try to solve using: pip install azureml-automl-runtime\nBut this throws a lot of incompatibility errors during the installation. When I then try to run the entry script I get an error with the message: \"Failed while applying learned transformations.\"\n\nSo I setup a new virtual environment on my local machine in which I only installed azure-automl-runtime. Using that setup the entry script works perfectly fine. So I created a custom environment in Azure ML studio using the conda file of that local virtual environment. Unfortunatly I still get the error \"service temporarily unavailable\" when trying to test the endpoint.\n\nI have a feeling the default Azure ML containers are incompatible with azureml-automl-runtime, since installing this on a ML studio notebook also throws a lot of errors.\n\nI feel like there should be an elegant way to deploy an AutoML model, am I doing something wrong here?\n\n\n\n\n\nUpdate: I found out I didn't change the environment for the endpoint, so that is why I was getting the same error probably. When using the custom environment I got errors from gunicorn, so I also added that package to the environment. Now I get the following error:\n\n       File \"\/var\/azureml-server\/entry.py\", line 1, in <module>\n     import create_app\n   File \"\/var\/azureml-server\/create_app.py\", line 4, in <module>\n     from routes_common import main\n   File \"\/var\/azureml-server\/routes_common.py\", line 39, in <module>\n     from azure.ml.api.exceptions.ClientSideException import ClientSideException\n ModuleNotFoundError: No module named 'azure.ml'\n\n\n\n\nSo what do I install to fix this? Is there a list somewhere of required packages for an ML model endpoint?",
        "Answers":[
            {
                "Answer_creation_time":"2021-07-28T09:19:56.087Z",
                "Answer_upvote_count":1,
                "Answer_body":"I managed to fix the issue with the environment by just adding everything that would throw an error. Then I found out the return value has to be a json\/dict object, which if not done throws the exact same 'service temporarily unavailable' error.\n\nBut my issue with the confusing curated environments and azureml-automl-runtime in ML studio notebooks remain. Maybe this is worth looking into @ramr-msft .",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-07-27T13:52:34.27Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Hidde-5466 Thanks, Can you try this notebook for deployment and if that works for you (it should), compare with your code?\nhttps:\/\/github.com\/CESARDELATORRE\/Easy-AutoML-MLOps\/blob\/master\/notebooks\/5-automl-model-service-deployment-and-inference\/automl-model-service-deployment-and-inference-safe-driver-classifier.ipynb\n\nYou\u2019ll first need to train and register the model with this previous notebook using a pipeline:\nhttps:\/\/github.com\/CESARDELATORRE\/Easy-AutoML-MLOps\/blob\/master\/notebooks\/4-automlstep-pipeline-run\/automlstep-pipeline-run-safe-driver-classifier.ipynb\n\nYou can also use the notebook with a simple AutoML remote run, but you might need to change the name of the model when registering it in the Workspace since it\u2019s a different name to what the deployment notebook is using:\nhttps:\/\/github.com\/CESARDELATORRE\/Easy-AutoML-MLOps\/blob\/master\/notebooks\/3-automl-remote-compute-run\/automl-remote-compute-run-safe-driver-classifier.ipynb",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to add r2 and adj r2 metric in linear regression model - AzureML Studio?",
        "Question_creation_time":1618843927707,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/362850\/how-to-add-r2-metric-in-linear-regression-model-az.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I have trained a linear regression model in AzureML studio which was created in designer as pipeline.\n\nI could not able to see R square and adj-R square metric in Evaluate Model step.\n\nCould any throw thoughts how can I add these 2 metrics to my trained model\n\n\n\n\n\n\n\n\n\nThanks\nBhaskar",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-20T00:19:19.74Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nSorry for the confusing. Actually, Coefficient of determination, often referred to as R2, represents the predictive power of the model as a value between 0 and 1. Zero means the model is random (explains nothing); 1 means there is a perfect fit. However, caution should be used in interpreting R2 values, as low values can be entirely normal and high values can be suspect in Azure Machine Learning Designer.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/evaluate-model#metrics-for-regression-models\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"(UserError) Error when parsing request; unable to deserialize request body",
        "Question_creation_time":1591616365497,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/33313\/usererror-error-when-parsing-request-unable-to-des.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi, getting this error when i run an azureml experiment with custom_docker_image (basegpu image of mcr) - can anybody help me understand this? Have tested this in local compute and it works, not sure why this does not work on a training cluster vm?\n\n\n\n\n    azureml._restclient.exceptions.ServiceException: ServiceException:\n         Code: 400\n         Message: (UserError) Error when parsing request; unable to deserialize request body\n         Details:\n        \n         Headers: {\n             \"Date\": \"Mon, 08 Jun 2020 11:03:52 GMT\",\n             \"Content-Type\": \"application\/json; charset=utf-8\",\n             \"Transfer-Encoding\": \"chunked\",\n             \"Connection\": \"keep-alive\",\n             \"Request-Context\": \"appId=cid-v1:6a27ce65-5555-41a3-85f7-b7a1ce31fd6b\",\n             \"x-ms-response-type\": \"error\",\n             \"Strict-Transport-Security\": \"max-age=15724800; includeSubDomains; preload\"\n         }\n         InnerException: {\n         \"additional_properties\": {},\n         \"error\": {\n             \"additional_properties\": {},\n             \"code\": \"UserError\",\n             \"message\": \"Error when parsing request; unable to deserialize request body\",\n             \"details_uri\": null,\n             \"target\": null,\n             \"details\": [],\n             \"inner_error\": null,\n             \"debug_info\": null,\n             \"message_format\": null,\n             \"message_parameters\": null,\n             \"reference_code\": null\n         },\n         \"correlation\": {\n             \"operation\": \"e96d6285280f5849a4a5e3f172d65d36\",\n             \"request\": \"1beee8ecb7180147\"\n         },\n         \"environment\": \"westeurope\",\n         \"location\": \"westeurope\",\n         \"time\": {}\n     }",
        "Answers":[
            {
                "Answer_creation_time":"2020-06-11T14:05:05.637Z",
                "Answer_upvote_count":1,
                "Answer_body":"My bad, after giving it some days and looking at the code, I noticed i had forgotten to add the parameters for the estimator configuration. Here is the estimator configuration that works for me:\n\n\n\n estimator = Estimator(source_directory=experiment_folder,\n                       compute_target=compute_target,\n                       script_params=script_params,\n                       entry_script='rps_efn_b0.py',\n                       node_count=1,        \n                       conda_packages=['ipykernel'],\n                       pip_packages = ['azureml-sdk',\n                                       'pyarrow',\n                                       'pyspark',\n                                       'azureml-mlflow',\n                                       'joblib',\n                                       'matplotlib',\n                                       'Pillow',\n                                       'tensorflow==2.2',\n                                       'tensorflow-datasets',\n                                       'tensorflow-hub',\n                                       'azureml-defaults',\n                                       'azureml-dataprep[fuse,pandas]'],\n                       custom_docker_image='mcr.microsoft.com\/azureml\/base-gpu:openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04')",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2020-06-09T14:44:45.27Z",
                "Answer_upvote_count":0,
                "Answer_body":"@sadeghHosseinpoor-9324 Apologies for not responding on the previous thread as we are having platform issues on providing response to some threads.\n\nIn this case having access to the backend details of your experiment run could help to suggest what changes are required in your current experiment setup. This can be addressed by our support team if you can raise a support ticket against this resource from the azure portal.\n\nMeanwhile, I have tried to lookup similar error messages faced by other users and based on your scenario are you installing any package in your environment with package name and version which is failing to read the request json? I found one user who corrected this error during environment setup by correcting the request for spark package installation in their environment.\n\nBefore:\n\n environment.spark.packages=[SparkPackage(group='com.microsoft.azure', artifact='azure:azure-sqldb-spark', version='1.0.2')]\n\n\n\nAfter:\n\n environment.spark.packages=[{'group':'com.microsoft.azure', 'artifact': 'azure-sqldb-spark', 'version':'1.0.2'}]\n\n\n\n\nIs there any similar requests in your case?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":3.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure ML Datastore\\Datasets",
        "Question_creation_time":1626270339670,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/475768\/azure-ml-datastoredatasets.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-storage-accounts"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello:\n\nI want to know that if it is possible automate copy file from azure storage to Azure ML folder.\n\nI understand that it is duplication of data, but I want to know if yes, how I can do that.\n\nAny pointer is greatly appreciated.\n\nThanks",
        "Answers":[
            {
                "Answer_creation_time":"2021-07-16T11:50:11.017Z",
                "Answer_upvote_count":1,
                "Answer_body":"Depending on the frequency at which you would like to move data you can create scripts that could run on crontab to move the data between source storage account to your workspace blob store. For example, use azcopy to perform this activity.\n\nA very comprehensive method to move storage between storage accounts is available as a Microsoft learn module that you could take to understand the possibilities and attain this from code to automate in your application.\n\nI would ideally assume that you would like to pull data when your experiment kicks off because you cannot move data to an experiments run id folder unless the experiment has started, In this case you could use the first option to place the data in your workspace blob store and then use it in your experiment without moving it to any other storage. I hope this helps.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"What's the next step after creating a pipeline?",
        "Question_creation_time":1661266129010,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/978610\/what39s-the-next-step-after-creating-a-pipeline.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi, the UI is very confused, not straightforward as Studio. Can you guide me to the next step to use the pipeline?",
        "Answers":[
            {
                "Answer_creation_time":"2022-08-23T18:07:17.917Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @Nicholes-3441\n\nThanks for using Microsft Q&A platform. I think you are on the stage of designing your pipeline and running it.\n\nThe next step should be submit your pipeline and evaluate your model - https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score#submit-the-pipeline\n\nWhen you feel good with your model, you can then deploy your pipeline as this guidance - https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy\n\nYou may then want to test and update your endpoint as above guidance.\n\nEach time you run a pipeline, the configuration of the pipeline and its results are stored in your workspace as a pipeline job. You can go back to any pipeline job to inspect it for troubleshooting or auditing. Clone a pipeline job to create a new pipeline draft for you to edit.\n\nPipeline jobs are grouped into experiments to organize job history. You can set the experiment for every pipeline job.\n\nI hope this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-08-23T18:16:30.973Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @Nicholes-3441,\n\nThere are several options of how you can run the pipeline after creating it e.g.,\n\n1) you can manually run the pipeline e.g., by Clicking on the Trigger Now option, using REST API, using PowerShell command etc.\n2) you can create a new scheduled \/ tumbling window \/ storage event \/custom event trigger\n\nPlease see the links below for details.\n\nThanks!\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/data-factory\/concepts-pipeline-execution-triggers",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How can I open the automated ML explanation in Jupyter notebooks?",
        "Question_creation_time":1614091964233,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/285089\/how-can-i-open-the-automated-ml-explanation-in-jup.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"What-If and Individual Conditional Expectation (ICE) plots are not supported in Azure Machine Learning studio under the Explanations tab since the uploaded explanation needs an active compute to recalculate predictions and probabilities of perturbed features. It is currently supported in Jupyter notebooks when run as a widget using the SDK. How can I open the automated ML explanation in Jupyter notebooks?",
        "Answers":[
            {
                "Answer_creation_time":"2021-03-01T15:58:38.55Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello Cagatay,\n\nIn jupyter notebook for AutoML models, you can download the trained model, then compute explanations locally and visualize the explanation results using ExplanationDashboard from interpret-community. Sample code below:-\n\n\n\n\n best_run, fitted_model = remote_run.get_output()\n     \n from azureml.train.automl.runtime.automl_explain_utilities import AutoMLExplainerSetupClass, automl_setup_model_explanations\n automl_explainer_setup_obj = automl_setup_model_explanations(fitted_model, X=X_train,\n                                                                                                                          X_test=X_test, y=y_train,\n                                                                                                                          task='regression')\n     \n from interpret.ext.glassbox import LGBMExplainableModel\n from azureml.interpret.mimic_wrapper import MimicWrapper\n explainer = MimicWrapper(ws, automl_explainer_setup_obj.automl_estimator, LGBMExplainableModel,\n                          init_dataset=automl_explainer_setup_obj.X_transform, run=best_run,\n                          features=automl_explainer_setup_obj.engineered_feature_names,\n                          feature_maps=[automl_explainer_setup_obj.feature_map],\n                          classes=automl_explainer_setup_obj.classes)\n     \n pip install interpret-community[visualization]\n     \n engineered_explanations = explainer.explain(['local', 'global'], eval_dataset=automl_explainer_setup_obj.X_test_transform)\n print(engineered_explanations.get_feature_importance_dict()),\n from interpret_community.widget import ExplanationDashboard\n ExplanationDashboard(engineered_explanations, automl_explainer_setup_obj.automl_estimator, datasetX=automl_explainer_setup_obj.X_test_transform)\n     \n raw_explanations = explainer.explain(['local', 'global'], get_raw=True, \n                                      raw_feature_names=automl_explainer_setup_obj.raw_feature_names,\n                                      eval_dataset=automl_explainer_setup_obj.X_test_transform)\n print(raw_explanations.get_feature_importance_dict()),\n from interpret_community.widget import ExplanationDashboard\n ExplanationDashboard(raw_explanations, automl_explainer_setup_obj.automl_pipeline, datasetX=automl_explainer_setup_obj.X_test_raw)\n\n\n\nThe code sample repo please refer to: https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/explain-model\/azure-integration\/scoring-time\/train-explain-model-locally-and-deploy.ipynb\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":5.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to get Model ID of the Latest Version registered in Azure Machine Learning Service Model Registry using az ml cli?",
        "Question_creation_time":1643903626503,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/721792\/how-to-get-model-id-of-the-latest-version-register.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello MS team,\n\nI have registered an ML model in the AML workspace using an Azure Machine learning pipeline and triggered the main control script of the pipeline by linking the repo present in Azure DevOps to the AML workspace(using Service principal).\n\nHow do I download the latest version of the model from the AML workspace to the \"Artifacts\" folder in Azure DevOPs?\n\nAny help is appreciated please.",
        "Answers":[
            {
                "Answer_creation_time":"2022-02-04T00:19:45.587Z",
                "Answer_upvote_count":0,
                "Answer_body":"@ShivapriyaKatta-8600\n\nI think you are mentioning how to get the latest version of model and download the model in az ml.\n\nThere are 2 steps, one is list the model to get the model ID you want, two is download the model.\n\naz ml model list\nList models in the workspace.\n\n az ml model list [--dataset-id]\n                  [--latest]\n                  [--model-name]\n                  [--path]\n                  [--property]\n                  [--resource-group]\n                  [--run-id]\n                  [--subscription-id]\n                  [--tag]\n                  [--workspace-name]\n                  [-v]\n\n\n\nOptional Parameters\n--dataset-id\nIf provided, will only show models with the specified dataset ID.\n\n--latest -l\nIf provided, will only return models with the latest version.\n\n--model-name -n\nAn optional model name to filter the list by.\n\n--path\nPath to a project folder. Default: current directory.\n\n--property\nKey\/value property to add (e.g. key=value ). Multiple properties can be specified with multiple --property options.\n\n--resource-group -g\nResource group corresponding to the provided workspace.\n\n--run-id\nIf provided, will only show models with the specified Run ID.\n\n--subscription-id\nSpecifies the subscription Id.\n\n--tag\nKey\/value tag to add (e.g. key=value ). Multiple tags can be specified with multiple --tag options.\n\n--workspace-name -w\nName of the workspace containing models to list.\n\n-v\nVerbosity flag.\n\naz ml model download\nDownload a model from the workspace.\n\n az ml model download --model-id\n                      --target-dir\n                      [--overwrite]\n                      [--path]\n                      [--resource-group]\n                      [--subscription-id]\n                      [--workspace-name]\n                      [-v]\n\n\n\n\nRequired Parameters\n--model-id -i\nID of model.\n\n--target-dir -t\nTarget directory to download the model file to.\n\nOptional Parameters\n--overwrite\nOverwrite if the same name file exists in target directory.\n\n--path\nPath to a project folder. Default: current directory.\n\n--resource-group -g\nResource group corresponding to the provided workspace.\n\n--subscription-id\nSpecifies the subscription Id.\n\n--workspace-name -w\nName of the workspace containing model to show.\n\n-v\nVerbosity flag.\n\nHope this helps!\n\nPlease kindly accept the answer if you feel helpful, thank you!\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-02-04T03:33:57.637Z",
                "Answer_upvote_count":0,
                "Answer_body":"Thanks a lot for the response....but I am trying to get the parameter \"--model-id\" as a variable and pass it into the download command, trying to do something like:\n\naz ml model download --model-id $(az ml model list --query \"[].{ID:id}[0].ID\" -o tsv --name saved_model --resource-group $(rg_name) --workspace-name $(ws_name)) --target-dir .\/models --resource-group $(rg_name) --workspace-name $(ws_name)\n\nNot working though...any idea?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Machine learning studio stuck",
        "Question_creation_time":1651358386807,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/832643\/machine-learning-studio-stuck.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"My project stuck again this week. It has been three hours for waiting.\n\nAny help?",
        "Answers":[
            {
                "Answer_creation_time":"2022-05-01T07:04:06.413Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @Azadeh-9323\n\nI am sorry for your experience, but I just double check on backlog, we don't see any ongoing issue currently. Could you please share your region?\n\nPlease let us know if you still see this issue after refreshing and we are willing to help you anytime.\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"machine learning Studio",
        "Question_creation_time":1648415916797,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/789066\/machine-learning-studio.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi:\n\nI wonder when will the classic Machine Learning Studio retire?\n\nAlso in order to save my data and file, any preparation or migration should be done to avoid any loss?\n\nThanks",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-27T23:20:57.9Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @dontbelazy-2604\n\nThanks for reaching out to us, I think you are mentioning Azure Machine Learning Studio(classic). Machine Learning Studio (classic) will retire on 31 August 2024.\n\nFrom now through 31 August 2024, you can continue to use the existing Machine Learning Studio (classic). Beginning 1 December 2021, you will not be able to create new Machine Learning Studio (classic) resources.\n\nRequired action to avoid loss:\n\nFollow these steps to transition using Azure Machine Learning before 31 August 2024. Pricing may be subject to change, please view pricing here.\n\nHope this helps!\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks!",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Permission error while finishing auto ml run",
        "Question_creation_time":1621886630607,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/407580\/permission-error-while-finishing-auto-ml-run.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":4,
        "Question_has_accepted_answer":true,
        "Question_body":"I get the following error inside the child runs in ML studio while doing an Automated ML experiment.\n\n\"Identity does not have permissions for Microsoft.MachineLearningServices\/workspaces\/metadata\/artifacts\/write actions.\"\n\nI am the owner of the resource group so I am not sure what the issue is.\n\n\n\n\nThanks",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-25T19:35:10.163Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello everyone, @ShubhamMiglani-1182 @NickSchafer-7538\n\nWe have identified the issue and a hot fix is rolling out. It will be fixed in all regions by end of today. Sorry for the experience.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-05-25T00:27:59.687Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us. It seems there is something wrong with the role-base. I would suggest you check on your current role or reassign roles to yourself and have a try as below:\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-assign-roles#manage-workspace-access\n\nPlease let me know if you still have any question.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-25T16:11:34.89Z",
                "Answer_upvote_count":0,
                "Answer_body":"We are having the same issue. I think that a change that Microsoft made some time within the last few days either deleted a bunch of custom roles or created new roles that are now required inside of the Machine Learning Workspace. Any thoughts @ramr-msft ?",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-26T17:41:12.733Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello everyone,\n\nThis issue should be fixed. Please check and let me know if you are still facing any issue.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Fisher Linear Discriminant Analysis Azure",
        "Question_creation_time":1621855005240,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/407053\/fisher-linear-discriminant-analysis-azure.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"How is the output of Fisher Linear Discriminant Analysis experiment interpreted now that the column labels in the output are replaced with Col1, Col2, Col3.......etc? How can the model be used to predict clusters of other input data as deployed web service requires even the dependent valuable(the same same ones we wish to predict)?",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-24T22:27:20.423Z",
                "Answer_upvote_count":0,
                "Answer_body":"Are you referring to the categories generated from LDA module? If so, then that's expected. LDA is an unsupervised technique, it groups words into categories\/topics and it's up to the analyst to interpret it by observing the results and transforming the output dataset accordingly. Here's are some examples of LDA approach in Azure AI Gallery. Hope this helps.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":5.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"anomaly detector with azure",
        "Question_creation_time":1664585272280,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1031454\/anomaly-detector-with-azure.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":3,
        "Question_has_accepted_answer":true,
        "Question_body":"May I have some samples about anomaly detector with azure machine learning studio?",
        "Answers":[
            {
                "Answer_creation_time":"2022-10-09T23:03:07.117Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @minhoolee-9603\n\nSorry about the late response, I think what you are looking for is Anomaly detection in time series analytic. I find some resource you may want to have a look -\nhttps:\/\/www.youtube.com\/watch?v=Ra8HhBLdzHE\nhttps:\/\/learn.microsoft.com\/en-us\/archive\/msdn-magazine\/2017\/november\/machine-learning-azure-machine-learning-time-series-analysis-for-anomaly-detection\n\nAbove resource are a little bit old, it is how to achieve the target in Azure Machine Learning.\n\nPlease let me know if you have more questions.\n\nI hope this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks a lot.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-10-01T00:52:35.153Z",
                "Answer_upvote_count":0,
                "Answer_body":"Kindly check it here",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-03T16:55:39.717Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi I know this service but what I am looking for is the solution in machine learning studio.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"azuremlsdk for R error Could not retrieve user token. Please run 'az login'",
        "Question_creation_time":1621290302507,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/398420\/azuremlsdk-for-r-error-could-not-retrieve-user-tok.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I'm trying to create a workspace in azure machine learning and receiving this error after 2 browser Windows open and I click log in.\n\nlibrary(azuremlsdk)\nnew_ws <- create_workspace(name = 'muffin',\n\n\n+ subscription_id = 'XXXXXXXXXXXX',\n+ resource_group = 'white',\n+ location = 'eastus2',\n+ create_resource_group = T)\nNote, we have launched a browser for you to login. For old experience with device code, use \"az login --use-device-code\"\nYou have logged in. Now let us find all the subscriptions to which you have access...\nNote, we have launched a browser for you to login. For old experience with device code, use \"az login --use-device-code\"\nYou have logged in. Now let us find all the subscriptions to which you have access...\nError in py_call_impl(callable, dots$args, dots$keywords) :\nAuthenticationException: AuthenticationException:\nMessage: Could not retrieve user token. Please run 'az login'\nInnerException It is required that you pass in a value for the \"algorithms\" argument when calling decode().\nErrorResponse\n{\n\"error\": {\n\"code\": \"UserError\",\n\"inner_error\": {\n\"code\": \"Authentication\"\n},\n\"message\": \"Could not retrieve user token. Please run 'az login'\"\n}\n}\n\n\nhow do I get passed this error?",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-24T08:27:35.833Z",
                "Answer_upvote_count":0,
                "Answer_body":"You have to use this command to make it install the correct version of miniconda reticulate::py_install(\"PyJWT==1.7.1\"). If you don't do that it seems to install the wrong version. I also had to manually delete the r-miniconda folder in \\appdata\\local\\r-miniconda which got installed previously to get it to install the correct version. It's pretty outrageous they leave that out of the tutorial when it ain't going to work otherwise.\n\nIf you try to do the accident.R tutorial for azuremlsdk-r next make sure you add the line\n\ninteractive_auth <- interactive_login_authentication(tenant_id=\"<tenant id>\")\n\nto your code otherwise you'll get a permissions error and it won't work.\n\nThen to the create_workspace or get_workspace function you have to add auth = interactive_auth after a comma.\n\nIt should look like this\n\nnew_ws <- get_workspace(name = \"<workspace name>\",\nsubscription_id = \"<subscription id>\",\nresource_group = \"<resource name>\",\nauth = interactive_auth)\n\nTo find the tenant ID I had to download the azure CLI and run the command az login. Not sure if there is another way to find a tenant ID or not.\n\n\n\n\nTo leave out critical steps from a tutorial is gross incompetence on the part of Azure. How anyone who isn't a comp sci phd uses this service is a mystery to me.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Code: AuthorizationFailed",
        "Question_creation_time":1651917005187,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/840311\/code-authorizationfailed.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-virtual-machines",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Unit 4 of 7\nExercise - Back up an Azure virtual machine\nCreate a backup for Azure virtual machines\n\nI am unable to run the following command in cloud shell to set up the environment:\nRGROUP=$(az group create --name vmbackups --location westus2 --output tsv --query name)\n\nFollowing error pop up:\nERROR: (AuthorizationFailed) The client 'live.com#...... does not have authorization to perform action 'Microsoft.Resources\/subscriptions\/resourcegroups\/write' over scope '\/subscriptions\/.......\/resourcegroups\/vmbackups' or the scope is invalid. If access was recently granted, please refresh your credentials.\nCode: AuthorizationFailed\nMessage: The client 'live.com#l...... with object id '.......' does not have authorization to perform action 'Microsoft.Resources\/subscriptions\/resourcegroups\/write' over scope '\/subscriptions\/.....\/resourcegroups\/vmbackups' or the scope is invalid. If access was recently granted, please refresh your credentials.\n\nWhen I do refresh, sign out or sign in do not helps. Anybody has any idea what to do?\nThank you",
        "Answers":[
            {
                "Answer_creation_time":"2022-05-07T10:07:44.643Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hello @Krisztian-8931\n\nWelcome to Microsoft Q&A community.\n\nHave you tried to do this first?\n\n\n\n\n\n\n\n\n\nCheers,\n\nPlease \"Accept the answer\" if the information helped you. This will help us and others in the community as well.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Not able to pull docker image from Container Registry",
        "Question_creation_time":1631798842910,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/555024\/not-able-to-pull-docker-image-from-container-regis.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "dotnet-ad",
            "azure-container-registry"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello community,\nI'm facing a problem, my ACR in my resource group was deleted and I couldn't create any instance. I created again and now I can create instances but i'm having problems to run the dataset profile. It's failing to pull the image docker.\n\nThis is the output\n\n AzureMLCompute job failed.\n FailedPullingImage: Unable to pull docker image\n     imageName: 19acd0cdf57549bcace363c924cf045b.azurecr.io\/azureml\/azureml_e7e3dfebc6129c75c60868383ebc992f\n     error: Run docker command to pull public image failed with error: Error response from daemon: Get https:\/\/19acd0cdf57549bcace363c924cf045b.azurecr.io\/v2\/azureml\/azureml_e7e3dfebc6129c75c60868383ebc992f\/manifests\/latest: unauthorized: authentication required, visit https:\/\/aka.ms\/acr\/authorization for more information.\n .\n     Reason: Error response from daemon: Get https:\/\/19acd0cdf57549bcace363c924cf045b.azurecr.io\/v2\/azureml\/azureml_e7e3dfebc6129c75c60868383ebc992f\/manifests\/latest: unauthorized: authentication required, visit https:\/\/aka.ms\/acr\/authorization for more information.\n    \n     Info: Failed to setup runtime for job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.\n\n\n\nThe ML Studio has the following permissions on the ACR permissions\n\n\n\n\nThe docker image appears in the repositories of the ACR\n\n\n\n\nAny hint how can i solve this problem?\n\nThanks in advance",
        "Answers":[
            {
                "Answer_creation_time":"2021-09-16T14:37:51.767Z",
                "Answer_upvote_count":2,
                "Answer_body":"@MoresiMarco-2752 Does this container registry have the admin account enabled? A requirement while creating a workspace with an existing container registry is to have the admin account enabled.\n\nIf you have already enabled it then a re-sync of keys might be required for your workspace.\n\n az ml workspace sync-keys -w <workspace-name> -g <resource-group-name>\n\nDeleting the default container registry used by the workspace can also cause the workspace to break.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"memory outage while running module",
        "Question_creation_time":1653902834057,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/869594\/memory-outage-while-running-module.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I am encountering an issue of error 0138, while training the data, at the end it shows memory has been exhausted exception\n\nI do not think my data has exceed the limit of azure ML studio, is there any way to solve this?",
        "Answers":[
            {
                "Answer_creation_time":"2022-05-30T20:29:41.987Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @darya-9510\n\nThanks for reaching out to us. This issue seldoms happen. Could you please share your structure to us and how is your dataset size? Based on the error info, too many steps in your experiment may cause that.\n\nI would suggest you try to remove some unnecessary one to try and see. If you believe your structure is reasonable, please share it to us. But it should be fine if you have not put too much.\n\nRegards,\nYutong\n\n-Please kindly accept the answer to help the community if you feel helpful, thanks.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"how to update azure ml model from adf?",
        "Question_creation_time":1619624088887,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/375702\/how-to-update-azure-ml-model-from-adf.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-data-factory",
            "azure-machine-learning",
            "azure-machine-learning-inference"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi, I manage to run a azure ml trainning pipeline in adf. Then I can see that I can create\/update a batch inference pipeline from the Designer. But can I update the batch inference pipeline from adf?\n\nthanks",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-28T17:13:15.207Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hi @javier-8889,\n\nThanks for using Microsoft Q&A !!\n\nUnfortunately this is not supported using Azure Data Factory and you can only update the scoring web service using Azure Machine Learning Studio (classic) update resource activity Can you please provide your scenario\/use case in details so that I can check internally. I also suggest you to please post this as a feedback at ADDF UserVoice. This will allow the community to upvote and for the product team to include into their plans\n\nPlease do not forget to \"Accept the answer\" wherever the information provided helps you to help others in the community.\n\nThanks\nSaurabh",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Data Factory : How to pass DataPath as a parameter to Azure ML Pipeline activity?",
        "Question_creation_time":1599771191990,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/91785\/azure-data-factory-how-to-pass-datapath-as-a-param.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-data-factory",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello All,\n\nHow to pass a Datapath as a parameter in Azure ML Pipeline activity?\n\nMore details here : Have opened an issue here : https:\/\/github.com\/Azure\/Azure-DataFactory\/issues\/216\n\n\n\n\n\nThanks.",
        "Answers":[
            {
                "Answer_creation_time":"2020-09-25T08:43:19.257Z",
                "Answer_upvote_count":1,
                "Answer_body":"Thanks @SriramNarayanan-6939 for your patience!\n\nI discussed with the Product team and they confirmed that there is no datatype supported for \"DataPath\" parameter today in Azure Data Factory(ADF). However, there is a feature already raised for the same and work is in progress for it.\n\nI would recommend you also to submit an idea in feedback forum. The ideas in this forum are closely monitored by data factory product team and will prioritize implementing them in future releases.\n\nSorry for the inconvenience!",
                "Answer_comment_count":8,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":4.0,
        "Question_follower_count":8.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Pathway for code free predictive modeling",
        "Question_creation_time":1592869306553,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/38841\/pathway-for-code-free-predictive-modeling.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I am looking at Azure&amp;#39;s training modules and it states I can learn no-code models with Azure, but it also tells me I should know python. I&amp;#39;m a little confused at where I should spend time training in most efficient pathway. My goal is to just do predictive modeling within Azure. I have technical\/IT literacy however coding is at a basic level.\n\nIdeally id like some sort of Certification, if possible from just &amp;#34;Create no-code predictive models with Azure Machine Learning&amp;#34;\n\nIs &amp;#34;Microsoft Certified: Azure Data Scientist Associate&amp;#34; going to require a lot of pre work on python\/torch\/tensor? I&amp;#39;d ideally like Azure to be my entry.",
        "Answers":[
            {
                "Answer_creation_time":"2020-06-23T15:06:48.467Z",
                "Answer_upvote_count":2,
                "Answer_body":"Thanks for reaching out. Azure machine learning has a drag and drop interface (Designer) that supports code free predictive modeling. Create no-code predictive models with Azure Machine Learning training modules is a great starting point and provides a pathway for Azure Data Scientist Associate certification. However, you also need programming experience and familiarity with various data science processes\/principles to be successful on the certification exam.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":2.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"[Azure][ML][Python SDK][Environment][Docker] Docker copy missing context",
        "Question_creation_time":1634739305317,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/597612\/azuremlpython-sdkenvironmentdocker-docker-copy-mis.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello,\n\nI am trying to create an Azure ML Environment using a Dockerfile but it contains the 'COPY' instruction.\n\nFrom the documentation of Environment.from_dockerfile ( https:\/\/docs.microsoft.com\/fr-fr\/python\/api\/azureml-core\/azureml.core.environment(class)?view=azure-ml-py#from-dockerfile-name--dockerfile--conda-specification-none--pip-requirements-none- ), I can not find a way to give it some files along with the Dockerfile itself.\n\nSo, how to pass context to enable using COPY in the Dockerfile ?\n\nThank you for your time !",
        "Answers":[
            {
                "Answer_creation_time":"2021-10-21T00:05:42.763Z",
                "Answer_upvote_count":1,
                "Answer_body":"Docker context is not supported with AzureML Python SDK at the moment. Context support will added later this year",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Machine Learning - Specify disk storage type",
        "Question_creation_time":1636713894743,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/625035\/azure-machine-learning-specify-disk-storage-type.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi,\n\nIs there a way to specify the disk storage type for Compute instances?\nBoth the Azure portal and ARM templates do not have an option to define the disk storage type, which defaults to the P10 disks (Premium SSD).\n\nThanks",
        "Answers":[
            {
                "Answer_creation_time":"2021-11-15T05:00:01.093Z",
                "Answer_upvote_count":0,
                "Answer_body":"@simonmagrin Thanks, Currently There's no way to change the disk storage type for CIs or compute clusters. We have added this to our product backlog item to support in the near future.\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Pipeline can not be built using a HyperdriveStep inside a Pipeline",
        "Question_creation_time":1621515534017,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/403018\/pipeline-can-not-be-built-using-a-hyperdrivestep-i.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"Hei, I'm trying to build a pipeline including a HyperdriveStep to tuen the hyperparameters.\nThe pipeline should later on run automatically and be tuned at each pipeline run.\n\nThe pipeline consists of three steps: a preparation step resulting in a PipelineData Object, the HyperdriveStep and a final PythonRegisterStep, where the best model should be registered.\n\nHowever, when creating the pipeline object I'm getting an error I can not relate to.\n\n\n\n\nTraceback (most recent call last):\n\n       File \"\/Users\/xxx\/Desktop\/azure_test\/pipeline-folder\/azure_pipeline_wrapper1.py\", line 168, in <module>\n         pipeline = Pipeline(workspace=ws, steps=pipeline_steps, description=\"Pipeline for hyperparameter tuning\")\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/core\/_experiment_method.py\", line 104, in wrapper\n         return init_func(self, *args, **kwargs)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/pipeline.py\", line 177, in __init__\n         self._graph = self._graph_builder.build(self._name, steps, finalize=False)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py\", line 1481, in build\n         graph = self.construct(name, steps)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py\", line 1503, in construct\n         self.process_collection(steps)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py\", line 1539, in process_collection\n         builder.process_collection(collection)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py\", line 1830, in process_collection\n         self._base_builder.process_collection(item)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py\", line 1533, in process_collection\n         return self.process_step(collection)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py\", line 1577, in process_step\n         node = step.create_node(self._graph, self._default_datastore, self._context)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/steps\/hyper_drive_step.py\", line 270, in create_node\n         hyperdrive_config, reuse_hashable_config = self._get_hyperdrive_config(context._workspace,\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/steps\/hyper_drive_step.py\", line 346, in _get_hyperdrive_config\n         hyperdrive_dto = _search._create_experiment_dto(self._hyperdrive_config, workspace,\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/train\/hyperdrive\/_search.py\", line 38, in _create_experiment_dto\n         platform_config = hyperdrive_config._get_platform_config(workspace, experiment_name, **kwargs)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/train\/hyperdrive\/runconfig.py\", line 672, in _get_platform_config\n         platform_config.update(self._get_platform_config_data_from_run_config(workspace))\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/train\/hyperdrive\/runconfig.py\", line 686, in _get_platform_config_data_from_run_config\n         run_config = get_run_config_from_script_run(self.run_config)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/core\/script_run_config.py\", line 84, in get_run_config_from_script_run\n         run_config.arguments = deepcopy(script_run_config.arguments)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 146, in deepcopy\n         y = copier(x, memo)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 205, in _deepcopy_list\n         append(deepcopy(a, memo))\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 172, in deepcopy\n         y = _reconstruct(x, memo, *rv)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 270, in _reconstruct\n         state = deepcopy(state, memo)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 146, in deepcopy\n         y = copier(x, memo)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 230, in _deepcopy_dict\n         y[deepcopy(key, memo)] = deepcopy(value, memo)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 172, in deepcopy\n         y = _reconstruct(x, memo, *rv)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 270, in _reconstruct\n         state = deepcopy(state, memo)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 146, in deepcopy\n         y = copier(x, memo)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 230, in _deepcopy_dict\n         y[deepcopy(key, memo)] = deepcopy(value, memo)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 172, in deepcopy\n         y = _reconstruct(x, memo, *rv)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 264, in _reconstruct\n         y = func(*args)\n        \n       File \"\/Users\/xxxr\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copyreg.py\", line 91, in __newobj__\n         return cls.__new__(cls, *args)\n        \n     TypeError: __new__() missing 2 required positional arguments: 'workspace' and 'name'\n\n\n\n\n\nMy Code:\n\n # Connect to workspace \n ws = Workspace.from_config()\n print(ws.name, \"loaded\")\n    \n # Set compute target\n cluster_name = \"compcluster234\"\n pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n    \n # Create new environment\n sklearn_env = Environment(\"sklearn_env\")\n # Adds dependencies to PythonSection of sklaern_env\n env_packages = CondaDependencies.create(conda_packages=['scikit-learn'])\n sklearn_env.docker.enabled = True\n sklearn_env.python.conda_dependencies = env_packages\n # Register the environment\n sklearn_env.register(workspace=ws)\n    \n # =============================================================================\n # Run Configuration\n # =============================================================================\n    \n # Create Run configuration \n # Pipeline_folder\n pipeline_folder = path + '\/pipeline-folder'\n # Create a new runconfig object for the pipeline\n pipeline_run_config = RunConfiguration()\n # Use the compute you created above. \n pipeline_run_config.target = pipeline_cluster\n # Assign the environment to the run configuration\n # In comparison to the ScriptRunCnfig object, the RunConfig is more generous\n pipeline_run_config.environment = sklearn_env\n print (\"Run configuration created.\")\n    \n # =============================================================================\n # DataPath\n # =============================================================================\n    \n # Get the default datastore\n default_ds = ws.get_default_datastore()\n # Create a DataPath object \n datapath = DataPath(datastore = default_ds,\n                      path_on_datastore = 'cancer-data')\n # Make the datapath a PipelineParameter\n datapath_pipeline_param = PipelineParameter(name='input-data',   \n                                             default_value=datapath)\n datapath_input = (datapath_pipeline_param, \n                    DataPathComputeBinding(mode = 'mount'))\n    \n # =============================================================================\n # PipelineData\n # =============================================================================\n    \n # Create a PipelineData (temporary Data Reference) for the preppared data folder\n prepped_data_folder = PipelineData(name=\"prepped_data_folder\",\n                                    datastore=ws.get_default_datastore())\n    \n # Create PipelineData objects for the Metrics and the saved model\n metrics_output_name = 'metrics_output'\n metrics_data = PipelineData(name='metrics_data',\n                             datastore=default_ds,\n                             pipeline_output_name=metrics_output_name,\n                             training_output=TrainingOutput(\"Metrics\"))\n    \n model_output_name = 'model_output'\n saved_model = PipelineData(name='saved_model',\n                            datastore=default_ds,\n                            pipeline_output_name=model_output_name,\n                            training_output=TrainingOutput(\"Model\",\n                                                           model_file=\"outputs\/model\/cancer_model.pkl\"))\n    \n # =============================================================================\n # Pipeline Steps\n # =============================================================================\n    \n # Step 1, Run the data prep script\n prep_step = PythonScriptStep(name = \"prepare_data\",\n                                 source_directory = pipeline_folder,\n                                 script_name = \"cancer_pipeline_preprocessing.py\",\n                                 arguments = ['--input-data', datapath_input,\n                                              '--prepped-data', prepped_data_folder],\n                                 inputs=[datapath_input],\n                                 outputs=[prepped_data_folder],\n                                 compute_target = pipeline_cluster,\n                                 runconfig = pipeline_run_config,\n                                 allow_reuse = False)\n    \n # Define the search strategy and parameter space for hyperparameter tuning\n ps = GridParameterSampling({ '--max_depth': choice(1,2,3)})\n # Define a early stopping criteria\n early_termination_policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n # Define a ScriptRunConfig for the Training script\n # The ScriptRunConfig is based on the RunConfig of the Pipeline\n script_run_config = ScriptRunConfig(script=\"cancer_pipeline_tuning.py\",\n                                     source_directory=pipeline_folder,\n                                     # Add non-hyperparameter arguments -in this case, the training dataset\n                                     arguments = ['--training_folder', prepped_data_folder],\n                                     run_config=pipeline_run_config)\n # Define a HyperDriveConfiguration\n # The primary_metric_name must be completely idential to the metric name logged during training (inside the training script)\n hd_config = HyperDriveConfig(run_config=script_run_config, \n                              hyperparameter_sampling=ps,\n                              policy=early_termination_policy,\n                              primary_metric_name='Accuracy', \n                              primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n                              max_total_runs=3,\n                              max_concurrent_runs=2)\n    \n # Step 2b, define a HyperDriveStep\n # HyperDriveStep can be used to run HyperDrive job as a step in pipeline.\n # No arguments need to be set as they are already set inside the ScriptRunConfig\n hyperdrive_step = HyperDriveStep(name=\"tune_hyperparameters\",\n                                  hyperdrive_config=hd_config,\n                                  inputs=[prepped_data_folder],\n                                  outputs=[metrics_data, saved_model])\n    \n hyperdrive_step.run_after(prep_step)    \n    \n # Step 3, Run the model registration step\n register_step = PythonScriptStep(name=\"register_model\",\n                                        script_name='cancer_pipeline_register1.py',\n                                        source_directory = pipeline_folder,\n                                        arguments=[\"--saved_model\", saved_model],\n                                        inputs=[saved_model],\n                                        compute_target = pipeline_cluster,\n                                        runconfig=pipeline_run_config,\n                                        allow_reuse = False)\n    \n register_step.run_after(hyperdrive_step)    \n print(\"Pipeline steps defined\")\n    \n    \n # Construct the pipeline\n pipeline_steps = [prep_step, hyperdrive_step, register_step]\n pipeline = Pipeline(workspace=ws, steps=pipeline_steps, description=\"Pipeline for hyperparameter tuning\")\n print(\"Pipeline is built.\")",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-27T06:48:25.463Z",
                "Answer_upvote_count":4,
                "Answer_body":"Solved the issue!\n\nHad to remove the arguments argument of the ScriptRunConfig and instead set the values to the Hyperdrive Steps estimator_entry_script_arguments argument.\n\n # Step 1, Run the data prep script\n prep_step = PythonScriptStep(name = \"prepare_data\",\n                                 source_directory = pipeline_folder,\n                                 script_name = \"cancer_pipeline_preprocessing.py\",\n                                 arguments = ['--input-data', datapath_input,\n                                              '--prepped-data', prepped_data_folder],\n                                 inputs=[datapath_input],\n                                 outputs=[prepped_data_folder],\n                                 compute_target = pipeline_cluster,\n                                 runconfig = pipeline_run_config,\n                                 allow_reuse=False)\n    \n # Define the search strategy and parameter space for hyperparameter tuning\n ps = GridParameterSampling({'--max_depth': choice(1,2,3),\n                             '--n_estimators': choice(100,300)})\n # Define a early stopping criteria\n early_termination_policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n # Define a ScriptRunConfig for the Training script\n # The ScriptRunConfig is based on the RunConfig of the Pipeline\n script_run_config = ScriptRunConfig(script=\"cancer_pipeline_tuning.py\",\n                                     source_directory=pipeline_folder,\n                                     run_config=pipeline_run_config)\n # Define a HyperDriveConfiguration\n # The primary_metric_name must be completely idential to the metric name logged during training (inside the training script)\n hd_config = HyperDriveConfig(run_config=script_run_config, \n                              hyperparameter_sampling=ps,\n                              policy=None,\n                              primary_metric_name=\"Accuracy\", \n                              primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n                              max_total_runs=6,\n                              max_concurrent_runs=2)\n    \n # Step 2b, define a HyperDriveStep\n # HyperDriveStep can be used to run HyperDrive job as a step in pipeline.\n # No arguments need to be set as they are already set inside the ScriptRunConfig\n hyperdrive_step = HyperDriveStep(name=\"tune_hyperparameters\",\n                                  hyperdrive_config=hd_config,\n                                  # Add non-hyperparameter arguments -in this case, the training dataset\n                                  # IMPORTANT: Don't add them already in the ScriptRunConfig\n                                  estimator_entry_script_arguments=['--training_folder', prepped_data_folder],\n                                  inputs=[prepped_data_folder],\n                                  outputs=[metrics_data, saved_model],\n                                  allow_reuse=False)",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-05-20T13:03:44.283Z",
                "Answer_upvote_count":0,
                "Answer_body":"The product group for Azure DevOps \/ TFS actively monitors questions over at\nhttps:\/\/developercommunity.visualstudio.com\/report?space=21&entry=problem\nhttps:\/\/developercommunity.visualstudio.com\/report?space=22&entry=problem\n\n--please don't forget to Accept as answer if the reply is helpful--",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Best compute cluster for training large image datasets !",
        "Question_creation_time":1633703536287,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/583349\/best-compute-cluster-for-training-large-image-data.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Good morning,\nI have a a dataset that consist of 99000 (256 x 256 pixels) images. I am trying to use this dataset to training a generative advesarial network (GAN) for at least a 1,000 epoch.\nCurrently, I am using a standard_NC24r (24 cores, 224 GB RAM, 1440 GB disk) GPU (4 x NVIDIA Tesla K80) cluster but the training is slow. It takes about 3000 seconds to train 1 epoch. This implies it would take at least a month to complete training.\nIs a cluster that I can used to speed up training?\n\nThanks for your help in advance\n\nMany thanks\n\nRoland",
        "Answers":[
            {
                "Answer_creation_time":"2021-10-11T05:01:12.66Z",
                "Answer_upvote_count":0,
                "Answer_body":"@OkwenRolandT-6377 Thanks, Instead of bigger machines with more memory, there are techniques to be used with Aml Compute for larger datasets. The Parallel Run Step is an AzureML Pipeline Step which enables parallel processing or data partitions across multiple workers on multiple nodes. PRS (ParallelRunStep) is designed for embarrassingly parallel workload, e.g. train many models, batch inference, etc.\n\nAlso look into using some of the curated images provided for compute clusters.\nSpecifically look into the DASK image.\n\nCurated environments - Azure Machine Learning | Microsoft Docs",
                "Answer_comment_count":4,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":7.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Copy experiment within workspace",
        "Question_creation_time":1653905030690,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/869578\/copy-experiment-within-workspace.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"How to duplicate experiments within workspace during debugging",
        "Answers":[
            {
                "Answer_creation_time":"2022-05-31T08:54:44.413Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @Alexandre-4252\n\nAre you mentioning studio classic? You can click the save as buttion and then you can save the experience and duplicate it, if you are mentioning studio, sorry, you can not do that.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Deploy AzureML Model locally: cannot import name 'convert_inputs'",
        "Question_creation_time":1591165699300,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/31601\/deploy-azureml-model-locally-cannot-import-name-co.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I have trained a model using azure AutoML and downloaded the model. Then I created a new conda env using the conda file and tried to execute the scoring_file_v_1_0_0.py which is in the zip. I receive this error:\n\n&amp;gt; WARNING - Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name &amp;#39;convert_inputs&amp;#39;.\n\nIs this still some dependency problem or am I doing something unexpected? I did expect the script to open a web server to serve the model.",
        "Answers":[
            {
                "Answer_creation_time":"2020-06-04T16:41:05.2Z",
                "Answer_upvote_count":1,
                "Answer_body":"I am sorry, the problem was something path related that got mixed up within my jupyter notebook setup and a moved directory. So actually the pickle was not where the framework expect it. Can be closed.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":4.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Form recognizer to report on missing information in (near) real-time",
        "Question_creation_time":1647481005860,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/775440\/form-recognizer-to-report-on-missing-information-i.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-form-recognizer"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi community,\nI'm interested in what Azure Form Recogniser or another tool can do for us in terms of screening the correctness of uploaded applications. Think of applications for funding grants. I haven't built any models yet, just wondering how feasible the below is. A solution doesn't have to involve AI at all, but must be able to 'read' the uploaded documents.\n\n\n\n\nA client uploads a set of standard documents (usually scanned PDF's) using a file upload in our .net application.\nCan we:\n1) Use form recogniser to extract key value pairs, after training a custom model.\n2) Run a loop over these pairs to find missing information e.g. they forgot to add their date of birth, or didn't enter their income.\n3) Report back to the user the missing information so they can correct the document and reupload them?\nPreferably in real time? So they hit submit on the webpage, it extracts, analyses and provides a result in a few seconds?",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-17T10:30:11.953Z",
                "Answer_upvote_count":0,
                "Answer_body":"@AndrewRobertson-7835 Yes, you can use Azure form recognizer to analyze a document that is passed to the API and use the result of the analyze operation to report any missing fields in the form back to the user. This is the most widely used use case by most of the customers.\n\nForm recognizer comes with a set of prebuilt APIs where it can extract common information from invoices, business cards, receipts etc. If you have a form that does not conform to the prebuilt API standards you need to create a custom model to extract the text in the form of a tags and their key:value pairs. The custom models require some basic training with some test forms and if all the forms that need extraction follow the same layout or guidelines the extraction results will be good.\n\nIn the case of custom forms the results are provided in almost real time where the form is submitted or POST request is sent to the API and an operation id is returned to retrieve the results using GET. Depending on your pricing tier of your resource if you intend to perform these actions synchronously you might have to limit the rate of requests sent to the API to avoid any TPS errors. If you are using async operations with a slight delay to fetch the results then you can design an application that can take large number of documents and provide results to the users within a short span of time.\n\nI hope the above information is helpful.\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Machine Learning (AutoML) export data to SharePoint",
        "Question_creation_time":1631064917827,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/543361\/azure-machine-learning-automl-export-data-to-share.html",
        "Question_topic":null,
        "Question_tag":[
            "office-sharepoint-online",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I am using Azure Machine Learning Studio to design pipelines to analyze data.\nIs there any possibility to export data to sharepoint?",
        "Answers":[
            {
                "Answer_creation_time":"2021-09-08T07:07:22.44Z",
                "Answer_upvote_count":2,
                "Answer_body":"Hi @MiaZhangWHQWistron-2092\nPer my research, there is no way to export data from Azure Machine Learning Studio to SharePoint directly.\n\nAs an alternative, you could export data to Azure SQL database first:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/export-to-azure-sql-database\n\nThen export data from Azure SQL database to SharePoint list:\nhttps:\/\/social.technet.microsoft.com\/wiki\/contents\/articles\/39170.azure-sql-db-with-sharepoint-online-as-external-list-using-business-connectivity-services.aspx\n\n\nIf an Answer is helpful, please click \"Accept Answer\" and upvote it.\n\nNote: Please follow the steps in our documentation to enable e-mail notifications if you want to receive the related email notification for this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":13.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Random forests on Azure GPU VM using the SDK",
        "Question_creation_time":1595050125193,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/49008\/random-forests-on-azure-gpu-vm-using-the-sdk.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Can you please share any code examples for training random forests with GPU on Azure using libraries.\nI want to run on the multiple nodes.",
        "Answers":[
            {
                "Answer_creation_time":"2020-07-20T07:47:48.033Z",
                "Answer_upvote_count":0,
                "Answer_body":"@vautoml-0887 Thanks for the question. You can run LightGBM with boosting=random_forest, Please follow the below documentation:\nhttps:\/\/github.com\/microsoft\/LightGBM\/blob\/master\/docs\/Parameters.rst#boosting\n\n\n\n\nHere is a general tutorial on how to run LightGBM on GPU, You can run it on any Azure GPU VM:\nhttps:\/\/github.com\/microsoft\/LightGBM\/blob\/master\/docs\/GPU-Tutorial.rst\n\n\n\n\nIf you need to run it on multiple nodes, there is also a distributed spark implementation available at https:\/\/github.com\/Azure\/mmlspark.\n\n\n\n\nRandom Forests for the GPU using PyCUDA: https:\/\/pypi.org\/project\/cudatree\/",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":34.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure Synapse ML predict [Errno 20] Not a directory",
        "Question_creation_time":1648335577807,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/788637\/azure-synapse-ml-predict-errno-20-not-a-directory.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-synapse-analytics",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I follow the official tutotial from microsoft: https:\/\/docs.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool\n\nBut when I execute:\n\n #Bind model within Spark session\n model = pcontext.bind_model(\n     return_types=RETURN_TYPES, \n     runtime=RUNTIME, \n     model_alias=\"Sales\", #This alias will be used in PREDICT call to refer  this   model\n     model_uri=AML_MODEL_URI, #In case of AML, it will be AML_MODEL_URI\n     aml_workspace=ws #This is only for AML. In case of ADLS, this parameter can be removed\n ).register()\n\n\n\nI\u00b4ve got:\n\n\n\n\nNotADirectoryError: [Errno 20] Not a directory: '\/mnt\/var\/hadoop\/tmp\/nm-local-dir\/usercache\/trusted-service-user\/appcache\/application_1648328086462_0002\/spark-3d802a7e-15b7-4eb6-88c5-f0e01f8cdb35\/userFiles-fbe23a43-67d3-4e65-a879-4a497e804b40\/68603955220f5f8646700d809b71be9949011a2476a34965a3d5c0f3d14de79b.pkl\/MLmodel'\nTraceback (most recent call last):\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_context.py\", line 47, in bind_model\nudf = _create_udf(\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_udf.py\", line 104, in _create_udf\nmodel_runtime = runtime_gen._create_runtime()\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_runtime.py\", line 103, in _create_runtime\nif self._check_model_runtime_compatibility(model_runtime):\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_runtime.py\", line 166, in _check_model_runtime_compatibility\nmodel_wrapper = self._load()\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_runtime.py\", line 78, in _load\nreturn SynapsePredictModelCache._get_or_load(\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_cache.py\", line 172, in _get_or_load\nmodel = load_model(runtime, model_uri, functions)\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/utils\/_model_loader.py\", line 257, in load_model\nmodel = loader.load(model_uri, functions)\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/utils\/_model_loader.py\", line 122, in load\nmodel = self._load(model_uri)\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/utils\/_model_loader.py\", line 215, in _load\nreturn self._load_mlflow(model_uri)\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/utils\/_model_loader.py\", line 59, in _load_mlflow\nmodel = mlflow.pyfunc.load_model(model_uri)\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/`init`.py\", line 640, in load_model\nmodel_meta = Model.load(os.path.join(local_path, MLMODEL_FILE_NAME))\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/mlflow\/models\/model.py\", line 124, in load\nwith open(path) as f:\n\nNotADirectoryError: [Errno 20] Not a directory: '\/mnt\/var\/hadoop\/tmp\/nm-local-dir\/usercache\/trusted-service-user\/appcache\/application_1648328086462_0002\/spark-3d802a7e-15b7-4eb6-88c5-f0e01f8cdb35\/userFiles-fbe23a43-67d3-4e65-a879-4a497e804b40\/68603955220f5f8646700d809b71be9949011a2476a34965a3d5c0f3d14de79b.pkl\/MLmodel'\n\nHow can I fix that error ?",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-28T11:26:12.193Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hello @ThiloBarth-2620,\n\nThanks for the question and using MS Q&A platform.\n\n(UPDATE:29\/3\/2022): You will experiencing this error message if you model does not contains all the required files in the ML model.\n\nAs per the repro, I had created two ML models named:\n\nsklearn_regression_model: Which contains only sklearn_regression_model.pkl file.\n\nWhen I predict for MLFLOW packaged model named sklearn_regression_model, getting same error as shown above:\n\nlinear_regression: Which contains the below files:\n\nWhen I predict for MLFLOW packaged model named linear_regression, it works as excepted.\n\n--------------------------------------------------\n\nIt should be AML_MODEL_URI = \"<aml model uri>\" #In URI \":x\" => Rossman_Sales:2\n\nBefore running this script, update it with the URI for ADLS Gen2 data file along with model output return data type and ADLS\/AML URI for the model file.\n\n #Set model URI\n        #Set AML URI, if trained model is registered in AML\n           AML_MODEL_URI = \"<aml model uri>\" #In URI \":x\" signifies model version in AML. You can   choose which model version you want to run. If \":x\" is not provided then by default   latest version will be picked.\n    \n        #Set ADLS URI, if trained model is uploaded in ADLS\n           ADLS_MODEL_URI = \"abfss:\/\/<filesystemname>@<account name>.dfs.core.windows.net\/<model   mlflow folder path>\"\n\nModel URI from AML Workspace:\n\n DATA_FILE = \"abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/AML\/LengthOfStay_cooked_small.csv\"\n AML_MODEL_URI_SKLEARN = \"aml:\/\/mlflow_sklearn:1\" #Here \":1\" signifies model version in AML. We can choose which version we want to run. If \":1\" is not provided then by default latest version will be picked\n RETURN_TYPES = \"INT\"\n RUNTIME = \"mlflow\"\n\nModel URI uploaded to ADLS Gen2:\n\n DATA_FILE = \"abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/AML\/LengthOfStay_cooked_small.csv\"\n AML_MODEL_URI_SKLEARN = \"abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/linear_regression\/linear_regression\" #Here \":1\" signifies model version in AML. We can choose which version we want to run. If \":1\" is not provided then by default latest version will be picked\n RETURN_TYPES = \"INT\"\n RUNTIME = \"mlflow\"\n\n\n\nHope this will help. Please let us know if any further queries.\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":7,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":16.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Data Import error for Azure table storage to Azure ML studio ?",
        "Question_creation_time":1616070530733,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/320696\/data-import-error-for-azure-table-storage-to-azure.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-blob-storage",
            "azure-machine-learning-studio-classic",
            "azure-table-storage"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hi Team,\n\nI tried connecting to Azure table storage in Azure ML Studio. It shows connection successful after updating all credentials but after hitting run, import is landing to internal system error.\nBelow is the message :\n[Critical] Error: Sorry, it seems that you have encountered an internal system error. Please contact amlforum@microsoft.com with the full URL in the browser and the time you experienced the failure. We can locate this error with your help and investigate further. Thank you.\n\nRequesting you to please assist in this case.\n\nRegards,\nSachin",
        "Answers":[
            {
                "Answer_creation_time":"2021-03-22T06:53:02.957Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nThere is a known issue that Azure ML Studio only supports \u201chttp\u201d protocol when connecting with Azure Storage Account. You might hit this issue when using the Import Data module.\n\n\n\n\nHere is a quick work around:\nPlease check the \u201cConfiguration\u201d of your Storage Account, and make sure the \u201cSecure transfer required\u201d is disabled (see the figure below).\n\nIf still encountering error after taking these steps, please double check and make sure the account key is correct.\n\n@SachinGaikwad-5400 Please accept the answer if you feel the work around works. Thank you!\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":6.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"How to run python 2.7 scripts on a computer cluster",
        "Question_creation_time":1637171846430,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/631040\/importerror-cannot-import-name-outputfiledatasetco.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I am aware that azureml will drop support for python 2.7, but I have got some old codes and have to finish training the models. Since I will not use the codes afterwards anyway, so I do not want to spend much time to port to python 3.\n\nAs I tried to run the codes in python 2.7 on a compute cluster, I got the error ImportError: cannot import name OutputFileDatasetConfig coming from this line:\nfrom azureml.data import OutputFileDatasetConfig\nThe environment, that I have created for python 2.7, has azureml-core v1.1.5. I cannot find any documentation for this version, so I do not know, if it supports OutputFileDatasetConfig.\n\nCan someone tell me, how I can run my codes in python 2.7 on compute clusters? Thanks!",
        "Answers":[
            {
                "Answer_creation_time":"2021-11-18T03:49:39.763Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @Lu-3578\n\nThanks for reaching out to us. I have not found any official document either.\n\nIn this scenario, I think the quickest way to solve the problem is to raise a support ticket.\n\nLet me know if you have no support plan, please share the ticket id since I will forward this issue to product team to see what we can do more.\n\n\n\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure AutoML Featurisation Error",
        "Question_creation_time":1638154550033,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/643670\/azure-automl-featurisation-error.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"According the following doc, I should be able to to turn on FeaturizationConfig in the settings:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train\n\nHowever I'm getting the following error when I try to change the switch to 'FeaturizationConfig' when setting up the AutoML experiment:\n\nConfigException: ConfigException: Message: Invalid argument(s) 'featurizationconfig' specified. Supported value(s): 'off, auto'\n\nThe following is my settings:\n\nimport logging\n\n\nautoml_settings = {\n\"iteration_timeout_minutes\": 15,\n\"experiment_timeout_hours\": 0.3,\n\"enable_early_stopping\": True,\n\"primary_metric\": 'spearman_correlation',\n\"featurization\": 'FeaturizationConfig',\n\"verbosity\": logging.INFO,\n\"n_cross_validations\": 5\n}",
        "Answers":[
            {
                "Answer_creation_time":"2021-11-29T12:46:23.847Z",
                "Answer_upvote_count":0,
                "Answer_body":"@SoonJooGenting-3682 Thanks, Previously, it was a black-box preprocessing, with user\u2019s preprocess=True\/False setting.\nNew change includes deprecation of preprocess and introduction of new field featurization, where featurization = \u2018auto\u2019 (for automatic featurization, comparable to preprocess=True) \/ \u2018off\u2019 (to turn off featurization, comparable to preprocess=False) \/ FeaturizationConfig (object to pass in customized configuration on featurization setting).\n\nFor more information on custom featurization as well as how to construct FeaturizationConfig is in this documentation.\nWe also have a notebook available with example in our git repo.\nUsage example:\n\n from azureml.automl.core.featurization import FeaturizationConfig\n    \n featurization_config = FeaturizationConfig()\n featurization_config.add_column_purpose('Column2', 'Categorical')\n featurization_config.add_column_purpose('Column5', 'Categorical')\n    \n automl_config = AutoMLConfig(task = 'classification', compute_target=compute_target, featurization=featurization_config, **automl_settings )\n remote_run = experiment.submit(automl_config, show_output = False)\n\n\n\n\nFor classification & regression you do have the option to turn off automatic featurization.\n\nfeaturization\nstr or FeaturizationConfig\n'auto' \/ 'off' \/ FeaturizationConfig Indicator for whether featurization step should be done automatically or not, or whether customized featurization should be used.\n\u2026\nNote: Timeseries features are handled separately when the task type is set to forecasting independent of this parameter.\n\n\n\n\n\u2022 AutoMLConfig Class",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Not enough quota available when deploying a machine learning model on Azure",
        "Question_creation_time":1666148560563,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1053752\/not-enough-quota-available-when-deploying-a-machin.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-machine-learning-studio-classic"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I was trying to deploy and score a machine learning model by using an online endpoint.\n\nWhen I was trying to run code this on Azure Machine Learning Wordspace,\n\n !az ml online-deployment create --name fraud-ga --endpoint endpoint-name -f ..\/deployment\/deployment.yml --all-traffic\n\n\n\nI got this error:\n\n {\"errors\":{\"VmSize\":[\"Not enough quota available for Standard_F16s_v2 in SubscriptionId 671ef6e1-2ded-466b-8fd1-91363cf12275. Current usage\/limit: 4\/6. Additional needed: 32 Please see troubleshooting guide, available here: https:\/\/aka.ms\/oe-tsg#error-outofquota\"]},\"type\":\"https:\/\/tools.ietf.org\/html\/rfc7231#section-6.5.1\",\"title\":\"One or more validation errors occurred.\",\"status\":400,\"traceId\":\"00-a308e99ddee5fc8714e34fd0808b7e93-2031400dbc3e84d1-01\"}\n\n\n\n\nWhat I understood is that I need more cores.\n\nSo, in this case how many cores I needed and how to solve this error?",
        "Answers":[
            {
                "Answer_creation_time":"2022-10-19T04:02:03.51Z",
                "Answer_upvote_count":1,
                "Answer_body":"It sounds like you don't have enough quota available in the region where you are trying to deploy the ML model.\nIn Azure portal, you can check the allocated quota for each region under the subscription blade:\n\nThe error message says: Current usage\/limit: 4\/6. Additional needed: 32\n\nRequest a quota increase and Azure support team can help on that!\n\n\n\n\n\n\n--please don't forget to upvote and Accept as answer if the reply is helpful--",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Notebook files have disaperred",
        "Question_creation_time":1652875560357,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/854288\/notebook-files-have-disaperred.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello,\n\nIn my MLStudio my notebook files window has disappeared so I can not access any of my data (as seen on the image) and I do not know what to do.\n\nPlease your help to solve this as soon as poosible.\n\nThank you.",
        "Answers":[
            {
                "Answer_creation_time":"2022-05-19T02:46:25.6Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us. Could you please check the access of Storage? https:\/\/docs.microsoft.com\/en-us\/azure\/storage\/blobs\/assign-azure-role-data-access?tabs=portal#assign-an-azure-role\n\nTo access these storage services, you must have at least Storage Blob Data Reader access to the storage account. Only storage account owners can change your access level via the Azure portal.\n\nOr, your admin put the data storage behind V-Net and you can not get access to it- https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-identity-based-data-access#work-with-virtual-networks\nIn this situation, you need to ask permission from your admin.\n\nCould you please share which situation you are in?\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":11.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"feature in new generation of classic studio",
        "Question_creation_time":1648513803980,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/791041\/feature-in-new-generation-of-classic-studio.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"hi:\n\nI have a question regarding to the new generation as I have already known that the classic old version of machine learning studio is retiring in August 2024.\n\nI wonder if all the features will be continouslty supported in the new generation of new version of studio in the future?",
        "Answers":[
            {
                "Answer_creation_time":"2022-03-29T03:44:35.91Z",
                "Answer_upvote_count":0,
                "Answer_body":"Hello @dontbelazy-2604\n\nThanks for reaching out to us here, I just answered your question under your previous thread. Not every feature in Studio (classic) will be back as the same, but most of the previous features\/ functions will be covered in the Azure Machine Learning Studio (V2).\n\nPlease go ahead to do the migration first, if you face any issue or you feel like some of the features missing, please let us know, we can help.\n\nGenerally, the new studio will provide a better experience.\n\nHope this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":0.0,
        "Question_follower_count":10.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Azure On-Demand ML cluster from a search in the data catalog",
        "Question_creation_time":1619209726297,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/369952\/azure-on-demand-ml-cluster-from-a-search-in-the-da.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning",
            "azure-data-catalog"
        ],
        "Question_upvote_count":1.0,
        "Question_view_count":null,
        "Question_answer_count":2,
        "Question_has_accepted_answer":true,
        "Question_body":"I'm trying to implement a self-service solution in Azure so users can run a Jupyter or PySpark notebook on-Demand\/automatically with the dataset they found a search in the Azure Data Catalog. I visualize, once the user finds the data in a search, there will be a link that will take him\/her to a Notebook and the dataset can be used for analysis. Any suggestion would be very much appreciated!",
        "Answers":[
            {
                "Answer_creation_time":"2021-04-26T10:22:10.247Z",
                "Answer_upvote_count":0,
                "Answer_body":"@JairoMelo-1657 Thanks for the question.Azure Purview can find, understand, and consume data sources. Please follow the Azure Purview documentation: https:\/\/docs.microsoft.com\/en-us\/azure\/purview\/\n\nand We have Azure Open Datasets where you can download a Notebook for AML, Databricks or Synapse that explores the data: Azure Open Datasets Catalog | Microsoft Azure. What are open datasets? Curated public datasets - Azure Open Datasets | Microsoft Docs.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-04-28T11:51:31.093Z",
                "Answer_upvote_count":1,
                "Answer_body":"Thank you very much for your response. I'll look into Azure Purview. Best! J.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":1.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"Auth Problems with Machine Learning Execute Pipeline Activity.",
        "Question_creation_time":1621952386747,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/408869\/auth-problems-with-machine-learning-execute-pipeli.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-data-factory",
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":3,
        "Question_has_accepted_answer":true,
        "Question_body":"Hello. Can anyone help with this error? Can not execute Azure ML activity from ADF.\nEverything was ok, no changes was done but suddenly(two-three days ago) I got this error.\n\n Request sent to Azure ML Service for operation 'submitMLPipelineRun' failed with http status code 'Forbidden'. Error message from Azure ML Service: '{ \"error\": { \"code\": \"UserError\", \"severity\": null, \"message\": \"Identity does not have permissions for Microsoft.MachineLearningServices\/workspaces\/experiments\/runs\/submit\/action, Microsoft.MachineLearningServices\/workspaces\/endpoints\/pipelines\/read actions.\", \"messageFormat\": null, \"messageParameters\": null, \"referenceCode\": null, \"detailsUri\": null, \"target\": null, \"details\": [], \"innerError\": { \"code\": \"ForbiddenError\", \"innerError\": null } '.",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-25T19:35:57.963Z",
                "Answer_upvote_count":1,
                "Answer_body":"@DenisBruk-6507\n\nWe have identified the issue and a hot fix is rolling out. It will be fixed in all regions by end of today. Sorry for the experience.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-05-25T17:34:38.503Z",
                "Answer_upvote_count":1,
                "Answer_body":"@YutongTie-5848 I think that this may also be related to our issue. I'm also getting a \"code\": \"ForbiddenError\" and the problem for this user arose at almost exactly the same time that it arose for us.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-26T17:41:58.203Z",
                "Answer_upvote_count":1,
                "Answer_body":"Hello everyone,\n\nThis issue should be fixed. Please check and let me know if you are still facing any issue.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":3.0,
        "Question_follower_count":12.0,
        "Question_converted_from_issue":null
    },
    {
        "Question_title":"NameError when trying to run an ScriptRunConfig in Azure Machine Learning",
        "Question_creation_time":1640331391010,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/674712\/nameerror-when-trying-to-run-an-scriptrunconfig-in.html",
        "Question_topic":null,
        "Question_tag":[
            "azure-machine-learning"
        ],
        "Question_upvote_count":0.0,
        "Question_view_count":null,
        "Question_answer_count":1,
        "Question_has_accepted_answer":true,
        "Question_body":"I'm trying to deploy a locally trained RandomForest model into Azure Machine Learning Studio.\n\ntraining code (whentrain.ipynb) :\n\n #import libs and packages\n import numpy as np\n import pandas as pd\n    \n from sklearn.preprocessing import MinMaxScaler\n from sklearn.model_selection import train_test_split\n    \n from sklearn import metrics\n from sklearn.metrics import r2_score\n from math import sqrt\n    \n from sklearn.ensemble import RandomForestRegressor\n    \n from sklearn.preprocessing import LabelEncoder\n from imblearn.over_sampling import SMOTE\n    \n import xgboost as xgb\n from sklearn.metrics import accuracy_score\n from azureml.core import Workspace, Dataset\n    \n # get existing workspace\n workspace = Workspace.from_config(path=\"config.json\")\n    \n # get the datastore to upload prepared data\n datastore = workspace.get_default_datastore()\n    \n # load the dataset which is placed in the data folder\n dataset = Dataset.Tabular.from_delimited_files(datastore.path('UI\/12-23-2021_023530_UTC\/prepped_data101121.csv'))\n dataset = dataset.to_pandas_dataframe()\n    \n # Create the outputs directories to save the model and images\n os.makedirs('outputs\/model', exist_ok=True)\n os.makedirs('outputs\/output', exist_ok=True)\n dataset['Date'] = pd.to_datetime(dataset['Date'])\n dataset = dataset.set_index('Date')\n ###\n scaler = MinMaxScaler()\n    \n #inputs\n X = dataset.iloc[:, 1:]\n #output\n y = dataset.iloc[:, :1]\n    \n X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 42, shuffle=True)\n    \n X_train = scaler.fit_transform(X_train)\n X_test = scaler.fit_transform(X_test)\n    \n ###\n    \n model1 = RandomForestRegressor(n_estimators = 6,\n                                    max_depth = 10,\n                                    min_samples_leaf= 1,\n                                    oob_score = 'True',\n                                    random_state=42)\n model1.fit(X_train, y_train.values.ravel())\n    \n y_pred2 = model1.predict(X_test)\n\n\n\n\nAnd here is the code on the estimator part (estimator.ipynb):\n\n from azureml.core import Experiment\n from azureml.core import Workspace\n from azureml.core.compute import ComputeTarget, AmlCompute\n from azureml.core.compute_target import ComputeTargetException\n from azureml.train.dnn import TensorFlow\n from azureml.widgets import RunDetails\n    \n import os\n    \n workspace = Workspace.from_config(path=\"config.json\")\n exp = Experiment(workspace=workspace, name='azure-exp')\n cluster_name = \"gpucluster\"\n    \n try:\n     compute_target = ComputeTarget(workspace=workspace, name=cluster_name)\n     print('Found existing compute target')\n except ComputeTargetException:\n     print('Creating a new compute target...')\n     compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS3_v2',\n                                                            max_nodes=1)\n    \n     compute_target = ComputeTarget.create(workspace, cluster_name, compute_config)\n    \n     compute_target.wait_for_completion(show_output=True)  # , min_node_count=None, timeout_in_minutes=20)\n     # For a more detailed view of current AmlCompute status, use get_status()\n     print(compute_target.get_status().serialize())\n from azureml.core import ScriptRunConfig\n source_directory = os.getcwd()\n    \n from azureml.core import Environment\n    \n myenv = Environment(\"user-managed-env\")\n myenv.python.user_managed_dependencies =True\n from azureml.core import Dataset\n test_data_ds = Dataset.get_by_name(workspace, name='prepped_data101121')\n    \n src = ScriptRunConfig(source_directory=source_directory,\n                       script='whentrain.ipynb',\n                          \n                       arguments=['--input-data', test_data_ds.as_named_input('prepped_data101121')],\n                       compute_target=compute_target,\n                       environment=myenv)\n run = exp.submit(src)\n RunDetails(run).show()\n run.wait_for_completion(show_output=True)\n\n\n\n\nThe error that happens in run.wait_for_completion states :\n\n [stderr]Traceback (most recent call last):\n [stderr]  File \"whentrain.ipynb\", line 107, in <module>\n [stderr]    \"notebookHasBeenCompleted\": true\n [stderr]NameError: name 'true' is not defined\n [stderr]\n\n\n\nAs you can see in my whentrain.ipynb, it does not even reach line 107, and I could not find where this error come from. So how do I fix it?\n\nI'm running the Notebook on Python 3.\n\n\n\n\n\nUPDATE:\n\nOkay, after a little adjustment that should not affect the whole code (I just removed some extra columns, added model save code in whentrain.ipynb making use of import os) it's now giving me somewhat the same error.\n\n [stderr]Traceback (most recent call last):\n [stderr]  File \"whentrain.ipynb\", line 115, in <module>\n [stderr]    \"source_hidden\": false,\n [stderr]NameError: name 'false' is not defined\n [stderr]",
        "Answers":[
            {
                "Answer_creation_time":"2021-12-27T18:03:50.64Z",
                "Answer_upvote_count":0,
                "Answer_body":"@Ash-8361 Ok, I think the issue is here.\n\n src = ScriptRunConfig(source_directory=source_directory,\n                        script='whentrain.ipynb',\n                              \n                        arguments=['--input-data', test_data_ds.as_named_input('prepped_data101121')],\n                        compute_target=compute_target,\n                        environment=myenv)\n\n\n\nThe script parameter is set to the notebook \"whentrain.ipynb\", This should be a python script *.py which can train your model. Since you are using the notebook filename the entire source of jupyter notebook is loaded and it fails with these errors. You can lookup samples on azure ml notebook github repo for reference. I think if you can convert your whentrain.ipynb file to a python script whentrain.py and save it the current folder structure you should be able to use it in this step.",
                "Answer_comment_count":4,
                "Answer_has_accepted":true
            }
        ],
        "Tool":"Azure Machine Learning",
        "Question_comment_count":2.0,
        "Question_follower_count":9.0,
        "Question_converted_from_issue":null
    }
]