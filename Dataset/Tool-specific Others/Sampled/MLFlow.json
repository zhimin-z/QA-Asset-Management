[
    {
        "Question_title":"MLflow Release 0.4.2",
        "Question_creation_date":"2018-08-07T21:52:29",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/NH0x9ch4MW0",
        "Question_answer_count":0,
        "Question_view_count":16,
        "Question_body":"Hi mlflow-users,\n\nMLflow Release 0.4.2 is ready, released 2018-08-07. The release is available on\u00a0PyPI\u00a0and docs are\u00a0updated. Here are the release notes (also available\u00a0on GitHub):\n\n\n\nBreaking changes: None\n\nFeatures:\n\nMLflow experiments REST API and\u00a0mlflow experiments create\u00a0now support providing\u00a0--artifact-location\u00a0(#232,\u00a0@aarondav)\n[UI] Runs can now be sorted by columns, and added a Select All button (#227,\u00a0@ToonKBC)\nDatabricks File System (DBFS) artifactory support added (#226,\u00a0@andrewmchen)\ndatabricks-cli version upgraded to >= 0.8.0 to support new DatabricksConfigProvider interface (#257,\u00a0@aarondav)\n\nBug fixes:\n\nMLflow client sends REST API calls using snake_case instead of camelCase field names (#232,\u00a0@aarondav)\nMinor bug fixes (#243,\u00a0#242,\u00a0@aarondav;\u00a0#251,\u00a0@javierluraschi;\u00a0#245,\u00a0@smurching;\u00a0#252,\u00a0@mateiz)",
        "Answers":[

        ]
    },
    {
        "Question_title":"GPT-3 integration?",
        "Question_creation_date":"2022-08-22T13:04:49",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/m36yrKpx87c",
        "Question_answer_count":0,
        "Question_view_count":8,
        "Question_body":"OpenAI has put out a powerful model called GPT-3. This model allows for custom model generation, complete with fine-tuning, metrics measurement, etc. I was wondering whether it would be possible to track GPT-3 runs using MLflow?\n\n\nThey do have a provision to track using Weights and Biases.\n\n\nHere's the link to the documentation (specific bookmark links to the chapter that provides github links to jupyter notebooks).\n\n\nThanks!",
        "Answers":[

        ]
    },
    {
        "Question_title":"custom database for mlflow",
        "Question_creation_date":"2020-10-19T15:30:27",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/5zHcAO36wXY",
        "Question_answer_count":0,
        "Question_view_count":20,
        "Question_body":"I believe I have heard you can configure mlflow to use your own custom db.\u00a0\u00a0 Any one have any info on that?\n\n\n\nDan",
        "Answers":[

        ]
    },
    {
        "Question_title":"log parameters in databricks",
        "Question_creation_date":"2021-05-04T18:18:23",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/M5-z8doznpo",
        "Question_answer_count":4,
        "Question_view_count":38,
        "Question_body":"Hello everyone , can someone please tell me how can i log the best parameters of crossvalid and paramgrid using mlflow , pyspark in databricks\u00a0\nthank you",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-04T19:19:30",
                "Answer_body":"Hello everyone , can someone please tell me how can i log the best parameters of crossvalid and paramgrid using mlflow , pyspark in databricks\u00a0\n\n\nI assume that your best metric is the consequence of your best parameters in the crossvalid and paragrid. So once you find the best\nmodel, use that model's parameters to log using MLflow APIs.\u00a0\u00a0\n\n\n# Run cross-validation, and choose the best set of parameters.\ncvModel = crossval.fit(training)\n\nHope\u00a0this direction helps\n\n\n\n\ncheers\n\nJules\n\n\n\n\n\u2013\u2013\n\nThe Best Ideas are Simple\n\nJules S. Damji\n\nSr. Developer Advocate\n\nDatabricks, Inc.\n\nju...@databricks.com\n\n(510) 304-7686\n\n\n\n\n\n\n\n\n\n\n\u00a0\u00a0\u00a0\n\n\n\n\n\n\n\n\nOn Tue, May 4, 2021 at 3:18 PM nadine ben harrath <nadinebe...@gmail.com> wrote:\n\nHello everyone , can someone please tell me how can i log the best parameters of crossvalid and paramgrid using mlflow , pyspark in databricks\u00a0\nthank you\u00a0\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/08c379bd-3969-492c-a6c7-7cb81650e7e5n%40googlegroups.com."
            },
            {
                "Answer_creation_time":"2021-05-04T19:37:06",
                "Answer_body":"yes i know but i should log every parameter of crossvalidation using mlflow\u00a0\n\ue5d3"
            },
            {
                "Answer_creation_time":"2021-05-05T18:51:48",
                "Answer_body":"you didn't get my problem , when i write with mlflow start_run() using paramgrid and crossvalidation , i don't find the best parameter of crossvalidation logged in mlflow\u00a0\n\ue5d3"
            },
            {
                "Answer_creation_time":"2021-05-05T20:43:49",
                "Answer_body":"Nadine,\n\n\nSorry for the confusion. Are you a Databricks customer? If so I would urge you to file a ticket and provide the notebook that's not\nlogging your parameter. Surely, the support person can follow up\u00a0with the issue if he\/she can reproduce it on the Databricks cluster.\n\n\n(Note: If you use the new autolog feature then all parameters, metrics, and artifacts are automatically logged for you during the model.fit() call; if you don't use autolog() then you will\nhave to explicitly\u00a0log the parameters yourself, using the tracking APIs. If you doing the latter, and it's now showing in the MLflow\u00a0UI run's page, then would be worthwhile to investigate)\n\n\nCheers\n\ue5d3\n\ue5d3\n\ue5d3\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/25115d0b-283a-45a2-aaf4-90a491d81764n%40googlegroups.com."
            }
        ]
    },
    {
        "Question_title":"GOCD Plugin for MLflow",
        "Question_creation_date":"2018-11-12T01:01:33",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/CIihDdCS014",
        "Question_answer_count":2,
        "Question_view_count":22,
        "Question_body":"Hi All,\n\n\nWe have built a new GoCD plugin[1] which works with mlflow and helps us in continuous delivery of models.\n\nHope Y'all find this useful.\u00a0\n\n\n[1] https:\/\/github.com\/indix\/mlflow-gocd\/\n\n\nBest,\nKrishna Sangeeth",
        "Answers":[
            {
                "Answer_creation_time":"2018-11-20T21:44:38",
                "Answer_body":"This is very cool, Krishna; thanks for sharing! We also just saw your blog post at https:\/\/stacktoheap.com\/blog\/2018\/11\/19\/mlflow-model-repository-ci-cd\/.\n\nIf you\u2019d like, we could feature this blog on mlflow.org or link to the plugin in the docs somewhere; please let us know whether you\u2019d be interested.\n\nMatei\n\n\ue5d3\n> --\n> You received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\n> To unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\n> To post to this group, send email to mlflow...@googlegroups.com.\n> To view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/CADub9hP%3DtTiJ6uMLL6pauzq_BorF26OD0mvp%3D9gzMhOkVuZesw%40mail.gmail.com.\n> For more options, visit https:\/\/groups.google.com\/d\/optout."
            },
            {
                "Answer_creation_time":"2018-11-21T01:43:34",
                "Answer_body":"<Reposting after joining group>\n\n\nHi Matei,\n\n\nThanks for the response.\n\n\nWe would definitely be happy if you can feature the blog and\/or the plugin. Let us know if you need anything from us.\n\n\nThanks\nManoj\n\n\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"MLflow 0.8.2 Released!",
        "Question_creation_date":"2019-01-30T18:30:19",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/pciLszBL2ig",
        "Question_answer_count":0,
        "Question_view_count":23,
        "Question_body":"MLflow 0.8.2 has been released!\n\n\n\nMLflow 0.8.2 is a patch release on top of 0.8.1 containing bug fixes and documentation updates. Please see the release change log\u00a0for more information\u00a0about the fixes and updates introduced in this release. Also, check out the latest documentation on mlflow.org.",
        "Answers":[

        ]
    },
    {
        "Question_title":"Model staging",
        "Question_creation_date":"2021-05-27T07:48:58",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/OpF4sawraY0",
        "Question_answer_count":0,
        "Question_view_count":10,
        "Question_body":"Hello Community\n\n\n1.Is there a way to get all the versions of\u00a0 a particular stage of a registered model\nlatest_version_info = client.get_latest_versions(model_name, stages=[\"Archived\"]). This code fetches only the latest version not all the versions of the staged model\n\n\n2.Is there a way to delete all the versions of a staged version say I want to delete all the versions staged \"Archived\"\n\n\nRegards,\nAarthi",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLflow 1.1 released!",
        "Question_creation_date":"2019-07-23T13:34:20",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/VDLdh-HzhlU",
        "Question_answer_count":0,
        "Question_view_count":14,
        "Question_body":"Hi all,\n\nMLflow 1.1 has been released! The release contains many exciting new features:\n* Automatic logging from TensorFlow and Keras\n* Parallel coordinate plots in the tracking UI\n* Pandas DataFrame based search API\n* Java Fluent API\n* Kubernetes execution backend for MLflow projects\n* Search Pagination\n\nSee the CHANGELOG for details about the new features:\nhttps:\/\/github.com\/mlflow\/mlflow\/releases\/tag\/v1.1.0\n\nAnd see the blog post for some examples of these features in action: https:\/\/databricks.com\/blog\/2019\/07\/23\/announcing-the-mlflow-1-1-release.html\n\nThanks,\nSid",
        "Answers":[

        ]
    },
    {
        "Question_title":"Autologging metrics",
        "Question_creation_date":"2021-08-22T23:54:30",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/dwowhoJAG-M",
        "Question_answer_count":0,
        "Question_view_count":11,
        "Question_body":"Hello everyone,\nI have a question about autologging. I use it and I want to record another metrics.\nCan I change the recorded metrics for autologging?\n\nThanks,\nIrina",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLFlow UI issue when running in docker",
        "Question_creation_date":"2019-11-30T12:08:45",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/7cezJGzfnic",
        "Question_answer_count":1,
        "Question_view_count":557,
        "Question_body":"I installed mlflow and started the ui with no issues on my windows 10 machine in an anaconda python 3.7 environment and am able to access the UI via http:\/\/localhost:5000\nHowever, when doing the exact same thing within the anacanda3 docker container the UI doesn't appear to be rendering\/responding.\nMy docker run command includes the proper port and I am able to exec into the container, install mlflow and start the ui (>mlflow ui) without any errors.\n\n\ndocker run --name conda3 -d -t -v \/\/c\/\/develop:\/develop -p 5000:5000 continuumio\/anaconda3\\\n\nWhen I try to access\u00a0http:\/\/localhost:5000\u00a0(or\u00a0http:\/\/127.0.0.1:5000\/), the response in the browser is \"ERR_EMPTY_RESPONSE\".\nI tried to access the UI within the contain via lynx, to confirm that it is running, however, the response is just a warning that this site is javascript which can't be rendered in lynx.\n\nI also tried the above docker approach using python 3.6 and also utilizing the docker container I normally develop with but in both cases I still get \"ERR_EMPTY_RESPONSE\".\n\nI am pretty much stuck at this point so any suggestions will be appreciated. Thanks.",
        "Answers":[
            {
                "Answer_creation_time":"2019-12-12T23:21:54",
                "Answer_body":"Solution was to start the server with the 'server' command instead of the 'ui' command like this: mlflow server -h 0.0.0.0\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"mlflow demonstration with Docker containers",
        "Question_creation_date":"2019-03-23T19:54:17",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/SsVBNB_7zEw",
        "Question_answer_count":0,
        "Question_view_count":30,
        "Question_body":"This\u00a0github repo\u00a0demonstrates the use of mlflow in a set of Docker container with Python and R.\u00a0 This is the high-level design for the demonstration environment and software stack.",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLFlow usage and contribution",
        "Question_creation_date":"2021-10-03T10:45:51",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/pSnbo3Mvd0w",
        "Question_answer_count":0,
        "Question_view_count":38,
        "Question_body":"Hi all,\n\n\nIntertec is considering using MLFlow as the primary MLOps tool. Please let me know what are the criteria to get our logo on your site. We can also try to contribute to the product.\n\n\nKind regards\n\n\n\u00a0 \u00a0 \u00a0\nVelimir Graorkoski\nSoftware engineer\n\n\n\n\nslack\u00a0| velimir.graorkoski\n\nmail\u00a0|\u00a0velimir.g...@intertec.io\n\n\nweb\u00a0|\u00a0\u00a0https:\/\/www.intertec.io",
        "Answers":[

        ]
    },
    {
        "Question_title":"Back up experiments on a new Mlflow server",
        "Question_creation_date":"2019-12-09T12:05:01",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/Utw2OAnyW7A",
        "Question_answer_count":0,
        "Question_view_count":11,
        "Question_body":"Hi,\n\n\nI am just wondering if there is a clean way to backup experiment(s) from one Mlflow server to another?\n\n\ncheers,\nAmin",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLflow model deployment as spark transform in a spark java job",
        "Question_creation_date":"2021-09-16T02:11:42",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/zTot8BDmGOA",
        "Question_answer_count":0,
        "Question_view_count":14,
        "Question_body":"Hi everyone,\nIs there a method which i can use to convert the mlflow model as spark UDF which i can use in spark java job? if Yes please help me with the approach to achieve it. If No is there any Workaround using which I can achieve it.\n\n\n\n\nThanks & Regards,\nSujay",
        "Answers":[

        ]
    },
    {
        "Question_title":"I'm presenting 'HIPAA Compliance for AI Data Using InfinStor MLflow' tomorrow at 11 AM Pacific",
        "Question_creation_date":"2022-07-26T15:52:04",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/CJBo2p1jddc",
        "Question_answer_count":0,
        "Question_view_count":4,
        "Question_body":"If this topic is of interest to you, please sign up at the following link:\n\n\nhttps:\/\/us06web.zoom.us\/webinar\/register\/2316563487439\/WN_etMx8m8oR--VhQBRmzuCfg\n\n\nWe look forward to exchanging ideas with you tomorrow.\n\nBest\nJagane",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLflow 1.10 released!",
        "Question_creation_date":"2020-07-22T15:18:14",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/XiJyetdLrdg",
        "Question_answer_count":0,
        "Question_view_count":22,
        "Question_body":"Hi all,\n\nWe are happy to announce the availability of\u00a0MLflow 1.10.0!\n\nIn addition to bug and documentation fixes, MLflow 1.10.0 includes the following features and improvements:\n\nMlflowClient.transition_model_version_stage\u00a0now supports an\narchive_existing_versions\u00a0argument for archiving existing staging or production model\nversions when transitioning a new model version to staging or production (#3095,\u00a0@harupy)\nAdded\u00a0set_registry_uri,\u00a0get_registry_uri\u00a0APIs. Setting the model registry URI causes\nfluent APIs like\u00a0mlflow.register_model\u00a0to communicate with the model registry at the specified\nURI (#3072,\u00a0@sueann)\nAdded paginated\u00a0MlflowClient.search_registered_models\u00a0API (#2939,\u00a0#3023,\u00a0#3027\u00a0@ankitmathur-db;\u00a0#2966,\u00a0@mparkhe)\nAdded syntax highlighting when viewing text files (YAML etc) in the MLflow runs UI (#3041,\u00a0@harupy)\n\nFor a comprehensive list of changes, see the\u00a0release change log.\u00a0The latest documentation will be available soon on mlflow.org\n\nThanks!\nSid",
        "Answers":[

        ]
    },
    {
        "Question_title":"What are the advantages of Database usage vs. file based storage with MLflow?",
        "Question_creation_date":"2020-03-11T16:47:09",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/ubaYYaDROns",
        "Question_answer_count":3,
        "Question_view_count":37,
        "Question_body":"Hi,\nwhat are the advantages of database usage vs. file based storage with MLflow?\nIs the DB faster on large experiments?\nI mean backup for example would be easier when it is all files. Artifacts and other data.\nThanks\nPhilip",
        "Answers":[
            {
                "Answer_creation_time":"2020-03-11T18:12:22",
                "Answer_body":"Philip,\n\n\nConsider the scale and performance. If you have hundreds and thousands of experiments and runs, each with many artifacts and metrics and parameters, those MLflow\nentities map to distinct directories and files. On a local file system that can be problematic and degrading for intensive file-based operations. Plus, on UNIX based\nsystems you may hit file descriptors limit.\n\n\nThough back up might just be as easy copying directories and files,\u00a0 arguably, you can dump or export DB tables too,\u00a0\n\n\n\nCheers\nJules\n\n\n\n\n\n\u2013\u2013\n\nThe Best Ideas are Simple\n\nJules S. Damji\n\nDeveloper Advocate\n\nDatabricks, Inc.\n\nju...@databricks.com\n\n(510) 304-7686\n\n\n\n\n\n\n\n\n\n\n\u00a0\u00a0\u00a0\n\n\n\n\n\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/d0eb3c31-500d-4ef1-9386-7810fff0e63d%40googlegroups.com."
            },
            {
                "Answer_creation_time":"2020-03-11T18:16:07",
                "Answer_body":"In addition, if you plan to use Model Registry, it isn't supported by the file based storage.\n\n\n\ue5d3\n\ue5d3\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/CAG0FyUbU7_FD%2BPnDjcR4O1nbVQmdEjgWnPkHipytYWS5EzUdyw%40mail.gmail.com."
            },
            {
                "Answer_creation_time":"2020-03-11T18:20:13",
                "Answer_body":"Ok. Many thanks.\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow...@googlegroups.com.\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"MLflow 1.3 released!",
        "Question_creation_date":"2019-10-01T13:01:46",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/GjvwSSCX_e4",
        "Question_answer_count":0,
        "Question_view_count":9,
        "Question_body":"Hi all, MLflow 1.3 has been released! In addition to bug and documentation fixes, MLflow 1.3.0 includes several major features and improvements - to mention a few:\n\n* The Python client now supports logging & loading models using TensorFlow 2.0\n* Significant performance improvements when fetching runs and experiments in MLflow servers that use SQL database-backed storage\n* New `GetExperimentByName` REST API endpoint, used in the Python client to speed up `set_experiment` and `get_experiment_by_name`\n* New `mlflow.delete_run`, `mlflow.delete_experiment` fluent APIs in the Python client\n* New CLI command (`mlflow experiments csv`) to export runs of an experiment into a CSV\n\nSee the CHANGELOG for details about the new features:\nhttps:\/\/github.com\/mlflow\/mlflow\/releases\/tag\/v1.3.0\n\n\n\nThanks,\nSid",
        "Answers":[

        ]
    },
    {
        "Question_title":"Organizations using MLflow - Cabify",
        "Question_creation_date":"2022-06-23T09:45:19",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/Ji1EvN2DRGk",
        "Question_answer_count":0,
        "Question_view_count":25,
        "Question_body":"Hey there,\n\nAt Cabify, we use MLflow since 2019 as part of our in-house ML platform named Lykeion. It has brought a lot of good things.\n\nWe would love to appear in the website as a company using MLflow. Please find attached our logo. \ud83d\ude00\n\nThanks,",
        "Answers":[

        ]
    },
    {
        "Question_title":"[RFC][Breaking] Runs URI for specifying artifact locations",
        "Question_creation_date":"2019-04-17T01:52:58",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/59srnQ6Cjsk",
        "Question_answer_count":0,
        "Question_view_count":11,
        "Question_body":"The proposal is described in more detail in this Google Document. Please use comments in the google doc to give feedback. Thank you!\n\n\n\n\n\nTL;DR \u00a0We propose a new runs:\/ URI scheme to represent artifact locations associated with a Run. This allows us to:\n\nClean up artifact APIs where the Run ID is optional by replacing the run_id and artifact_path arguments with a single artifact_uri argument, unifying the representation of the artifact location in such APIs. \n\nRefer to artifacts by Run in places where currently only URIs are allowed; for example, for specifying artifact dependencies in Projects or pyfunc models.\n\n\n\n\nProposed Changes\n\n\n\n\nThe representation and support for artifact locations in MLflow is varied:\n\nIn most MLflow APIs, namely those in Tracking, the artifact location is represented as a tuple of (run_id,\n artifact_path = relative path with respect to the Run\u2019s base artifact URI).\n\nIn a few places the location is an absolute URI such as s3:\/\/<bucket>\/path\/to\/file.\n\nSome APIs take both representations, where artifact_path is relative if run_id is specified, and absolute otherwise. For absolute URIs, some such APIs support remote URIs (e.g. S3), and some only support local paths.\n\n\n\n\nTo unify the representation of artifact locations, we propose that for user-facing APIs in components outside of MLflow Tracking, such as MLflow Models, the artifact location be specified as a single URI argument:\n\n\n\n\nIn the scope of MLflow Tracking, there is always a contextual Run ID whenever we work with an artifact, and in the fluent APIs the user need not know the Run ID. The current API is convenient as the user doesn\u2019t need to think about the Run ID in most places.\n\n\n\n\nOutside of Tracking, artifacts and models may or may not be associated with an MLflow Tracking Run. It is in the philosophy of MLflow for the different components to be stand-alone, allowing the user to only use the components they want.\n\n\n\n\nThis means in the changed APIs,\n\n\n\n\nIf an artifact has no Run association, the user can give the absolute URI of the artifact location.\n\nIf the artifact has a Run associated, it is convenient to be able to specify the (Run ID, relative path) tuple (assuming there is a tracking server available in the context) instead of the underlying absolute path that has to be carefully constructed from the Run\u2019s RunInfo and the relative path. To support this Run ID short-cut while keeping the APIs succinct, we propose an absolute URI format:\n\n\t\n\nruns:\/<run_id>\/<relative_path>\n\n\n\n\nNote that affected APIs are all reading artifacts as they are in the Models component. To make the implementation simple, we can expand the scope of data.download_uri to support all URI types including runs:\/; then data.download_uri also becomes a full-functional utility method to download files from any artifact store backed by an Artifact Repository.\n\n\n\n\nBreaking Changes\n\n\n\n\nMany of the APIs proposed to be changed will lose the run_id argument and have the artifact_path argument renamed to artifact_uri. This means any usage of the said APIs specifying the run_id argument (which defaults to None) or using the artifact_path argument by name will break.\n\n\n\n\nThe most notable APIs to be affected are:\n\n<model-type>.load_model\n\npyfunc.load_pyfunc\n\npyfunc.spark_udf\n\nas they may already be used in deployments in production.\n\n\n\n\nFor the list of all APIs that would be affected, please see the google doc.\n\n\n\n\nRequest for Comment\n\n\nAgain, the full RFC is available in this Google Document. Please use comments in the Google Doc to give feedback. Thank you!\n\n\n\n\n\n\n--\n\n\n\n\nSue Ann Hong\n\n\nSoftware Engineer - Machine Learning\n\nDatabricks, Inc.",
        "Answers":[

        ]
    },
    {
        "Question_title":"pattern for ML model versioning?",
        "Question_creation_date":"2019-09-04T18:48:26",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/d2g7oAa6Hy4",
        "Question_answer_count":1,
        "Question_view_count":46,
        "Question_body":"Hi,\n\n\nIs there a standard pattern for tracking different versions of a model in mlflow?\n\n\nIdeally, I would like to use a model id and version to determine a mlflow URI that can be used to load that model.\u00a0\n\n\nI could use mlflow tags, but tags wouldn't enforce version uniqueness for a given model id.\n\n\nrun_id can't really be used as a version number as a model run can be resumed from an existing run_id.\n\n\nThanks for any pointers.",
        "Answers":[
            {
                "Answer_creation_time":"2019-09-12T18:35:57",
                "Answer_body":"This is a great question, Sam. We\u2019re actually working on a Model Registry API that will help with this (see a quick demo here: https:\/\/youtu.be\/QJW_kkRWAUs?t=1391) but in the meantime, you can try one of the following methods:\n\n\n- Copy the models to another storage system, such as Git, and use versioning there. Each MLflow Model is just a directory and it includes a link to the run ID that produced it, so you can always follow that to go back to the run. We\u2019ve seen people placing the models in Git or just in a shared storage system like S3, where they assign them version numbers and make sure not to modify them.\n\n\n- Use run IDs but ask people not to resume the runs. It\u2019s pretty uncommon to resume a run, but that behavior is supported in case you have a long training job that can restart from a checkpoint on failure.\n\n\nHope this helps,\n\n\n\nMatei\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/9eead3fb-8a55-4fbf-889d-c298434ae313%40googlegroups.com."
            }
        ]
    },
    {
        "Question_title":"Facing Problems in mlflow deployment on windows server",
        "Question_creation_date":"2019-09-19T02:43:09",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/lovl7Ns6x0Y",
        "Question_answer_count":3,
        "Question_view_count":7,
        "Question_body":"I am new to mlflow and finding its windows deployment extremely challenging. Has anyone been able to successfully deploy models with mlflow on windows machine ??",
        "Answers":[
            {
                "Answer_creation_time":"2019-09-20T06:19:56",
                "Answer_body":"Maybe you can use docker container .\n\n\nOn Thu, 19 Sep 2019, 12:13 babar ali, <bac...@gmail.com> wrote:\n\nI am new to mlflow and finding its windows deployment extremely challenging. Has anyone been able to successfully deploy models with mlflow on windows machine ??\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/5e8a0cee-7833-48d3-9fed-a61c3db8c349%40googlegroups.com."
            },
            {
                "Answer_creation_time":"2019-09-20T12:45:11",
                "Answer_body":"Hi Babar.\u00a0\n\n\nUnfortunately mlflow windows support is limited to experiment tracking for now (we would appreciate contributions).\n\ue5d3"
            },
            {
                "Answer_creation_time":"2019-09-22T19:27:11",
                "Answer_body":"Just to add to that, you may want to consider Docker on Windows as a way to run the packaged models. MLflow provides a command to package models as a Docker container already. The simple built-in model server in mlflow serve is not designed to run on Windows right now.\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\n\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/2c536152-711c-4be5-b79b-45530411ac14%40googlegroups.com."
            }
        ]
    },
    {
        "Question_title":"ADFS Authentication to MLflow",
        "Question_creation_date":"2020-10-19T15:44:06",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/l3udtZwwdbU",
        "Question_answer_count":1,
        "Question_view_count":95,
        "Question_body":"Hi all,\u00a0\n\n\nI was just wondering if there is any simpler way to apply Authentication to mlflow dashboards using active directory apart from nginx,\u00a0 or if any plugin is available to serve the purpose.\u00a0\n\n\nThanks\nIsha",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-19T14:39:56",
                "Answer_body":"I would like know it too.\nAt this moment I'm trying to user oauth2_proxy with Nginx.\nhttps:\/\/github.com\/bitly\/oauth2_proxy.\n\n\nlamba.isha12 do you use something like that?\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"[ANNOUNCEMENT] CFP for Data + AI Conference",
        "Question_creation_date":"2021-02-05T14:55:07",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/SrwmTCHd4vw",
        "Question_answer_count":0,
        "Question_view_count":11,
        "Question_body":"MLflow users:\n\n\nWe accept CfP on MLflow for this conference: how you use it in production; use MLOps best practices; with popular ML frameworks for experiment tracking; integrations and extensions with MLflow; and the model registry\u00a0for discovering, sharing, and deploying models, etc.\u00a0\n\n\nShare your bright ideas with the larger data community on how MLflow helps you manage your model lifecycle.\n\n\nhttps:\/\/databricks.com\/dataaisummit\/north-america-2021\/call-for-presentations\n\n\n\nCheers\nJules\n\n\n\n\n\u2013\u2013\n\nThe Best Ideas are Simple\n\nJules S. Damji\n\nSr. Developer Advocate\n\nDatabricks, Inc.\n\nju...@databricks.com\n\n(510) 304-7686",
        "Answers":[

        ]
    },
    {
        "Question_title":"windows compatibility",
        "Question_creation_date":"2019-07-10T21:33:05",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/mNJwqIkvMR8",
        "Question_answer_count":1,
        "Question_view_count":8,
        "Question_body":"Hello,\n\n\nI am not sure if this is the right place to ask this:\nI have seen the PR of the mlflow which replaces Gunicorn by Waitress has been approved and merged in master, but when will this versioned released on Pypi?\n\n\nThanks a lot!",
        "Answers":[
            {
                "Answer_creation_time":"2019-07-14T13:39:37",
                "Answer_body":"It will be in the next release (1.1), which should hopefully come in the next 1-2 weeks. You can also build an installable version of MLflow from the Git version as described here if you want to use that:\u00a0https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/CONTRIBUTING.rst#building-a-distributable-artifact.\n\n\nMatei\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/c27fe5b9-ba0b-4843-985d-8edce9acdf1e%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            }
        ]
    },
    {
        "Question_title":"Failed to call Java API: MlflowClient.listArtifacts in docker",
        "Question_creation_date":"2019-06-09T23:34:03",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/SrdkbCtKmgs",
        "Question_answer_count":2,
        "Question_view_count":11,
        "Question_body":"HI,\n\n\nmy Dockerfile as follows:\n\n\nFROM python:3.6\n\nENV MLFLOW_VERSION 0.8.2\n\nWORKDIR \/\nRUN apt-get update \\\n   && apt-get install -y ca-certificates wget openjdk-8-jdk\n\nRUN pip install mlflow==${MLFLOW_VERSION}\n\nRUN wget -O dd-java-agent.jar \\\n         'https:\/\/search.maven.org\/classic\/remote_content?g=com.datadoghq&a=dd-java-agent&v=LATEST'\n\n\nCOPY target\/xxxxxx.jar app.jar\nCOPY pipeline\/ci\/entrypoint.sh .\nCOPY pipeline\/ci\/sysctl.conf \/etc\/sysctl.d\/00-alpine.conf\n\nRUN chmod +x entrypoint.sh\n\nEXPOSE 8080\nENTRYPOINT [\"\/entrypoint.sh\"]\n\n\nmlflow is deployed in localhost outer docker\nartifact storage is s3 implemented by minio in localhost\n\n\nAfter started docker container, MlflowClient.listArtifacts is called by my own rest API, but it failed\n\n\n\n[http-nio-8080-exec-9] - [ERROR] - [com.xxx.dsd.aop.ApiExceptionHandler.internalErrorHandler(line:26)] - org.mlflow.tracking.MlflowClientException: Failed to exec 'python -m mlflow.cli', needed to access artifacts within the non-Java-native artifact store at 's3:\/\/mlflow\/artifacts\/1\/a34faddc96a544ce8e41f6049189a351\/artifacts'. Please make sure mlflow is available on your local system path (e.g., from 'pip install mlflow')\n\nat org.mlflow.artifacts.CliBasedArtifactRepository.checkMlflowAccessible(CliBasedArtifactRepository.java:181)\n\nat org.mlflow.artifacts.CliBasedArtifactRepository.listArtifacts(CliBasedArtifactRepository.java:127)\n\nat org.mlflow.artifacts.CliBasedArtifactRepository.listArtifacts(CliBasedArtifactRepository.java:137)\n\nat org.mlflow.tracking.MlflowClient.listArtifacts(MlflowClient.java:438)\n\nat com.rakuten.dsd.service.ModelService.getArtifacts(ModelService.java:97)\n\nat com.rakuten.dsd.controller.ModelController.getArtifacts(ModelController.java:117)\n\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\nat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\nat java.lang.reflect.Method.invoke(Method.java:498)\n\nat org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:209)\n\nat org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:136)\n\nat org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:102)\n\nat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:870)\n\nat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:776)\n\nat org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)\n\nat org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:991)\n\nat org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:925)\n\nat org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:978)\n\nat org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:870)\n\nat javax.servlet.http.HttpServlet.service(HttpServlet.java:635)\n\nat org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:855)\n\nat javax.servlet.http.HttpServlet.service(HttpServlet.java:742)\n\nat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)\n\nat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n\nat org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)\n\nat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n\nat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n\nat org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:158)\n\nat org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.filterAndRecordMetrics(WebMvcMetricsFilter.java:126)\n\nat org.springframework.boot.actuate.metrics.web.servlet.WebMvcMetricsFilter.doFilterInternal(WebMvcMetricsFilter.java:111)\n\nat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n\nat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n\nat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n\nat org.springframework.boot.actuate.web.trace.servlet.HttpTraceFilter.doFilterInternal(HttpTraceFilter.java:84)\n\nat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n\nat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n\nat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n\nat org.springframework.web.filter.CorsFilter.doFilterInternal(CorsFilter.java:96)\n\nat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n\nat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n\nat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n\nat org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:200)\n\nat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n\nat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n\nat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n\nat org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:199)\n\nat org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)\n\nat org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:496)\n\nat org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)\n\nat org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:81)\n\nat org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)\n\nat org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)\n\nat org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:803)\n\nat org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)\n\nat org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790)\n\nat org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1459)\n\nat org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)\n\nat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\nat org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)\n\nat java.lang.Thread.run(Thread.java:748)\n\nCaused by: org.mlflow.tracking.MlflowClientException: Failed to get mlflow version. Error: Traceback (most recent call last):\n\n\u00a0 File \"\/usr\/local\/lib\/python3.6\/runpy.py\", line 193, in _run_module_as_main\n\n\u00a0 \u00a0 \"__main__\", mod_spec)\n\n\u00a0 File \"\/usr\/local\/lib\/python3.6\/runpy.py\", line 85, in _run_code\n\n\u00a0 \u00a0 exec(code, run_globals)\n\n\u00a0 File \"\/usr\/local\/lib\/python3.6\/site-packages\/mlflow\/cli.py\", line 223, in <module>\n\n\u00a0 \u00a0 cli()\n\n\u00a0 File \"\/usr\/local\/lib\/python3.6\/site-packages\/click\/core.py\", line 764, in __call__\n\n\u00a0 \u00a0 return self.main(*args, **kwargs)\n\n\u00a0 File \"\/usr\/local\/lib\/python3.6\/site-packages\/click\/core.py\", line 696, in main\n\n\u00a0 \u00a0 _verify_python3_env()\n\n\u00a0 File \"\/usr\/local\/lib\/python3.6\/site-packages\/click\/_unicodefun.py\", line 124, in _verify_python3_env\n\n\u00a0 \u00a0 ' mitigation steps.' + extra\n\nRuntimeError: Click will abort further execution because Python 3 was configured to use ASCII as encoding for the environment. Consult https:\/\/click.palletsprojects.com\/en\/7.x\/python3\/ for mitigation steps.\n\n\n\n\nThis system supports the C.UTF-8 locale which is recommended.\n\nYou might be able to resolve your issue by exporting the\n\nfollowing environment variables:\n\n\n\n\n\u00a0 \u00a0 export LC_ALL=C.UTF-8\n\n\u00a0 \u00a0 export LANG=C.UTF-8\n\n\n\n\nat org.mlflow.artifacts.CliBasedArtifactRepository.forkMlflowProcess(CliBasedArtifactRepository.java:209)\n\nat org.mlflow.artifacts.CliBasedArtifactRepository.checkMlflowAccessible(CliBasedArtifactRepository.java:173)\n\n... 61 more\n\n\n\nBut, if I use 'exec' command to enter into the container, and use python API of mlflow, everything looks OK.\n\n\nSo, I'm not suer\u00a0 if there's anything wrong in my docker image or any other things wrong ?",
        "Answers":[
            {
                "Answer_creation_time":"2019-06-10T00:39:16",
                "Answer_body":"Have you tried exporting the suggested variables? Looks like the python mlflow library doesn't want to run because of that.\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/eb7d29ff-f103-467d-bee6-40370812e7b7%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            },
            {
                "Answer_creation_time":"2019-06-10T01:43:46",
                "Answer_body":"Thanks for replying, I've tried that, but didn't work.\n\n\nI 've tried to enter into the running container\ndocker exec -it mlflow-container-name sh\n\n\nthen use python API, like\u00a0\nmlflow.tracking.MlflowClient.list_experiment\n\nand this works.\n\n\nand I also tried \"python -m mlflow.cli --help\" just like the error message showed, and it works too.\n\n\nso I'm confused.\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow...@googlegroups.com.\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"[Python] MLflow 0.9.0.1 released",
        "Question_creation_date":"2019-04-09T22:35:36",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/OVyxnXd0Jac",
        "Question_answer_count":0,
        "Question_view_count":11,
        "Question_body":"Hi all,\n\n\nWe've released an updated MLflow Python package (MLflow 0.9.0.1) on PyPI, which fixes an issue raised in https:\/\/github.com\/mlflow\/mlflow\/issues\/1113 & https:\/\/github.com\/mlflow\/mlflow\/issues\/1056 where form input (e.g. searching runs) was broken in the MLflow 0.9.0 UI.\n\n\nYou can upgrade to the new version via \"pip install --upgrade mlflow\".\n\nThanks,\nSid",
        "Answers":[

        ]
    },
    {
        "Question_title":"Spark-related tests are failing",
        "Question_creation_date":"2019-03-27T17:54:49",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/BgU1p2juiBo",
        "Question_answer_count":3,
        "Question_view_count":19,
        "Question_body":"Hi all,\n\n\nI'm trying to set up the dev environment for contributing to MLflow. I followed the instructions\u00a0here but I have some issues running the tests.\u00a0\nI am using pytest and see that 9 tests fail. Most of them are part of the:\u00a0tests\/spark\/test_spark_model_export.py file. The error description is the following:\n\n\ntests\/spark\/test_spark_model_export.py:61:\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n..\/anaconda2\/lib\/python2.7\/site-packages\/pyspark\/context.py:115: in __init__\n\u00a0\u00a0\u00a0 SparkContext._ensure_initialized(self, gateway=gateway, conf=conf)\n\n\n\u00a0ValueError: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local-cluster[2, 1, 1024]) created by getOrCreate at \/home\/mlflow\/mlflow\/tests\/pyfunc\/test_spark.py:27\n..\/anaconda2\/lib\/python2.7\/site-packages\/pyspark\/context.py:314: ValueError\n\n\n************************************************\n\n\nIt seems that the SparkContext cannot be initialized because of an existing one. Any idea what might be the problem here?\n\n\nThanks,\nAvrilia",
        "Answers":[
            {
                "Answer_creation_time":"2019-03-27T21:09:54",
                "Answer_body":"That looks like a bug in the test code - in tests\/spark\/test_spark_model_export.py:61\u00a0we call the pyspark.SparkContext constructor directly so the getOrCreate is moot (we'll always try to create a SparkContext). For now you should be able to get around this by changing:\n\n\n\u00a0 sc = pyspark.SparkContext(master=\"local-cluster[2, 1, 1024]\", conf=conf).getOrCreate()\n\n\nto:\n\n\n\u00a0 \u00a0 spark = pyspark.sql.SparkSession.builder \\\n\u00a0 \u00a0 \u00a0 \u00a0 .config(key=\"spark.python.worker.reuse\", value=True) \\\n\u00a0 \u00a0 \u00a0 \u00a0 .config(key=\"spark.jars.packages\", value='ml.combust.mleap:mleap-spark-base_2.11:0.12.0,'\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0'ml.combust.mleap:mleap-spark_2.11:0.12.0') \\\n\u00a0 \u00a0 \u00a0 \u00a0 .master(\"local-cluster[2, 1, 1024]\") \\\n\u00a0 \u00a0 \u00a0 \u00a0 .getOrCreate()\n\u00a0 \u00a0 sc = spark.sparkContext\n\n\n\nWould also be happy to review a PR with such a change (our CI doesn't catch it because it runs Spark & Pyfunc tests separately).\n\nThanks,\nSid\n\n\n\n\n\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/b8b5ad46-e2fa-4d00-9f1c-149ba5cc8abe%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            },
            {
                "Answer_creation_time":"2019-03-28T16:45:39",
                "Answer_body":"Hi Sid,\n\n\nThanks for your help. I made the change but it seems it breaks sth else and I get more tests failing now. I am debugging it and will get back to you. I'd be happy to submit a PR once it is ready.\n\n\nThanks,\nAvrilia\n\ue5d3"
            },
            {
                "Answer_creation_time":"2019-03-28T20:36:15",
                "Answer_body":"Sid,\u00a0\n\n\nThanks for your help! Your suggestion is definitely addressing part of the problem but some other changes were needed as well.\n\n\nIt seems that the keras test is executed before the spark tests. The test invokes score_model_as_udf from\u00a0the\u00a0 tests\/pyfunc\/test_spark.py.\u00a0\nThe function also creates a SparkSession builder but its configuration does not include the mleap jars See below:\n\n\n\u00a0spark = pyspark.sql.SparkSession.builder \\\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 .config(key=\"spark.python.worker.reuse\", value=True) \\\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 .master(\"local-cluster[2, 1, 1024]\") \\\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 .getOrCreate()\n\n\n\n\nI had to add that config there as well so that the subsequent spark tests (with the change that you suggested) are executed successfully. I can create a PR that contains all the changes but\u00a0\nit seems to me that the SparkConf should get automatically updated when the spark tests are executed. Is this the expected behavior or there is some bug in pyspark.sql.SparkSession that does not allow config updates?\u00a0\n\n\nAvrilia\n\n\nOn Wednesday, March 27, 2019 at 2:54:49 PM UTC-7, Avrilia Floratou wrote:\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"Organizations using MLflow - Emerton Data",
        "Question_creation_date":"2020-06-27T15:30:17",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/9WHVX1YBK_A",
        "Question_answer_count":1,
        "Question_view_count":30,
        "Question_body":"Hi !\n\n\nAt Emerton Data, we are big fans of MLflow and are using it in our project to industrialize AI models and data projects.\n\n\nHappy to be one of the mlflow supporter and would be glad to appear on your website as an organization using MLFlow.\u00a0\n\n\nCheers,\n\n\n\nYannick LEO\nDirector Data Science\n\n16 avenue Hoche\u00a0\u00a0\n75008 Paris\u00a0\nM + 33 6 38 21 33 99\nT + 33 1 53 75 38 75\nyanni...@emerton-data.com\u00a0|\u00a0http:\/\/www.emerton-data.com",
        "Answers":[
            {
                "Answer_creation_time":"2020-06-27T17:33:39",
                "Answer_body":"Hello Yannick,\n\n\nWe will be happy to include you as supporters and users of mlflow.\u00a0\n\n\nCan you send me your preferred logo? We will include in the list.\n\n\nThanks for being a fan and supporter of MLflow.\n\n\nCheers\nJules\u00a0\n\n\nSent from my iPhone\nPardon the dumb thumb typos :)\n\n\nOn Jun 27, 2020, at 12:32 PM, Yannick Leo <yanni...@emerton-data.com> wrote:\n\n\n\ufeffHi !\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/a52afb80-ce39-4985-8e13-ef601a2d4edfn%40googlegroups.com."
            }
        ]
    },
    {
        "Question_title":"mlflow load_model - no host supplied",
        "Question_creation_date":"2022-09-16T10:38:29",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/jHikb5beQ9I",
        "Question_answer_count":0,
        "Question_view_count":5,
        "Question_body":"In the below image, I mention tracking URI and trying to load the model but facing an error in no host supplied.",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLFlow 1.29.0 release",
        "Question_creation_date":"2022-09-19T10:42:47",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/RJYpm6WZZQc",
        "Question_answer_count":0,
        "Question_view_count":31,
        "Question_body":"We are happy to announce the availability of MLflow 1.29.0!\n\nMLflow 1.29.0 includes several major features and improvements:\n\nFeatures:\n[Pipelines] Improve performance and fidelity of dataset profiling in the scikit-learn regression Pipeline (#6792, @sunishsheth2009)\n[Pipelines] Add an mlflow pipelines get-artifact CLI for retrieving Pipeline artifacts (#6517, @prithvikannan)\n[Pipelines] Introduce an option for skipping dataset profiling to the scikit-learn regression Pipeline (#6456, @apurva-koti)\n[Pipelines \/ UI] Display an mlflow pipelines CLI command for reproducing a Pipeline run in the MLflow UI (#6376, @hubertzub-db)\n[Tracking] Automatically generate friendly names for Runs if not supplied by the user (#6736, @BenWilson2)\n[Tracking] Add load_text(), load_image() and load_dict() fluent APIs for convenient artifact loading (#6475, @subramaniam02)\n[Tracking] Add creation_time and last_update_time attributes to the Experiment class (#6756, @subramaniam02)\n[Tracking] Add official MLflow Tracking Server Dockerfiles to the MLflow repository (#6731, @oojo12)\n[Tracking] Add searchExperiments API to Java client and deprecate listExperiments (#6561, @dbczumar)\n[Tracking] Add mlflow_search_experiments API to R client and deprecate mlflow_list_experiments (#6576, @dbczumar)\n[UI] Make URLs clickable in the MLflow Tracking UI (#6526, @marijncv)\n[UI] Introduce support for csv data preview within the artifact viewer pane (#6567, @nnethery)\n[Model Registry \/ Models] Introduce mlflow.models.add_libraries_to_model() API for adding libraries to an MLflow Model (#6586, @arjundc-db)\n[Models] Add model validation support to mlflow.evaluate() (#6582, @jerrylian-db)\n[Models] Introduce sample_weights support to mlflow.evaluate() (#6806, @dbczumar)\n[Models] Add pos_label support to mlflow.evaluate() for identifying the positive class (#6696, @harupy)\n[Models] Make the metric name prefix and dataset info configurable in mlflow.evaluate() (#6593, @dbczumar)\n[Models] Add utility for validating the compatibility of a dataset with a model signature (#6494, @serena-ruan)\n[Models] Add predict_proba() support to the pyfunc representation of scikit-learn models (#6631, @skylarbpayne)\n[Models] Add support for Decimal type inference to MLflow Model schemas (#6600, @shitaoli-db)\n[Models] Add new CLI command for generating Dockerfiles for model serving (#6591, @anuarkaliyev23)\n[Scoring] Add \/health endpoint to scoring server (#6574, @gabriel-milan)\n[Scoring] Support specifying a variant_name during Sagemaker deployment (#6486, @nfarley-soaren)\n[Scoring] Support specifying a data_capture_config during SageMaker deployment (#6423, @jonwiggins)\nBug fixes:\n[Tracking] Make Run and Experiment deletion and restoration idempotent (#6641, @dbczumar)\n[UI] Fix an alignment bug affecting the Experiments list in the MLflow UI (#6569, @sunishsheth2009)\n[Models] Fix a regression in the directory path structure of logged Spark Models that occurred in MLflow 1.28.0 (#6683, @gwy1995)\n[Models] No longer reload the __main__ module when loading model code (#6647, @Jooakim)\n[Artifacts] Fix an mlflow server compatibility issue with HDFS when running in --serve-artifacts mode (#6482, @shidianshifen)\n[Scoring] Fix an inference failure with 1-dimensional tensor inputs in TensorFlow and Keras (#6796, @LiamConnell)\nDocumentation updates:\n[Tracking] Mark the SearchExperiments API as stable (#6551, @dbczumar)\n[Tracking \/ Model Registry] Deprecate the ListExperiments, ListRegisteredModels, and list_run_infos() APIs (#6550, @dbczumar)\n[Scoring] Deprecate mlflow.sagemaker.deploy() in favor of SageMakerDeploymentClient.create() (#6651, @dbczumar)\n\n\nFor a comprehensive list of changes, see the\u00a0release change log, and check out the latest documentation on\u00a0mlflow.org.",
        "Answers":[

        ]
    },
    {
        "Question_title":"Model Branching",
        "Question_creation_date":"2021-05-17T11:42:20",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/W3FwEcd31VI",
        "Question_answer_count":1,
        "Question_view_count":16,
        "Question_body":"I am wondering if anyone here explored idea of tracking model branching in GIT branching sense.\n\n\n\n\nI.e.\u00a0 as model is been worked on and modified\/updated\/retrained it gets different versioning, but then someone decided to \"extend\" model to say adopt model for similar data.\u00a0 At this point we can \"branch\" model and keep versioning of each branch separate.",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-17T12:00:47",
                "Answer_body":"Vadim,\n\n\nNot that I know\u00a0of but post this on the MLflow slack channel; model registry keeps track of each version per run but not in the sense of\nbranching as Git.\n\n\nCheers\nJules\n\n\n\n\n\n\n\u2013\u2013\n\nThe Best Ideas are Simple\n\nJules S. Damji\n\nSr. Developer Advocate\n\nDatabricks, Inc.\n\nju...@databricks.com\n\n(510) 304-7686\n\n\n\n\n\n\n\n\n\n\n\u00a0\u00a0\u00a0\n\n\n\n\n\n\n\n\nOn Mon, May 17, 2021 at 8:42 AM 'Vadim Kutsyy' via mlflow-users <mlflow...@googlegroups.com> wrote:\n\n\nI am wondering if anyone here explored idea of tracking model branching in GIT branching sense.\n\n\n\n\nI.e.\u00a0 as model is been worked on and modified\/updated\/retrained it gets different versioning, but then someone decided to \"extend\" model to say adopt model for similar data.\u00a0 At this point we can \"branch\" model and keep versioning of each branch separate.\n\n\n\n\n\u00a0\n\n\n\n\n\u00a0\n\n\n\n\n\u00a0\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/a4083de3-88b3-44a1-a836-28d525ff88dan%40googlegroups.com."
            }
        ]
    },
    {
        "Question_title":"Organizations using MLFlow and Integrations",
        "Question_creation_date":"2021-05-23T17:57:57",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/j9vx2xoFfxA",
        "Question_answer_count":1,
        "Question_view_count":31,
        "Question_body":"Hello,\n\n\nAt Composable Analytics (https:\/\/composable.ai) we develop an end-to-end DataOps Platform that has direct integrations with MLFlow. Further, we are enabling our customers in using MLFlow as their in house ML platform.\n\n\nCan you please add Composable's logo in both Integrations and Organizations on the main site? Logo attached.\n\n\nBest,\nAndy",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-24T11:12:55",
                "Answer_body":"Thanks Andy for using MLflow and enabling your customers to using MLflow. I\u2019ll add your logo to the website and will be pushed as part of our next release.\u00a0\n\n\nWill follow up later after this week to understand your use and how your customers use MLflow.\u00a0\n\n\nCheers\u00a0\nJules\u00a0\n\n\nCheers\nJules\u00a0\n\n\nSent from my iPhone\nPardon the dumb thumb typos :)\n\n\nOn May 23, 2021, at 2:57 PM, Andy Vidan <andy...@gmail.com> wrote:\n\n\n\ufeffHello,\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/0bd529a2-ad22-49b3-bcc0-52cb5f28f2een%40googlegroups.com.\n\n<ComposableLogo.png>"
            }
        ]
    },
    {
        "Question_title":"java api serve model",
        "Question_creation_date":"2020-05-07T04:06:21",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/Cl2cPlQhy98",
        "Question_answer_count":0,
        "Question_view_count":19,
        "Question_body":"Hey. is there a possibility to serve a model with java api",
        "Answers":[

        ]
    },
    {
        "Question_title":"Does MLFLOW supports CNNs ike yolo and unet running on NVIDIA tao platform",
        "Question_creation_date":"2022-09-18T03:07:04",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/BjkpwrXLXPM",
        "Question_answer_count":0,
        "Question_view_count":18,
        "Question_body":"Hi, we are a company working in the field of computer vision and would like to make sure that the MLFLOW experiment management platform fits our needs and workflow.\n\nWe work with image processing\u00a0 CNNs like Yolo, UNET, and RetinaNet based on an NVIDIA TAO framework.\u00a0\n\nWhat we actually need is a tool that concentrates on one place (in a nice and representative way comfortable for comparison) at least the three following things for each experiment:\n\n\na- chosen by user typical meta parameters that were used to train a network (such as batches, subdivisions, max batches, etc)\n\nb- a link to the dataset the network was trained on, located on our cloud storage (such as one-drive, google drive or google cloud) or a list of filenames or a link to a file storage cloud or online drive suggested by your service if there is such a thing.\n\nc- a result of running the trained network - the number of detected objects\n\nThank you very much",
        "Answers":[

        ]
    },
    {
        "Question_title":"Organization - NetObjex uses MLFlow",
        "Question_creation_date":"2021-03-02T00:36:34",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/oqewetS7cuY",
        "Question_answer_count":0,
        "Question_view_count":18,
        "Question_body":"Attached is our logo\nhttp:\/\/www.netobjex.com",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLflow 1.0 released!",
        "Question_creation_date":"2019-06-06T13:30:16",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/4N9tJToclI0",
        "Question_answer_count":0,
        "Question_view_count":12,
        "Question_body":"MLflow 1.0 has been released! In addition to some exciting new features (much-improved metric visualizations, metric X coordinates, improved search functionality and HDFS support), MLflow 1.0 offers Python, Java, R, and REST API stability. Note that in order to stabilize the APIs, we had to make several breaking changes.\n\nSee the CHANGELOG for details about the new features and breaking changes, and see the blog post for some examples of these features in action!",
        "Answers":[

        ]
    },
    {
        "Question_title":"How to either memorize column selection, or use sql to query mlflow?",
        "Question_creation_date":"2020-11-13T20:48:50",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/ZOzitFyJHaA",
        "Question_answer_count":1,
        "Question_view_count":9,
        "Question_body":"MLFlow looks super nice :)\n\n\nI have a lot of parameters and metrics (like dozens of each), and they won't all fit on the main mlflow page, that shows the list of experiments. I'd like to only show a subset. Now I can do this by clicking on 'columns' and choosing them, but every time I refresh the page or similar, I have to re-select the columns, which takes ~minutes each time.\n\n\nI'd like to be able to do one of the following things ideally:\n1. somehow save, memorize, persist, the choice of columns. Happy to use a bookmarklet for this, though I'm not clear how to write one, or\n2. have a sql interface for this page, so in the sql i will choose the values\/columns I want to display. i can then just copy\/paste the sql to a plain-text file somewhere, and just paste it back in after loading the page.\n\n\nIs there something I need to change to my workflow so that I don't face this issue with having to reselect the columns? Alternatively, is there some way to achieve either of the options 1 or 2 above? Or is there some way for me to achieve my high-level goal of only showing specific columns, and choosing those relatively quickly (currently takes minutes, because have to open columns, unslelect everything, then scroll down the lloonnng list of paramters and metrics).\n\n\nHugh",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-14T04:31:42",
                "Answer_body":"Good point. I created a FR because I am also interested in having this:\nhttps:\/\/github.com\/mlflow\/mlflow\/issues\/3692\n\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"Evaluating MLFlow on Kubernetes",
        "Question_creation_date":"2018-08-22T15:33:06",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/vx1uqw2GsFk",
        "Question_answer_count":1,
        "Question_view_count":411,
        "Question_body":"Hi,\n\n\nI meet Matei and Mani during spark summit. We are currently evaluating MLFlow on Kubernetes and had some questions about it.\u00a0\n\n\nScenario: We have MLFlow Tracking server deployed in Kubernetes we also have a Jupyter notebook to run MLFlow Training.\u00a0\n\n\nHowever, if we don't provide s3 credentials in Jupyter Notebook container it sends an error. Is it required for both Jupyter Notebook and MLFlow Tracking Server to have s3 credentials in the container?\u00a0\n\n\nApache Spark allows for us to specify an non s3 endpoint other than aws. That way we can use systems like Ceph to store our models. Is this something that will work for MLFlow.\u00a0\n\n\n\n\nThanks,\u00a0\n\nZak Hassan\n\nEngineer - Artificial Intelligence -\u00a0 Center Of Excellence, CTO Office\nhttp:\/\/radanalytics.io\/ - Machine Learning On OpenShift",
        "Answers":[
            {
                "Answer_creation_time":"2018-08-23T15:12:05",
                "Answer_body":"Hi Zak,\n\n\nCan you describe where and how these notebooks are hosted (locally or in a container) and how are the ACLs set up to talk to container hosting MLflow tracking server? Also can you share the error you are seeing in the notebooks?\n\n\nIf you would like to open an issue on github, we can help debug that.\u00a0\n\n\nThanks.\n\n--\u00a0\n\n\nMani Parkhe\n\nma...@databricks.com\n\n\n\n\n\n\n\n\n\n\n\n\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"MLflow 1.20 released!",
        "Question_creation_date":"2021-08-25T22:51:37",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/S36kTwPILeM",
        "Question_answer_count":0,
        "Question_view_count":8,
        "Question_body":"We are happy to announce the availability of MLflow 1.20.0!\n\nNote: The MLflow R package for 1.20.0 is not yet available but will be in a week because CRAN's submission system will be offline until September 1st.\n\nIn addition to bug and documentation fixes, MLflow 1.20.0 includes the following features and improvements:\n\n- Autologging for scikit-learn now records post training metrics when scikit-learn evaluation APIs, such as `sklearn.metrics.mean_squared_error`, are called (#4491, #4628 #4638, @WeichenXu123)\n- Autologging for PySpark ML now records post training metrics when model evaluation APIs, such as `Evaluator.evaluate()`, are called (#4686, @WeichenXu123)\n- Add `pip_requirements` and `extra_pip_requirements` to `mlflow.*.log_model` and `mlflow.*.save_model` for directly specifying the pip requirements of the model to log \/ save (#4519, #4577, #4602, @harupy)\n- Added `stdMetrics` entries to the training metrics recorded during PySpark CrossValidator autologging (#4672, @WeichenXu123)\n- MLflow UI updates:\n1. Improved scalability of the parallel coordinates plot for run performance comparison,\n2. Added support for filtering runs based on their start time on the experiment page,\n3. Added a dropdown for runs table column sorting on the experiment page,\n4. Upgraded the AG Grid plugin, which is used for runs table loading on the experiment page, to version 25.0.0,\n5. Fixed a bug on the experiment page that caused the metrics section of the runs table to collapse when selecting columns from other table sections (#4712, @dbczumar)\n- Added support for distributed execution to autologging for PyTorch Lightning (#4717, @dbczumar)\n- Expanded R support for Model Registry functionality (#4527, @bramrodenburg)\n- Added model scoring server support for defining custom prediction response wrappers (#4611, @Ark-kun)\n- `mlflow.*.log_model` and `mlflow.*.save_model` now automatically infer the pip requirements of the model to log \/ save based on the current software environment (#4518, @harupy)\n- Introduced support for running Sagemaker Batch Transform jobs with MLflow Models (#4410, #4589, @YQ-Wang)\n\nFor a comprehensive list of changes, see the release change log, and check out the latest documentation on mlflow.org.",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLflow 1.11.0 released!",
        "Question_creation_date":"2020-08-31T03:41:05",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/Cf8RLtdN5A4",
        "Question_answer_count":0,
        "Question_view_count":31,
        "Question_body":"Hi all,\n\nWe are happy to announce the availability of\u00a0MLflow 1.11.0!\n\nMLflow 1.11.0 includes a number of major features and improvements, in addition to bug fixes and documentation updates:\n\nNew\u00a0mlflow.sklearn.autolog()\u00a0API for automatic logging of metrics, params, and models from scikit-learn model training (#3287,\u00a0@harupy;\u00a0#3323,\u00a0#3358\u00a0@dbczumar)\nRegistered model & model version creation APIs now support specifying an initial\u00a0description\u00a0(#3271,\u00a0@sueann)\nThe R\u00a0mlflow_log_model\u00a0and\u00a0mlflow_load_model\u00a0APIs now support XGBoost models (#3085,\u00a0@lorenzwalthert)\nNew\u00a0mlflow.list_run_infos\u00a0fluent API for listing run metadata (#3183,\u00a0@trangevi)\nAdded section for visualizing and comparing model schemas to model version and model-version-comparison UIs (#3209,\u00a0@zhidongqu-db)\nEnhanced support for using the model registry across Databricks workspaces: support for registering models to a Databricks workspace from outside the workspace (#3119,\u00a0@sueann), tracking run-lineage of these models (#3128,\u00a0#3164,\u00a0@ankitmathur-db;\u00a0#3187,\u00a0@harupy), and calling\u00a0mlflow.<flavor>.load_model\u00a0against remote Databricks model registries (#3330,\u00a0@sueann)\nUI support for setting\/deleting registered model and model version tags (#3187,\u00a0@harupy)\nUI support for archiving existing staging\/production versions of a model when transitioning a new model version to staging\/production (#3134,\u00a0@harupy)\n\nFor a comprehensive list of changes, see the\u00a0release change log, and check out the latest documentation on\u00a0mlflow.org.\n\nThanks,\nSid",
        "Answers":[

        ]
    },
    {
        "Question_title":"No module named pandas when \" mlflow run\"",
        "Question_creation_date":"2018-06-19T10:40:55",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/QnASq7ITAoI",
        "Question_answer_count":1,
        "Question_view_count":57,
        "Question_body":"Hi all,\n\u00a0\nI have pandas 0.22.0 installed in ubuntu16.04, it successfully run\u00a0python example\/tutorial\/train.py:\npython example\/tutorial\/train.py\u00a0\nElasticnet model (alpha=0.500000, l1_ratio=0.500000):\n\u00a0 RMSE: 0.82224284976\n\u00a0 MAE: 0.627876141016\n\u00a0 R2: 0.126787219728\n\n\nbut failed as below:\n\u00a0mlflow run example\/tutorial -P alpha=0.5 --no-conda\n\n=== Fetching project from example\/tutorial ===\n=== Work directory for this run: example\/tutorial ===\n=== Created directory \/tmp\/tmpigdg385u for downloading remote URIs passed to arguments of type 'path' ===\n=== Running command: python train.py 0.5 0.1 ===\nTraceback (most recent call last):\n\u00a0 File \"train.py\", line 9, in <module>\n\u00a0 \u00a0 import pandas as pd\nImportError: No module named pandas\n=== Run failed ===\n\n\n\n\ndouble checked that pandas installed:\n$ python\nPython 3.5.1+ (default, Mar 30 2016, 22:46:26)\u00a0\n[GCC 5.3.1 20160330] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import pandas as pd\n>>>\u00a0\n\n\n\n\nAny advice or work around?\n\n\nThanks,\nForest",
        "Answers":[
            {
                "Answer_creation_time":"2018-06-19T13:47:51",
                "Answer_body":"Hi Forest.\n\n\nI was not able to reproduce your issue unfortunately.\u00a0\nThe only thing that is different between the two runs is the working directory so my guess would be that your pandas is installed in a nonstandard location visible from the first directory and not visible from the second.\n\n\nTo verify, can you please try:\n\n\n```\ncd example\/tutorial\n\npython -c \"import pandas as pd; print(pd.__version__)\"\n\n```\n\n\nBest,\n\n\nTomas\n\n\n\n\n\ue5d3\n\ue5d3\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users+unsubscribe@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/2773f0ed-67bd-4cdd-aacd-a9a0448a2ac0%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            }
        ]
    },
    {
        "Question_title":"Set Github as Artifacts location",
        "Question_creation_date":"2019-06-27T14:19:09",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/QKRO33wr3hM",
        "Question_answer_count":5,
        "Question_view_count":20,
        "Question_body":"Im testing MLFLOW 1.0.0. I run MLFLOW in docker container, myArifacts location is Minio bucket (Minio is running in its own docker container), backend store is Postgres ( running in its own docker container); I train my model in Jupiter notebook ( also in its own docker container). Is it possible to use Github as an artifact location?\n\n\nThank you.",
        "Answers":[
            {
                "Answer_creation_time":"2019-06-27T15:34:12",
                "Answer_body":"No, you can\u2019t use GitHub by default, but it may be possible to write an artifact store plugin that does that. Our idea was that artifacts can be very large, however (multi-gigabyte models or multi-terabyte datasets), so it might not make sense to use GitHub.\n\n\nMatei\n\n\n\nOn Jun 27, 2019, at 11:19 AM, SoniaK <sofia....@8451.com> wrote:\n\n\nIm testing MLFLOW 1.0.0. I run MLFLOW in docker container, myArifacts location is Minio bucket (Minio is running in its own docker container), backend store is Postgres ( running in its own docker container); I train my model in Jupiter notebook ( also in its own docker container). Is it possible to use Github as an artifact location?\n\n\nThank you.\n\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/59f7455b-4b7b-41f5-8058-6bb231bb0807%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            },
            {
                "Answer_creation_time":"2019-06-27T15:36:20",
                "Answer_body":"Hi, I think you should use the right tool for the right job. GitHub is for sharing code.\nThx\n\n\n\n\ue5d3\n\ue5d3\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/F25604B5-40AA-4907-960B-C588609BC72A%40databricks.com.\n\ue5d3"
            },
            {
                "Answer_creation_time":"2019-06-27T16:03:55",
                "Answer_body":"Thank you, Matei and Zahir.\n\n\nOn Thursday, June 27, 2019 at 2:36:20 PM UTC-5, zahir hamroune wrote:\nHi, I think you should use the right tool for the right job. GitHub is for sharing code.\nThx\n\n\n\nOn 27 Jun 2019, at 21:34, Matei Zaharia <ma...@databricks.com> wrote:\n\n\nNo, you can\u2019t use GitHub by default, but it may be possible to write an artifact store plugin that does that. Our idea was that artifacts can be very large, however (multi-gigabyte models or multi-terabyte datasets), so it might not make sense to use GitHub.\n\n\nMatei\n\n\n\nOn Jun 27, 2019, at 11:19 AM, SoniaK <sofia...@8451.com> wrote:\n\n\nIm testing MLFLOW 1.0.0. I run MLFLOW in docker container, myArifacts location is Minio bucket (Minio is running in its own docker container), backend store is Postgres ( running in its own docker container); I train my model in Jupiter notebook ( also in its own docker container). Is it possible to use Github as an artifact location?\n\n\nThank you.\n\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\n\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow...@googlegroups.com.\n\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/59f7455b-4b7b-41f5-8058-6bb231bb0807%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout.\n\n\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\n\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow...@googlegroups.com.\n\ue5d3"
            },
            {
                "Answer_creation_time":"2019-07-01T18:14:36",
                "Answer_body":"Hi Zahir.\u00a0 If GitHub is not the right tool for the job (I don't disagree with that), what would you say IS the right tool for persisting artifacts?\n\nThanks in advance!\n\n\nOn Thursday, June 27, 2019 at 2:36:20 PM UTC-5, zahir hamroune wrote:\n\ue5d3"
            },
            {
                "Answer_creation_time":"2019-07-02T06:37:31",
                "Answer_body":"You can use a shared filesystem or blob store, such as AWS S3, Azure Blob Storage, HDFS, or a POSIX file system set up through NFS.\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\n\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/9bd4f3f5-4574-473e-8fd9-81361945f52f%40googlegroups.com.\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"Dagster integration",
        "Question_creation_date":"2019-12-10T07:56:22",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/t0evBl17ZvE",
        "Question_answer_count":0,
        "Question_view_count":8,
        "Question_body":"Just a thought --\u00a0\n\n\nI like ML Flow, but the Projects aspects of it seem a bit weak & cumbersome (no clear docs for sophisticated pipelines, such as DAGs, etc.)\n\n\nCould it be possible to integrate with\u00a0Dagster? This way we can enjoy the best of both worlds...",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLFlow UI extensibility",
        "Question_creation_date":"2021-12-22T05:12:02",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/ORiCle7j4NM",
        "Question_answer_count":3,
        "Question_view_count":33,
        "Question_body":"Hello everyone,\n\n\nso I recently chose mlflow as our current solution for logging long-term research results in our company and one significant pain point I encountered is the UI extensibility. I would love to be able to display whatever I want but even a small amount of flexibility\/customization would go a long way.\n\n\nIs this something currently on the roadmap?\n\n\nIf I were to fork mlflow and implement my own UI modules or even whole UI API module for extensibility:\nwould you be interested in a later pull request with such contribution to the project?\nif I wanted to get a feel for how difficult it would be to make this happen, could you point me to some relevant parts of the codebase which I should see first and start with?\nCheers,\nAdam",
        "Answers":[
            {
                "Answer_creation_time":"2022-01-02T13:41:36",
                "Answer_body":"Hey, I'm also interested in any kind of UI extensibility.\n\ue5d3"
            },
            {
                "Answer_creation_time":"2022-01-02T17:38:04",
                "Answer_body":"On Sun, Jan 2, 2022 at 10:41 Haroune Mohammedi <mohammed...@gmail.com> wrote:\n\n\nHey, I'm also interested in any kind of UI extensibility.\n\nOn Wednesday, December 22, 2021 at 11:12:02 AM UTC+1 adam....@gmail.com wrote:\n\nHello everyone,\n\n\nso I recently chose mlflow as our current solution for logging long-term research results in our company and one significant pain point I encountered is the UI extensibility. I would love to be able to display whatever I want\nCan you be more specific about the new functionality you're looking for, including examples of things you want to display but can't currently?\n\n\nbut even a small amount of flexibility\/customization would go a long way.\n\n\nIs this something currently on the roadmap?\n\n\nIf I were to fork mlflow and implement my own UI modules or even whole UI API module for extensibility:\nwould you be interested in a later pull request with such contribution to the project?\nif I wanted to get a feel for how difficult it would be to make this happen, could you point me to some relevant parts of the codebase which I should see first and start with?\nThe https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/mlflow\/server\/js\/src\n\n\n\n\nCheers,\nAdam\n\n\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/a6ff268c-29f2-4fbf-859f-3453e6ab9c91n%40googlegroups.com."
            },
            {
                "Answer_creation_time":"2022-01-02T17:44:04",
                "Answer_body":"On Sun, Jan 2, 2022 at 14:37 Andy Konwinski <andyko...@gmail.com> wrote:\n\n\n\n\n\nOn Sun, Jan 2, 2022 at 10:41 Haroune Mohammedi <mohammed...@gmail.com> wrote:\n\n\nHey, I'm also interested in any kind of UI extensibility.\n\nOn Wednesday, December 22, 2021 at 11:12:02 AM UTC+1 adam....@gmail.com wrote:\n\nHello everyone,\n\n\nso I recently chose mlflow as our current solution for logging long-term research results in our company and one significant pain point I encountered is the UI extensibility. I would love to be able to display whatever I want\nCan you be more specific about the new functionality you're looking for, including examples of things you want to display but can't currently?\n\n\nbut even a small amount of flexibility\/customization would go a long way.\n\n\nIs this something currently on the roadmap?\n\n\nIf I were to fork mlflow and implement my own UI modules or even whole UI API module for extensibility:\nwould you be interested in a later pull request with such contribution to the project?\nif I wanted to get a feel for how difficult it would be to make this happen, could you point me to some relevant parts of the codebase which I should see first and start with?\nThe https:\/\/github.com\/mlflow\/mlflow\/tree\/master\/mlflow\/server\/js\/src\n\n\nSorry sent early. That's the source of the server\/UI. It's \u00a0built using flask + react. The Readme is at\u00a0\nhttps:\/\/github.com\/mlflow\/mlflow\/tree\/master\/mlflow\/server\/js#readme though most of the readme is still from the create-react-app readme template, I.e., not MLflow specific.\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"mlflow gui - displaying csv artifact.",
        "Question_creation_date":"2018-12-11T11:11:31",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/OgApYabrvPE",
        "Question_answer_count":2,
        "Question_view_count":23,
        "Question_body":"Hi all,\n First of all great job with mlflow, it is an amazing tool.\nI have a question\/request though, is there a way to display a csv file (i.e. confusion matrix data) saved in mlflow artifacts repo as a table or graph? \nIf not,  it would be nice if we could add some plugin into ML Flow to display CSV data in a table view.  \n\nCheers",
        "Answers":[
            {
                "Answer_creation_time":"2018-12-12T00:56:22",
                "Answer_body":"There\u2019s actually an open pull request to do this from a while back: https:\/\/github.com\/mlflow\/mlflow\/pull\/436. It was waiting on some code review comments, but if you want, maybe you can take it over and finish it? We agree that it would be nice to visualize these as tables.\n\nMatei\n\n\ue5d3\n> --\n> You received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\n> To unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\n> To post to this group, send email to mlflow...@googlegroups.com.\n> To view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/867f37be-3692-4ddf-964a-631a03687348%40googlegroups.com.\n> For more options, visit https:\/\/groups.google.com\/d\/optout."
            },
            {
                "Answer_creation_time":"2018-12-12T10:43:59",
                "Answer_body":"Definitely interested to finish the work. Analyzing the patch.\n\n\nCheers\nAmir Sanjar\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"MLflow Release 0.4.1",
        "Question_creation_date":"2018-08-03T19:30:52",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/2Diy6_Sflr0",
        "Question_answer_count":0,
        "Question_view_count":28,
        "Question_body":"Hi mlflow-users,\n\nMLflow Release 0.4.1 is ready, released 2018-08-03. The release is available on\u00a0PyPI\u00a0and docs are\u00a0updated. Here are the release notes (also available\u00a0on GitHub):\n\n\n\nBreaking changes: None\n\nFeatures:\n\n[Projects] MLflow will use the conda installation directory given by the $MLFLOW_CONDA_HOME if specified (e.g. running conda commands by invoking \"$MLFLOW_CONDA_HOME\/bin\/conda\"), defaulting to running \"conda\" otherwise. (#231,\u00a0@smurching)\n[UI] Show GitHub links in the UI for projects run from http(s):\/\/ GitHub URLs (#235,\u00a0@smurching)\n\nBug fixes:\n\nFix GCSArtifactRepository issue when calling list_artifacts on a path containing nested directories (#233,\u00a0@jakeret)\nFix Spark model support when saving\/loading models to\/from distributed filesystems (#180,\u00a0@tomasatdatabricks)\nAdd missing mlflow.version import to sagemaker module (#229,\u00a0@dbczumar)\nValidate metric, parameter and run IDs in file store and Python client (#224,\u00a0@mateiz)\nValidate that the tracking URI is a remote URI for Databricks project runs (#234,\u00a0@smurching)\nFix bug where we'd fetch git projects at SSH URIs into a local directory with the same name as the URI, instead of into a temporary directory (#236,\u00a0@smurching)\n\n\n\n\n\nThanks,\nSid",
        "Answers":[

        ]
    },
    {
        "Question_title":"Deploy problems",
        "Question_creation_date":"2019-05-13T15:16:42",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/mZCOZ5FCQaM",
        "Question_answer_count":2,
        "Question_view_count":27,
        "Question_body":"Hi guys!\n\n\nI'm new with MLFlow and I would like to deploy a simple model on SageMaker but I got some problems.\n\n\n\nI have trained a model locally and successfully generated a docker image and uploaded it to AWS ECR but, when I called deploy method I got the following error:\u00a0MlflowException: Run '6b33f54c1b2541da8ec95152ab5f566b' not found\n\n\nI'm using MLFlow\u00a00.9.1 and I'm following this tutorial:\u00a0https:\/\/docs.databricks.com\/_static\/notebooks\/mlflow\/mlflow-quick-start-deployment-aws.html\n\n\nCould someone help me please =D S2\u00a0\n\n\nThanks a lot!",
        "Answers":[
            {
                "Answer_creation_time":"2019-05-13T16:17:17",
                "Answer_body":"Hi Rafael.\u00a0\n\n\nThe exception you got signals that MLflow was not able to access the run at the time you called the deploy. What is your mlflow set up? Do you run against a remote tracking server or the default file based one? The local file-based store will by default store the data on a relative path, so you need to make sure that you logged to the same location you are trying to read from when you deploy. You can look for mlruns directory and see if it has run you are trying to deploy. You can set location of the store data by setting MLFLOW_TRACKING_URI environment variable.\n\n\n\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/68f260a8-ea05-4690-af08-b0796065d255%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            },
            {
                "Answer_creation_time":"2019-05-16T12:27:48",
                "Answer_body":"Hi Tomas\n\nI finally got to put the trained model on sagemaker, I was actually running the commands in the wrong folder, but there were some issues with the AWS configuration as well. Thanks a lot for\u00a0your help!\n\n\nNow that I got it I have different questions like how can I \"integrate\" my Jupyter Notebook experiments with MLFlow but I'll check the mail list history for that.\n\n\nThanks!\nAtenciosamente,\nRafael J. R. Novello\n\n\nSkype: rafael.novello\nBlog:\u00a0http:\/\/rafanovello.blogspot.com.br\/\n\n\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"benchmark issue",
        "Question_creation_date":"2018-12-24T05:10:26",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/WZFtu_8SK_Q",
        "Question_answer_count":4,
        "Question_view_count":23,
        "Question_body":"https:\/\/databricks.com\/blog\/2018\/09\/13\/whats-new-in-mlflow-v0-6-0.html\n\nIn the above article, the team presented a comparison between sprak-ml and mlflow time consumption, I am\ncurious about those data.\nIs there anyone knows more about the machine information? Such us memory, CPU ...",
        "Answers":[
            {
                "Answer_creation_time":"2018-12-24T11:06:36",
                "Answer_body":"I think you mean SparkML and MLeap, right?\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/ce713327-3744-4b09-85c4-890935a782ca%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            },
            {
                "Answer_creation_time":"2018-12-25T22:12:36",
                "Answer_body":"Yes, you are right, I want to know what hardware config was used for the experiment.\nAnd I am also curious about the \"time\" in your experiment, how did you measure the time for a single real time serving query? Do you start the timer before you start a HTTP request to the server, or do you start the timer before the module starts make prediction? And when do you stop the timer?\u00a0\nAnd could you please tell me more about your model? What is the input and output? Is it complex or not?\n\ue5d3"
            },
            {
                "Answer_creation_time":"2018-12-26T21:04:43",
                "Answer_body":"Hi Mark,\n\n\n\n\nThank you for your detailed questions regarding the MLeap vs Spark MLLib benchmark comparison that we included with the release of MLflow 0.6.0.\n\n\n\n\nThe benchmark was performed on an AWS EC2 t2.large instance. First, we trained a Spark model on the 20 Newsgroups dataset (https:\/\/archive.ics.uci.edu\/ml\/datasets\/Twenty+Newsgroups); you can find the training code here: https:\/\/docs.databricks.com\/spark\/latest\/mllib\/mlflow-mleap.html#mlflow-and-mleap. \n\n\n\n\nThen, we persisted the model in two formats: MLeap and Spark MLLib. We benchmarked each format by performing the following procedure:\n\n\n\n\nStart a local server for the model on the EC2 instance\n\n\n\nExecute a driver program *on the same EC2 instance* that runs the following loop:\n\n\n\nSample a single item (batch size = 1) from the 20 newsgroups test dataset\n\n\n\nTake a timestamp *before* sending an HTTP request containing the sample\n\n\n\nSend an HTTP post request with the sample to the local model server\n\n\n\nTake a timestamp *after* a response is received\n\n\n\nThe driver program persisted the time deltas associated with each request; we generated the blog histogram from this data.\n\n\n\n\nPlease let me know if anything is unclear or if you have any additional questions regarding the comparison!\n\n\n\n\nBest,\n\n\n\n\nCorey\n\n\n\n\ue5d3"
            },
            {
                "Answer_creation_time":"2018-12-26T21:50:12",
                "Answer_body":"Hi\u00a0corey.zumar,\n\n\nThanks for your details, very appreciate your help!\u00a0\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"MLFLOW project MLFLOW_TRACKING_URI to postgres in docker",
        "Question_creation_date":"2019-07-01T17:51:46",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/HOstT6RINbA",
        "Question_answer_count":0,
        "Question_view_count":17,
        "Question_body":"I want to test MLFLOW projects running in docker container, I use examples\/docker from mlflow. My\u00a0 MLFLOW runs in docker container, backend store is in Postgres ( runs in its own docker container). I have started mlfow container and postgres container using docker-compose. I can connect to postgres using command:\n\npsql -p 5432 -d mlflow -U mlflow -h localhost\n\n\n\n\nHowever, when I am trying to run mlflow project (export MLFLOW_TRACKING_URI=postgresql:\/\/mlflow:mlflow@localhost\/mlflow)\n\n\u00a0 \u00a0\u00a0mlflow run . -P alpha=0.55\n\nI have an error message:\u00a0sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not connect to server: Connection refused\n\nIs the server running on host \"localhost\" (::1) and accepting\n\nTCP\/IP connections on port 5432?\n\ncould not connect to server: Connection refused\n\nIs the server running on host \"localhost\" (127.0.0.1) and accepting\n\nTCP\/IP connections on port 5432?",
        "Answers":[

        ]
    },
    {
        "Question_title":"adding pyspark.ml.recommendation.ALS to allowlist for mlflow.pyspark.ml.autolog?",
        "Question_creation_date":"2022-06-24T09:04:50",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/gOopnnYcaas",
        "Question_answer_count":0,
        "Question_view_count":15,
        "Question_body":"Hi, so\u00a0 mlflow.pyspark.ml.autolog by default excludes\u00a0pyspark.ml.recommendation.ALS from the allowlist.\u00a0\n\n\nI have two questions:\nIf I add it to a custom allowlist, is there a maximum model size that will cause a problem?\nIf I cannot do an autolog, how am I supposed to log and use the model with mlflow on databricks?\n\n\nThanks!",
        "Answers":[

        ]
    },
    {
        "Question_title":"mlflow usage clarification",
        "Question_creation_date":"2021-11-02T01:33:51",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/Zqzr2Sib7CA",
        "Question_answer_count":2,
        "Question_view_count":30,
        "Question_body":"Hi,\n\n\nI am new to MLflow and I am glad to find this group.\n\n\nI would appreciate if someone can give me some advice on how proceed in the scenario described below.\u00a0\u00a0\n\n\nI run mlflow in a Conda env (say mlflow-dev). I also have a few ML models in another Conda env (say models-dev).\u00a0 The models-dev has a few older dependencies that I have to keep it separate at all cost. How can I access and run models from models-dev in mlflow?\n\n\nAny suggestions, links or pointers would be very much appreciated.\n\n\nThanks\nRoy",
        "Answers":[
            {
                "Answer_creation_time":"2021-11-02T12:16:33",
                "Answer_body":"If you use ML projects, you can specify a conda environment yaml\u00a0file. If you create a yaml file for models-dev - then when you run the project, MLflow creates a clean sandbox for models-dev (and caches it for later runs) that you model training runs in.\nhttps:\/\/mlflow.org\/docs\/latest\/projects.html\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/20598a77-969f-4453-b0f2-a042df80675bn%40googlegroups.com."
            },
            {
                "Answer_creation_time":"2021-12-02T19:24:26",
                "Answer_body":"Sorry Paul for my delayed reply.\u00a0Thanks a lot for your suggestion. In my case I had to stack up conda envs to get my scenario working and then switch back.\u00a0\n\n\nThanks,\nShounak\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"mlflow scaling issue",
        "Question_creation_date":"2019-02-05T15:16:58",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/MfgmfilrJsI",
        "Question_answer_count":1,
        "Question_view_count":32,
        "Question_body":"Hi all,\nwhen running below script, we notice a visible performance degradation as number of experiments increases.\nimport mlflow\n  \nfor i in range(5000):\n\n    mlflow.set_experiment('exp%d' % i)\n\n    for j in range(5):\n\n        with mlflow.start_run() as run:\n\n            mlflow.log_param('n', '%d-%d' % (i, j))\n            mlflow.log_metric('fscore', 0.9242)\n            mlflow.set_tag('some tag', '%d-%d' % (i, j))\n            with open('test.json', 'w') as f:\n                f.write('{ \"i\": %d, \"j\": %d }' % (i, j))\n            mlflow.log_artifact('test.json')\n            print(mlflow.active_run())\n\nabove script creates 5000 experiments, with 5 dummy runs in each experiment.  After about 18 hours, it has only created 2500 experiments.  At this point, it is taking about a minute to create a new experiment, and 5 seconds to create a run.\n\nwhat is the bottleneck. \nThanks in advance ..",
        "Answers":[
            {
                "Answer_creation_time":"2019-02-05T16:14:40",
                "Answer_body":"Are you running this on a local machine? Note that each experiment under \"mlruns\" directory has an experiment_id as the name of the directory, and\neach run_id for that experiment gets a run_id as a directory. Furthermore, each artifact, metrics, and\u00a0params receive its own directory. So what you seeing is an explosion of file descriptors across the UNIX filesystem, which\nexplains its degradation over time.\n\n\nThis issue is being addressed by using a DB to track experiments and run_ids, mitigating (or eliminating) file descriptor degradation over volumes of experiments\nwith its respective runs at scale.\u00a0\n\n\n\n\n\n--\u00a0\n\n\nThe Best Ideas are Simple\n\nJules S. Damji\n\nApache Spark Developer & Community Advocate\n\nDatabricks, Inc.\n\nju...@databricks.com\n\n(510) 304-7686\n\ndatabricks.com\n\n\n\n\n\u00a0\u00a0\u00a0\n\n\n\n\n\n\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/bbb34a21-66d7-474e-9c3e-20355eebec07%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            }
        ]
    },
    {
        "Question_title":"Kedro vs MLFlow",
        "Question_creation_date":"2019-07-01T18:09:08",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/NKeIrAaBpV8",
        "Question_answer_count":1,
        "Question_view_count":96,
        "Question_body":"Newbie question: Is anyone familiar with Kedro?\u00a0 If so, how does it compare with MLFlow?\u00a0 Could they be used together effectively, if one has strengths the other lacks?\u00a0 As I start trying to move my organization in this direction, I would like to have any experienced honest feedback available.\u00a0 I know Kedro is pretty new, so I understand if noone has any experience with it.\n\nKedro Ref:\u00a0https:\/\/medium.com\/@QuantumBlack\/introducing-kedro-the-open-source-library-for-production-ready-machine-learning-code-d1c6d26ce2cf",
        "Answers":[
            {
                "Answer_creation_time":"2019-11-25T19:48:00",
                "Answer_body":"You can check out this post comparing the two:\u00a0https:\/\/medium.com\/@QuantumBlack\/deploying-and-versioning-data-pipelines-at-scale-942b1d81b5f5\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"Org Using MLflow - BRIDGEi2i Analytics",
        "Question_creation_date":"2021-01-20T00:13:05",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/1ptDCEaHLZ0",
        "Question_answer_count":0,
        "Question_view_count":15,
        "Question_body":"Hi all,\n\n\nWe at BRIDGEi2i Analytics Solutions\u00a0are extensively using MLFlow in most of our analytical products.\nWe would like to support and contribute to MLFlow, Please add our organization to the list on MLFlow website.\n\n\n\n\nThanks!!\n\n\n\n\nRegards,\n\nSaddam |\u00a0Manager |\u00a0AI Actions\u00a0\n\nBRIDGEi2i Analytics Solutions\n\nCell:\u00a0+91 - 8147171826\n\n\n\n\n\n\n\nThis e-mail (and any attachments), is confidential and may be privileged. It may be read, copied and used only by intended recipients. Unauthorized access to this e-mail (or attachments) and disclosure or copying of its contents or any action taken in reliance on it is unlawful. Unintended recipients must notify the sender immediately by e-mail or phone and delete it from their system without making any copies or disclosing it to a third person. BRIDGEi2i Analytics Solutions reserves the right to store, monitor and review the content of all messages sent to or from this email address.",
        "Answers":[

        ]
    },
    {
        "Question_title":"sanic python - instead of flask",
        "Question_creation_date":"2019-06-13T08:41:26",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/KjKwpgi8EjI",
        "Question_answer_count":1,
        "Question_view_count":6,
        "Question_body":"Hey,\n\n\nWe are not able to use the mlflow server in our production API due to the fact it's using flask.\nWe have create our own API which is taking the pickel from mlflow and uses\u00a0sanic python for the API which is much faster.\n\n\nCan you please change your flask to\u00a0sanic python?\n\n\nIt will help us a lot.",
        "Answers":[
            {
                "Answer_creation_time":"2019-06-13T11:53:27",
                "Answer_body":"We definitely welcome contributions of this sort! If interested in contributing, it would also be great to point out the pros\/cons of sanic vs flask, and if there are backwards-compatibility issues that might arise from switching.\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/56a48ce0-6460-4f8f-91c8-a9feec6d5a1c%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            }
        ]
    },
    {
        "Question_title":"MLflow 1.26.1 released!",
        "Question_creation_date":"2022-05-27T21:27:04",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/OkDlyI-k6Ss",
        "Question_answer_count":0,
        "Question_view_count":12,
        "Question_body":"We are happy to announce the availability of\u00a0MLflow 1.26.1!\n\n\n\nMLflow 1.26.1 is a patch release containing the following bug fixes:\n\n[Installation] Fix compatibility issue with\u00a0protobuf >= 4.21.0\u00a0(#5945,\u00a0@harupy)\n[Models] Fix\u00a0get_model_dependencies\u00a0behavior for\u00a0models:\u00a0URIs containing artifact paths (#5921,\u00a0@harupy)\n[Models] Revert a problematic change to\u00a0artifacts\u00a0persistence in\u00a0mlflow.pyfunc.log_model()\u00a0that was introduced in MLflow 1.25.0 (#5891,\u00a0@kyle-jarvis)\n[Models] Close associated image files when\u00a0EvaluationArtifact\u00a0outputs from\u00a0mlflow.evaluate()\u00a0are garbage collected (#5900,\u00a0@WeichenXu123)\nFor a comprehensive list of changes, see the\u00a0release change log, and check out the latest documentation on\u00a0mlflow.org.\n\n\n\nNote: Version 1.26.1 of the MLflow R package has not yet been released. It will be available on CRAN within the next week.",
        "Answers":[

        ]
    },
    {
        "Question_title":"Cannot save Spark Pipeline model as pyfunc",
        "Question_creation_date":"2020-02-24T13:40:38",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/IRaESID1o5g",
        "Question_answer_count":0,
        "Question_view_count":11,
        "Question_body":"I have a Spark Pipeline model saved using mlflow.spark.save_model().Then load it back as a Pyfunc model (mlflow.pyfunc.load_pyfunc). But it is not getting saved on my local machine using the mlflow.pyfunc.save_model command. Why not able to save using mlflow.pyfunc.save_model () ?",
        "Answers":[

        ]
    },
    {
        "Question_title":"mlflow system environment in windows",
        "Question_creation_date":"2020-11-04T02:09:36",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/aGVwpa-0IC4",
        "Question_answer_count":0,
        "Question_view_count":13,
        "Question_body":"Hi,\n\n\nIs it possible to create and implement ml model using mlflow without conda installed in the system environment(python environment) ?\n\n\nThanks\nSafuvan",
        "Answers":[

        ]
    },
    {
        "Question_title":"Trying to add the log_param() function",
        "Question_creation_date":"2018-10-18T20:52:25",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/CxuBUiu1gys",
        "Question_answer_count":1,
        "Question_view_count":11,
        "Question_body":"with mlflow.start_run(nested =True):\n### instantiate the RNN model object\u00a0\n\u00a0 \u00a0 regr = Sequential()\u00a0\n\n\n### add the input and LSTM layers\u00a0\nregr.add(LSTM(units =4, activation ='sigmoid', input_shape =(None, 1)))\u00a0 \u00a0\u00a0\n\n\n### add the output layer\nregr.add(Dense(units =1))\n\n\n### compile the RNN\u00a0\noptimizer = 'adam'\nloss = 'mean_squared_error'\nmetrics = ['accuracy']\u00a0\nregr.compile(optimizer, loss , metrics)\u00a0\n\n\n### fit the model on the training set\u00a0\nbatch_size = 5\nepochs = 1\nregr.fit(X_train, y_train, batch_size, epochs)\u00a0\n\n\nlog_param(\"loss\", loss)\u00a0\nlog_param(\"epochs\", epochs)\nlog_param(\"optimizer\", optimizer)\nlog_param(\"batch_size\", batch_size)\nlog_param(\"metrics\", metrics)",
        "Answers":[
            {
                "Answer_creation_time":"2018-10-18T20:53:53",
                "Answer_body":"\ue5d3\n\ue5d3\njust want to get the params in the mlflow ui"
            }
        ]
    },
    {
        "Question_title":"mlflow on CDSW",
        "Question_creation_date":"2019-03-17T10:02:47",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/CYyStbjSTts",
        "Question_answer_count":1,
        "Question_view_count":13,
        "Question_body":"Hi there!\n\n\nI had been able to integrate mlflow into my model on local and track the metrics.\n\n\nHowever, now am carrying out a task to integrate mlflow into Cloudera workbench. Facing either SSL or https connection issues when trying to trigger the tracking URI.\nDo you please have any documentation on working with mlflow on CDSW? Any suggestions are\u00a0welcome.\n\n\nThanks!\nBest,\nAsis",
        "Answers":[
            {
                "Answer_creation_time":"2019-03-17T12:42:09",
                "Answer_body":"How have you run the tracking server? and are you running an SSL-enabled proxy in front of it?"
            }
        ]
    },
    {
        "Question_title":"MLflow 1.14.1 released!",
        "Question_creation_date":"2021-03-01T20:56:25",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/lSEtCZf7CrI",
        "Question_answer_count":0,
        "Question_view_count":7,
        "Question_body":"Hi all, we are happy to announce the availability of\u00a0MLflow 1.14.1!\n\n\nMLflow 1.14.1 is a patch release containing the following bug fix:\nFix issues in handling flexible numpy datatypes in TensorSpec (#4147,\u00a0@arjundc-db)\nThis information is also available in the\u00a0release change log, and you can check out the latest documentation for MLflow 1.14.1 on\u00a0mlflow.org.",
        "Answers":[

        ]
    },
    {
        "Question_title":"Mlflow integration with Google's Vertex AI",
        "Question_creation_date":"2022-02-18T06:31:06",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/q9759ED2C2A",
        "Question_answer_count":0,
        "Question_view_count":82,
        "Question_body":"Hi,\n\n\n\u00a0 Is there any way through which we can integrate mlflow with vertex AI ?\u00a0\nAny articles or resources I can go through ?\n\nThanks\nAvinash",
        "Answers":[

        ]
    },
    {
        "Question_title":"Is it possible to filter on Date?",
        "Question_creation_date":"2019-07-18T23:51:40",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/EKDhKa3UrbM",
        "Question_answer_count":1,
        "Question_view_count":5,
        "Question_body":"There is a Date column in the run's field. Can I do filtering on this field? I haven't find a way to do this.",
        "Answers":[
            {
                "Answer_creation_time":"2019-07-19T08:15:20",
                "Answer_body":"Hello,\n\n\nUnfortunately, we don\u2019t support filtering on that date right now. The date is actually the start_time time stamp converted into a date in the UI, and I believe the MLflow docs section on Search has a note that start_time isn\u2019t supported in the filter string.\u00a0\n\n\nWould you mind telling us about the use case you have where filtering based on date is really important? If many users have this use case we can probably prioritize adding that feature. Or you can make the change and submit a PR for it!\u00a0\n\n\nBest,\n- Max\n\n\nOn Thu, Jul 18, 2019 at 23:51 Cheng Li <scrapped...@gmail.com> wrote:\n\nThere is a Date column in the run's field. Can I do filtering on this field? I haven't find a way to do this.\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/b1857de5-d645-430d-871f-c6f0172fe52f%40googlegroups.com."
            }
        ]
    },
    {
        "Question_title":"Model serve",
        "Question_creation_date":"2019-10-03T02:47:05",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/ATDsXS83w9o",
        "Question_answer_count":0,
        "Question_view_count":18,
        "Question_body":"Hi ,\u00a0\nI am trying to use model serve, REST API ser er is created and now I am trying to pass CSV file as POST input to the \/invocations path.\u00a0\nCan someone please guide on how to pass the csv file as POST input and save the output to a file.\u00a0\n\n\nRegards\nBinay",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLflow 1.5.0 released!",
        "Question_creation_date":"2019-12-19T20:24:06",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/aLPUvzEx2KY",
        "Question_answer_count":0,
        "Question_view_count":14,
        "Question_body":"Hi all,\n\n\nWe are happy to announce the availability of\u00a0MLflow 1.5.0!^\u00a0 In addition to bug and documentation fixes, MLflow 1.5.0 includes several major features and improvements, including:\n\n\n* New support for a LightGBM flavor (#2136, @harupy)\n* New support for a XGBoost flavor (#2124, @harupy)\n* New support for a Gluon flavor and autologging (#1973, @cosmincatalin)\n* Runs created by mlflow.tensorflow.autolog() and mlflow.keras.autolog() (#2088) are now automatically ended after training (#2094, @juntai-zheng)\n\n* When using the mlflow server CLI command, you can now expose metrics on \/metrics for Prometheus via the optional --activate-parameter argument (#2097, @t-henri)\n\n\n\nFor a comprehensive list of changes, see the\u00a0release change log, and check out the latest documentation on\u00a0mlflow.org.\n\n\nThanks,\n\nSid",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLProject with Docker not producing MLModel artifact",
        "Question_creation_date":"2019-08-27T10:34:27",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/54mVBwanIVQ",
        "Question_answer_count":3,
        "Question_view_count":31,
        "Question_body":"Hello,\n\n\nI've been trying to run an MLProject (using the command mlflow run ...) with a Docker image to generate an MLmodel file with sklearn and the project runs but the artifacts directory created in the newly created mlruns directory is empty. If I run the exact same python script as a standalone (without the MLProject and Docker image), it works perfectly fine and correctly populates the artifacts directory. I'm not sure if this is an actual bug or if I am just doing something incorrectly.\n\n\nHere is the workflow I am using:\ncreated script (sklearn_mlflow_train.py) that uses mlflow.sklearn.log_model() python api call to create model log\nsnippet of python script:\n# Run the experiments using set parameters and log the resulting model\nwith mlflow.start_run() as run:\n\u00a0 \u00a0 clf = DecisionTreeClassifier(criterion=params.criterion, random_state=params.trand)\n\u00a0 \u00a0 model = clf.fit(X_train, y_train)\n\u00a0 \u00a0 mlflow.log_metric(\"Accuracy\", model.score(X_test, y_test))\n\n\n\u00a0 \u00a0 mlflow.log_param('train_size', params.train_size)\n\u00a0 \u00a0 mlflow.log_param('srand', params.srand)\n\u00a0 \u00a0 mlflow.log_param('trand', params.trand)\n\u00a0 \u00a0 mlflow.log_param('criterion', params.criterion)\n\n\n\u00a0 \u00a0 sk_model_path = \"sk_models\"\n\u00a0 \u00a0 mlflow.sklearn.log_model(model, sk_model_path)\ncreate docker image (standard docker image creation)\ncreate MLproject file that references the docker image\n\nname: mlflowproject-sklearn-test\n\n\ndocker_env:\n\u00a0 \u00a0 image: mlflow-sklearn-test\n\n\nentry_points:\n\u00a0 \u00a0 main:\n\u00a0 \u00a0 \u00a0 \u00a0 parameters:\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 train_size: {type: float, default: 0.2}\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 trand: {type: int, default: 123}\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 srand: {type: int, default: 12}\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 criterion: {type: string, default: gini}\n\u00a0 \u00a0 \u00a0 \u00a0 command: \"python36 sklearn_mlflow_train.py -train_size {train_size} -trand {trand} -srand {srand} -criterion {criterion}\"\nrun the mlflow project in the working directory that has both the python script and the MLproject file: mlflow run .\nafter running the project, an mlruns directory is created and all of the params and metrics are correctly logged, but the artifacts directory is empty\nThanks in advance for the help!",
        "Answers":[
            {
                "Answer_creation_time":"2019-08-27T15:55:46",
                "Answer_body":"Hi,\n\n\nThis works for me.\n\n\nModel saved in run 6bad622aa6cf44dda6a7fdf084e6a407\n2019\/08\/27 12:52:15 INFO mlflow.projects: === Run (ID '6bad622aa6cf44dda6a7fdf084e6a407') succeeded ===\n(mlflow-dev-env-36) [08\/27 12:52][mani@:~\/databricks\/mlflow\/examples\/sklearn_docker] (master) $ > tree mlruns\/\n.trash\/ 0\/\n(mlflow-dev-env-36) [08\/27 12:52][mani@:~\/...\/sklearn_docker] (master) $ > tree mlruns\/0\/6bad622aa6cf44dda6a7fdf084e6a407\/\nmlruns\/0\/6bad622aa6cf44dda6a7fdf084e6a407\/\n\u251c\u2500\u2500 artifacts\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 sk_models\n\u2502\u00a0\u00a0 \u00a0 \u00a0 \u251c\u2500\u2500 MLmodel\n\u2502\u00a0\u00a0 \u00a0 \u00a0 \u251c\u2500\u2500 conda.yaml\n\u2502\u00a0\u00a0 \u00a0 \u00a0 \u2514\u2500\u2500 model.pkl\n\u251c\u2500\u2500 meta.yaml\n\u251c\u2500\u2500 metrics\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 Accuracy\n\u251c\u2500\u2500 params\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 criterion\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 srand\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 train_size\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 trand\n\u2514\u2500\u2500 tags\n\u00a0 \u00a0 \u251c\u2500\u2500 mlflow.docker.image.id\n\u00a0 \u00a0 \u251c\u2500\u2500 mlflow.docker.image.uri\n\u00a0 \u00a0 ...\n\n\nCan you run \"sklearn_mlflow_train.py\" directly on your local machine to see if there is an issue with writing out the model. You can use conda or pip directly to install necessary libraries.\n\n\n\n\n\nMani Parkhe\n\nma...@databricks.com\n\n\u00a0\n\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/9932a304-56f6-44db-b117-0e427e316e4b%40googlegroups.com."
            },
            {
                "Answer_creation_time":"2019-08-27T16:29:52",
                "Answer_body":"I can run the python script locally by itself and it works perfectly fine and correctly generates the artifacts."
            },
            {
                "Answer_creation_time":"2019-09-03T10:42:08",
                "Answer_body":"I figured out the possible cause of the issue. I was attempting to do all of this on Windows 10 initially when I was running into the error. However, when I transferred everything over to a Linux EC2 instance and ran the exact same command on the exact same script, it worked. It looks to be an issue that is specific to Windows. I currently don't have a fix for it outside of using Linux."
            }
        ]
    },
    {
        "Question_title":"[RFC] Fluent API for MLflow Java SDK",
        "Question_creation_date":"2019-06-27T16:57:58",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/QdB_DBMGPhU",
        "Question_answer_count":0,
        "Question_view_count":2,
        "Question_body":"Hi MLflow users,\n\n\nWe're planning on adding a \"fluent\" API to the MLflow Java SDK. This API allows users to manage their MLflow runs similarly to how they would with the Python SDK. Instead of\n    RunInfo runCreated = client.createRun(expId);\n    System.out.println(\"CreateRun: \" + runCreated);\n    String runId = runCreated.getRunUuid();\n\n    \/\/ Log parameters\n    client.logParam(runId, \"min_samples_leaf\", \"2\");\n    client.logParam(runId, \"max_depth\", \"3\");\n\n    \/\/ Log metrics\n    client.logMetric(runId, \"auc\", 2.12F);\n    client.logMetric(runId, \"accuracy_score\", 3.12F);\n    client.logMetric(runId, \"zero_one_loss\", 4.12F);\n\n    \/\/ Update finished run\n    client.setTerminated(runId, RunStatus.FINISHED);\nthe code would look something like\n    MlflowContext mlflow = MlflowContext.getOrCreate();\n    ActiveRun run = mlflow.startRun(\"run\");\n    run.logParam(\"alpha\", \"0.0\");\n    run.logMetric(\"MSE\", 0.0);\n    run.setTags(ImmutableMap.of(\n      \"company\", \"databricks\",\n      \"org\", \"engineering\"\n    ));\n    run.endRun();\nWe'd appreciate any feedback on the proposed APIs on the Github PR.\u00a0https:\/\/github.com\/mlflow\/mlflow\/pull\/1508\n\n\nThanks!\nAndrew",
        "Answers":[

        ]
    },
    {
        "Question_title":"mlflow ui throws exception when using sqlite as backend_store_uri",
        "Question_creation_date":"2020-01-26T11:33:36",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/qeRbVnClqSI",
        "Question_answer_count":1,
        "Question_view_count":18,
        "Question_body":"I try to start the mlflow ui service using SQLite as a backend store and cannot get rid of this exception:\n\n\nTypeError: Invalid argument(s) 'pool_pre_ping' sent to create_engine(), using configuration SQLiteDialect_pysqlite\/NullPool\/Engine.\u00a0 Please check that the keyword arguments are appropriate for this combination of components.\n\n\n\ncommand:\n(mlflow_demo) netanel@netpy:~\/git\/mlflow\/backend_store$ mlflow ui --backend-store-uri 'sqlite:\/\/\/home\/netanel\/git\/mlflow\/backend_store\/mlflow_tracker.db'\n\n\n\nI created the SQLite DB using the sqlite3 command line and initialize the schema using the latest_schema.sql script.\n\n\npython version:\u00a0Python 3.6.0 :: Anaconda 4.3.1 (64-bit)\nmlflow version: 1.5.0\n\n\nThanks.",
        "Answers":[
            {
                "Answer_creation_time":"2020-01-28T00:53:17",
                "Answer_body":"Someone can help me with that?\nThanks.\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"posting to managed mlflow (azure databricks) from remote",
        "Question_creation_date":"2019-09-21T01:33:05",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/jFvYBFUTIAc",
        "Question_answer_count":2,
        "Question_view_count":7,
        "Question_body":"If we have mlflow via a managed mlflow instance such as Azure Databricks - can we track, post experiments from remote like my machine's Jupyter notebook instead of running the code in databricks workspace?",
        "Answers":[
            {
                "Answer_creation_time":"2019-09-22T19:29:17",
                "Answer_body":"Yes, you can submit runs from anywhere. You first need to configure your machine with an access token to connect to the Azure Databricks MLflow server, as described on\u00a0https:\/\/docs.databricks.com\/applications\/mlflow\/projects.html#prerequisites\u00a0(basically, run \u201cdatabricks configure --token\u201d). Then you can simply set your tracking URI to \u201cdatabricks\u201d and runs will go to this server.\n\n\nMatei\n\n\n\nOn Sep 20, 2019, at 10:33 PM, Maheshwar Dattatri <mahes...@gmail.com> wrote:\n\n\nIf we have mlflow via a managed mlflow instance such as Azure Databricks - can we track, post experiments from remote like my machine's Jupyter notebook instead of running the code in databricks workspace?\n\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/3d35946f-251a-49b0-a731-325a9c560398%40googlegroups.com."
            },
            {
                "Answer_creation_time":"2019-09-24T01:45:22",
                "Answer_body":"Thank you\n\n\nOn Sunday, September 22, 2019 at 6:29:17 PM UTC-5, Matei Zaharia wrote:\nYes, you can submit runs from anywhere. You first need to configure your machine with an access token to connect to the Azure Databricks MLflow server, as described on\u00a0https:\/\/docs.databricks.com\/applications\/mlflow\/projects.html#prerequisites\u00a0(basically, run \u201cdatabricks configure --token\u201d). Then you can simply set your tracking URI to \u201cdatabricks\u201d and runs will go to this server.\n\n\nMatei\n\n\n\nOn Sep 20, 2019, at 10:33 PM, Maheshwar Dattatri <mahes...@gmail.com> wrote:\n\n\nIf we have mlflow via a managed mlflow instance such as Azure Databricks - can we track, post experiments from remote like my machine's Jupyter notebook instead of running the code in databricks workspace?\n\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\n\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow...@googlegroups.com.\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"Admin Tool",
        "Question_creation_date":"2020-05-20T04:59:10",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/KHc7WI97kJE",
        "Question_answer_count":3,
        "Question_view_count":36,
        "Question_body":"Hi ,\n\n\nI hope you are good.\n\n\nIs there any governance or admin tool in mlflow by which we can give only access to certain people to register a model or change a model status?\n\n\nThanks\u00a0\nSonalee",
        "Answers":[
            {
                "Answer_creation_time":"2020-05-20T11:09:47",
                "Answer_body":"Hello Sonalee,\n\n\nAt the moment the controlled access policies to model registry is part of the enterprise managed MLFlow feature.\u00a0\n\n\nWe welcome community contributions for a generic RBAC for the OSS MLflow.\u00a0\n\n\nDo share with the community if you have any ideas.\u00a0\n\n\nCheers\nJules\u00a0\n\n\n\n\nSent from my iPhone\nPardon the dumb thumb typos :)\n\n\nOn May 20, 2020, at 1:59 AM, Sonalee Naina <sonale...@gmail.com> wrote:\n\n\n\ufeff\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/df679645-25d6-48d4-84c8-6ec9eb81009d%40googlegroups.com."
            },
            {
                "Answer_creation_time":"2020-05-20T12:30:02",
                "Answer_body":"Hi Jules,\n\n\nCan\u00a0you share more details about the enterprise managed MLFlow feature?\n\n\nThanks,\n\n\nHien\n\n\n\ue5d3\n\ue5d3\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/3F296C11-B9C5-40DF-B4EF-DB75CFB9B171%40databricks.com."
            },
            {
                "Answer_creation_time":"2020-05-20T13:20:51",
                "Answer_body":"Yes, Sonalee,\n\n\nIncidentally, I just finished doing a part-3 (on MLflow Model Registry) of a\u00a0 three-part series. You\u00a0can\u00a0\nhttps:\/\/www.youtube.com\/watch?v=AxYmj8ufKKY&feature=youtu.be\n\n\nThere's also a blog where we explain the enterprise features:\u00a0\nhttps:\/\/databricks.com\/blog\/2020\/04\/15\/databricks-extends-mlflow-model-registry-with-enterprise-features.html\n\n\n\nHTH!\n\n\nCheers\nJules\n\n\n\n\n\n\n\n\n\u2013\u2013\n\nThe Best Ideas are Simple\n\nJules S. Damji\n\nDeveloper Advocate\n\nDatabricks, Inc.\n\nju...@databricks.com\n\n(510) 304-7686\n\n\n\n\n\n\n\n\n\n\n\u00a0\u00a0\u00a0\n\n\n\n\n\n\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"Artifacts not shown in mlflow tracking ui",
        "Question_creation_date":"2018-12-19T10:49:18",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/_wStTxLPmRg",
        "Question_answer_count":8,
        "Question_view_count":80,
        "Question_body":"Hi,\n\n\nI am running the following command: mlflow server -h 0.0.0.0\u00a0--file-store .\/mlruns\u00a0--default-artifact-root .\/artifacts\n\n\nI then run the example from here:\u00a0https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/examples\/quickstart\/mlflow_tracking.py\n\n\nEverything seems to be running fine, but the artifacts are not shown in the ui.\n\n\nShmuel",
        "Answers":[
            {
                "Answer_creation_time":"2018-12-19T13:49:10",
                "Answer_body":"Hi Shmuel,\n\n\nWhen you specify \".\/artifacts\" for default artifact root, it is the relative path. When you the quick start example,\u00a0LocalArtifactRepository used by default since it is a local path will put the artifact in \".\/artifact\" relative to where you are running the python code from. So for instance, in this sequence\u00a0\n\n\ncd ~\/A\nmlflow server -h 0.0.0.0\u00a0--file-store .\/mlruns\u00a0--default-artifact-root .\/artifacts\ncd ~\/B\nMLFLOW_TRACKING_URI=\"http:\/\/0.0.0.0:5000\"\u00a0python quickstart\/mlflow_tracking.py\n\n\nIt will create \"~\/A\/mlruns\" for all metrics and params (and will be viewable from UI running at 0.0.0.0:5000). However artifacts will be dumped under \"~\/B\/artifacts\".\n\n\nYou have two possible solutions for local artifact store\n[1] Run python code in the same directory \"A\" where you are running the server. But that can be restrictive.\n\n\n[2] (preferred) Specify absolute path for artifact location.\nmlflow server -h 0.0.0.0 --file-store .\/mlruns --default-artifact-root \/Users\/mani\/RANDOM_LOCATION\/DEEP_PATH\/ARTIFACTS\/\ncd ~\/some_other_run_location\nMLFLOW_TRACKING_URI=\"http:\/\/0.0.0.0:5000\" python ~\/mlflow\/examples\/quickstart\/mlflow_tracking.py\n\n\n\n\n\n\nOther options are to use blob storage like S3, Azure blob store, ... etc to store artifacts. Documentation details out different storage options.\n\n\nHope that helps\n\n\n\nMani Parkhe\n\nma...@databricks.com\n\n\n\n\n\n\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/3b16e2a5-4ef2-4789-a27b-cee8d4c212a9%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout.\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/3b16e2a5-4ef2-4789-a27b-cee8d4c212a9%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            },
            {
                "Answer_creation_time":"2018-12-19T16:50:12",
                "Answer_body":"Hi Mani,\n\n\nThanks for your response.\n\n\nHere is the issue: The way we write S3 is by using mounts to the Databricks environemnet.\nIf we want to write to bucket mybucket wemount it at \/mnt\/mybucket and then write to dbfs:\/\/mnt\/mybucket\nBut this won't work on the server side...\n\n\n\n\nShmuel\n\n\nOn Wed, Dec 19, 2018 at 10:15 PM Mani Parkhe <ma...@databricks.com> wrote:\n\nHi,\n\n\nYou might want to use S3:\/\/ for storing artifacts. If the artifact path is an S3:\/ path, mlflow will use S3ArtifactRepository\u00a0instead of LocalArtifactRepository. A user had filed a similar question on github -- look at\u00a0MLflow#158\u00a0for detailed conversation on this.\n\n\nThe link above has details on S3 based storage works. Also here's a\u00a0notebook example\u00a0that'll descriptive.\n\n\nDo you mind giving us details on your use case, how you are using MLflow and a bit more detail about your setup on how you are running ML training ... etc.\n\n\n\nMani Parkhe\n\nma...@databricks.com\n\n\n\n\n\n\n\n\n\n\nOn Wed, Dec 19, 2018 at 12:02 PM Shmuel Blitz <shmuel...@similarweb.com> wrote:\n\nHi Mani,\n\n\nThank for tge quick and detailed response. I now understand much better.\n\n\nThe issue is, I am running the server on an ec2 instance, while the code run either from my pc or from a Databricks notebook.\n\n\nHow can I configure the server to store the artifacts?\n\n\nShmuel\n\ue5d3\n\n\n\n\n--\n\nShmuel Blitz\nBig Data Developer\n\nEmail: shmuel...@similarweb.com\nwww.similarweb.com"
            },
            {
                "Answer_creation_time":"2018-12-20T04:23:12",
                "Answer_body":"Hi again,\n\n\nThere is an inherent problem in assuming that the server and the client would be accessing the artifact data in the same way.\nAs explained in my previous email, we have at least 3 use cases requiring access to the mlflow artifacts:\nThe mlflow server\nClients running on personal machines (e.g. when running a local Jupyter)\nClients running on Databricks\nEach use case has different patterns of accessing S3 and has different rights.\n\n\nSo I have no way of setting `--default-artifact-root` in such a way that will satisfy all the use cases. As result, `log_artifact()` is broken.\n\n\nI will open a Jira case explaining all this.\n\n\nShmuel\n\ue5d3"
            },
            {
                "Answer_creation_time":"2018-12-26T02:46:18",
                "Answer_body":"Hi Shmuel,\n\n\nDid you get around to filing this issue? Based on your description earlier--it seems you are running you server on EC2 instances and access data on local machines and within Databricks. Is my understanding correct? The recommendation from our side it to use S3:\/ paths everywhere local machines and Databricks. For the latter, use the IAM functionality in Databricks to be able to use a s3:\/\/ path, instead of a DBFS mount path.\n\n\nIf you run into any issues or have questions please reach out to your Databricks contact or kindly (little - r) reply back (only) to me and I help you with that.\n\n\nRegards,\n\n\n\nMani Parkhe\n\nma...@databricks.com\n\n\n\n\n\ue5d3\n\ue5d3"
            },
            {
                "Answer_creation_time":"2018-12-26T02:55:44",
                "Answer_body":"Hi,\n\n\nNo. I added my vote to the issue requesting the server to by the tunnel for file transfers (this one).\n\n\nI don't want to detail too much about our setup over this list, but the use case is problematic.\nIt's far from trivial to assume that the server and all its clients have the same access to S3.\n\n\nShmuel\n\ue5d3\n--\n\nShmuel Blitz\nData Analysis Team Leader\n\ue5d3"
            },
            {
                "Answer_creation_time":"2019-06-11T03:32:13",
                "Answer_body":"Hi ,\nI am using the command\u00a0mlflow server -h 0.0.0.0 --default-artifact-root (\"artifact store root\")\nHowever I am getting the following error :\u00a0Connection in use: ('127.0.0.1', 5000)"
            },
            {
                "Answer_creation_time":"2019-06-11T18:19:54",
                "Answer_body":"Do you still have this problem? The error message suggests you may have another instance of `mlflow server` running.\u00a0\n\n\n\ue5d3\n\ue5d3\nConfidentiality Notice and Disclaimer: This email (including any attachments) contains information that may be confidential, privileged and\/or copyrighted. If you are not the intended recipient, please notify the sender immediately and destroy this email. Any unauthorized use of the contents of this email in any manner whatsoever, is strictly prohibited. If improper activity is suspected, all available information may be used by the sender for possible disciplinary action, prosecution, civil claim or any remedy or lawful purpose. Email transmission cannot be guaranteed to be secure or error-free, as information could be intercepted, lost, arrive late, or contain viruses. The sender is not liable whatsoever for damage resulting from the opening of this message and\/or the use of the information contained in this message and\/or attachments. Expressions in this email cannot be treated as opined by the sender company management \u2013 they are solely expressed by the sender unless authorized.\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\n\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/5fdc69be-7f65-4a14-9230-c5f317341d06%40googlegroups.com.\n\nFor more options, visit https:\/\/groups.google.com\/d\/optout.\n\n\n\n\n\n--\n\n\n\n\u00a0\n\n\nSue Ann Hong\n\n\nSoftware Engineer - Machine Learning\n\nDatabricks, Inc."
            },
            {
                "Answer_creation_time":"2019-06-12T02:08:49",
                "Answer_body":"Was able to resolve the above error. Still unable to work with HDFS artifact store. Any help?\n\n\nOn Wednesday, June 12, 2019 at 3:49:54 AM UTC+5:30, Sue Ann Hong wrote:\nDo you still have this problem? The error message suggests you may have another instance of `mlflow server` running.\u00a0\n\n\nOn Tue, Jun 11, 2019 at 12:32 AM Shevy Mittal <shevy...@gslab.com> wrote:\n\nHi ,\nI am using the command\u00a0mlflow server -h 0.0.0.0 --default-artifact-root (\"artifact store root\")\nHowever I am getting the following error :\u00a0Connection in use: ('127.0.0.1', 5000)\n\n\nConfidentiality Notice and Disclaimer: This email (including any attachments) contains information that may be confidential, privileged and\/or copyrighted. If you are not the intended recipient, please notify the sender immediately and destroy this email. Any unauthorized use of the contents of this email in any manner whatsoever, is strictly prohibited. If improper activity is suspected, all available information may be used by the sender for possible disciplinary action, prosecution, civil claim or any remedy or lawful purpose. Email transmission cannot be guaranteed to be secure or error-free, as information could be intercepted, lost, arrive late, or contain viruses. The sender is not liable whatsoever for damage resulting from the opening of this message and\/or the use of the information contained in this message and\/or attachments. Expressions in this email cannot be treated as opined by the sender company management \u2013 they are solely expressed by the sender unless authorized.\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\n\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow...@googlegroups.com.\n\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/5fdc69be-7f65-4a14-9230-c5f317341d06%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout.\n\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"Bay Area MLflow Meetup @ Databricks, San Francisco",
        "Question_creation_date":"2019-11-20T17:40:17",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/HFC-t4OCzL8",
        "Question_answer_count":0,
        "Question_view_count":6,
        "Question_body":"Hello Everyone,\n\n\nWe hosting\u00a0a Bay Area MLflow Meetup with talks from Microsoft, Google, and Databricks on machine\u00a0learning, model management, and model data analytics\/validation. if you\u00a0are interested and live in the San Francisco Bay Area, please do join us for an evening of technical talks.\n\n\nRSVP here:\u00a0https:\/\/www.meetup.com\/Bay-Area-MLflow\/events\/266614106\/\n\n\nSee you all there!\n\n\n\n\n--\u00a0\n\n\nThe Best Ideas are Simple\n\nJules S. Damji\n\nApache Spark Developer & Community Advocate\n\nDatabricks, Inc.\n\nju...@databricks.com\n\n(510) 304-7686",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLflow 1.9.0 released!",
        "Question_creation_date":"2020-06-19T13:32:00",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/M525psdvxds",
        "Question_answer_count":0,
        "Question_view_count":10,
        "Question_body":"Hi all,\n\nWe are happy to announce the availability of MLflow 1.9.0! Some highlights from this release:\n\n\nlog_model and save_model APIs now support saving model signatures (the model's input and output schema) and example input along with the model itself \u00a0(#2698, #2775, @tomasatdatabricks). Model signatures are used to reorder and validate input fields when scoring\/serving models using the pyfunc flavor, mlflow models CLI commands, or mlflow.pyfunc.spark_udf (#2920, @tomasatdatabricks and @aarondav)\nIntroduce fastai model persistence and autologging APIs under mlflow.fastai (#2619, #2689 @antoniomdk)\nAdd pluggable mlflow.deployments API and CLI for deploying models to custom serving tools, e.g. RedisAI (#2327, @hhsecond)\nAdd plugin interface for executing MLflow projects against custom backends (#2566, @jdlesage)\nEnable viewing PDFs logged as artifacts from the runs UI \u00a0(#2859, @ankmathur96)\nSignificant performance and scalability improvements to metric comparison and scatter plots in the UI (#2447, @mjlbach)\nFor a comprehensive list of changes, see the\u00a0release change log (https:\/\/github.com\/mlflow\/mlflow\/releases\/tag\/v1.9.0), and check out the latest documentation on\u00a0mlflow.org.",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLflow 1.1 Release Candidate Process",
        "Question_creation_date":"2019-07-16T21:12:44",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/VIc0iMz1sSM",
        "Question_answer_count":0,
        "Question_view_count":8,
        "Question_body":"Hi all,\n\nWe\u2019re excited to announce that we\u2019re moving towards MLflow 1.1, with a tentative release date of July 19. The release contains a number of major features, including a pandas-based runs search API, autologging from TensorFlow to MLflow, a high-level Java fluent API, support for running MLflow projects on Kubernetes, search pagination, and a parallel coordinates plot in the runs UI.\n\n\nWe\u2019ve published an RC of MLflow 1.1, which you can use to try out all the latest features. We\u2019d love to get your feedback and fix any issues that arise before the 1.1 release. Please report issues at\u00a0https:\/\/github.com\/mlflow\/mlflow\/issues\u00a0with [MLflow 1.1] in the issue title.\n\n\nPlease see this document for instructions on how to try out the latest RC:\nhttps:\/\/docs.google.com\/document\/d\/1n3rAQwf9ldkcnOY7WOLxNeyJafq3br0N_gLSPgxxjhQ\/edit\n\n\n\nThanks!\nSid",
        "Answers":[

        ]
    },
    {
        "Question_title":"grpc Endpoint for Databricks MLFlow server",
        "Question_creation_date":"2022-01-05T04:12:20",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/sB9lZIvPu0E",
        "Question_answer_count":0,
        "Question_view_count":19,
        "Question_body":"Hello Everyone,\n\n\nDoes MLFlow server (Azure managed) provide gRPC endpoints?\nIf so, I couldn't find any doc to use client libraries to communicate with server with gRPC endpoints.\nAny guidance would be highly appreciated.",
        "Answers":[

        ]
    },
    {
        "Question_title":"Predicting H2O-models stored as pyfunc-models",
        "Question_creation_date":"2019-05-16T08:32:59",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/y8hhL4ecb7k",
        "Question_answer_count":3,
        "Question_view_count":29,
        "Question_body":"Hi,\n\n\u00a0\n\nMe and my team are trying to run H2O models (stored as pyfunc-models) on our Hadoop-cluster using spark.\nBasically not much more than this: \u00a0\n\nimport mlflow\n\nimport mlflow.pyfunc\n\n\u00a0\n\nfeatures = spark.read.parquet(\u201c\u2026\/features.parquet\u201d) \\\n\npredict_udf = mlflow.pyfunc.spark_udf(spark,\"..\/mlruns\/0\/f4ff13d1d93f4baab67dea545effca9b\/artifacts\/model_pyfunc\/\")\n\n\u00a0\n\npredictions = features.withColumn(\"prediction\", predict_udf('FML_Saved_vs_AUM_Ratio','TOT_IVT_AM','IND_Saved_vs_AUM_Ratio','SOL_SMT_CD','FML_PSN_FUND_AM')\n\npredictions.show(100,False)\n\n\u00a0\n\n\u00a0\n\nWe get the same prediction for each row.\n\n\n\n\nAfter taking a closer look at what happens during the prediction I see that the column names on which the data is trained are not recognized within the dataset that is being predicted.\n\n\n\n\/hadoop\/sdj1\/yarn\/local\/usercache\/jd05953\/appcache\/application_1557817794126_12227\/container_e312_1557817794126_12227_01_000002\/env\/mlflow_h2o\/lib\/python2.7\/site-packages\/h2o\/job.py:69: UserWarning: Test\/Validation dataset is missing column 'FML_Saved_vs_AUM_Ratio': substituting in a column of NaN\n\n\u00a0 warnings.warn(w)\n\n\/hadoop\/sdj1\/yarn\/local\/usercache\/jd05953\/appcache\/application_1557817794126_12227\/container_e312_1557817794126_12227_01_000002\/env\/mlflow_h2o\/lib\/python2.7\/site-packages\/h2o\/job.py:69: UserWarning: Test\/Validation dataset is missing column 'TOT_IVT_AM': substituting in a column of NaN\n\n\u00a0 warnings.warn(w)\n\n\/hadoop\/sdj1\/yarn\/local\/usercache\/jd05953\/appcache\/application_1557817794126_12227\/container_e312_1557817794126_12227_01_000002\/env\/mlflow_h2o\/lib\/python2.7\/site-packages\/h2o\/job.py:69: UserWarning: Test\/Validation dataset is missing column 'IND_Saved_vs_AUM_Ratio': substituting in a column of NaN\n\n\u00a0 warnings.warn(w)\n\n\/hadoop\/sdj1\/yarn\/local\/usercache\/jd05953\/appcache\/application_1557817794126_12227\/container_e312_1557817794126_12227_01_000002\/env\/mlflow_h2o\/lib\/python2.7\/site-packages\/h2o\/job.py:69: UserWarning: Test\/Validation dataset is missing column 'SOL_SMT_CD': substituting in a column of NaN\n\n\u00a0 warnings.warn(w)\n\n\/hadoop\/sdj1\/yarn\/local\/usercache\/jd05953\/appcache\/application_1557817794126_12227\/container_e312_1557817794126_12227_01_000002\/env\/mlflow_h2o\/lib\/python2.7\/site-packages\/h2o\/job.py:69: UserWarning: Test\/Validation dataset is missing column 'FML_PSN_FUND_AM': substituting in a column of NaN\n\n\u00a0 warnings.warn(w)\n\n\u00a0\n\n\u00a0\n\nWhen I take a look at the dataframe which is actually being used for the prediction (generated within the pandas UDF of the pyfunc-module)\u00a0 \u2026\n\n\u00a0\u00a0\u00a0 def predict(*args):\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 model = SparkModelCache.get_or_load(archive_path)\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 schema = {str(i): arg for i, arg in enumerate(args)}\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 # Explicitly pass order of columns to avoid lexicographic ordering (i.e., 10 < 2)\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 columns = [str(i) for i, _ in enumerate(args)]\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 pdf = pandas.DataFrame(schema, columns=columns)\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 result = model.predict(pdf)\n\n\u00a0\n\n\u2026 I do indeed see that the column names are replaced by numeric values:\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 1\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 3\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 4\u00a0\u00a0\u00a0\u00a0\u00a0\n\n0\u00a0\u00a0\u00a0\u00a0 0.826852\u00a0\u00a0\u00a0 2891.36\u00a0 0.825862\u00a0\u00a0\u00a0\u00a0\u00a0 123.62\u00a0\u00a0 0.00\u00a0\u00a0\u00a0\n\n1\u00a0\u00a0\u00a0\u00a0 0.656996\u00a0\u00a0\u00a0 7227.10\u00a0 0.000000\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0.00\u00a0\u00a0\u00a0 0.00\u00a0\u00a0\u00a0\u00a0\u00a0\n\n2\u00a0\u00a0\u00a0\u00a0 0.011852\u00a0\u00a0\u00a0 1498.00\u00a0 0.000000\u00a0 \u00a0\u00a0\u00a065.25\u00a0\u00a0\u00a0\u00a0 0.00\n\n\u00a0\n\n\u00a0\n\nSo it seems I\u2019m getting the same prediction because everything is predicted on NaN-values.\n\n\u00a0\n\nIn Scikit-learn the order of the column is used so this should not be a problem. However, in H2O, the column names are used.\n\nSo I don\u2019t see how I can score my H2O-model properly? Am I missing something?\u00a0\n\n\n\n\nkind regards\n\nTomasz",
        "Answers":[
            {
                "Answer_creation_time":"2019-05-24T07:22:01",
                "Answer_body":"Anyone with any thoughts?\n\n\nDid someone ever try running an H2O model with the pyfunc.predict?\u00a0\nBecause I don't see how this feature can work..\n\n\ngreets\nTomasz\n\nOp donderdag 16 mei 2019 14:32:59 UTC+2 schreef tomasz2:\n\ue5d3"
            },
            {
                "Answer_creation_time":"2019-05-24T13:37:08",
                "Answer_body":"Hey Tomasz. Yes this is a known limitation of spark_udf. It relies on pandas udf under the hood and that means the column names are lost. This should be fixed soon-ish with updates coming to spark but for now you would need to do some workaround. The easiest solution is to use a custom pyfunc model wrapper which would set column names to expected values before calling h2o.\n\n\nYou can do something like this:\n\n\n```\nclass H2OPyFuncWrapper(mlflow.pyfunc.PythonModel):\n\n\u00a0 \u00a0 def __init__(self, column_names):\n\u00a0 \u00a0 \u00a0 \u00a0 self.column_names = column_names\n\n\u00a0 \u00a0 def load_context(self, context):\n\u00a0 \u00a0 \u00a0 \u00a0 self.wrapped_model = mlflow.pyfunc.load_pyfunc(context[\"wrapped_model\"])\n\n\n\u00a0 \u00a0 def predict(self, context, model_input):\n\u00a0 \u00a0 \u00a0 \u00a0 pandas_df = pandas_df.copy(deep=False)\n\u00a0 \u00a0 \u00a0 \u00a0 pandas_df.columns = list(self.column_names)\n\u00a0 \u00a0 \u00a0 \u00a0 return self.wrapped_model.predict(pandas_df)\n\n\ndef log_model(path_to_h2o_model_artifact, env = mlflow.h2o.DEFAULT_CONDA_ENV):\n\u00a0 \u00a0 mlflow.pyfunc.log_model(artifact_path=\"wrapped_h2o_model\",\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 python_model=H2OModelPyFuncWrapper(column_names = column_names),\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 artifacts={\"wrapped_model\": path_to_model_artifact},\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 conda_env=env)\n\n```\n\n\n\n\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/3649ddcc-30a7-45f0-9fb7-f2bd8f7f68e2%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            },
            {
                "Answer_creation_time":"2019-05-28T04:34:58",
                "Answer_body":"Hi Tomas,\n\n\nthanks for the feedback!\n\n\nCurious for the spark updates. In the meanwhile we'll be using the work-around.\u00a0\n\n\n\n\n\ngreets\nTomasz\n\n\nOp vrijdag 24 mei 2019 19:37:08 UTC+2 schreef Tomas Nykodym:\n\ue5d3\n\ue5d3\n\ue5d3\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow...@googlegroups.com.\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"Feedback Welcome: dropping Python 2 support in MLflow 1.8.0",
        "Question_creation_date":"2020-03-01T19:57:27",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/fMRrlEdZHos",
        "Question_answer_count":1,
        "Question_view_count":10,
        "Question_body":"Hi all,\n\nThis github issue\u00a0contains a proposal for dropping Python 2 support in MLflow 1.8.0, with a target release date of end-of-March, 2020.\n\n\nThis move will help reduce MLflow's ongoing maintenance burden, and we believe it makes sense given that Python 2 is EOL & many other ML libraries (pandas, numpy, sklearn, tensorflow) have already dropped support.\n\n\nPlease review the issue & leave questions or comments - barring major concerns, we'll publish a formal announcement the week of March 8 - thanks!",
        "Answers":[
            {
                "Answer_creation_time":"2020-03-06T16:45:33",
                "Answer_body":"Just a final ping on this, thanks all for your feedback!\n\n\nHaven't heard any blocking issues\/commentary related to this - barring new input, will go ahead & publish the announcement next week.\n\nThank you!\nSid\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"System Tags",
        "Question_creation_date":"2020-11-10T04:15:34",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/kecHfSKU8eY",
        "Question_answer_count":5,
        "Question_view_count":14,
        "Question_body":"Hey there,\n\n\nThe documentation includes reference to a list of system tags that are said to be automatically set.\nhttps:\/\/www.mlflow.org\/docs\/latest\/tracking.html#system-tags\n\n\n\nHowever, in my flows I see no trace of these tags in the UI as well as in the programmatic interface. Is there a flag I need to set to have this automatic tagging? Or are these values available for me to tag my flows manually?\n\n\nThanks,\nAvi",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-10T04:30:55",
                "Answer_body":"OK I took a deep dive into the code and I think that the issue is that I'm creating the run using the `MlflowClient.create_run` method, and that seems to not include the automatic tags. Opening an issue on github\n\ue5d3"
            },
            {
                "Answer_creation_time":"2020-11-10T07:00:01",
                "Answer_body":"OK scratch that. I tried logging with the simple way (`with mlflow.start_run`...) and still these values are not logged. So back to the original question :)\n\ue5d3"
            },
            {
                "Answer_creation_time":"2020-11-10T11:05:08",
                "Answer_body":"Yes, those system tags reserved for internal use in MLflow. They are not displayed as part of the \"Tags\" in the UI. Rather, they\u00a0\nare displayed in the Run's page as, for example, user, filename, git version, etc.\n\n\nAre you trying to overwrite them or reset them with your own values?\u00a0\n\n\n\n\n\n\u2013\u2013\n\nThe Best Ideas are Simple\n\nJules S. Damji\n\nSr. Developer Advocate\n\nDatabricks, Inc.\n\nju...@databricks.com\n\n(510) 304-7686\n\n\n\n\n\n\n\n\n\n\n\u00a0\u00a0\u00a0\n\n\n\n\n\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/b672ed79-6825-4eaa-85c1-b5fd5aebcab1n%40googlegroups.com."
            },
            {
                "Answer_creation_time":"2020-11-10T18:45:27",
                "Answer_body":"Hey Jules,\n\n\nI'm just trying to read these values instead of logging them myself, to make my code simpler. Is there way to read these values?\n\ue5d3"
            },
            {
                "Answer_creation_time":"2020-11-10T18:59:07",
                "Answer_body":"Yes, you can fetch all MLflow tags from the RunInfo's data.tags property values. Check this code where you can fetch the tags. Here I'm excluding them. Do the\nopposite, and you can retch only startswith(\"mlflow\").\n\n\nhttps:\/\/github.com\/dmatrix\/mlflow-tests\/blob\/master\/py\/mlflow\/apis\/client\/search_runs.py\n\n\ntags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n\n\n\n\nHope that\u00a0helps\n\n\n\n\ncheers\n\nJules\n\n\ue5d3\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"MLflow project error",
        "Question_creation_date":"2021-10-07T07:03:46",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/9yeEpSWsoFc",
        "Question_answer_count":0,
        "Question_view_count":25,
        "Question_body":"Hi Team, there is an error although all my tries, I could not resolve it. I also posted the problem in StackOverflow and our slack channel.\n\nThe description of the error:\n\u00a0\nI want to implement the MLFlow project on my own ML model. However, I am getting \"Could not find main among entry points\"\n\nThe full problem with source files published on StackOverflow.\n\nhttps:\/\/stackoverflow.com\/questions\/69479488\/hi-i-am-very-new-to-mlflow-and-want-to-implement-mlflow-project-on-my-own-ml-m\n\nAny comments are more than welcome.\nBest Regards,\nNihad Shukur",
        "Answers":[

        ]
    },
    {
        "Question_title":"Unable to load Spark model",
        "Question_creation_date":"2019-11-28T22:34:37",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/IjZxr890xlY",
        "Question_answer_count":1,
        "Question_view_count":12,
        "Question_body":"Hi, I have saved my pyspark pipelines with mlflow. The pipelines includes several custom transformers.\u00a0\n\n\nWhen i tried to load the pipeline with\u00a0model=mlflow.spark.load_model(\"location of model on local\"), it is giving me the error as below:\n```AttributeError: module '__main__' has no attribute 'AgeCalc'``` and 'AgeCalc' is one of the name of my custom transformer.\u00a0\n\n\nAny idea how to fix this?",
        "Answers":[
            {
                "Answer_creation_time":"2019-11-28T23:32:51",
                "Answer_body":"error message is as below:\n2019\/11\/29 12:31:06 INFO mlflow.spark: File '\/mnt\/disk1\/project\/mlflow_preprocess1\/sparkml' not found on DFS. Will attempt to upload the file.\n2019\/11\/29 12:31:07 INFO mlflow.spark: Copied SparkML model to \/tmp\/mlflow\/73a2a40c-941f-47da-a8cf-b398b9c91586\nTraceback (most recent call last):\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u00a0\n\u00a0 File \"<stdin>\", line 1, in <module>\n\u00a0 File \"\/home\/davidooi\/.conda\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/spark.py\", line 417, in load_model\n\u00a0 \u00a0 return _load_model(model_uri=model_uri, dfs_tmpdir=dfs_tmpdir)\n\u00a0 File \"\/home\/davidooi\/.conda\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/spark.py\", line 378, in _load_model\n\u00a0 \u00a0 return PipelineModel.load(model_path)\n\u00a0 File \"\/usr\/lib\/spark-current\/python\/pyspark\/ml\/util.py\", line 362, in load\n\u00a0 \u00a0 return cls.read().load(path)\n\u00a0 File \"\/usr\/lib\/spark-current\/python\/pyspark\/ml\/pipeline.py\", line 244, in load\n\u00a0 \u00a0 uid, stages = PipelineSharedReadWrite.load(metadata, self.sc, path)\n\u00a0 File \"\/usr\/lib\/spark-current\/python\/pyspark\/ml\/pipeline.py\", line 378, in load\n\u00a0 \u00a0 stage = DefaultParamsReader.loadParamsInstance(stagePath, sc)\n\u00a0 File \"\/usr\/lib\/spark-current\/python\/pyspark\/ml\/util.py\", line 611, in loadParamsInstance\n\u00a0 \u00a0 py_type = DefaultParamsReader.__get_class(pythonClassName)\n\u00a0 File \"\/usr\/lib\/spark-current\/python\/pyspark\/ml\/util.py\", line 539, in __get_class\n\u00a0 \u00a0 m = getattr(m, comp)\n\ue5d3\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"MLflow 1.27.0 released, including new MLflow Pipelines component!",
        "Question_creation_date":"2022-06-28T23:57:22",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/7H5WdbTpuYk",
        "Question_answer_count":0,
        "Question_view_count":25,
        "Question_body":"We are very excited to announce the availability of\u00a0MLflow\u00a01.27.0!\n\n\n\n\nMLflow 1.27.0 includes several major features and improvements:\n\n[Pipelines] With MLflow 1.27.0, we are excited to announce the release of\nMLflow Pipelines, an opinionated framework for\nstructuring MLOps workflows that simplifies and standardizes machine learning application development\nand productionization. MLflow Pipelines makes it easy for data scientists to follow best practices\nfor creating production-ready ML deliverables, allowing them to focus on developing excellent models.\nMLflow Pipelines also enables ML engineers and DevOps teams to seamlessly deploy models to production\nand incorporate them into applications. To get started with MLflow Pipelines, check out the documentation at\nhttps:\/\/mlflow.org\/docs\/latest\/pipelines.html. (#6115)\n\n[UI] Introduce UI support for searching and comparing runs across multiple Experiments (#5971,\u00a0@r3stl355)\n\nMore features:\n\n[Tracking] When using batch logging APIs, automatically split large sets of metrics, tags, and params into multiple requests (#6052,\u00a0@nzw0301)\n[Tracking] When an Experiment is deleted, SQL-based backends also move the associate Runs to the \"deleted\" lifecycle stage (#6064,\u00a0@AdityaIyengar27)\n[Tracking] Add support for logging single-element\u00a0ndarray\u00a0and tensor instances as metrics via the\u00a0mlflow.log_metric()\u00a0API (#5756,\u00a0@ntakouris)\n[Models] Add support for\u00a0CatBoostRanker\u00a0models to the\u00a0mlflow.catboost\u00a0flavor (#6032,\u00a0@danielgafni)\n[Models] Integrate SHAP's\u00a0KernelExplainer\u00a0with\u00a0mlflow.evaluate(), enabling model explanations on categorical data (#6044,\u00a0#5920,\u00a0@WeichenXu123)\n[Models] Extend\u00a0mlflow.evaluate()\u00a0to automatically log the\u00a0score()\u00a0outputs of scikit-learn models as metrics (#5935,\u00a0#5903,\u00a0@WeichenXu123)\n\nBug fixes and documentation updates:\n\n[UI] Fix broken model links in the Runs table on the MLflow Experiment Page (#6014,\u00a0@hctpbl)\n[Tracking\/Installation] Require\u00a0sqlalchemy>=1.4.0\u00a0upon MLflow installation, which is necessary for usage of SQL-based MLflow Tracking backends (#6024,\u00a0@sniafas)\n[Tracking] Fix a regression that caused\u00a0mlflow server\u00a0to reject\u00a0LogParam\u00a0API requests containing empty string values (#6031,\u00a0@harupy)\n[Tracking] Fix a failure in scikit-learn autologging that occurred when\u00a0matplotlib\u00a0was not installed on the host system (#5995,\u00a0@fa9r)\n[Tracking] Fix a failure in TensorFlow autologging that occurred when training models on\u00a0tf.data.Dataset\u00a0inputs (#6061,\u00a0@dbczumar)\n[Artifacts] Address artifact download failures from SFTP locations that occurred due to mismanaged concurrency (#5840,\u00a0@rsundqvist)\n[Models] Fix a bug where MLflow Models did not restore bundled code properly if multiple models use the same code module name (#5926,\u00a0@BFAnas)\n[Models] Address an issue where\u00a0mlflow.sklearn.model()\u00a0did not properly restore bundled model code (#6037,\u00a0@WeichenXu123)\n[Models] Fix a bug in\u00a0mlflow.evaluate()\u00a0that caused input data objects to be mutated when evaluating certain scikit-learn models (#6141,\u00a0@dbczumar)\n[Models] Fix a failure in\u00a0mlflow.pyfunc.spark_udf\u00a0that occurred when the UDF was invoked on an empty RDD partition (#6063,\u00a0@WeichenXu123)\n[Models] Fix a failure in\u00a0mlflow models build-docker\u00a0that occurred when\u00a0env-manager=local\u00a0was specified (#6046,\u00a0@bneijt)\n[Projects] Improve robustness of the git repository check that occurs prior to MLflow Project execution (#6000,\u00a0@dkapur17)\n[Projects] Address a failure that arose when running a Project that does not have a\u00a0master\u00a0branch (#5889,\u00a0@harupy)\n[Docs] Correct several typos throughout the MLflow docs (#5959,\u00a0@ryanrussell)\n\nFor a comprehensive list of changes, see the\u00a0release change log, and check out the latest documentation on\u00a0mlflow.org.",
        "Answers":[

        ]
    },
    {
        "Question_title":"Load any model.pkl file into mlflow format",
        "Question_creation_date":"2019-10-10T06:46:22",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/fgEmXcVn6Kg",
        "Question_answer_count":1,
        "Question_view_count":29,
        "Question_body":"I have some models pre trained that I want to deploy using mlflow. My models come from different libraries scikit-learn, boostedTrees, XGBoost etc. I have model.pkl files for these models and I want to load these models and write a wrapper that will save my model in Mflow format. My question is how can I load any model saved in .pkl file format and save it in mlflow format??",
        "Answers":[
            {
                "Answer_creation_time":"2019-10-10T20:18:37",
                "Answer_body":"You can use the pkl files to log a model using mlflow.pyfunc.log_model. I'd recommend reading the documentation\u00a0\n\nhttps:\/\/www.mlflow.org\/docs\/latest\/models.html#python-function-python-function\u00a0and\u00a0https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.pyfunc.html.\n\n\n\nYou'll need to write your own loader\u00a0functions matching that load the pkld object along with providing any wrapper code for data transformation as the inference API of the function returned by the loader function must support the interface\n\n\npredict(model_input: pandas.DataFrame) -> [numpy.ndarray | pandas.Series | pandas.DataFrame]\n\n\nFor scikit-learn there's built-in support with\u00a0https:\/\/www.mlflow.org\/docs\/latest\/python_api\/mlflow.sklearn.html#mlflow.sklearn.log_model; you could reload the pkld model and then resave it using mlflow.sklearn.log_model.\n\n\n\n\n\n\nOn Thu, Oct 10, 2019 at 3:46 AM babar ali <bac...@gmail.com> wrote:\n\nI have some models pre trained that I want to deploy using mlflow. My models come from different libraries scikit-learn, boostedTrees, XGBoost etc. I have model.pkl files for these models and I want to load these models and write a wrapper that will save my model in Mflow format. My question is how can I load any model saved in .pkl file format and save it in mlflow format??\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/dd2e1c2f-d75d-4dc1-99ad-e826eb74a0e5%40googlegroups.com."
            }
        ]
    },
    {
        "Question_title":"Adding ONNX flavor -- issue with python version during CI",
        "Question_creation_date":"2019-04-15T15:57:31",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/baS8WpeJ2JQ",
        "Question_answer_count":2,
        "Question_view_count":17,
        "Question_body":"Hi all,\u00a0\n\n\nI submitted a PR for supporting ONNX flavor in Mlflow (source code: https:\/\/github.com\/avflor\/mlflow\/tree\/onnx).\u00a0\n\n\nONNX only supports Python 3 and not 2.\u00a0\nMy PR consists on an mlflow\/onnx.py file and tests\/onnx\/test_onnx_model_export.py.\u00a0\n\n\nI have some issues when testing through Travis.\nI have managed to successfully exclude the tests when testing with Python 2.* version but I have trouble with the main onnx.py file.\nIn this file, I import onnx and onnxmltools packages, but these imports fail on Python 2 (as expected).\n\n\nI added the following lines in the file:\n\n\nimport sys\nif sys.version_info <= (3, 6):\n\u00a0\u00a0\u00a0 print('Requires Python 3.6')\n\u00a0\u00a0\u00a0 sys.exit(1)\nimport os\nimport yaml\u00a0\n\n\n...more imports...\n\n\n\n\nbut then lint.sh fails with the following errors:\u00a0\nmlflow\/onnx.py:9:1: E402 module level import not at top of file\n\nWhat is the best way to exclude a module in the main code based on python version?\n\nThanks,\nAvrilia",
        "Answers":[
            {
                "Answer_creation_time":"2019-04-19T12:07:38",
                "Answer_body":"Hi all,\n\n\nAny suggestion for this? I would really like to proceed with the PR but I'm stuck on this issue during CI.\n\n\nThanks,\nAvrilia\n\n\ue5d3"
            },
            {
                "Answer_creation_time":"2019-04-19T12:16:39",
                "Answer_body":"Hi Avrilia,\u00a0\n\nIt's possible to selectively disable lint & conditionally run tests in CI for cases like this one - generally we try to have feature parity between Python 2 & 3 but for something like ONNX that only works in Python 2, it could make sense to only test against Python 2. Left a comment\/suggestion on the PR, hope that helps!\n\n\nSid\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/b1832314-ba37-4dc6-bd4a-fb2a60ee7455%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            }
        ]
    },
    {
        "Question_title":"Get artifact with authentication",
        "Question_creation_date":"2018-11-30T02:51:37",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/1RdBm4j3GMU",
        "Question_answer_count":1,
        "Question_view_count":28,
        "Question_body":"I have setup Authentication for MLflow v0.8 by NGinx. But when I access artifact page of model in MLflow UI, I received error:\n\n\n\n\n\nI have seen that mlflow get artifact by \"\/get-artifact\" request followed by:\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/v0.8.0\/mlflow\/server\/js\/src\/components\/artifact-view-components\/ShowArtifactPage.js#L42\n\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/v0.8.0\/mlflow\/server\/js\/src\/components\/artifact-view-components\/ShowArtifactTextView.js#L60\n\n\n\nHow could I get artifact with authentication ?",
        "Answers":[
            {
                "Answer_creation_time":"2018-12-02T14:58:00",
                "Answer_body":"How did you configure your nginx proxy, and how did you authenticate to get to the main page to begin with? It should work the same way for the nested page. Maybe your authentication is only set to apply on a certain path or something like that.\n\nMatei\n\n\n> On Nov 29, 2018, at 11:51 PM, Tri\u1ebft Nguy\u1ec5n <peter...@gmail.com> wrote:\n>\n> I have setup Authentication for MLflow v0.8 by NGinx. But when I access artifact page of model in MLflow UI, I received error:\n>\n\n> <MLflow.png>\n>\n>\n> I have seen that mlflow get artifact by \"\/get-artifact\" request followed by:\n> https:\/\/github.com\/mlflow\/mlflow\/blob\/v0.8.0\/mlflow\/server\/js\/src\/components\/artifact-view-components\/ShowArtifactPage.js#L42\n> https:\/\/github.com\/mlflow\/mlflow\/blob\/v0.8.0\/mlflow\/server\/js\/src\/components\/artifact-view-components\/ShowArtifactTextView.js#L60\n>\n> How could I get artifact with authentication ?\n>\n\n> --\n> You received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\n> To unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\n> To post to this group, send email to mlflow...@googlegroups.com.\n> To view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/8c425b88-0799-4db1-9ec2-20186db19575%40googlegroups.com.\n> For more options, visit https:\/\/groups.google.com\/d\/optout.\n> <MLflow.png>"
            }
        ]
    },
    {
        "Question_title":"Using mlflow.models.FlavorBackend(config, **kwargs)",
        "Question_creation_date":"2019-06-12T02:12:17",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/mjlgu0lDAJM",
        "Question_answer_count":1,
        "Question_view_count":13,
        "Question_body":"Hi,\nI am trying to use\u00a0mlflow.models.FlavorBackend(config,\u00a0**kwargs) to serve the model from python. What should be the values of config and what all params do we need to specify? Any kind of help would be appreciated.",
        "Answers":[
            {
                "Answer_creation_time":"2019-06-12T12:04:46",
                "Answer_body":"Hi Shevy,\n\nThere currently is no Python API for serving models - however you can use the\u00a0mlflow models serve\u00a0CLI (see docs via mlflow models serve --help to serve your Python model. If you have a use case for programmatically launching a model server from within some Python code, we'd be happy to discuss it at\u00a0https:\/\/github.com\/mlflow\/mlflow\/issues.\n\nThanks,\nSid\n\n\nOn Tue, Jun 11, 2019 at 11:12 PM Shevy Mittal <shevy....@gslab.com> wrote:\n\nHi,\nI am trying to use\u00a0mlflow.models.FlavorBackend(config,\u00a0**kwargs) to serve the model from python. What should be the values of config and what all params do we need to specify? Any kind of help would be appreciated.\n\n\nConfidentiality Notice and Disclaimer: This email (including any attachments) contains information that may be confidential, privileged and\/or copyrighted. If you are not the intended recipient, please notify the sender immediately and destroy this email. Any unauthorized use of the contents of this email in any manner whatsoever, is strictly prohibited. If improper activity is suspected, all available information may be used by the sender for possible disciplinary action, prosecution, civil claim or any remedy or lawful purpose. Email transmission cannot be guaranteed to be secure or error-free, as information could be intercepted, lost, arrive late, or contain viruses. The sender is not liable whatsoever for damage resulting from the opening of this message and\/or the use of the information contained in this message and\/or attachments. Expressions in this email cannot be treated as opined by the sender company management \u2013 they are solely expressed by the sender unless authorized.\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/f5f38111-b358-4bc6-a77d-739d45d7e642%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            }
        ]
    },
    {
        "Question_title":"mlflow version",
        "Question_creation_date":"2021-05-30T23:34:22",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/cIO3sb6oQx0",
        "Question_answer_count":0,
        "Question_view_count":16,
        "Question_body":"can someone tell me why i'm getting this error\nand when i tried to upgrade mlflw i still get the same error",
        "Answers":[

        ]
    },
    {
        "Question_title":"purging deleted runs (from db and NFS artifacts store)",
        "Question_creation_date":"2019-11-14T00:59:27",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/EtF0x3BuCR8",
        "Question_answer_count":1,
        "Question_view_count":10,
        "Question_body":"Before I write one, I wanted to see if anyone was aware of a script floating around that could be used to permanently remove deleted runs\/experients, both in terms of their records in the DB and any artifacts in the NFS store?",
        "Answers":[
            {
                "Answer_creation_time":"2019-12-09T12:30:48",
                "Answer_body":"I am not aware of any, but I have also felt the need for it and would need to write my own some time soon.\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"Configuring the docker swarm\/cluster in MLflow project",
        "Question_creation_date":"2019-05-20T16:24:02",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/nTDNBIE3g2g",
        "Question_answer_count":0,
        "Question_view_count":17,
        "Question_body":"I am developing an MLflow project. The running environment is docker and needs to be a cluster\/swarm due to data and computation needs.\u00a0\n\nWhat is the recommended way to configure and manage the cluster\/swarm? Specifically, do we need Kubeflow or Kubernetes to manage the docker cluster? Where(at which file in the MLflow project structure) should we configure in MLflow project? Currently, in\u00a0the MLflow docker example on GithHub, there is a place that we can define\n\ndocker_env:\n  image:  mlflow-docker-example\n\n\nShould we define the cluster\/swarm outside MLflow framework, or let MLflow control the cluster or docker swarm?\u00a0\n\n\n\n\nThanks,\n\nBin",
        "Answers":[

        ]
    },
    {
        "Question_title":"Can I build an Azure ML Container Image for an MLflow model which is trained and stored locally on my machine.",
        "Question_creation_date":"2019-09-20T07:23:04",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/k0GuAjkC24k",
        "Question_answer_count":0,
        "Question_view_count":4,
        "Question_body":"Can I build an Azure ML Container Image for an MLflow model which is trained and stored locally on my machine.",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLflow models deployment\/serving",
        "Question_creation_date":"2018-07-18T02:38:40",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/sI7yw-eZxnE",
        "Question_answer_count":0,
        "Question_view_count":56,
        "Question_body":"Hi folks,\n\n\nFew people have checked on easy model deployment method. And Matei also mentioned on Slide 9 in last MLflow meetup.\n\n\nWhat do you folks think of this \"one click\" solution to get your endpoint? See on site: http:\/\/dockai.com\u00a0\nYou can try wine quality example there.\u00a0\n\n\n\nBased on the feedback, we would like to extend and open it up. Feel free to reach out directly to me.\n\n\nThanks,\nHenry",
        "Answers":[

        ]
    },
    {
        "Question_title":"Shared Deployments of MLFlow",
        "Question_creation_date":"2019-09-25T12:20:37",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/mLqqkTBBel0",
        "Question_answer_count":1,
        "Question_view_count":13,
        "Question_body":"Good afternoon,\n\n\n\nAre there any resources available to centralize MLFlow to a dedicated server which can:\n\n\n1) Archive models\n\n2) Host MLFlow web UI\n3) Host deployed model REST API\n\n\n\nIdeally, each model could be secured by groups or individual users, and shared with other groups \/ users.\n\n\n\nDo any existing example deployments exist? I see Databricks appears to have a hosted version of MLFlow per this announcement: https:\/\/mlflow.org\/news\/2019\/09\/10\/MLflow-Community-Edition\/index.html\n\n\nThanks!\n\n\n-Rob",
        "Answers":[
            {
                "Answer_creation_time":"2019-09-25T14:29:54",
                "Answer_body":"Hi Robert.\n\n\n1. In the oss, you can use ``mlflow server`` to start a rest api tracking server. The server will host MLflow web UI and tracking rest api.\u00a0\n2. The tracking server does not store models. The models are stored as artifacts and will be stored depending on where you set the artifact root uri for each experiment.\u00a0\nIf you want the models stored on the tracking server, you would need to be able to access it via one of the supported\u00a0artifact\u00a0store\u00a0apis (e.g.\u00a0 sftp server)\n3. The tracking server does not host deployed models. You can deploy models locally via ``mlflow serve``.\u00a0\n4. Yes, Databricks has a hosted MLFlow and it is also available in the (free) Databricks Community edition, you can\u00a0 try it here\u00a0https:\/\/databricks.com\/try-databricks\n\n\nLet me know if you have any questions.\n\n\nTomas\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/61bf1576-410f-4706-a316-47b0a0669052%40googlegroups.com."
            }
        ]
    },
    {
        "Question_title":"Depploy Mlflow with python wheel and egg file on dat bricks",
        "Question_creation_date":"2022-03-31T01:41:32",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/bKm7IdEuARg",
        "Question_answer_count":0,
        "Question_view_count":8,
        "Question_body":"Hi team,\nI have to deploy the model built on data bricks with mlflow\u00a0\nas python egg and wheel file on data bricks. please let me know the process and share me the resources.\n\n\n\nThanks in advance.\n\n\nRegards,\nNaveen",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLflow 1.16.0 Released!",
        "Question_creation_date":"2021-04-26T22:35:12",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/iCtI31h79PI",
        "Question_answer_count":0,
        "Question_view_count":14,
        "Question_body":"We are happy to announce the availability of\u00a0MLflow 1.16.0!\n\n\nIn addition to bug and documentation fixes, MLflow 1.16.0 includes the following features and improvements:\nAdd\u00a0mlflow.pyspark.ml.autolog()\u00a0API for autologging of\u00a0pyspark.ml\u00a0estimators (#4228,\u00a0@WeichenXu123)\nAdd\u00a0mlflow.catboost.log_model,\u00a0mlflow.catboost.save_model,\u00a0mlflow.catboost.load_model\u00a0APIs for CatBoost model persistence (#2417,\u00a0@harupy)\nEnable\u00a0mlflow.pyfunc.spark_udf\u00a0to use column names from model signature by default (#4236,\u00a0@Loquats)\nAdd\u00a0datetime\u00a0data type for model signatures (#4241,\u00a0@vperiyasamy)\nAdd\u00a0mlflow.sklearn.eval_and_log_metrics\u00a0API that computes and logs metrics for the given scikit-learn model and labeled dataset. (#4218,\u00a0@alkispoly-db)\nFor a comprehensive list of changes, see the\u00a0release change log, and check out the latest documentation on\u00a0mlflow.org.\n\n\nThanks,\nHaru",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLflow Serving",
        "Question_creation_date":"2020-10-19T04:43:51",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/5QBHlQ90OuY",
        "Question_answer_count":0,
        "Question_view_count":31,
        "Question_body":"Hi all, I'm wondering if there is a limit for the curl json requests sent to the served model or not when using Sklearn's Linear Regression within mlflow's pyfunc. I receive an output for messages of about 75 records of input. However, for larger messages, I receive error 52, empty reply from server and I wonder why is that. For other served models I deployed, everything works normally such as custom pyfunc, and randomforests on R.\u00a0\n\n\nThanks a lot for any hints,\nCheers\u00a0\nKarim",
        "Answers":[

        ]
    },
    {
        "Question_title":"Shapash and MLFlow",
        "Question_creation_date":"2021-09-11T17:39:30",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/D4ttV9ONWRA",
        "Question_answer_count":0,
        "Question_view_count":11,
        "Question_body":"Dear all,\nI have a Model which is using shapash LIbray. Do I need any special precompilation to its input values, in order to serve it through MLFlow?",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLflow workflows",
        "Question_creation_date":"2020-02-13T10:09:26",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/w4BGI5qcFzE",
        "Question_answer_count":0,
        "Question_view_count":26,
        "Question_body":"Hi all,\n\n\u00a0\n\nI am new to mlflow and I'd like to ask for MLflow workflows capabilities. In April 2019 (SPARK+AI) two new components were announced for feature releases: MLflow workflows and MLflow Model registry. Afterwards, MLflow Model registry has been added (ver.1.4) but MLflow workflows has not till now (as far as I know). Does anyone know if MLflow workflows will be released and when (in which release)?\n\n\u00a0\n\nThanks,\n\n\u00a0\n\nDimitris",
        "Answers":[

        ]
    },
    {
        "Question_title":"log_artifact not working",
        "Question_creation_date":"2018-08-23T13:43:03",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/vyq2eJqDU0k",
        "Question_answer_count":9,
        "Question_view_count":2390,
        "Question_body":"Hey folks,\n\n\nI got the mlflow ui server set up, and its saving everything except log_artifact.\n\n\nThe server is running mlflow in a docker container with continuum\/miniconda3 as the base image.\n\n\nFrom the command line, I'm launching the server like this:\n\n\n$ mlflow ui -h 0.0.0.0 -p 5000\n\n\nI can see and interact with the data.\n\n\nWhen I try to save the params, metrics and artifacts, I do this:\n\n\n# neumann\nmlflow_server = '52.89....'\n\n# Tracking URI\nmlflow_tracking_URI = 'http:\/\/' + mlflow_server + ':5000'\nprint (\"MLflow Tracking URI: %s\" % (mlflow_tracking_URI))\n\n\n# set tracking URI\nmlflow.set_tracking_uri(mlflow_tracking_URI)\n\n\nwith mlflow.start_run(experiment_id=3):\n\u00a0 \u00a0 mlflow.log_param(\"depth\", 5)\n\u00a0 \u00a0 mlflow.log_metric(\"roc_auc\", 0.8)\n\u00a0 \u00a0 mlflow.log_artifact(local_path='curve.png')\n\nThis is my FileNotFoundError error message:\n\n\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\n<ipython-input-113-f5870bc80ffe> in <module>()\n      2     mlflow.log_param(\"depth\", 5)\n      3     mlflow.log_metric(\"roc_auc\", 0.8)\n----> 4     mlflow.log_artifact(local_path='curve.png')\n\n~\/py3\/lib\/python3.7\/site-packages\/mlflow\/tracking\/fluent.py in log_artifact(local_path, artifact_path)\n    131     \"\"\"Log a local file or directory as an artifact of the currently active run.\"\"\"\n    132     artifact_uri = _get_or_start_run().info.artifact_uri\n--> 133     get_service().log_artifact(artifact_uri, local_path, artifact_path)\n    134 \n    135 \n\n~\/py3\/lib\/python3.7\/site-packages\/mlflow\/tracking\/service.py in log_artifact(self, artifact_uri, local_path, artifact_path)\n    105         :param artifact_path: If provided, will be directory in artifact_uri to write to\"\"\"\n    106         artifact_repo = ArtifactRepository.from_artifact_uri(artifact_uri, self.store)\n--> 107         artifact_repo.log_artifact(local_path, artifact_path)\n    108 \n    109     def log_artifacts(self, artifact_uri, local_dir, artifact_path=None):\n\n~\/py3\/lib\/python3.7\/site-packages\/mlflow\/store\/local_artifact_repo.py in log_artifact(self, local_file, artifact_path)\n     14             if artifact_path else self.artifact_uri\n     15         if not exists(artifact_dir):\n---> 16             mkdir(artifact_dir)\n     17         shutil.copy(local_file, artifact_dir)\n     18 \n\n~\/py3\/lib\/python3.7\/site-packages\/mlflow\/utils\/file_utils.py in mkdir(root, name)\n     99             return target\n    100     except OSError as e:\n--> 101         raise e\n    102 \n    103 \n\n~\/py3\/lib\/python3.7\/site-packages\/mlflow\/utils\/file_utils.py in mkdir(root, name)\n     96     try:\n     97         if not exists(target):\n---> 98             os.mkdir(target)\n     99             return target\n    100     except OSError as e:\n\nFileNotFoundError: [Errno 2] No such file or directory: '\/mlruns\/3\/1053b732c0a14d6cb8c07ee4320fd781\/artifacts'\n\n\n\nWhen I look at the filesystem, everything is saving except artifacts:\n\n\n~\/mlruns\/3$ tree\n.\n\u251c\u2500\u2500 5dcd18160aa74e6e8e405a6257a13177\n\u2502 \u00a0 \u251c\u2500\u2500 artifacts\n\u2502 \u00a0 \u251c\u2500\u2500 meta.yaml\n\u2502 \u00a0 \u251c\u2500\u2500 metrics\n\u2502 \u00a0 \u2502 \u00a0 \u2514\u2500\u2500 roc_auc\n\u2502 \u00a0 \u2514\u2500\u2500 params\n\u2502 \u00a0 \u00a0 \u00a0 \u2514\u2500\u2500 depth\n\n\nAny suggestions?\n\n\nThanks!\nFranklin",
        "Answers":[
            {
                "Answer_creation_time":"2018-08-23T13:49:48",
                "Answer_body":"\"mlflow ui\" is actually not suitable to be run on a remote server, you should be using \"mlflow server\" to let you specify further options. Either way, the problem you are running into is that the \"--default-artifact-root\" is \"\/mlruns\", which differs between the server and client.\n\nPlease take a look at this section of the docs:\nhttps:\/\/mlflow.org\/docs\/latest\/tracking.html#running-a-tracking-server\n\n\n\n(and for a more complete explanation of the problem, see the highlighted \"Important\" section there)\n\n\n\ue5d3\n\ue5d3\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users+unsubscribe@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/1db93876-9c50-4c3d-94e9-04d67f0165e6%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            },
            {
                "Answer_creation_time":"2018-08-23T21:42:54",
                "Answer_body":"Thank you! That fixed it.\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\n\ue5d3"
            },
            {
                "Answer_creation_time":"2018-09-04T00:55:47",
                "Answer_body":"Looks like I am also facing the same issue even after taking care of the suggested solution. Not sure what am I missing.\n\n\n1. Started MLFlow Server on a RHEL 6.10 server (say server 1) using the following command. I have specified two different locations for default-artifact-root and file-store.\n\n\n$ cd\u00a0 \/home\/arnab\/mlflow_install\n$ mlflow server --host 0.0.0.0 --port 8090 --default-artifact-root \/home\/arnab\/artifact_location\/ --file-store \/home\/arnab\/file_store_location\/\n\n\nMLFlow starts successfully.\n\n\n2. From Server 2, conda environment, I tried to execute the \"mlflow\/example\/tutorial\/train.py\". However, I have added the following code so that it uses MLFlow server. Please note, while creating the experiment, I have NOT added \"artifact_location\".\u00a0\n\n\nmlflow.set_tracking_uri(\"http:\/\/<Server_1_IP>:8090\")\nexp_id = mlflow.create_experiment(\"Yet Another Sklearn wine experiment\")\n......\nwith mlflow.start_run(experiment_id = exp_id):\n\t.........\n\u00a0 \u00a0 # Log parameter, metrics, and model to MLflow\n\u00a0 \u00a0 mlflow.log_param(\"alpha\", alpha)\n\u00a0 \u00a0 mlflow.log_param(\"l1_ratio\", l1_ratio)\n\u00a0 \u00a0 mlflow.log_metric(\"rmse\", rmse)\n\u00a0 \u00a0 mlflow.log_metric(\"r2\", r2)\n\u00a0 \u00a0 mlflow.log_metric(\"mae\", mae)\n\n\n\u00a0 \u00a0 mlflow.sklearn.log_artifacts(lr, \"model\")\n\t\nOn executing the code, mlflow.sklearn.log_model fails with the following stack trace. However, the params and metrics got saved at MLFlow server and are visible through mlflow ui.\n\n\n---------------------------------------------------------------------------\nFileNotFoundError\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0Traceback (most recent call last)\n<ipython-input-5-4c49cbe9b70c> in <module>()\n----> 1 train(0.5, 0.5)\n\n\n<ipython-input-4-ec3e6c2563bd> in train(in_alpha, in_l1_ratio)\n\u00a0 \u00a0 \u00a073\u00a0 \u00a0 \u00a0 \u00a0 \u00a0mlflow.log_metric(\"mae\", mae)\n\u00a0 \u00a0 \u00a074\u00a0\n---> 75\u00a0 \u00a0 \u00a0 \u00a0 \u00a0mlflow.sklearn.log_artifacts(lr, \"model\")\n\n\n~\/anaconda3\/envs\/python-skl\/lib\/python3.7\/site-packages\/mlflow\/tracking\/fluent.py in log_artifacts(local_dir, artifact_path)\n\u00a0 \u00a0 135\u00a0 \u00a0 \u00a0\"\"\"Log all the contents of a local directory as artifacts of the run.\"\"\"\n\u00a0 \u00a0 136\u00a0 \u00a0 \u00a0artifact_uri = _get_or_start_run().info.artifact_uri\n--> 137\u00a0 \u00a0 \u00a0get_service().log_artifacts(artifact_uri, local_dir, artifact_path)\n\u00a0 \u00a0 138\u00a0\n\u00a0 \u00a0 139\u00a0\n\n\n~\/anaconda3\/envs\/python-skl\/lib\/python3.7\/site-packages\/mlflow\/tracking\/service.py in log_artifacts(self, artifact_uri, local_dir, artifact_path)\n\u00a0 \u00a0 113\u00a0 \u00a0 \u00a0 \u00a0 \u00a0:param artifact_path: If provided, will be directory in artifact_uri to write to\"\"\"\n\u00a0 \u00a0 114\u00a0 \u00a0 \u00a0 \u00a0 \u00a0artifact_repo = ArtifactRepository.from_artifact_uri(artifact_uri, self.store)\n--> 115\u00a0 \u00a0 \u00a0 \u00a0 \u00a0artifact_repo.log_artifacts(local_dir, artifact_path)\n\u00a0 \u00a0 116\u00a0\n\u00a0 \u00a0 117\u00a0 \u00a0 \u00a0def set_terminated(self, run_id, status=None, end_time=None):\n\n\n~\/anaconda3\/envs\/python-skl\/lib\/python3.7\/site-packages\/mlflow\/store\/local_artifact_repo.py in log_artifacts(self, local_dir, artifact_path)\n\u00a0 \u00a0 \u00a021\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0if artifact_path else self.artifact_uri\n\u00a0 \u00a0 \u00a022\u00a0 \u00a0 \u00a0 \u00a0 \u00a0if not exists(artifact_dir):\n---> 23\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0mkdir(artifact_dir)\n\u00a0 \u00a0 \u00a024\u00a0 \u00a0 \u00a0 \u00a0 \u00a0dir_util.copy_tree(src=local_dir, dst=artifact_dir)\n\u00a0 \u00a0 \u00a025\u00a0\n\n\n~\/anaconda3\/envs\/python-skl\/lib\/python3.7\/site-packages\/mlflow\/utils\/file_utils.py in mkdir(root, name)\n\u00a0 \u00a0 \u00a099\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0return target\n\u00a0 \u00a0 100\u00a0 \u00a0 \u00a0except OSError as e:\n--> 101\u00a0 \u00a0 \u00a0 \u00a0 \u00a0raise e\n\u00a0 \u00a0 102\u00a0\n\u00a0 \u00a0 103\u00a0\n\n\n~\/anaconda3\/envs\/python-skl\/lib\/python3.7\/site-packages\/mlflow\/utils\/file_utils.py in mkdir(root, name)\n\u00a0 \u00a0 \u00a096\u00a0 \u00a0 \u00a0try:\n\u00a0 \u00a0 \u00a097\u00a0 \u00a0 \u00a0 \u00a0 \u00a0if not exists(target):\n---> 98\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0os.mkdir(target)\n\u00a0 \u00a0 \u00a099\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0return target\n\u00a0 \u00a0 100\u00a0 \u00a0 \u00a0except OSError as e:\n\n\nFileNotFoundError: [Errno 2] No such file or directory: '\/home\/arnab\/artifact_location\/1\/365b8fd4692d47f8bc611ab3c5cfce24\/artifacts\/model'\n\n\nFollowing is the detail of the directory related to the experiment (at Server 1). There is no file or directory created under \"default-artifact-root\" location:\n\n\n$ pwd\n\/home\/arnab\/artifact_location\n$ ls\n$\n\n\nThe artifact directory is under \"file-store\" location, but, there is no \"model\" directory under artifacts.\n\n\n$ pwd\n\/home\/arnab\/file_store_location\/1\/365b8fd4692d47f8bc611ab3c5cfce24\n$ ls\nartifacts\u00a0 meta.yaml\u00a0 metrics\u00a0 params\n\n\nPlease let me know if I am missing anything.\n\n\nI have tried various combinations with \"default-artifact-root\" and create_experiment locations. But, no success.\u00a0\n\n\nThanks,\nArnab\n\ue5d3"
            },
            {
                "Answer_creation_time":"2018-09-04T05:05:57",
                "Answer_body":"Well.... from this (https:\/\/github.com\/mlflow\/mlflow\/issues\/212) issue, I understood that the artifact location should be a NFS mounting shared by both client and serve). I was not sure about the \"client and server sharing\" portion of it and hence assuming a local directory\/path at the server would be considered as a valid location. My bad!\n\n\nIn between, I tried to use the SFTP option for artifact location and encountered with several issues:\n\n\n1. I started the MLFLow server in the following way:\n\n\nmlflow server --host 0.0.0.0 --port 8090 --default-artifact-root sftp:\/\/arnab@<Server_3>:2222\/home\/arnab\/artifact_location --file-store \/home\/arnab\/file_store_location\/\n\n\nServer 3 is different from Server_1 (Where MLFlow Server is running) and Server 2 (Where client code is running). Also note I am using a custom SFTP port (2222) here.\u00a0\n\n\n2. First issue is I got the following error message which seems to be due to a bug in paramiko with Python 3.7 (https:\/\/github.com\/paramiko\/paramiko\/issues\/1108 , https:\/\/github.com\/unbit\/sftpclone\/issues\/26, ). Paramiko version needs to be bumped for this (https:\/\/github.com\/paramiko\/paramiko\/commit\/0e0b2b87b547d97860ccf5962ad030df640b692f).\n\n\n\u00a0 \u00a0 \u00a0 ................................\n\u00a0 \u00a0 \u00a0 File \"\/home\/arnab\/.conda\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/server\/handlers.py\", line 198, in _list_artifacts\n\u00a0 \u00a0 \u00a0 \u00a0 artifact_entities = _get_artifact_repo(run).list_artifacts(path)\n\u00a0 \u00a0 \u00a0 File \"\/home\/arnab\/.conda\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/server\/handlers.py\", line 249, in _get_artifact_repo\n\u00a0 \u00a0 \u00a0 \u00a0 return ArtifactRepository.from_artifact_uri(run.info.artifact_uri, store)\n\u00a0 \u00a0 \u00a0 File \"\/home\/arnab\/.conda\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact_repo.py\", line 82, in from_artifact_uri\n\u00a0 \u00a0 \u00a0 \u00a0 return SFTPArtifactRepository(artifact_uri)\n\u00a0 \u00a0 \u00a0 File \"\/home\/arnab\/.conda\/envs\/mlflow\/lib\/python3.7\/site-packages\/mlflow\/store\/sftp_artifact_repo.py\", line 26, in __init__\n\u00a0 \u00a0 \u00a0 \u00a0 import pysftp\n\u00a0 \u00a0 \u00a0 File \"\/home\/arnab\/.conda\/envs\/mlflow\/lib\/python3.7\/site-packages\/pysftp\/__init__.py\", line 12, in <module>\n\u00a0 \u00a0 \u00a0 \u00a0 import paramiko\n\u00a0 \u00a0 \u00a0 File \"\/home\/arnab\/.conda\/envs\/mlflow\/lib\/python3.7\/site-packages\/paramiko\/__init__.py\", line 31, in <module>\n\u00a0 \u00a0 \u00a0 \u00a0 from paramiko.transport import SecurityOptions, Transport\n\u00a0 \u00a0 \u00a0 File \"\/home\/arnab\/.conda\/envs\/mlflow\/lib\/python3.7\/site-packages\/paramiko\/transport.py\", line 70, in <module>\n\u00a0 \u00a0 \u00a0 \u00a0 from paramiko.sftp_client import SFTPClient\n\u00a0 \u00a0 \u00a0 File \"\/home\/arnab\/.conda\/envs\/mlflow\/lib\/python3.7\/site-packages\/paramiko\/sftp_client.py\", line 43, in <module>\n\u00a0 \u00a0 \u00a0 \u00a0 from paramiko.sftp_file import SFTPFile\n\u00a0 \u00a0 \u00a0 File \"\/home\/arnab\/.conda\/envs\/mlflow\/lib\/python3.7\/site-packages\/paramiko\/sftp_file.py\", line 68\n\u00a0 \u00a0 \u00a0 \u00a0 self._close(async=True)\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ^\n\u00a0 \u00a0 SyntaxError: invalid syntax\n\n\n3. On resolving that, I started getting the following error. This is because of the fact that paramiko does not handle custom ports (https:\/\/bitbucket.org\/dundeemt\/pysftp\/issues\/106\/no-hostkey-for-host). I was able to handle by following the work around mentioned here:\n\"A workaround available to users, assuming that they don't also use the same server on the standard port, is to copy the entry in known_hosts and put it in again labeled with only host.\"\n\u00a0 \u00a0 \u00a0...........................\n\u00a0 \u00a0 ~\/anaconda3\/envs\/python-skl\/lib\/python3.7\/site-packages\/mlflow\/store\/artifact_repo.py in from_artifact_uri(artifact_uri, store)\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a080\u00a0 \u00a0 \u00a0 \u00a0 \u00a0elif artifact_uri.startswith(\"sftp:\/\"):\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a081\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0from mlflow.store.sftp_artifact_repo import SFTPArtifactRepository\n\u00a0 \u00a0 ---> 82\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0return SFTPArtifactRepository(artifact_uri)\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a083\u00a0 \u00a0 \u00a0 \u00a0 \u00a0elif artifact_uri.startswith(\"dbfs:\/\"):\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a084\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0from mlflow.store.dbfs_artifact_repo import DbfsArtifactRepository\n\n\n\u00a0 \u00a0 ~\/anaconda3\/envs\/python-skl\/lib\/python3.7\/site-packages\/mlflow\/store\/sftp_artifact_repo.py in __init__(self, artifact_uri, client)\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a047\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0self.config['private_key'] = user_config['identityfile'][0]\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a048\u00a0\n\u00a0 \u00a0 ---> 49\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0self.sftp = pysftp.Connection(**self.config)\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a050\u00a0\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a051\u00a0 \u00a0 \u00a0 \u00a0 \u00a0super(SFTPArtifactRepository, self).__init__(artifact_uri)\n\n\n\u00a0 \u00a0 ~\/anaconda3\/envs\/python-skl\/lib\/python3.7\/site-packages\/pysftp\/__init__.py in __init__(self, host, username, private_key, password, port, private_key_pass, ciphers, log, cnopts, default_path)\n\u00a0 \u00a0 \u00a0 \u00a0 130\u00a0 \u00a0 \u00a0 \u00a0 \u00a0# check that we have a hostkey to verify\n\u00a0 \u00a0 \u00a0 \u00a0 131\u00a0 \u00a0 \u00a0 \u00a0 \u00a0if self._cnopts.hostkeys is not None:\n\u00a0 \u00a0 --> 132\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0self._tconnect['hostkey'] = self._cnopts.get_hostkey(host)\n\u00a0 \u00a0 \u00a0 \u00a0 133\u00a0\n\u00a0 \u00a0 \u00a0 \u00a0 134\u00a0 \u00a0 \u00a0 \u00a0 \u00a0self._sftp_live = False\n\n\n\u00a0 \u00a0 ~\/anaconda3\/envs\/python-skl\/lib\/python3.7\/site-packages\/pysftp\/__init__.py in get_hostkey(self, host)\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a069\u00a0 \u00a0 \u00a0 \u00a0 \u00a0kval = self.hostkeys.lookup(host)\u00a0 # None|{keytype: PKey}\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a070\u00a0 \u00a0 \u00a0 \u00a0 \u00a0if kval is None:\n\u00a0 \u00a0 ---> 71\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0raise SSHException(\"No hostkey for host %s found.\" % host)\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a072\u00a0 \u00a0 \u00a0 \u00a0 \u00a0# return the pkey from the dict\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a073\u00a0 \u00a0 \u00a0 \u00a0 \u00a0return list(kval.values())[0]\n\n\n\u00a0 \u00a0 SSHException: No hostkey for host <IP_Address> found.\n\n\nI am still encountering issues with SFTP and custom port (most probably because of my set up), but thought of composing of this email first (before I start forgetting things :-))\n\n\nThanks,\nArnab\n\ue5d3"
            },
            {
                "Answer_creation_time":"2018-09-04T14:04:55",
                "Answer_body":"Thanks for the detailed investigation. If you have an NFS mount, that should work if and only if it's the same path on the client and server, which you might be able to fake by using symlinks\/remounting.\n\n\nFor the first SFTP issue you mentioned with paramiko, good catch -- we should probably publish the versions of the dependent libraries we've tested against (e.g., paramiko and pysftp versions) for each artifact store, and make them available like \"pip install mlflow[sftp]\", similar to Airflow.\n\n\nRegarding the problems with getting a non-default port to work, unfortunately I too have little experience with this artifactory. I CC'd Toon, who wrote the initial SFTP artifactory, in case he has any experience with this.\n\n\n\ue5d3\n\ue5d3\n\ue5d3\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users+unsubscribe@googlegroups.com.\n\nTo post to this group, send email to mlflow...@googlegroups.com.\n\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/f8e0ca2b-e295-49c4-84a5-d843b905e5fd%40googlegroups.com.\n\ue5d3"
            },
            {
                "Answer_creation_time":"2018-09-04T14:12:05",
                "Answer_body":"Oops, Toon's Github email does not seem to point anywhere, so a response is unlikely :)\n\ue5d3"
            },
            {
                "Answer_creation_time":"2018-09-05T02:31:18",
                "Answer_body":"Hi Aaron,\n\n\nUnderstood. Thank you for clarifying.\u00a0\n\n\nI was able to make SFTP work and that gave me an idea about how MLFlow Server remote artifact storage work.\u00a0\n\n\n[Aaron]\u00a0\u00a0If you have an NFS mount, that should work if and only if it's the same path on the client and server, which you might be able to fake by using symlinks\/remounting.\n[Arnab] Should not this be clearly documented?\u00a0\n\n\nFor the other two issues, do you want me to raise bugs at github?\n\n\nThanks,\nArnab\u00a0\n\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3"
            },
            {
                "Answer_creation_time":"2018-09-05T11:31:51",
                "Answer_body":"Yes, please do. We should probably explicitly document NFS in the Storage section here:\u00a0https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/docs\/source\/tracking.rst\n\n\n\ue5d3\n\ue5d3\n\ue5d3\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users+unsubscribe@googlegroups.com.\n\nTo post to this group, send email to mlflow...@googlegroups.com.\n\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/c76fb621-db55-41c5-95ef-afee78993170%40googlegroups.com.\n\ue5d3"
            },
            {
                "Answer_creation_time":"2018-09-07T04:58:21",
                "Answer_body":"I have raised the following two issues:\n\n\nhttps:\/\/github.com\/mlflow\/mlflow\/issues\/446\nhttps:\/\/github.com\/mlflow\/mlflow\/issues\/447\n\n\nFor correcting the documentation, should we re-open :\u00a0https:\/\/github.com\/mlflow\/mlflow\/issues\/212?\n\n\nThanks,\nArnab\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"How to delete previously logged metrics?",
        "Question_creation_date":"2022-06-23T12:46:34",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/e35ItjNDE20",
        "Question_answer_count":0,
        "Question_view_count":17,
        "Question_body":"It am aware its quite easy to add metrics to an old experiment with\n\n\n```\nwith mlflow.start_run(run_id=some_old_run_id) as run:\n\u00a0 \u00a0 mlflow.log_metric(k,v)\n```\nHowever, I was wondering if we could delete metrics as well?\n\n\nWe have some old experiments that used the incorrect key convention and we want to delete old keys\/value pairs from the jsonb column.",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLflow 0.8.0 released!",
        "Question_creation_date":"2018-11-12T16:47:10",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/TgR6lSe4gfA",
        "Question_answer_count":1,
        "Question_view_count":17,
        "Question_body":"MLflow 0.8.0 has been released: https:\/\/github.com\/mlflow\/mlflow\/releases\/tag\/v0.8.0\n\n\nMLflow 0.8.0 introduces several major features:\n\n\n- Dramatically improved UI for comparing experiment run results (grouping columns, showing nested runs, using run names instead of ids, and persisting table state)\n- Support for deploying models as Docker containers directly to Azure Machine Learning Service Workspace (as opposed to the previously-recommended solution of Azure ML Workbench)\n\n\nIn addition to these features, there are a host of improvements and bugfixes to the REST API, R API, Python API, tracking UI, and documentation.",
        "Answers":[
            {
                "Answer_creation_time":"2018-11-12T17:45:38",
                "Answer_body":"Congrats to the MLflow team!\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/CAGnzRon1A-v-2LeutZzFK%2ByJUvdqhZwyAEie6142ugMBt%2BmD3A%40mail.gmail.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            }
        ]
    },
    {
        "Question_title":"Train and deploy H2O model using MLFlow spark",
        "Question_creation_date":"2019-10-29T01:05:54",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/RJBzJjxPl0w",
        "Question_answer_count":1,
        "Question_view_count":9,
        "Question_body":"Hi,\n\n\nI want to train and deploy a h2o model using mlfow spark as mentioned in the diagram:\u00a0https:\/\/res.infoq.com\/presentations\/mlflow-databricks\/en\/slides\/sl21-1566324281761.jpg\nI am training the model using below link:\nhttps:\/\/docs.databricks.com\/_static\/notebooks\/h2o-sparkling-water-python.html\nThen after training when I try to deploy the model using mlflow spark, it throws an error \"MLFlow can only save descendants of pyspark.ml.Model which implement MLReadable and MLWritable\".\nCan anyone help and let me know what I am doing wrong.",
        "Answers":[
            {
                "Answer_creation_time":"2019-11-28T22:22:06",
                "Answer_body":"If you are unable to save due to custom transformer maybe you can check this\u00a0saving spark custom transformer\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"Using MLflow and Sagemaker with preprocessing steps",
        "Question_creation_date":"2022-07-20T08:12:24",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/I7LdK_7KCIw",
        "Question_answer_count":1,
        "Question_view_count":17,
        "Question_body":"I'm deploying my models to Sagemaker using MLflow integration. However, my ML pipeline includes some basic preprocessing steps, such as scalers, and I need it to be part of my inference endpoint. Is there a way to do that with MLflow? I looked in the\u00a0mlflow_pyfunc\u00a0is closer to what I want, but I'm not sure if it is compatible with Sagemaker.",
        "Answers":[
            {
                "Answer_creation_time":"2022-07-20T12:31:38",
                "Answer_body":"Yes, you can add preprocessing or post processing\u00a0steps around a logged MLflow model and then re-log the new extended pipeline model as a new wrapped MLflow model. Then this new MLflow model should work the same way as the original model with the additional functionality of doing pre\/post processing.\nAnd it should work in Sagemaker as well. Let me know if you have any further questions.\n\n\nYong\nhttps:\/\/www.linkedin.com\/in\/yongliu\/\n\n\n\nOn Wed, Jul 20, 2022 at 5:12 AM 'Paulo Vasconcellos' via mlflow-users <mlflow...@googlegroups.com> wrote:\n\nI'm deploying my models to Sagemaker using MLflow integration. However, my ML pipeline includes some basic preprocessing steps, such as scalers, and I need it to be part of my inference endpoint. Is there a way to do that with MLflow? I looked in the\u00a0mlflow_pyfunc\u00a0is closer to what I want, but I'm not sure if it is compatible with Sagemaker.\n\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/213752ed-f2d3-4ae2-ac4f-03492769799fn%40googlegroups.com."
            }
        ]
    },
    {
        "Question_title":"Custom Tags to MLflow registry",
        "Question_creation_date":"2021-10-01T03:07:05",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/ADNSwAemjAw",
        "Question_answer_count":0,
        "Question_view_count":14,
        "Question_body":"Hi Team,\n\n\nI am looking to add custom tags to a model registered in mlflow registry via python api. I am able to add tags from the UI but unable to find an api to do it programmatically.\u00a0\u00a0\nThe set_tag api only allows to add tags to a run and those tags are not being taken forward when the model is registered. Please help.\n\n\nThank you,\nJagdeesh R",
        "Answers":[

        ]
    },
    {
        "Question_title":"Tracking URI",
        "Question_creation_date":"2021-05-21T07:46:42",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/kJOp3qmaqdI",
        "Question_answer_count":3,
        "Question_view_count":11,
        "Question_body":"Hello Community\n\n\nI am trying to save and register only the last 5 runs and one older run among the 20 runs registered is there a way to delete it all at once instead of using the ui\n\n\n\n\nRegards,\nAarthi",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-21T07:54:52",
                "Answer_body":"If you know the run_ids you can use the api to deleted them:\u00a0https:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.delete_run\n\n\n[mlflow.delete_run(run_id) for run_id in run_ids]\n\n\nHope that helps\u00a0\n\n\nCheers\nJules\u00a0\n\n\nSent from my iPhone\nPardon the dumb thumb typos :)\n\n\nOn May 21, 2021, at 4:46 AM, k.aarthi alagammai <aarthial...@gmail.com> wrote:\n\n\n\ufeffHello Community\n\n\nI am trying to save and register only the last 5 runs and one older run among the 20 runs registered is there a way to delete it all at once instead of using the ui\n\n\n\n\nRegards,\nAarthi\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/38d78ed7-053f-41f7-9470-004c2f4003a2n%40googlegroups.com."
            },
            {
                "Answer_creation_time":"2021-05-21T09:22:31",
                "Answer_body":"Is it possible to dowithout the run id's using specific tags like production?\n\ue5d3"
            },
            {
                "Answer_creation_time":"2021-05-21T09:59:24",
                "Answer_body":"Runs are unique have unique ids; tags are not. You can set same tag Foo two different runs.\u00a0\n\n\nThe API for delete only takes run_ids. You can use search runs with tags and other attributes.\u00a0\n\n\nhttps:\/\/mlflow.org\/docs\/latest\/python_api\/mlflow.html#mlflow.search_runs\n\n\nCheers\nJules\u00a0\n\n\nSent from my iPhone\nPardon the dumb thumb typos :)\n\n\nOn May 21, 2021, at 6:22 AM, k.aarthi alagammai <aarthial...@gmail.com> wrote:\n\n\n\ufeffIs it possible to dowithout the run id's using specific tags like production?\n\ue5d3\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/c9a92be9-a427-458a-8632-5de382cdb3f5n%40googlegroups.com."
            }
        ]
    },
    {
        "Question_title":"[RFC] Extended Search and Pagination functionality",
        "Question_creation_date":"2019-05-08T13:55:29",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/IdVF99MAgyM",
        "Question_answer_count":0,
        "Question_view_count":8,
        "Question_body":"Overview\n\nSearch is one of the most used APIs in MLflow to read logged experiment and run data. As organizations and projects scale and an increasing number of ML runs are logged, users have a need to severely limit the search results returned. In addition to selecting specific rows, there may be needs to limit the number of parameters, metrics, tags, and run attributes returned with searches. In cases where a large number of runs are produced from a search, there is a need to paginate the results at server-side and return only a limited set of runs at a time.\n\nIn this RFC, we present proposals to extend search functionality for advanced use cases along with some optimizations. We also discuss proposed solution for server-side pagination of results.\n\n\n\nRequest for comment\n\nFull RFC for these 2 features is in this google doc\u00a0(which has comment access). We are looking forward to your feedback directly in this document.Thank you!\n\n\n\n\nMani Parkhe\n\nma...@databricks.com",
        "Answers":[

        ]
    },
    {
        "Question_title":"Using SQL to log params",
        "Question_creation_date":"2020-01-16T16:01:21",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/7dnPPx5tXSk",
        "Question_answer_count":3,
        "Question_view_count":17,
        "Question_body":"Hi,\n\n\nThis is probably a stupid question, but as far as I have seen mlflow does not allow to log params in a SQL databse. Am I right?\nIf so, what is the main reason for that? Is that due to the fact that through the project the number of parameters might increase largely?\n\n\nAlso, I'm currently running computations on a compute server that I access through ssh from my laptop. The loggings happen on that machine. I then download to my laptop the mlruns folder and I have to run a script I wrote to update the yaml files so that they point to the right artifact location on my laptop. That's not much of a hassle but is there a better way to do that? I cannot run the http server through mlflow serve as I am not allowed to do that on the compute server I use.\n\n\nThanks.",
        "Answers":[
            {
                "Answer_creation_time":"2020-01-16T19:38:15",
                "Answer_body":"You can point mlflow at a database to track your runs. Is that what you mean?\nhttps:\/\/www.mlflow.org\/docs\/latest\/tracking.html#where-runs-are-recorded\n\n\n\nYou can point to any external tracking server from your instance, rather than log them locally and transfer. Of course that means running a tracking server (or database).\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/a67816ae-550c-4f8a-b3fb-12f2dfb8a683%40googlegroups.com."
            },
            {
                "Answer_creation_time":"2020-01-22T15:05:55",
                "Answer_body":"Hi Sean,\n\n\nApologies for the late reply, I think I need to reorganize my emails a bit...\u00a0\nThanks for the link I'll take a look. Basically I'm logging a lot of parameters, and I'd like to be able to use the full SQL syntax in the MLFlow UI (currently I think this is a limited version, for example 'OR' doesn't work).\n\n\nYou mean I'd set up my laptop as the tracking server? That could work, but I'd have to leave my laptop running the server whenever I do the computations on the compute server I guess. I'll think of it thanks a lot!\n\n\nBest,\nArthur\n\ue5d3"
            },
            {
                "Answer_creation_time":"2020-01-22T15:30:26",
                "Answer_body":"As I understand, you could connect any tracking server (on your laptop, in the cloud) to any supported database (local, cloud) as long as the one can see the other. So the DB backend could apply anywhere.\n\n\nYes you can query the results in the UI no matter what the backend it, with the syntax documented at\u00a0https:\/\/www.mlflow.org\/docs\/latest\/search-syntax.html\u00a0Yes it's fairly simple. To implement 'or' for example, I guess you could programmatically query it twice or something and combine the results.\n\n\nDo you mean you want to query the raw mlflow results directly with SQL? I bet you could, if you are having mlflow log to a database, but I'm not sure the schema is documented or fixed. It may however be easy enough to figure it out by browsing.\n\n\n(I don't know a lot about this, so others will have better info)\n\n\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"MLFLOW project run from artifactory (s3)",
        "Question_creation_date":"2019-06-28T09:47:07",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/CJQN4zxO7ZE",
        "Question_answer_count":0,
        "Question_view_count":14,
        "Question_body":"I am testing MLFLOW; MLFLOW runs in docker container, artifactory is in MINIO ( runs in its own docker container); backend store is in Postgres ( runs in its own docker container). I run my experiments in Jupiter notebook ( runs in its own docker container). After I run an experiment, I can see artifacts located in MINIO S3 bucket - MLModel, conda.yml and model.pkl files. How do I create a project and run it? I have to created MLProject file, do I create it locally and specify full path to the artifacts (s3 full path)?",
        "Answers":[

        ]
    },
    {
        "Question_title":"Reproducible runs with Mlflow Projects Problem Authenticating databrics",
        "Question_creation_date":"2019-09-30T06:22:25",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/GzWFU13yNoc",
        "Question_answer_count":1,
        "Question_view_count":10,
        "Question_body":"I am running the tutorial\u00a0https:\/\/docs.databricks.com\/applications\/mlflow\/projects.html#prerequisites\nto create an experiement in databrics and run an MLflow project from my local machine. I have setup the databrics cli authentication and MLFLOW_TRACKING_URI=databrics\n\n\nWhen I run the command\u00a0mlflow\u00a0run\u00a0examples\/sklearn_elasticnet_wine\/\u00a0-b\u00a0databricks\u00a0-c\u00a0clusterspec.json\u00a0--experiment-id\u00a03914263189079640\u00a0-P\u00a0alpha=0.5\n\n\nI get the following error\n2019\/09\/30\u00a015:15:36\u00a0ERROR\u00a0mlflow.utils.rest_utils:\u00a0API\u00a0request\u00a0to\u00a0https:\/\/westeurope.azuredatabricks.net\/?o=7680777384243007\/api\/2.0\/mlflow\/runs\/create\u00a0failed\u00a0with\u00a0code\u00a0500\u00a0!=\u00a0200,\u00a0retrying\u00a0up\u00a0to\u00a02\u00a0more\u00a0times.\u00a0API\u00a0response\u00a0body:\u00a0<html>\n<head>\n<meta\u00a0http-equiv=\"Content-Type\"\u00a0content=\"text\/html;charset=ISO-8859-1\"\/>\n<title>Error\u00a0500\u00a0<\/title>\n<\/head>\n<body>\n<h2>HTTP\u00a0ERROR:\u00a0500<\/h2>\n<p>Problem\u00a0accessing\u00a0\/login.html.\u00a0Reason:\n<pre>\u00a0\u00a0\u00a0\u00a0java.lang.NumberFormatException:\u00a0For\u00a0input\u00a0string:\u00a0&quot;7680777384243007\/api\/2.0\/mlflow\/runs\/create&quot;<\/pre><\/p>\n<hr\u00a0\/>\n<\/body>\n<\/html>\n\n\n2019\/09\/30\u00a015:15:40\u00a0ERROR\u00a0mlflow.utils.rest_utils:\u00a0API\u00a0request\u00a0to\u00a0https:\/\/westeurope.azuredatabricks.net\/?o=7680777384243007\/api\/2.0\/mlflow\/runs\/create\u00a0failed\u00a0with\u00a0code\u00a0500\u00a0!=\u00a0200,\u00a0retrying\u00a0up\u00a0to\u00a01\u00a0more\u00a0times.\u00a0API\u00a0response\u00a0body:\u00a0<html>\n<head>\n<meta\u00a0http-equiv=\"Content-Type\"\u00a0content=\"text\/html;charset=ISO-8859-1\"\/>\n<title>Error\u00a0500\u00a0<\/title>\n<\/head>\n<body>\n<h2>HTTP\u00a0ERROR:\u00a0500<\/h2>\n<p>Problem\u00a0accessing\u00a0\/login.html.\u00a0Reason:\n<pre>\u00a0\u00a0\u00a0\u00a0java.lang.NumberFormatException:\u00a0For\u00a0input\u00a0string:\u00a0&quot;7680777384243007\/api\/2.0\/mlflow\/runs\/create&quot;<\/pre><\/p>\n<hr\u00a0\/>\n<\/body>\n<\/html>\n\n\n2019\/09\/30\u00a015:15:44\u00a0ERROR\u00a0mlflow.utils.rest_utils:\u00a0API\u00a0request\u00a0to\u00a0https:\/\/westeurope.azuredatabricks.net\/?o=7680777384243007\/api\/2.0\/mlflow\/runs\/create\u00a0failed\u00a0with\u00a0code\u00a0500\u00a0!=\u00a0200,\u00a0retrying\u00a0up\u00a0to\u00a00\u00a0more\u00a0times.\u00a0API\u00a0response\u00a0body:\u00a0<html>\n<head>\n<meta\u00a0http-equiv=\"Content-Type\"\u00a0content=\"text\/html;charset=ISO-8859-1\"\/>\n<title>Error\u00a0500\u00a0<\/title>\n<\/head>\n<body>\n<h2>HTTP\u00a0ERROR:\u00a0500<\/h2>\n<p>Problem\u00a0accessing\u00a0\/login.html.\u00a0Reason:\n<pre>\u00a0\u00a0\u00a0\u00a0java.lang.NumberFormatException:\u00a0For\u00a0input\u00a0string:\u00a0&quot;7680777384243007\/api\/2.0\/mlflow\/runs\/create&quot;<\/pre><\/p>\n<hr\u00a0\/>\n<\/body>\n<\/html>\n\n\nTraceback\u00a0(most\u00a0recent\u00a0call\u00a0last):\n\u00a0\u00a0File\u00a0\"\/root\/mlflow\/new-venv\/bin\/mlflow\",\u00a0line\u00a010,\u00a0in\u00a0<module>\n\u00a0\u00a0\u00a0\u00a0sys.exit(cli())\n\u00a0\u00a0File\u00a0\"\/root\/mlflow\/new-venv\/lib\/python3.5\/site-packages\/click\/core.py\",\u00a0line\u00a0764,\u00a0in\u00a0__call__\n\u00a0\u00a0\u00a0\u00a0return\u00a0self.main(*args,\u00a0**kwargs)\n\u00a0\u00a0File\u00a0\"\/root\/mlflow\/new-venv\/lib\/python3.5\/site-packages\/click\/core.py\",\u00a0line\u00a0717,\u00a0in\u00a0main\n\u00a0\u00a0\u00a0\u00a0rv\u00a0=\u00a0self.invoke(ctx)\n\u00a0\u00a0File\u00a0\"\/root\/mlflow\/new-venv\/lib\/python3.5\/site-packages\/click\/core.py\",\u00a0line\u00a01137,\u00a0in\u00a0invoke\n\u00a0\u00a0\u00a0\u00a0return\u00a0_process_result(sub_ctx.command.invoke(sub_ctx))\n\u00a0\u00a0File\u00a0\"\/root\/mlflow\/new-venv\/lib\/python3.5\/site-packages\/click\/core.py\",\u00a0line\u00a0956,\u00a0in\u00a0invoke\n\u00a0\u00a0\u00a0\u00a0return\u00a0ctx.invoke(self.callback,\u00a0**ctx.params)\n\u00a0\u00a0File\u00a0\"\/root\/mlflow\/new-venv\/lib\/python3.5\/site-packages\/click\/core.py\",\u00a0line\u00a0555,\u00a0in\u00a0invoke\n\u00a0\u00a0\u00a0\u00a0return\u00a0callback(*args,\u00a0**kwargs)\n\u00a0\u00a0File\u00a0\"\/root\/mlflow\/new-venv\/lib\/python3.5\/site-packages\/mlflow\/cli.py\",\u00a0line\u00a0137,\u00a0in\u00a0run\n\u00a0\u00a0\u00a0\u00a0run_id=run_id\n\u00a0\u00a0File\u00a0\"\/root\/mlflow\/new-venv\/lib\/python3.5\/site-packages\/mlflow\/projects\/__init__.py\",\u00a0line\u00a0266,\u00a0in\u00a0run\n\u00a0\u00a0\u00a0\u00a0use_conda=use_conda,\u00a0storage_dir=storage_dir,\u00a0synchronous=synchronous,\u00a0run_id=run_id)\n\u00a0\u00a0File\u00a0\"\/root\/mlflow\/new-venv\/lib\/python3.5\/site-packages\/mlflow\/projects\/__init__.py\",\u00a0line\u00a094,\u00a0in\u00a0_run\n\u00a0\u00a0\u00a0\u00a0active_run\u00a0=\u00a0_create_run(uri,\u00a0experiment_id,\u00a0work_dir,\u00a0entry_point)\n\u00a0\u00a0File\u00a0\"\/root\/mlflow\/new-venv\/lib\/python3.5\/site-packages\/mlflow\/projects\/__init__.py\",\u00a0line\u00a0622,\u00a0in\u00a0_create_run\n\u00a0\u00a0\u00a0\u00a0active_run\u00a0=\u00a0tracking.MlflowClient().create_run(experiment_id=experiment_id,\u00a0tags=tags)\n\u00a0\u00a0File\u00a0\"\/root\/mlflow\/new-venv\/lib\/python3.5\/site-packages\/mlflow\/tracking\/client.py\",\u00a0line\u00a088,\u00a0in\u00a0create_run\n\u00a0\u00a0\u00a0\u00a0tags=[RunTag(key,\u00a0value)\u00a0for\u00a0(key,\u00a0value)\u00a0in\u00a0iteritems(tags)]\n\u00a0\u00a0File\u00a0\"\/root\/mlflow\/new-venv\/lib\/python3.5\/site-packages\/mlflow\/store\/rest_store.py\",\u00a0line\u00a0153,\u00a0in\u00a0create_run\n\u00a0\u00a0\u00a0\u00a0response_proto\u00a0=\u00a0self._call_endpoint(CreateRun,\u00a0req_body)\n\u00a0\u00a0File\u00a0\"\/root\/mlflow\/new-venv\/lib\/python3.5\/site-packages\/mlflow\/store\/rest_store.py\",\u00a0line\u00a062,\u00a0in\u00a0_call_endpoint\n\u00a0\u00a0\u00a0\u00a0host_creds=host_creds,\u00a0endpoint=endpoint,\u00a0method=method,\u00a0json=json_body)\n\u00a0\u00a0File\u00a0\"\/root\/mlflow\/new-venv\/lib\/python3.5\/site-packages\/mlflow\/utils\/rest_utils.py\",\u00a0line\u00a059,\u00a0in\u00a0http_request\n\u00a0\u00a0\u00a0\u00a0(url,\u00a0retries))\nmlflow.exceptions.MlflowException:\u00a0API\u00a0request\u00a0to\u00a0https:\/\/westeurope.azuredatabricks.net\/?o=7680777384243007\/api\/2.0\/mlflow\/runs\/create\u00a0failed\u00a0to\u00a0return\u00a0code\u00a0200\u00a0after\u00a03\u00a0tries",
        "Answers":[
            {
                "Answer_creation_time":"2019-09-30T13:43:05",
                "Answer_body":"Hi\u00a0Babar,\n\n\nI was unable to reproduce your issue against. For Databricks related issues, would you please file a ticket through\u00a0https:\/\/help.databricks.com\/s\/\u00a0and be sure to include information like which version of MLflow and what operating\u00a0system you are using?\n\n\nCheers,\nPaul\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/5cd78837-be67-4fbf-884d-d37ad39554b2%40googlegroups.com."
            }
        ]
    },
    {
        "Question_title":"MLflow 1.30.0 release",
        "Question_creation_date":"2022-10-20T18:24:02",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/h0AobjGBZ6Q",
        "Question_answer_count":0,
        "Question_view_count":9,
        "Question_body":"We are happy to announce the availability of MLflow 1.30.0!\n\nMLflow 1.30.0 includes several major features and improvements\n\nFeatures:\n[Pipelines] Introduce hyperparameter tuning support to MLflow Pipelines (#6859, @prithvikannan)\n[Pipelines] Introduce support for prediction outlier comparison to training data set (#6991, @jinzhang21)\n[Pipelines] Introduce support for recording all training parameters for reproducibility (#7026, #7094, @prithvikannan)\n[Pipelines] Add support for Delta tables as a datasource in the ingest step (#7010, @sunishsheth2009)\n[Pipelines] Add expanded support for data profiling up to 10,000 columns (#7035, @prithvikanna)\n[Pipelines] Add support for AutoML in MLflow Pipelines using FLAML (#6959, @mshtelma)\n[Pipelines] Add support for simplified transform step execution by allowing for unspecified configuration (#6909, @Apurva Koti)\n[Pipelines] Introduce a data preview tab to the transform step card (#7033, @prithvikannan)\n[Tracking] Introduce run_name attribute for create_run, get_run and update_run APIs (#6782, #6798 @Apurva Koti)\n[Tracking] Add support for searching by creation_time and last_update_time for the search_experiments API (#6979, @harupy)\n[Tracking] Add support for search terms run_id IN and run ID NOT IN for the search_runs API (#6945, @harupy)\n[Tracking] Add support for searching by user_id and end_time for the search_runs API (#6881, #6880 @subramaniam02)\n[Tracking] Add support for searching by run_name and run_id for the search_runs API (#6899, @harupy; #6952, @alexacole)\n[Tracking] Add support for synchronizing run name attribute and mlflow.runName tag (#6971, @BenWilson2)\n[Tracking] Add support for signed tracking server requests using AWSSigv4 and AWS IAM (#7044, @pdifranc)\n[Tracking] Introduce the update_run() API for modifying the status and name attributes of existing runs (#7013, @gabrielfu)\n[Tracking] Add support for experiment deletion in the mlflow gc cli API (#6977, @shaikmoeed)\n[Models] Add support for environment restoration in the evaluate() API (#6728, @jerrylian-db)\n[Models] Remove restrictions on binary classification labels in the evaluate() API (#7077, @dbczumar)\n[Scoring] Add support for BooleanType to mlflow.pyfunc.spark_udf() (#6913, @BenWilson2)\n[SQLAlchemy] Add support for configurable Pool class options for SqlAlchemyStore (#6883, @mingyu89)\n\nBug fixes:\n[Pipelines] Enable Pipeline subprocess commands to create a new SparkSession if one does not exist (#6846, @prithvikannan)\n[Pipelines] Fix a rendering issue with bool column types in Step Card data profiles (#6907, @sunishsheth2009)\n[Pipelines] Add validation and an exception if required step files are missing (#7067, @mingyu89)\n[Pipelines] Change step configuration validation to only be performed during runtime execution of a step (#6967, @prithvikannan)\n[Tracking] Fix infinite recursion bug when inferring the model schema in mlflow.pyspark.ml.autolog() (#6831, @harupy)\n[UI] Remove the browser error notification when failing to fetch artifacts (#7001, @kevingreer)\n[Models] Allow mlflow-skinny package to serve as base requirement in MLmodel requirements (#6974, @BenWilson2)\n[Models] Fix an issue with code path resolution for loading SparkML models (#6968, @dbczumar)\n[Models] Fix an issue with dependency inference in logging SparkML models (#6912, @BenWilson2)\n[Models] Fix an issue involving potential duplicate downloads for SparkML models (#6903, @Serena Ruan)\n[Models] Add missing pos_label to sklearn.metrics.precision_recall_curve in mlflow.evaluate() (#6854, @dbczumar)\n[SQLAlchemy] Fix a bug in SqlAlchemyStore where set_tag() updates the incorrect tags (#7027, @gabrielfu)\n\nDocumentation updates:\n[Models] Update details regarding the default Keras serialization format (#7022, @balvisio)\n\nFor a comprehensive list of changes, see the release change log, and check out the latest documentation on mlflow.org.",
        "Answers":[

        ]
    },
    {
        "Question_title":"How to backup all MLFlow Tracking and Model Registry data from a Databricks Workspace",
        "Question_creation_date":"2021-01-19T16:13:29",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/Kttrnxcw3C4",
        "Question_answer_count":1,
        "Question_view_count":486,
        "Question_body":"Dear all,\n\n\nI have a few questions, so please bear with me.\n\n\n\nThe MLFlow documentation does not provide any information regarding backups, except here. If I managed my own tracking server, I could make a backup, but how to I achieve this within Databricks?\n\n\npprint([dict(e)[\"artifact_location\"] for e in MlflowClient().list_experiments()])\n\n\nshows that the artifact locations are in dbfs:\/databricks\/mlflow-tracking\/, but these are accessible only with the client ( https:\/\/docs.microsoft.com\/de-de\/azure\/databricks\/security\/access-control\/workspace-acl#mlflow-artifact-permissions ) I had thought about a blunt rsync copy all artifacts, but these would probably be problematic for the model lineage stored in the Registry.\n\n\n\nI was hoping to get an idea of the tracking server inside a Databricks Notebook, with the env variable MLFLOW_TRACKING_URI, but its value is only:\n\nMLFLOW_TRACKING_URI=databricks\n\n3. In short, if I would delete a Databricks Workspace and wanted to have the full Tracking and Model Registry in a new one, how would I go about it?\n\n\nThank you for any help!\n\n\n-Alec",
        "Answers":[
            {
                "Answer_creation_time":"2021-01-20T03:28:54",
                "Answer_body":"I found the answer here: https:\/\/github.com\/amesar\/mlflow-export-import\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to a topic in the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this topic, visit https:\/\/groups.google.com\/d\/topic\/mlflow-users\/Kttrnxcw3C4\/unsubscribe.\nTo unsubscribe from this group and all its topics, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/0a05f049-aaa0-4058-ba7e-1542f59cd754n%40googlegroups.com."
            }
        ]
    },
    {
        "Question_title":"Is it possible to use MLFlow logo on our landing page?",
        "Question_creation_date":"2019-12-16T06:13:56",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/F1YiBxZa1dc",
        "Question_answer_count":2,
        "Question_view_count":23,
        "Question_body":"Hello,\u00a0\n\n\nAt NBT AG, we are currently developing\u00a0a\u00a0deployment and orchestration platform for MLOps. We are planning to make an integration of MLflow for deploying models on edge devices through our platform. Could we use MLflow logo on our landing page already until we actually make that integration?\n\n\nThank you!\n\n\nSimon Bernard",
        "Answers":[
            {
                "Answer_creation_time":"2019-12-16T09:22:06",
                "Answer_body":"I think the general policy that the ASF adopts would be good guidance here too. Referring to a third party project by name or logo by itself is 'fair use'. You just want to avoid implying\u00a0endorsement or that your product 'is' mlflow in some way. I think you can do that by for example having the logo link to the mlflow.org site, and describing it as something like 'powered by mlflow' to make clear it's something separate that is integrated. It wouldn't hurt to mention at (for example) the bottom of the page that logos are trademarked by their respective owners too (see bottom of mlflow.org for example). I think that should be pretty complete IMHO.\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/4b4b29b9-e1ab-428f-8a74-16beb152a96f%40googlegroups.com."
            },
            {
                "Answer_creation_time":"2019-12-16T10:17:49",
                "Answer_body":"Thanks for your answer Sean!\n\n\nOn Monday, 16 December 2019 15:22:06 UTC+1, Sean Owen wrote:\nI think the general policy that the ASF adopts would be good guidance here too. Referring to a third party project by name or logo by itself is 'fair use'. You just want to avoid implying\u00a0endorsement or that your product 'is' mlflow in some way. I think you can do that by for example having the logo link to the mlflow.org site, and describing it as something like 'powered by mlflow' to make clear it's something separate that is integrated. It wouldn't hurt to mention at (for example) the bottom of the page that logos are trademarked by their respective owners too (see bottom of mlflow.org for example). I think that should be pretty complete IMHO.\n\n\nOn Mon, Dec 16, 2019 at 5:13 AM Simon Bernard <simon....@nbt.ag> wrote:\n\nHello,\u00a0\n\n\nAt NBT AG, we are currently developing\u00a0a\u00a0deployment and orchestration platform for MLOps. We are planning to make an integration of MLflow for deploying models on edge devices through our platform. Could we use MLflow logo on our landing page already until we actually make that integration?\n\n\nThank you!\n\n\nSimon Bernard\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\n\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow...@googlegroups.com.\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"MLflow 1.20.2 released!",
        "Question_creation_date":"2021-09-03T21:00:51",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/LO5wYh97kk4",
        "Question_answer_count":0,
        "Question_view_count":15,
        "Question_body":"We are happy to announce the availability of\u00a0MLflow\u00a01.20.2!\n\nMLflow 1.20.2 is a patch release containing the following features and bug fixes:\n\nFeatures:\n\n- Enabled auto dependency inference in spark flavor in autologging (#4759, @harupy)\n\nBug fixes and documentation updates:\n\n- Increased MLflow client HTTP request timeout from 10s to 120s (#4764, @jinzhang21)\n- Fixed autologging compatibility bugs with TensorFlow and Keras version 2.6.0 (#4766, @dbczumar)\n\nSmall bug fixes and doc updates (#4770, @WeichenXu123)\n\nFor a comprehensive list of changes, see the\u00a0release change log, and check out the latest documentation on\u00a0mlflow.org.",
        "Answers":[

        ]
    },
    {
        "Question_title":"Website section \"organizations using MLflow\"",
        "Question_creation_date":"2020-10-30T05:39:40",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/AL3eITG_MP8",
        "Question_answer_count":1,
        "Question_view_count":24,
        "Question_body":"Hi,\n\n\nI am from https:\/\/mlcertific.com which provides the certification on machine learning\u00a0 we are using mlflow in our organisation and want to contribute to it. Please add our organization\u00a0in the list\u00a0 .\n\n\nThanks,\nhttps:\/\/mlcertific.com\/",
        "Answers":[
            {
                "Answer_creation_time":"2020-11-05T14:10:15",
                "Answer_body":"Hello Sweta,\n\n\nWe will add it to the list. Thanks for using MLflow for your certification.\n\n\ncheers\nJules\n\n\n\n\n\n\n\u2013\u2013\n\nThe Best Ideas are Simple\n\nJules S. Damji\n\nSr. Developer Advocate\n\nDatabricks, Inc.\n\nju...@databricks.com\n\n(510) 304-7686\n\n\n\n\n\n\n\n\n\n\n\u00a0\u00a0\u00a0\n\n\n\n\n\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/CAOUcoWx%3D2x-BaMJBq9PkRbko%3DPQ3bnfsSszpZiCPA6RvAS%2BbJQ%40mail.gmail.com."
            }
        ]
    },
    {
        "Question_title":"Upgrade mlflow",
        "Question_creation_date":"2021-06-28T03:13:36",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/CX4PiIGYZiE",
        "Question_answer_count":1,
        "Question_view_count":114,
        "Question_body":"The following error is thrown when I upgrade mlflow from 1.13.1 to 1.18.0\n\n\nalembic.util.exc.CommandError: Can't locate revision identified by 'a8c4a736bde6' mlflow\n\n\n\nWould deleting the alembic version fix the issue or is there any alternate solution?\n\n\nThank you and Warm Regards",
        "Answers":[
            {
                "Answer_creation_time":"2021-06-28T03:36:33",
                "Answer_body":"The issue is resolved - please ignore, I upgraded my mlflow version to the latest which was 1.7.2 in the conda environment from where I was trying to fire mlflow db uprade command\u00a0\u00a0\n\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"Support for Oracle dialect for backend-store-uri",
        "Question_creation_date":"2021-11-12T00:03:52",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/zB-1xLJ6IJk",
        "Question_answer_count":0,
        "Question_view_count":12,
        "Question_body":"Hello,\nDoes anyone knows any way for Oracle database as backend-store-uri\nCurrently, only mysql,\u00a0mssql,\u00a0sqlite, and\u00a0PostgreSQL are supported.\n\n\nRegards,\nNikhil",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLflow-Docker Artifacts Model Not Found",
        "Question_creation_date":"2021-06-28T12:05:19",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/JFdrWyG9vIA",
        "Question_answer_count":0,
        "Question_view_count":28,
        "Question_body":"https:\/\/github.com\/mlflow\/mlflow\/issues\/4487\n\n\n\nHi, I have posted this issue in github, please help me to solve this issue",
        "Answers":[

        ]
    },
    {
        "Question_title":"Doubt regarding MLFlow",
        "Question_creation_date":"2022-05-31T14:56:59",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/s717aOcKwQ0",
        "Question_answer_count":0,
        "Question_view_count":15,
        "Question_body":"Can we do training datasets and feature storing , recurrent model training and deployment pipelines and integration of ML models using MLFlow ?",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLflow 1.0 Release Candidate Process",
        "Question_creation_date":"2019-05-22T11:03:18",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/HIlqey_t2qU",
        "Question_answer_count":0,
        "Question_view_count":36,
        "Question_body":"We\u2019re excited to announce that we\u2019re moving towards MLflow 1.0, with a tentative release date of May 29. In addition to some exciting new features (dramatically improved metric visualizations, metric x coordinates, improved search functionality), MLflow 1.0 offers Python, Java, R, and REST API stability.\n\n\nTo that end, we\u2019ve published an RC of MLflow 1.0, which you can use to try out all the latest 1.0 features. We\u2019d love to get your feedback and fix any issues that arise before the 1.0 release. Please report issues at https:\/\/github.com\/mlflow\/mlflow\/issues.\n\n\nPlease see this document for instructions on how to try out the latest RC:\nhttps:\/\/docs.google.com\/document\/d\/1Hu1y73aR21uDPbuUTBlTfSN7e5tR-9txqk_VHlCnupk\/edit#\n\n\nThanks!",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLFlow integration with Kubeflow",
        "Question_creation_date":"2019-09-06T20:21:57",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/b8WLoMLFtmo",
        "Question_answer_count":2,
        "Question_view_count":30,
        "Question_body":"Hello,\nCan anyone point me to docs that talks about integration of how MLFlow can be integrated to use Kubeflow. As per my understanding by looking at the code of MLFlow, code has to be written to integrate it with Kubeflow. By default support does not exist.\n\n\nPlease advise.\n\n\n-Sid",
        "Answers":[
            {
                "Answer_creation_time":"2019-09-12T18:17:04",
                "Answer_body":"Hi Sid,\n\n\nKubeflow is more of a deployment framework and MLflow is an API you can use in your Python code, so you can just use them side by side. For example, your code running on Kubeflow can connect to an MLflow tracking server to keep track of experiments and models. You can also export MLflow models as Docker containers or load them into Seldon (see\u00a0https:\/\/docs.seldon.io\/projects\/seldon-core\/en\/latest\/examples\/mlflow.html for the latter). One thing missing now is an easy way to deploy the MLflow tracking server itself on Kubernetes, but we\u2019d love to accept that as a contribution (just Helm would be fine for this).\n\n\nMatei\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/8396cb7a-6b9d-4d1e-b0d1-5a122d100353%40googlegroups.com."
            },
            {
                "Answer_creation_time":"2019-09-26T16:22:15",
                "Answer_body":"Matei - Thanks for your insight. Now, it looks like MLFlow has direct integration with Kubernetes:\nCode:\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/projects\/kubernetes.py\n\n\n\nBut it still looks like it is experimental:\nhttps:\/\/mlflow.org\/docs\/latest\/projects.html#kubernetes-execution\n\n\n\nSo, do we still need to use Kubeflow or we can just use MLFlow directly on Kubernetes.\n\n\n-Sid\n\n\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"Multi user on one DB ok?",
        "Question_creation_date":"2020-03-07T16:18:14",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/VQc6nWUNjYM",
        "Question_answer_count":1,
        "Question_view_count":23,
        "Question_body":"When I use tracking directly on a Database (PostgreSQL) would it cause problems when two computer do tracking into the same DB at the same time?\n\n\n\nSame question with MLFlow UI: Is it ok when we connect two UIs from two different computers to one (the same) DB?\n\n\nMy guess is that it is no problem but just want to make sure.\n\n\nThanks\nPhilip",
        "Answers":[
            {
                "Answer_creation_time":"2020-03-07T16:54:42",
                "Answer_body":"When I use tracking directly on a Database (PostgreSQL) would it cause problems when two computers do tracking into the same DB at the same time?\n\n\n\nI don't believe that would be an issue, given that PostgresSQL is a relational DB supporting transactions, and each run has a unique ID; even within an umbrella experiment name, your run will be different from the other person's run on a different computer.\n\n\nSame question with MLFlow UI: Is it ok when we connect two UIs from two different computers to one (the same) DB?\n\n\nThe same idea\n\n\nJules\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/98d2d583-19bf-4198-bc73-ebaefb64cd62%40googlegroups.com."
            }
        ]
    },
    {
        "Question_title":"MLflow 0.6.0 released!",
        "Question_creation_date":"2018-09-10T20:59:17",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/kJz7T4052RM",
        "Question_answer_count":2,
        "Question_view_count":29,
        "Question_body":"MLflow 0.6.0 has been released: https:\/\/github.com\/mlflow\/mlflow\/releases\/tag\/v0.6.0\n\n\nMLflow 0.6.0 introduces several major features:\n\n\n- A Java client API (to be published on Maven within the next day or two)\n- Support for saving and serving SparkML models as MLeap for low-latency serving\n- Support for tagging runs with metadata, during and after the run completion\n- Support for deleting (and restoring deleted) experiments\n\n\nIn addition to these features, there are a host of improvements and bugfixes to the REST API, Python API, tracking UI, and documentation.",
        "Answers":[
            {
                "Answer_creation_time":"2018-09-10T23:21:07",
                "Answer_body":"Congrats to all contributors!\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/CAGnzRok5teZdZwaYyAVho-MFRe0OUSE8TLaKKP3aODwe9eCJcA%40mail.gmail.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            },
            {
                "Answer_creation_time":"2018-09-11T04:04:57",
                "Answer_body":"Congratulations to all of the contributors!\n\n\nOne website problem: when I visit announcement page at https:\/\/mlflow.org\/news\/2018\/08\/24\/0.5.2-release\/ I get\n\n\n\n\u00a0\u00a0 \"This XML file does not appear to have any style information associated with it. The document tree is shown below.\"\n\n\nand the following:\n\n\n<Error>\n\u00a0 <Code>AccessDenied<\/Code>\n\u00a0 <Message>Access Denied<\/Message>\n\u00a0 <RequestId>43FC41ABEE5DDD92<\/RequestId>\n\u00a0 <HostId>+pqcuwYpiZTWNZ2Qhvj\/SJfj6UPnqy76B0laQtqcsxF0Pr0DS4iPEEjrIWssCZPMll9ZtAvGV0Y=<\/HostId>\n<\/Error>\n\n\n\nSimilar for other announcement web pages.\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"MLflow Lightweight Python Client",
        "Question_creation_date":"2022-02-05T05:03:26",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/_QoyNVy60Bs",
        "Question_answer_count":0,
        "Question_view_count":84,
        "Question_body":"Dear MLflow users,\n\nWe actively use MLFlow at MTS as a part of our MLOps platform for experiment tracking and model registry.\n\nFurthermore, I\u2019m happy to say that we started to post on GitHub under Apache 2.0 license some parts of our inhouse development around MLFlow.\n\nLightweight python client for MLflow REST API:\n\nhttps:\/\/github.com\/MobileTeleSystems\/mlflow-rest-client\n\nMain features:\n\nMinimal dependencies\nAll REST API methods and params are exposed to user\nAll methods and classes are documented\n\nFeel free to contribute and\/or open issues on GitHub.\n\nP.S. It would be nice if you add our logo to the \u201cOrganizations using and contributing\u201d section. Website:\u00a0https:\/\/mts.ru\/\n\n\u00a0\n\nBest Regards,\n\nMax Bartenev, CTO\n\nMTS BigData department",
        "Answers":[

        ]
    },
    {
        "Question_title":"Bay Area MLflow Meetup @ Mesoshere",
        "Question_creation_date":"2018-09-20T14:33:58",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/h8MFLcRq11M",
        "Question_answer_count":3,
        "Question_view_count":30,
        "Question_body":"If you can't flow with us in person, do so remotely:\n\n\nMEETUP @ Mesosphere :\u00a0 https:\/\/www.meetup.com\/Bay-Area-MLflow\/events\/254124344\/\n\n\nZOOM:\u00a0https:\/\/mesosphere.zoom.us\/j\/823248629\n\n\nCheers\nJules",
        "Answers":[
            {
                "Answer_creation_time":"2018-11-29T22:47:20",
                "Answer_body":"Is there a plan for another meetup in the Bay area soon?\n\n\n-Alex\n\ue5d3"
            },
            {
                "Answer_creation_time":"2018-11-30T01:00:48",
                "Answer_body":"Hello Alex,\n\n\nWe are in the process of finding a spot or host in the South Bay, either in December or Jan. But coming soon.\u00a0\n\n\nCheers\u00a0\nJules\u00a0\n\n\nSent from my iPhone\nPardon the dumb thumb typos :)\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/3ac5db44-a295-4e02-8050-5a5ac00f99fe%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            },
            {
                "Answer_creation_time":"2018-11-30T02:49:51",
                "Answer_body":"If anyone would like to host one or speak at one by the way, definitely contact Jules and let him know.\n\nMatei\n\n\ue5d3\n> To view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/CF31FBF2-2668-4337-9570-DD8602873C41%40databricks.com.\n\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"MLflow 1.28.0 released!",
        "Question_creation_date":"2022-08-11T06:29:58",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/2BtF8qwt0Zc",
        "Question_answer_count":0,
        "Question_view_count":32,
        "Question_body":"Hi all,\n\nWe are happy to announce the availability of\u00a0MLflow\u00a01.28.0\u00a0!\n\n\nMLflow\u00a01.28.0 includes several major features and improvements:\n\nFeatures:\n\n[Pipelines] Log the full Pipeline runtime configuration to MLflow Tracking during Pipeline execution (#6359,\u00a0@jinzhang21)\n[Pipelines] Add\u00a0pipeline.yaml\u00a0configurations to specify the Model Registry backend used for model registration (#6284,\u00a0@sunishsheth2009)\n[Pipelines] Support optionally skipping the\u00a0transform\u00a0step of the scikit-learn regression pipeline (#6362,\u00a0@sunishsheth2009)\n[Pipelines] Add UI links to Runs and Models in Pipeline Step Cards on Databricks (#6294,\u00a0@dbczumar)\n[Tracking] Introduce\u00a0mlflow.search_experiments()\u00a0API for searching experiments by name and by tags (#6333,\u00a0@WeichenXu123;\u00a0#6227,\u00a0#6172,\u00a0#6154,\u00a0@harupy)\n[Tracking] Increase the maximum parameter value length supported by File and SQL backends to 500 characters (#6358,\u00a0@johnyNJ)\n[Tracking] Introduce an\u00a0--older-than\u00a0flag to\u00a0mlflow gc\u00a0for removing runs based on deletion time (#6354,\u00a0@Jason-CKY)\n[Tracking] Add\u00a0MLFLOW_SQLALCHEMYSTORE_POOL_RECYCLE\u00a0environment variable for recycling SQLAlchemy connections (#6344,\u00a0@postrational)\n[UI] Display deeply nested runs in the Runs Table on the Experiment Page (#6065,\u00a0@tospe)\n[UI] Add box plot visualization for metrics to the Compare Runs page (#6308,\u00a0@ahlag)\n[UI] Display tags on the Compare Runs page (#6164,\u00a0@CaioCavalcanti)\n[UI] Use scientific notation for axes when viewing metric plots in log scale (#6176,\u00a0@RajezMariner)\n[UI] Add button to Metrics page for downloading metrics as CSV (#6048,\u00a0@rafaelvp-db)\n[UI] Include NaN and +\/- infinity values in plots on the Metrics page (#6422,\u00a0@hubertzub-db)\n[Tracking \/ Model Registry] Introduce environment variables to control retry behavior and timeouts for REST API requests (#5745,\u00a0@peterdhansen)\n[Tracking \/ Model Registry] Make\u00a0MlflowClient\u00a0importable as\u00a0mlflow.MlflowClient\u00a0(#6085,\u00a0@subramaniam02)\n[Model Registry] Add support for searching registered models and model versions by tags (#6413,\u00a0#6411,\u00a0#6320,\u00a0@WeichenXu123)\n[Model Registry] Add\u00a0stage\u00a0parameter to\u00a0set_model_version_tag()\u00a0(#6185,\u00a0@subramaniam02)\n[Model Registry] Add\u00a0--registry-store-uri\u00a0flag to\u00a0mlflow server\u00a0for specifying the Model Registry backend URI (#6142,\u00a0@Secbone)\n[Models] Improve performance of Spark Model logging on Databricks (#6282,\u00a0@bbarnes52)\n[Models] Include Pandas Series names in inferred model schemas (#6361,\u00a0@RynoXLI)\n[Scoring] Make\u00a0model_uri\u00a0optional in\u00a0mlflow models build-docker\u00a0to support building generic model serving images (#6302,\u00a0@harupy)\n[R] Support logging of NA and NaN parameter values (#6263,\u00a0@nathaneastwood)\n\nBug fixes and documentation updates:\n\n[Pipelines] Improve scikit-learn regression pipeline latency by limiting dataset profiling to the first 100 columns (#6297,\u00a0@sunishsheth2009)\n[Pipelines] Use\u00a0xdg-open\u00a0instead of\u00a0open\u00a0for viewing Pipeline results on Linux systems (#6326,\u00a0@strangiato)\n[Pipelines] Fix a bug that skipped Step Card rendering in Jupyter Notebooks (#6378,\u00a0@apurva-koti)\n[Tracking] Use the 401 HTTP response code in authorization failure REST API responses, instead of 500 (#6106,\u00a0@balvisio)\n[Tracking] Correctly classify artifacts as files and directories when using Azure Blob Storage (#6237,\u00a0@nerdinand)\n[Tracking] Fix a bug in the File backend that caused run metadata to be lost in the event of a failed write (#6388,\u00a0@dbczumar)\n[Tracking] Adjust\u00a0mlflow.pyspark.ml.autolog()\u00a0to only log model signatures for supported input \/ output data types (#6365,\u00a0@harupy)\n[Tracking] Adjust\u00a0mlflow.tensorflow.autolog()\u00a0to log TensorFlow early stopping callback info when\u00a0log_models=False\u00a0is specified (#6170,\u00a0@WeichenXu123)\n[Tracking] Fix signature and input example logging errors in\u00a0mlflow.sklearn.autolog()\u00a0for models containing transformers (#6230,\u00a0@dbczumar)\n[Tracking] Fix a failure in\u00a0mlflow gc\u00a0that occurred when removing a run whose artifacts had been previously deleted (#6165,\u00a0@dbczumar)\n[Tracking] Add missing\u00a0sqlparse\u00a0library to MLflow Skinny client, which is required for search support (#6174,\u00a0@dbczumar)\n[Tracking \/ Model Registry] Fix an\u00a0mlflow server\u00a0bug that rejected parameters and tags with empty string values (#6179,\u00a0@dbczumar)\n[Model Registry] Fix a failure preventing model version schemas from being downloaded with\u00a0--serve-arifacts\u00a0enabled (#6355,\u00a0@abbas123456)\n[Scoring] Patch the Java Model Server to support MLflow Models logged on recent versions of the Databricks Runtime (#6337,\u00a0@dbczumar)\n[Scoring] Verify that either the deployment name or endpoint is specified when invoking the\u00a0mlflow deployments predict\u00a0CLI (#6323,\u00a0@dbczumar)\n[Scoring] Properly encode datetime columns when performing batch inference with\u00a0mlflow.pyfunc.spark_udf()\u00a0(#6244,\u00a0@harupy)\n[Projects] Fix an issue where local directory paths were misclassified as Git URIs when running Projects (#6218,\u00a0@ElefHead)\n[R] Fix metric logging behavior for +\/- infinity values (#6271,\u00a0@nathaneastwood)\n[Docs] Move Python API docs for\u00a0MlflowClient\u00a0from\u00a0mlflow.tracking\u00a0to\u00a0mlflow.client\u00a0(#6405,\u00a0@dbczumar)\n[Docs] Document that MLflow Pipelines requires Make (#6216,\u00a0@dbczumar)\n[Docs] Improve documentation for developing and testing MLflow JS changes in\u00a0CONTRIBUTING.rst\u00a0(#6330,\u00a0@ahlag)\nFor a comprehensive list of changes, see the\u00a0release change log, and check out the latest documentation on\u00a0mlflow.org.",
        "Answers":[

        ]
    },
    {
        "Question_title":"We would like to be listed in the MLflow users\/contributors list",
        "Question_creation_date":"2020-11-05T14:20:50",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/RXIK8zSzZPU",
        "Question_answer_count":0,
        "Question_view_count":22,
        "Question_body":"Hello,\n\n\nAt InfinStor, we are users of MLflow, we have a free MLflow SaaS offering in the cloud, and we hope to contribute to the MLflow open source project.\n\n\nWe would like to be listed in the users\/contributors list.\n\n\nThanks to the MLflow contributors for creating such an awesome project. Kudos to the architects of MLflow - it is a truly extensible piece of software.\n\n\nBest\nJagane\n\n\nPS: Included with this email is a logo of InfinStor",
        "Answers":[

        ]
    },
    {
        "Question_title":"mlflow ui is not running in windows 10",
        "Question_creation_date":"2019-11-20T14:32:35",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/YMa_sVOspgw",
        "Question_answer_count":1,
        "Question_view_count":7,
        "Question_body":"MLFLOW UI is not running to any of my installed browser while I tried to run it through terminal.Please help with a solution.",
        "Answers":[
            {
                "Answer_creation_time":"2019-11-30T12:23:36",
                "Answer_body":"I was able to get MLFlow running on Windows 10 and access the UI via http:\/\/localhost:5000 by doing the following:\ninstalling anaconda (full anaconda)\ncreating an anaconda python 3.7 environment\u00a0 (e.g. called py37)\nactivating the py37 env\nInstalling mylflow via: >pip install mlflow\nStarting thie ui via >mlflow ui\nNote that I had issues trying to utilize the 'base' anaconda env so be sure to create a new python 3.7 environment and install MLFlow in that env.\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"MLFlow Tracking server scalability",
        "Question_creation_date":"2018-06-22T04:38:07",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/TQe7ATr8Wqw",
        "Question_answer_count":4,
        "Question_view_count":107,
        "Question_body":"Hey Guys,\n\n\nFirst of all, great job with this effort. It's certainly something a lot of people are waiting for (or have tried to create themselves).\n\n\nI was wondering about the scalability of the tracking server. I see in the code there is an abstraction of for the tracking Store, which is currently a FileStore if I'm correct. What are the plans to support other stores for this (ElasticSearch, Kafka, S3, ...?)\n\n\nCheers,\nD.",
        "Answers":[
            {
                "Answer_creation_time":"2018-06-23T19:06:44",
                "Answer_body":"Hi Daan,\n\nWe do intend to add other ones. There are actually two elements here,\nthe metadata store and the artifact store (which can contain large\nfiles uploaded by the job). For the metadata part we'll probably add a\ndatabase option, and for the artifacts we'll support cloud storage\nsystems.\n\n\ue5d3\n> --\n> You received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\n> To unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\n> To post to this group, send email to mlflow...@googlegroups.com.\n> To view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/bd04aa5c-3197-4000-9acc-a1857783fcf2%40googlegroups.com.\n> For more options, visit https:\/\/groups.google.com\/d\/optout."
            },
            {
                "Answer_creation_time":"2018-10-22T16:02:46",
                "Answer_body":"Hi,\n\n\nIs there issues in github for these two stores? would be great to understand plans & participate\n\n\nThanks!\n\ue5d3"
            },
            {
                "Answer_creation_time":"2018-11-08T18:36:23",
                "Answer_body":"We\u2019ve already received pull requests for a few artifact store backends (Google Cloud Storage, Azure Storage, SFTP, and others). If you\u2019d like to work on another one, or if you\u2019d like to work on a database store for metadata, that would be awesome. There is an open pull request for a DynamoDB metadata store but we\u2019d prefer to use something like SQLAlchemy that can work with a variety of backend databases if possible.\n\nMatei\n\n\ue5d3\n> To view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/13a17d23-1fe1-4bd5-91a5-6f81d68e8178%40googlegroups.com.\n\n\ue5d3"
            },
            {
                "Answer_creation_time":"2018-11-08T18:38:33",
                "Answer_body":"BTW I\u2019ll also add that the MLflow team at Databricks will probably implement this at some point if we don\u2019t receive an external patch, but it might be a bit further down the line since we also have requests about the UI, model scoring, etc right now. In any case though we\u2019re happy to provide feedback to anyone interested in it. The metadata store has a clearly separated API already and it shouldn\u2019t be a huge amount of work to make a new one, though some care might need to be taken to make sure we can support database migrations, etc.\n\nMatei\n\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"MLflow 2.0.0rc0 release",
        "Question_creation_date":"2022-11-01T01:00:53",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/khwIVANuAKI",
        "Question_answer_count":0,
        "Question_view_count":18,
        "Question_body":"We're happy to announce a release candidate for MLflow 2.0:\nhttps:\/\/github.com\/mlflow\/mlflow\/releases\/tag\/v2.0.0rc0\n\nInstallation:\n===================================\n# Make sure python version is >=3.8\npip install mlflow==2.0.0rc0\n===================================\n\n\nDocumentation:\nMLflow 2.0.0rc0 documentation\n\nPlease report any issues with the release candidate in the issue tracker.",
        "Answers":[

        ]
    },
    {
        "Question_title":"Not able to get expected output while serving the model using \"mlflow model serve\" while using sklearn-crfsuite",
        "Question_creation_date":"2019-09-13T01:54:00",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/l7sPjsCx9dQ",
        "Question_answer_count":1,
        "Question_view_count":7,
        "Question_body":"I am not able to get the expected response when calling api served with \"mlflow model serve\" command. It is working with other sklearn libraries but not with sklearn-crfsuite. Need help.",
        "Answers":[
            {
                "Answer_creation_time":"2019-09-16T18:09:30",
                "Answer_body":"Can you open an issue on GitHub with the inputs \/ sample code to reproduce this? It might be that your model didn\u2019t specify a Conda environment with the sklearn-crfsuite dependency but it\u2019s hard to tell without seeing the error message.\n\n\n\nOn Sep 12, 2019, at 10:54 PM, vikash kumar <vikash....@gmail.com> wrote:\n\n\nI am not able to get the expected response when calling api served with \"mlflow model serve\" command. It is working with other sklearn libraries but not with sklearn-crfsuite. Need help.\n\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/380176cf-d733-4e6f-b516-dddde25e607f%40googlegroups.com."
            }
        ]
    },
    {
        "Question_title":"Unable to connect to HDFS",
        "Question_creation_date":"2020-06-01T05:13:03",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/8olskwFCHJY",
        "Question_answer_count":0,
        "Question_view_count":14,
        "Question_body":"Hello,\nI'm installing MLFlow 1.6 on a production environment with a PostgreSQL database for --backend-store-uri and HDFS for --default-artifact-root.\u00a0When I launch an experiment it writes perfectly in PostgreSQL, but it cannot connect to HDFS to save the artifacts. El error is \"HDFS connection failed\".\u00a0HDFS is on a Cloudera cluster.I also tried MLFlow 1.8 and the error is the same.\n\n\nThanks",
        "Answers":[

        ]
    },
    {
        "Question_title":"Track training loss to Azure when running file locally",
        "Question_creation_date":"2022-06-16T12:35:24",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/QXD8azgicVI",
        "Question_answer_count":4,
        "Question_view_count":23,
        "Question_body":"Hi all :)\n\n\nI have followed the official microsoft tutorial (https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-mlflow-cli-runs?tabs=mlflow) to log parameters or metrics in the Azure Workspace when I run something locally. That works just fine.\n\n\nHowever, what I want to do is run a train.py file by using the os.system command like\nos.system(f\"python .\/src\/train.py --data_path .\/data) instead of the os.system command used in the tutorial.\u00a0\n\n\nThis works fine in general. However, inside the train.py file, I am not able to get access to the Azure Machine Learning experiment that I created in the file which runs the os.system command. Therefore, I am not able to track the loss of the train.py file to Azure.\n\n\n\nDo you have any suggestions how I could solve that?\n\n\nThanks a lot already!\n\n\nBest regards",
        "Answers":[
            {
                "Answer_creation_time":"2022-06-18T12:01:28",
                "Answer_body":"Hi Frank,\nThe command os.system() starts a new process in a separate shell; consequently, any information you want to make available to the subprocess needs to be passed as arguments (to keep things simple). On top of that, if you are using virtual environments to install python packages, the libraries you installed won't be available (I guess that this is why you can't access Azure ML, cause the other shell doesn't have azureml-mlflow installed). To give a concrete answer I would need a bit more details about what you are doing. Generally speaking:\nIf the train.py file handles all the training processes, then such file should be the one configuring the experiments and doing all the logging. Don't run it in a separate shell. If you want to separate responsibilities into different files (like a file for configuring the experiment and another for the training - which I won't recommend but still) then use the importing mechanisms in Python.\u00a0\nIf you are creating multiple training executions in separate processes (for instance, for hyper-parameter tunning or because you train multiple \"things\"), then you need to use the concept of nested runs (or child runs).\n\nIf you are doing hyperparameter tunning in subprocesses:\nUse a library for optimization compatible with mlflow. There are a lot. We have an example here:\u00a0 Hyper-parameters optimization using child runs with MLflow and HyperOpt optimizer\nUse the sweep job in Azure ML:\u00a0 CLI (v2) sweep job YAML schema\nStart child processes from your main training script but use subprocess instead of os.system(). The former will run in the same shell so for instance, the same virtual environment will be available.\nIf you are training multiple models in different steps, use a pipeline:\u00a0 CLI (v2) pipeline job YAML schema\nHope it helps,\nFacundo.\n\ue5d3"
            },
            {
                "Answer_creation_time":"2022-06-20T03:27:30",
                "Answer_body":"Hi Facundo,\n\n\nthank you really much for your fast and detailed reply! I understand the problem with os.system() now.\n\n\nMy main idea is that sometimes (for smaller tasks), I want to train my network locally on my computer and for bigger tasks I would like to train the network with Azure Machine Learning. Therefore, I thought it would be best to have one train.py script, which I could either call from a run-on-azure.py file or from a run-locally.py file. In the train.py script, I use mlflow.log_metric() to log my loss.\n\n\nIn the run-on-azure.py file, I would use the command command (Azure v2) to start the compute cluster with the train.py script. This automatically generates a new run in the experiment and successfully tracks the loss using mlflow.\nTherefore, I was looking for a way to start the train.py script with a similar command like the command command from Azure v2 but locally. In run_local.py I would therefore use a tracking URI so that the local run is still tracked on Azure using MLFlow but everything is computed locally.\n\n\nWould you solve this differently? Or do you see a way that I could use the run-local.py file to start the train.py script but still track the log_metrics?\n\n\nThank you so much for your help!\n\n\nBest regards\n\n\n\ue5d3"
            },
            {
                "Answer_creation_time":"2022-06-20T13:08:57",
                "Answer_body":"Hi Frank,\nThanks for the detailed scenario. It makes a lot of sense to me and, moreover, MLflow is the right tool to enable such portability of code from local to cloud compute. I would solve the problem in a different way. Basically,\nKeep 1 train.py file that leverages MLflow for tracking and logging. Any data path needed by the training script should be passed as parameters.\nFor running the file locally\n\nConfigure the environment variable MLFLOW_TRACKING_URI to point to the workspace you are using.\n\nRun your jobs by invoking python: \"python train.py\u00a0 --training-data-path \/my\/path\/to\/where\/data\/is\"\n\nFor running the file on Azure:\nCreate a job definition YAML file using:\nInputs for indicating the data paths needed by your script\nIn the \"command\" section of the file, put the same thing that you run locally, but replace the data paths by the \"inputs\" specified before. Then, paths will be resolved to cloud locations. For instance, \"python train.py --training-data-path ${{ inputs.training_data_path }}\".\u00a0\nUse compute clusters for running the job and configure the compute cluster with a minimum number of nodes = 0. That will do exactly what you are doing manually: turning on the compute cluster when there is jobs to do, and turn it off once there is no more jobs.\nSubmit jobs using the Azure ML CLI v2: \"az ml job create -f train.yml\".\nI actually have a repository that demonstrates how to do this:\u00a0https:\/\/github.com\/santiagxf\/mlproject-sample, you can check it out. The repo is about something different (about how to structure an ML project) but it does the same thing you are trying to achieve (which is a good practice, by the way).\n\n\n\nHope it helps,\nFacundo.\n\n\n\ue5d3"
            },
            {
                "Answer_creation_time":"2022-06-21T08:36:51",
                "Answer_body":"Hi Facundo,\n\n\nThanks again! I have managed to get my code running on Azure using the job definition YAML file like you proposed.\nHowever, I am still struggling about using the same train.py file for both locally and running on Azure.\n\n\nIf I place the following code inside the train.py file, I can run the train.py file locally with the command you proposed and everything is logged on Azure just as it should be.\nml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace)\ntracking_uri = ml_client.workspaces.get(name=workspace).mlflow_tracking_uri\nmlflow.set_tracking_uri(tracking_uri)\nexperiment_name = 'pytorch-test-yml'\nmlflow.set_experiment(experiment_name)\n\n\n\nHowever, if I have this code snipped inside my train.py function I cannot run the train.py file on Azure anymore using the YAML file. I get some errors on Azure about the credentials that I do not understand. I have included a screenshot of the error.\n\n\nIs it your idea to place this code snippet inside the train.py file or where do you mean to place it? If I understood it correctly so far, I do not need that code if I run my code with the YAML file on Azure but I do need it if I run the file locally.\n\n\nBest regards and thank you so much!\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"Step by step instructions for running MLflow Projects in EKS",
        "Question_creation_date":"2022-04-26T18:20:19",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/r-XDGcqb4Qg",
        "Question_answer_count":0,
        "Question_view_count":17,
        "Question_body":"Folks - as you might know, MLflow includes preliminary support for running MLflow Projects in kubernetes. if you are interested in doing so, specifically on EKS, I wrote a medium article with step by step instructions.\n\n\nhttps:\/\/medium.com\/infinstor\/run-mlflow-project-in-eks-b0906e04c273\n\n\n\nCheers!\nJagane",
        "Answers":[

        ]
    },
    {
        "Question_title":"databricks to power bi",
        "Question_creation_date":"2021-05-17T10:50:13",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/GvkoTw0sL4U",
        "Question_answer_count":2,
        "Question_view_count":9,
        "Question_body":"Hello community , i'm trying to save stream data in delta lake and i want to push this data to power bi for real time insights , however when i try to connect databricks to power bi i get an empty table , someone can help me please ??\u00a0\nif there's another alternative it would be grateful\u00a0\nthank you",
        "Answers":[
            {
                "Answer_creation_time":"2021-05-17T11:47:47",
                "Answer_body":"Hello Nadine,\n\n\nYou might want to post this on the delta-lake user group or Delta Lake slack channel. You can join both here:\u00a0https:\/\/delta.io\/\n\u00a0\n\n\n\nThanks,\nJules\n\n\n\n\n\n\n\u2013\u2013\n\nThe Best Ideas are Simple\n\nJules S. Damji\n\nSr. Developer Advocate\n\nDatabricks, Inc.\n\nju...@databricks.com\n\n(510) 304-7686\n\n\n\n\n\n\n\n\n\n\n\u00a0\u00a0\u00a0\n\n\n\n\n\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/dc8ee8ff-3f04-423c-a446-96b7f250a3e5n%40googlegroups.com."
            },
            {
                "Answer_creation_time":"2021-05-17T11:50:14",
                "Answer_body":"Ok , thank you\u00a0\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"runtime timeout?",
        "Question_creation_date":"2018-09-17T16:15:10",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/JN9X_yUJ1bY",
        "Question_answer_count":2,
        "Question_view_count":12,
        "Question_body":"Hi all,\nIs there a way to set timeout value when mlflow.project.run(...) is called?",
        "Answers":[
            {
                "Answer_creation_time":"2018-09-17T16:30:16",
                "Answer_body":"Hi,\n\nCurrently there's no way to explicitly pass a timeout to mlflow.project.run(...). However, you can launch your run asynchronously e.g. via mlflow.projects.run(..., block=False). The projects.run() API then returns a SubmittedRun\u00a0that exposes a cancel() method for cancelling the run, so you could write your own logic to wait for some time period\u00a0 & cancel the run.\n\n\nOn Mon, Sep 17, 2018 at 1:15 PM, MrAsanjar <afsa...@gmail.com> wrote:\n\nHi all,\nIs there a way to set timeout value when mlflow.project.run(...) is called?\u00a0\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users+unsubscribe@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/0c2991e3-0acd-4788-bfee-7bffab7432b4%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            },
            {
                "Answer_creation_time":"2018-09-17T20:39:45",
                "Answer_body":"thanks for the info. however, I believe that would be a critical feature to have.\nWould you consider a contribution to add this feature?\n\n\n\n\nOn Monday, September 17, 2018 at 3:30:16 PM UTC-5, Siddharth Murching wrote:\nHi,\n\nCurrently there's no way to explicitly pass a timeout to mlflow.project.run(...). However, you can launch your run asynchronously e.g. via mlflow.projects.run(..., block=False). The projects.run() API then returns a SubmittedRun\u00a0that exposes a cancel() method for cancelling the run, so you could write your own logic to wait for some time period\u00a0 & cancel the run.\nOn Mon, Sep 17, 2018 at 1:15 PM, MrAsanjar <afsa...@gmail.com> wrote:\n\nHi all,\nIs there a way to set timeout value when mlflow.project.run(...) is called?\u00a0\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\n\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"Deploy a Shap explainer model with mlflow",
        "Question_creation_date":"2019-10-09T02:55:59",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/d6FOZhHqTOg",
        "Question_answer_count":1,
        "Question_view_count":10,
        "Question_body":"I have a shap explainer model and I want to deploy it using mlflow to azure AKS how can I do that. The model is available in model.pk file.\n\n\nimport shap\nX_train_summary = shap.kmeans(X_train,5)\nk_explainer = shap.KernelExplainer(model_bag_clf.predict_proba, X_train_summary)\nk_shap_values = k_explainer.shap_values(data_for_prediction)",
        "Answers":[
            {
                "Answer_creation_time":"2019-10-09T08:14:25",
                "Answer_body":"As in your other question, what if you just make a custom model that returns the shap values, as a list()?\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/f6d059a9-a62a-41cd-bc33-01c82c6f9bc7%40googlegroups.com."
            }
        ]
    },
    {
        "Question_title":"DATA Pill - knowledge-sharing project",
        "Question_creation_date":"2022-06-27T15:42:17",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/hm7VvOcNIuY",
        "Question_answer_count":0,
        "Question_view_count":16,
        "Question_body":"Hi,\n\nAs we are a community focused around MLFlow I thought I would send you some information about the new DATA Pill project.\u00a0\n\nI hope you will be interested because it covers our area and the project is focused on highly selected content for specialists.\n\nIt is also a community-driven project.\n\nDATA Pill is a weekly newsletter with an overview of the best Big Data, Cloud and AI\/ML content.\n\nfiltered content from over 200 sources\n\nextracts from articles, tutorials, podcasts, youtube, etc\n\na simple mail with a condensed form that you can skim through in just 10 minutes\u00a0\n\nreminders of upcoming meetups and events\n\nHere you can see examples of previous mails: DATA PiIl, so you can decide if it's something for you.\n\nIt started from the internal slack channel where we shared interesting links.\n\nOver time, the idea arose to organize this content more and gather it in one place\u00a0\n\nso that it would not get lost amongst hundreds of notifications.\u00a0\n\nSince we started doing this, browsing through even more sources of information,\u00a0\n\nsomeone threw in a thought: why not share it and allow everyone to subscribe?\n\n\n\n\nWe also want to involve everyone who is interested in creating this newsletter.\u00a0\n\nWe are in ongoing communication by mail and we are looking for a place where we could interact more.\n\nAny ideas are welcomed.\n\n\n\n\n\n\nCheers!\nSylwia from\u00a0GetInData",
        "Answers":[

        ]
    },
    {
        "Question_title":"RFC: Add a \"step\" axis for logging metrics in MLflow",
        "Question_creation_date":"2019-04-15T19:59:06",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/8zlfjQHnhgk",
        "Question_answer_count":0,
        "Question_view_count":8,
        "Question_body":"Motivation \/ Overview\n\nTraining machine learning models is a process of iterative improvement. Models are successively exposed to sections of training data and adjusted based on their performance. Therefore, ML developers often need to observe how model performance changes throughout the training process. There are multiple ways to quantify the progress of the training process; here are several:\n\nThe amount of time, in seconds (wall clock time), that the training process has been running\nThe number of times that the model has been exposed to the entire training dataset. This is the number of training epochs.\nModels often make multiple passes through the training dataset.\nThe number of batches (fixed-size subsets of training data) to which the model has been exposed. This is the number of training iterations.\n\nMLflow currently provides an API for tracking model performance metrics; however, MLflow metrics can only be specified as a function of wall clock time. To paraphrase, wall clock time is the only supported x-axis on which metrics can recorded and visualized; wall clock time is the only supported x-coordinate for a metric entry.\n\nThe purpose of this RFC is to introduce support for recording and visualizing performance metrics against different types of axes, enabling ML developers to answer questions such as:\n\n\u201cWhat was the training accuracy of my model after the 50th training epoch?\u201d\n\u201cWhat was the precision of my model when evaluating the test data set after the 20th training iteration?\u201d\n\nSummary of Proposed Solution\nAt a high level, we propose to introduce a\u00a0step\u00a0attribute to MLflow metrics via the following high-level tasks:\n\nIntroduce a step attribute to MLflow\u2019s Metric entity definition\nUpdate backend store definitions to handle the new attribute\nUpdate the metric write path to create Metric entities that supply values for the step attribute\nThis includes client APIs, protos, the backend store write path, etc.\nExpand plotting capabilities of the MLflow UI to allow the user to toggle between the step axis and the \u201cwall clock time\u201d axis.\n\nFor more information, please see the full RFC below.\n\n\n\n\nRFC link\nThe full RFC is available as a Google Document at:\u00a0https:\/\/docs.google.com\/document\/d\/17yHR_xOvoEJQBT-D-y4QGfc3OvHqP-eGWwfMcGBIH2k\/edit?usp=sharing\n\nPlease leave comments and feedback within Google Docs!",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLFlow Meetup 1.0 @ Microsoft",
        "Question_creation_date":"2019-06-27T17:27:55",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/Xf5Bs8xootI",
        "Question_answer_count":0,
        "Question_view_count":12,
        "Question_body":"Hello!\n\n\n\nIf you missed the last\u00a0MLflow meetup,\u00a0here are the slides and the video presentation.\n\nTalks for the meetup are on the SlideShare:\n1. Talk 1:\u00a0https:\/\/www.slideshare.net\/databricks\/flock-data-science-platform-cisl\n2. Talk-2:\u00a0https:\/\/www.slideshare.net\/databricks\/mlflow-10-meetup\n\nAnd the video is now available:\u00a0\u00a0https:\/\/youtu.be\/ILIllCMDEgc\n\n\n\n\n--\u00a0\n\n\nThe Best Ideas are Simple\n\nJules S. Damji\n\nApache Spark Developer & Community Advocate\n\nDatabricks, Inc.\n\nju...@databricks.com\n\n(510) 304-7686",
        "Answers":[

        ]
    },
    {
        "Question_title":"mlflow.sagemaker.deploy",
        "Question_creation_date":"2018-07-06T10:23:25",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/M51fi08Drk4",
        "Question_answer_count":1,
        "Question_view_count":45,
        "Question_body":"Hi Databricks,\n\n\nI was successfully able to push image to ecr -\n\n\n\u00a0mlflow.sagemaker.push_image_to_ecr(image='mlflow_sage')\n\n\nI was trying to deploy the model using -\n\n\nmlflow.sagemaker.deploy(app_name,\u00a0model_path,\u00a0execution_role_arn,\u00a0bucket,\u00a0run_id=None,\u00a0image='mlflow_sage',\u00a0region_name='us-west-2')\n\n\napp_name\u00a0\u2013 Name of the deployed app.\n\n\nI am not sure what is deployed app. Could help here.\n\n\nThanks,\nSunil",
        "Answers":[
            {
                "Answer_creation_time":"2018-07-06T12:20:37",
                "Answer_body":"Hi Sunil,\n\nGood question - the deployed app is the serving application that gets deployed to SageMaker, consisting of a SageMaker endpoint. The app_name you specify is used as the name of the deployed endpoint (i.e. the EndpointName in this example). You can then use the SageMaker CLI describe-endpoint command\u00a0with the app_name you specified to query the status of your endpoint.\n\nThanks,\nSid\n\n\n\ue5d3\n\ue5d3\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users+unsubscribe@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/a009bb1a-5376-4858-831d-cbbafca18742%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            }
        ]
    },
    {
        "Question_title":"request for help",
        "Question_creation_date":"2021-05-06T20:07:15",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/k0kgHG1Qbm8",
        "Question_answer_count":0,
        "Question_view_count":45,
        "Question_body":"hello everyone , how can i solve this probblem plase\u00a0\nMlflowException: Failed to download an \"MLmodel\" model file from \"\/dbfs\/databricks\/mlflow-tracking\/4026011258138627\/e1e6a5f1819e426b81587a5ea2124228\/artifacts\/spark-model\": No such file or directory: '\/dbfs\/databricks\/mlflow-tracking\/4026011258138627\/e1e6a5f1819e426b81587a5ea2124228\/artifacts\/spark-model\/MLmodel'\n\nit's urgent , please help",
        "Answers":[

        ]
    },
    {
        "Question_title":"Request to add TVS in Organizations using & contributing to MLflow",
        "Question_creation_date":"2021-07-26T10:12:04",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/ReyGdDjmCeo",
        "Question_answer_count":1,
        "Question_view_count":57,
        "Question_body":"Hi Team,\n\nAt TVS Motor we use MLflow extensively for ML model tracking, projects and registry. In the past, I was a contributor to MLflow as well.\n\nSo, can we get the TVS Motor listed in the \u201cOrganizations using and contributing to MLflow\u201d section, please?\n\n\n\n\n\u00a0\n\n\u00a0Thanks,\nNaga",
        "Answers":[
            {
                "Answer_creation_time":"2021-11-13T10:20:20",
                "Answer_body":"Dear MLflow team, reinitiating our request to add www.tvsmotor.com listed as\u00a0 \u201cOrganizations using and contributing to MLflow\u201d section. our teams use MLflow extensively for ML model tracking, projects and registry.\u00a0\ncheers.\n\n\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"mlflow for beginners",
        "Question_creation_date":"2022-11-07T11:44:12",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/px-W1aq-dE8",
        "Question_answer_count":0,
        "Question_view_count":9,
        "Question_body":"Hello everyone, I would like to use MLflow but I don't know how to register on the platform. Also, I would like to know if there are any step-by-step instructions on how to use this tool (for example, Run an MLflow project).\n\n\nthanks in advance,\n\n\n--\n\nOlga Ximena Giraldo Pasmin\nOrcid ID: orcid.org\/0000-0003-2978-8922\nTwiter: @olgaxgiraldo\nSkype:olgaximenagiraldo\nWebsite: http:\/\/oxgiraldo.wordpress.com",
        "Answers":[

        ]
    },
    {
        "Question_title":"How does MLflow compare to ModelDB (A system to manage machine learning models)?",
        "Question_creation_date":"2018-07-04T06:42:09",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/NW5GxrD9NQ0",
        "Question_answer_count":1,
        "Question_view_count":701,
        "Question_body":"Hello,\n\n\nI wonder how MLflow compares to ModelDB (A system to manage machine learning models).\n\n\nIn ModelDB web page, I've seen Matei Zaharia as one of the contributors:\n\n\n\u00a0\u00a0\u00a0 https:\/\/mitdbg.github.io\/modeldb\/\n\n\nAny ideas?\n\n\n\n--\nEmre",
        "Answers":[
            {
                "Answer_creation_time":"2018-07-05T20:26:38",
                "Answer_body":"Hi Emre,\n\nI did indeed work on the ModelDB research project back in 2016. MLflow Tracking is the closest part to ModelDB in that it lets you report experiment results and parameters, so it solves a similar problem. There are some differences in how these systems work though \u2014 for example, right now, MLflow Tracking is a lower level API you call directly, whereas ModelDB adds wrappers around popular ML libraries (SciKit-Learn and Spark MLlib) to easily capture this info. The ways they store and display results are different too.\n\nMatei\n\n\ue5d3\n> --\n> You received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\n> To unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\n> To post to this group, send email to mlflow...@googlegroups.com.\n> To view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/1468ddd1-03a1-47dd-9844-af8b5fdfb28b%40googlegroups.com.\n> For more options, visit https:\/\/groups.google.com\/d\/optout."
            }
        ]
    },
    {
        "Question_title":"MLflow 1.12.0 released!",
        "Question_creation_date":"2020-11-11T19:28:46",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/txoBu2XyQO8",
        "Question_answer_count":0,
        "Question_view_count":10,
        "Question_body":"Hi all,\n\n\nIn addition to bug and documentation fixes,\u00a0MLflow 1.12.0\u00a0includes several major features and improvements, in particular a number of improvements to MLflow\u2019s Pytorch integrations and autologging:\n\nPyTorch:\nmlflow.pytorch.log_model,\u00a0mlflow.pytorch.load_model\u00a0now support logging\/loading TorchScript models (#3557,\u00a0@shrinath-suresh)\nmlflow.pytorch.log_model\u00a0supports passing\u00a0requirements_file\u00a0&\u00a0extra_files\u00a0arguments to log additional artifacts along with a model (#3436,\u00a0@shrinath-suresh)\nAutologging:\nAdd universal\u00a0mlflow.autolog\u00a0which enables autologging for all supported integrations (#3561,\u00a0#3590,\u00a0@andrewnitu)\nAdd\u00a0mlflow.pytorch.autolog\u00a0API for automatic logging of metrics, params, and models from Pytorch Lightning training (#3601,\u00a0@shrinath-suresh,\u00a0#3636,\u00a0@karthik-77). This API is also enabled by\u00a0mlflow.autolog.\nScikit-learn, XGBoost, and LightGBM autologging now support logging model signatures and input examples (#3386,\u00a0#3403,\u00a0#3449,\u00a0@andrewnitu)\nmlflow.sklearn.autolog\u00a0now supports logging metrics (e.g. accuracy) and plots (e.g. confusion matrix heat map) (#3423,\u00a0#3327,\u00a0@willzhan-db,\u00a0@harupy)\nFor a comprehensive list of changes, see the\u00a0release change log, and check out the latest documentation on\u00a0mlflow.org.",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLProject",
        "Question_creation_date":"2019-11-14T06:29:23",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/wfNFPYbJo6M",
        "Question_answer_count":1,
        "Question_view_count":18,
        "Question_body":"The sample MLProject file copied below contains entry_points for running train.py and validate.py. Kindly let me know the mlflow run command for running the validate.py script.\n\n\u00a0\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 name: My Project\n\n\u00a0\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 conda_env: my_env.yaml\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 # Can have a docker_env instead of a conda_env, e.g.\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 # docker_env:\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 #\u00a0\u00a0\u00a0 image:\u00a0 mlflow-docker-example\n\n\u00a0\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 entry_points:\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0 main:\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 parameters:\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0 data_file: path\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0 regularization: {type: float, default: 0.1}\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 command: \"python train.py -r {regularization} {data_file}\"\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0 validate:\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 parameters:\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0 data_file: path\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 command: \"python validate.py {data_file}\"\n\n\u00a0\n\nRegards\n\nBinay",
        "Answers":[
            {
                "Answer_creation_time":"2019-11-15T12:09:11",
                "Answer_body":"If your MLflow project file is in your directory \"my_project,\" along with other python scripts, you can use CLI to execute the\u00a0project and its respective entry point\n\n\ncd\u00a0my_project\u00a0&&\u00a0mlflow run . -e validate -P data_file=<path>\u00a0\n\n\nCheers\nJules\n\n\n\n\n--\u00a0\n\n\nThe Best Ideas are Simple\n\nJules S. Damji\n\nApache Spark Developer & Community Advocate\n\nDatabricks, Inc.\n\nju...@databricks.com\n\n(510) 304-7686\n\n\n\n\n\n\n\n\n\n\n\u00a0\u00a0\u00a0\n\n\n\n\n\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/078e441f-fcf8-4d66-96bb-87b0a0a61e38%40googlegroups.com."
            }
        ]
    },
    {
        "Question_title":"MLflow 1.15.0 Released!",
        "Question_creation_date":"2021-03-26T16:42:28",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/hxFNU7qIBRw",
        "Question_answer_count":0,
        "Question_view_count":13,
        "Question_body":"We are happy to announce the availability of\u00a0MLflow 1.15.0!\nIn addition to bug and documentation fixes, MLflow 1.15.0 includes the following features and improvements:\nAdd\u00a0silent=False\u00a0option to all autologging APIs, to allow suppressing MLflow warnings and logging statements during autologging setup and training (#4173, @dbczumar)\nAdd\u00a0disable_for_unsupported_versions=False\u00a0option to all autologging APIs, to disable autologging for versions of ML frameworks that have not been explicitly tested against the current version of the MLflow client (#4119, @WeichenXu123)\nFor a comprehensive list of changes, see the\u00a0release change log, and check out the latest documentation on\u00a0mlflow.org.\n\n\nThanks,\nSid",
        "Answers":[

        ]
    },
    {
        "Question_title":"mlflow hangs during training -- no error message",
        "Question_creation_date":"2022-08-23T22:14:15",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/7-1JNBwU1aQ",
        "Question_answer_count":0,
        "Question_view_count":14,
        "Question_body":"Hi,\n\n\nI'm training a large model (a TCN -- Temporal Convolutional Network) in TensorFlow 2.8.1 with Keras 2.8.0 and mlflow 1.27.0 on Ubuntu 18.04.\n\n\n\nI have a loop to do multiple mlflow training runs... I'm getting a \"random\" hang in the middle of training my 150 epochs.\u00a0 Sometimes 1-3 runs (out of 13) will complete ok, but there's always (somewhere within the first 3 runs) a hang or \"total freeze\" of output in my terminal with no error message or anything else... no output at all.\u00a0 The terminal just freezes on some random epoch during 1-3 runs.\n\nI checked and the GPU memory upper limit has not been hit... also system RAM has not been hit.\u00a0 Neither is close.\n\nAny ideas?\u00a0 Does MLflow ever freeze like this?\n\nThanks for any ideas :).",
        "Answers":[

        ]
    },
    {
        "Question_title":"Unable to log_artifact using HDFS",
        "Question_creation_date":"2019-06-13T03:29:46",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/3WYutmO54ao",
        "Question_answer_count":1,
        "Question_view_count":18,
        "Question_body":"Hi,\n\nI am trying to use an HDFS for the artifact repository.\nI used the following command to run the mlflow server :\nmlflow server --host 0.0.0.0 --default-artifact-root hdfs:\/\/--.--.--.---:8020\/mlruns\n\nIn my python code :\n\nmlflow.create_experiment(\"NewTest21\",\"hdfs:\/\/--.--.--.---:8020\/mlruns\")\nmlflow.set_experiment(\"NewTest21\")\nwith mlflow.start_run():\n\tprint(mlflow.get_artifact_uri())\n\tlr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n\tlr.fit(train_x, train_y)\n\tpredicted_qualities = lr.predict(test_x)\n\t\n\t(rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n\tmlflow.log_param(\"alpha\", alpha)\n\tmlflow.log_param(\"l1_ratio\", l1_ratio)\n\tmlflow.log_metric(\"rmse\", rmse)\n\tmlflow.log_metric(\"r2\", r2)\n\tmlflow.log_metric(\"mae\", mae)\n\u00a0 \u00a0 \u00a0 \u00a0 with open(\"output.txt\", \"w\") as f:\n\u00a0 \u00a0 \t\tf.write(\"Hello world! Its a new day\")\n\u00a0 \u00a0 \t\tmlflow.log_artifact(\"output.txt\")\n\tmlflow.sklearn.log_model(lr,\"hdfs:\/\/--.--.--.---::8020\")\n\nHowever I am getting the following error :\n\nTraceback (most recent call last):\n\u00a0 File \"C:\\Program Files\\KNIME\\plugins\\org.knime.python2_3.7.1.v201901281201\\py\\PythonKernelBase.py\", line 278, in execute\n\u00a0 \u00a0 exec(source_code, self._exec_env, self._exec_env)\n\u00a0 File \"<string>\", line 59, in <module>\n\u00a0 File \"C:\\Users\\gs-2024\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\mlflow\\tracking\\fluent.py\", line 244, in log_artifact\n\u00a0 \u00a0 MlflowClient().log_artifact(run_id, local_path, artifact_path)\n\u00a0 File \"C:\\Users\\gs-2024\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\mlflow\\tracking\\client.py\", line 210, in log_artifact\n\u00a0 \u00a0 artifact_repo.log_artifact(local_path, artifact_path)\n\u00a0 File \"C:\\Users\\gs-2024\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\mlflow\\store\\hdfs_artifact_repo.py\", line 34, in log_artifact\n\u00a0 \u00a0 with hdfs_system(host=self.host, port=self.port) as hdfs:\n\u00a0 File \"C:\\Users\\gs-2024\\AppData\\Local\\Programs\\Python\\Python35\\lib\\contextlib.py\", line 59, in __enter__\n\u00a0 \u00a0 return next(self.gen)\n\u00a0 File \"C:\\Users\\gs-2024\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\mlflow\\store\\hdfs_artifact_repo.py\", line 168, in hdfs_system\n\u00a0 \u00a0 extra_conf=extra_conf)\n\u00a0 File \"C:\\Users\\gs-2024\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\pyarrow\\hdfs.py\", line 211, in connect\n\u00a0 \u00a0 extra_conf=extra_conf)\n\u00a0 File \"C:\\Users\\gs-2024\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\pyarrow\\hdfs.py\", line 36, in __init__\n\u00a0 \u00a0 _maybe_set_hadoop_classpath()\n\u00a0 File \"C:\\Users\\gs-2024\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\pyarrow\\hdfs.py\", line 134, in _maybe_set_hadoop_classpath\n\u00a0 \u00a0 classpath = _hadoop_classpath_glob(hadoop_bin)\n\u00a0 File \"C:\\Users\\gs-2024\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\pyarrow\\hdfs.py\", line 161, in _hadoop_classpath_glob\n\u00a0 \u00a0 return subprocess.check_output(hadoop_classpath_args)\n\u00a0 File \"C:\\Users\\gs-2024\\AppData\\Local\\Programs\\Python\\Python35\\lib\\subprocess.py\", line 316, in check_output\n\u00a0 \u00a0 **kwargs).stdout\n\u00a0 File \"C:\\Users\\gs-2024\\AppData\\Local\\Programs\\Python\\Python35\\lib\\subprocess.py\", line 383, in run\n\u00a0 \u00a0 with Popen(*popenargs, **kwargs) as process:\n\u00a0 File \"C:\\Users\\gs-2024\\AppData\\Local\\Programs\\Python\\Python35\\lib\\subprocess.py\", line 676, in __init__\n\u00a0 \u00a0 restore_signals, start_new_session)\n\u00a0 File \"C:\\Users\\gs-2024\\AppData\\Local\\Programs\\Python\\Python35\\lib\\subprocess.py\", line 957, in _execute_child\n\u00a0 \u00a0 startupinfo)\nFileNotFoundError: [WinError 2] The system cannot find the file specified\n\n\nCan anyone help me with this?",
        "Answers":[
            {
                "Answer_creation_time":"2019-06-17T19:59:21",
                "Answer_body":"Hi Shevy,\n\nSorry for the\u00a0late reply & thanks for raising this. I've copied this over to\u00a0https:\/\/github.com\/mlflow\/mlflow\/issues\/1466, let's continue discussion there - would you mind commenting on the issue with your version of MLflow etc?\n\nIn general, for these types of issues we recommend filing a GitHub issue, so that others with the same problem can easily find & discuss it.\n\nThanks!\nSid\n\n\n\ue5d3\n\ue5d3\nConfidentiality Notice and Disclaimer: This email (including any attachments) contains information that may be confidential, privileged and\/or copyrighted. If you are not the intended recipient, please notify the sender immediately and destroy this email. Any unauthorized use of the contents of this email in any manner whatsoever, is strictly prohibited. If improper activity is suspected, all available information may be used by the sender for possible disciplinary action, prosecution, civil claim or any remedy or lawful purpose. Email transmission cannot be guaranteed to be secure or error-free, as information could be intercepted, lost, arrive late, or contain viruses. The sender is not liable whatsoever for damage resulting from the opening of this message and\/or the use of the information contained in this message and\/or attachments. Expressions in this email cannot be treated as opined by the sender company management \u2013 they are solely expressed by the sender unless authorized.\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/946e7f11-30bc-49a2-a546-9b2732e14406%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            }
        ]
    },
    {
        "Question_title":"HOW LOG IN PRODUCTION?",
        "Question_creation_date":"2021-09-24T16:10:34",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/xvXSBl-2V6c",
        "Question_answer_count":0,
        "Question_view_count":14,
        "Question_body":"Hey everyone!\n\n\nI'l planning put MLFlow server into production and I'm worried about logging.\nIs there an way about how to tail logs? Is there something such a verbose mode ?\nAs far as I could see on documentation there is no way to set this thing.",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLflow 1.23.1 released!",
        "Question_creation_date":"2022-01-27T00:31:50",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/VBcXL-yx3WQ",
        "Question_answer_count":0,
        "Question_view_count":25,
        "Question_body":"We are happy to announce the availability of\u00a0MLflow\u00a01.23.1!\n\nMLflow 1.23.1 is a patch release containing the following bug fixes:\n\n[Models] Fix a directory creation failure when loading PySpark ML models (#5299,\u00a0@arjundc-db)\n[Model Registry] Revert to using case-insensitive validation logic for stage names in\u00a0models:\/\u00a0URIs (#5312,\u00a0@lichenran1234)\n[Projects] Fix a race condition during Project tar file creation (#5303,\u00a0@dbczumar)\n\nNote: Version 1.23.1 of the MLflow R package has not yet been released. It will be available on CRAN within the next week.",
        "Answers":[

        ]
    },
    {
        "Question_title":"How to display artifacts in AWS S3?",
        "Question_creation_date":"2022-08-05T01:28:51",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/D3K4imRGS20",
        "Question_answer_count":1,
        "Question_view_count":15,
        "Question_body":"Hi there,\n\n\nI'm using Mlflow 1.27.0 tracking server with docker, log db (MySQL), Artifacts storage (AWS S3). I'm trying to make model with log_params, metrics, artifacts and checked the functions worked correctly. Also, I checked my artifacts storage(AWS S3) whether artifacts are stored or not and there was no problem.\n\n\nBut, if i access tracking server and select specific log in experiment, there is no display about artifacts with tracking server's error.\n\u00a0\nSo, I want to know display artifacts in aws s3 is impossible or just environment error.\n\n\nHere are links refer to solve this problem.\n\n\nhttps:\/\/docs.databricks.com\/applications\/mlflow\/tracking.html\n\nhttps:\/\/stackoverflow.com\/questions\/72280328\/mlflow-artifacts-on-s3-but-not-in-ui\n\n\n\nBest regards,\nKwon",
        "Answers":[
            {
                "Answer_creation_time":"2022-08-05T02:28:28",
                "Answer_body":"I'm sorry. I solved...\n\n\nThe reason was region name in .aws\/credentials\n\n\n\n\n\n2022\ub144 8\uc6d4 5\uc77c \uae08\uc694\uc77c \uc624\ud6c4 2\uc2dc 28\ubd84 51\ucd08 UTC+9\uc5d0 \uad8c\uc724\uc7ac\ub2d8\uc774 \uc791\uc131:\n\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"security setup - username\/password experiment level",
        "Question_creation_date":"2018-11-15T00:55:19",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/E9QW4HdS8a8",
        "Question_answer_count":4,
        "Question_view_count":4154,
        "Question_body":"Hi\n\n\nCurrently the way mlflow works is that we can set an experiment ID for a MLFLOW tracker server URL and call it using our training model code. We would like to see if we can add security to this - say setup username\/password and also assign users with permissions for certain experiments\/projects. Is it possible to do that?",
        "Answers":[
            {
                "Answer_creation_time":"2018-11-20T21:46:46",
                "Answer_body":"Hi Maheshwar,\n\nCurrently, we recommend adding authentication in front of your MLflow server using a HTTP proxy such as nginx. You can configure this to use some other internal authentication mechanism, such as verifying whether the user is part of a group. This won\u2019t isolate things per user, but you could run a separate tracking server for each team using ML for example.\n\nMatei\n\n\n\n> On Nov 14, 2018, at 9:55 PM, Maheshwar Dattatri <mahes...@gmail.com> wrote:\n>\n>\n> Hi\n>\n> Currently the way mlflow works is that we can set an experiment ID for a MLFLOW tracker server URL and call it using our training model code. We would like to see if we can add security to this - say setup username\/password and also assign users with permissions for certain experiments\/projects. Is it possible to do that?\n>\n\n> --\n> You received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\n> To unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\n> To post to this group, send email to mlflow...@googlegroups.com.\n> To view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/de8d707f-fee9-4450-b906-89142f5d9827%40googlegroups.com.\n> For more options, visit https:\/\/groups.google.com\/d\/optout."
            },
            {
                "Answer_creation_time":"2018-11-22T03:28:48",
                "Answer_body":"Hi Matei\n\n\nIn \"rest_utils.py\" , there is \"http_request\" function, which receives host_creds (include username, password) to make http request for authentication\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/utils\/rest_utils.py#L20\u00a0\u00a0\n\nThe \"http_request\" fucntion is also used in \"databricks.py\"\nhttps:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/projects\/databricks.py#L88\n\n\n\nCould we use this function to make authentication for MLflow?\nDoes MLflow support authentication for next versions ?\n\n\nTriet Nguyen\n\ue5d3"
            },
            {
                "Answer_creation_time":"2018-11-22T18:50:09",
                "Answer_body":"Yes, you can actually pass these already using the environment variables MLFLOW_TRACKING_USERNAME and MLFLOW_TRACKING_PASSWORD or MLFLOW_TRACKING_TOKEN (see https:\/\/github.com\/mlflow\/mlflow\/blob\/master\/mlflow\/tracking\/utils.py). These will be used with all HTTP requests to the tracking server. You can run the server behind a proxy such as nginx to perform authentication before passing requests through (the goal here is to make it possible for people to integrate it with their own company\u2019s auth systems instead of baking one into our server).\n\nMatei\n\n\ue5d3\n> To view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/a25a55cb-9d64-438d-9e84-4f5061b59aed%40googlegroups.com.\n\n\ue5d3"
            },
            {
                "Answer_creation_time":"2021-11-29T10:21:54",
                "Answer_body":"Hello, this is an old question but we tried the solution suggested by @matei and we hit a dead end because of the following reasons\n\n\n\n- Nginx `auth_request` erases the data before sending `\/authorize` requests and MLFlow sends the `experiment_id`\/`run_id` in the data of `POST` and `UPDATE` requests instead of the URL (`POST \/tracking\/experiments\/1`), this makes it impossible to authorize such requests, we are denying all them right now.\n- We can't filter out the list of the experiments a user can see, we can only allow them to do a request or not. If we don't allow them to see the list of experiments, the front page of MLFlow will broken.\n\n\nI think access control mechanics over MLFlow resources should implemented in MLFlow itself or in an MLFlow plugin or at least think about how third party application can do that and makes it possible for them, that way we'll have access to the database, the UI and everything we need to implement such features.\n\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"Model Deployment Issues",
        "Question_creation_date":"2019-09-03T10:59:24",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/QPGFSApJ4Io",
        "Question_answer_count":3,
        "Question_view_count":41,
        "Question_body":"Hello,\n\n\nI've been trying to deploy a scikit-learn model (a super simple classification using the Iris data set) that I built and trained using the standard MLproject protocol. I have been trying to deploy in two different manners and have been getting errors both ways:\n\n\nServe the model using a local REST server\n\nTo serve the model, I have been using the following command:\nmlflow models serve -m mlruns\/0\/f7cad9db15134c2abaa6d2a8b208c505\/artifacts\/sk_models -h **.***.**.** -p 1234 --no-conda\nNOTE: The host flag is the correct IP, I just masked it for this post\n\nWhen I run this command, I get the following output:\n2019\/09\/03 14:36:16 INFO mlflow.models.cli: Selected backend for flavor 'python_function'\n2019\/09\/03 14:36:16 INFO mlflow.pyfunc.backend: === Running command 'gunicorn --timeout=60 -b **.***.**.**:1234 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app'\nbash: gunicorn: command not found\n\nI have ensured that gunicorn is in fact installed:\nsudo gunicorn --version\ngunicorn (version 19.9.0)\n\nIs this an issue that anyone else has run into?\n\n\nDeploy the model to Sagemaker\n\nTo deploy onto Sagemaker, I built the model using MLProject. The docker image that I have uploaded to ECR is the image I used to run the project and generate the model. When I attempt to deploy the model, I am using the following python script (the XXXX are personal info I removed for the post):\n\nimport mlflow.sagemaker as mfs\n\n\nrun_id = '0'\nexperiment_id = 'f7cad9db15134c2abaa6d2a8b208c505'\nregion = 'us-east-1'\naws_id = 'XXXXXXX'\narn = 'XXXXXXXXXX'\nimage_url = 'XXXXXXX\/mlflow-sklearn-test:latest'\napp_name = 'iris-dt-1'\nmodel_uri = 'mlruns\/%s\/%s\/artifacts\/sk_models' % (run_id, experiment_id)\n\n\nmfs.deploy(app_name=app_name, model_uri=model_uri, region_name=region, mode='create', execution_role_arn=arn, image_url=image_url)\n\n\nWhen I run the script, I get the following error:\n\u00a0\n2019\/09\/03 14:50:53 INFO mlflow.sagemaker: Creating new endpoint with name: iris-dt-1 ...\nTraceback (most recent call last):\n\u00a0 File \"sagemaker_deployment.py\", line 12, in <module>\n\u00a0 \u00a0 mfs.deploy(app_name=app_name, model_uri=model_uri, region_name=region, mode='create', execution_role_arn=arn, image_url=image_url)\n\u00a0 File \"\/usr\/local\/lib\/python3.6\/site-packages\/mlflow\/sagemaker\/__init__.py\", line 325, in deploy\n\u00a0 \u00a0 role=execution_role_arn, sage_client=sage_client)\n\u00a0 File \"\/usr\/local\/lib\/python3.6\/site-packages\/mlflow\/sagemaker\/__init__.py\", line 628, in _create_sagemaker_endpoint\n\u00a0 \u00a0 sage_client=sage_client)\n\u00a0 File \"\/usr\/local\/lib\/python3.6\/site-packages\/mlflow\/sagemaker\/__init__.py\", line 840, in _create_sagemaker_model\n\u00a0 \u00a0 model_response = sage_client.create_model(**create_model_args)\n\u00a0 File \"\/usr\/local\/lib\/python3.6\/site-packages\/botocore\/client.py\", line 357, in _api_call\n\u00a0 \u00a0 return self._make_api_call(operation_name, kwargs)\n\u00a0 File \"\/usr\/local\/lib\/python3.6\/site-packages\/botocore\/client.py\", line 661, in _make_api_call\n\u00a0 \u00a0 raise error_class(parsed_response, operation_name)\nbotocore.exceptions.ClientError: An error occurred (ValidationException) when calling the CreateModel operation: ECR image \"XXXXXXX\/mlflow-sklearn-test:latest\" is invalid.\n\n\nHas anyone experienced this error before? I have tried googling the answer and the only answer I could find was to add the\u00a0:latest\u00a0tag to the image URI, but I have already done this and I still get the error.\n\n\n\n\nThank you so much!!",
        "Answers":[
            {
                "Answer_creation_time":"2019-09-04T00:48:20",
                "Answer_body":"Hey\u00a0Melanie,\u00a0\n\n\nFor (1) My only long-shot thought would be that maybe\u00a0its a python versioning issue, Could MLFlow be running on Python 3 and gunicorn be install on 2? Shouldn't impact bash, but it could be a problem. There's also a random suggestion to install gunicorn from source.\u00a0 Are you spinning that up in a virtual\u00a0environment just to control for all of the dependencies.\n\n\n\n\nFor (2) I think this is an issue we dealt with, two things to try:\nin ECR, when you go into the repository in the console, is \"latest\" the image tag that is listed? Are there any others? If not, I'd maybe try pushing a new image to the same repository with a new tag, and then reference that tag just to confirm.\nAlthough this doesn't explicitly state anything about permissions, there's a chance it's a sneaky IAM issue. In the CreateModel docs\u00a0(which mlflow is calling), it mentions that the user who is calling this endpoint must have permissions to assume the role to provide access to the artifacts or containers. This means the account that boto3 is attached to in python should have an sts:assumerole permission that assume a role with access to ECR (this is probably the right permission). I've attached the JSON example that you can give you could add to account to test the assume role permission.\u00a0\n\n\nLet me know if any of this helps!\n\n\n-Adam\n\n\n\n\n\ue5d3\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/36db1100-ba72-48f2-90b8-faa55c8e560b%40googlegroups.com."
            },
            {
                "Answer_creation_time":"2019-09-13T19:05:15",
                "Answer_body":"Hi Melanie,\n\n\nWere you able to confirm that the ECR image URI you're referencing is listed in the ECR console? Did Adam's ECR suggestion help you resolve the issue?\n\n\nBest,\n\n\nCorey\n\n\n\ue5d3\n\ue5d3\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/CAHbUTHtxn%3D382DaJMCgbn9gqOrQ8C-K8Re%2BJsg7XpiL92c0BDA%40mail.gmail.com."
            },
            {
                "Answer_creation_time":"2019-09-13T20:05:54",
                "Answer_body":"Sorry for the slow reply. It turns out the issues I was having was due to the ECR permissions in place at the enterprise I work at. With some help of the AWS team, I was able to get all of those permissions squared away and everything is now working."
            }
        ]
    },
    {
        "Question_title":"Artifacts are not shown in UI",
        "Question_creation_date":"2019-06-19T17:28:41",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/-WkRc1NoH5g",
        "Question_answer_count":2,
        "Question_view_count":432,
        "Question_body":"I run mlflow server with Postgres backend and local directory as default artifact root. When I run my experiments\/runs I do see them in mlflow uI, however, artifacts are not shown. Artifacts are created in the local directory ( subdirectory from which I train model), but they are not showing in UI.",
        "Answers":[
            {
                "Answer_creation_time":"2019-06-26T01:50:37",
                "Answer_body":"Where is the UI server running? It should have access to the same artifact root \u2014 you may need to pass it a command line parameter to set that.\n\n\nMatei\n\n\n\nOn Jun 19, 2019, at 2:28 PM, SoniaK <sofia....@8451.com> wrote:\n\n\nI run mlflow server with Postgres backend and local directory as default artifact root. When I run my experiments\/runs I do see them in mlflow uI, however, artifacts are not shown. Artifacts are created in the local directory ( subdirectory from which I train model), but they are not showing in UI.\n\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/b0cde6b8-ae66-444c-b0e0-431600f703a4%40googlegroups.com.\nFor more options, visit https:\/\/groups.google.com\/d\/optout."
            },
            {
                "Answer_creation_time":"2019-06-27T10:22:33",
                "Answer_body":"Thank you, Matei. Im using Minio for storing artifacts. Setting artifact location solved the problem:\u00a0\u00a0\u00a0--default-artifact-root s3:\/\/sample-bucket\n\n\nOn Wednesday, June 26, 2019 at 12:50:37 AM UTC-5, Matei Zaharia wrote:\nWhere is the UI server running? It should have access to the same artifact root \u2014 you may need to pass it a command line parameter to set that.\n\n\nMatei\n\n\n\nOn Jun 19, 2019, at 2:28 PM, SoniaK <sofia...@8451.com> wrote:\n\n\nI run mlflow server with Postgres backend and local directory as default artifact root. When I run my experiments\/runs I do see them in mlflow uI, however, artifacts are not shown. Artifacts are created in the local directory ( subdirectory from which I train model), but they are not showing in UI.\n\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\n\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow...@googlegroups.com.\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"MLflow 1.9.1 released!",
        "Question_creation_date":"2020-06-25T03:20:57",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/z--UqHehim0",
        "Question_answer_count":0,
        "Question_view_count":10,
        "Question_body":"Hi all,\n\nWe are happy to announce the availability of MLflow 1.9.1! It's a patch release containing a number of bug-fixes & improvements:\n\n\nFixes AttributeError when pickling an instance of the Python MlflowClient class (#2955, @Polyphenolx)\nFixes bug that prevented updating model-version descriptions in the model registry UI (#2969, @AnastasiaKol)\u00a0\nFixes bug where credentials were not properly propagated to artifact CLI commands when logging artifacts from Java to the DatabricksArtifactRepository (#3001, @dbczumar)\nRemoves use of new Pandas API in new MLflow model-schema functionality, so that it can be used with older Pandas versions (#2988, @aarondav)\nFor a comprehensive list of changes, see the release change log, and check out the latest documentation on https:\/\/mlflow.org\/\n\nThanks,\nSid",
        "Answers":[

        ]
    },
    {
        "Question_title":"MLflow 1.20.1 released!",
        "Question_creation_date":"2021-08-26T04:06:12",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/OxR3LPYxfgU",
        "Question_answer_count":0,
        "Question_view_count":7,
        "Question_body":"We are happy to announce the availability of\u00a0MLflow 1.20.1!\n\nNote: The MLflow R package for 1.20.1 is not yet available but will be in a week because CRAN's submission system will be offline until September 1st.\n\nMLflow 1.20.1 is a patch release for the MLflow Python and R packages containing the following bug fixes:\n\n-\u00a0Avoid calling\u00a0`importlib_metadata.packages_distributions`\u00a0upon\u00a0`mlflow.utils.requirements_utils`\u00a0import (#4741, @dbczumar)\n-\u00a0Avoid depending on\u00a0`importlib_metadata==4.7.0`\u00a0(#4740, @dbczumar)\n\nFor a comprehensive list of changes, see the\u00a0release change log, and check out the latest documentation on\u00a0mlflow.org.",
        "Answers":[

        ]
    },
    {
        "Question_title":"Is there a specification document for server sizing?",
        "Question_creation_date":"2018-06-27T03:39:26",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/f0hQ6k4w8dA",
        "Question_answer_count":2,
        "Question_view_count":42,
        "Question_body":"Hello,\n\n\nI'll give MLflow a try within my team: that'll be a few data scientists trying out some use cases to evaluate MLflow in our environment.\n\n\n\nI couldn't find a specification document for sizing servers for MLflow installation. Is there some kind of guideline that could tell me amount of CPU, RAM, etc. for the server on which MLflow runs? It's of course not very important in this early stage, but nevertheless I think having such a guideline would be good.\n\n\nCheers,\nEmre",
        "Answers":[
            {
                "Answer_creation_time":"2018-06-27T13:04:18",
                "Answer_body":"For your reference, at least in a test environment, I have my MLflow server running on a t2.micro (free-tier) instance.\u00a0 Of course, its just me hitting it ;-).\n\ue5d3"
            },
            {
                "Answer_creation_time":"2018-06-27T17:17:51",
                "Answer_body":"Hey guys,\n\n\nI have got ML flow working in a docker image on an AWS EC2 instance (t2.medium). We are able to have multiple data scientists send jobs to the tracker. However, I am unable to store artifacts on a remote VM from different local machines.\n\n\nAny ideas if this is in the pipeline?\n\n\nCheers,\nVivek\n\n\n\ue5d3\n\ue5d3\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users+unsubscribe@googlegroups.com.\nTo post to this group, send email to mlflow...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/094a339c-e77c-4220-80df-a1e5693e5092%40googlegroups.com.\n\nFor more options, visit https:\/\/groups.google.com\/d\/optout.\n\n\n\n\n\n\n--\n\nVivek Katial\nData Scientist\n\n\n\n\n\nLevel 1, 155 Karangahape Road, Auckland Central,\u00a01010\nvivek....@quantiful.co.nz | \u00a00210435892\nwww.quantiful.co.nz"
            }
        ]
    },
    {
        "Question_title":"Help us with the MLflow Features",
        "Question_creation_date":"2019-01-21T11:38:39",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/QQ7ycCYpeGE",
        "Question_answer_count":0,
        "Question_view_count":28,
        "Question_body":"Hello,\n\n\n\n\nWe would like to continue our momentum of building new MLflow features at the same pace as we did in the past six months. We need your help. Give us your feedback by taking\n\nthis user\u00a0feedback survey.\n\n\n\n\nYou can also read Matei's blog: Kicking off 2019 with an MLflow Survey.\u00a0\n\n\n\n\nThank you for help.\n\n\n\n\nCheers,\n\nJules\n\n--\u00a0\n\n\nThe Best Ideas are Simple\n\nJules S. Damji\n\nApache Spark Developer & Community Advocate\n\nDatabricks, Inc.\n\nju...@databricks.com\n\n(510) 304-7686\n\ndatabricks.com",
        "Answers":[

        ]
    },
    {
        "Question_title":"Organizations using and contributing to MLflow - we are using it! :)",
        "Question_creation_date":"2020-04-28T10:33:37",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/n8GI4uhm8No",
        "Question_answer_count":2,
        "Question_view_count":40,
        "Question_body":"Hello MLflow organization,\n\nAt\u00a0Stratio\u00a0- a leading Big Data and Artificial Intelligence company - we've been using MLflow and integrating it to our product. We want MLFlow to be one of the key elements for the development of ML Algorithms\u00a0in our product and we've already been using it for quite some time.\u00a0\n\n\nWe would really like to be included in your website's list of contributors.\u00a0Attached you can find our logo. Please let us know if you need anything else.\n\nThanks in advance,\n\nStratio Team",
        "Answers":[
            {
                "Answer_creation_time":"2020-04-28T11:11:42",
                "Answer_body":"\ufeffThanks for using and contributing. We shall include your logo soon.\u00a0\n\n\nCheers\u00a0\nJules\u00a0\n\n\nSent from my iPhone\nPardon the dumb thumb typos :)\n\n\nOn Apr 28, 2020, at 7:33 AM, Communications Stratio <co...@stratio.com> wrote:\n\n\n\ufeff\n\ue5d3\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/bf478e53-d61b-44c0-9b26-a4141a7ae5ed%40googlegroups.com.\n\n<2020_Stratio.svg>"
            },
            {
                "Answer_creation_time":"2020-04-28T11:22:26",
                "Answer_body":"Perfect! Thank you very much Jules :)\n\ue5d3\n--\n\n\n\n\n\n| Stratio Comms\n\n\n\n\nV\u00eda de las dos Castillas, 33, \u00c1tica 4, 2\u00aa Planta\n\n28224 Pozuelo de Alarc\u00f3n, Madrid, Spain\u00a0\n\n+34 918 286 473 | www.stratio.com\n\nThis e-mail and the information contained in it is confidential and it is addressed exclusively to the recipient named in the heading. If you have received or accessed this message by error, please notify us and proceed to erase it immediately. Any unauthorized disclosure, copying, distribution or use of the information contained therein is prohibited by law. The personal data provided by you or by third parties are the responsibility of STRATIO in order to manage and maintain contacts and relationships that occur as a result of the relationship with STRATIO. Normally, the legal basis that legitimates this processing, will be your consent, our legitimate interest or the need to manage a contractual relationship with you. The storage period of your data will be determined by your relationship with us. STRATIO's email service is outsourced with Google, which implies an international transfer of your contact data to the United States; however, Google provides adequate data protection guarantees, by adhering to the Privacy Shield framework, and because of the authorization TI\/00153\/2017 of the Spanish Data Protection Agency (AEPD) to transfer personal data to the United States. For further information, or to exercise your rights of access, rectification, erasure, objection, limitation or portability, please write to pri...@stratio.com. Likewise, in the event that you consider your data protection rights violated in any manner, you may file a claim with the AEPD (www.aepd.es)."
            }
        ]
    },
    {
        "Question_title":"connecting vertica to mlflow for recording runs",
        "Question_creation_date":"2019-09-13T03:39:03",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/Fg7JEwWlbTA",
        "Question_answer_count":2,
        "Question_view_count":23,
        "Question_body":"Hi,\u00a0\n\nHas anyone tried connecting vertica with mlflow? It's an\u00a0SQLAlchemy compatible database which means it should work with mlflow.",
        "Answers":[
            {
                "Answer_creation_time":"2019-09-16T18:07:19",
                "Answer_body":"I\u2019m not sure whether anyone\u2019s tried it, but feel free to open an issue on GitHub if you run into problems with it. It should work through SQLAlchemy.\n\n\n\nOn Sep 13, 2019, at 12:39 AM, Ali Mojiz <ali.m...@gmail.com> wrote:\n\n\nHi,\u00a0\n\nHas anyone tried connecting vertica with mlflow? It's an\u00a0SQLAlchemy compatible database which means it should work with mlflow.\u00a0\n\n\n--\nYou received this message because you are subscribed to the Google Groups \"mlflow-users\" group.\nTo unsubscribe from this group and stop receiving emails from it, send an email to mlflow-users...@googlegroups.com.\nTo view this discussion on the web visit https:\/\/groups.google.com\/d\/msgid\/mlflow-users\/a553d0e7-6402-450b-9282-34116e9c653a%40googlegroups.com."
            },
            {
                "Answer_creation_time":"2019-09-17T02:06:00",
                "Answer_body":"Great. I shall do that. Thanks!\n\ue5d3"
            }
        ]
    },
    {
        "Question_title":"MLflow Release 0.5.2",
        "Question_creation_date":"2018-08-27T20:56:33",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/k9oG1jeZxQM",
        "Question_answer_count":0,
        "Question_view_count":31,
        "Question_body":"MLflow Release 0.5.2 is ready, released 2018-08-27. The release is available on\u00a0PyPI\u00a0and docs are\u00a0updated. Here are the release notes (also available\u00a0on GitHub):\n\n\nBreaking changes: None\n\n\n\nChange log:\n\n\n0.5.2 (2018-08-24)\n------------------\n\n\nMLflow 0.5.2 is a patch release on top of 0.5.1 containing only bug fixes and no breaking changes or features.\n\n\nBug fixes:\n\n\n- Fix a bug with ECR client creation that caused ``mlflow.sagemaker.deploy()`` to fail when searching for a deployment Docker image (#366, @dbczumar)",
        "Answers":[

        ]
    },
    {
        "Question_title":"Regarding pushing managed MLflow models to sagemaker endpoints",
        "Question_creation_date":"2022-01-05T06:21:30",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/oPRZpS35XRw",
        "Question_answer_count":0,
        "Question_view_count":18,
        "Question_body":"Hi All,\n\n\nDoes anybody know anything about the below procedure.\n\n\nIf we have a registered model on managed AWS Databricks then how can we publish it as sagemaker endpoint.\u00a0\n\n\nThe mlflow sagemaker API doesn\u2019t work because it requires an image to be present in ECR. This seems like a manual step. Also the model registry path is not accessible on databricks. Only accessible via mlflow API.\u00a0\n\n\nIs there any way where we can directly push our managed mlflow models to sagemaker endpoint with \u00a0all the imgae creation and push steps are automatically handled by the API itself.\n\n\nThanks\nSaurabh\n\n\n--\n\nThanks & Regards\nSaurabh Verma",
        "Answers":[

        ]
    },
    {
        "Question_title":"RFC: Batched logging APIs in MLflow",
        "Question_creation_date":"2019-02-25T17:49:00",
        "Question_link":"https:\/\/groups.google.com\/g\/mlflow-users\/c\/0M2BIceZirQ",
        "Question_answer_count":0,
        "Question_view_count":13,
        "Question_body":"Hi all,\n\n\nThis GitHub issue contains a proposal for adding new REST, fluent, and client APIs for logging batches of metrics\/params\/tags in MLflow, which we expect will improve performance by reducing the number of API requests needed to log data.\n\n\n\nWe may deprecate the existing set of REST APIs in favor of the new batched API endpoint in MLflow 1.0. Any feedback is welcome - we'd like to start implementation work on this by early next week.\n\nThanks!\nSid",
        "Answers":[

        ]
    }
]