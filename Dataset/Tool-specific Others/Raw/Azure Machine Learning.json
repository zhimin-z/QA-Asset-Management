[
    {
        "Question_title":"Azure machine learning compute local",
        "Question_creation_time":1669634912270,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1106844\/azure-machine-learning-compute-local.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"Hello all, I have followed the https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-azure-ml-in-a-day tutorial with successful result. Now, instead of using the compute cluster, i would like to use the resources of my local computer to run the job. I change the compute option to 'local' in the command function, but throws me an error: JobException: Failed to read in local executable job. Do i need additional configuration? Thanks in advance.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-29T07:50:45.563Z",
                "Answer_score":0,
                "Answer_body":"@ramr-msft Good morning!! Thank you for your reply. I tried the code you wrote above but everytime i change parameters i get the same error: 'JobException: Failed to read in local executable job. If i create a compute, then set it in the command function it runs successfully and create the job in aml studio. I upload some pictures of the code and the error: \n\n\n\n\n\nAny idea why this error is happening?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Endpoint Unhealthy error when trying to test deployed endpoint for inference pipeline",
        "Question_creation_time":1669672796280,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1107528\/endpoint-unhealthy-error-when-trying-to-test-deplo.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":19,
        "Question_score":0,
        "Question_body":"Hello, I am following the module from Microsoft Learn on regression using Azure's Machine Learning Designer, when trying to Test the service\n\nhttps:\/\/microsoftlearning.github.io\/AI-900-AIFundamentals\/instructions\/02a-create-regression-model.html#test-the-service\n\nWhen trying to test the predict-auto-price endpoint, I get the following screen\n\n\n\n\n\n\n\nDoes anyone know how I can address this? I am fairly new to Azure, so I apologize if I'm missing something obvious",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Batchscoring on Batch Endpoint of AutoML model giving error - UserError: {\"NonCompliant\":\"Process",
        "Question_creation_time":1669318257423,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1103764\/batchscoring-on-batch-endpoint-of-automl-model-giv.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":18,
        "Question_score":0,
        "Question_body":"AutoML time-series model created from Sql Database data. - successful\nRegistered Model. - successful\nEndPoints creation - Deploy to Batch End Point. - successful\nCreating Batchscoring Jon in EndPoint - Fails with below error.\n\nError -\n{\"NonCompliant\":\"Process '\/azureml-envs\/azureml_c9e8754bdba5226a1ab803f256ee343b\/bin\/python' exited with code 1 and error message 'Execution failed. Process exited with status code 1. Error: Traceback (most recent call last):\\n File \\\"driver\/amlbi_main.py\\\", line 184, in <module>\\n main()\\n File \\\"driver\/amlbi_main.py\\\", line 126, in main\\n boot(driver_dir)\\n File \\\"driver\/amlbi_main.py\\\", line 58, in boot\\n booter.start()\\n File \\\"\/mnt\/azureml\/cr\/j\/5abd1dee5bc441ae8d26b873695fdcf8\/exe\/wd\/driver\/azureml_user\/parallel_run\/boot.py\\\", line 383, in start\\n self.start_sys_main()\\n File \\\"\/mnt\/azureml\/cr\/j\/5abd1dee5bc441ae8d26b873695fdcf8\/exe\/wd\/driver\/azureml_user\/parallel_run\/boot.py\\\", line 269, in start_sys_main\\n self.run_sys_main(cmd)\\n File \\\"\/mnt\/azureml\/cr\/j\/5abd1dee5bc441ae8d26b873695fdcf8\/exe\/wd\/driver\/azureml_user\/parallel_run\/boot_node.py\\\", line 111, in run_sys_main\\n self.check_run_result(proc=proc, stdout=stdout or \\\"\\\", stderr=stderr or \\\"\\\")\\n File \\\"\/mnt\/azureml\/cr\/j\/5abd1dee5bc441ae8d26b873695fdcf8\/exe\/wd\/driver\/azureml_user\/parallel_run\/boot.py\\\", line 218, in check_run_result\\n BootResult().check_result(stdout)\\n File \\\"\/mnt\/azureml\/cr\/j\/5abd1dee5bc441ae8d26b873695fdcf8\/exe\/wd\/driver\/azureml_user\/parallel_run\/boot_result.py\\\", line 36, in check_result\\n raise Exception(message) from cause\\nException: Run failed, please check logs for details. You can check logs\/readme.txt for the layout of logs.\\n\\n'. Please check the log file 'user_logs\/std_log_0.txt' for more details.\"}\n{\n\"code\": \"ExecutionFailed\",\n\"target\": \"\",\n\"category\": \"UserError\",\n\"error_details\": [\n{\n\"key\": \"exit_codes\",\n\"value\": \"1\"\n}\n]\n}",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Error while depolying Whisper Model in batch pipeline",
        "Question_creation_time":1667482799767,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1074438\/error-while-depolying-whisper-model-in-batch-pipli.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":17,
        "Question_score":0,
        "Question_body":"I'm trying to deploy the OpenAI Whisper model with a batch pipeline, following the example notebook: https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/parallel-run\/file-dataset-image-inference-mnist.ipynb\n\nI'm using the STANDARD_NC6S_V3 Machine.\n\nI keep getting the following error:\n\nError '\/azureml-envs\/azureml_2b0a8ce0115582fe46e2aa65a9665d55\/lib\/python3.9\/site-packages\/torch\/lib\/..\/..\/nvidia\/cublas\/lib\/libcublas.so.11: undefined symbol: cublasLtGetStatusString, version libcublasLt.so.11 File \"\/mnt\/azureml\/cr\/j\/3f034c6e7a1b4166b24b196339e7b655\/exe\/wd\/whisper_transcribe.py\", line 3, in <module>\nimport whisper\nFile \"\/azureml-envs\/azureml_2b0a8ce0115582fe46e2aa65a9665d55\/lib\/python3.9\/site-packages\/whisper\/init.py\", line 8, in <module>\nimport torch\nFile \"\/azureml-envs\/azureml_2b0a8ce0115582fe46e2aa65a9665d55\/lib\/python3.9\/site-packages\/torch\/init.py\", line 191, in <module>\nload_global_deps()\nFile \"\/azureml-envs\/azureml_2b0a8ce0115582fe46e2aa65a9665d55\/lib\/python3.9\/site-packages\/torch\/init.py\", line 153, in load_global_deps\nctypes.CDLL(lib_path, mode=ctypes.RTLD_GLOBAL)\nFile \"\/azureml-envs\/azureml_2b0a8ce0115582fe46e2aa65a9665d55\/lib\/python3.9\/ctypes\/init.py\", line 382, in init\nself._handle = _dlopen(self._name, mode)'\n\nI can't find what causes the error, but I think it has to do with the machine I'm deploying on, because with a different machine, the error did not appear.\nhelp will be much appreciated.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Import issue with azureml-train-automl-runtime package",
        "Question_creation_time":1669689516027,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1107805\/import-issue-with-azureml-train-automl-runtime-pac.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I am trying to import azureml-train-automl-runtime to do explanations from azure automl pipeline following the tutorial in the link https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/v1\/how-to-machine-learning-interpretability-automl\n\nBut I am getting the below error\n\n Exception ignored in: <function _Win32Helper.del at 0x0000021ECA3AD430> Traceback (most recent call last): File \"C:\\Anaconda3\\envs\\check_win32_error\\lib\\site-packages\\azureml\\automl\\runtime\\shared\\win32_helper.py\", line 246, in del TypeError: catching classes that do not inherit from BaseException is not allowed\n\n\n\n\nError Screenshot:\n\n\n\n\n\nI asked this question in stackoverflow but did not get valid answer,\nplease refer to the stackoverflow link below:\nhttps:\/\/stackoverflow.com\/questions\/74160617\/baseexception-when-trying-to-import-azureml-train-automl-runtime-in-windows-10",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Why explanation dashboard is showing 2 tabs with duplicate information in Azure ML Studio?",
        "Question_creation_time":1669620849057,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1106407\/why-explanation-dashboard-is-showing-2-tabs-with-d.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"When using explanations for AutoML models or standalone model, the explanation dashboard has 2 tabs which displays same information.\n\nI am using azureml-interpret to explain the models that are executed under azure context and upload the explanations into Azure ML studio.\nI use global_explanation and local_explanation to explain the overall model performance and local model performance.\n\nI guess this is creating 2 tabs if I am correct, but both of them seems to have same or duplicate information. I don't understand what is the need for that?\n\nThis seem to the case when I use AutoML models also, there is 2 tabs which has same information. Note, here I am not uploading anything, it is by default uploading the model explanations and I am using azure-python-sdk-v1.\n\nI have provided the accompanying screenshots with the information, please let me know if there is gap in my understanding or it is problem with the azure explanation?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-28T11:24:56.12Z",
                "Answer_score":1,
                "Answer_body":"@BharathKumarLoganathan-7743 I think the explanation ids are based on the raw and engineered datasets. Raw explanations are based on the features from the original dataset and engineered explanations are based on the features from the dataset with feature engineering applied. The documentation from these links provides a bit more information about the different explanation ids. If you expand the menu on the left this should confirm the same.\n\nhttps:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-automated-ml-for-ml-models#model-explanations-preview\nhttps:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-machine-learning-interpretability-aml#visualizations\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning Data Labeling: labeler can access the project but can't see the data",
        "Question_creation_time":1669659426597,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1107289\/azure-machine-learning-data-labeling-labeler-can-a.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Granted the \"labeler\" permission. But when vendor clicked the \"start labeling\" button, blank under \"Tasks\".",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"The pre-built components of the pipeline designer in Azure ML studio don't appear",
        "Question_creation_time":1653032834087,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/857398\/the-pre-built-components-of-the-pipeline-designer.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"With allarming frequency, when I try to design a pipeline I don't have access to all the pre-built components\/assets. In this case, the only components that are still available are the datasets, web input and output and the custom components. This problem reverts itself after some time without any input. What should I do to avoid it or at least revert it as fast as possible?\n\nEdit: I add a screenshot of the issue",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-25T11:19:16.43Z",
                "Answer_score":0,
                "Answer_body":"Experiencing this as well, any update?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-11-28T16:55:48.91Z",
                "Answer_score":0,
                "Answer_body":"I have this challenge as well. Any tips?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AciDeploymentFailed",
        "Question_creation_time":1655464430947,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/893526\/acideploymentfailed.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hello,\n\nIt's been a few days already since I've been struggling with this error which is not suggesting me anything.\nThis is the error I receive. Every time I'm trying to access the logs it displays me \"None\". Also, the init() function is a very basic one. It's the one I've found in your tutorials and while I've followed your tutorials I didn't encounter this bug.\n\nscore.py script:\n\n import pandas as pd\n import numpy as np\n import joblib\n import json\n import os\n    \n # Called when the service is loaded\n def init():\n     global model\n     # Get the path to the deployed model file and load it\n     model = joblib.load(Model.get_model_path(model_name='aml_live_model_end'))\n    \n # Called when a request is received\n def run(raw_data):\n     # Get the input data as a numpy array\n     data = np.array(json.loads(raw_data)['data'])\n     # Get a prediction from the model\n     predictions = model.predict(data)\n     # Get the corresponding classname for each prediction (0 or 1)\n     classnames = ['De avizat', 'De analizat']\n     predicted_classes = []\n     for prediction in predictions:\n         predicted_classes.append(classnames[prediction])\n     # Return the predictions as JSON\n     return json.dumps(predicted_classes)\n\n\n\n\n.yaml file\n\n name: aml_live_env\n dependencies:\n - python=3.6.2\n - scikit-learn\n - ipykernel\n - matplotlib\n - pandas\n - pip\n - pip:\n   - azureml-defaults\n   - pyarrow\n\n\n\n\nThe error I receive\n\n Deploying model...\n Tips: You can try get_logs(): https:\/\/aka.ms\/debugimage#dockerlog or local deployment: https:\/\/aka.ms\/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n Running\n 2022-06-17 10:52:16+00:00 Creating Container Registry if not exists.\n 2022-06-17 10:52:16+00:00 Registering the environment.\n 2022-06-17 10:52:17+00:00 Use the existing image.\n 2022-06-17 10:52:17+00:00 Generating deployment configuration.\n 2022-06-17 10:52:18+00:00 Submitting deployment to compute.\n 2022-06-17 10:52:20+00:00 Checking the status of deployment aml-live-service-model..\n 2022-06-17 10:54:07+00:00 Checking the status of inference endpoint aml-live-service-model.\n Failed\n Service deployment polling reached non-successful terminal state, current service state: Failed\n Operation ID: 93d48e89-cb16-4d1c-bbb6-f453acaeaa7f\n More information can be found using '.get_logs()'\n Error:\n {\n   \"code\": \"AciDeploymentFailed\",\n   \"statusCode\": 400,\n   \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n     1. Please check the logs for your container instance: aml-live-service-model. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n     2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n     3. You can also try to run image libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\",\n   \"details\": [\n     {\n       \"code\": \"CrashLoopBackOff\",\n       \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n     1. Please check the logs for your container instance: aml-live-service-model. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n     2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n     3. You can also try to run image libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\"\n     },\n     {\n       \"code\": \"AciDeploymentFailed\",\n       \"message\": \"Your container application crashed. Please follow the steps to debug:\n     1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.\n     2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.\n     3. You can also interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n     4. View the diagnostic events to check status of container, it may help you to debug the issue.\n \"RestartCount\": 5\n \"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n \"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2022-06-17T10:56:57.554Z\",\"exitCode\":111,\"finishTime\":\"2022-06-17T10:57:01.314Z\",\"detailStatus\":\"Error\"}\n \"Events\":\n {\"count\":1,\"firstTimestamp\":\"2022-06-17T10:26:38Z\",\"lastTimestamp\":\"2022-06-17T10:26:38Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\"\",\"type\":\"Normal\"}\n {\"count\":1,\"firstTimestamp\":\"2022-06-17T10:27:42Z\",\"lastTimestamp\":\"2022-06-17T10:27:42Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\"\",\"type\":\"Normal\"}\n {\"count\":10,\"firstTimestamp\":\"2022-06-17T10:28:00Z\",\"lastTimestamp\":\"2022-06-17T10:47:11Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n {\"count\":9,\"firstTimestamp\":\"2022-06-17T10:28:03Z\",\"lastTimestamp\":\"2022-06-17T10:40:46Z\",\"name\":\"Killing\",\"message\":\"Killing container with id a7e717efa63259b36b19bc4951b3f3dcc5f1093177e729c589355a7371353ca3.\",\"type\":\"Normal\"}\n {\"count\":1,\"firstTimestamp\":\"2022-06-17T10:31:33Z\",\"lastTimestamp\":\"2022-06-17T10:31:33Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\"\",\"type\":\"Normal\"}\n {\"count\":1,\"firstTimestamp\":\"2022-06-17T10:32:31Z\",\"lastTimestamp\":\"2022-06-17T10:32:31Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\"\",\"type\":\"Normal\"}\n {\"count\":5,\"firstTimestamp\":\"2022-06-17T10:47:52Z\",\"lastTimestamp\":\"2022-06-17T10:52:09Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n {\"count\":6,\"firstTimestamp\":\"2022-06-17T10:48:26Z\",\"lastTimestamp\":\"2022-06-17T10:52:37Z\",\"name\":\"Killing\",\"message\":\"Killing container with id 2bdec1005a6dd58312e10ab939d88ea08b312771de6573d9b86c5f571104277e.\",\"type\":\"Normal\"}\n \"\n     }\n   ]\n }\n    \n ---------------------------------------------------------------------------\n WebserviceException                       Traceback (most recent call last)\n <ipython-input-17-315dbb5f83ec> in <module>\n      16 service_name = \"aml-live-service-model\"\n      17 service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, overwrite=True)\n ---> 18 service.wait_for_deployment(True)\n      19 print(service.state)\n    \n \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/core\/webservice\/webservice.py in wait_for_deployment(self, show_output, timeout_sec)\n     916                     logs_response = 'Current sub-operation type not known, more logs unavailable.'\n     917 \n --> 918                 raise WebserviceException('Service deployment polling reached non-successful terminal state, current '\n     919                                           'service state: {}\\n'\n     920                                           'Operation ID: {}\\n'\n    \n WebserviceException: WebserviceException:\n     Message: Service deployment polling reached non-successful terminal state, current service state: Failed\n Operation ID: 93d48e89-cb16-4d1c-bbb6-f453acaeaa7f\n More information can be found using '.get_logs()'\n Error:\n {\n   \"code\": \"AciDeploymentFailed\",\n   \"statusCode\": 400,\n   \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n     1. Please check the logs for your container instance: aml-live-service-model. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n     2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n     3. You can also try to run image libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\",\n   \"details\": [\n     {\n       \"code\": \"CrashLoopBackOff\",\n       \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n     1. Please check the logs for your container instance: aml-live-service-model. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n     2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n     3. You can also try to run image libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\"\n     },\n     {\n       \"code\": \"AciDeploymentFailed\",\n       \"message\": \"Your container application crashed. Please follow the steps to debug:\n     1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.\n     2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.\n     3. You can also interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n     4. View the diagnostic events to check status of container, it may help you to debug the issue.\n \"RestartCount\": 5\n \"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n \"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2022-06-17T10:56:57.554Z\",\"exitCode\":111,\"finishTime\":\"2022-06-17T10:57:01.314Z\",\"detailStatus\":\"Error\"}\n \"Events\":\n {\"count\":1,\"firstTimestamp\":\"2022-06-17T10:26:38Z\",\"lastTimestamp\":\"2022-06-17T10:26:38Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\"\",\"type\":\"Normal\"}\n {\"count\":1,\"firstTimestamp\":\"2022-06-17T10:27:42Z\",\"lastTimestamp\":\"2022-06-17T10:27:42Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\"\",\"type\":\"Normal\"}\n {\"count\":10,\"firstTimestamp\":\"2022-06-17T10:28:00Z\",\"lastTimestamp\":\"2022-06-17T10:47:11Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n {\"count\":9,\"firstTimestamp\":\"2022-06-17T10:28:03Z\",\"lastTimestamp\":\"2022-06-17T10:40:46Z\",\"name\":\"Killing\",\"message\":\"Killing container with id a7e717efa63259b36b19bc4951b3f3dcc5f1093177e729c589355a7371353ca3.\",\"type\":\"Normal\"}\n {\"count\":1,\"firstTimestamp\":\"2022-06-17T10:31:33Z\",\"lastTimestamp\":\"2022-06-17T10:31:33Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\"\",\"type\":\"Normal\"}\n {\"count\":1,\"firstTimestamp\":\"2022-06-17T10:32:31Z\",\"lastTimestamp\":\"2022-06-17T10:32:31Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\"\",\"type\":\"Normal\"}\n {\"count\":5,\"firstTimestamp\":\"2022-06-17T10:47:52Z\",\"lastTimestamp\":\"2022-06-17T10:52:09Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n {\"count\":6,\"firstTimestamp\":\"2022-06-17T10:48:26Z\",\"lastTimestamp\":\"2022-06-17T10:52:37Z\",\"name\":\"Killing\",\"message\":\"Killing container with id 2bdec1005a6dd58312e10ab939d88ea08b312771de6573d9b86c5f571104277e.\",\"type\":\"Normal\"}\n \"\n     }\n   ]\n }\n     InnerException None\n     ErrorResponse \n {\n     \"error\": {\n         \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 93d48e89-cb16-4d1c-bbb6-f453acaeaa7f\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: aml-live-service-model. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: aml-live-service-model. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\n\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.\\n\\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.\\n\\t3. You can also interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\\n\\\"RestartCount\\\": 5\\n\\\"CurrentState\\\": {\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"}\\n\\\"PreviousState\\\": {\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2022-06-17T10:56:57.554Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2022-06-17T10:57:01.314Z\\\",\\\"detailStatus\\\":\\\"Error\\\"}\\n\\\"Events\\\":\\n{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2022-06-17T10:26:38Z\\\",\\\"lastTimestamp\\\":\\\"2022-06-17T10:26:38Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2022-06-17T10:27:42Z\\\",\\\"lastTimestamp\\\":\\\"2022-06-17T10:27:42Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":10,\\\"firstTimestamp\\\":\\\"2022-06-17T10:28:00Z\\\",\\\"lastTimestamp\\\":\\\"2022-06-17T10:47:11Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":9,\\\"firstTimestamp\\\":\\\"2022-06-17T10:28:03Z\\\",\\\"lastTimestamp\\\":\\\"2022-06-17T10:40:46Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id a7e717efa63259b36b19bc4951b3f3dcc5f1093177e729c589355a7371353ca3.\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2022-06-17T10:31:33Z\\\",\\\"lastTimestamp\\\":\\\"2022-06-17T10:31:33Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2022-06-17T10:32:31Z\\\",\\\"lastTimestamp\\\":\\\"2022-06-17T10:32:31Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\"libraaimlwor4c93b458.azurecr.io\/azureml\/azureml_8fd1decee2b379a3d59fed509c692f31@sha256:47fc896a553e4b7bb972cbaa9a31de99b4755688dd525b9c725563ddde86aa0c\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":5,\\\"firstTimestamp\\\":\\\"2022-06-17T10:47:52Z\\\",\\\"lastTimestamp\\\":\\\"2022-06-17T10:52:09Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":6,\\\"firstTimestamp\\\":\\\"2022-06-17T10:48:26Z\\\",\\\"lastTimestamp\\\":\\\"2022-06-17T10:52:37Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id 2bdec1005a6dd58312e10ab939d88ea08b312771de6573d9b86c5f571104277e.\\\",\\\"type\\\":\\\"Normal\\\"}\\n\\\"\\n    }\\n  ]\\n}\"\n     }\n }",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-20T07:11:19.413Z",
                "Answer_score":0,
                "Answer_body":"@ramr-msft I've tried to use both of the commands that you've mentioned above. Unfortunately they tell me nothing, both of them are displaying me \"None\" and it's not very suggestive honestly.\n\n\nAlso, I've tried to debug it locally. This is the error that I receive:\n\n The environment variable 'AZUREML_MODEL_DIR' has not been set.\n Use the --model_dir command line argument to set it.\n    \n Azure ML Inferencing HTTP server v0.4.11\n    \n    \n Server Settings\n ---------------\n Entry Script Name: score_aml_live.py\n Model Directory: None\n Worker Count: 1\n Worker Timeout (seconds): None\n Server Port: 5001\n Application Insights Enabled: false\n Application Insights Key: None\n    \n    \n Server Routes\n ---------------\n Liveness Probe: GET   127.0.0.1:5001\/\n Score:          POST  127.0.0.1:5001\/score\n    \n Starting gunicorn 20.1.0\n Listening at: http:\/\/0.0.0.0:5001 (17478)\n Using worker: sync\n Booting worker with pid: 17483\n Initializing logger\n 2022-06-20 06:41:02,353 | root | INFO | Starting up app insights client\n logging socket not found. logging not available.\n logging socket not found. logging not available.\n 2022-06-20 06:41:02,358 | root | INFO | Starting up request id generator\n 2022-06-20 06:41:02,358 | root | INFO | Starting up app insight hooks\n 2022-06-20 06:41:02,358 | root | INFO | Invoking user's init function\n 2022-06-20 06:41:02,358 | root | ERROR | User's init function failed\n 2022-06-20 06:41:02,374 | root | ERROR | Encountered Exception Traceback (most recent call last):\n   File \"\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml_inference_server_http\/server\/aml_blueprint.py\", line 201, in register\n     main.init()\n   File \"\/score_aml_live.py\", line 41, in init\n     model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'aml_live_model_end.pkl')\n   File \"\/lib\/python3.8\/posixpath.py\", line 76, in join\n     a = os.fspath(a)\n TypeError: expected str, bytes or os.PathLike object, not NoneType",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-20T07:39:14.62Z",
                "Answer_score":0,
                "Answer_body":"@MihaiMunteanu-1542 Thanks for the details. Is your files (model) in local file system or in AzureML directory?. Here is document to check the model path fail to debug.\nAlso document to Advance entry script. Still facing an issue please share the notebook.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-11-28T09:38:04.237Z",
                "Answer_score":0,
                "Answer_body":"Hi @MihaiMunteanu-1542 @ramr-msft I am also facing the exactly same issue. Are there any tips that you can share with us? Thank you, Roxana.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"What's the best way to preserve Azure ML workspace so that it can be restored",
        "Question_creation_time":1669442139003,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1105130\/what39s-the-best-way-to-preserve-azure-ml-workspac.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"What's the best way to preserve Azure ML workspace so that it can be restored at a later point? I was hoping to find some automatic way to take a snapshot of artifacts & code and dump it into Azure storage, but haven't been able to find anything relevant in the online documentation.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-28T00:46:02.44Z",
                "Answer_score":0,
                "Answer_body":"@VaraPrasad-1740 Thanks for the question. I would recommend you can have a git repository that backs your project. For some details about this approach you can check https:\/\/santiagof.medium.com\/structure-your-machine-learning-project-source-code-like-a-pro-44815cac8652",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"New Azure ML failed run due to utf8 code",
        "Question_creation_time":1669408545177,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1105085\/new-azure-ml-failed-run-due-to-utf8-code.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"Hi,\nError to use new AMl pipeline with a simpe mannual input and R script module:\n\nAmlExceptionMessage:{\"NonCompliant\":\"Process '\/azureml-envs\/azureml_e24376f9faf4b95be4687d020926fba7\/bin\/python' exited with code 1 and error message 'Execution failed. Process exited with status code 1. Error: ModuleReflector(parser.module_entry, env).exec(\\n File \\\"\/azureml-envs\/azureml_e24376f9faf4b95be4687d020926fba7\/lib\/python3.8\/site-packages\/azureml\/studio\/modulehost\/module_reflector.py\\\", line 397, in exec\\n self._handle_exception(bex)\\n File \\\"\/azureml-envs\/azureml_e24376f9faf4b95be4687d020926fba7\/lib\/python3.8\/site-packages\/azureml\/studio\/modulehost\/module_reflector.py\\\", line 471, in _handle_exception\\n raise exception\\n File \\\"\/azureml-envs\/azureml_e24376f9faf4b95be4687d020926fba7\/lib\/python3.8\/site-packages\/azureml\/studio\/modulehost\/module_reflector.py\\\", line 379, in exec\\n output_tuple = self._entry.func(**reflected_input_ports, **reflected_parameters)\\n File \\\"\/azureml-envs\/azureml_e24376f9faf4b95be4687d020926fba7\/lib\/python3.8\/site-packages\/azureml\/studio\/modulehost\/module_reflector.py\\\", line 76, in wrapper\\n ret = func(args, validated_args)\\n File \\\"\/azureml-envs\/azureml_e24376f9faf4b95be4687d020926fba7\/lib\/python3.8\/site-packages\/azureml\/studio\/modules\/r_language_modules\/execute_r_script.py\\\", line 174, in run\\n return _run_impl(*input_values)\\n File \\\"\/azureml-envs\/azureml_e24376f9faf4b95be4687d020926fba7\/lib\/python3.8\/site-packages\/azureml\/studio\/modules\/r_language_modules\/execute_r_script.py\\\", line 278, in _run_impl\\n ErrorMapping.throw(FailedToEvaluateScriptError(\\n File \\\"\/azureml-envs\/azureml_e24376f9faf4b95be4687d020926fba7\/lib\/python3.8\/site-packages\/azureml\/studio\/common\/error.py\\\", line 835, in throw\\n raise err\\nazureml.studio.common.error.FailedToEvaluateScriptError: The following error occurred during script evaluation, please view the output log for more information:\\n---------- Start of error message from R interpreter ----------\\nGot exception when invoking script: ''utf-8' codec can't decode byte 0xe2 in position 105: invalid continuation byte'.\\n---------- End of error message from R interpreter ----------\\n\\n'. Please check the log file 'user_logs\/std_log.txt' for more details.\"}\n{\n\"code\": \"ExecutionFailed\",\n\"target\": \"\",\n\"category\": \"UserError\",\n\"error_details\": [\n{\n\"key\": \"exit_codes\",\n\"value\": \"1\"\n}\n]\n}\n\nModuleExceptionMessage:FailedToEvaluateScript: The following error occurred during script evaluation, please view the output log for more information:\n---------- Start of error message from R interpreter ----------\nGot exception when invoking script: ''utf-8' codec can't decode byte 0xe2 in position 105: invalid continuation byte'.\n---------- End of error message from R interpreter ----------\n\nWhat could be wrong?\n\nThanks,\nA.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"how to share project to my team",
        "Question_creation_time":1669425813897,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1105193\/how-to-share-project-to-my-team.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"I want to share my whole project to my team in CLI, how to do that, can\u2019t find any document about that.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-26T10:40:35.147Z",
                "Answer_score":0,
                "Answer_body":"Hello @sursalaterrano-8475\n\nThanks for reaching out to us, which version you are working on?\n\nFor Azure Machine Learning CLI V1, you should use az ml workspace share commands\n\nFor Azure Machine Learning CLI V2, you should use az role assignment create commands\n\nPlease refer to below document -\n\nhttps:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ml\/workspace?view=azure-cli-latest\n\nhttps:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ml(v1)\/workspace?view=azure-cli-latest\n\nI hope this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"deploy-a-model-as-a-service: <Response [400]>",
        "Question_creation_time":1668961426670,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1096747\/deploy-a-model-as-a-service-ltresponse-400gt.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"Hi There,\nSorry if this very silly mistake. I am onto \"microsoft-azure-machine-learning\". Just created account, and set up environment\n\nIf I got to Endpoints --> Consume -- > Python snippet, it runs fine in Jupyter within Azure Studio\n\nHowever, when I try to run test code (endpoint and key replaced as required), I am getting below error\n\n<Response [400]>\n\nBasic difference in snippet and exercise is\n\nendpoint = 'http:\/\/URL\/score' #Replace with your endpoint\nkey = 'my key' #Replace with your key\n\nurl = 'http:\/\/URL\/score'\napi_key = 'my key' # Replace this with the API key for the web service\n\nANy help would be great\n\nRegards\nNikhil",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-20T18:48:45.5Z",
                "Answer_score":0,
                "Answer_body":"Hi Nikhil,\n\nDid you followed any learning module? Please check the error codes and resolution for this.\n\n\n\n\nHope this helps.\nJS\n\n==\nPlease Accept the answer if the information helped you. This will help us and others in the community as well.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-11-26T07:19:25.687Z",
                "Answer_score":0,
                "Answer_body":"Yes, I am following the module.. Exercise Part 5: Deploy a Model as a Service\n\nThe code is provided in training module and not working. All I get is <Response [400]>\n\nBasic different I noticed in module and azure endpoint snippet is\n\nModule\n\n\n\nx = [[1,1,2022,1,0,6,0,2,0.344167,0.363625,0.805833,0.160446],\n\n [2,1,2022,1,0,0,0,2,0.363478,0.353739,0.696087,0.248539], \n [3,1,2022,1,0,1,1,1,0.196364,0.189405,0.437273,0.248309], \n [4,1,2022,1,0,2,1,1,0.2,0.212122,0.590435,0.160296], \n [5,1,2022,1,0,3,1,1,0.226957,0.22927,0.436957,0.1869]] \n\n\n\n\ninput_json = json.dumps({\"data\": x})\n\n\n\nendpoint in \"consume\"\n\n\n\ndata = {\n\"Inputs\": {\n\"data\": [\n{\n\"day\": 0,\n\"mnth\": 0,\n\"year\": 0,\n\"season\": 0,\n\"holiday\": 0,\n\"weekday\": 0,\n\"workingday\": 0,\n\"weathersit\": 0,\n\"temp\": 0.0,\n\"atemp\": 0.0,\n\"hum\": 0.0,\n\"windspeed\": 0.0\n}\n]\n},\n\"GlobalParameters\": 0.0\n}\n\nbody = str.encode(json.dumps(data))",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Best practice for model deployment (Real-time Endpoints vs Compute Inference Cluster)",
        "Question_creation_time":1669291283107,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1103168\/best-practice-for-model-deployment-real-time-endpo.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":23,
        "Question_score":0,
        "Question_body":"Hello community!\nReaching out for some help here.\n\nManagedOnlineDeployment vs KubernetesOnlineDeployment\n\nGoal:\nHost a large number of distinct models on Azure ML.\n\nDescription:\nAfter throughout investigation, I found out that there are two ways to host a pre-trained real-time model (i.e., run inference) on Azure ML.\n- Real-time Endpoints - Managed Online Deployment\n- Compute Inference cluster - kubernetes-online-endpoints\nThe differences between the two options are detailed here.\nI want to host a large number of distinct models (i.e., endpoints) while having the best price\/performance\/ease-of-deployment ratio.\n\nDetails:\n\nWhat I tried\nI have 4 running VMs as a result of my creation of 4 real-time endpoints. Those endpoints use Curated Environments that are provided by Microsoft.\n\n\n\n\n\n\nIssues\n\nWhen I want to create a custom environment out of a docker file and then use it as a base image for a certain endpoint, it is a long process:\nBuild Image > Push Image to CR > Create Custom Environment in AzureML > Create and Deploy Endpoint\nIf something goes wrong, it only shows when I finish the whole pipeline. It just doesn't feel like the correct way of deploying a model.\nThis process is needed when I cannot use one of the curated environments because I need some dependency that cannot be imported using the conda.yml file\nFor example:\n\nRUN apt-get update -y && apt-get install build-essential cmake pkg-config -y\nRUN python setup.py build_ext --inplace\n\nAlthough I'm using 1 instance per endpoint (Instance count = 1), each endpoint creates its dedicated VM which will cost me a lot in the long run (i.e., when I have lots of endpoints), now it is costing me around 20$ per day.\n\n\n\n\nNote: Each endpoint has a distinct set of dependencies\/versions...\n\n\n\n\nQuestions\n1- Am I following the best practice? Or do I need to drastically change my deployment strategy (Move from ManagedOnlineDeployment to KubernetesOnlineDeployment or even another option that I don't know of)?\n2- Is there a way to host all the endpoints on a single VM? Rather than creating a VM for each endpoint. To make it affordable.\n3- Is there a way to host the endpoints and get charged per transaction?\n\n\n\n\n\n\n\n\nGeneral recommendations and clarification questions are more than welcome.\n\nThank you!",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"undefined symbol: cublasLtGetStatusString at Endpoint Deployment Error",
        "Question_creation_time":1669225633070,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1102061\/undefined-symbol-cublasltgetstatusstring-at-endpoi.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":36,
        "Question_score":0,
        "Question_body":"Hi\n\nI am getting this error while deploying an end point. This was working fine for 3 months and I had to rebuild due to a minor change and started getting this error.\n\nFile \"\/azureml-envs\/tensorflow-2.7\/lib\/python3.8\/site-packages\/azureml_inference_server_http\/server\/user_script.py\", line 81, in load_script\nmain_module_spec.loader.exec_module(user_module)\nFile \"<frozen importlib.bootstrap_external>\", line 843, in exec_module\nFile \"<frozen importlib.bootstrap>\", line 219, in call_with_frames_removed\nFile \"\/var\/azureml-app\/221123171914-1667710269\/score.py\", line 6, in <module>\nimport ktrain\nFile \"\/azureml-envs\/tensorflow-2.7\/lib\/python3.8\/site-packages\/torch\/init.py\", line 191, in <module>\nload_global_deps()\nFile \"\/azureml-envs\/tensorflow-2.7\/lib\/python3.8\/site-packages\/torch\/init.py\", line 153, in load_global_deps\nctypes.CDLL(lib_path, mode=ctypes.RTLD_GLOBAL)\nFile \"\/azureml-envs\/tensorflow-2.7\/lib\/python3.8\/ctypes\/init.py\", line 373, in init_\nself._handle = _dlopen(self._name, mode)\nOSError: \/azureml-envs\/tensorflow-2.7\/lib\/python3.8\/site-packages\/torch\/lib\/..\/..\/nvidia\/cublas\/lib\/libcublas.so.11: undefined symbol: cublasLtGetStatusString, version libcublasLt.so.11\n\n\n\n\nThis is my environment:\n\nFROM mcr.microsoft.com\/azureml\/openmpi4.1.0-cuda11.2-cudnn8-ubuntu20.04:20220714.v1\n\nENV AZUREML_CONDA_ENVIRONMENT_PATH \/azureml-envs\/tensorflow-2.7\n\nCreate conda environment\n\nRUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\\npython=3.8 pip=20.2.4\n\nPrepend path to AzureML conda environment\n\nENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/bin:$PATH\n\nInstall pip dependencies\n\nRUN HOROVOD_WITH_TENSORFLOW=1 pip install 'matplotlib~=3.5.0' \\\n'psutil~=5.8.0' \\\n'tqdm~=4.62.0' \\\n'scipy~=1.7.0' \\\n'numpy~=1.21.0' \\\n'ipykernel~=6.0' \\\n# upper bound azure-core to address typing-extensions conflict\n'azure-core<1.23.0' \\\n'azureml-core==1.43.0' \\\n'azureml-defaults==1.43.0' \\\n'azureml-mlflow==1.43.0.post1' \\\n'azureml-telemetry==1.43.0' \\\n'azureml-inference-server-http==0.7.2' \\\n'pandas==1.4.1' \\\n'ktrain==0.30.0' \\\n'sentence-transformers==2.1.0' \\\n'tensorflow==2.7.0' \\\n'tokenizers==0.10.3' \\\n'protobuf~=3.19.1' \\\n'Flask==2.1.0' \\\n'transformers==4.10.3'\n\nThis is needed for mpi to locate libpython\n\nENV LD_LIBRARY_PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/lib:$LD_LIBRARY_PATH",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-24T17:08:14.207Z",
                "Answer_score":1,
                "Answer_body":"Hi @romungi-MSFT\n\nI managed to solve it\n\nkept the container same as 20220729.v1\nand added 'torch==1.12.0' \\ 'torchvision==0.13.0' to the list. Didn't need the higher version as given in the link.\nThanks for that link\n\n\n\n\nfinal env file\n\nFROM mcr.microsoft.com\/azureml\/openmpi4.1.0-cuda11.2-cudnn8-ubuntu20.04:20220729.v1\n\nENV AZUREML_CONDA_ENVIRONMENT_PATH \/azureml-envs\/tensorflow-2.7\n\nCreate conda environment\n\nRUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\\npython=3.8 pip=20.2.4\n\nPrepend path to AzureML conda environment\n\nENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/bin:$PATH\n\nInstall pip dependencies\n\nRUN HOROVOD_WITH_TENSORFLOW=1 pip install 'matplotlib~=3.5.0' \\\n'psutil~=5.8.0' \\\n'tqdm~=4.62.0' \\\n'scipy~=1.7.0' \\\n'numpy~=1.21.0' \\\n'ipykernel~=6.0' \\\n# upper bound azure-core to address typing-extensions conflict\n'azure-core<1.23.0' \\\n'azureml-core==1.43.0' \\\n'azureml-defaults==1.43.0' \\\n'azureml-mlflow==1.43.0.post1' \\\n'azureml-telemetry==1.43.0' \\\n'azureml-inference-server-http==0.7.2' \\\n'pandas==1.4.1' \\\n'ktrain==0.30.0' \\\n'sentence-transformers==2.1.0' \\\n'tensorflow==2.7.0' \\\n'tokenizers==0.10.3' \\\n'protobuf~=3.19.1' \\\n'Flask==2.1.0' \\\n'transformers==4.10.3' \\\n'torch==1.12.0' \\\n'torchvision==0.13.0'\n\nThis is needed for mpi to locate libpython\n\nENV LD_LIBRARY_PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/lib:$LD_LIBRARY_PATH",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unable to import prophet",
        "Question_creation_time":1650846070067,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/824199\/unable-to-import-prophet.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I am attempting to run Prophet (fbprophet) in an Azure Notebook. I have installed prophet using the terminal window and it is listed as an installed package (prophet (0.1.1.post1)).\n\nWhen I attempt to import the Prophet module using either of the following commands in a Notebook cell I receive the error message; \"ModuleNotFoundError: No module named 'prophet'\"\n\n from fbprophet import Prophet\n or\n from prophet import Prophet\n\nCould someone please assist...thank you.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-25T10:22:14.557Z",
                "Answer_score":0,
                "Answer_body":"@GrahamBenson-6517 Please try installing the package using the notebook cells instead of terminal window since you are running different kernels for the notebook session.\nPlease try the following from the cell and try to import the package.\n\n %pip install Prophet\n\n\n\nWorked in my notebook as seen below.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"What is the difference between R-squared generated during machine learning model training and the R-squared generated for model performance under Explanations?",
        "Question_creation_time":1669146778730,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1100346\/what-is-the-difference-between-r-squared-generated.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"For some of my ML experiments, I've selected R-squared as the primary metric for guiding the training. I also noticed that under the Explanations section of the algorithm overview, there is a section called Model Performance and with it, a box plot graph that also shows a different value for R-squared.\n\nWhat is the difference between these two values of R-squared?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Working with AzureMachineLearningFileSystem and binary files",
        "Question_creation_time":1669043044797,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1098198\/working-with-azuremachinelearningfilesystem-and-bi.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"https:\/\/learn.microsoft.com\/en-gb\/azure\/machine-learning\/how-to-access-data-interactive?tabs=adls - this is the recommended route in the v2 API for interactive \/ exploratory data access - rather than mount() a FileDataset object, use this new filesystem-like interface. So far this works:\n\nuri = f'azureml:\/\/subscriptions\/{subscription}\/resourcegroups\/{resource_group}\/workspaces\/{workspace}\/datastores\/{datastore_name}\/paths\/{path_on_datastore}'\nfs = AzureMachineLearningFileSystem(uri)\nfs.ls()\n\n\n\n\nfs.open('path\/to\/file.tif') returns a pystreaminfo_companion.StreamInfoFileObject which has io.BytesIO-like behaviours and apparently no documentation on the internet\n\nIn this case we are trying to work with the data using the rasterio python package which accepts a python file object or a path as input. This won't work, it throws a read buffer error:\n\nraster_data = rasterio.open(fs.open('path\/to\/image.tif'))\nimg_arr = raster_data.read()\n\n\n\n\nWe can short-term work around this by reading the byte stream into a rasterio MemoryFile object, but it's inefficient - files could be very large\n\nfs.get('path\/to\/image.tif', 'local_path.tif') throws a NotImplementedError\n\nWe know this interface is only in public preview but is it cooked? Is it mainly a documentation problem?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-21T17:14:03.41Z",
                "Answer_score":1,
                "Answer_body":"What we found when digging into this further - I was reading relatively large files (>100Mb) from a Data Lake Gen2 and seeing the read() fail with a buffer size error like this:\n```\nERROR 1: TIFFReadEncodedStrip:Read error at scanline 4294967295; got 4600 bytes, expected 8000\nERROR 1: TIFFReadEncodedStrip() failed.\nERROR 1: \/vsipythonfilelike\/6c4028d8-2a05-4b4a-95fd-998f4395afb7\/6c4028d8-2a05-4b4a-95fd-998f4395afb7, band 1: IReadBlock failed at X offset 0, Y offset\n```\n\nMy colleague tried it on tiny files in blob storage and the behaviour of the StreamInfoFileObject with`rasterio` worked as you'd hope and expect",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How do I register ADLS as datastore in AMLW (via cli) corrcetly?",
        "Question_creation_time":1669041298113,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1098193\/how-do-i-register-adls-as-datastore-in-amlw-via-cl.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":20,
        "Question_score":0,
        "Question_body":"Hi!\n\nI'm trying to create a datastore from an ADLS (Gen2) using azure cli (using version 2.42), with credentials using service principal. The service principal is added as Storage Blob Data Reader to my ADLS. I use the following schema (with XXX replaced by correct details), file is named create-datastore-azure-adls.yml .\n\n$schema: https:\/\/azuremlschemas.azureedge.net\/latest\/azureDataLakeGen2.schema.json\ntype: azure_data_lake_gen2\nname: XXX\ndescription: Datastore, ADLS and service principal\naccount_name: XXX\nfilesystem: XXX\ncredentials:\ntenant_id: XXX\nclient_id: XXX\nclient_secret: XXX\n\nand run\naz ml datastore create --file create-datastore-azure-adls.yml --workspace-name $WORKSPACENAME --resource-group $RESOURCENAME --subscription $SUBSCRIPTIONID\n\nThe datastore ends up in my workspace but I can't read from the datastore. When I look at it in the workspace it is not connected to any subscription-id nor resource group (see image).\n\nHowever, if I choose update authentication and fill in subscription-id and resource group everything works. So my question is if there is any way I can't do it correctly, only using the cli, eg. adding this info (subscription-id and rg-name) to the schema? So I don't have to update authentication in the workspace every time :)",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Compose model",
        "Question_creation_time":1669041105107,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1098169\/compose-model.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"As the document\nA composed model is created by taking a collection of custom models and assigning them to a single model ID. You can assign up to 100 trained custom models to a single composed model ID. When a document is submitted to a composed model, the service performs a classification step to decide which custom model accurately represents the form presented for analysis.\n\nWhat\u2019s the price for the classification step?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-21T15:31:45.523Z",
                "Answer_score":0,
                "Answer_body":"Hello @KenSmith-3969\n\nThanks for reaching out to us and sorry for the confusion of the document.\n\nThere is no extra fee for the classification you mentioned in the document. You only pay for the custom model you finally run for your document.\n\nI will raise a ticket to fix the document, thanks a lot for pointing out it.\n\nI hope this helps!\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks!",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Access to Azure ML named datasets",
        "Question_creation_time":1668460319020,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1088577\/access-to-azure-ml-named-datasets.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"We have a computer vision pipeline that finetunes a vision model.\nThe data for training the vision model is a large collection of images that lands in our data lake.\nThe problem is that we are not able to mount this dataset to our training job.\n\nIn Azure ML portal we defined a named dataset for the image folder in our data lake (not the default workspace data source).\nBut if in our job control script we will try to reference the dataset by name and mount it to the training job:\n\n docker_config = DockerConfiguration(use_docker=True)\n    \n # Access the dataset\n dataset = Dataset.get_by_name(ws, 'the name of our named dataset')\n    \n # Run the experiment\n args = ['--data-folder', dataset.as_mount() ]\n print(\"Mounted dataset\")\n    \n src = ScriptRunConfig(source_directory='.\/src',\n                       script='balearms_cnn_training.py',\n                       arguments=args,\n                       compute_target=compute_target,\n                       environment=keras_env,\n                       docker_runtime_config=docker_config)\n\n\n\n\nThe job will fail with the error:\n\n {\"NonCompliant\":\"UserErrorException:\\n\\tMessage: Cannot mount Dataset(id='389fb088-59eb-4288-8225-aa9fb55f14c0', name='balearms', version=1). Error Message: DataAccessError(PermissionDenied(Some(This request is not authorized to perform this operation using this permission.)))\\n\\tInnerException None\\n\\tErrorResponse \\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"Cannot mount Dataset(id='389fb088-59eb-4288-8225-aa9fb55f14c0', name='balearms', version=1). Error Message: DataAccessError(PermissionDenied(Some(This request is not authorized to perform this operation using this permission.)))\\\"\\n    }\\n}\"}\n\n\n\n\u2026\n\n\n\n\nTo overcome this problem we use the default workspace dataset.\n\n datastore = ws.get_default_datastore()\n  dataset = Dataset.File.from_files(path=(datastore, 'datasets\/balearms\/ExtractedImages\/'))\n     \n  # Run the experiment\n  args = ['--data-folder', dataset.as_mount() ]\n  print(\"Mounted dataset\")\n     \n  src = ScriptRunConfig(source_directory='.\/src',\n  script='balearms_cnn_training.py',\n  arguments=args,\n  compute_target=compute_target,\n  environment=keras_env,\n  docker_runtime_config=docker_config)\n\n\n\nIt works but it also means that we have to copy the files to a different storage account (the default workspace dataset) and that creates complexities.\nThere is no doubt that we should be able to mount a named dataset. I believe that we miss just a small detail\u2026\n\nWould you be able to help us to figure out how to use named datasets and mount them to our training jobs?\n\nThanks\n\nManu",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-17T00:37:32.987Z",
                "Answer_score":0,
                "Answer_body":"It's possible you defined the datalake as a datastore with identity-based access and also defined your compute instance\/cluster with managed identity enabled. In this case, you'll need to grant the Compute Cluster Managed Identity access to the Data Lake through RBAC. Check this link for more details: https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-identity-based-service-authentication",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-11-17T21:05:10.023Z",
                "Answer_score":0,
                "Answer_body":"The dataset that I needed to mount is a folder in my data lake (gen2).\nAs you would imagine the Azure ML data store I use is of type the data lake, and it is configured with a service principal that has all the permissions to access the data lake, but still, I cannot access the data.\n\nBUT. It is possible to create a blob data store (that uses the access key) to reference the same data.\nYes, it's not RBAC but when creating a data set from that blob-based data store, I am able to access the dataset, mount it, etc.\n\nSomething is broken in my data lake gen2 data store. I do not know what it is, but the blob data store is a reasonable workaround.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Specifying AzureML output destination in SDK v2",
        "Question_creation_time":1660825064220,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/972481\/specifying-azureml-output-destination-in-sdk-v2.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":14,
        "Question_score":4,
        "Question_body":"Hi. I have set up an AzureML pipeline with YAML components using the Python SDK (v2) with an attached blob store. However, it appears that the output destination is handled automatically by AzureML and so I can't specify where on the blob the pipeline writes its output. I want to configure the AzureML pipeline run using ADF, which involves moving some data to the blob, running the AzureML pipeline, and then moving some data from the blob to somewhere else. The trouble is that ADF doesn't get access to the AzureML output directory, and so it won't know where to look for the output file.\n\nI have tried to pass the output directory as an input rather than an output so that I can explicitly state where this should go. The directory, however, gets mounted as read only (quite sensibly by design, I trust) so that doesn't work. So I'm kind of running out of options.\n\nIs there any way for me specify the output path for an Azure ML SDK v2 pipeline in a similar way to how I would specify an input path? Alternatively, is there another way of solving this particular predicament of mine?\n\nI have looked through the notebooks (e.g. https:\/\/github.com\/Azure\/azureml-examples\/blob\/8a4070f55593c9641083784283b773f4f20955dd\/sdk\/jobs\/pipelines\/1a_pipeline_with_components_from_yaml\/pipeline_with_components_from_yaml.ipynb) and I can't find an example where people explicitly control the output destination (which seems odd).\n\nThoughts?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-10T10:39:09.38Z",
                "Answer_score":1,
                "Answer_body":"Any updates on this?\nI have the same problem, it seems you can specify the path in the output like\noutputs={\n\"output_path\": Output(type=\"uri_folder\", mode=\"rw_mount\", path=<path>),\n}\nIt doesnt throw an error, however the path is ignored anyways...",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"az ml workspace share command (v1) alternatives",
        "Question_creation_time":1668184683380,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1085726\/az-ml-workspace-share-command-v1-alternatives.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I'm trying to share my azure ML workspace by SP (Service Principal)\n\nI've created a SP and share my workspace to the SP\n\nBut when I try to share a workspace using the cli, I get this error:\n\n'share' is misspelled or not recognized by the system.\n\n\n\n\nMaybe I guess this error was caused by version of azure cli, (share command only exists in v1 docs: https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ml(v1)\/workspace?view=azure-cli-latest)\n\nbut I don't have any idea to alter the command above.\n\nThanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-12T22:50:14.973Z",
                "Answer_score":0,
                "Answer_body":"Hello @92907795\n\nThanks for using Microsoft Q&A platform, it seems you are working on V2 and you want to do workspace sharing, but there are some changes between CLI V1 and V2.\n\nTo migrate from Azure Machine Learning V1 to V2, you need to upgrade az ml workspace share commands to equivalent az role assignment create commands.\n\nPlease refer to here - https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/role\/assignment?view=azure-cli-latest#az-role-assignment-create\nCreate a new role assignment for a user, group, or service principal.\n\n az role assignment create --role\n                           [--assignee]\n                           [--assignee-object-id]\n                           [--assignee-principal-type {ForeignGroup, Group, ServicePrincipal, User}]\n                           [--condition]\n                           [--condition-version]\n                           [--description]\n                           [--name]\n                           [--resource-group]\n                           [--scope]\n\n\n\nThere are some examples for how to use it here for your reference - https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/role\/assignment?view=azure-cli-latest#az-role-assignment-create-examples\n\nI hope this helps!\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot!",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Compute Instance Times Out During File Upload",
        "Question_creation_time":1668533994507,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1090211\/azure-ml-compute-instance-times-out-during-file-up.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"I have deployed a gpu-enabled AZ ML Compute instance and am running a custom docker container on top of it. This custom docker container uses bentoml to receive, batch, and manage inference requests, with various endpoints for doing so. I have exposed the necessary ports so that the endpoints are available to send requests to. There are 2 major types of request endpoints involve: first, an endpoint where a path to a file that the compute\/container have access to through a volume mount\/storage mounting is sent as the data, and the container endpoint preforms inference on the file that path points to. This works just fine. Second is where the actual file is uploaded to the endpoint. The files in question are quite large image files, ~300-500mb. This second method has an issue: the file never reaches the endpoint. I attached a remote debugger and found the entrypoint of the data, and it is never reached in the case of the image upload, while it is in the case of the path upload. I then replicated the container on a local compute, and repeated the same scenario, in which the container was able to receive and handle the image upload with no issue. Additionally, when the image is more than 500mb, when attempting to upload to the container on the ml compute instance, I get an \"entity too large\" error, that I do not get when doing the same thing on a local compute instance.\n\nI have been unable to find any definite documentation of the limitations on file upload size\/speed for ML compute instances, all that I have been able to find pertains to azure apps and to ml online endpoints (which could be an alternative option), but not to ml compute instances. Is there such a limit? If so, what is it?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-15T23:35:12.483Z",
                "Answer_score":0,
                "Answer_body":"Hello @JasonLunder-5242\n\nThanks for using Microsoft Q&A and sorry to hear your experience is not smooth.\n\nUploading file directly to Azure ML compute instance is acutualy not a suggested way due to security limitation from Ngnix (Ngnix is one of our environment here ) - Restricting file upload size is useful to prevent some types of denial-of-service (DOS) attacks and many other related issues. https:\/\/www.tecmint.com\/limit-file-upload-size-in-nginx\/\n\nThe official limitation of upload suggests from Ngnix is only 1MB, for Azure the limitation is 512MB.\n\nWe are obsessed in MS with security challenges, the workaround for myself for your reference is not to upload files, but to create a custom docker image, and on that docker image, between the docker commands to download the needed file with wget.\n\nI hope my answer help you solve your issue and I also provide my suggestion to product team for make this point clear.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"ACI Service request failed",
        "Question_creation_time":1619647321237,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/376182\/aci-service-request-failed.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hello,\n\nI got an error when trying to deploy AML model. The tutorial I refer to is this: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python\nPart of the console log is below.\n\n\n\n\n2021-04-28 14:35:51-07:00 Registering the environment.\n2021-04-28 14:35:53-07:00 Use the existing image.\n2021-04-28 14:35:55-07:00 Submitting deployment to compute.\nFailed\nService deployment polling reached non-successful terminal state, current service state: Transitioning\nOperation ID: b6e3b3b3-d1f0-4819-81ac-b72c7b3582dd\nCurrent sub-operation type not known, more logs unavailable.\nError:\n{\n\"code\": \"InaccessibleImage\",\n\"statusCode\": 400,\n\"message\": \"ACI Service request failed. Reason: The image 'registryxdjudax3mnivo.azurecr.io\/azureml\/azureml_e1f2520e8a691cb15119fcbae8e452b7' in container\ngroup 'myservice-dV-NN8cdrU2R5BJEiypZqQ' is not accessible. Please check the image and registry credential.. Refer to https:\/\/docs.microsoft.com\/azure\/cont\nainer-registry\/container-registry-authentication#admin-account and make sure Admin user is enabled for your container registry.\"\n}\n\nTraceback (most recent call last):\nFile \"deploy-model.py\", line 34, in <module>\nservice.wait_for_deployment(show_output=True)\nFile \"C:\\Users\\Administrator\\source\\repos\\TestPython\\venv\\lib\\site-packages\\azureml\\core\\webservice\\webservice.py\", line 917, in wait_for_deployment\nraise WebserviceException('Service deployment polling reached non-successful terminal state, current '\nazureml.exceptions._azureml_exception.WebserviceException: WebserviceException:\nMessage: Service deployment polling reached non-successful terminal state, current service state: Transitioning\nOperation ID: b6e3b3b3-d1f0-4819-81ac-b72c7b3582dd\nCurrent sub-operation type not known, more logs unavailable.\nError:\n{\n\"code\": \"InaccessibleImage\",\n\"statusCode\": 400,\n\"message\": \"ACI Service request failed. Reason: The image 'registryxdjudax3mnivo.azurecr.io\/azureml\/azureml_e1f2520e8a691cb15119fcbae8e452b7' in container\ngroup 'myservice-dV-NN8cdrU2R5BJEiypZqQ' is not accessible. Please check the image and registry credential.. Refer to https:\/\/docs.microsoft.com\/azure\/cont\nainer-registry\/container-registry-authentication#admin-account and make sure Admin user is enabled for your container registry.\"\n}\nInnerException None\nErrorResponse\n{\n\"error\": {\n\"message\": \"Service deployment polling reached non-successful terminal state, current service state: Transitioning\\nOperation ID: b6e3b3b3-d1f0-4819\n-81ac-b72c7b3582dd\\nCurrent sub-operation type not known, more logs unavailable.\\nError:\\n{\\n \\\"code\\\": \\\"InaccessibleImage\\\",\\n \\\"statusCode\\\": 400,\\n \\\n\"message\\\": \\\"ACI Service request failed. Reason: The image 'registryxdjudax3mnivo.azurecr.io\/azureml\/azureml_e1f2520e8a691cb15119fcbae8e452b7' in container\ngroup 'myservice-dV-NN8cdrU2R5BJEiypZqQ' is not accessible. Please check the image and registry credential.. Refer to https:\/\/docs.microsoft.com\/azure\/cont\nainer-registry\/container-registry-authentication#admin-account and make sure Admin user is enabled for your container registry.\\\"\\n}\"\n}\n}\n\n\n\n\n\nThe python code used for this is below. The local deployment works actually.\n\n\n\n\n\nfrom azureml.core import Environment\nfrom azureml.core.model import InferenceConfig\nfrom azureml.core.webservice import LocalWebservice\nfrom azureml.core.webservice import AciWebservice\nfrom azureml.core.model import Model\nfrom azureml.core import Workspace\n\nws = Workspace.from_config(path=\".\/config.json\")\n\nmodel = Model(ws, 'bidaf_onnx')\nprint(model.name, \" : \", model.created_by)\n\nenv = Environment(name='myenv')\npython_packages = ['nltk', 'numpy', 'onnxruntime']\nfor package in python_packages:\nenv.python.conda_dependencies.add_pip_package(package)\n\ninf_config = InferenceConfig(environment=env, source_directory='.\/source_dir', entry_script='.\/score.py')\nprint(\"Generated inference configuration\")\n\ndeploy_config = AciWebservice.deploy_configuration(cpu_cores = 0.5, memory_gb = 1)\nprint(\"Generated deployment configuration\")\n\nservice = Model.deploy(ws, \"myservice\", [model], inf_config, deploy_config, overwrite=True)\nservice.wait_for_deployment(show_output=True)\nprint(service.get_logs())\n\n\n\n\n\nI've enabled \"Admin user\" for the container registry as indicated by the error message. But still got the same error message.\nThank you,\n\nHai",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-21T13:42:35.867Z",
                "Answer_score":0,
                "Answer_body":"We are having same issue, are there any updates to this forum?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-11-17T20:53:28.99Z",
                "Answer_score":0,
                "Answer_body":"any update on this. running into same issue.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Does Azure Cognitive Service provide a way to detect depression (or mental health) from a text?",
        "Question_creation_time":1668695329173,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1093496\/does-azure-cognitive-service-provide-a-way-to-dete.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":20,
        "Question_score":0,
        "Question_body":"I'm doing research that aims to detect if social media users are depressed or\/and have mental health issues. Does Cognitive Service and its sentiment analysis models provide an API for this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-17T20:12:33.53Z",
                "Answer_score":1,
                "Answer_body":"Hello @xiriro\n\nThanks for using Microsoft Q&A platform. Sentimnt Analysis of Azure Cognitive Service does not support Depression Detection at this moment, it can only returen positive, neutral and negative labels, which may not enough for depression from my personal experience.\n\nBut I do see Microsoft Research group is working on this case - https:\/\/www.microsoft.com\/en-us\/research\/project\/technology-for-mental-health-and-well-being-interventions\/\n\nAnd also I see some external Microsoft resource about this topic you may be interested in - https:\/\/www.youtube.com\/watch?v=HzlOkaGHZSg&t=1432s\n\nI hope this helps and thank you for your product feedback, I will bring this feature to product team for future considerations.\n\n\n\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Unable to parse the response from the Azure ML Web Service in Azure Stream Analytics",
        "Question_creation_time":1664971317523,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1036188\/unable-to-parse-the-response-from-the-azure-ml-web-1.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":7,
        "Question_follower_count":17,
        "Question_score":0,
        "Question_body":"Hi, using Azure ML Studio I have created an endpoint for a model generated with automated ML. The model works fine in test (consume) - provides an expected outcome. Then I created a Stream Analytics query using the function to consume the same ML endpoint. However when I test the Stream Analytics query I receive the following error:\n\n\"Callout failed within query runner. An error was encountered while calling the Azure ML web service. An error occurred when parsing the Azure ML web service response. Please check your Azure ML web service and data model. The content of the response from the ML web service should be a JSON array. The response received from the Web Service is: {\"Results\": [\"none\", \"none\", \"none\"]} Parameter name: result\"\n\nThe result I am getting is fine - as expected - but the problem seems to be with parsing the result.\nSo by reading the docs I understand the desired output format from ML endpoint is JSON Array like this [\"none\", \"none\", \"none\"], while I am getting a JSON object. {\"Results\": [\"none\", \"none\", \"none\"]}\nThe question is, can I (how I) modify the output format (swagger?) to have it return the json array? The model was calculated by automated ML (no-code)\n\nFor the record the Stream Analytics query is like this:\n\nSELECT udf.pdmpredict(TRY_CAST(inputArray AS record))\nINTO [pdm-predict-data]\nFROM ModelInput\nWHERE inputArray is not null\n\nudf.pdmpredict is my ASA ML function created in accordance to this article: https:\/\/learn.microsoft.com\/en-us\/azure\/stream-analytics\/machine-learning-udf\n\nAny ideas will be greatly appreciated!\nThanks.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"AzureML Error on Linux: \"Unable to retrieve .NET dependencies. Please make sure you are connected ...\"",
        "Question_creation_time":1618767312437,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/361522\/azureml-error-on-linux-34unable-to-retrieve-net-de.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"I am getting this error on a Linux box (Gentoo w\/ .NET via Mono properly installed)\n\n\"Unable to retrieve .NET dependencies. Please make sure you are connected to the Internet and have a stable network connection.\"\n\nThe error is triggered when creating a dataset from a directory using\n\n\"dataset = Dataset.File.from_files(path=(datastore, path_to_dataset_in_datastore))\"\n\nSome system info:\nPython: 3.8.8.\nazureml-automl-core 1.26.0\nazureml-core 1.26.0\nazureml-dataprep 2.13.2\nazureml-dataprep-native 32.0.0\nazureml-dataprep-rslex 1.11.2\nazureml-dataset-runtime 1.26.0\nazureml-pipeline 1.26.0\nazureml-pipeline-core 1.26.0\nazureml-pipeline-steps 1.26.0\nazureml-sdk 1.26.0\nazureml-telemetry 1.26.0\nazureml-train 1.26.0\nazureml-train-automl-client 1.26.0\nazureml-train-core 1.26.0\nazureml-train-restclients-hyperdrive 1.26.0\n\n.NET Info:\nMono JIT compiler version 6.6.0.161 (tarball Sat Apr 10 16:41:12 PDT 2021)\nCopyright (C) 2002-2014 Novell, Inc, Xamarin Inc and Contributors. www.mono-project.com\nTLS: __thread\nSIGSEGV: altstack\nNotifications: epoll\nArchitecture: amd64\nDisabled: none\nMisc: softdebug\nInterpreter: yes\nLLVM: supported, not enabled.\nSuspend: hybrid\nGC: sgen (concurrent by default)",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-22T05:16:55.363Z",
                "Answer_score":0,
                "Answer_body":"@VictorFragoso-6349 Thanks for the details. Gentoo is not a 'natively' supported distribution of linux for Datasets. The Exception message doesn't link to a .NET docs page with instructions on installing the system dependencies required for .NET to work. Though it seems a different one is being thrown related to not being able to connect to out blob storage which has pre-prepared dependency sets for some linux distros (not gentoo).\n\nThis page Install .NET on Linux Distributions | Microsoft Docs does not detail support for .NET on gentoo.\nYou can get the names of the missing dependencies themselves by running:\n\n\n\n from dotnetcore2 import runtime\n runtime._enable_debug_logging()\n runtime.ensure_dependencies()\n\n\n\nThis code snippet should print the libraies missing required by .NET core 2.1.\nIf the above does not print anything, other than the Exception, then instead this should:\n\n from dotnetcore2 import runtime\n print(runtime._gather_dependencies(runtime._get_bin_folder()))",
                "Answer_comment_count":5,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-05-20T22:54:23.117Z",
                "Answer_score":0,
                "Answer_body":"Hi @ramr-msft I am facing the same issue while read my data from Datalake. Can you please help me out to resolve this issue. \n\n@VictorFragoso-6349 I try to install this package not the issue is still the same.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"OSError: Cannot save file into a non-existent directory",
        "Question_creation_time":1666367036920,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1058457\/oserror-cannot-save-file-into-a-non-existent-direc.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I am using Azure ML Studio to read data from a csv file by creating a data asset test5 and write data into a csv file for my current working directory (which is failing). I am submitting a Job using a Compute Cluster and a Custom Environment and I am following the instructions from the tutorial: https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-azure-ml-in-a-day\n\nI have written the code in a notebook cell as:\n\n # Handle to the workspace\n from azure.ai.ml import MLClient\n    \n # Authentication package\n from azure.identity import DefaultAzureCredential\n credential = DefaultAzureCredential()\n    \n # Get a handle to the workspace\n ml_client = MLClient(\n     credential=credential,\n     subscription_id=\"abc\",\n     resource_group_name=\"xyz\",\n     workspace_name=\"pqr\",\n )\n from azure.ai.ml import command\n from azure.ai.ml import Input\n    \n registered_model_name = \"read_data\"\n env_name = \"docker-context\"\n job = command(inputs=dict(\n         data=Input(\n             type=\"uri_file\",\n             path=\"azureml:test5:1\",\n         ),\n         registered_model_name=registered_model_name\n     ),   \n     code=\".\/src\/\",  # location of source code\n     command=\"python main.py --data ${<!-- -->{inputs.data}} --registered_model_name ${<!-- -->{inputs.registered_model_name}}\",\n     environment=\"docker-context:10\",\n     compute=\"amlcluster01\",\n     experiment_name=\"read_data1\",\n     display_name=\"read_data2\",\n     )\n ml_client.create_or_update(job)\n\n\n\nThis works fine. The content of the main.py is:\n\n import os\n import argparse\n import pandas as pd\n    \n def main():\n     print(\"Hello\")\n      # input and output arguments\n     parser = argparse.ArgumentParser()\n     parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n     parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n     args = parser.parse_args()\n     print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n     print(\"input data:\", args.data)\n     read_data=pd.read_csv(args.data)\n     #read_data=pd.read_parquet(args.data, engine='pyarrow')\n     #credit_df = pd.read_excel(args.data, header=1, index_col=0)\n     print(read_data)\n     read_data.to_csv(r'\/home\/azureuser\/cloudfiles\/code\/Users\/Ankit19.Gupta\/azureml-in-a-day\/src\/file3.csv')\n    \n     print(\"Hello World !\")\n    \n if __name__ == \"__main__\":\n     main()\n\nHere, all lines of code work fine except read_data.to_csv(r'\/home\/azureuser\/cloudfiles\/code\/Users\/Ankit19.Gupta\/azureml-in-a-day\/src\/file3.csv').\n\nIt shows the error message as: OSError: Cannot save file into a non-existent directory:\/home\/azureuser\/cloudfiles\/code\/Users\/Ankit19.Gupta\/azureml-in-a-day\/src\n\nCan anyone please help me how to save dataframe into a csv file into my current working directory through a Job. Any help would be appreciated.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-23T19:18:49.723Z",
                "Answer_score":0,
                "Answer_body":"Helllo @Ankit19Gupta-9721\n\nThanks for using Microsoft Q&A platform, for \"Reading and Writing data in a job\" in official guidance, please refer to below sample for ML SDK V2 - https:\/\/github.com\/Azure\/azureml-examples\/blob\/sdk-preview\/sdk\/assets\/data\/data.ipynb\n\nIf that's not want you want, I have done some researches around it and found a thread about the same issue in Stack - https:\/\/stackoverflow.com\/questions\/47143836\/pandas-dataframe-to-csv-raising-ioerror-no-such-file-or-directory\n\nIt seems this error was caused by to_csv does create the file if it doesn't exist as you said, but it does not create directories that don't exist. Ensure that the subdirectory you are trying to save your file within has been created first as below -\n\n import os\n    \n outname = 'name.csv'\n    \n outdir = '.\/dir'\n if not os.path.exists(outdir):\n     os.mkdir(outdir)\n    \n fullname = os.path.join(outdir, outname)    \n    \n df.to_csv(fullname)\n\n\n\nPlease have a try and I hope above helps, let me know how is going and we are happy to help.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Select column by name option is faded in edit metadata object in Azure ML studio",
        "Question_creation_time":1653833837490,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/868582\/select-column-by-name-option-is-faded-in-edit-meta.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":16,
        "Question_score":1,
        "Question_body":"As shown in the image, by name option is faded. I have already ran the pipeline and it was successful. Then why not adding another step in pipeline shows the output of imported data ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-30T13:11:43.96Z",
                "Answer_score":1,
                "Answer_body":"@TanwarGauravSingh-9735 I think this issue is related to this thread. Recent changes to UI have rendered this functionality unusable. The issue is reported to the product group for review, meanwhile you could use the preview option from Import Data to lookup the column names that need to be used in Select Columns from dataset. I hope this helps!!",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-11-16T16:17:53.917Z",
                "Answer_score":1,
                "Answer_body":"Hi, I'm also facing the same error still. Could you please help to select the By name",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-11-16T17:08:53.983Z",
                "Answer_score":1,
                "Answer_body":"Just enter the column name, its how i solved the issue",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AzureML HyperDriveStep is incorrectly reading Input port names as duplicates",
        "Question_creation_time":1668549291787,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1090410\/azureml-hyperdrivestep-is-incorrectly-reading-inpu.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I'm trying to build a regression model pipeline using a HyperDriveStep for parameter tuning.\n\nWhen I pass in my features dataset and targets dataset as named inputs, if I run this in a notebook with a fresh kernel, I get an error that says ValueError: [features_data] is repeated. Input port names must be unique. (See first screenshot)\n\nIf I comment out the features data input and re-run the cell, the HyperDriveStep builds with no issue. (But obviously I can't run the step and train my model without the features.) (See second screenshot)\n\nIf I un-comment the features data input and re-run the cell, this time the HyperDriveStep builds with no issue, and I can run my pipeline. (See third screenshot)\n\n\n\nError report is as follows:\n\n\n\nValueError Traceback (most recent call last)\nInput In [7], in <cell line: 25>()\n21 # Risk: need to ensure tha the model_file entered here is the same name\n22 # as what's saved in training\/train_{model_algorithm}regressor.py\n24 hd_step_name=f'hd_training_step{segment_type}_{model_algorithm}'\n---> 25 hd_step = HyperDriveStep(\n26 name=hd_step_name,\n27 hyperdrive_config=hd_config,\n28 inputs=[\n29 training_features.as_named_input('features_data'),\n30 training_targets.as_named_input('targets_data')],\n31 outputs=[metrics_data, saved_model],\n32 allow_reuse=False)\n\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/pipeline\/steps\/hyper_drive_step.py:249, in HyperDriveStep.init(self, name, hyperdrive_config, estimator_entry_script_arguments, inputs, outputs, metrics_output, allow_reuse, version)\n246 self._params[HyperDriveStep._primary_metric_goal] = hyperdrive_config._primary_metric_config['goal'].lower()\n247 self._params[HyperDriveStep.primary_metric_name] = hyperdrive_config.primary_metric_config['name']\n--> 249 super(HyperDriveStep, self).init(name=name, inputs=inputs, outputs=outputs,\n250 arguments=estimator_entry_script_arguments)\n\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py:149, in PipelineStep.init(self, name, inputs, outputs, arguments, fix_port_name_collisions, resource_inputs)\n146 resource_input_port_names = [PipelineStep._get_input_port_name(input) for input in resource_inputs]\n147 output_port_names = [PipelineStep._get_output_port_name(output) for output in outputs]\n--> 149 PipelineStep._assert_valid_port_names(input_port_names + resource_input_port_names,\n150 output_port_names, fix_port_name_collisions)\n152 self._inputs = inputs\n153 self._resource_inputs = resource_inputs\n\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py:190, in PipelineStep._assert_valid_port_names(input_port_names, output_port_names, fix_port_name_collisions)\n188 if input_port_names is not None:\n189 assert_valid_port_names(input_port_names, 'input')\n--> 190 assert_unique_port_names(input_port_names, 'input')\n192 if output_port_names is not None:\n193 assert_valid_port_names(output_port_names, 'output')\n\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py:184, in PipelineStep._assert_valid_port_names.<locals>.assert_unique_port_names(port_names, port_type, seen)\n182 for port_name in port_names:\n183 if port_name in seen:\n--> 184 raise ValueError(\"[{port_name}] is repeated. {port_type} port names must be unique.\"\n185 .format(port_name=port_name, port_type=port_type.capitalize()))\n186 seen.add(port_name)\n\nValueError: [features_data] is repeated. Input port names must be unique.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"AML - AssetException: Error with code: Can't connect to HTTPS URL because the SSL module is not available.",
        "Question_creation_time":1667553245710,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1075753\/aml-assetexception-error-with-code-can39t-connect.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hello Microsoft Q&A Team,\n\nI get the error\n\nAssetException: Error with code: Can't connect to HTTPS URL because the SSL module is not available\n\nwhen executing the following command:\n\npipeline_job = ml_client.jobs.create_or_update(\npipeline_job, experiment_name=\"data_preparation\"\n)\npipeline_job\n\nYesterday the command worked without an error. I did not make any changes. So I have no idea, what the problem is.\n\nThanks for helping me out.\n\nCheers\n\nLukas",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-04T23:41:10.037Z",
                "Answer_score":0,
                "Answer_body":"@Lukas-6968 Thanks for your question. Can you please add more details about the document\/sample that you are trying.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-11-07T09:10:33.28Z",
                "Answer_score":1,
                "Answer_body":"Hello,\n\nI was able to solve the issue.\n\nThank you.\n\nCheers\n\nLukas",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"ML Model deployment outside Azure",
        "Question_creation_time":1667289083130,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1070537\/ml-model-deployment-outside-azure.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"There are company restrictions on using Azure AKS and ACI for deployment, and also we are restricted to use only Notebooks for ML model development. Can someone point me to step-by-step documentation on downloading modle and deploying it outside Azure?\n\nLike after building a ML Model, how to download a packaged model - Docker image that contains the model and other files needed to host it as a web service",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-02T07:02:20.19Z",
                "Answer_score":0,
                "Answer_body":"@06434076 Thanks for the question. You can download the model as shown below in the screen shot.\nIf you have problems when deploying a model to ACI or AKS, deploy it as a local web service. Using a local web service makes it easier to troubleshoot problems. To troubleshoot a deployment locally, see the local troubleshooting article.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML deploy new model",
        "Question_creation_time":1667478071347,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1074346\/azure-ml-deploy-new-model.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I have created an Azure ML model using Azure ML studios notebooks.\n\nIm trying to build and environment with the needed packages, but im having some problems get my model deployed to the environment.\n\nIm pretty new to this whole process so im following the Microsofts guides, but im finding them hard to use when running into issues.\n\nAre there some blogs\/post with real life examples on how to deploy and troubleshoot deploying ML models on Azure?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-15T19:55:09.683Z",
                "Answer_score":0,
                "Answer_body":"Hello @JacobBrockHansen-5654\n\nWe have not hear from you. I hope you have solved your problem but I still want to share more information I got for your issue for reference.\n\nFor your question - real life trouble shooting guidance, you can post any issue you have in this forum, engineers and community will help you out of it.\n\nOfficial troubleshooting guidance we have two -\nTroubleshooting online endpoints deployment and scoring: https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-online-endpoints?tabs=cli\nTroubleshooting remote model deployment: https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/v1\/how-to-troubleshoot-deployment?tabs=azcli\n\nHow guidance for new users -\nHow to deploy models, please see - https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-managed-online-endpoints?tabs=azure-cli\nThere is also a sample for how to deploy models in designer - https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy\n\nYou can post any issue you face during your exploration, we are happy to help.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"ModuleNotFoundError: No module named 'azure.ai'",
        "Question_creation_time":1668204745757,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1086028\/modulenotfounderror-no-module-named-39azureai39.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I am getting the following error message\n\nModuleNotFoundError: No module named 'azure.ai'\n\n\n\n\nin Azure machine learning studio...when i try to run sample azureml-in-a-day.ipynb",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-15T19:33:55.33Z",
                "Answer_score":1,
                "Answer_body":"Hello @Antonymstephen\n\nSorry for your experience and thanks for reaching out to us, I am able to reproduce your issue with my new create compute-cpu.\n\nThere are two workaround working well for myself, please have a try and let me know if that works for you or not -\n\n1.Copy the whole Tutorial file as this guidance - https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/quickstart-run-notebooks#clone-tutorials-folder\n\n\n\n\n2.Easy install the azureml in your compute at the terminal under your root user.\n\n pip install azureml\n\n\n\nJust in case, I encounter pyarrow error after that, the resolution is uninstall the pyarrow 4.0 and install pyarrow 3.0.0 instead as below:\n\n pip uninstall pyarrow\n        \n pip install pyarrow==3.0.0\n\n\n\nI have forwarded this bug to product group and hope to make this process smoother. Please let me know how is things going and I am willing to help more.\n\n\n\n\nRegards,\nYutong\n\nPlease kindly accept the answer if you feel this is helpful. Thank you.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to use parameter weight_column_name in AutoMLConfig Class for Automated Azure MAchine Learning",
        "Question_creation_time":1642428938500,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/698115\/how-to-use-parameter-weight-column-name-in-automlc.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi everybody,\ncould you please help with the weight_column_Name in the AutomLconfig how is used,and how should the syntax be for multiple columns? We are trying to run various different experiments with specific weights in some columns that we consider more serious. Can somebody provide an example of this parameter in use?\n\nKind Regards",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-15T17:32:25.97Z",
                "Answer_score":0,
                "Answer_body":"how do I add this setting with the autoML UI?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-11-15T17:42:44.437Z",
                "Answer_score":0,
                "Answer_body":"how do I set this in the auto ML UI?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML pipeline designer export",
        "Question_creation_time":1668149568060,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1085047\/azure-ml-pipeline-designer-export.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hey,\nIs there any way to export the ML Pipeline as Template\/PNG\/Code ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-11T08:53:54.877Z",
                "Answer_score":1,
                "Answer_body":"@its-kumar The designer pipelines cannot be exported to code or a template currently.\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"EntryPointNotFoundException: Unable to find an entry point named 'OrtGetApiBase' in DLL 'onnxruntime'.",
        "Question_creation_time":1615215403083,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/304053\/entrypointnotfoundexception-unable-to-find-an-entr.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_comment_count":3,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I want to make prediction using azure AutoML onnx model in .net core(3.1) console application in visual studio. I have exported onnx model from azure AutoML.\n\nI am following the tutorial link : https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-automl-onnx-model-dotnet\n\nIt says to install following packages (in parenthesis shows the version I am using)\nMicrosoft.ML (1.5.4)\nMicrosoft.ML.OnnxRuntime(1.7.0)\nMicrosoft.ML.OnnxTransformer(1.5.4)\n\nwhile defining the pipeline\nvar onnxPredictionPipeline =mlContext.Transforms.ApplyOnnxModel(\noutputColumnNames: outputColumns,\ninputColumnNames: inputColumns,\nONNX_MODEL_PATH);\n\nI am getting the following error :\nSystem.TypeInitializationException: 'The type initializer for 'Microsoft.ML.OnnxRuntime.NativeMethods' threw an exception.'\nEntryPointNotFoundException: Unable to find an entry point named 'OrtGetApiBase' in DLL 'onnxruntime'.\n\nThen I tried with Microsoft.ML.OnnxRuntime.Managed(1.7.1) along with above packages but still getting the same issue.\n\nPlease suggest to resolve this issue.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-23T11:11:19.33Z",
                "Answer_score":0,
                "Answer_body":"Hi,\nI included the following packages:\n\nMicrosoft.ML (1.5.5)\nMicrosoft.ML.OnnxRuntime.Managed(1.7.1)\nMicrosoft.ML.OnnxRuntime.MKLML(1.6.0)\nMicrosoft.ML.OnnxTransformer(1.5.5)\n\nIt is working now.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-13T10:30:20.437Z",
                "Answer_score":0,
                "Answer_body":"Hi,\nI included those packages but I am still getting the same error.\nHas anyone else having the same error message and managed to fix it? I read someone else talking about cuda version non compatible, but I don't know what I should do to fix it... Any idea?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-06-03T05:43:45.307Z",
                "Answer_score":1,
                "Answer_body":"In my environment I reproduce the issue after uninstall below redistributable package from control panel.\n\nMicrosoft Visual C++ 2015-2019 Redistributable (x64) -14.29....\nMicrosoft Visual C++ 2015-2019 Redistributable (x86) -14.29....\n\nMy OS is Windows 10, Visual Studio 2019\n\nand installing again this package may solve the issue.\n\nhttps:\/\/support.microsoft.com\/en-us\/topic\/the-latest-supported-visual-c-downloads-2647da03-1eea-4433-9aff-95f26a218cc0\nDirect Link:\nhttps:\/\/aka.ms\/vs\/16\/release\/vc_redist.x86.exe\nand\nhttps:\/\/aka.ms\/vs\/16\/release\/vc_redist.x64.exe\n\nplease install those if not install. And try .\nIf doesn't work Then Install all C++ for Desktop from Visual Studio Installer.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-11-15T11:42:03.173Z",
                "Answer_score":0,
                "Answer_body":"I solved the issue by change Bitness to X64 in project properties --> Web --> Servers.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How can I import existing data labels to Azure Machine Learning Studio?",
        "Question_creation_time":1625099167257,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/458706\/how-can-i-import-existing-data-labels-to-azure-mac.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":8,
        "Question_comment_count":2,
        "Question_follower_count":22,
        "Question_score":2,
        "Question_body":"I have a dataset on the Azure Machine Learning Studio, which is about 1200 images. I also have a tab-delimited text file that specifies the file name, i.e. \"xxyyzz.png\", and the category name i.e. \"dog\".\n\nThe data labeling tools in the dashboard seem to be built with the intention of labeling the images by hand. How can I apply the labels I that I already have to the data in my dataset?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-01T11:39:18.323Z",
                "Answer_score":1,
                "Answer_body":"@JamieHanlon-5975 I can confirm that this functionality is currently under development and we can expect this in future releases. It should go into preview first for interested customers, I can post an update here whenever the preview is announced so you could test it out. Thanks!!",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-15T10:33:14.373Z",
                "Answer_score":0,
                "Answer_body":"Hi @romungi-MSFT, I would be interested in the preview too. Commenting so I could be notified when there's an update in this thread!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-20T12:35:48.8Z",
                "Answer_score":0,
                "Answer_body":"Hi @romungi-MSFT, I am also interested in this new feature, cause we already have lots of labeled data.\nAre there any updated when this feature will be released?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-08T13:47:40.223Z",
                "Answer_score":0,
                "Answer_body":"@romungi-MSFT how can I get access to the preview ?\n\nthanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-15T09:00:57.537Z",
                "Answer_score":0,
                "Answer_body":"@romungi-MSFT I too would love to get access to the preview of this feature.\n\n\/Thomas",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-18T05:41:13.067Z",
                "Answer_score":0,
                "Answer_body":"@romungi-MSFT I would like to get access to this feature as well.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-01-05T22:02:42.103Z",
                "Answer_score":0,
                "Answer_body":"@romungi-MSFT any update on this? I have a lot of images that I can only label manually right now, while I have the labeling data available. It would be very helpful if the labeling data could be uploaded\/imported along with the images, like what is available in Microsoft Custom Vision API.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-09T18:12:28.45Z",
                "Answer_score":2,
                "Answer_body":"Any update on this? I'm also interested on this feature.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Constantly getting this error while training Deep and Wide model. Model is expected to be fed with features: ['feature_user_feature_2', ....",
        "Question_creation_time":1668240133527,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1086242\/constantly-getting-this-error-while-training-deep.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azure-mgmt-core 1.3.0 (\/azureml-envs\/azureml_1c52c6e25bd3041eabbd9a52168ae46\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-core<2.0.0,>=1.3.1'), {'azure-mgmt-keyvault'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azure-mgmt-core 1.3.0 (\/azureml-envs\/azureml_1c52c6e25bd3041eabbd9a52168ae46\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-core<2.0.0,>=1.3.1'), {'azure-mgmt-keyvault'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azure-mgmt-core 1.3.0 (\/azureml-envs\/azureml_1c52c6e25bd3041eabbd9a52168ae46\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-core<2.0.0,>=1.3.1'), {'azure-mgmt-keyvault'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (azure-mgmt-core 1.3.0 (\/azureml-envs\/azureml_1c52c6e25bd3041eabbd9a52168ae46\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-core<2.0.0,>=1.3.1'), {'azure-mgmt-keyvault'}).\nSession_id = 84c324df-90e3-4d06-963d-c896854583\nInvoking module by urldecode_invoker 0.0.8.\n\nModule type: custom module.\n\nUsing runpy to invoke module 'azureml.designer.modules.recommendation.dnn.wide_and_deep.train.run'.\n\n2022-11-06 17:12:43.374707: W tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: \/azureml-envs\/azureml_1c52c6e25bd041eabbd9a52168ae46\/lib:\/usr\/local\/nvidia\/lib:\/usr\/local\/nvidia\/lib64:\/usr\/local\/cuda\/lib64:\/usr\/local\/cuda\/extras\/CUPTI\/lib64\n2022-11-06 17:12:43.374762: I tensorflow\/stream_executor\/cuda\/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2022-11-06 17:12:45,992 studio.common INFO azureml-designer-recommender-modules 0.0.54\n2022-11-06 17:12:51,404 studio.core INFO preprocess_transactions - Start:\n2022-11-06 17:13:06,585 studio.core INFO preprocess_transactions - End with 15.1769s elapsed.\n2022-11-06 17:13:06,589 studio.core INFO preprocess_features - Start:\n2022-11-06 17:13:06,607 studio.core INFO preprocess_features - End with 0.0176s elapsed.\n2022-11-06 17:13:06,607 studio.core INFO preprocess_features - Start:\n2022-11-06 17:13:06,666 studio.core INFO preprocess_features - End with 0.0583s elapsed.\n2022-11-06 17:13:12,074 studio.common INFO Get 10 features\n2022-11-06 17:13:12,166 studio.common INFO Create feature metas for 10 features\n2022-11-06 17:13:14,412 studio.common INFO Get 1 features\n\/azureml-envs\/azureml_1c52c6e25bd3041eabbd9a52168ae46\/lib\/python3.8\/site-packages\/pandas\/core\/generic.py:6245: SettingWithCopyWarning:\nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https:\/\/pandas.pydata.org\/pandas-docs\/stable\/user_guide\/indexing.html#returning-a-view-versus-a-copy\nself._update_inplace(new_data)\n2022-11-06 17:13:14,466 studio.common INFO Create feature metas for 1 features\n2022-11-06 17:13:14,500 studio.common DEBUG Init train input function builder.\n2022-11-06 17:13:14,503 studio.common INFO Build 10 features for User ids.\n2022-11-06 17:13:17,704 studio.common INFO Process null values for features.\n2022-11-06 17:13:17,736 studio.common INFO Build 1 features for Item ids.\n2022-11-06 17:13:20,012 studio.common INFO Process null values for features.\n2022-11-06 17:13:26,398 studio.module INFO Get 5775792 training instances, and 90247.0 batches per epoch.\n2022-11-06 17:13:29,489 studio.module INFO Build model:\nEpochs: 15\nBatch size: 64\nWide optimizer: OptimizerSelection.Adagrad\nWide learning rate: 0.1\nDeep optimizer: OptimizerSelection.Adagrad\nDeep learning rate: 0.1\nHidden units: (256, 128)\nActivation function: ActivationFnSelection.ReLU\nDropout: 0.8\nBatch norm: True\nCrossed dimension: 1000\nUser embedding dimension: 16\nItem embedding dimension: 16\nCategorical feature embedding dimension: 4\n2022-11-06 17:13:29,546 studio.module INFO Model is expected to be fed with features: ['feature_user_feature_2', 'feature_user_feature_8', 'feature_user_feature_3', 'feature_user_feature_9', 'feature_user_feature_4', 'feature_item_feature_0', 'User', 'Item', 'feature_user_feature_5', 'feature_user_feature_1', 'feature_user_feature_6', 'feature_user_feature_0', 'feature_user_feature_7']\n2022-11-06 17:13:30,077 tensorflow INFO Using config: {'_model_dir': '\/tmp\/tmp7lhxl5n0\/checkpoints', '_tf_random_seed': 42, '_save_summary_steps': 100, '_save_checkpoints_steps': 1353705.0, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\ngraph_options {\nrewrite_options {\nmeta_optimizer_iterations: ONE\n}\n}\n, '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 90247.0, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Error creating endpoint from mlflow model (tensorflow job)",
        "Question_creation_time":1667731273557,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1077214\/error-creating-endpoint-from-mlflow-model-tensorfl.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":1,
        "Question_body":"Hello everybody,\nI am trying to deploy a realtime endpoint from a registered mlflow model obtained from a tensorflow training job.\nIn this repository, you will find the training scripts:\n\nhttps:\/\/github.com\/antigones\/py-hands-ml-tf\/tree\/main\/azure_ml\/job_script\n\nThe job outputs a MLFlow model with its conda environment yml file.\n\n\n\n\nWhen I try to deploy the model to a realtime endpoint, I get the following error:\n\n257528-azure-ml-deploy-error.txt\n\nIt seems to be an error related to protobuf, when loading the model:\n\n  File \"\/opt\/miniconda\/envs\/userenv\/lib\/python3.8\/site-packages\/google\/protobuf\/descriptor.py\", line 560, in __new__\n     _message.Message._CheckCalledFromGeneratedFile()\n TypeError: Descriptors cannot not be created directly.\n If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\n If you cannot immediately regenerate your protos, some other possible workarounds are:\n  1. Downgrade the protobuf package to 3.20.x or lower.\n  2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n    \n More information: https:\/\/developers.google.com\/protocol-buffers\/docs\/news\/2022-05-06#python-updates\n\n\n\nThe environment is deployed automatically (the scoring script is also generated).\nI have also tried different images, with different python versions (3.7) and Tensorflow versions (2.4) with no luck.\n\nHow can I solve this issue?\n\n\n\n\nThank you in advance for your support.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-06T14:01:03.993Z",
                "Answer_score":1,
                "Answer_body":"Seems like the problem is in azureml-inference-server-http package, where there is a mismatch with protobuf version.\n\nAs a workaround, I created a custom managed online deployment via CLI, specifing the following environment variable:\n\n environment_variables:\n   \"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\": \"python\"\n\n\n\nand then I was able to publish the endpoint.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-11-10T19:57:59.41Z",
                "Answer_score":0,
                "Answer_body":"I have a Keras model and I had to develop and upload my own score.py to override the init() function in order to load the model using load_model() for Keras models, instead of using joblib.load(model_path) as it was by default.\nYou probably also have to override the run() function to customize the inference.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Designer: Export Code",
        "Question_creation_time":1646150939773,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/755142\/azure-ml-designer-export-code.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"Is there an option to export the Azure ML Designer to code so we can copy between workspaces?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-02T06:20:05.287Z",
                "Answer_score":1,
                "Answer_body":"Hi, this feature is currently not supported as mentioned on this thread. However, it's on the roadmap.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-11-10T18:23:47.713Z",
                "Answer_score":0,
                "Answer_body":"Is the roadmap public? When is this feature planning on being released?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Creating Workspace using python",
        "Question_creation_time":1667322573967,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1071316\/creating-workspace-using-python.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"I'm trying to create a Workspace using Python\n\nws = Workspace.create(name = '', subscription_id ='', resource_group='', create_resource_group = True, location = 'India')\n\nBelow is the error I'm facing\n\nMe default directory has a subscription\n\nAzureMLException: AzureMLException:\nMessage: No subscriptions found for enochkranthi@gmail.com.\nInnerException None\nErrorResponse\n{\n\"error\": {\n\"message\": \"No subscriptions found for enochkranthi@gmail.com.\"\n}\n}",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Import, call and development of other predictive models into Azure",
        "Question_creation_time":1667551730223,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1075731\/import-call-and-development-of-other-predictive-mo.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":25,
        "Question_score":0,
        "Question_body":"Can Microsoft Azure supports importing, calling and development of custom predictive models through R, SAS code, C, C++, Java, Predictive Model Markup Language (PMML), Open Neural Network Exchange (ONNX) or REST APIs?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-08T09:04:02.123Z",
                "Answer_score":0,
                "Answer_body":"@MingJunLim-7028 You should be able to register a model with supported formats with Azure ML workspace. Please see this section from documentation.\n\nYou would need to create an Azure ML workspace from azure portal and then use ml.azure.com to register your model from the above screen.\n\nOnce the model is registered, you can deploy it and call it using REST API or the SDK.\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML - Can not list\/load registered Datasets via Python SDK",
        "Question_creation_time":1667981280147,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1081549\/azure-ml-can-not-listload-registered-datasets-via.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I'm quite new to Azure ML and Python. I created some datasets using both the Azure ML GUI and the Python SDK:\n\n\n\n\nNow I want to load these datasets in a Pandas Dataframe. But when I run\n\nDataset.get_all(workspace=workspace)\n\nI got an empty list:\n\nDo I miss something? I'm using the version 0.2.7. of azureml and Version 1.46.0. of azureml-core.\n\nI also tried\n\nworkspace.datasets\n\n\n\n\nBut also got an empty result.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure ML service and SAS files",
        "Question_creation_time":1667406090587,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1072904\/azure-ml-service-and-sas-files.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Am not able to preview the sas7bdat files in Azure ML service.. whether sas7bdat files analysis are supported in Azure ML services ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-03T02:38:56.42Z",
                "Answer_score":1,
                "Answer_body":"I want to import them in ML studio designer pipelines. Tried to import the sas7dat extension files for processing the data. Also converttocsv service is throwing the error with source as sas extension.\n\nGot the error as ValueError: Unable to detect DataType: Unrecognized file extension '.sas7bdat'.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"ML assisted data labeling completed the Training run phase, but how to start the Inference run?",
        "Question_creation_time":1663730318027,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1016703\/ml-assisted-data-labeling-completed-the-training-r.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":13,
        "Question_score":1,
        "Question_body":"I'm having trouble getting ML assisted data labeling to begin prelabeling.\n\nI have an object detection Data Labeling project in Azure ML Studio workspace. ML Assisted is enabled from the project creation. I manually labeled the number required to start Training run (in my case, 45). Completed Training run without issue. Yet, the Inference run never started up. The info button when I hover over the \"Prelabeled\" Task Queue informs me the Inference run must be done before prelabeling can begin. How do I start the Inference run? Is there a manual step needed to start the Inference run? I thought it would happen automatically after the Training run completed (ensuring compute resource is available of course). I labeled more manually to trigger and complete a 2nd Training run, but Inference still did not start. I must be missing something, but not sure what to do.\n\nThe on-demand button in the Settings is for the Training run only, so it is not clear if the Inference run can be triggered on-demand.\n\nHere's my project experiments summary on the dashboard view:\n\nML assisted data labeling experiments Experiment Latest run Run Status\nTraining cool_experiment AutoML_<hashid> Completed\nInference Experiment not started -- --",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-22T05:59:23.483Z",
                "Answer_score":0,
                "Answer_body":"@jen-8776 Thanks for the question. Once you have exported your labeled data to an Azure Machine Learning dataset, you can use AutoML to build computer vision models trained on your labeled data.\n\nHere is the Document to setup AutoML.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-28T06:59:41.007Z",
                "Answer_score":0,
                "Answer_body":"Inference run is used to generate ML-Assisted pre-labeled task for labelers. There are two prerequisites for that to happen:\n\nThere is a model - That is at least one training run completed successfully.\n\n\nThere is a need - If the system believes there isn't enough tasks in the task queue. (For example, < 300 tasks that queue), it will start an inference run to generate pre-labeled tasks.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Wheres my component",
        "Question_creation_time":1667251682350,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1070006\/wheres-my-component.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hi expert, I am struggling in a bug, I can\u2019t see anything in my studio and it shows empty, how can I fixed it. Anyone else experience this or is this a bug.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-31T23:42:44.343Z",
                "Answer_score":0,
                "Answer_body":"Hello @jamesschmidt-7068\n\nThanks for reaching out to us for this issue. I have checked on my end and I find everything is OK.\n\nCould you please make sure you have not selected any filter\/ selected all tags and click on the refresh button to make sure you have every component.\n\nMy studio is as above, please do check all the settings and let me know if you still have any issue.\n\nRegards,\nYutong\n\n-Please kindly accept the asnwer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Hide arugments of the Job properties on AzureML ?",
        "Question_creation_time":1667818798267,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1078267\/hide-arugments-of-the-job-properties-on-azureml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I would like to know if there is a way to hide specific Arguments from being displayed in the properties Tab of a Job ?\nThis would be helpful because for the run i have to pass several IDs and dont want it to be displayed. I am using a ScriptRunConfig() function to which i am passing the arguments.\nThanks in advance",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How to register a model in Azure Machine Learning when the model is a self made class encapsulating a tensorflow model ?",
        "Question_creation_time":1667560124293,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1075887\/how-to-register-a-model-in-azure-machine-learning.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hello,\n\nI'm training a tensor flow model locally, and using it in a self made class to add pre\/post code to the TF model prediction.\n\nI can't find how to register the model because a tensor flow model (ans thus my class containing it) can't be pickled (and apparently is not advised) so I can't use\nModel.register(workspace, model_name=..., model_path=..., tags=..., description=...)\n\nAs I train my model locally and don't use experiments, it seems I can't either use run.register(...) as I don't have a run.\n\nAlso, I've seen from the documentation that I can add model_framework and model_framework_version parameters to the register method but I'm not sure what I should put in these parameters as I guess the framework is not just tensorflow but my self made class ?\n\nHere is the structure of my class in case it can help:\n\nclass DNN():\n    \n    def __init__(self, dim, tokenizer, max_len):\n        \"\"\"\n        Initialize Neural Network recommender.\n        \n        Parameters\n        ----------\n        dim : int Dimension of the output Embedding layer.\n        tokenizer : The tokenize() generator\n        max_len : int Maximum number of elements for each list.\n        \"\"\"\n        self.dim = dim\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n          \n    def fit(self, X, Y):\n        self.model = Sequential()\n        self.model.add(...)\n        self.model.compile(...)\n        self.model.fit(x=X, y=Y, ...)\n        return self\n    def predict(self, x):\n        apply_preprocessing(x)\n        pred = self.model.predict(padded_order)[0]\n        res = apply_postprocessing(pred )  \n        return res\n\n\n\n\nThank you for your help !",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"I can't select By name in Columns to be cleaned as picture I attached. How should I deal with this?",
        "Question_creation_time":1666255977207,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1056111\/i-can39t-select-by-name-in-columns-to-be-cleaned-a.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-21T06:27:20.537Z",
                "Answer_score":0,
                "Answer_body":"@ShoaibakhtarShaikh-9486 Thanks for the question. We can see the column names as shown below.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"can I build my ML pipeline\/experiment in ML studio designer, and export it as a python and jupyter notebook?",
        "Question_creation_time":1667248966827,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1069926\/can-i-build-my-ml-pipelineexperiment-in-ml-studio.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I am able to run the notebook in studio, but can I export the studio as notebook and import it in another place?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-01T02:02:29.163Z",
                "Answer_score":0,
                "Answer_body":"Hello @usuigina-5328\n\nThanks for using Microsoft Q&A. Sorry, this is not support at this moment. But Azure Machine Learning Studio already has Notebook function just for your reference.\n\nI will forward your feedback to product team and at the same time, I would highly recommend you provide your feedback in Azure Machine Learning portal to raise more visability - top right side as below screenshot\n\nI hope this helps!\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Response status code does not indicate success: 400 (Conda dependencies were not specified. Please make sure that all conda dependencies were specified i).",
        "Question_creation_time":1667250048510,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1069928\/response-status-code-does-not-indicate-success-400.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I was trying to setup my env runconfig = ScriptRunConfig(source_directory='script\/', script='my-script.py', arguments=script_params)\nrunconfig.run_config.target = compute_target\nrunconfig.run_config.environment = env\nrun = exp.submit(runconfig)",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-01T07:37:12.75Z",
                "Answer_score":0,
                "Answer_body":"Hello @jackson-0025\n\nThanks for using Microsoft Q&A platform. I have seen a very similar question as your, and the solution is you need to use RunConfiguration instead of ScriptRunConfig. More info here\n\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-getting-started.ipynb\n\n from azureml.core.runconfig import RunConfiguration\n    \n env = Environment.get(workspace=ws, name='my-environment', version='1')\n # create a new runconfig object\n runconfig = RunConfiguration()\n runconfig.environment = env\n    \n pipeline_step = PythonScriptStep(\n     source_directory='script', script_name='my-script.py',\n     arguments=['-a', param1, '-b', param2],\n     compute_target=compute_target,\n     runconfig=runconfig\n )\n    \n pipeline = Pipeline(workspace=ws, steps=[pipeline_step])\n    \n pipeline_run = Experiment(ws, 'my_pipeline_run').submit(pipeline)\n\nReference for the issue - https:\/\/stackoverflow.com\/questions\/60506398\/how-do-i-use-an-environment-in-an-ml-azure-pipeline\n\nI hope this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpfuk to support the community, thanks a lot.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Can you create an MLTable Dataset (Tabular Format) from a CSV file?",
        "Question_creation_time":1665800219957,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1049085\/can-you-create-an-mltable-dataset-tabular-format-f.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"I have collected data that I'd like to use in AutoML to see if there's a pattern that can be derived from the data. According to docs, the data needs to be uploaded in the MLTable format in order to be used in AutoML. However, my data is currently in CSV format. There are fairly clear instructions on how to create an MLTable data asset, but the instructions assume your data starts in MLTable format (see the Note: \"The path points to the folder containing the MLTable artifact\"). I can't seem to find any instructions on how to create the MLTable artifact\/folder in the first place, so I can't follow these instructions. Do these instructions exist somewhere? If so, is it possible for someone to link me to it or describe this process? Thank you!",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Pytorch error - RuntimeError: Unable to find a valid cuDNN algorithm to run convolution on Standard_NC6 and Python 3.8 - Pytorch and Tensorflow kernel",
        "Question_creation_time":1666006220943,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1050727\/pytorch-error-runtimeerror-unable-to-find-a-valid.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello community,\n\nI am new to Azure. I have some scripts in a working environment in google colab, and as I am working on my Thesis I tried to user Azure Student promo.\nI have setup a Standard_NC6 with Pytorch and Tensorflow kernel and I am getting the following error:\n\n---------------------------------------------------------------------------\nRuntimeError Traceback (most recent call last)\nInput In [9], in <cell line: 64>()\n76 loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake))\n77 critic.zero_grad()\n---> 78 loss_critic.backward(retain_graph=True)\n79 opt_critic.step()\n81 # clip critic weights between -0.01, 0.01\n\n\nFile \/anaconda\/envs\/azureml_py38_PT_TF\/lib\/python3.8\/site-packages\/torch\/_tensor.py:396, in Tensor.backward(self, gradient, retain_graph, create_graph, inputs)\n387 if has_torch_function_unary(self):\n388 return handle_torch_function(\n389 Tensor.backward,\n390 (self,),\n(...)\n394 create_graph=create_graph,\n395 inputs=inputs)\n--> 396 torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n\n\nFile \/anaconda\/envs\/azureml_py38_PT_TF\/lib\/python3.8\/site-packages\/torch\/autograd\/init.py:173, in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\n168 retain_graph = create_graph\n170 # The reason we repeat same the comment below is that\n171 # some Python versions print out the first line of a multi-line function\n172 # calls in the traceback and some print out the last line\n--> 173 Variable.execution_engine.run_backward( # Calls into the C++ engine to run the backward pass\n174 tensors, grad_tensors, retain_graph, create_graph, inputs,\n175 allow_unreachable=True, accumulate_grad=True)\n\n\nRuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n\n\n\n\nI tried different versions of pytorch + cu113 and cu116.\n\nThe nvdia-smi output is:\n\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.141.03 Driver Version: 470.141.03 CUDA Version: 11.4 |\n|-------------------------------+----------------------+----------------------+\n| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |\n| Fan Temp Perf Pwr:Usage\/Cap| Memory-Usage | GPU-Util Compute M. |\n| | | MIG M. |\n|===============================+======================+======================|\n| 0 Tesla K80 On | 00000001:00:00.0 Off | 0 |\n| N\/A 41C P0 70W \/ 149W | 880MiB \/ 11441MiB | 0% Default |\n| | | N\/A |\n+-------------------------------+----------------------+----------------------+\n\n\n+-----------------------------------------------------------------------------+\n| Processes: |\n| GPU GI CI PID Type Process name GPU Memory |\n| ID ID Usage |\n|=============================================================================|\n| 0 N\/A N\/A 11425 C ...eml_py38_PT_TF\/bin\/python 877MiB |\n+-----------------------------------------------------------------------------+\n\nI guess that the problem is about drivers and versions.. as in google colab environment it's working\n\nThanks,\nDP",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-18T14:26:03.943Z",
                "Answer_score":0,
                "Answer_body":"@dp-5741Thanks for the question. using one of the containers \/ environments in AML which is correctly configured for GPU should be sufficient if the ML framework being used supports GPU acceleration. The GPU images contain Miniconda, OpenMPI, CUDA, cuDNN, and NCCL. You can use these images for your environments, or use their corresponding Dockerfiles as reference when building your own custom images.\n\nFor the set of base images and their corresponding Dockerfiles, see the AzureML-Containers repo.\n\nhttps:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-environments-v2?tabs=cli#create-an-environment",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Trained NLP model snippet",
        "Question_creation_time":1667251332713,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1069986\/trained-nlp-model-snippet.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Newbie data scientist here, I am just starting my way in Azure, is there any I should start NLP? Any trained model or code sample? Thank you for any idea",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-06T23:15:45.22Z",
                "Answer_score":0,
                "Answer_body":"Hello @jacksonschmidt-1888\n\nSorry I have not heard from you. I have done some researches around NLP in Azure. This can be done by two ways -\n\nAzure Machine Learning Python SDK\/ ML CLI extension\nWe don't have any trained model you can use in Azure ML but you do have the SDK supporting you to train your model\nhttps:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-nlp-models?tabs=cli\n\nNLP Server\nApache Spark is a parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications. Azure Synapse Analytics, Azure HDInsight, and Azure Databricks offer access to Spark and take advantage of its processing power.\n\nFor customized NLP workloads, Spark NLP serves as an efficient framework for processing a large amount of text. This open-source NLP library provides Python, Java, and Scala libraries that offer the full functionality of traditional NLP libraries such as spaCy, NLTK, Stanford CoreNLP, and Open NLP. Spark NLP also offers functionality such as spell checking, sentiment analysis, and document classification. Spark NLP improves on previous efforts by providing state-of-the-art accuracy, speed, and scalability.\n\nThe NLP Server is available in Azure Marketplace. To explore large-scale custom NLP in Azure, see NLP Server - https:\/\/azuremarketplace.microsoft.com\/en-US\/marketplace\/apps\/johnsnowlabsinc1646051154808.nlp_server?ocid=gtmrewards_whatsnewblog_nlp_server_040622\n\nAzure Language Service\nThough we don't have trained model in Azure ML, but we do have REST APIs you can use for Text Analytics, Sentiment Analytics and so on functions for NLP, I would suggest you to check on the document, it may help you achieve your bussiness goals.\nhttps:\/\/learn.microsoft.com\/en-us\/azure\/cognitive-services\/language-service\/\n\nI hope those information helps. Please let me know if you have any questions regarding to any of above.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure ML online endpoint suddenly returns timeout",
        "Question_creation_time":1666021337190,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1051161\/azure-ml-online-endpoint-suddenly-returns-timeout.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hi all,\n\nWe have deployed a managed online endpoint in Azure ML and first it works fine. However, after a few days, with the exact same request, the endpoint takes much longer to process the request and gives a timeout (the HTTP code returned is 504). We don't understand this behavior since we did not modify the endpoint and the metrics don't show a huge increase in cpu or memory usage. If we restart it then it works again for a few days until it doesn't work anymore. Has anyone faced the same issue? Could you solve it?\n\nThanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-29T14:10:52.19Z",
                "Answer_score":0,
                "Answer_body":"@AlbertGarrigaPorqueras-9657\nI came across the same error trying to invoke the model from public internet though, I retried invoking it in a VM that is in the same vnet\/subnet that Azure Machine Learning Workspace, Storage Account and Container Registry connect to by private endpoints, and it works.\nMy scenario is public inbound, and public egress network access is disabled.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Deploy Azure ML Model on HTML able to read excel files",
        "Question_creation_time":1667420764960,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1073090\/deploy-azure-ml-model-on-html-able-to-read-excel-f.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I have a trained model on Azure Automated Machine Learning, what I want to know is that if it is possible to deploy that model on an executable program (C# or Python) or with an HTML program.\nWith this I want to accomplish the following process:\n\n\n\n\n\n\nI would really appreciate an answer. Thank you in advance!",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Unable to connect to adls gen2 from azure ml workspace",
        "Question_creation_time":1667403446370,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1072809\/unable-to-connect-to-adls-gen2-from-azure-ml-works.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":19,
        "Question_score":0,
        "Question_body":"Hi,\n\nI tried to create datastore in azure ml to connect to adls gen2. I have created app registration and used those client id and secret id. I also assigned the required permission [ storage blob data owner for the client id] in the resource group where the adls gen2 is located\n\nBut still I am not able to access the data. Please suggest me what further I have to do\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-03T12:55:34.46Z",
                "Answer_score":1,
                "Answer_body":"Hi @romungi-MSFT\n\nThanks for the reply. The issue is resolved now\n\nI have mentioned the path wrong and datastore also couldn't directly read my data\n\nThen I came to know that path name should starts after the file system name. After changing my path [ similar to source-data\/abc.csv] it worked fine\n\nThanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"how to set budget limit on a compute instance created in azure ML studio",
        "Question_creation_time":1666864166367,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1065129\/how-to-set-budget-limit-on-a-compute-instance-crea.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":21,
        "Question_score":0,
        "Question_body":"hi Team,\nI want to set limitations on the VMs which are used for model training. Now, these compute instances are created using ML Studio and my requirement is to pause the model training if the pre-defined budget is over. This is to prevent user of unexpected charges and control the expenses.\n\nBut I am not able to figure out the way on how to do it.\n1 way is to put a limit on the compute instance so that if it crosses the budget then its is paused and only upon resetting the budget, user can start it back.\n\nTo achieve this, I am thinking to set some actionGroup on budget to pause the VM or is there any automatic setting available to do this?\n\nOn top of everything, I am not able to find the filter which can put a budget on ML Compute. I can find till workspace but nowhere on compute part. How to control the model training budgets in that case?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-27T14:36:24.467Z",
                "Answer_score":0,
                "Answer_body":"@JA-9673 I believe you can set budget for Azure ML compute using the following settings. I don't see this documented in detail in Azure ML docs but there is a section to manage costs using budgets.\nThe following settings should work to set alerts on your compute usage within the workspace. I do not see an option to drill down on the compute type like compute instances, compute clusters or inference clusters though.\n\nThe resource ID is what you will have to check to get the compute usage for your workspace. Just search with the workspace name for the Resource.Id filter value and you should be able to filter the cost of your workspace compute.\n\nAlso, the compute instance offers a feature in the advanced settings to schedule the compute instance start, stop and auto shutdown. I have been using this feature to manage my compute instance in my workspace.\n\nOther ways to reduce costs related to Azure ML are documented here for reference.\nI hope this helps!!\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How can I install local python library to azure ml studio environment",
        "Question_creation_time":1667248136980,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1069983\/how-can-i-install-local-python-library-to-azure-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"As title, find no docs or code sample from Azure",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-01T07:47:34.23Z",
                "Answer_score":0,
                "Answer_body":"Hello @jameslong-5485\n\nThanks for using Microsoft Q&A, below is how to use private Python packages securely within Azure Machine Learning. Use cases for private Python packages include:\n\nYou've developed a private package that you don't want to share publicly.\nYou want to use a curated repository of packages stored within an enterprise firewall.\nThe recommended approach depends on whether you have few packages for a single Azure Machine Learning workspace, or an entire repository of packages for all workspaces within an organization.\n\nThe private packages are used through Environment class. Within an environment, you declare which Python packages to use, including private ones. To learn about environment in Azure Machine Learning in general, see How to use environments.\n\nFor more details, please refer to here - https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/v1\/how-to-use-private-python-packages\n\nLet me know if you need more information, I hope this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Access to Azure subscription for users",
        "Question_creation_time":1666972949727,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1067157\/access-to-azure-subscription-for-users.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":53,
        "Question_score":0,
        "Question_body":"We have an active subscription. For few of the users we activated owner role for the machine learning resource group.\nBut when they login to the portal\/ML environment and try to switch directory and subscription, they don't see our production subscription and hence the workspace, although directory is correct. User had created a trial subscription on its own before and he only has visibility to that.\n\nI checked with a test account and after login to ML studio I see this, which I believe is the same reason user does not see the subscription.\n\nHow can I safely give user subscription access only for ML resource group",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-28T17:11:56.507Z",
                "Answer_score":0,
                "Answer_body":"Hi @RT-7199\n\nThank you for asking this question on the Microsoft Q&A Platform.\n\nThe role will depend on the activity that the user performs, for example, to create a new workspace you will require the role owner or contributor at the Resource group-level. (If you receive a failure when trying to create a workspace for the first time, make sure that your role allows Microsoft.MachineLearningServices\/register\/action. This action allows you to register the Azure Machine Learning resource provider with your Azure subscription.)\n\nYou can get more information about RBAC for Azure Machine Learning workspace here\n\nHope this helps!\n\nAccept Answer and Upvote, if any of the above helped, this thread can help others in the community looking for remediation for similar issues.\nNOTE: To answer you as quickly as possible, please mention me in your reply.",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"R support in Azure ML using CLI 2.0",
        "Question_creation_time":1666005191493,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1050764\/r-support-in-azure-ml-using-cli-20.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi, can somebody point me out to the latest hands on for using R Machine Learning in Azure ML. All the documentations are using Azure SDK for R, but it is deprecated as of end of 2021. Is there any step by step sample implementation using CLI 2.0 for R ML development",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-18T09:45:29.093Z",
                "Answer_score":0,
                "Answer_body":"@06434076Thanks for the question. Currently We don't have any support for R in Azure ML CLI 2.0. In the near future we will support Running R training and inferencing workloads in AzureML leveraging AzureML (CLI + SDK).\n\nYou can use the R-studio on Compute instance where users could get R-studio community installed on Compute instance to develop\/debug their ML models.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML pipeline from an Azure DevOps pipeline",
        "Question_creation_time":1667236694490,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1069739\/azure-ml-pipeline-from-an-azure-devops-pipeline.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Tried invoking an Azure ML pipeline from an Azure DevOps pipeline ? I keep running into errors, so I want to make sure my high level process is correct.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-01T02:57:49.657Z",
                "Answer_score":0,
                "Answer_body":"@Srin-4824 Thanks for the question. You can use the Azure CLI task - Azure Pipelines | Microsoft Docs step and run command line or Python scripts inside that to submit your pipelines.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning - Access uri_folder dataset (ML v2) from notebook (not job)",
        "Question_creation_time":1666794361980,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1063867\/azure-machine-learning-access-uri-folder-dataset-m.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":18,
        "Question_score":0,
        "Question_body":"Hi all,\n\nI've registered in Azure Machine Learning a Data Lake Gen2 datastore that point to a container with a hierarchy of folders that contain avro files and on top of it I registered a folder_uri dataset (ML v2).\n\nNow I want to access to these folders from a notebook, convert them in a pandas dataframe in order to do some data exploration.\n\nI search on the documentation, and I only found examples that run job and using this type of dataset as input, but I need to be able to explore it using notebook.\n\nIs it possible? How can I do it?\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-27T12:45:05.14Z",
                "Answer_score":0,
                "Answer_body":"@GCocci Thanks for the question. Currently it's not supported to access the avro files. Here is the document for accessing the datastore using folder_uri dataset.\nhttps:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/migrate-to-v2-resource-datastore\n\nMapping Data Flow supports AVRO as a source type https:\/\/learn.microsoft.com\/en-us\/azure\/data-factory\/data-flow-source#supported-sources",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Can't Test my ML model because of schema mismatch in Test data",
        "Question_creation_time":1666918751970,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1066126\/can39t-test-my-ml-model-because-of-schema-mismatch.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I have a model which I would like to test against a test dataset. I am using AutoML and have generated a regression model. I notice that when I register a data asset it randomly incorrectly assigns certain columns as Integer or Decimal. When I try to test the model against a new data asset there is a mismatch of about 50 columns. I have about 1400 columns in my dataset so it is impossible to go through every column to make sure they match what was in the orginal data asset used for the model. I don't even know how to view or change the schema of a data asset as it doesn't seem to allow me to do that in the Azure ML Studio. Is there a workaround for this problem or at least a way I can programatically update my test data asset schema to match the schema used in the model?\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-31T16:25:51.123Z",
                "Answer_score":1,
                "Answer_body":"Thanks!I realized the GUI was a pain and there are better options via pipelines, or using the python SDK.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Why am I being charged for Azure Machine Learning?",
        "Question_creation_time":1667150713980,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1068344\/why-am-i-being-charged-for-azure-machine-learning.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":32,
        "Question_score":1,
        "Question_body":"Context: I created an Azure Machine Learning workspace and uploaded a dataset that's less than 1mb. I created a compute instance and a compute cluster to test. They're shutdown, and haven't used the workspace since Oct 25, yet today I log in and find out I have been charged around $0.40 daily for no apparent reason at all.\n\nThe cost management shows the following:\n\n\n\n\nAnd it's even showing that i'm supposedly using a premium SSD, which is what's costing the most:\n\nI don't remember getting such a disk. And according to the portal, there isn't any:\n\n\n\n\nAccording to the cost management again, it's not storage what's causing the high cost, it's the Azure ML resource:\n\nThere's even this tag: amlresourcetype: provisioner.batch\nI tried to google it, but I can't find anything about it.\n\nSo finally, I check the computer instances but everything seems ok:\n\nSo, does anyone have any remote idea as to why I'm being charged? Why does the cost management says I'm been charged for storage but then it says it's the Azure ML resource? How can I get rid of the supposedly premium SSD I'm using?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-30T18:07:19.763Z",
                "Answer_score":1,
                "Answer_body":"Hi,\n\nI will suggest you to raise a support case with the billing team so they can assist you further over here\n\n\n\n\nHope this helps.\nJS\n\n==\nPlease \"Accept the answer\" if the information helped you. This will help us and others in the community as well.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Not able to read variable in custom RStudio open-source application , Azure ML",
        "Question_creation_time":1665035652217,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1037115\/not-able-to-read-variable-in-custom-rstudio-open-s.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"In Azure ML we have created compute instance by using setup shell script and we also installed custom RStudio open-source application using below MS docs\nhttps:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance?tabs=azure-studio\n\nIn setup shell script we define environment variable\n\nCreate .Renviron file\n\nr_env_file=\"\/home\/${aml_user}\/.Renviron\"\n\necho \"Creating R environment variables\"\nsudo tee \"${r_env_file}\" > \/dev\/null <<EOF\nAZURE_TENANT_ID=${AZURE_TENANT_ID}\nAZURE_CLIENT_ID=${AZURE_CLIENT_ID}\nAZURE_CLIENT_SECRET=${AZURE_CLIENT_SECRET}\nDEFAULT_ADLS_ACCOUNT=${DEFAULT_ADLS_ACCOUNT}\nDEFAULT_ADLS_CONTAINER=${DEFAULT_ADLS_CONTAINER}\nEOF\n\nsudo chown \"${aml_user}\" \"${r_env_file}\"\nsudo chmod 600 \"${r_env_file}\"\n\nIn terminal we are able to read above variable\n\n\nHowever, we are not able to read above variable in custom RStudio open-source application.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-07T03:08:25.81Z",
                "Answer_score":0,
                "Answer_body":"@SHAIKHAlifAbdul-9052 Thanks for the question. Can you please add more details about the usecase that you are trying?. The Azure Machine Learning SDK for R was deprecated at the end of 2021 to make way for an improved R training and deployment experience using Azure Machine Learning CLI 2.0. See the samples repository below to get started with the 2.0 CLI.\n\nThis directory provides sample code to run R using the Azure ML CLI (v2).",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to priotize certain values from the Excel Worksheet (CSV) in \"automated ML or Designer\"",
        "Question_creation_time":1664834223093,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1033854\/how-to-priotize-certain-values-from-the-excel-work.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I have an Excel Worksheet with many values from students (anonymized) who applied for a MSC.\nAll values are checked during the \"admission process\" from the University.\n\nAdmission criteria: The student will only be granted (accepted) to the MSc if he has a certain grade (BSc) and his University (BSc) is accepted (accredited). Furthermore, he should show a good English level. In addition, the student needs at least (around) 2 years of work experience, before he can start with the MSc. Certain values (e.g. the grade) can be compensated by other values (e.g. the work experience) to a defined level.\n\nBy using Microsoft Azure, I want to predict if a student will be accepted or not accepted. And\/or maybe if a certain process step (e.g. check the English level) needs to be conducted or a recommendation\/prediction can be given instead - just on the basis of historical values.\n\nSo far, my models (in Microsoft Azure automated ML and sometimes in Micorosft Azure Designer) recognize (or weight) values such as the student ID (e.g. 1, 2, 3) or the Start-Semester (e.g. Autumn 2022) as more important than values such as e.g. \"work experience\", \"grade\" (BSc) or \"the University\" (BSc).\n\nMy question: Is there a possibility to prioritize certain values in \"Microsoft Azure automated ML\" or Microsoft Azure Designer\"?\nMoreover, can I set admission criteria (please see above), which need to be fulfilled or taken into account for the model?\n\nThank you for your feedback\nBest regards\nLukas",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-05T16:32:08.97Z",
                "Answer_score":0,
                "Answer_body":"@LukasBusers-1078 Thanks for the details. Are you not able to convert\/extract with the current value to datetime datatype.\n\nHere is the document for creating the tabular dataset from CSV.\n\nhttps:\/\/learn.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.dataset_factory.tabulardatasetfactory?view=azure-ml-py#azureml-data-dataset-factory-tabulardatasetfactory-from-delimited-files",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"how to set Quota at resource group level?",
        "Question_creation_time":1667069444447,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1067916\/how-to-set-quota-at-resource-group-level.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":21,
        "Question_score":1,
        "Question_body":"Hi team,\nI am learning about the quota for machine learning service and I have a general doubt.\n\nI can see that quotas for CPU cores is set at subscription level. Now, lets say my subscription level total CPU cores quota is 10.\nAnd i have 2 resource groups under that subscription. Can I assign 5 -5 cores each to both of the resource groups.\n\nso that if all the cores are taken up by the resources under 1 resource group, the other resource_group (or the ML workspace under the other resource group) should not suffer.\n\nI am able to find out the- get details query but this one doesnt give me details specific to each resource-group or the workspace.\n\nHTTP query -> https:\/\/management.azure.com\/subscriptions\/{subs_id}\/providers\/Microsoft.MachineLearningServices\/locations\/eastus\/usages?api-version=2022-10-01",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-29T18:59:07.337Z",
                "Answer_score":1,
                "Answer_body":"Hi @JA-9673 ,\n\nquotas can be set on Azure Subscription level only.\nThere is no option to apply quotas for different Azure Resource Groups.\nThere are 2 options I can see for your requirement:\nUse 2 Azure Subscriptions for each Resource Group\nUse the 2 Resource Groups in 2 different regions. There is a quota for vCPUs per region within the same Subscription.\n\n(If the reply was helpful please don't forget to upvote and\/or accept as answer, thank you)\n\nRegards\nAndreas Baumgarten",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Last Operation Failed. Not able to Start my VM compute",
        "Question_creation_time":1666994188850,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1067503\/last-operation-failed-not-able-to-start-my-vm-comp.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":31,
        "Question_score":0,
        "Question_body":"Hi all,\n\nI am very new to the azure cloud, and I was using ML Studio service for my DS modeling until something happened with my Compute. One of my compute is stuck on Stopped status with a loading icon for a week. I cannot do anything with it, no start, no stopping, and no restarting. Does anybody know what is going on with my compute?\n\nThank you\nNathan",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-29T08:18:31.367Z",
                "Answer_score":0,
                "Answer_body":"Hello @FanyangKong-9847\n\nIn most instances with Azure Machine learning, you can just delete and recreate the compute. Looking at the size and name of the compute instance, I am assuming you are using Jupyter notebooks, which you are most likely deploying any required packages at the start of the notebook, therefore deleting and recreating should be ok as the notebooks are stored within an Azure storage account.\n\nIf for some reason you require this instance of compute, then you can contact Microsoft support who can look into the back-end logs and determine the issue.\n\nhttps:\/\/learn.microsoft.com\/en-us\/azure\/azure-portal\/supportability\/how-to-create-azure-support-request\n\nI hope this helps provide you with the information you need. If it does, please make sure to mark the question as answered so it helps other people in future.\n\nKind Regards\n\nAlistair",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML, OnlineEndPoint List API",
        "Question_creation_time":1666975825190,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1067262\/azure-ml-onlineendpoint-list-api.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"The Rest API to list all Online endpoints is returning an empty list. I have several Online Endpoints some with kubernetes cluster and some with Instance Containers.\n\nhttps:\/\/learn.microsoft.com\/en-us\/rest\/api\/azureml\/2022-10-01-preview\/online-endpoints\/list?tabs=HTTP#code-try-0",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-28T19:01:30.87Z",
                "Answer_score":0,
                "Answer_body":"Hi Surabhi,\n\nWhat is the error message you receive? As the API is in the preview mode there could be a issue in the query and as you have listed that you have several Online Endpoints but none are returnded I believe could be an API issue. I will suggest you to raise a feedback on the preview page here.\n\n\n\n\nHope this helps.\nJS\n\n==\nPlease \"Accept the answer\" if the information helped you. This will help us and others in the community as well.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-28T23:28:05.477Z",
                "Answer_score":0,
                "Answer_body":"Thank you, but same issue exist even with non-preview version as well.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML REST API - how to list Realtime Endpoints?",
        "Question_creation_time":1650984915950,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/827037\/azure-ml-rest-api-how-to-list-realtime-endpoints.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":5,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I'm trying to find the right Azure REST endpoint that would allow me to programmatically list out Realtime-Endpoints have have deployed in Azure ML.\nThe closest one that looked like it might give me what I'm looking for is Online Endpoints - List, what when I test it out, get get back and empty results set, even though my workspace does contain a live and working Realtime enabled endpoint. Is this possibly a feature that's not fully implemented because it's in preview? Or is there another endpoint I should use to get this information? Thanks in advance for any help on this.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-26T18:18:41.777Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. Assuming you've created and deployed a managed online endpoint, you should be able to use the Online Endpoints - List api to list the online real-time endpoints. Here's additional resource. Please let me know if you have any further questions or concerns. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-02T13:39:50.723Z",
                "Answer_score":0,
                "Answer_body":"@GiftA-MSFT - the 'Online Endpoint - List' api is that one that i'm testing with, but getting an empty result set back, even though I do have a live endpoint. Would it have something to do with the fact I published using a Container Instance?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-25T10:19:21.203Z",
                "Answer_score":0,
                "Answer_body":"Any luck with this? I am experiencing the same issue (also deployed using a Container Instance). Thanks!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-26T09:35:01.187Z",
                "Answer_score":0,
                "Answer_body":"If they were deployed to a 'web service', they may instead be stored under the webService API instead.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-28T16:44:25.533Z",
                "Answer_score":0,
                "Answer_body":"Is this Issue resolved. I am facing same issue. this API call is returning empty list.\n\nhttps:\/\/management.azure.com\/subscriptions\/{subscriptionId}\/resourceGroups\/{resourceGroupName}\/providers\/Microsoft.MachineLearningServices\/workspaces\/{workspaceName}\/onlineEndpoints?api-version=2022-10-01-preview",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Data Labeling Data name",
        "Question_creation_time":1622641393617,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/419384\/data-labeling-data-name.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Is there a possibility to show the data name of an image while labeling?\nSo I mean in this step https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-labeling-projects\nIt would be much easier to choose the label if we know the data name",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-02T23:26:11.54Z",
                "Answer_score":0,
                "Answer_body":"Hi, there's no way to show the dataset name while labeling, it only shows the images. However, I'd be more than happy to share your feedback with the product team as a feature request.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-28T07:04:28.687Z",
                "Answer_score":0,
                "Answer_body":"Update: This is a supported feature now. whether allowing labeler to check the image name is controlled by the project owner.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"can I set budget for each model training session and then to pause the model training if the budget is crossed?",
        "Question_creation_time":1666811077247,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1064344\/can-i-set-budget-for-each-model-training-session-a.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hi Team,\n\nis it possible to control the budget for each training session in azure ML.\nLets say I am training a model and before starting the run, I want to set a budget of X dollars. and if it crosses, then my model training should pause unless I increase the budget to X+Y dollars.\n\nOnce the budget is increased, then only model training should resume. Is there any raw rest HTTP API or SDK options to control this?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Use a trained model for use cases (a new data set)",
        "Question_creation_time":1665310129110,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1040790\/use-a-trained-model-for-use-cases-a-new-data-set.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Dear all\n\nI conducted some experiments with Microsoft Azure automated ML and DESIGNER.\n\nAs far as I understand the given results, the trained model shows e.g. the accuracy? How well or in how many cases can the trained model predict the value (e.g. TRUE or FALSE) correctly?\n\nNow, I want to use the \"trained\" model(s) for use cases. My goal is to use the trained model(s) and provide predictions for new samples (a new data set). E.g. I want to predict the value \"TRUE\" or \"FALSE\" for the values of the new data set.\n\nIn my case, there is no value in the column (TRUE or FALSE). I want the model to provide me with the answers.\n\nNext steps: As far as I see, I need to deploy the model so that I can conduct the same experiments with new samples?\n\nOr how can I apply my trained model for the new use cases? (please see my description above)\n\nThank you for your feedback\n\nBest regards\n\nLukas",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-10T14:14:26.413Z",
                "Answer_score":0,
                "Answer_body":"@LukasBusers-1078 After you create a deployment, you can score it as described in Test the endpoint with sample data.\nAre you facing any error, if yes please add the error details.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-26T14:46:01.66Z",
                "Answer_score":0,
                "Answer_body":"Tutorial Overview\nThis tutorial is divided into three parts; they are:\n\nPrepare a Training Dataset\nHow to Fit a Model on the Training Dataset\nHow to Connect Predictions With Inputs to the Model\n2. Prepare a Training Dataset\nLet\u2019s start off by defining a dataset that we can use with our model.\n\nYou may have your own dataset in a CSV file or in a NumPy array in memory.\n\nIn this case, we will use a simple two-class or binary classification problem with two numerical input variables.\n\nInputs: Two numerical input variables:\nOutputs: A class label as either a 0 or 1.\nWe can use the make_blobs() scikit-learn function to create this dataset with 1,000 examples.\n\nThe example below creates the dataset with separate arrays for the input (X) and outputs (y).",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML - Is there a way to prevent registering an Environment when deploying locally?",
        "Question_creation_time":1665427554937,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1042597\/azure-ml-is-there-a-way-to-prevent-registering-an.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi, we're trying to separate environment registration from deployment scripts so we have created two py files. This is a very simple example of the first one, which is actually registering the environment as desired.\n\n import argparse\n import logging\n    \n from azureml.core import Workspace\n from azureml.core.environment import Environment\n    \n import azure_config\n    \n '''\n This script registers an environment in Azure ML Studio.\n Usage:\n     # Deploy a local webservice for testing\n     python register_env-rm.py -m department\n '''\n    \n # Set up logging\n logging.basicConfig(level=logging.INFO)\n logger = logging.getLogger()\n logger.setLevel(logging.INFO)\n    \n def register_env(test_name: str):\n     '''\n     Registers an environment if one of the same version OR specs doesnt already exist.\n     '''\n     # Create instance of workspace\n     ws = Workspace.get(\n         name=azure_config.WORKSPACE_NAME,\n         subscription_id=azure_config.SUBSCRIPTION_ID,\n         resource_group=azure_config.RESOURCE_GROUP\n     )\n        \n     # Create an instance of the Environment based on the given specs\n     myenv = Environment(name=test_name)\n    \n     # Register Environment\n     myenv.register(workspace=ws)\n     myenv.python.conda_dependencies = CondaDependencies.create(\n             pip_packages=[\"fasttext==0.9.2\"]\n             )\n     logger.info(\"New env registered\")\n    \n if __name__ == \"__main__\":\n     parser = argparse.ArgumentParser(description='Registers an environment in Azure ML Studio')\n     parser.add_argument(\n         \"-m\",\n         \"--test-name\",\n         help=\"Name of test\",\n         required=True,\n         default=None,\n         type=str)\n        \n     args = parser.parse_args()\n     test_name = args.test_name\n    \n     register_env(test_name)\n\nThen, here's another simple example of the script that will use to deploy our model. Since we're detecting that a new environment is being registered when deploying locally after the one that we've explicitly registered (running the script above), I'm just including that part of the deployment.\n\n import argparse\n import json\n import logging\n    \n from azureml.core import Workspace\n from azureml.core.environment import Environment\n from azureml.core.model import InferenceConfig, Model\n from azureml.core.webservice import LocalWebservice\n    \n import azure_config\n    \n '''\n This script reproduces the bug where Model.deploy registers an environment.\n '''\n    \n # Set up logging\n logging.basicConfig(level=logging.INFO)\n logger = logging.getLogger()\n logger.setLevel(logging.INFO)\n    \n def test_dup_envs(test_name: str):\n    \n     # Create instance of workspace\n     ws = Workspace.get(\n         name=azure_config.WORKSPACE_NAME,\n         subscription_id=azure_config.SUBSCRIPTION_ID,\n         resource_group=azure_config.RESOURCE_GROUP\n     )\n        \n     # Load model if exists\n     model = Model(\n         ws,\n         name='mymodel', \n         version=1\n     )\n    \n     # Get a newly registered env\n     env = Environment.get(\n             workspace=ws, \n             name=test_name, \n             version='1')\n        \n     logger.info(f\"Env object: {env}\")\n    \n     # Create inference config\n     inference_config = InferenceConfig(\n         entry_script='score.py', \n         source_directory='mysourcedir',\n         environment=env)\n    \n     # Deploy service locally\n     local_dep_config = LocalWebservice.deploy_configuration(port=6789)\n    \n     service = Model.deploy(\n         workspace=ws, \n         name=test_name, \n         models=[model], \n         inference_config=inference_config, \n         deployment_config=local_dep_config\n         )\n    \n     service.wait_for_deployment(show_output=True)\n     logger.info(service.get_logs())\n    \n    \n if __name__ == \"__main__\":\n     parser = argparse.ArgumentParser(description='Reproduces the duplicate env bug')\n     parser.add_argument(\n         \"-m\",\n         \"--test-name\",\n         help=\"Name of test to deploy\",\n         required=True,\n         default=None,\n         type=str)\n    \n     args = parser.parse_args()\n        \n     test_name = args.test_name\n    \n     test_dup_envs(test_name)\n\nIs there a way to prevent that? Although we believe this might no impact predictions, we wouldn't like to have many versions of the same environment being registered.\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-18T14:36:30.37Z",
                "Answer_score":0,
                "Answer_body":"@RodrigoMaldonado-2494 Thanks for the details. we can simply register it to be able to use it when necessary.my_spark_env.register(workspace). To get this environment we can use Environment.get from azureml-sdk as well, so we can get the frozen environment to reuse it when it's being defined the Inference Config in the deployment process.\n\n\n\n  from azureml.core.environment import Environment\n     from azureml.core.model import InferenceConfig\n        \n     my_spark_env = Environment.get(name='spark-env-custom', workspace=workspace)\n        \n     inference_config = InferenceConfig(entry_script=\"<YOUR-ENTRY-SCRIPT>\", environment=my_spark_env)",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Invitation to join Microsoft Community Champions Program - Azure",
        "Question_creation_time":1660030627450,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/960307\/invitation-to-join-microsoft-community-champions-p.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":7,
        "Question_comment_count":5,
        "Question_follower_count":112,
        "Question_score":11,
        "Question_body":"Are you a Microsoft Azure Technology Expert? Do you resonate with the idea of using your skills to help customers, create Impact and also get recognized?\n\nIf your answer is yes \u2013 you have an opportunity to be part of the Microsoft Azure Community Champions family! This is a thriving community of 100+ members made of Microsoft employees, MVPs, Suppliers, and other experts who enjoy solving latest customer problems in Microsoft Q&A technical site and thereby learn hands-on.\n\nFor your voluntary contributions you can also receive exciting rewards and recognitions which includes monthly $50 gift cards, being featured on Microsoft branded social media & leaderboards, considerations for Microsoft MVP award, Microsoft NDA with Private Preview access and more.\n\nVisit Microsoft Community Champions for Q&A | Microsoft Docs to learn more and become an Azure Community Champion!\n\nSee you on the other side!!\n\nSpecial invitation to:\n\n@carlzhao-msft @TchimwaSougang-3249 @LiHongMSFT-3908 @MarkBrownMSFT @LuDaiMSFT-0289 @dominicbetts @SujithreddyKomma-8764 @BertZhoumsft-7490 @ZehuiYaoMSFT-7151 @SeeyaXi-msft @VickyKumarMindtreeConsultingPVTLTD-5545 @chbeier @JasonPan-MSFT @OlafHelper-2800 @AzureAaronHughes @lukemurraynz @sadomovalex @NaomiNNN @EricBoyd @sql-articles @JingyangLi @MOXiMOX-2301 @msfthiker @NewbieJones-6218 @Viorel-1 @clivewatson-9831 @RichMatheisen-8856 @Chungsun-1776 @JamesLongworth @kaaven @MotoX80 @RishabhMishra-9205 @rkiss @SrikanthRana @67603284 @AkashChopra-0052 @JimmySalian-2011 @AgaveJoe @Yufeishao-0810 @ZoeHui @Jason-MSFT @Sheena-MSFT @Bruce-SqlWork @martinta @LynnNiu-5125\n\nThank You to all the Microsoft Q&A Community Champions.\nThey are helping make Microsoft Q&A a vibrant place for learning.\n\n@AlbertoMorillo @soysoliscarlos @ricardosolisvillegas-4678 @AlanKinane @ManuPhilip @NandanHegde-7720 @AndrewBlumhardt-1137 @sikumars @PratikSomaiya @TakahitoIwasa @DavidBroggy-5270 @KamleshKumar @AndreasBaumgarten @michev @AndyDavid @SandervandeVelde42 @BrunoLucas-9843 @shivapatpi-MSFT @DillonJS @martins-jackson @SubashriVasudevan-1752 @Samy-7940 @pituach @AndriyBilous @stan @CristianSPIRIDON72 @DSPatrick @nasreen-akter @Sam-Cogan @rbrundritt @BjoernPeters @ErlandSommarskog @sreejukg @msrini-MSFT @VidyaNarasimhan-2409 @SudiptaChakraborty-1767 @ZollnerD @cooldadtx @AlistairRoss-msft @MarkKromer-MSFT @ScottAzureRTOS @maserg @Dev073 @nhcloud @TomPhillips-1744 @IoTGirl @JaliyaUdagedara @JohndeuMSFT @PradeepKommaraju-MSFT @MatthijsvdVeer @HasanSavran-7728 @VinodKumar-0434 @AliSufyan-1625 @CdricPerion-5162 @learn2skills @VineetKumarGupta-6574 @Vinodh247-1375 @Thameur-BOURBITA @kashyapa @PierreLucGiguere-5297 @DanGuzman @derhoppe @MartinCairney-6481 @piaudonn @yagmoth555 @eepyaich @GeorgeChrysovalantisGrammatikos-8518 @KenMaxwell-4349 @RahulJindal-2267 @SubbuKonathala @VaibhavChaudhari @vukasinterzic @GeorgeMoise-0315 @YugandharMunagala-MSFT @arnavsharma @MatthewBrowne-7065 @pvanberlo @Saggiehaim @SaiGunaranjan @GlenScales-6756 @jasjitchopra @RahulTherayil @ShamirCharania-2101 @Yuvaraj-MSFT @abhishekshaha @adiazcan @damianoandresini @demiliani @hugobarona @jloudon @Joecarlyle @JoseBenjaminSolisNolasco-2402 @JuanSobrado-3258 @mgessenay @oscarmh @RyanJohnson-MSFT @Sean-Liming @sqlarcher @SruthiSaranyaKarthikeyan-7489 @StoyanChalakov @VigneshSukumar-0037 @MohammedAltamashKhan-3285 @LuisRodriguez-MSFT",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-09T08:21:01.273Z",
                "Answer_score":0,
                "Answer_body":"Thanks for the invitation - happy to help ;-)",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-08-10T02:55:34.273Z",
                "Answer_score":0,
                "Answer_body":"Thanks for the invitation\nI'm happy to help",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-08-10T05:00:55.343Z",
                "Answer_score":0,
                "Answer_body":"Thanks for the Invite\nHappy to get in",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-08-16T06:27:37.377Z",
                "Answer_score":0,
                "Answer_body":"Happy to Part of this.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-08-19T14:02:03.447Z",
                "Answer_score":0,
                "Answer_body":"The thing is, am now part of the ITS GREATNESS, AZURE TEAM ready to instill Azure in them\/me\/us, haha Thanks for the inv!!!!",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-09-10T12:17:26.737Z",
                "Answer_score":0,
                "Answer_body":"@tbgangav-MSFT\nThank you for the invitation. it's pleasure to be part of you and share my knowledge in this forum.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-26T12:02:05.217Z",
                "Answer_score":0,
                "Answer_body":"Very happy to be here! All the best!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How do I fix the ImportError: cannot import name 'delayed'?",
        "Question_creation_time":1664630157437,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1031590\/how-do-i-fix-the-importerror-cannot-import-name-39.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I am using the LORAS package from pyloras for imbalanced learning, but it requires importing the delayed package. I used the pip.main() to install the delayed package and from delayed.delay imported delayed. However, I am still getting the following error: ImportError: cannot import name 'delayed'. I appreciate your help and suggestions.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-10T05:07:54.997Z",
                "Answer_score":1,
                "Answer_body":"You cannot import a custom environment in execute python script. You can install some packages with execute python script, but it has limitations on packages that can be installed depending on the number of dependencies of the package. Glad you can use the notebook and work on your experiments now.\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Integrate Azure ML Studio with Azure DevOps repo",
        "Question_creation_time":1666021308520,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1051117\/integrate-azure-ml-studio-with-azure-devops-repo.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hello,\n\nI am working with Azure Machine Learning Studio via GUI (upload dataset, run experiments, register ML models, register endpoints, develop code in notebooks, ...) and would like to have that code available in Azure DevOps repo in order to restore it if necessary.\n\nDoes anyone know how that integration between Azure ML Studio and Azure DevOps repo could be done?\n\nThanks,",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-17T20:52:43.673Z",
                "Answer_score":0,
                "Answer_body":"Hi, @PedroGonzalez-2046\n\nI checked the documentation of Azure Machine Learning Studio, but it seems that there is no integration function with the version control system.\n\nYou can download the created model code by referring to the following questions.\n\nhttps:\/\/learn.microsoft.com\/en-us\/answers\/questions\/355882\/azure-ml-studio-and-gitazuredevops.html\n\nBy applying this to build a regular batch mechanism, you can periodically acquire the latest model on ML Studio with code and reflect it in Git management.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-18T10:02:33.74Z",
                "Answer_score":0,
                "Answer_body":"@PedroGonzalez-2046 You can use MLOps to setup Azure ML pipelines and experiments with Azure DevOps. A good working sample is available in the MLOpsPython repo. The setup should be straightforward where any changes in your pipeline code will trigger a job in your Azure ML workspace.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":5,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to get the probability\/score by each cell\/row with machine learning?",
        "Question_creation_time":1666667585287,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1061214\/how-to-get-the-probabilityscore-by-each-cellrow-wi.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":33,
        "Question_score":0,
        "Question_body":"I have go through the solution in the forum but couldn't find a suitable solution for my question.\nI have use machine learning model to get the best algo for data modelling.\nI manage to get the confusion table but somehow i looking for probability\/scoring for each cell instead of overall result.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-26T08:03:28.34Z",
                "Answer_score":0,
                "Answer_body":"Below is my coding for Program.cs:\n\nstatic void Main(string[] args)\n{\n\/\/testing file location\nstring filepath = @\"C:\\Users\\Desktop\\Validation_Dataset - ColumnRename.csv\";\n\n\n\n         CsvConfiguration config = new CsvConfiguration(CultureInfo.InvariantCulture)\n         {\n             PrepareHeaderForMatch = args => args.Header.ToLower(),\n             MissingFieldFound = null\n         };\n         int correct = 0;\n         int total = 0;\n         using (var reader = new StreamReader(filepath))\n         using (var csv = new CsvReader(reader, config))\n         {\n             csv.Context.RegisterClassMap<PredictionDetailPredictMap>();\n             var records = csv.GetRecords<TrainTest.MLModel1.ModelInput>();\n             StringBuilder sb = new StringBuilder();\n             sb.Append(\"No,Expected,Predicted,IsMatch\");\n             sb.AppendLine();\n             foreach (var record in records)\n             {\n                 try\n                 {\n                     if (record.GB == \"0\") continue;\n                     total++;\n                     var result = TrainTest.MLModel1.Predict(record);\n                     Console.WriteLine(record.No);\n                     Console.WriteLine(\"Expected:\" + record.GB);\n                     Console.WriteLine(\"Predicted:\" + result.PredictedLabel);\n                     Console.WriteLine(\"====================\");\n                     \/\/if (record.BinRootCause.ToLower() == result.Prediction.ToLower()) correct++;\n                     string isMatch = record.GB.ToLower() == result.PredictedLabel.ToLower() ? \"YES\" : \"NO\";\n                     if (isMatch == \"YES\") correct++;\n                     sb.Append(record.No + \",\"  + record.GB + \",\" + result.PredictedLabel + \",\" + isMatch + \",\");\n                     sb.AppendLine();\n                 }\n                 catch (Exception ex)\n                 {\n                     \/\/store output file path\n                     Console.WriteLine(ex.Message);\n                     File.WriteAllText(@\"C:\\Desktop\\Result\\Testing.csv\", sb.ToString());\n                 }\n             }\n             sb.Append(\"Accuracy =\" + ((float)correct \/ (float)total) * 100 + \"%\");\n             File.WriteAllText(@\"C:\\Desktop\\Result\\Testing.csv\", sb.ToString());\n             Console.WriteLine(\"Accuracy=\" + ((float)correct \/ (float)total) * 100 + \"%\");\n         }\n     }\n\n\n\n\n\n\nHere is my sample output:\n\n\n\n\n\nI looking for each cell\/row have probability behind, for example:\n\n\n\n\n\n\n\n\nDo you know how to get the probability for each prediction result?\nThanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Generating scoring.py for azure ml model deployment",
        "Question_creation_time":1642499410857,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/699403\/generating-scoringpy-for-azure-ml-model-deployment.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":17,
        "Question_score":1,
        "Question_body":"Hi,\nI have registered a pretrained model to azure ml and i wish to deploy the model.\nThere is a compulsory file attachment called scoring file that i need to attach in order to deploy my model.\nMay i know how do i generate this scoring.py file?\nThanks in advance",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-18T17:38:53.153Z",
                "Answer_score":0,
                "Answer_body":"@Yuzu-9670\n\nHello,\n\nThanks for reaching out to us. Please follow below documentation to define your entry script after you registered your model.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=azcli#define-a-dummy-entry-script\n\nPlease start with define a dummy entry and do the steps after.\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-26T04:53:39.51Z",
                "Answer_score":0,
                "Answer_body":"See this link:\nhttps:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-managed-online-endpoints?tabs=azure-cli#understand-the-scoring-script\n\nSee this other thread as well:\nhttps:\/\/learn.microsoft.com\/en-us\/answers\/questions\/713048\/azure-ml-how-should-my-score-script-look-like-to-d.html\n\nIn my case, using Automated ML, I was able to download the scoring script by clicking on the model (yolov5 in my case) then clicking download\n@IamBeginner-6521",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"\"Cold-start\" problem in Azure Recommender",
        "Question_creation_time":1623136695973,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/426312\/34cold-start34-problem-in-azure-recommender.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi, I've trained and deployed an Azure Wide & Deep Recommender in the Designer tab of the Machine learning workspace.\nI have 3 datasets:\n\nRatings\n\n\nUser features\n\n\nItem features\n\nThe recommendation system works fine for existing user IDs available in User Features and Rating datasets.\nHowever, when a want to make a prediction for a new user to the system, which IDs were not used during training, I get an error.\n\nIs that expected that the recommendations are made only for users that the model learned during training? If not, please help me resolve this issue, so that even \"cold\" users can receive recommendations.\n\nThe model training and real-time inference pipelines are attached. Also, included the deployment logs with errors when sending a request to the model to make recommendations for new users.\n\n103326-ci-error-logs-recommender-system.txt\n\n\n\n\n\n\n\nThanks!",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Can't pull ACR image in compute instance of Azure Machine Learning Workspace: VNetPLSetupError",
        "Question_creation_time":1666098594973,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1052833\/can39t-pull-acr-image-in-compute-instance-of-azure.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"When I deployed a training job to a compute instance it fails with the following error:\n\nAzureMLCompute job failed.\nVNetPLSetupError: Failed to pull Docker image xxxxxxxxxxx.azurecr.io\/azureml\/azureml_f306f67d2a96fc883ff0773a2a01394e with authentication mode IdentityToken due to: Docker responded with status code 500: {\"message\":\"Head \\\"https:\/\/xxxxxxxxxx.azurecr.io\/v2\/azureml\/azureml_f306f67d2a96fc883ff0773a2a01394e\/manifests\/latest\\\": Post \\\"https:\/\/xxxxxxxx.azurecr.io\/oauth2\/token\\\": net\/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)\"}\n. This error may be caused by a Deny outgoing rule to Container Registry or AzureFrontDoor service tag, or a missing Allow outgoing rule to the same, which is blocking access to container registry xxxxxxxxxx.azurecr.io\n\nIt suddenly stopped working after it pulled without problems before.\nI can build and push an image, but not pull anymore.\n\nI checked the NSG that is associated with this ML workspace, but it has no outbound rules that could prevent the pull (push works as mentioned). There is no AzureFrontDoor tag configured.\n\nDid anyone come across this 'VNetPLSetupError' error?\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-21T13:07:49.777Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nits not enabled. Interestingly the error suddenly disappeared. Not sure what caused it, but I had this error only for a couple of days. There was no change to the infrastructure.\n\nThanks for responding.\n\nBest, Andrej",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Register Data Sets in Azure ML",
        "Question_creation_time":1665561633607,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1044629\/register-data-sets-in-azure-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hello dear Microsoft Q&A Team,\n\nI'm new to Azure ML and have the following problem: I can't create data assets using a datastore. I did the following:\n\nI created a datastore which points on my adls gen2 datalake using a service principal. I assigend all Storage Blob Data rolls (of the ressource group of the datalake) to this service principal. But when I try to create a dataset using this datastore the storage path does not load:\n\nAny idea what I'm doing wrong?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-21T07:48:19.023Z",
                "Answer_score":0,
                "Answer_body":"Hello @romungi-MSFT ,\n\nno worries. I was able to create a data set, but had to enter the file path manually:\n\n\n\n\n\nFor me it is fine, but I think it still not working the way it should be.\n\nCheers\n\nLukas",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"ray+dask native support be added to Azure Machine Learning",
        "Question_creation_time":1666227934133,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1055350\/raydask-native-support-be-added-to-azure-machine-l.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"While distributed dask can be setup manually on AML compute, the process requires lot of configs to be maintained. Is there any native support.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-20T11:44:42.8Z",
                "Answer_score":0,
                "Answer_body":"@Divya-0887 Thanks for the question. you can do is to setup the compute cluster & compute instance in the same vnet and pip install ray-on-aml. This allows both interactive and job use of Ray and Dask right within Azure ML.\n\nHere is the document Library to turn Azure ML Compute into Ray and Dask cluster.\nhttps:\/\/techcommunity.microsoft.com\/t5\/ai-machine-learning-blog\/library-to-turn-azure-ml-compute-into-ray-and-dask-cluster\/ba-p\/3048784",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Not enough quota available when deploying a machine learning model on Azure",
        "Question_creation_time":1666148560563,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1053752\/not-enough-quota-available-when-deploying-a-machin.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I was trying to deploy and score a machine learning model by using an online endpoint.\n\nWhen I was trying to run code this on Azure Machine Learning Wordspace,\n\n !az ml online-deployment create --name fraud-ga --endpoint endpoint-name -f ..\/deployment\/deployment.yml --all-traffic\n\n\n\nI got this error:\n\n {\"errors\":{\"VmSize\":[\"Not enough quota available for Standard_F16s_v2 in SubscriptionId 671ef6e1-2ded-466b-8fd1-91363cf12275. Current usage\/limit: 4\/6. Additional needed: 32 Please see troubleshooting guide, available here: https:\/\/aka.ms\/oe-tsg#error-outofquota\"]},\"type\":\"https:\/\/tools.ietf.org\/html\/rfc7231#section-6.5.1\",\"title\":\"One or more validation errors occurred.\",\"status\":400,\"traceId\":\"00-a308e99ddee5fc8714e34fd0808b7e93-2031400dbc3e84d1-01\"}\n\n\n\n\nWhat I understood is that I need more cores.\n\nSo, in this case how many cores I needed and how to solve this error?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-19T04:02:03.51Z",
                "Answer_score":1,
                "Answer_body":"It sounds like you don't have enough quota available in the region where you are trying to deploy the ML model.\nIn Azure portal, you can check the allocated quota for each region under the subscription blade:\n\nThe error message says: Current usage\/limit: 4\/6. Additional needed: 32\n\nRequest a quota increase and Azure support team can help on that!\n\n\n\n\n\n\n--please don't forget to upvote and Accept as answer if the reply is helpful--",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Is it possible to add\/modify AKS pod's labels when using Azure ML model deployment V2?",
        "Question_creation_time":1666100120170,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1052819\/is-it-possible-to-addmodify-aks-pod39s-labels-when.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hey!\n\nI am deploying model to AKS by using model deployment V2.\n\nWhen deployment is succeeding, I can see from created pod in AKS, that it contains certain labels, like:\n\nml.azure.com\/compute: ***\nml.azure.com\/deployment-name: ***\nml.azure.com\/endpoint-name: ***\nml.azure.com\/resource-group: ***\nml.azure.com\/scrape-metrics: 'true'\nml.azure.com\/subscription-id: ***\nml.azure.com\/workspace: ***\n\nMany of these are very clear, but where ml.azure.com\/scrape-metrics: 'true' comes from? Can I modify these labels or create new ones somehow in the deployment.yaml?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure OpenAI advantages",
        "Question_creation_time":1648125540293,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/785866\/azure-openai-advantages.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"We have a customer that is interested in the Azure OpenAI Service and had a few question:\n\nWhat are the advantages for using Azure OpenAI vs. OpenAI API.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-24T14:21:38.047Z",
                "Answer_score":0,
                "Answer_body":"@App-4824 Thanks for the question. The Azure OpenAI team always works to make the latest models available in Azure as soon as they are available from OpenAI. This is an active area of work for the team to tighten release date for future models.\nThe Azure service is backed by an SLA (which typically a customer's primary need for high availability, low latency), and the support that comes along with Azure services. This is the first commercialized model of its kind from any public cloud provider. This is unique advantage to be first to market and to work closely with customer to adopt\/embrace these models for production use.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How to use Azure ML Design ML Algorithms and Anomaly Detection in notebook?",
        "Question_creation_time":1665342567200,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1041081\/how-to-use-azure-ml-design-ml-algorithms-and-anoma.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I am using Azure ML notebook to build and test a PCA-based anomaly detection model. The Azure ML Designer contains ML algorithms and anomaly detection methods. How can I reuse these Designer components in Azure notebook?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-11T03:27:34.187Z",
                "Answer_score":1,
                "Answer_body":"@Ghada-9640 Thanks for the question. Once you have trained in the designer you can Download the entry script file and conda dependencies file from the designer and use in the notebook.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"getting error -> does not support the API version '2022-05-01' while making query for arm using CURL",
        "Question_creation_time":1665747402973,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1048385\/getting-error-gt-does-not-support-the-api-version.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":22,
        "Question_score":0,
        "Question_body":"I am trying to get the AML token using CLI.\nI am able to get the token using the command -> token=$(az account get-access-token --subscription {subscri ID} --resource-type arm --query accessToken --output tsv)\n\nbut when I use this token to get the AMLToken I get below error, however it is working fine if I make this query using postman :\ncurl -d POST --header \"Authorization: Bearer $token\" \"https:\/\/management.azure.com\/subscriptions\/{subcri id}\/resourceGroups\/{res_grup}\/providers\/Microsoft.MachineLearningServices\/workspaces\/{workspace}\/onlineEndpoints\/{endpoint}\/token?api-version=2022-05-01\"\n\nany helps or pointers please, why I am getting this error? Not able to find any documentation for it.\n\nError which I am getting is this->\n\n{\n\"error\": {\n\"code\": \"UnsupportedApiVersion\",\n\"message\": \"The HTTP resource that matches the request URI 'https:\/\/cert-eastus2.experiments.azureml.net\/mferp\/managementfrontend\/subscriptions\/{sub_id}\/resourceGroups\/{r_group}\/providers\/Microsoft.MachineLearningServices\/workspaces\/{workspace}\/onlineEndpoints\/{endpoint}\/token' does not support the API version '2022-05-01'.\",\n\"innerError\": null\n}\n}",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-15T08:55:59.363Z",
                "Answer_score":0,
                "Answer_body":"Hello @JA-9673\n\nThanks for reaching out to us. I have seen a similar issue posted here, the reason for the issue is caused by using pip to install Azure CLI. Please check on below solution for this issue and let me know if that works for you or not. - https:\/\/github.com\/Azure\/azure-cli\/issues\/23821\n\nThe reason for this issue is https:\/\/aka.ms\/InstallAzureCLIDeb installs Azure CLI DEB package at \/opt\/az, but your Azure CLI was installed with pip judging by the installation location: \/usr\/local\/lib\/python3.8\/site-packages\/azure\/cli\n\nWe recommend installing the Azure CLI DEB package, but if you have to use pip, we recommend installing to a virtual environment. See #20476 (comment) - https:\/\/github.com\/Azure\/azure-cli\/issues\/20476#issuecomment-1007131837.\n\nPlease be aware that installing from pip is not officially supported.\n\nI hope this helps.\n\n\n\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the conmunity, thanks a lot.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How is Data Drift Magnitude and Data Drift Contribution of each feature calculated in Azure Machine Learning (Azure ML)?",
        "Question_creation_time":1646758413733,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/764042\/how-is-data-drift-magnitude-and-data-drift-contrib.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":10,
        "Question_score":1,
        "Question_body":"On https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-monitor-datasets?tabs=python,\n\nit says :\n\nData drift magnitude:\nA percentage of drift between the baseline and target dataset over time. Ranging from 0 to 100, 0 indicates identical datasets and 100 indicates the Azure Machine Learning data drift model can completely tell the two datasets apart. Noise in the precise percentage measured is expected due to machine learning techniques being used to generate this magnitude.\n\nTop drifting features:\nShows the features from the dataset that have drifted the most and are therefore contributing the most to the Drift Magnitude metric. Due to covariate shift, the underlying distribution of a feature does not necessarily need to change to have relatively high feature importance.\n\nMy questions are:\n\nHow is data drift magnitude calculated?\n\n\nHow is the data drift contribution of each feature calculated?\n\n\nIn the documentation, there are cases where the Wasserstein distance is low, yet the contribution of the feature is significant. Could you please clarify why that is the case?\n\nThank you in advance!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-31T08:51:43.177Z",
                "Answer_score":0,
                "Answer_body":"@DavidZ-4323 Thanks, For internal product details please share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Total Regional Cores quota error",
        "Question_creation_time":1665265961547,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1040655\/total-regional-cores-quota-error.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":1,
        "Question_body":"Dear all\nI have a free Microsoft Azure student account. I am using Microsoft Azure automated ML and DESIGNER.\nI tried to deploy my model, which I created in DESIGNER.\nFor that, I need to create Compute, Inference clusters. When I do so, I always receive an error message: \"Operational could not be completed as it results in exceeding approved Total Regional Cores quota\". I tested various options, but all failed. I always chose Switzerland North, as it is the closest.\nIn addition, I constructed a new resource group. However, this did not make any difference.\nI read something about altering the Subscription (Azure for Students). However, then I'm not sure if I have to pay for the upgrade?\n\nMay you can tell me how it works with \"Azure for students\" when I want to deploy my model? How can I build a Compute, Inference clusters?\n\nThank you for your feedback.\n\nBest regards\n\nLukas",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-08T22:14:01.357Z",
                "Answer_score":1,
                "Answer_body":"Hi @LukasBusers-1078 ,\n\neach Azure subscription has is quotas for different Azure services.\nDepending on the type of Azure subscription it is a hard hard quota limit, for instance for Free Trial subscriptions.\nhttps:\/\/learn.microsoft.com\/en-us\/azure\/azure-resource-manager\/management\/azure-subscription-service-limits#managing-limits\n\nYou an get the details of the usage and the quotas in the Azure Portal for each subscription:\n\nFor vCPUs for Azure Compute resources there are quotas per region in Total and per VM SKU.\nFor instance Total Regional vCPUs = 20\nFor each VM Series (e.g. Ev3 Series\/Family) = 20\nYou have to take care for both quotas, the Total and the VM Family quota per region, as they are working together and related to each other.\n\nDepending on the type of Azure Subscription and the Azure Resource you could increase the quota by yourself or via Azure Support.\nI have no Azure for Students subscription. So I am not able to give you an answer about the costs. But you should be able to get the information which Azure resources are included in the Azure Students subscription and which resources are charged in addition.\nhttps:\/\/azure.microsoft.com\/en-gb\/offers\/ms-azr-0170p\/\n\n(If the reply was helpful please don't forget to upvote and\/or accept as answer, thank you)\n\nRegards\nAndreas Baumgarten",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-09T09:44:44.14Z",
                "Answer_score":0,
                "Answer_body":"Thank you for your feedback.\nWhen I chose \"user settings\", I receive following answer: No access",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"which role to assign to a user to prevent him from accessing an ML scoring endpoint",
        "Question_creation_time":1665639362440,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1046043\/which-role-to-assign-to-a-user-to-prevent-him-from.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":16,
        "Question_score":0,
        "Question_body":"I have users who have contributor access for a subscription, so what I understand from this is that they would have all the access to the resource groups, resources except granting user access.\nNow, I have ML endpoints created in a ML workspace.\nWorkspace also by default inherit the access for all user as contributor which means they will be able to access the scoring endpoints.\nNow, I want to prevent users from accessing few endpoints in the workspace.\nSo, how I can achieve this narrow access when they already inherit broader access from subscription.\nWhich access should I give to user on endpoint? will the \"reader\" role prevent a user from accessing the endpoint?\nI am not able to understand this very clearly from microsoft documentation so clear pointers would help here.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-13T10:53:18.243Z",
                "Answer_score":0,
                "Answer_body":"@JA-9673 I believe you would like to restrict access to users to ensure they do not modify or delete the endpoint right?\nIn this case you could add a custom role for read actions for the workspace or add a NotActions list to disable delete or write actions. This page in the documentation should help to identify the roles that need to added under NotActions.\n\nYou could also identify the roles available under Microsoft.MachineLearningService using the following CLI command and use the name field of all the write\/delete actions in the NotActions list of your custom role.\n\n az provider operation show \u2013n Microsoft.MachineLearningServices",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Pepiline data not showing anything",
        "Question_creation_time":1665577767170,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1045134\/azure-pepiline-data-not-showing-anything.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I'm following the https:\/\/microsoftlearning.github.io\/AI-900-AIFundamentals\/instructions\/02a-create-regression-model.html exercise from the Azure IA-900 tutorial. In the Pepiline Assert Library Data Search is not showing anything, the Automobile price data (Raw) is not being found. ![249725-azure-pepiline.png][1] [1]: \/answers\/storage\/attachments\/249725-azure-pepiline.png",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-12T23:05:04.233Z",
                "Answer_score":0,
                "Answer_body":"Hello anonymous user\n\nThanks for using Microsoft Q&A platform, I think there is somethng wrong with the Learn page, you can find the Automobile price data (Raw) in component but not data as below screenshot:\n\nYou can click Component -> Sample data - > scroll down and you can find it\n\nOr you can search it in Component directly.\n\nI will reach out to the author of this tutorial to fix the issue. I hope this helps! Let us know if you still have problem for this.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AzureML Scoring Script fails with ImportError: no known parent package",
        "Question_creation_time":1603969996160,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/144492\/azureml-scoring-script-fails-with-importerror-no-k.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"On trying to deploy a Model as a Container, endpoint gets created, however, scoring script fails with an error:\n\nImportError: attempted relative import with no known parent package\n\n\n\n\n\nThis is because i'm referencing another module (packaged in the docker image using source_directory) with a relative path from scoring file.\n\nCan you help me in resolving this error?\n\nFiles\\modules structure (a simplified version):\n\nproject\n->src\n-> scoring.py\n-> module1.py\n-> common\n-> module2.py, etc\n-> init.py\n-> init.py\n-> configs\n-> conda_env.yml\n\nIn scoring.py,\nfrom .module1.py import SomeClass\n..\n..\n\nIn module1.py,\nfrom .common.module2.py importSC2\n...\n..\n\n\n\n\n\nAnd below is how an Inference config is initialized:\ninference_config = InferenceConfig(source_directory=\".\/\",\nruntime= \"python\",\nentry_script=\"src\/scoring.py\",\nconda_file=\"configs\/conda_env.yml\"\n)\n\n\n\n\n\nI could not pass entry_script as \"src.scoring\" as this fails the Validation and relative path to scoring file is expected",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-29T16:20:54.573Z",
                "Answer_score":0,
                "Answer_body":"@SunilSinghal-3380 Thanks for the question. When deploying your inference script, beyond the entry script (score.py), inferenceConfig also let you specify source directory that include the entry script as well as all other python code (packages as a subfolder in the source directory that has its own init.py, or plain python script files modules). The score.py script can directly import from them because the whole folder including score.py and all other folders will be available at the inference running environment. There is no need to save them as a \"model\".\nhttps:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.model.inferenceconfig?view=azure-ml-py\n\nFull sample available at https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/deployment\/deploy-to-cloud\/model-register-and-deploy.ipynb",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-11-02T10:44:15.697Z",
                "Answer_score":0,
                "Answer_body":"@SunilSinghal-3380 Thanks for the details. When you specify a source directory and a path(relative to the source_directory) to entry script, and if your deployment is failing, most likely the issue is with how you entry_script references other files in the source_directory. register-model-deploy-local-advanced.ipynb has an example of how to specify source directory and perform a local deployment for faster troubleshooting.\n\nHow to deploy using environments can be found here model-register-and-deploy.ipynb . InferenceConfig class accepts source_directory and entry_script parameters, where source_directory is a path to the folder that contains all files(score.py and any other additional files) to create the image.\nThis multi-model-register-and-deploy.ipynb has code snippets on how to create InferenceConfig with source_directory and entry_script.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-12T17:44:52.173Z",
                "Answer_score":0,
                "Answer_body":"Hi, I am having the same issue. Could you please direct me to the right resource from where I can get some insight to solve my issue. I have a trained model file which also includes some supported py module files. The tree is shown below:\n\nmodel --> conf --> hmcn.json\n--> data --> (some other required json files)\n--> dataset --> init.py\n--> classification_dataset.py\n--> collator.py\n--> data_preprocessor.py\n--> dataset.py\n--> model --> (some other .py module files)\n--> config.py\n--> HMCN\n--> util.py\n\nIn the above tree HMCN is the model file and as shown there are some python module files which are imported in the score.py (not included in this tree) script for inferencing. I was using the AZURE Web UI and registered the model by selecting the \"model\" directory so that in the artifacts tab the root item is shown as \"model\" and inside the model there are all the files shown in the tree are uploaded.\n\nNow I am trying to create an endpoint and deploy the model by using a \"score.py\" script for real-time inferencing. I did it with the WebUI by going to Endpoints --> Create deployment and in the Environment I selected score.py and choose PyTorch 1.9 curated environment but the during deployment the process fails and gives error that the module not found in the \"score.py\". The module that it is referring is in the \"config.py\" as shown in the model tree. I believe I need to set the path of the model tree so that the \"score.py\" can find the module. But I do now know how.\n\nYour help would be greatly appreciated. Thanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Machine learning model retraining on Azure Devops",
        "Question_creation_time":1665464342207,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1042999\/machine-learning-model-retraining-on-azure-devops.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I am building a pipeline Azure Devops. The model is in a .py file which connect to a database to extract training data and output a pickle file with the model.\nI would like to trigger this script every time there is a database update.\nI use a .yaml file pipeline where I build and run a docker container with the model inside.\nI checked the possible way to trigger the .yaml pipeline and could not find a way to do that.\nWhat is the best way to achieve this? Should it be on it's own .yaml pipeline?\nI just started to use Azure devops and I am not sure what is the best practice in this case.\n\nThank you in advance.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-11T07:47:26.17Z",
                "Answer_score":1,
                "Answer_body":"Hi,\n\nYou can try the Microsoft learn modules, create-a-build-pipeline also try the lab-services Lab Services and this way you can understand the process and test the required deployment process.\n\nSome of the best practices - phase-rollout-with-rings\n\n\n\n\n\nHope this helps.\n\n==\nPlease \"Accept the answer\" if the information helped you. This will help us and others in the community as well.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-12T03:54:30.937Z",
                "Answer_score":0,
                "Answer_body":"@JimmySalian-2011 Thank you for the answer. I am sorry I am still a bit lost with this. Could you write your guidance here about this. I would like to trigger the script .py which is in a Docker container everytime there is a db update. Using Azure devops, what, where and how should be the trigger please?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-12T04:01:43.71Z",
                "Answer_score":0,
                "Answer_body":"Is UDF the good solution?\nhttps:\/\/stackoverflow.com\/questions\/23382499\/run-python-script-on-database-event",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"'Execution Python Script' version change",
        "Question_creation_time":1661190354030,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/977128\/39execution-python-script39-version-change.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"Hello all,\n\nI coded some ML models using darts library on local desktop.\nI am trying to build the pipeline in Azure ML Studio, using the in-built component 'Execute Python Script' in the designer tab.\n\nWhat I am doing is, compressing the '.py' files of my code on local desktop into a zip file, and passing it into the 'Script bundle' argument of 'Execute Python Script' component of Azure ML, so that the code programmed on the local desktop could be reused in that component of pipeline.\n\nWhat the issue is, the python version of 'Execute Python Script' component shows up as 3.6.8 and the darts library is suitable for python versions 3.8 and above. This version gap does not let the pipeline execute successfully and ends up throwing the following error:\n\n\n\n\nazureml.studio.common.error.FailedToEvaluateScriptError: The following error occurred during script evaluation, please view the output log for more information:\n---------- Start of error message from Python interpreter ----------\nGot exception when invoking script at line 38 in function azureml_main: 'ImportError: cannot import name 'parse_version''.\n---------- End of error message from Python interpreter ----------",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-24T02:22:57.34Z",
                "Answer_score":1,
                "Answer_body":"@WaghbakriwalaArif-7809 Thanks for the details. Here is the troubleshooting guide for design error codes.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/component-reference\/designer-error-codes\n\nHere is the sample notebook for creating the custom components and document for component SDK.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"anomaly detector with azure",
        "Question_creation_time":1664585272280,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1031454\/anomaly-detector-with-azure.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"May I have some samples about anomaly detector with azure machine learning studio?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-09T23:03:07.117Z",
                "Answer_score":0,
                "Answer_body":"Hello @minhoolee-9603\n\nSorry about the late response, I think what you are looking for is Anomaly detection in time series analytic. I find some resource you may want to have a look -\nhttps:\/\/www.youtube.com\/watch?v=Ra8HhBLdzHE\nhttps:\/\/learn.microsoft.com\/en-us\/archive\/msdn-magazine\/2017\/november\/machine-learning-azure-machine-learning-time-series-analysis-for-anomaly-detection\n\nAbove resource are a little bit old, it is how to achieve the target in Azure Machine Learning.\n\nPlease let me know if you have more questions.\n\nI hope this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks a lot.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-10-01T00:52:35.153Z",
                "Answer_score":0,
                "Answer_body":"Kindly check it here",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-03T16:55:39.717Z",
                "Answer_score":0,
                "Answer_body":"Hi I know this service but what I am looking for is the solution in machine learning studio.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"RStudio application not installed in Azure ML compute",
        "Question_creation_time":1662442948630,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/995175\/rstudio-application-not-installed-in-azure-ml-comp.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":13,
        "Question_score":1,
        "Question_body":"When users were creating a new compute in AML environment by default RStudio application was created.\n\nHowever, from month of July, by default RStudio application is not getting created. Only JupyterLab, Jupyter, VS Code, Terminal, Notebook applications installed not a RStudio.\n\nIs there any way to by default install RStudio application in azure ML compute instance?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-06T08:48:34.98Z",
                "Answer_score":0,
                "Answer_body":"@SHAIKHAlifAbdul-9052 Yes, this is a recent change in the setup of compute instance that happens during the creation of compute instance. This change does not setup the rstudio community edition by default but you can set it up while creation by adding it as a custom application from advanced settings. This change is done as part of RStudio requirements to allow users to setup their own license key or use open studio version during creation. Please refer this documentation page for details to setup licensed and open version of the studio.\n\nIf you add a license key then please use RStudio Workbench (bring your own license) option from the advanced options and enter your own license key.\n\nIf you need to add the open version you need to select custom application and enter the docker image and mount point details to setup the rstudio during creation.\n\nTarget\/Published port 8787\nDocker image set to ghcr.io\/azure\/rocker-rstudio-ml-verse:latest\n\/home\/azureuser\/cloudfiles for Host path\n\/home\/azureuser\/cloudfiles for Container path\n\n\n\n\nOnce the creation and setup is complete the options to use Rstudio for open and licensed version will be visible as links on the compute instances page.\n\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-09-14T14:43:24.217Z",
                "Answer_score":1,
                "Answer_body":"FYI the mount point is separate now from the main files in notebooks. R is also missing a lot of stuff as the file system doesn't include \/ install various stuff. Basically MS have depreciated one of the top tools for data science. Well done MS top job again :( .",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-10T12:37:45.953Z",
                "Answer_score":0,
                "Answer_body":"Is there a way to add Rstudio after the compute instance has been created. In my organization, I can not create a compute instance myself, it has to be done by requesting the cloude infra structure team and they have created compute instances for me. I dread sending them these instructions to create another CI",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Studio error while testing real-time endpoint - list index out of range",
        "Question_creation_time":1645577589217,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/746784\/azure-ml-studio-error-while-testing-real-time-endp.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":5,
        "Question_comment_count":4,
        "Question_follower_count":13,
        "Question_score":1,
        "Question_body":"I am new to the Azure ML Studio and just deployed the bike-rental regression model. When I tried to test it using the built in test tool in the studio, I am getting the attached error. Similar results running the Python code as well. Can someone please help me?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-24T09:35:29.74Z",
                "Answer_score":3,
                "Answer_body":"@KumarPriya-6121 Thanks for the question. It's known issue and the product team working on the fix to change in the UI.\n\nWorkaround: As shown below please set the GlobalParameters flag to 1.0 or a float number or remove it.",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-03-01T07:41:18.553Z",
                "Answer_score":0,
                "Answer_body":"Change GlobalParameters flag value from integer 1 to decimal 1.0 to make it works.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-16T03:22:52.183Z",
                "Answer_score":0,
                "Answer_body":"What about when making GET requests to the score endpoint or doing a POST? Is there a way of setting the GlobalParameters flag there? I get this just by doing an authorized GET to my endpoint from postman.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-25T21:41:46.547Z",
                "Answer_score":2,
                "Answer_body":"@FernandoJosRibeiroJnior-4000 I had to modify the notebook as follows to get it to work:\n\n x = [[1,1,2022,1,0,6,0,2,0.344167,0.363625,0.805833,0.160446], \n    \n     [2,1,2022,1,0,0,0,2,0.363478,0.353739,0.696087,0.248539], \n    \n     [3,1,2022,1,0,1,1,1,0.196364,0.189405,0.437273,0.248309], \n    \n     [4,1,2022,1,0,2,1,1,0.2,0.212122,0.590435,0.160296], \n    \n     [5,1,2022,1,0,3,1,1,0.226957,0.22927,0.436957,0.1869]] \n    \n columns = [\"day\",\"mnth\", \"year\", \"season\", \"holiday\", \"weekday\", \"workingday\", \"weathersit\", \"temp\", \"atemp\", \"hum\", \"windspeed\"]\n data = [{columns[i]: v for i, v in enumerate(x_i)} for x_i in x]\n    \n request = {\n   \"Inputs\": {\n     \"data\": data\n   },\n   \"GlobalParameters\": 0.0 # not sure if this value matters\n }\n    \n input_json = json.dumps(request)",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-10T06:25:59.75Z",
                "Answer_score":0,
                "Answer_body":"Azure ML Studio error while testing real-time endpoint - Input data are inconsistent with schema\n\n\n\n\n\nKindly help me to resolve this issue.\n\n\n\n\nThanks in Advance\n\nRegards,\nPrashanth K",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AzureML: Data initialization error when input to the batch endpoint is data from cloud",
        "Question_creation_time":1664012828150,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1021674\/azureml-data-initialization-error-when-input-to-th.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I'm trying to invoke batch endpoint using data on cloud as input using CLI. When I use the input as local data it works fine but when I use the register datastore as input the job fails with the following error:\nDataset initialization failed: UserErrorException:\nMessage: Cannot mount Dataset(id='d10c7934-9c62-4e15-adf1-bc7386648403', name='None', version=None). Error Message: DataAccessError(NotFound)\nInnerException None\nErrorResponse\n{\n\"error\": {\n\"code\": \"UserError\",\n\"message\": \"Cannot mount Dataset(id='d10c7934-9c62-4e15-adf1-bc7386648403', name='None', version=None). Error Message: DataAccessError(NotFound)\"\n}\n}\n\nMy cli command:",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-26T10:39:21.9Z",
                "Answer_score":0,
                "Answer_body":"@IshikaRajput-5783 Thanks for the question. Are you using Pipeline or Runconfig?\n\nHere is the document to invoke batch endpoint with different input options.\nConcepts: https:\/\/aka.ms\/batch-endpoints-concepts \u200b\nHow-to: https:\/\/aka.ms\/managed-batch-endpoint \u200b\nExamples: https:\/\/aka.ms\/batch-endpoints-examples \u200b\nDemo: https:\/\/aka.ms\/batch-endpoints-demo",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"need guidance to use train models in ML studio",
        "Question_creation_time":1664405211343,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1027872\/need-guidance-to-use-train-models-in-ml-studio.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"hello new to ML studio. We have some trained model already but I want to use the studio for my next step. How should I import my model and retrain them?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-29T00:12:34.943Z",
                "Answer_score":0,
                "Answer_body":"Hello @Manuel-0778\n\nThanks for using Microsoft Q&A platform. Yes you can import your trained model to Azure Machine Learning Studio - https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-models?tabs=use-local\n\nYou can learn how to register a model from different locations, and how to use the Azure Machine Learning SDK, the user interface (UI), and the Azure Machine Learning CLI to manage your models.\n\nPlease check on above article to see how to register your model. I hope it helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"is move workspace easy?",
        "Question_creation_time":1664405263187,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1027803\/is-move-workspace-easy.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"we are not sure about our location but we do want to start now. If we need to move our workspace, is that possible? easy to accomplishing? Thank you",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-29T02:12:26.213Z",
                "Answer_score":0,
                "Answer_body":"Hello @Manuel-0778\n\nThanks for using Microsoft Q&A platform. In my opionion, it depends on your scenario. Please check on this preview feature - https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-move-workspace\n\nAs the document said, there are a lot of limitations -\n\nWorkspace move is not meant for replicating workspaces, or moving individual assets such as models or datasets from one workspace to another.\n\n\nWorkspace move doesn't support migration across Azure regions or Azure Active Directory tenants.\n\n\nThe workspace mustn't be in use during the move operation. Verify that all experiment jobs, data profiling jobs, and labeling projects have completed. Also verify that inference endpoints aren't being invoked.\n\n\nThe workspace will become unavailable during the move.\n\n\nBefore to the move, you must delete or detach computes and inference endpoints from the workspace.\n\n\nDatastores may still show the old subscription information after the move.\n\nEspecially the second point, if you are considering move the region, you may need to be careful. I hope this helps!\n\nLet me know if you have more questions and we are happy to help.\n\n\n\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-09-29T00:25:39.95Z",
                "Answer_score":0,
                "Answer_body":"Kindly go through the following reference:\n\nMove your workspace",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"machine learning pricing",
        "Question_creation_time":1664581676843,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1031348\/machine-learning-price.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"hi I would like to know how to estimate the price for designer ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-09T23:41:11.54Z",
                "Answer_score":0,
                "Answer_body":"Hello @Louis-4194\n\nThanks for using Microsoft Q&A platform, I am sorry I should have seen your question earlier.\n\nThis price depends on your settings about the compute. I would say you should try the calculator to estimate your price to avoid surprise - https:\/\/azure.microsoft.com\/en-us\/pricing\/calculator\/\n\nThe screenshot of pricing calculator is as below -\n\nI hope this helps.\n\n\n\n\nRegards,\nYutong\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-09-30T23:50:37.403Z",
                "Answer_score":0,
                "Answer_body":"Check it out here.\nhttps:\/\/azure.microsoft.com\/en-us\/pricing\/details\/machine-learning\/\n\n--please don't forget to upvote and Accept as answer if the reply is helpful--",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to download mlflow model artifacts from Azure Databricks workspace to local directory?",
        "Question_creation_time":1664972415760,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1036179\/how-to-download-mlflow-model-from-azure-databricks.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":18,
        "Question_score":2,
        "Question_body":"I have trained a machine learning model in Databricks workspace using mlflow. Model is getting registered in databricks model registry and saved in databricks file share. Now I want to download model artifacts from workspace. Currently I am transferring model to azure machine learning workspace. There I am able to download all the artifacts. How to do it from databricks workspace?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-06T10:12:30.293Z",
                "Answer_score":1,
                "Answer_body":"@SriramReddy-9682 Thanks for the question. To download a model from Databricks workspace you need to do two things:\n\nSet MLFlow tracking URI to databricks using python API\n\nSetup databricks authentication. I prefer authenticating by setting the following environment variables, you can also use databricks CLI to authenticate:\n\nDATABRICKS_HOST\n\nDATABRICKS_TOKEN\nHere's a basic code snippet to download a model from Databricks workspace model registry:\n\n import os\n import mlflow\n from mlflow.store.artifact.models_artifact_repo import ModelsArtifactRepository\n    \n model_name = \"example-model-name\"\n model_stage = \"Staging\"  # Should be either 'Staging' or 'Production'\n    \n mlflow.set_tracking_uri(\"databricks\")\n    \n os.makedirs(\"model\", exist_ok=True)\n local_path = ModelsArtifactRepository(\n     f'models:\/{model_name}\/{model_stage}').download_artifacts(\"\", dst_path=\"model\")\n    \n print(f'{model_stage} Model {model_name} is downloaded at {local_path}')\n\n\n\nRunning above python script will download an ML model in the model directory.\n\nContainerizing MLFlow model serving with Docker\n\nFor more information you can follow this article from Akshay Milmile",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Publishing AML Pipelines with SDK v2",
        "Question_creation_time":1664802453843,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1033206\/publishing-aml-pipelines-with-sdk-v2.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi,\n\nis it possible (or will be in the future) using Python SDK v2 to create pipeline endpoint (or endpoint + deployment)?\nIm looking for a way to submit a job for a created pipeline with a REST request.\n\nFor SDK v1 pipeline i was able to acquire satisfying result using Pipeline.publish method.\n\n\n\n\nThanks for any advice!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-04T05:27:42.76Z",
                "Answer_score":0,
                "Answer_body":"Hello @MaciejStefaniak-6173\n\nThanks for using Microsoft Q&A platform. For how to publish pipeline, I don't find anything currently. But for deploy endpoint, please check on this sample repo for SDK v2, there are several samples for you to refer about how to deploy endpoint - https:\/\/github.com\/Azure\/azureml-examples\/tree\/v2samplesreorg\/sdk\/python\n\nAlso, there is an example about using Azure Machine Learning (Azure ML) to create a production ready machine learning (ML) project, using AzureML Python SDK v2 (preview). - https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-pipeline-python-sdk\n\nI hope this helps, please let me know if you need more information or have any questiion regarding to above examples.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Can we connect the data from Kusto to Azure Machine Learning Studio directly ?",
        "Question_creation_time":1663120535263,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1006422\/can-we-connect-the-data-from-kusto-to-azure-machin.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":19,
        "Question_score":0,
        "Question_body":"Hi everyone,\nPlease help me to verify that is there anyway to connect the data from Kusto (KQL\/ADX) to use on Azure ML Studio. I have tried the solution alternatively that I exported the data from Kusto and them imported them to the instance container on Azure Portal, then link them to the Datastore of Azure ML Studio.\n\nAs I researched, there is a suggestion as : https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-pipeline-steps\/azureml.pipeline.steps.kustostep?view=azure-ml-py\n\nBut I dont know whether that is a good approach? And how to implemented the \"KustoStep\" pipeline correctly?\nPlease help me if there is another way to connect the data directly from Kusto to Azure ML\nThank you so much !",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-14T09:01:49.703Z",
                "Answer_score":0,
                "Answer_body":"@NguyenHuuMinhTriUTOPPROD-0093 This step can be used if you are looking to use the output of this step as input to another step, The output is the result of kusto queries run based on the configuration of this step. There is a sample notebook that is available in the azure ML notebook github repo for reference. This should be the sequence of running the step and using the output with another step.\n\n database_name = \"<database_name>\" # Name of the database to perform Kusto queries on\n query_directory = \"<query_directory>\" # Path to folder that contains a text file with Kusto queries\n    \n kustoStep = KustoStep(\n     name='KustoNotebook',\n     compute_target=compute_name,\n     database_name=database_name,\n     query_directory=query_directory,\n     output=step_1_output,\n )\n step2_input = step_1_output.as_input(\"input_data\")\n    \n step2 = PythonScriptStep(name=\"train_step\",\n                    script_name=\"train.py\",\n                    inputs=[step2_input],\n                    arguments=['--input_data', step2_input],\n                    compute_target='cpu_cluster',\n                    source_directory='.\/train',\n                    allow_reuse=True)\n    \n steps = [kustoStep, step2]\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML: Creating a Siamese network, I have the reference data stored in one blob storage and the user input stored in another blob storage. How can I connect the two blob storage to my batch endpoint. If not, is there a workaround?",
        "Question_creation_time":1662886746297,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1002087\/azure-ml-creating-a-siamese-network-i-have-the-ref.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Azure ML: Creating a Siamese network, I have the reference data stored in one blob storage and the user input stored in another blob storage. How can I connect the two blob storage to my batch endpoint. If not, is there a workaround? The setup looks like this.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-12T12:04:20.93Z",
                "Answer_score":0,
                "Answer_body":"@SamarjeetSinghPatil-6739 I think this should be possible where your input could be a different storage account and your output could be the default datastore.\n\n export OUTPUT_FILE_NAME=predictions_`echo $RANDOM`.csv\n JOB_NAME=$(az ml batch-endpoint invoke --name $ENDPOINT_NAME --input https:\/\/pipelinedata.blob.core.windows.net\/sampledata\/mnist --input-type uri_folder --output-path azureml:\/\/datastores\/workspaceblobstore\/paths\/$ENDPOINT_NAME --set output_file_name=$OUTPUT_FILE_NAME --mini-batch-size 20 --instance-count 5 --query name -o tsv)\n\n\n\nRef: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-batch-endpoint#configure-the-output-location-and-overwrite-settings\n\nPlease refer some other scenarios that you can set with the input and output path while using the batch endpoint invoke command.\n\n az ml batch-endpoint invoke --help",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is there a way to get all the machine learning algorigthms tried by azure automl for a machine learning job in python sdk?",
        "Question_creation_time":1662345469883,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/993641\/is-there-a-way-to-get-all-the-machine-learning-alg.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I am trying azure automl through python sdk. What I need is to get all the algorithm names along with the best algorithm azure tried for that particular job using python sdk.\nI have been exploring documentation but didn't get much.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-05T12:46:12.697Z",
                "Answer_score":0,
                "Answer_body":"@Nuron-5007 I believe this can be achieved by getting the best and fitted model from your automl run's get_output and then printing the details of the algorithms used by this model.\n\n automl_config = AutoMLConfig(\u2026)\n automl_run = experiment.submit(automl_config \u2026)\n best_run, fitted_model = automl_run.get_output()\n\n\n\n\nUse fitted_model.steps to print the selected algorithm with its hyperparameter values\nThis is documented here from the Azure ML documentation.\n\nI hope this helps!!\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Cannot create new compute instance",
        "Question_creation_time":1662003553540,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/989732\/cannot-create-new-compute-instance.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I'm trying to create my first compute instance using Azure Machine Learning Studio, but it fails every time with little to no details.\n\nHere are the parameters I use to create a new instance:\n\n\nThis is what the instance looks like during creation:\n\nAs well as additional attributes\n\n\nIt runs like that for an hour or so, and then fails.\nThis is what the instance looks like after an error:\n\n\nI can also see another error message in the logs:\n\n\nCan I please get some help to create new compute instance. Everything looks pretty straight forward, I would definitely expect to have no errors there.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-01T05:41:36.307Z",
                "Answer_score":0,
                "Answer_body":"@gkozyrev I think the error in this case is specific to your subscription or request. I am able to create a new compute instance without any errors from the studio.\n\nIs this a managed account by a 3rd party with some restrictions? If Yes, you could reach out to the admin of the team to check if you have all permissions to create a compute instance.\n\nIf this is your personal account and since the details of the failure are not obvious, from the message you could report the failure screen shot of the request id by using the smiley icon on the top right-hand corner of the studio. This enables the service team who has access to your request details to contact you for any failures related to the service.\nYou also have the option to contact support team through Azure portal using the Help + Support blade for 1:1 support from a support team engineer.\n\nI hope this helps!!",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning - Input \"Untrained model\" has invalid type \"DataTable\" error",
        "Question_creation_time":1663734079143,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1016607\/azure-machine-learning-input-34untrained-model34-h.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"First time trying Azure ML using Two-Class Logistic Regression.\n\nData source is a table in AzureSQL and it's throwing InvalidLearnerError: Input \"Untrained model\" has invalid type \"DataTable\".\n\nHelp?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-03T13:17:10.397Z",
                "Answer_score":0,
                "Answer_body":"@tw22 Thanks for the details. If the component output data is in a tabular format, you must choose to register the output as a file dataset or tabular dataset. Here is the document that can help.\nhttps:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/v1\/how-to-designer-import-data#register-a-dataset",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML 'Designer': how to view logistic regression model coefficients \/ intercept",
        "Question_creation_time":1607433503623,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/190478\/azure-ml-39designer39-how-to-view-logistic-regress.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":1,
        "Question_body":"Using Azure ML Designer it is easy to create a model using the Two-Class Logistic Regression & Train Model components. However it does not seem to be possible to view the regression coefficients \/ intercept (ie. the weights applied to the feature values within the model). How can we go about viewing the model coefficients? Are they stored in one of the Train Model output files (eg. data.ilearner) in a way that can be viewed \/ exported to a human readable format?\n\nNote: this question relates to the Azure Machine Learning Studio (not the older 'classic' version where I believe it was possible to 'right-click' and visualise the model coefficients).",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-09T05:26:10.807Z",
                "Answer_score":0,
                "Answer_body":"Thanks for reaching out. These are the metrics reported when evaluating binary classification models. You can view the results by clicking evaluate model > visualize > evaluation results. Hope this helps.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-05T20:37:41.743Z",
                "Answer_score":0,
                "Answer_body":"Any update on this? Is it still not possible to get the coefficients for the trained linear regression model?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Can you create an azure aks cluster with ephemeral os disk using python sdk ?",
        "Question_creation_time":1664280949717,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1025025\/can-you-create-an-azure-aks-cluster-with-ephemeral.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"I'm deploying some code with azure aks and think an ephemeral os disk would be beneficial but I can't see a way to include this setting with the python SDK. Is this possible at the moment?\n\nCheers\nRhys",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-27T19:00:49.64Z",
                "Answer_score":1,
                "Answer_body":"@RhysGreen-4252\n\nI understand you are wanting to set the OS disk for your AKS cluster to ephemeral using the python sdk. This blog post covers lots of helpful information regarding ephemeral disks and AKS, though it does not contain specific information on python. According to this the default should be ephemeral if the VM type supports an ephemeral OS disk. \"When a user does not explicitly request managed OS disks (e.g. using the --node-osdisk-type Managed parameter in an az aks create or in an az aks nodepool add command), AKS will default to ephemeral OS disks whenever possible for a given node pool configuration.\"\n\nPlease deploy your cluster using an ephemeral compatible VM. You can verify the cluster is using an ephemeral disk with the command here.\n\nHope this helps. If you still need assistance, please let me know!\n\n\n\n\nPlease don\u2019t forget to \"Accept the answer\" and \u201cup-vote\u201d wherever the information provided helps you, this can be beneficial to other community members.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-09-30T12:44:56.233Z",
                "Answer_score":0,
                "Answer_body":"I'm using the python sdk and running:\n\n  prov_config = AksCompute.provisioning_configuration(\n      cluster_purpose=\"FastProd\",\n      vm_size=\"Standard_F8s_v2\",\n      agent_count=3,\n  )\n  aks_target = ComputeTarget.create(\n      workspace=ws, name=aks_name, provisioning_configuration=prov_config\n  )\n  inf_config = InferenceConfig(\n         environment=env, source_directory=\".\/\", entry_script=entry_script\n     )\n  deployment_config = AksWebservice.deploy_configuration(\n              cpu_cores=6,\n              memory_gb=10,\n              autoscale_enabled=True,)\n  service = Model.deploy(\n         workspace = ws,\n         name = service_name, \n         models = model,\n         inference_config = inf_config,\n         deployment_config = deployment_config,\n         deployment_target = aks_target,\n         overwrite=True,)\n\n\n\nThis then produces the cluster shown in the image below.",
                "Answer_comment_count":5,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Machine learning, Resource group exhaustion when triggering ML Compute Cluster run",
        "Question_creation_time":1664374745717,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1027000\/machine-learning-resource-group-exhaustion-when-tr.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I am running a Jupiter notebook in Azure Machine Learning, but my runs today frequently end up with this error:\n\nCreating the resource group 'afd46bcb-6c53-431c-9f34-f6c2e97e95a0-AzureBatch-CloudService' would exceed the quota of '980'. The current resource group count is '980', please delete some groups before creating a new one.\n{\"error\":{\"code\":\"ResourceGroupQuotaExceeded\",\"message\":\"Creating the resource group 'afd46bcb-6c53-431c-9f34-f6c2e97e95a0-AzureBatch-CloudService' would exceed the quota of '980'. The current resource group count is '980', please delete some groups before creating a new one.\"}}. False\n\nMy guess is that the mentioned subscription (and resource group) is part of the Machine Learning PaaS. Could you advise me what to do if I want to avoid this error going forward while I insist on deploying my Machine Learning workspace in West Europe ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-29T11:56:26.163Z",
                "Answer_score":0,
                "Answer_body":"Hi MS Team,\n\nFrom yesterday, I am seeing the same issue while using Azure batch with spot instances.\n\nSame observation as @kimhansen-6134 had. I think this error is for Azure batch spot instance subscription. My subscription doesn't have not even 100 RG's.\n\n\n\n\n AllocationTimedout\n Desired number of low priority nodes could not be allocated as the resize timeout was reached\n Provider Error Json: {\"error\":{\"code\":\"ResourceGroupQuotaExceeded\",\"message\":\"Creating the resource group '736eba88--AzureBatch-CloudService' would exceed the quota of '980'. The current resource group count is '980', please delete some groups before creating a new one.\"}}\n Provider Error Json Truncated: False",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-10-04T16:16:50.797Z",
                "Answer_score":0,
                "Answer_body":"Hello @kimhansen-6134 @Joliving-7079\n\nThanks for reporting this issue again and we just got a confirmation from product team for this issue -\n\nEssentially, that's a transient Azure batch issue that affects low-priority clusters. To prevent that from happening, the customer should have dedicated a cluster.\n\nPlease do have a try to see how things going, please let me know if you still have this issue. I hope this helps.\n\n\n\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Time duration (years and months)",
        "Question_creation_time":1664745919727,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1032331\/time-duration-years-and-months.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Dear all.\nI'm trying to figure out how I need to format \"a time duration value\" (years and months) on my Excel sheet (CSV) so that it is recognized correctly by Microsoft Azure automated ML and Designer. E.g. I have a value on my Excel Sheet like: \"14years, 4months\".\nMay you can tell me which format I have to choose in Excel for such values?\nThank you.\nBest regards Lukas",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-03T21:17:42.827Z",
                "Answer_score":0,
                "Answer_body":"I have an Excel Worksheet with values from students (anonymized) who applied for a MSC.\nAll values are checked during the \"admission process\" from the University.\nThe student will only be granted (accepted) to the MSc if he has a certain grade (BSc) and his University (BSc) is accepted (accredited). Furthermore, he should show a good English level. In addition, the student needs at least (around) 2 years of work experience, before he can start with the MSc.\nCertain values (e.g. the grade) can be compensated by other values (e.g. the work experience) to a defined level.\n\nBy using Microsoft Azure, I want to predict if a student will be accepted or not accepted. And\/or maybe if a certain process step (e.g. check the English level) needs to be conducted or a recommendation\/prediction can be given instead - just on the basis of historical values.\n\nMy question was about the values in the column \"work experience\". I have many values which are just typed like 4 years, 2 months or 4y, 2m.\n\nI am not sure how I need to \"provide or formate\" the values in the column \"work experience\" (time duration) accordingly in Excel so that it can be used perfectly by \"Microsoft Azure automated ML\" or the \"Microsoft Azure Designer\".\n\nCurrently, I don't get any errors. But I realize that my current model does not recognize the importance of this column \"work experience\" with its current values (e.g. 4 years, 2 months).\n\nThank you for your feedback.\nBest regards\nLukas",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How do you create an azure jupyter in vscode?",
        "Question_creation_time":1662435889603,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/995055\/how-do-you-create-an-azure-jupyter-in-vscode.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hey all,\n\nI hope you are all doing well. I am wondering if you can use azure jupyter notebook in vscode if you have the azure extension and the jupyter notebook extension?\n\nThanks,\nKen",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-07T01:08:26.917Z",
                "Answer_score":1,
                "Answer_body":"@KenHuang-1956 Thanks for the question. Here is the document to connect Jupyter from VScode.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-set-up-vs-code-remote?tabs=studio#configure-compute-instance-as-remote-notebook-server",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-09-23T06:47:37.513Z",
                "Answer_score":0,
                "Answer_body":"In VS Code, open the command palette by selecting View > Command Palette.\nEnter into the text box Azure ML: Connect to Compute Instance.\nSelect your subscription.\nSelect your workspace.\nSelect your compute instance or create a new one.\n\nThis may help.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML for SAP ERP",
        "Question_creation_time":1664541861543,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1030800\/azure-ml-for-sap-erp.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":1,
        "Question_body":"I am trying to figure out about standard connectors between SAP ERP product and Azure ML especially for NLP scenarios. Can you please suggest on this.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-30T13:01:37.547Z",
                "Answer_score":0,
                "Answer_body":"@Divya-0887 Thanks for the question. Here is the blog that could help and nlp recipes.\nhttps:\/\/blogs.sap.com\/2022\/08\/03\/azure-machine-learning-triggering-calculations-ml-in-sap-data-warehouse-cloud\/",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"I want to register the model learned by AutoML in Azure Machine learning in ONNX format and call it in Azure Synapse Analitics.",
        "Question_creation_time":1664411309103,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1027830\/i-want-to-register-the-model-learned-by-automl-in.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I found that I can register the model using Mlflow, but I don't know how to register it in ONNX format.\nI found out that the model is registered using Mlflow.\nBut I don't know how to convert AutoML models to ONNX format and register them with Mlflow.\n\nfrom azure.ai.ml import MLClient\nfrom azure.identity import DefaultAzureCredential\nfrom azureml.train.automl import AutoMLConfig\nfrom azureml.core import Workspace, Dataset\nfrom azureml.core.experiment import Experiment\nfrom azureml.core.model import Model\nfrom azureml.core.authentication import ServicePrincipalAuthentication\nfrom azureml.automl.runtime.onnx_convert import OnnxConverter\nfrom random import random\nfrom mlflow.tracking import MlflowClient\nimport mlflow\nimport mlflow.onnx\nimport os\nimport azureml.mlflow\n\nauth = ServicePrincipalAuthentication(\ntenant_id=\"\",\nservice_principal_id=\"\",\nservice_principal_password=\"\")\n\nsubscription_id = ''\nresource_group = ''\nworkspace_name = ''\n\nml_client = MLClient(credential=auth,\nsubscription_id=subscription_id,\nresource_group_name=resource_group)\n\nazure_mlflow_uri = ml_client.workspaces.get(workspace_name).mlflow_tracking_uri\nmlflow.set_tracking_uri(azure_mlflow_uri)\n\nws = Workspace(subscription_id, resource_group, workspace_name, auth=auth)\n\ntrain_data = Dataset.get_by_name(ws, name='iris')\n\nlabel = \"class\"\n\nautoml_settings = {\n\"primary_metric\": 'AUC_weighted',\n\"n_cross_validations\": 2\n}\n\nautoml_classifier = AutoMLConfig(\ntask='classification',\nblocked_models=['XGBoostClassifier'],\nenable_onnx_compatible_models=True,\nexperiment_timeout_minutes=30,\ntraining_data=train_data,\nlabel_column_name=label,\n**automl_settings\n)\n\nexperiment_name = 'experimetn_with_mlflow'\nmlflow.set_experiment(experiment_name)\nexperiment = Experiment(ws, experiment_name)\n\nwith mlflow.start_run() as mlflow_run:\nmlflow.log_metric(\"iris_metric\", random())\n\n mlflow_run = experiment.submit(automl_classifier, show_output=True)\n description = 'iris_Description'\n model = mlflow_run.register_model(description=description,\n                                model_name='iris_Model')\n best_run, onnx_mdl = mlflow_run.get_output(return_onnx_model=True)\n onnx_fl_path = \".\/best_model.onnx\"\n OnnxConverter.save_onnx_model(onnx_mdl, onnx_fl_path)\n model = Model.register(workspace=ws,\n                     description=description,\n                     model_name='iris_onnx_model',\n                     model_path=onnx_fl_path)\n client = MlflowClient()\n finished_mlflow_run = MlflowClient().get_run(mlflow_run.run_id)\n metrics = finished_mlflow_run.data.metrics\n tags = finished_mlflow_run.data.tags\n params = finished_mlflow_run.data.params\n model_path  = \"best_model\"\n model_uri = 'runs:\/{}\/{}'.format(mlflow_run.run_id, model_path)\n mlflow.register_model(model_uri, 'iris_onnx_mlflow_model')",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-29T12:05:27.3Z",
                "Answer_score":0,
                "Answer_body":"@10433767 Thanks for the question. Can you please share document\/sample that you are trying. In order to save trained model download (and score) as the ONNX model you have here a few code examples.\nMLflow model registry will enable Synapse to run ONNX models is in preview.\n\nHere is the ONNX prediction section in the sample notebook.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-09-29T13:28:40.59Z",
                "Answer_score":0,
                "Answer_body":"Thanks for the reply.\nI made it with the code you gave me.\nI was able to save the model in ONNX format in Azure Machine learning(See image file 2) using the following code, but could not reference it from Azure Synapse Analytics. See image file 1.\n\nfrom azureml.automl.runtime.onnx_convert import OnnxConverter\n\nonnx_fl_path = \".\/best_model.onnx\"\nOnnxConverter.save_onnx_model(onnx_mdl, onnx_fl_path)",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Not able to archieve specific enviornment version in azure ml",
        "Question_creation_time":1664433909617,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1028195\/not-able-to-archieve-specific-enviornment-version.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I was trying to archive a specific environment version in azure machine learning using the \"az ml environment archive \" but getting error that the \"Version is already registered and can not be changed\".\nAs per the Microsoft documentation at https:\/\/learn.microsoft.com\/en-us\/cli\/azure\/ml\/environment?view=azure-cli-latest#az-ml-environment-archive it is possible to archive a specific version without archiving entire environment container.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-29T07:10:45.163Z",
                "Answer_score":0,
                "Answer_body":"From my experience and how I understand that given documentation:\n\nIf you already have archived version 1 then you won't be able to do this again, you have to change the version to a higher value.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Moving Azure Machine Learning Studio jobs to a new region",
        "Question_creation_time":1662467585447,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/995833\/moving-azure-machine-learning-studio-jobs-to-a-new.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I need to move my Machine Learning Studio workspace to a new region. I am aware that the move function doesn't allow automatically moving to a new region, so I'll have to create a new workspace. That's not a big problem, but I still want to keep my job\/experiment history (in my new workspace). How can I do that?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-27T15:12:08.087Z",
                "Answer_score":0,
                "Answer_body":"Hello @David-3633\n\nSorry, I just got confimation from product team, this is currently impossible. I am sorry for the inconvenience.\n\nA near future workaround which could let users at least share some experiment outputs\/inputs like environments, models, datasets cross region, but not the jobs\/metrics\/logs themselves. This feature is in private preview now and will be in public preview soon.\n\nI hope this information helps.\n\n\n\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure ML Notebook: The code being run in the notebook may have caused a crash or the compute may have run out of memory",
        "Question_creation_time":1663925084710,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1020607\/azure-ml-notebook-the-code-being-run-in-the-notebo.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I am using Azure ML Notebook with python kernel to run the following code:\n\n %reload_ext rpy2.ipython\n    \n from azureml.core import Dataset, Datastore,Workspace\n    \n subscription_id = 'abc'\n resource_group = 'pqr'\n workspace_name = 'xyz'\n    \n workspace = Workspace(subscription_id, resource_group, workspace_name)\n datastore = Datastore.get(workspace, 'mynewdatastore')\n    \n # create tabular dataset from all parquet files in the directory\n tabular_dataset_1 = Dataset.Tabular.from_parquet_files(path=(datastore,'\/RNM\/CRUD_INDIFF\/CrudeIndiffOutput_PRD\/RW_Purchases\/2022-09-05\/RW_Purchases_2022-09-05T17:23:01.01.parquet'))\n df=tabular_dataset_1.to_pandas_dataframe()\n print(df)\n\n\n\nAfter executing this code, I am getting the Cancelled message from the notebook cell and also getting the message on top of the cell as:\n\n  The code being run in the notebook may have caused a crash or the compute may have run out of memory.\n  Jupyter kernel is now idle.\n  Kernel restarted on the server. Your state is lost.\n\n\n\nThe Parquet file which I am using in the code is of size 20.25 GiB and I think due to the large size of this file, this problem is being created. Can anyone please help me how to resolve this error without breaking the file into multiple files of small sizes. Any help would be appreciated.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Issue with DataDriftDetector get_output method",
        "Question_creation_time":1664169018620,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1022532\/issue-with-datadriftdetector-get-output-method.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_follower_count":26,
        "Question_score":0,
        "Question_body":"Hi,\n\nPlease help me with issue in below code\n\nWhen i run above code in .ipynb file separately, there is no issue.\n\nStandalone execution:\nfrom azureml.core import Workspace\nfrom azureml.datadrift import DataDriftDetector, AlertConfiguration\nfrom datetime import datetime\nws = Workspace.from_config()\ndstore = ws.get_default_datastore()\n\n monitor = DataDriftDetector.get_by_name(ws, 'cc-silver_stable-drift-test-ver2')\n monitor.get_output(start_time=datetime(year=2019, month=9, day=1))\n\n\n\n\n\nWithin Azure SDK Pipeline\nWhile running below code (monitor.get_output()) in Azure SDK pipeline,\nit results in error (TypeError: Cannot Unpack Non-Iterable NoneType Object).\nIssue is with last line of code (bold).\n\n from azureml.core import Datastore, Dataset, Workspace\n from azureml.core import Experiment, Run\n from azureml.core.compute import ComputeTarget, AmlCompute\n from azureml.core.compute_target import ComputeTargetException\n from azureml.datadrift import DataDriftDetector\n from azureml.core import Workspace\n import pandas as pd\n import numpy as np\n import datetime as dt\n from datetime import datetime, date, timedelta\n    \n run = Run.get_context()\n ws = run.experiment.workspace\n    \n from azureml.datadrift import DataDriftDetector\n from azureml.core import Workspace\n monitor = DataDriftDetector.get_by_name(ws, 'cc-silver_stablever3')\n print(monitor.get_output(start_time=datetime(year=2022, month=1, day=1),\n                         end_time=datetime(year=2022, month=5, day=1)))\n\n\n\n\nRegards,\nAijaz Ahmad Hajam",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure CLI - az ml register components idempotent?",
        "Question_creation_time":1664211025747,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1023499\/azure-cli-az-ml-register-components-idempotent.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Are az ml register components idempotent?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-27T10:22:32.037Z",
                "Answer_score":1,
                "Answer_body":"@DevollTascha-3956 Are you referring to az ml component create command?\nAs per the reference, running this command multiple times will generate a new version if version is not specified. So, in that perspective I don't think it is idempotent but if there are no other changes to the component then the new version will be the same as the earlier. Thanks!!\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Warning while cretaing Dataset from Datastore",
        "Question_creation_time":1664348355043,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1026239\/warning-while-cretaing-dataset-from-datastore.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"While creating a dataset using a datastore I see the following\n\"Warning: The selected datastore's SAS is insufficient to create this dataset.\nReading the dataset requires Read permission for Objects as well as Containers if the path is a folder or glob.\"\n\nI've ensured that the necessary permissions are assigned to the managed resources as well as the users. But still I see this warning. Will this create problem while accessing data from blob storage?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure OpenAI service capabilities",
        "Question_creation_time":1663989341807,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1021561\/azure-openai-service-capabilities.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":1,
        "Question_body":"How do I get access to the Azure OpenAI service to evaluate it's capabilities?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-24T06:32:47.767Z",
                "Answer_score":0,
                "Answer_body":"@Srin-4824 Thanks for the question. It is a Limited Access service so you have to apply for it https:\/\/aka.ms\/oai\/access",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"unable to create datadrift alert in Azure ML",
        "Question_creation_time":1663946292127,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1021112\/unable-to-create-datadrift-alert-in-azure-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I am unable to create datadrift alert while trying to create a datadrift monitor. I am getting following error: Datadriftdetector with id: e83bd907-a268-4137. This may be because you do not have access to the AppInsights associated with this AzureML Workspace\n\nI have even given User Access Admin role but not able to create alert",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure ML CLI v2 independent, parallel, low-priority nodes which restart",
        "Question_creation_time":1663790217710,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1018156\/azure-ml-cli-v2-independent-parallel-low-priority.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi and thanks in advance for your time. This one's a bit long-winded, sorry.\n\nI am using the Azure ML CLI v2 to perform both training and hyperparameter optimization of deep neural networks. My codebase makes use of checkpointing and can therefore be pre-empted. I also have a lot of parallel, largely independent work going on (e.g. training separate models over a fixed number of seeds or performing parallel hyperparameter optimization with an RDB coordinating the trials). Basically I want to recreate a SLURM Job Array. My solution so far has been to create a low-priority compute cluster of size N, spawn a single job with N nodes, and use\n\nyaml\ndistribution:\n  type: pytorch\n  process_count_per_instance: 1\n\n\n\n\nto create N processes to run independently. This works (sort of), but has two major drawbacks. First, Azure doesn't know that the N processes are independent, meaning both queueing and preemption happens for all N processes at once. I'm fine with any number of processes being preempted at a time as long as they finish eventually. That's my second point: the preempted job does not requeue automatically. I can manually restart it, of course, but ideally I can leave it and come back.\n\nDoes anyone have a better solution for this? Can Azure ML handle what I want to do, or do I have to switch to something like Batch Shipyard?\n\nThanks again,\nSean",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Registering Data Asset from Job with v2 SDK\/CLI",
        "Question_creation_time":1663328415870,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1011004\/registering-data-asset-from-job-with-v2-sdkcli.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_follower_count":12,
        "Question_score":1,
        "Question_body":"Following this example I tried to register the output of a job as a Data Asset, by using the azureml:<my_data>:<version> syntax for the path. The following minimal example shows what I'm trying to achieve:\n\n from azure.ai.ml import command\n from azure.ai.ml.entities import Data\n from azure.ai.ml import Input, Output\n from azure.ai.ml.constants import AssetTypes\n    \n my_job_outputs = {\n     \"prep_data\": Output(type=AssetTypes.URI_FOLDER, path=\"azureml:test_output:1\")\n }\n    \n job = command(\n     command=\"echo 'test' > ${\n                 {outputs.prep_data}}\",\n     outputs=my_job_outputs,\n     environment=\"test-env@latest\",\n     compute=\"cpu-cluster\",\n )\n    \n # submit the command\n returned_job = ml_client.create_or_update(job)\n\n\n\nUnfortunately, this fails. The job submission works, but the Job is immediately going to the Failed status with the following error message:\n\n Invalid output uri azureml:test_output:1\/ found for output prep_data of run , the list of supported uri formats are [\"wasb:\/\/\", \"wasbs:\/\/\", \"adl:\/\/\", \"abfs\", \"abfss:\/\/\", \"azureml:\/\/\"]\n\n\n\nWhat is the correct syntax for registering a Data Asset from a Job output?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How can I use a already trained model of AutoML in Designer pipelines, for retraining and deploy?",
        "Question_creation_time":1663853333980,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1019338\/how-can-i-use-a-already-trained-model-of-automl-in.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I have a model that is already been trained with Auto ML (Voting Ensemble algorithm). This model is already deployed and in production.\nI would like to know how can I retrain this model using the Designer pipelines? More specificaly, how can I import this model, builded on Auto ML, with some of the components in the designer for retraining?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-23T08:00:28.367Z",
                "Answer_score":0,
                "Answer_body":"Hello @RafaelNakamura-5502\n\nThanks for using Microsoft Q&A platform. I understand you have already trained your model with AutoML. Luckily in V2 preview, you can deploy an AutoML-trained machine learning model to an online (real-time inference) endpoint.\n\nThe guidance is here - https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-automl-endpoint?tabs=Studio\n\nBut please be aware that SDK v2 is currently in public preview. The preview version is provided without a service level agreement, and it's not recommended for production workloads. Certain features might not be supported or might have constrained capabilities. For more information, see Supplemental Terms of Use for Microsoft Azure Previews- https:\/\/azure.microsoft.com\/support\/legal\/preview-supplemental-terms\/\n\nIf you are aimming to a stable environment and want to use SDK v1, you can import your model to designer as this guidance - https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-models?tabs=use-local\n\nTo create a model in Machine Learning, from the UI, open the Models page. Select Register model, and select where your model is located. Fill out the required fields, and then select Register. Then you can find the model in your conponent and use it directly in designer.\n\nI hope above information helps. Please let us know if you have more questions.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning Studio - Create Environment with private ACR is blocked by Firewall",
        "Question_creation_time":1663859823703,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1019515\/azure-machine-learning-studio-create-environment-w.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"We have a Azure Machine Learning Studio, which is connected to a private ACR. The ACR sits behind a Firewall and has a private endpoint to our VNET.\n\nIn Machine Learning Studio, when using the feature \"Environments\" -> \"Custom Environments\" -> \"Create\" -> \"Use existing docker image with conda\" and \"imagePathInOurPrivateRegistry\", we get the error \"Logging in to registry: ourregistry.azurecr.io\nfailed to login, ran out of retries: failed to set docker credentials: Error response from daemon: Get \"https:\/\/ourregistry.azurecr.io\/v2\/\": denied: client with IP '20.50.200.109' is not allowed access.\". A manual approach to fix this, was to whitelist the mentioned IP address in the Firewall Settings of our ACR.\n\nI know there is a public list of IP adresses, which are used by AzureML. But these are way over 300 and I don't think it is a proper solution to whitelist all of them.\n\nWhat would be the best solution to fix this?\n\nThis article ( https:\/\/learn.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-workspace-vnet?tabs=pe%2Ccli#azure-container-registry-1) states an environment has to be created from one of our Compute Instances, which can be placed in our VNET. Is there an article describing how to create a custom environment via Compute Instance? This seems to me a rather complicated way for a feature, which is directly included in Azure ML. Do I miss something here?\n\n\nIs there a way to get the IP Address of our current Azure ML Studio?\n\n\nWhen creating this environment, what hardware or compute instance is used? Our ML workspace currently has only one Compute Cluster, which is integrated in our VNET. There is no compute instance.\n\nThanks in advance and kind regards!",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How do I use Azure Key Vault from Notebook in Azure Machine Learning",
        "Question_creation_time":1662737071997,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1001137\/how-do-i-use-azure-key-vault-from-notebook-in-azur.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":20,
        "Question_score":0,
        "Question_body":"I am trying to use Azure Key Vault in Azure Machine learning notebook. However, I am unable to load the credentials from Kev Vault to Jupiter Notebook Environment.\n\nI tried using the Microsoft docs available. Using those docs it works for python environments outside Jupiter notebook but not in Jupiter notebook.\n\nCan someone please let me know solution for this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-23T06:45:58.667Z",
                "Answer_score":0,
                "Answer_body":"Navigate to your new key vault in the Azure portal\n  On the Key Vault settings pages, select Secrets.\n  Click on Generate\/Import.\n  On the Create a secret screen choose the following values:\n\n\n\nUpload options: Manual.\nName: Type a name for the secret. The secret name must be unique within a Key Vault. The name must be a 1-127 character string, starting with a letter and containing only 0-9, a-z, A-Z, and -. For more information on naming, see Key Vault objects, identifiers, and versioning\nValue: Type a value for the secret. Key Vault APIs accept and return secret values as strings.\nLeave the other values to their defaults. Click Create.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Why is azure ml studio not showing my subscription",
        "Question_creation_time":1662182084083,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/992557\/why-is-azure-ml-studio-not-showing-my-subscription.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":20,
        "Question_score":0,
        "Question_body":"azure machine learning studio does not show my azure pass subscription",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-04T10:52:24.843Z",
                "Answer_score":0,
                "Answer_body":"Hello @ArnavSareen-7252\n\nThanks for using Microsoft Q&A, you can find your subscription information as below screenshot when you are in your studio page.\n\nYou can also go to Azure portal and check you subscription info directly.\n\nIf you are still not able to find it, please share the screenshot and I can help you.\n\nI hope it helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-09-23T06:42:04.777Z",
                "Answer_score":0,
                "Answer_body":"This problem occurs if you selected at the wrong directory, or if your account doesn\u2019t have sufficient permissions.\n\nSolution:\nMake sure that the correct Azure directory is selected by selecting your account at the top right.\nIf the right Azure directory is selected but you still receive the error message, assign the Owner role to your account.\n\nRegards,\nBruce",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to access Azure Machine Learning Studio without a Public IP",
        "Question_creation_time":1645431850553,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/743872\/how-to-access-azure-machine-learning-studio-withou.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Dear Support Team,\n\nHope this email finds you well. I am writing to you because I am trying to access Azure ML Studio without a public IP but I am having some troubles.\n\nI saw the tutorial \"Create a secure workspace\" tutorial and I wanted to confirm that making the jump box is a \"must\" for accessing the azure ML studio without public IP, or I can do it from my browser after making all the secure space?\n\nIs there any method I can do it? I just can not upload any file\/ or see previous files\n\nAlso I have this error:\n[2]: \/answers\/storage\/attachments\/176304-screen-shot-2022-02-21-at-171846.png\n\nHowever I have the contributor permission\n![176315-screen-shot-2022-02-21-at-171938.png][1]![176304-screen-shot-2022-02-21-at-171846.png][2]\n[1]: \/answers\/storage\/attachments\/176315-screen-shot-2022-02-21-at-171938.png\n\nCan you help me with this?\n\nThank you for your time and hope you are having a great day,\n\nCatherine",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-23T06:31:08.52Z",
                "Answer_score":0,
                "Answer_body":"In the studio, select Datastores.\n\nTo update an existing datastore, select the datastore and select Update credentials.\n\nTo create a new datastore, select + New datastore.\n\nIn the datastore settings, select Yes for Use workspace managed identity for data preview and profiling in Azure Machine Learning studio.\n\nIn the Networking settings for the Azure Storage Account, add the Microsoft.MachineLearningService\/workspaces Resource type, and set the Instance name to the workspace.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"what is the best IoT architecture for AI in Azure ?",
        "Question_creation_time":1663849334273,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1019237\/what-is-the-best-iot-architecture-for-ai-in-azure.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":26,
        "Question_score":0,
        "Question_body":"I'm here to ask for advice on an architecture I've set up for real-time data processing. The goal is to have a Dashboard able to display all the metrics coming from the connected objects and to be able to make predictions in real time (cost prediction, maintenance prediction etc..) using AI.\n\nI set up the architecture below with a script simulating a machine. But I have a lot of doubts about this one.\n\nEspecially for Stream Analytics. I would like to be able to clean the raw data, before storing them (aggregation in particular) to calculate an OEE and other things.\n\nBut SA is limited in terms of data aggregation, so I would like to know what would be the best alternative for real-time data processing before storing it.\n\nShould I use Azure Function combined with SA?\nCan Azure Machine Learning studio do this processing work with or without SA?\nAzure Databricks seemed to be a good alternative but I'm having a lot of trouble setting up a real-time data processing stream and CSV\/Json storage in my data lake but I don't know if I'm doing it wrong or if it's just impossible.\n\nAzure Data Factory didn't seem to be adapted to real time data processing so I abandoned this option\n\nThere are so many options and I have no idea in which direction to go, I've been working on it for several months.\n\nThanks to all the people who will take the time to answer.\n\n\n\n\n\n\n[1]: \/answers\/storage\/attachments\/243758-architecture.png",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-22T22:03:57.087Z",
                "Answer_score":1,
                "Answer_body":"Take a look at examples in Azure Architecture Center and Real-time processing and Stream processing with Azure Stream Analytics\n, Stream Analytics does seem to be solution.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Connection Error 403",
        "Question_creation_time":1663611187617,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1014310\/connction-error-403.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":36,
        "Question_score":0,
        "Question_body":"Hi, I keep on getting this error while trying to access the Twitter API using the TwitterClient. The Client builds successfully but then it shows this error when I run: dotnet run",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-19T20:27:36.457Z",
                "Answer_score":1,
                "Answer_body":"This is not an Azure error, right?\n\nThis is the developer forum https:\/\/developer.microsoft.com\/en-us\/community\/\nAnd this is the .NET forum https:\/\/techcommunity.microsoft.com\/t5\/net\/ct-p\/dotnet",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to create tabular dataset in notebook with R kernel",
        "Question_creation_time":1663428115537,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1012184\/how-to-create-tabular-dataset-in-notebook-with-r-k.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I want to create a tabular dataset in a notebook with R kernel. The following code works with python kernel but how to do the same thing with R kernel ? Can anyone please help me ? Any help would be appreciated.\n\n from azureml.core import Workspace, Dataset\n  from azureml.core.dataset import Dataset\n        \n  subscription_id = 'abc'\n  resource_group = 'abcd'\n  workspace_name = 'xyz'\n        \n  workspace = Workspace(subscription_id, resource_group, workspace_name)\n        \n  dataset = Dataset.get_by_name(workspace, name='test')\n        \n        \n  # create tabular dataset from all parquet files in the directory\n  tabular_dataset_3 = Dataset.Tabular.from_parquet_files(path=(datastore,'\/UI\/09-17-2022_125003_UTC\/userdata1.parquet'))",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-19T07:14:55.407Z",
                "Answer_score":1,
                "Answer_body":"@Ankit19Gupta-9721 The Azure Machine Learning SDK for R was deprecated at the end of 2021 to make way for an improved R training and deployment experience using Azure Machine Learning CLI 2.0\nPlease refer the azureml SDK repo for more details which was deprecated at the end of last year. You can use CLI to register the dataset using specification file.\n\n\n\n az ml dataset register [--file]\n                        [--output-metadata-file]\n                        [--path]\n                        [--resource-group]\n                        [--show-template]\n                        [--skip-validation]\n                        [--subscription-id]\n                        [--workspace-name]\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure MLv2 CLI extension not recognized in DevOps",
        "Question_creation_time":1657302176180,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/919949\/azure-mlv2-cli-extension-not-recognized-in-devops.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"Having some trouble with one of our DevOps pipelines. In the pipeline, we install the Azure MLv2 CLI extension and then use the extension to make a call to our AzureML workspace. The pipeline was working fine yesterday, but now results in an error saying that 'ml' is misspelled or not recognized. There is an additional message about a name import that might be causing the issue. Here is the full error message:\n\nERROR: 'ml' is misspelled or not recognized by the system.\n\nExamples from AI knowledge base:\naz extension add --name anextension\nAdd extension by name\n\naz extension list-available\nList all publicly available extensions\n\nhttps:\/\/docs.microsoft.com\/en-US\/cli\/azure\/extension#az_extension_add\nRead more about the command in reference docs\ncannot import name 'case_insensitive_dict' from 'azure.core.utils' (\/opt\/az\/lib\/python3.10\/site-packages\/azure\/core\/utils\/init.py)\n\nAzure CLI Versions:\nWARNING: You have 2 updates available. Consider updating your CLI installation with 'az upgrade'\nazure-cli 2.37.0 *\n\n\n\n\nPlease let us know how we are doing: https:\/\/aka.ms\/azureclihats\ncore 2.37.0 *\nand let us know if you're interested in trying out our newest features: https:\/\/aka.ms\/CLIUXstudy\ntelemetry 1.0.6\n\nExtensions:\nml 2.5.0\nazure-devops 0.25.0\n\nDependencies:\nmsal 1.18.0b1\nazure-mgmt-resource 21.1.0b1\n\nPython location '\/opt\/az\/bin\/python3'\nExtensions directory '\/opt\/az\/azcliextensions'\n\nPython (Linux) 3.10.4 (main, May 23 2022, 14:03:08) [GCC 9.4.0]\n\nTrying to update the CLI version also results in an error",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-08T20:39:50.49Z",
                "Answer_score":0,
                "Answer_body":"In case anyone else is having issues with this, rolling the CLI back to 2.36.0 seems to be working",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-07-09T07:07:56.847Z",
                "Answer_score":0,
                "Answer_body":"I'm facing the same issue in Azure DevOps. My last successful test was on Tuesday 5th July, but on Friday 8th this error appeared.\n\nAs it is not easy to change the installed version on Microsoft or self-hosted agents, an other workaround is to install the version 2.4.1 of the az ml extension in place of the latest one.\n\n az extension add --name ml --version 2.4.1 --yes\n\n\n\n\nOne more thing, on the Azure Machine Learning CLI (v2) release notes, the version 2.5.0 is not listed.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-09-15T12:28:41.863Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nI am facing the same issue from today in Azure DevOps. The agent is ubuntu for me. Below is the error. Please help here. It has become a roadblock for us.\n\nmodule.azml_test.null_resource.azure-ml: Still creating... [30s elapsed]\nmodule.azml_test.null_resource.azure-ml (local-exec): WARNING: Unable to load extension 'azure-cli-ml: cannot import name 'case_insensitive_dict' from 'azure.core.utils' (\/opt\/az\/lib\/python3.8\/site-packages\/azure\/core\/utils\/init.py)'. Use --debug for more information.\nmodule.azml_test.null_resource.azure-ml (local-exec): WARNING: Command group 'config' is experimental and under development. Reference and support levels: https:\/\/aka.ms\/CLI_refstatus\n\nmodule.azml_test.null_resource.azure-ml (local-exec): WARNING: Unable to load extension 'azure-cli-ml: cannot import name 'case_insensitive_dict' from 'azure.core.utils' (\/opt\/az\/lib\/python3.8\/site-packages\/azure\/core\/utils\/init.py)'. Use --debug for more information.\nmodule.azml_test.null_resource.azure-ml (local-exec): ERROR: 'ml' is misspelled or not recognized by the system.\n\nmodule.azml_test.null_resource.azure-ml (local-exec): Examples from AI knowledge base:\nmodule.azml_test.null_resource.azure-ml (local-exec): az extension add --name anextension\nmodule.azml_test.null_resource.azure-ml (local-exec): Add extension by name",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-09-21T05:21:15.213Z",
                "Answer_score":0,
                "Answer_body":"Hi!\nI have the same problem:\n\"Unable to load extension 'azure-cli-ml: cannot import name 'CaseInsensitiveEnumMeta''. Use --debug for more information.\n'ml' is misspelled or not recognized by the system.\"\n\nVersions:\nazure-cli 2.22.1\ncore 2.22.1\ntelemetry 1.0.6\n\nExtensions:\nazure-cli-ml 1.41.0\nml 2.4.1\n\nDid you find a solution? Should I downgrade to any other version? If yes - which one?\n\nThanks for help!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"allow_reuse in Azure ml sdk v2",
        "Question_creation_time":1656438857840,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/906911\/allow-reuse-in-azure-ml-sdk-v2.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":1,
        "Question_body":"I am running a training pipeline on azure ml python sdk v2. It is running fine but when I am reinitiating it, it takes only 1 second to finish which I assume is taking previous step from last ran pipeline. In v1 sdk we have allow_reuse parameter to stop this behaviour. But how can we do that in ml python sdk v2.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-29T05:54:50.887Z",
                "Answer_score":1,
                "Answer_body":"Hello @rjtshrm ,\n\nThank you for posting query in Microsoft Q&A Platform.\n\nWe don't have allow_reuse flag in the v2. However, I would like to understand use case little more in details.\nDo you mind sharing why you want to rerun the step when everything is not changed (meaning the output would be exactly the same even if you rerun)?\nThere is a way to disable reuse behavior by setting \"is_deterministic: False\" for your component.\n\nRegards,\nPritee",
                "Answer_comment_count":5,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Databricks mlflow model serving networking",
        "Question_creation_time":1662480716897,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/996163\/databricks-mlflow-model-serving-networking.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":30,
        "Question_score":1,
        "Question_body":"Hi there, I'm trying to register a ML model to the mlflow model registry to be served from an Azure web app. I'm wondering if the databricks networking configuration will apply to the model api endpoint, as in, calls to the api from outside the VNET which the databricks is deployed to with private endpoints and disabled public access will be rejected and the call from within the vnet integrated web app will be successful?\n\nThank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-13T05:14:35.633Z",
                "Answer_score":1,
                "Answer_body":"Hello @ynh-9693,\n\nThanks for the question and using MS Q&A platform.\n\nI'm wondering if the databricks networking configuration will apply to the model api endpoint\n\nYes, it will. The single node cluster on which the model is hosted (classic), is deployed in data plane and will have a private IP.\n\n\nI should be able to call the model with the url <databricks-instance>\/model\/<registered-model-name>\/<model-version>\/invocations, my question is whether this url will have the same restrictions as the databricks where it resides\n\nI believe, this should work as long as you have not defined any IP access list. The PAT will let you authenticate.\n\nbut I can't find information for IP restrictions\n\nIP access lists - Azure Databricks | Microsoft Docs\n\nHope this will help. Please let us know if any further queries.\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is jhow you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"real-time inference pipeline failed to deploy for some unknown error and unable to view the logs",
        "Question_creation_time":1662748337977,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1001503\/real-time-inference-pipeline-failed-to-deploy-for.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"After submitting a successful inference pipeline, I attempted to deploy the model to a container instance. However, it failed and to make it worse I can't see the logs due to forbidden permissions error even though I am sole owner of resource group & instance. To put the nail on the coffin, I also can't view any related container instances inside Azure Portal...only the endpoints in ML studio.\n\nHere's the permissions error:\n\n ![{\n   \"error\": {\n     \"code\": \"Forbidden\",\n     \"message\": \"Forbidden\",\n     \"details\": [\n       {\n         \"code\": \"AuthorizationFailed\",\n         \"message\": \"The client 'df9ec36b-a97d-4c60-a6fe-91048565a571' with object id 'df9ec36b-a97d-4c60-a6fe-91048565a571' does not have authorization to perform action 'Microsoft.ContainerInstance\/containerGroups\/containers\/logs\/read' over scope '\/subscriptions\/7d36b75b-8fd4-4ef9-92fe-69f951afa25d\/resourceGroups\/playground\/providers\/Microsoft.ContainerInstance\/containerGroups\/playground-pipe-ommOzSbRhUSx8qiJGQ4HiA\/containers\/playground-pipe' or the scope is invalid. If access was recently granted, please refresh your credentials.\"\n       }\n     ]\n   },\n   \"correlation\": {\n     \"RequestId\": \"745ad382-74c0-4c67-8853-053807cd6336\"\n   }\n }][1]\n\n\n\n\n[1]: \/answers\/storage\/attachments\/239641-screenshot-2022-09-09-175802.png",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Facing Trouble with Evaluate Model in Azure Machine Learning Designer",
        "Question_creation_time":1662807677703,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1001826\/facing-trouble-with-evaluate-model-in-azure-machin.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":8,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi Everyone,\n\nI'm trying to run a MNIST prediction model on the ML Designer similar to the Image Classification sample given. All my components are working except the final evaluate model. It shows an error:\nazureml.studio.common.error.NotScoredDatasetError: There is no score column in dataset.\n\nThe scored dataset to the evaluate model component is exactly the same as given in the sample pipeline. I don't know what this issue is.\nCould anyone help me out with the same? I'll be thankful",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure ML real-time inference endpoint deployment stuck with deployment state as transitioning for over 2 hours",
        "Question_creation_time":1663182438927,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1007819\/azure-ml-real-time-inference-endpoint-deployment-s.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I have an AKS cluster and am trying to deploy a real-time inference pipeline to it as an endpoint. The deployment state is switching between \"Transitioning\" and \"Failed\" and I am unable to see any logs. My cluster is in West Central US.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Set MLflow Tracking to only track in your Azure Machine Learning workspace",
        "Question_creation_time":1656381127797,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/905516\/set-mlflow-tracking-to-only-track-in-your-azure-ma.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":18,
        "Question_score":0,
        "Question_body":"Hi Team,\n\nAs per below link\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-mlflow-azure-databricks?tabs=custom\n\nAnd section: Set MLflow Tracking to only track in your Azure Machine Learning workspace\n\nWe can set ML Flow Tracking URI to Azure ML in Databricks but i am getting below error upon setting and trying to create experiement\n\n\n\n\nUnsupportedModelRegistryStoreURIException: Model registry functionality is unavailable; got unsupported URI 'azureml:\/\/eastus.api.azureml.ms\/mlflow\/v1.0\/subscriptions\/60732f07-e07d-4492-b2cc-e43155932aca\/resourceGroups\/RG-BHOGA\/providers\/Microsoft.MachineLearningServices\/workspaces\/[REDACTED]' for model registry data storage. Supported URI schemes are: ['', 'file', 'databricks', 'http', 'https', 'postgresql', 'mysql', 'sqlite', 'mssql']. See https:\/\/www.mlflow.org\/docs\/latest\/tracking.html#storage for how to run an MLflow server against one of the supported backend storage locations.\n\nCould you please advise what has to be done?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-28T16:55:09.987Z",
                "Answer_score":0,
                "Answer_body":"@bhogasenareddykalakata-6505 Thanks for the question. Can you please share the notebook that you are trying. Here is the sample for ml flow tracking.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-07-26T18:41:36.383Z",
                "Answer_score":0,
                "Answer_body":"@bhogasenareddykalakata-6505, you probably forgot to install the plugin azureml-mlflow. This is required to interpret the URI and that's why you get the unsupported URI error.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure for students showing no usage despite using it",
        "Question_creation_time":1662893566663,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/1002201\/azure-for-students-showing-no-usage-despite-using.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":1,
        "Question_body":"Hello,\n\nI've created an azure for students account wiht $100 free credit and started using Azure Notebooks to train some ML models. I've created a GPU instance which costs $1.20\/hr. I've been using it for at least 1.5h now and what's weird is that no usage is being shown on my dashboard, and on the sponsorship page it's showing that it is not active and that I haven't used any of my credit:\n\n\n\n\nOn the other hand when I go to my subscriptions it says it's active:\n\nIs something wrong or does it take a while to see usage statistics\/credit spending?\n\nThanks in advance.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-11T13:58:24.207Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nUsually it is every 4 hours the data\/cost is updated so check after sometime, you can check and download the data by using and following the steps over here - download-azure-daily-usage\n\n\n\n\n\n==\nPlease \"Accept the answer\" if the information helped you. This will help us and others in the community as well.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-09-12T17:18:02.6Z",
                "Answer_score":0,
                "Answer_body":"Hi Ak,\n\nI will suggest you raise a support ticket for this issue how-to-create-azure-support-request\n\n\n\n\n\n==\nPlease \"Accept the answer\" if the information helped you. This will help us and others in the community as well.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"BatchARMResponseError when creating environment in AzureML Studio",
        "Question_creation_time":1662653924287,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/999600\/batcharmresponseerror-when-creating-environment-in.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I cannot create a new environment through the AzureML studio GUI - each time I reach \"create\" I receive this error. I previously was able to create environments and am not aware of any configuration changes since then. While the error initially says \"Service temporarily unavailable,\" it has been a week and is still not working.\n\nAny suggestions?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure ML: I'm quite new to Azure ML, I created a CI\/CD pipeline for my pytorch basedmachine learning model using azure. But since my model takes more than 60mins to train, I'm unable to train my machine learning model using CI pipeline.",
        "Question_creation_time":1662383691607,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/994546\/azure-ml-i39m-quite-new-to-azure-ml-i-created-a-ci.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I'm trying to train my Pytorch based machine learning model via azure CI pipeline. But since it takes more than 60mins to train, the CI pipeline fails. How can I train such huge model using azure CI pipeline. Additionally, I would like to use the GPU based cluster but I'm unable to do so. I have tried many workflows but failed every time.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Submitting a job using the Azureml SDK gives an error \"Execution failed in operation 'to_pandas_dataframe' for Dataset",
        "Question_creation_time":1636261062910,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/617861\/submitting-a-job-using-the-azureml-sdk-gives-an-er.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":13,
        "Question_score":1,
        "Question_body":"I am getting the above error and the runs are constantly failing. I have attached a screenshot of the code I am running. Script 180 runs fine if ran manually so I don't understand why when I run script 180 indirectly via script 170 it is throwing up an error about the to_pandas_dataframe() function. Everything is installed and I checked the version numbers so I need help understanding why it is failing.\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-08T09:43:08.587Z",
                "Answer_score":0,
                "Answer_body":"@94268751 Ideally, scriptrunconfig() is configured to run a training script while submitting an experiment by setting the config, datastore or inputs required for the experiment. In this case you are getting the configuration from az cli command instead of the config from JSON. In the first context when you run the script directly it is able to pickup the workspace and use the workspace to get get the required dataset or datastore and then perform the to_pandas_dataframe operation.\n\nIn the second case you are again setting the config inside the script after calling it from scriptrunconfig(), In this context the workspace is actually not returned in the 180 script with the form_config() command. It does not error out because the command itself is setting a null response. I feel the error only occurs in to_pandas_data_frame() operation because the operation needs data and all the above being set to null causes it to fail.\n\nI think you can consider merging your script to something as mentioned in this reference. A sample notebook to run on remote compute should also be helpful.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-04T04:38:16.643Z",
                "Answer_score":2,
                "Answer_body":"pandas is not getting imported automatically, you have to create pandas environment. Check the image for the code, it worked for me.\nJust add this extra line of code for creating environment in your \"170 - submit job.py\"",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Automated ML endpoint questions (performance, multiple return values, scoring)",
        "Question_creation_time":1662590602493,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/998394\/automated-ml-endpoint-questions-performance-multip.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi....\n\nI used Automated ML to train a model on a set of grouping ids and titles, very simple use case, just two columns...predict the group id from the title. There were about 32000 rows in the input split into a training set of 90% and a validation set of 10%. Best model was 'MaxAbsScaler, LogisticRegression'.\n\nI deployed the endpoint using the 'realtimeendpoint' method. But each request takes 10 seconds to return a response. I took the default ML compute type VM which isn't a wimpy machine. Is it normal to be so slow? Will better hardware get the response time into the sub-one-second time-frame I need it to be? Are there other options to improve performance?\n\n\nI only ever get back one value in the response. Is it possible to get multiple predicted values?\n\n\nI don't see a 'confidence' score in the response, or see a way to request one. Is that possible?\n\nThank you.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure ml notebook does not show widgets from ipywidgets",
        "Question_creation_time":1621085408217,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/396317\/azure-ml-notebook-does-not-show-widgets-from-ipywi.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"ipywidgets seems to work fine for the simplest usages, i.e. just using a slider. However, when trying to use more complex functionality the notebook does not show \/ display the widgets anymore.\n\nSee in the picture:\n\n\nThe simple usage\n\n widgets.IntSlider()\n\n\n\nworks fine.\nHowever, using ipywidget's interact does not show any widget:\n\n def f(x):\n     return x\n    \n interact(f, x=10)\n\n\n\nWhen I change the editor using the dropdown\n\n\nand use Jupyter or JupyterLab, everything works as expected without flaws.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-26T11:37:49.587Z",
                "Answer_score":0,
                "Answer_body":"@imbachb-2223 Thanks for the feedback. This specific type of ipywidget is currently not supported, we have roadmap to support in the future.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Creating Components in Azure ml throws an error after update, how do I resolve it?",
        "Question_creation_time":1661965347647,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/989198\/creating-components-in-azure-ml-throws-an-error-af.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":22,
        "Question_score":0,
        "Question_body":"Hey everyone,\nI was building components using YAML scripts and it worked pretty fine and everything was smooth as butter until I upgraded the az ml extension & az ml cli extension.\nMostly, reading the error responses helps, but here I am not at all able to debug or trace down into the depth to discover the cause of the issue.\n\nBelow is the snippet of the version of extensions and the errors that are popping up:\n\n\n\n\n\n\nFor the sake of reference, below is the snippet of yaml file of the component\n\n\nBelow is the snapshot of the conda file referenced in the above yaml file\n\n\nAnd below is the python script that executes for the corresponding component",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-07T13:15:33.133Z",
                "Answer_score":1,
                "Answer_body":"Hi @romungi-MSFT I had tried that as well and it didn't work.\nHere's what worked for me.\nUninstalling certain libraries as mentioned below:\n\n python -m pip uninstall azure-common\n python -m pip uninstall azure-storage\n python -m pip uninstall azure-nspkg\n python -m pip uninstall azure-storage-blob\n\nAnd then installing the azure ml storage blob again\n\n python -m pip install azure-storage-blob\n\n\n\nNot really sure what sense it makes but it worked out well, though still generating warnings",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"updating\/upgrading of Azure ML VM Operating System?",
        "Question_creation_time":1662553688820,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/997469\/updatingupgrading-of-azure-ml-vm-operating-system.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":30,
        "Question_score":0,
        "Question_body":"Currently in my Azure ML portal the OS version is\n\nNAME=\"Ubuntu\"\nVERSION=\"20.04.4 LTS (Focal Fossa)\"\n\nI need to update os version to Ubuntu 22.04 LTS\n\nIn azure, user can updating os version manually? or it is by default upgrading from Microsoft Azure?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-07T12:43:29.337Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nIt is a fully managed instance so you cannot update or install anything on the Azure ML instance you have.\n\n\n\n\n\n==\nPlease \"Accept the answer\" if the information helped you. This will help us and others in the community as well.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Why is the different components not grouped in the designer any more?",
        "Question_creation_time":1661248060107,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/978187\/why-is-the-different-components-not-grouped-in-the.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi, Guys,\nI'm new to Azure Ml, and when i started using the Designer, the different components where grouped.\nWhen you chose for example \"model scoring and evaluation\", and then all components related to that topic was there.\nNow it's like all components available is just listed in alphabetic order.\nWhat is the point with that change? and can i get the grouped components back?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-23T11:52:22.877Z",
                "Answer_score":0,
                "Answer_body":"@PedersenBjarke-7167 Yes, you could select the filter next to search and select Built-in to see the grouped components again.\nThe change allows users to view only the required modules or components and also filter then according to the available criteria. If you want to go back to the older view, simply select the built in assets only to group by functionality.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.\n\n\n\n\n\nRef: https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/972775\/change-in-machine-learning-designer.html",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Kubernetes \/ AKS cluster requirments for Azure ML Endpoints",
        "Question_creation_time":1660720523597,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/970235\/kubernetes-aks-cluster-requirments-for-azure-ml-en.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":21,
        "Question_score":0,
        "Question_body":"Hello,\n\nI'm trying to experiment with Azure ML Endpoints deployed to a Azure Kubernetes Service (AKS) cluster.\n\nRight now I'm able to attach AKS cluster(s) to Azure ML, from Compute \/ Inference Clusters.\n\nHowever, the no Kubernetes clusters are showing up nor in Endpoint Deployments, neither in the Attached Computes (see the screenshots bellow).\n\nI would like to now if there are any special requirements \/ additional steps needed for AKS cluster used with Azure ML endpoints. The AKS cluster I'm using is 3 nodes, each with 4 vCPU and 16 GB RAM.\n\nEndpoint(s):\n\n\nAttached Compute(s):\n\n\nThanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-24T05:29:49.9Z",
                "Answer_score":0,
                "Answer_body":"@Attila-3020 I feel the error is most likely an issue with the AKS cluster setup. I see the following in the log:\n\n \"aksAssignedIdentity\":null\n\n\n\nI don't have a lot of experience with AKS setup issues, but I feel this could be the issue here. As per AKS documentation there is an option to update to system assigned managed identity.\n\n az aks update -g <RGName> -n <AKSName> --enable-managed-identity\n\nIf this still does not work I think it would be easier to review the setup through a support case so the service team could advise what could be wrong with your subscription.\n\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"In AzureML, start_logging will start asynchronous execution or synchronous execution?",
        "Question_creation_time":1659982904493,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/959540\/in-azureml-start-logging-will-start-asynchronous-e.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":24,
        "Question_score":0,
        "Question_body":"It was written in the Microsoft AzureML documentation, \"A run represents a single trial of an experiment. Runs are used to monitor the asynchronous execution of a trial\" and A Run object is also created when you submit or start_logging with the Experiment class.\"\n\nRelated to start_logging, as far as I know, when we have simply started the run by executing this start logging method. We have to stop, or complete by complete method when the run is completed. This is because start_logging is a synchronized way of creating an experiment. However, Run object created from start_logging is to monitor the asynchronous execution of a trial.\n\nCan anyone clarify whether start_logging will start asynchronous execution or synchronous execution?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-09T06:55:25.043Z",
                "Answer_score":0,
                "Answer_body":"@MoZein-9081 start_logging will create a run object similar to experiment.submit() but in the case of start_logging you can create an interactive logging session and create an interactive run in the specified experiment and in either case, the logging methods on the returned run object work the same.\n\nFor example,\n\n run = exp.start_logging() #Will give you the context of run object directly\n run_id = run.id # access the run id for use later\n Run = experiment.submit() \n run = Run.get_context() #To access the current run context of your code\n\n\n\n\nI think this notebook explains the usage of logging better in this context.\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Failed to test real-time endpoint request() got an unexpected keyword argument 'tenant_id'",
        "Question_creation_time":1660588808613,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/967753\/failed-to-test-real-time-endpoint-request-got-an-u.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":27,
        "Question_score":0,
        "Question_body":"Hi all,\nafter deployment of real time endpoint I try to test it by pinging. For now my run is minimal and looks like this:\ndef run(raw_data):\n\"\"\"\nThis function is called for every invocation of the endpoint to perform the actual scoring\/prediction.\nIn the example we extract the data from the json input and call the scikit-learn model's predict()\nmethod and return the result back\n\"\"\"\nlogging.info(\"Request received\")\n\n     KVUri = f\"<<endpoint url here>>\"\n    \n     credential = ManagedIdentityCredential()\n     client = SecretClient(vault_url=KVUri, credential=credential)\n     retrieved_secret = client.get_secret(\"test-secret\")\n    \n     logging.info(\"Request processed\")\n     return [retrieved_secret]\n\nAfter pinging I just get an error:\n\nFailed to test real-time endpoint\nrequest() got an unexpected keyword argument 'tenant_id'\n\nSomebody mentioned that this might be something that was fixed in later verisions of azure identity library. My conda currently looks like this:\n\n name: model-env\n channels:\n   - conda-forge\n dependencies:\n   - python=3.7\n   - numpy=1.21.2\n   - pip=21.2.4\n   - scikit-learn=0.24.2\n   - scipy=1.7.1\n   - pip:\n     - azureml-defaults==1.39.0\n     - inference-schema[numpy-support]==1.3.0\n     - joblib==1.0.1\n     - azure-identity\n     - azure-keyvault-secrets\n\n\n\n\nUnfortunately, getting never azure-identity seems to require newer python. Unfortunately - I did not manage to make an endpoint even deploy with python 3.8\/3.9.\nDoes anybody have a suggestion on how to fix it?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-16T10:39:04.163Z",
                "Answer_score":0,
                "Answer_body":"@MateuszMacias-3397 Thanks for the question. Can you please try Installing azure-identity>=1.8.0.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"DataDrift in AzureML",
        "Question_creation_time":1659816958003,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/957739\/datadrift-in-azureml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi, What is the underlying algorithm for azureml DataDriftDetector class? and what is the mathematical implication of the threshold in datadrift?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-09T03:15:57.817Z",
                "Answer_score":0,
                "Answer_body":"@AmoozegarShahrzad-3484 Thanks for the question. Concept Drift Detection Methods:\nApproaches to Drift Detection:\n\n\nwe will pivot to focusing on detecting drift in Data \u2013 regardless of what it is, where it came from. Our prereq becomes usage of TimeSeriesDataset, which is a low bar for entry.\ndatadrift = DataDriftDetector.create(ws, baseline=tsd.timerange(start, end), target=tsd)\nHere is the document for Detect data drift (preview) on datasets.",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Newly released based image for Azure Machine Learning contains medium- and high-level security vulnerabillities",
        "Question_creation_time":1659575906903,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/954345\/newly-released-based-image-for-azure-machine-learn.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hi,\n\nWe are currently using the latest (as of 4 Aug 2022) container based image released by Microsoft for our AML workloads: mcr.microsoft.com\/azureml\/openmpi4.1.0-ubuntu20.04:20220729.v1 (https:\/\/github.com\/Azure\/AzureML-Containers\/blob\/master\/base\/cpu\/openmpi4.1.0-ubuntu20.04\/release-notes.md).\n\nHowever, this image contains the following security vulnerabilities:\n\n\n\n\n\n\nWe would like to know if it's possible to resolve them (we are not sure how to implement the remedy provided).\nIn our company, vulnerable container registry images would be deleted automatically - hence it's important for us to know how to make the image secure.\n\nThanks!",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Is Azure supporting distributed GPU?",
        "Question_creation_time":1661977194510,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/989398\/is-azure-supporting-distributed-gpu.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Is there any plan? Any date we can expect?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-05T02:34:31.897Z",
                "Answer_score":0,
                "Answer_body":"Hello @nam-4027\n\nI hope yo are doing well. We have multiple options for Distributed GPU for Azure Machine Learnig for SDK v1 as below -\nMessage Passing Interface (MPI)\nHorovod\nDeepSpeed\nEnvironment variables from Open MPI\nPyTorch\nProcess group initialization\nLaunch options\nDistributedDataParallel (per-process-launch)\nUsing torch.distributed.launch (per-node-launch)\nPyTorch Lightning\nHugging Face Transformers\nTensorFlow\nEnvironment variables for TensorFlow (TF_CONFIG)\nAccelerate GPU training with InfiniBand\n\nFor V2 there should be big change. Please feel free to let us know any problems. Thanks.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-08-31T20:32:46.857Z",
                "Answer_score":0,
                "Answer_body":"Hi Nam,\n\nDo you mean by distributed GPU for ML or specific to Azure ? Here is the link related to Azure GPU - how-to-train-distributed-gpu\n\n\n\n\n\nIf it is something else, please reply so I can have a look.\n\n==\nPlease \"Accept the answer\" if the information helped you. This will help us and others in the community as well.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"certification test for AI-900: Microsoft Azure AI Fundamentals not available",
        "Question_creation_time":1662205880130,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/992629\/exam-ai-900-microsoft-azure-ai-fundamentals-not-av.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hallo, i would like make an appointment for Exam AI-900: Microsoft Azure AI Fundamentals.\nHowever this exam is currently not available at Pearson vue or Certiport. When can i expect this again? Is there an alternative ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-03T13:15:33.98Z",
                "Answer_score":0,
                "Answer_body":"Hi Jurian,\n\nThis is available in PearsonVue check this. ai-900\n\nAny specific region you are trying from?\n\n\n\n\n\n==\nPlease \"Accept the answer\" if the information helped you. This will help us and others in the community as well.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Machine Learning migration",
        "Question_creation_time":1647272307493,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/771467\/machine-learning-migration.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"now I would like to migrate the machine learning component from 'dev environment' to 'prd environment', may I know how I can do step by step\uff0c thanks\u3002",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-14T21:50:18.747Z",
                "Answer_score":0,
                "Answer_body":"Hello @SeiyaSum-3219\n\nThanks for reaching out to us. I think you are mentioning how to register and reuse your Azure Machine Learning Component. Components are automatically shared with users in the same workspace. You can reuse components across pipelines, environments, workspaces, and subscriptions. Built-in version-tracking lets you keep track of changes and reproduce results.\n\nTo do that, you need to register your created component as below guidance and reuse your component by changing the YAML file.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-component-pipelines-cli#register-components-for-reuse-and-sharing\n\nHope this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-09-02T12:33:59.81Z",
                "Answer_score":1,
                "Answer_body":"With Azure Machine Learning Service, once the data scientist builds a satisfactory model, the trained model can be easily put into production and monitored.\n\nThe following diagram illustrates the complete deployment workflow (compare Amazon AWS with Microsoft Azure):\n\nAmazon AWS:\n\nMicrosoft Azure:\n\nKeep in mind the workspace, which represents a central location for a team to collaborate and it manages access to compute targets, data storage, models created, docker images created, webservices deployed and it keeps track of all the experiment runs that were performed with it. Data scientists can manage the authorization and creation of workspaces and experiment from the Python SDK.\n\nBasically, you should perform the following steps:\n\nRegister the model in a registry hosted in your Azure Machine Learning Service workspace\n\n\nRegister an image that pairs a model with a scoring script and dependencies in a portable container\n\n\nDeploy the image as a web service in the cloud or to edge devices",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Issue with data lake mounting in custom RStudio application Azure ML",
        "Question_creation_time":1661155798650,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/976098\/install-rstudio-application-in-azure-ml-vm.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"previously while creating a compute instance we were able to see RStudio application by default and we were able to mount\/access the data lake from RStudio.\n![compute creation][1]\n\n\n\n\n![Data lake mont][2]\n2. In current situation we are not able to access RStudio application by default.\n![234345-4.png][3]\n3.with the help of below link we are able to create custom RStudio application\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance?tabs=azure-studio\n![custom RStudio app][4]\n\n4.In custom RStudio we are not able to mount\/access the data lake.\n\n![missing data lake][5]\n\nIs there way to mount\/access the data lake in custom RStudio app\n[1]: \/answers\/storage\/attachments\/234344-screenshot-2022-08-23-170502.png\n[2]: \/answers\/storage\/attachments\/234353-5.png\n[3]: \/answers\/storage\/attachments\/234345-4.png\n[4]: \/answers\/storage\/attachments\/234314-2.png\n[5]: \/answers\/storage\/attachments\/234361-3.png",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-23T02:41:16.113Z",
                "Answer_score":0,
                "Answer_body":"@alifshaikh-6049 Thanks for the question. Here is the snapshot for using the Rstudio from ml.azure.com\n\n\nHere is the sample to train Rmodel.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning - Python SDK - Create Workspace with existing resources",
        "Question_creation_time":1661014342310,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/975103\/azure-machine-learning-python-sdk-create-workspace.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"This article shows you how to create a workspace with the Python SDK\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace?tabs=python#create-a-workspace\n\nFor some reason the existing resources are added to the ServicePrincipalAuthentication, but I think this is a mistake and should be added to the Workspace.Create function.\nBut when I try to add the existing Azure resource IDs to the Create function I get a non descriptive error. Can someone show a working example of how to create a workspace (including a new resource group) programmatically with existing resources (in another resource group), like a Key Vault, Azure Container Registry and Storage Account?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-22T17:50:51.913Z",
                "Answer_score":0,
                "Answer_body":"@JIren-1543 Thanks for the question. it's a duplicate of the following github question for creating workspace..\nhttps:\/\/github.com\/MicrosoftDocs\/azure-docs\/issues\/97360",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning - Train model with DockerFile and any other files needed to build the image",
        "Question_creation_time":1660640861417,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/968696\/azure-machine-learning-train-model-with-dockerfile.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hello, I am trying to train a model using azureml.core using my own custom Dockerfile. However my Dockerfile depends on a configuration file, so it needs to Copy this file when it is build.\nWhen I run my experiment I get an error saying it can't find my config.yml file while building the docker file. How do I add a file to my docker environment build context?\n\nI have the following setup to build my environment\n\n from azureml.core import Workspace\n from azureml.core import Experiment\n from azureml.core.environment import Environment\n import os\n import shutil\n    \n ws = Workspace.from_config()\n exp = Experiment(workspace=ws, name=\"tfrs-test-experiment\")\n    \n env = Environment('tfrs-test-env')\n    \n env.docker.base_image = None\n env.docker.base_dockerfile = os.path.join('..', 'Dockerfile')\n ### NOT WORKING\n shutil.copy(os.path.join('..', 'config.yml'), os.getcwd())\n ###\n    \n env.register(workspace = ws)\n ### CODE TO BUILD COMPUTE CLUSTER\n  ...\n ###\n from azureml.core import ScriptRunConfig\n    \n src = ScriptRunConfig(source_directory=os.path.join('..', 'src'),\n                       script='tfrs-recsys.py', \n                       compute_target=compute_target,\n                       environment=env)\n run = exp.submit(config=src)\n run\n    \n from azureml.widgets import RunDetails\n RunDetails(run).show()\n    \n # specify show_output to True for a verbose log\n run.wait_for_completion(show_output=True)",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-17T12:38:57.757Z",
                "Answer_score":0,
                "Answer_body":"@JIren-1543 Thanks for the question. Here is the document for the custom docker image.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-custom-container#create-a-yaml-file-for-your-endpoint-and-deployment",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"YOLO v5 in azure",
        "Question_creation_time":1661985450753,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/989581\/yolo-v5-in-azure.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi, does Azure Machine Learning support YOLOv5? How we can import it?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-09-01T17:27:32.523Z",
                "Answer_score":0,
                "Answer_body":"Hello @matsuoka-4412\n\nMore info about YOLO v5 could be found here - https:\/\/github.com\/ultralytics\/yolov5\n\nMicrosoft currently has no official docs about YOLO v5 but you can surely use it in Azure environment as guidance above. I will reach out to product team to see how we can leverage YOLO v5 more but please let us know if you have more question during the time you working on your project.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure ML Endpoint-Deploy as Webservice Greyed out",
        "Question_creation_time":1661970732707,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/989371\/azure-ml-endpoint-deploy-as-webservice-greyed-out.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-31T21:06:04.857Z",
                "Answer_score":0,
                "Answer_body":"Hello @DomsohnKyle-2610\n\nThanks for using Microsoft Q&A platform. As you see, the \"Deploy to web service\" option has been upgrade to two new options -\n\"Deploy to real-time endpoint\" and \"Deploy to batch endpoint\"\n\nFor more information about the two new options, please refer to this page - https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-endpoints\n\nI hope this helps! Those new options make thing easier. Please feel free to use this forum if you have any further questions.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-09-01T13:17:06.07Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nI have been trying to get the \"Deploy to real-time endpoint\" option to work but the deployment keeps failing with the error below:\n\n{\"code\":\"DeploymentFailed\",\"message\":\"At least one resource deployment operation failed. Please list deployment operations for details. Please see https:\/\/aka.ms\/DeployOperations for usage details.\",\"details\":[{\"code\":\"InferencingClientCreateDeploymentFailed\",\"message\":\"InferencingClient HttpRequest error, error detail: \\\"No Environment was provided. Environment is required for custom model formats.\\\"\"}]}\n\nAlthough, when I create deployments I have option to select an environment.\n\n\n\n\n\n\nThanks,\nKyle",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Very slow execution time with NC6_Standart",
        "Question_creation_time":1661975240997,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/989386\/very-slow-execution-time-with-nc6-standart.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hello,\nIn Azure ML, I created an NC6_Standart instance in order to have GPU. In order to familiarize myself with the cloud, I decide to run this (which is actually in a microsoft tutorial) https:\/\/github.com\/MicrosoftDocs\/tensorflowfundamentals\/blob\/main\/intro-keras\/kintro.py on my pc it takes about 2~3 minutes to do 100 epochs (with 2ms\/step), from the documentation sandbox about 3 minutes also with 2ms\/step but from the NC6 instance it takes 8 minutes BUT with 2ms\/step. In fact, it is the time between each epoch that is long. Would you have a solution?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"SDK v1 or V2",
        "Question_creation_time":1661977244390,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/989368\/sdk-v1-or-v2.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"We are planing for next gen of product. Will V2 provide way more changes than V1?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-31T21:32:40.817Z",
                "Answer_score":0,
                "Answer_body":"Hello @nam-4027\n\nThanks for using Microsoft Q&A. I will recommend you keeping in V1 at this moment.\n\nSDK v2 is currently in public preview. The preview version is provided without a service level agreement, and it's not recommended for production workloads. Certain features might not be supported or might have constrained capabilities. For more information, see Supplemental Terms of Use for Microsoft Azure Previews.\n\nhttps:\/\/azure.microsoft.com\/support\/legal\/preview-supplemental-terms\/\n\nI hope this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Descriptors cannot not be created",
        "Question_creation_time":1661977116463,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/989409\/descriptors-cannot-not-be-created.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"This error message is super confusing, what does it mean?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-31T21:19:30.76Z",
                "Answer_score":0,
                "Answer_body":"Hello @matsuoka-4412\n\nThanks for using Microsoft Q&A platform. This problem is caused by breaking changes introduced in protobuf 4.0.0. For more information, see https:\/\/developers.google.com\/protocol-buffers\/docs\/news\/2022-05-06#python-updates.\n\nPlease refer to this troubleshooting guidance - https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-protobuf-descriptor-error\n\nI hope it helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Endpoint \"predict-auto-price\" deployment failed",
        "Question_creation_time":1661430065143,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/981735\/endpoint-34predict-auto-price34-deployment-failed.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I'm following the \"Exercise - Explore regression with Azure Machine Learning designer\"\n\nI've redone this exercise twice following all the instructions perfectly!\n\nOn the \"Deploy a service\" section in the exercise, I've tried it over 7 times:\n\n4. In the configuration screen, select Deploy a new real-time endpoint, using the following settings:\n\nName: predict-auto-price\nDescription: Auto price regression\nCompute type: Azure Container Instance\n\nIt always fails with \"Endpoint \"predict-auto-price\" deployment failed\"\n\nAnd nothing comes up in the Deployment Logs.\nPlease help! I'm out of idea's\n\n\"\"",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-26T11:10:26.997Z",
                "Answer_score":1,
                "Answer_body":"@MervynKing-2075 Do you see any new jobs added on the jobs tab when your deployment fails? Usually, there is a drop down that loads on the Deployment logs tab to select the Deployment. But, I dont see that on your page. It looks like the page might not have loaded completely. You can also report the issue using the smiley icon on the top right corner with a screen shot of this page.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-08-31T17:46:02.323Z",
                "Answer_score":0,
                "Answer_body":"When you are deploying, you must increase CPU reserve capacity to 0.5. I think the default value of 0.1 is not enough for the predictive service deployment.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Multiple Inputs to a Single Port while creating component.",
        "Question_creation_time":1661875118607,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/987589\/multiple-inputs-to-a-single-port-while-creating-co.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hi there,\nI am creating custom components using yaml scripts containing my reusable code in python scripts.\n\nI want to create one component with a single input port that could handle multiple inputs at a time, i.e take the outputs of multiple components within the single component.\n\nfor example in the image above, i want the final component to take in the output not only from 'Component Models - Random Forest Regression', but should also take output of 'Component Models - Arima' within the same input port of 'Component Aggregate'\n\nThe Yaml script for component Aggregate is below:\n\nThe python script for the same is below:",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"AzureML: In Batch Endpoints can we use a tuple(two file paths from different folders) as input?",
        "Question_creation_time":1661847830690,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/986878\/azureml-in-batch-endpoints-can-we-use-a-tupletwo-f.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I'm a novice to Azure and Azure ML, I'm trying to create a batch endpoint and in most of the documentation I found it was mentioned that the input to the batch endpoint would be a file path. In my case I was to connect the endpoint to two blobstorage and get a tuple as input to the batch endpoint. Is it possible? If not is there any other work around as my model takes as input path to two files.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-31T03:04:05.907Z",
                "Answer_score":0,
                "Answer_body":"Hello @SamarjeetSinghPatil-6739\n\nThanks for using Microsoft Q&A platform! I am sorry you can not use multiple resource as one input for one job, but you can do it in separate jobs.\n\nAn alternative way\/ workaround for you is a FileDataset, you can put your resource into one dataset and then input it.\n\nFileDataset -\nRepresents a collection of file references in datastores or public URLs to use in Azure Machine Learning.\nA FileDataset defines a series of lazily-evaluated, immutable operations to load data from the data source into file streams. Data is not loaded from the source until FileDataset is asked to deliver data.\nA FileDataset is created using the from_files method of the FileDatasetFactory class.\nFor more information, see the article Add & register datasets. To get started working with a file dataset, see https:\/\/aka.ms\/filedataset-samplenotebook.\n\nReference - https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.filedataset?view=azure-ml-py\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-batch-endpoints-studio#start-a-batch-scoring-job-with-different-input-options\n\nI hope it helps!\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Invitation to join Microsoft Community Champions Program - Azure",
        "Question_creation_time":1661847000993,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/986864\/invitation-to-join-microsoft-community-champions-p-1.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":0,
        "Question_follower_count":80,
        "Question_score":10,
        "Question_body":"Are you a Microsoft Azure Technology Expert? Do you resonate with the idea of using your skills to help customers, create Impact and also get recognized?\n\nIf your answer is yes \u2013 you have an opportunity to be part of the Microsoft Azure Community Champions family! This is a thriving community of 100+ members made of Microsoft employees, MVPs, Suppliers, and other experts who enjoy solving latest customer problems in Microsoft Q&A technical site and thereby learn hands-on.\n\nFor your voluntary contributions you can also receive exciting rewards and recognitions which includes monthly $50 gift cards, being featured on Microsoft branded social media & leaderboards, considerations for Microsoft MVP award, Microsoft NDA with Private Preview access and more.\n\nVisit Microsoft Community Champions for Q&A | Microsoft Docs to learn more and become an Azure Community Champion!\n\nSee you on the other side!!\n\nSpecial invitation to:\n\n@Bruce-SqlWork @Prasad-MSFT @Chungsun-1776 @SrikanthRana @67603284 @LimitlessTechnology-2700 @Alexandre-4252 @ealmuneyeer-MSFT @Nivedipa MSFT-6619 @PriteeBhuyan-MSFT @DavidBristol-1279 @Sayali-MSFT-0291 @Yukimaru123 @Alexandre-2525 @AzureAaronHughes @sadomovalex @sidramadoss @ZoeHui-MSFT @32213614 @35247258 @54720164 @akiotatako-3558 @ChristopherGeckert-7726 @HarryArthur-7261 @HediaRiahi-4975 @ItaiNorman-6771 @JonPayne-8781 @Lawrence080-MSFT @lextm @maximebmsft @michael84 @MikeC-5683 @OlafHelper-2800 @psrsekhar @RyanAbbey-0701 @seanma @SubashriVasudevan-3801 @TKujala @tmm1 @Yufeishao-msft\n\nThank You to all the Microsoft Q&A Community Champions.\nThey are helping make Microsoft Q&A a vibrant place for learning.\n\n@AlbertoMorillo @ManuPhilip @DillonJS @martins-jackson @DavidBroggy-5270 @soysoliscarlos @KamleshKumar @JimmySalian-2011 @ricardosolisvillegas-4678 @NandanHegde-7720 @AndreasBaumgarten @AndyDavid @SubashriVasudevan-1752 @maserg @AndrewBlumhardt-1137 @AlanKinane @michev @SandervandeVelde42 @CristianSPIRIDON72 @BjoernPeters @BrunoLucas-9843 @MohammedAltamashKhan-3285 @msrini-MSFT @DSPatrick @ErlandSommarskog @Samy-7940 @AndriyBilous @shivapatpi-MSFT @stan @rbrundritt @TakahitoIwasa @pituach @Sam-Cogan @PratikSomaiya @sikumars @sreejukg",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Data Science Learning Path",
        "Question_creation_time":1596221270310,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/56400\/data-science-learning-path.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"What are the learning paths in MS Learn for Data Science, Machine Learning, Deep Learning with Python as the base programming language",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-31T18:49:16.097Z",
                "Answer_score":0,
                "Answer_body":"MVA learning is not currently supported here on QnA. They're actively answering question in dedicated forums here.\nhttps:\/\/trainingsupport.microsoft.com\/en-us\/\n\n--please don't forget to Accept as answer if the reply is helpful--",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-31T20:11:25.957Z",
                "Answer_score":0,
                "Answer_body":"Thanks for reaching out. On the Microsoft Learn page, you can browse learning paths and apply appropriate filters to select learning path for Data Science. You can also apply additional filters based on your learning goals. Hope this helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-08-01T06:11:06.997Z",
                "Answer_score":1,
                "Answer_body":"Below certification also be good\n\nhttps:\/\/docs.microsoft.com\/en-us\/learn\/certifications\/azure-data-scientist",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-08-01T09:06:24.963Z",
                "Answer_score":1,
                "Answer_body":"Hello AnupamDey\n\nI'm Vriz Zhang. I've compiled some content that you may be interested in Microsoft Learn as follows:\n\nData science Click Here\nMachine learning Click Here\nPython Click Here and Additional recommendations beyond the Microsoft Learning website Python.Org\nC# Click Here\nSQL Click Here\n\nHopefully what I suggest. It will be useful for You and others, more or less.\nIf you require any further information, feel free to contact me.\nFacebook : Vriz Zhang",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Two Class Decision Forest - Evaluate Results with Own Test Dataset?",
        "Question_creation_time":1659565398167,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/954252\/two-class-decision-forest-evaluate-results-with-ow.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi - can you train the Azure Two Class Decision Tree forest with a training data set you upload, then test it with a different data set that you upload rather than letting Azure do the random splitting into train and test?\n\nThank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-04T16:23:52.697Z",
                "Answer_score":0,
                "Answer_body":"@DunleavyLisa-8881 Thanks for the question. Yes, you can do the two-class decision forest using the azure ML SDK.\n\nHere is the document to upload and train data.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Models registered with AML CLI cause ACI deployments to fail",
        "Question_creation_time":1634746520717,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/597710\/models-registered-with-aml-cli-cause-aci-deploymen.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":11,
        "Question_score":1,
        "Question_body":"We were registering a local file ts_scalar.pickle as a model using AML CLI's create az model create -n test-model -l .\/ts_scalar.pickle ...\nThis registered model test-model works fine when deployed to a LocalWebService, but does not work for a AciWebService.\nWe either get a timeout during the deployment (does not reach stage where containers start running) or this error:\n\n Traceback (most recent call last):\n   File \".\/download.py\", line 353, in <module>\n     init_container_assets(args.config_json, args.conn_string, args.container, args.appinsights_key, args.config_folder)\n   File \".\/download.py\", line 327, in init_container_assets\n     downloader.download(config_file_content)\n   File \".\/download.py\", line 128, in download\n     self.download_artifact(blob_path, local_path, unpack_type)\n   File \".\/download.py\", line 92, in download_artifact\n     file_path=local_path)\n   File \"\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/blob\/baseblobservice.py\", line 2014, in get_blob_to_path\n     cpk=cpk)\n   File \"\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/blob\/baseblobservice.py\", line 2193, in get_blob_to_stream\n     raise ex\n   File \"\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/blob\/baseblobservice.py\", line 2160, in get_blob_to_stream\n     cpk=cpk)\n   File \"\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/blob\/baseblobservice.py\", line 1887, in _get_blob\n     operation_context=_context)\n   File \"\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/common\/storageclient.py\", line 446, in _perform_request\n     raise ex\n   File \"\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/common\/storageclient.py\", line 374, in _perform_request\n     raise ex\n   File \"\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/common\/storageclient.py\", line 360, in _perform_request\n     HTTPError(response.status, response.message, response.headers, response.body))\n   File \"\/usr\/local\/lib\/python3.6\/site-packages\/azure\/storage\/common\/_error.py\", line 115, in _http_error_handler\n     raise ex\n azure.common.AzureMissingResourceHttpError: The specified blob does not exist. ErrorCode: BlobNotFound\n <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>BlobNotFound<\/Code><Message>The specified blob does not exist.\n RequestId:59b52a82-301e-005a-51c8-c52ce4000000\n Time:2021-10-20T15:40:04.2703282Z<\/Message><\/Error>\n\n\n\nHowever if we register the model through AML's UI model registration, both kinds of deployments are successful.\n\nIs there an issue with using the CLI to register models for ACI deployment?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-26T06:56:37.237Z",
                "Answer_score":0,
                "Answer_body":"Any Update on this? I am having the same issue?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"azureml-core 1.44.0 fails to deploy model to webservice",
        "Question_creation_time":1661413994937,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/981325\/azureml-core-1440-fails-to-deploy-model-to-webserv.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"azureml-core\n\n\n1.44.0\n\n\nconda virtualenv (compute instance):\n\n\nAzure Machine Learning\n\n\nML\n\nDescribe the bug\nModel fails to deploy when I run the deployment code in Azure Notebook using virtualenv with azureml-core 1.44.0\n\nIt works just fine with older version (1.43.0) or the default Python 3.8 - Azure ML that uses 1.42.0 at the moment.\n\nThe output:\n\nRunning\n2022-08-25 07:03:20+00:00 Creating Container Registry if not exists.\n2022-08-25 07:03:20+00:00 Registering the environment.\n2022-08-25 07:03:21+00:00 Use the existing image.\n2022-08-25 07:03:22+00:00 Generating deployment configuration.\n2022-08-25 07:03:23+00:00 Submitting deployment to compute.\n2022-08-25 07:03:30+00:00 Checking the status of deployment heart-disease-classification-env..\n2022-08-25 07:05:44+00:00 Checking the status of inference endpoint heart-disease-classification-env.\nFailed\nService deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: 3a980ad2-890e-4e8a-91d6-c119bd0528a4\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n    1. Please check the logs for your container instance: heart-disease-classification-env. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n    2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n    3. You can also try to run image 237a7cc8f2c84e1287a6cc08d5e54f9f.azurecr.io\/azureml\/azureml_09e362cde9760a4b66987389c8bbc20a locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n    1. Please check the logs for your container instance: heart-disease-classification-env. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n    2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n    3. You can also try to run image 237a7cc8f2c84e1287a6cc08d5e54f9f.azurecr.io\/azureml\/azureml_09e362cde9760a4b66987389c8bbc20a locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"AciDeploymentFailed\",\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\n    1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.\n    2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.\n    3. You can also interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n    4. View the diagnostic events to check status of container, it may help you to debug the issue.\n\"RestartCount\": 3\n\"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n\"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2022-08-25T07:07:34.619Z\",\"exitCode\":111,\"finishTime\":\"2022-08-25T07:07:48.858Z\",\"detailStatus\":\"Error\"}\n\"Events\":\n{\"count\":1,\"firstTimestamp\":\"2022-08-25T07:03:36Z\",\"lastTimestamp\":\"2022-08-25T07:03:36Z\",\"name\":\"Pulling\",\"message\":\"pulling image \"237a7cc8f2c84e1287a6cc08d5e54f9f.azurecr.io\/azureml\/azureml_09e362cde9760a4b66987389c8bbc20a@sha256:7650a3f19eb4803881637a920dc3e9bf9837c0e9c492b7d22be840d0ba8cb1cf\"\",\"type\":\"Normal\"}\n{\"count\":1,\"firstTimestamp\":\"2022-08-25T07:05:15Z\",\"lastTimestamp\":\"2022-08-25T07:05:15Z\",\"name\":\"Pulled\",\"message\":\"Successfully pulled image \"237a7cc8f2c84e1287a6cc08d5e54f9f.azurecr.io\/azureml\/azureml_09e362cde9760a4b66987389c8bbc20a@sha256:7650a3f19eb4803881637a920dc3e9bf9837c0e9c492b7d22be840d0ba8cb1cf\"\",\"type\":\"Normal\"}\n{\"count\":4,\"firstTimestamp\":\"2022-08-25T07:05:37Z\",\"lastTimestamp\":\"2022-08-25T07:07:34Z\",\"name\":\"Started\",\"message\":\"Started container\",\"type\":\"Normal\"}\n{\"count\":4,\"firstTimestamp\":\"2022-08-25T07:05:54Z\",\"lastTimestamp\":\"2022-08-25T07:07:48Z\",\"name\":\"Killing\",\"message\":\"Killing container with id 54971cd5cf0e6de46f30bd592bea94752d4ad857fb32f6d85e33b3a8bd4e4c92.\",\"type\":\"Normal\"}\n\"\n    }\n  ]\n}\n\n\n\n\nTo Reproduce\nSteps to reproduce the behavior:\n1. I use the standard heart-diseaase dataset, train the model and export it to model\/hd_otr.pkl\n2. In assets folder I store the outlierremover.py script that I use to remove outliers:\n\nimport pandas as pd\nfrom sklearn.base import BaseEstimator, TransformerMixin\nclass OutlierRemover(BaseEstimator, TransformerMixin):\n    def __init__(self, factor=1.5):\n        self.factor = factor\n        \n    def outlier_detector(self, X, y=None):\n        X = pd.Series(X).copy()\n        q1 = X.quantile(0.25)\n        q3 = X.quantile(0.75)\n        iqr = q3 - q1\n        self.lower_bound.append(q1 - (self.factor * iqr))\n        self.upper_bound.append(q3 + (self.factor * iqr))\n    def fit(self,X,y=None):\n        self.lower_bound = []\n        self.upper_bound = []\n        X.apply(self.outlier_detector)\n        return self\n    \n    def transform(self, X, y=None):\n        X = pd.DataFrame(X).copy()\n        for i in range(X.shape[1]):\n            x = X.iloc[:, i].copy()\n            x[(x < self.lower_bound[i])] = self.lower_bound[i]\n            x[(x > self.upper_bound[i])] = self.upper_bound[i]\n            X.iloc[:, i] = x\n        return X\n    \noutlier_remover = OutlierRemover()\n\n\n\n\nand score.py file:\n\nimport joblib\nfrom azureml.core.model import Model\nimport json\nimport pandas as pd\nimport numpy as np\nfrom outlierremover import OutlierRemover\nfrom inference_schema.schema_decorators import input_schema, output_schema\nfrom inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\nfrom inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\nfrom inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType\ndef init():\n    global model\n    # Example when the model is a file\n    model_path = Model.get_model_path('hd_otr') # logistic\n    print('Model Path is  ', model_path)\n    model = joblib.load(model_path)\n    \ndata_sample = PandasParameterType(pd.DataFrame({'age': pd.Series([71], dtype='int64'),\n                                                'sex': pd.Series(['0'], dtype='object'),\n                                                'cp': pd.Series(['0'], dtype='object'),\n                                                'trestbps': pd.Series([112], dtype='int64'),\n                                                'chol': pd.Series([203], dtype='int64'),\n                                                'fbs': pd.Series(['0'], dtype='object'),\n                                                'restecg': pd.Series(['1'], dtype='object'),\n                                                'thalach': pd.Series([185], dtype='int64'),\n                                                'exang': pd.Series(['0'], dtype='object'),\n                                                'oldpeak': pd.Series([0.1], dtype='float64'),\n                                                'slope': pd.Series(['2'], dtype='object'),\n                                                'ca': pd.Series(['0'], dtype='object'),\n                                                'thal': pd.Series(['2'], dtype='object')}))\ninput_sample = StandardPythonParameterType({'data': data_sample})\nresult_sample = NumpyParameterType(np.array([0]))\noutput_sample = StandardPythonParameterType({'Results': result_sample})\n@input_schema('Inputs', input_sample)\n@output_schema(output_sample)\ndef run(Inputs):\n    try:\n        data = Inputs['data']\n        #result = model.predict_proba(data)\n        result = np.round(model.predict_proba(data)[0][0], 2)\n        return result.tolist()\n    except Exception as e:\n        error = str(e)\n        return error\n\n\n\n\nIn the deployment.ipynb notebook the code is as follows:\n\nfrom azureml.core import Workspace\nfrom azureml.core.webservice import AciWebservice\nfrom azureml.core.webservice import Webservice\nfrom azureml.core.model import InferenceConfig\nfrom azureml.core.environment import Environment\nfrom azureml.core import Workspace\nfrom azureml.core.model import Model\nfrom azureml.core.conda_dependencies import CondaDependencies\nws = Workspace.from_config()\nmodel = Model.register(workspace = ws,\n              model_path ='model\/hd_otr.pkl',\n              model_name = 'hd_otr',\n              tags = {'version': '1'},\n              description = 'Heart disease classification with outliers detection',\n              )\n# to install required packages\nenv = Environment('env')\ncd = CondaDependencies.create(pip_packages=['pandas', 'azureml-defaults', 'joblib', 'inference-schema', 'imbalanced-learn'], conda_packages = ['scikit-learn'])\nenv.python.conda_dependencies = cd\n# register environment to re-use later\nenv.register(workspace = ws)\nmyenv = Environment.get(workspace=ws, name='env')\nmyenv.save_to_directory('.\/environ', overwrite=True)\naciconfig = AciWebservice.deploy_configuration(\n            cpu_cores=1,\n            memory_gb=1,\n            tags={'data':'heart disease classifier'},\n            description='Classification of heart diseases'\n            )\ninference_config = InferenceConfig(entry_script='score.py', environment=myenv, source_directory='.\/assets')\nservice = Model.deploy(workspace=ws,\n                name='heart-disease-classification-env',\n                models=[model],\n                inference_config=inference_config,\n                deployment_config=aciconfig, \n                overwrite=True)\nservice.wait_for_deployment(show_output=True)\nurl = service.scoring_uri\nprint(url)\n\n\n\n\n...which gives the error from 1. with 1.44.0 but works just fine with the older versions.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure Machine Learning profiling model errors",
        "Question_creation_time":1660748272003,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/970964\/azure-machine-learning-profiling-model-errors.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"After successfully completing the image-classification-mnist-data tutorial in Azure Machine Learning Samples\n\nSamples\/1.43.0\/tutorials\/image-classification-mnist-data\/img-classification-part1-training.ipynb\n\nI would like to profile the resulting model as shown in this article https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/v1\/how-to-deploy-profile-model?pivots=py-sdk\n\nHowever I keep getting an error saying Running..................................... Failed \/tmp\/ipykernel_56534\/2365332213.py:15: UserWarning: Model Profiling operation failed with the following error: Model service has failed with status: CrashLoopBackOff: Back-off restarting failed. This may be caused by errors in your scoring file's init() function. Error logs URL: Log upload failed. Request ID: b5384f0f-8a3a-4f53-908e-0a028374b924. Inspect ModelProfile.error property for more information. profile.wait_for_completion(True) {'name': 'sklearn-08172022-143854', 'createdTime': '2022-08-17T14:38:56.706085+00:00', 'state': 'Failed', 'requestedCpu': 3.5, 'requestedMemoryInGB': 15.0, 'requestedQueriesPerSecond': 0, 'error': {'code': 'ModelTestBackendCrashLoopBackoff', 'statusCode': 400, 'message': \"Model service has failed with status: CrashLoopBackOff: Back-off restarting failed. This may be caused by errors in your scoring file's init() function. Error logs URL: Log upload failed.\", 'details': []}}\n\n\n\n\n\nI only have 1 model in my workspace model list. So why am I getting an error and how can I see the error that is thrown inside the scoring file?\n\n\n\n\n\nscoring.py\n\n\n\n   %%writefile score.py\n     import json\n     import numpy as np\n     import os\n     import pickle\n     import joblib\n        \n     def init():\n         global model\n         # AZUREML_MODEL_DIR is an environment variable created during deployment.\n         # It is the path to the model folder (.\/azureml-models\/$MODEL_NAME\/$VERSION)\n         # For multiple models, it points to the folder containing all deployed models (.\/azureml-models)\n         model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'sklearn_mnist_model.pkl')\n         model = joblib.load(model_path)\n        \n     def run(raw_data):\n         data = np.array(json.loads(raw_data)['data'])\n         # make prediction\n         y_hat = model.predict(data)\n         # you can return any data type as long as it is JSON-serializable\n         return y_hat.tolist()\n\n\n\n\nprofiling.py\n\n     import os\n     from azureml.core import Dataset\n     from azureml.opendatasets import MNIST\n     from utils import load_data\n     import os\n     import glob\n        \n        \n     data_folder = os.path.join(os.getcwd(), 'data')\n     os.makedirs(data_folder, exist_ok=True)\n        \n     mnist_file_dataset = MNIST.get_file_dataset()\n     mnist_file_dataset.download(data_folder, overwrite=True)\n        \n     data_folder = os.path.join(os.getcwd(), 'data')\n     # note we also shrink the intensity values (X) from 0-255 to 0-1. This helps the neural network converge faster\n     X_test = load_data(glob.glob(os.path.join(data_folder,\"**\/t10k-images-idx3-ubyte.gz\"), recursive=True)[0], False) \/ 255.0\n     y_test = load_data(glob.glob(os.path.join(data_folder,\"**\/t10k-labels-idx1-ubyte.gz\"), recursive=True)[0], True).reshape(-1)\n        \n        \n        \n        \n     import json\n     from azureml.core import Datastore\n     from azureml.core.dataset import Dataset\n     from azureml.data import dataset_type_definitions\n        \n     random_index = np.random.randint(0, len(X_test)-1)\n     input_json = \"{\\\"data\\\": [\" + str(list(X_test[random_index])) + \"]}\"\n     # create a string that can be utf-8 encoded and\n     # put in the body of the request\n     serialized_input_json = json.dumps(input_json)\n     dataset_content = []\n     for i in range(100):\n         dataset_content.append(serialized_input_json)\n     dataset_content = '\\n'.join(dataset_content)\n     file_name = 'sample_request_data.txt'\n     f = open(file_name, 'w')\n     f.write(dataset_content)\n     f.close()\n        \n     # upload the txt file created above to the Datastore and create a dataset from it\n     data_store = Datastore.get_default(ws)\n     data_store.upload_files(['.\/' + file_name], target_path='sample_request_data')\n     datastore_path = [(data_store, 'sample_request_data' +'\/' + file_name)]\n     sample_request_data = Dataset.Tabular.from_delimited_files(\n         datastore_path, separator='\\n',\n         infer_column_types=True,\n         header=dataset_type_definitions.PromoteHeadersBehavior.NO_HEADERS)\n     sample_request_data = sample_request_data.register(workspace=ws,\n                                                        name='sample_request_data',\n                                                        create_new_version=True)\n        \n        \n        \n     from azureml.core.model import InferenceConfig, Model\n     from azureml.core.dataset import Dataset\n     from datetime import datetime\n        \n        \n     model = Model(ws, id='sklearn_mnist:1')\n     inference_config = InferenceConfig(entry_script='score.py', environment=env)\n     input_dataset = Dataset.get_by_name(workspace=ws, name='sample_request_data')\n     profile = Model.profile(ws,\n                 'sklearn-%s' % datetime.now().strftime('%m%d%Y-%H%M%S'),\n                 [model],\n                 inference_config,\n                 input_dataset=input_dataset)\n        \n     profile.wait_for_completion(True)\n        \n     # see the result\n     details = profile.get_details()",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-18T12:23:20.69Z",
                "Answer_score":0,
                "Answer_body":"@JIren-1543 Thanks for the question. Can you please add more details about the azure ML SDK version that you are using?\ncurrently, Profile your model to determine resource utilization applies to CLI v1 and SDK v1. This profiling technique is not available for v2 of either CLI or SDK.\nIt\u2019s possible that you have uncaught exceptions in your init() function that is triggering the CrashLoopBackOff error. Did you inspect the docker logs for details?\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment#service-launch-fails",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"ML.NET or Azure ML for job satisfaction prediction?",
        "Question_creation_time":1659816548317,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/957699\/mlnet-or-azure-ml-for-job-satisfaction-prediction.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Recently my manager asked to consider machine learning in our company. The specific problem he had in mind could be described as follows.\n\nThere are customers with datasets with employee information - gender, nationality, age, marital status, last salary increase time, current salary, CV information (can deduce \"how many times the employee has changed their job in last 10 years\" etc.) and also we could include general job market data (typical salary for this position in other companies etc.). Based on all of these features and their historically observed results, we would like to train ML models that can predict specific simple yes\/no answers about employees, such as \"are they considering leaving the company?\", \"are they undervalued?\" and generate a report on employees who have high probability scores for predicted \"yes\" answers.\n\nI'm an experienced .net C# developer and also have general architecture experience with Azure (VMs, app services, functions, DevOps) but I have no serious experience with machine learning yet. Some years ago I was playing around with Nvidia's StyleGAN and neural networks based speech synthesis, but I was treating the \"AI stuff\" as a black box, tweaking only the control UIs and data input utilities. However, yesterday I watched a few MLNET tutorials and it all seemed to make sense and made me thinking that even a \"mere mortal\" .net developers might be able to create something usable, especially if we get some help from a data scientist sometime later.\n\nWould MLNET Model Builder be enough to help with this specific scenario? Would binary classification model be a good candidate? Or maybe Azure ML Studio might offer a better starting point?\nAre there any code examples that show how to properly featurize such kind of input data and that might work well for our case, at least to have a usable proof-of-concept to demonstrate? Or am I oversimplifying the task and it would need much more data analysis and algorithm selection than automated ML.NET and Azure builders can offer?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-08T14:36:04.797Z",
                "Answer_score":0,
                "Answer_body":"@progmars-8315 Thanks for the question. We would recommend using the AutoML that automates the process of applying ML to data\u200b, User only needs to choose their ML scenario and input their dataset\u200b. Currently, ML.NET doesn't support this recommendation.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Mounting the dataset in ML Workspace",
        "Question_creation_time":1661408727513,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/981126\/mounting-the-dataset-in-ml-workspace.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":1,
        "Question_body":"How to mount the dataset in ML Studio using python sdk ?\nWhat are the different ways and which is the right one ?\n\nCan we create dataset pointing to two different stores ?\n\nAlso where can I learn more about azure machine learning ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-25T23:18:32.52Z",
                "Answer_score":2,
                "Answer_body":"Hello @VJEEVA-5492\n\nThanks for using Microsoft Q&A platform. Let me answer your questions one by one.\n\nwhere can I learn more about azure machine learning\nThe best way to learn Azure Machine Learning is the documentation, please refer to - https:\/\/azure.microsoft.com\/en-us\/services\/machine-learning\/#documentation\n\nHow to mount the dataset in ML Studio using python sdk ?\nGenerally there are two ways to work with data in Azure Machine Learning -\nUse datastores - https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-datastore?tabs=cli-identity-based-access%2Ccli-adls-identity-based-access%2Ccli-azfiles-account-key%2Ccli-adlsgen1-identity-based-access\nUse data assets - https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-datastore?tabs=cli-identity-based-access%2Ccli-adls-identity-based-access%2Ccli-azfiles-account-key%2Ccli-adlsgen1-identity-based-access\n\nWhat are the different ways and which is the right one ?\nIt depends on your need. Compared to data assets and datastore, the benefits of creating data assets are:\nYou can share and reuse data with other members of the team such that they do not need to remember file locations.\nYou can seamlessly access data during model training (on any supported compute type) without worrying about connection strings or data paths.\nYou can version the data.\n\nCan we create dataset pointing to two different stores ?\nIf you need to assembly data, you may want to consider data assets. By creating a data asset, you create a reference to the data source location, along with a copy of its metadata. Because the data remains in its existing location, you incur no extra storage cost, and don't risk the integrity of your data sources. You can create Data from datastores, Azure Storage, public URLs, and local files.\n\nI hope this helps!\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"a request to change the personal account (MSA) associated with my Certification profile",
        "Question_creation_time":1661434194677,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/981835\/a-request-to-change-the-personal-account-msa-assoc.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I want to connect my MSA with my certification profile.\n\nMy MSA is julia.loef@hotmail.com and my work account is julia.loef-bleiksch@nl.abnamro.com\n\nCan you please help me with this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-25T13:50:43.443Z",
                "Answer_score":0,
                "Answer_body":"Hi @JuliaLoefBleiksch-4662\n\nPlease post this on Microsoft Certifications forum found at https:\/\/trainingsupport.microsoft.com\/en-us\/mcp and someone will gladly assist.\n\nUnfortunately MS Certifications is not supported on this forum.\n\nIf this was helpful please accept answer.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure ML Model in Failed State when deploying as Web Service",
        "Question_creation_time":1661369796427,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/980558\/azure-ml-model-in-failed-state-when-deploying-as-w.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"][1]",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Time series training for anomal detect",
        "Question_creation_time":1661358044013,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/980372\/time-series-training-for-anomal-detect.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I have not seen any doc talking about this topic, is this supported in Microsoft Machine Learning? Is this a good plan if anyone has tried?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-24T22:18:48.52Z",
                "Answer_score":0,
                "Answer_body":"Hello @minhoolee-9603\n\nThanks for using Microsoft Q&A platform, Azure Machine Learning Serivce support time series training - https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-forecast\n\nYou can check above document to see how to set up a quick model.\n\nBut for Anomaly Dectection, I think Anomaly Detector API is a better choice for you - https:\/\/docs.microsoft.com\/en-us\/azure\/cognitive-services\/anomaly-detector\/\n\nI hope this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Receiving error while submitting the pipeline run",
        "Question_creation_time":1661308367600,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/979208\/receiving-error-while-submitting-the-pipeline-run.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I am trying to train Model in the AML Designer and on the Train Model component, I am receiving the following error when submitting it for a pipeline run\u2026\n\n\n\n\nAmlExceptionMessage:AzureMLCompute job failed.\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\n\n\n\n\nModuleExceptionMessage:ColumnUniqueValuesExceeded: Number of unique values in column: \"MessageID\" is greater than allowed.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-24T03:23:00.71Z",
                "Answer_score":1,
                "Answer_body":"@Srin-4824 Thanks for the question. Here is the troubleshooting document for this issue.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Realtime endpoint deploy 'xxx' stayed in progress",
        "Question_creation_time":1661074944827,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/975300\/realtime-endpoint-deploy-39xxx39-stayed-in-progres.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hi everyone,\n\nI'm trying to deploy my real time inference, but after a while not happened to it. I didn't got any error or message and nothing happens. (See the following picture).\n\nWhat I did:\n\nI created a pipeline in designer, it's valid and be submitted very well.\n\n\nAfter submit is complete, I created a \"Real-time inference pipeline\" via button in menu!\n\n\n\n\nAnd finally I tried to deploy it, but nothing happened. (For deploy I tried both of Azure Kubernetes Service and Azure Container Instance)",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-22T22:20:19.56Z",
                "Answer_score":0,
                "Answer_body":"Hello @ImranShams-7088\n\nYou have been enabled for one-time Free Technical Support. To create the support request, please do the following as detailed below. It may take up to 1 hour for the free support ticket enablement to go through.\n\n\u2022 Go to the Health Advisory section within the Azure Portal: https:\/\/aka.ms\/healthadvisories\n\u2022 Select the Issue Name \"You have been enabled for one-time Free Technical Support\"\n\u2022 Details will populate below in the Summary Tab within the reading pane and you can click on the link \"Create a Support Request\" to the right of the message\n\nOnce created, please share the ticket number with me. Thanks.\n\nRegards,\nYutong",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"What's the next step after creating a pipeline?",
        "Question_creation_time":1661266129010,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/978610\/what39s-the-next-step-after-creating-a-pipeline.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":1,
        "Question_body":"Hi, the UI is very confused, not straightforward as Studio. Can you guide me to the next step to use the pipeline?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-23T18:07:17.917Z",
                "Answer_score":0,
                "Answer_body":"Hello @Nicholes-3441\n\nThanks for using Microsft Q&A platform. I think you are on the stage of designing your pipeline and running it.\n\nThe next step should be submit your pipeline and evaluate your model - https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score#submit-the-pipeline\n\nWhen you feel good with your model, you can then deploy your pipeline as this guidance - https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy\n\nYou may then want to test and update your endpoint as above guidance.\n\nEach time you run a pipeline, the configuration of the pipeline and its results are stored in your workspace as a pipeline job. You can go back to any pipeline job to inspect it for troubleshooting or auditing. Clone a pipeline job to create a new pipeline draft for you to edit.\n\nPipeline jobs are grouped into experiments to organize job history. You can set the experiment for every pipeline job.\n\nI hope this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-08-23T18:16:30.973Z",
                "Answer_score":0,
                "Answer_body":"Hi @Nicholes-3441,\n\nThere are several options of how you can run the pipeline after creating it e.g.,\n\n1) you can manually run the pipeline e.g., by Clicking on the Trigger Now option, using REST API, using PowerShell command etc.\n2) you can create a new scheduled \/ tumbling window \/ storage event \/custom event trigger\n\nPlease see the links below for details.\n\nThanks!\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/data-factory\/concepts-pipeline-execution-triggers",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML BFSMountError: Unable to mount blob fuse file system",
        "Question_creation_time":1660200527397,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/963683\/azure-ml-bfsmounterror-unable-to-mount-blob-fuse-f.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Training yolov5 using Azure ML SDK and encountered error below. I have a gpu cluster created (no vnet) and encountered this error when i ScriptRunConfig and experiment.submit. My Azure ML Storage account is enabled from all network (no vnet). Thank you very much\n\nsrc = ScriptRunConfig(.......)\nrun = experiment.submit(src)\n\nAzureMLCompute job failed.\nBFSMountError: Unable to mount blob fuse file system\nInfo: Could not mount Azure Blob Container azureml-blobstore-xxxxxxxx at workspaceblobstore: <nil>. Unable to start blobfuse due to a lack of credentials. Please check the readme for valid auth setups.\nUnmounting blobfuse.\nUnmounted blobfuse successfully.\n\n Info: Failed to setup runtime for job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Change in Machine Learning Designer",
        "Question_creation_time":1660839023247,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/972775\/change-in-machine-learning-designer.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I can\u2019t find some of the basic modules from this week. Any significant change about Designer?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-18T16:58:23.857Z",
                "Answer_score":0,
                "Answer_body":"Hello @67603284\n\nThanks for using Microsoft Q&A platform, there is no surprising change in Azure Machine Learning Designer.\n\nBased on my experience, you may use the filter so you can not see some of the modules as below screenshot.\n\n\nIf this is not your case, could you please share which module you have lost? Thanks.\n\nI hope this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Where should I begin with Machine Learning on Azure?",
        "Question_creation_time":1660784016847,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/971544\/where-should-i-begin-with-machine-learning-on-azur.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":1,
        "Question_body":"Hi, I have only been programming for about 6 months and I don't have any formal training.\n\nI started on a platform called Ninjatrader8 building automated trading systems in C#5 on .NET 4.8\n\nout of curiosity I have been experimenting with ML.NET in C# using my own machine but now I have started experimenting with Azure.\n\nI have taken a peak at Python etc, and it seems easy to understand, I have also read a bit about Computer Science principles but there seems to be so much learning I can devout myself to now that I need to break it up into things that I will actually use, else I be stuck in a perpetual loop.\n\nmy goal is simply to have my strategy in the Ninjatrader platform be able to look up the most recent values output by an ML model.\n\nI was going to have my model analyse a file any time a new file was added to a data set and then serialise the results in some way, perhaps by .csv file.\n\nthe file would need to allow for multiple simultaneous read iterations but only a single write iteration.\n\nI feel like with azure I could probably have the strategy and model talking directly over the internet somehow, but it is not 100% necessary if it is to difficult\n\nI am starting on the Microsoft online courses but they are also very broad and numerous.\n\nThankyou, Any help would be appreciated.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-18T01:23:57.683Z",
                "Answer_score":2,
                "Answer_body":"Hi @KevinMonaghan-1023\n\nTake a look on content of this one . I personally use udemy for learning and certification.\n\nhttps:\/\/www.udemy.com\/course\/machine-learning-using-azureml\/\n\nRegards,\n\n--please don't forget to upvote and Accept as answer if the reply is helpful--",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Issue with Deploying a Model using Azure Machine Learning Service using notebook",
        "Question_creation_time":1660651524797,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/968888\/issue-with-deploying-a-model-using-azure-machine-l.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"---> Running in 6d157abd883c\nRemoving intermediate container 6d157abd883c\n---> f7ff072c2749\nStep 6\/10 : RUN mv '\/var\/azureml-app\/tmpiax4fwcd.py' \/var\/azureml-app\/main.py\n---> Running in 28fb7f825815\nRemoving intermediate container 28fb7f825815\n---> a475f38ff1ed\nStep 7\/10 : RUN sed -i '\/^\\s*-\\s*python\\s*[<>=]\/d' '\/var\/azureml-app\/conda_env.yml' && cat '\/var\/azureml-app\/conda_env.yml'\n---> Running in 6f1b1bcf415a\n\nConda environment specification. The dependencies defined in this file will\nbe automatically provisioned for runs with userManagedDependencies=False.\n\n\nDetails about the Conda environment file format:\nhttps:\/\/conda.io\/docs\/user-guide\/tasks\/manage-environments.html#create-env-file-manually\n\n\n\nname: project_environment\ndependencies:\n# The python interpreter version.\n# Currently Azure ML only supports 3.8 and later.\n- pip<=22.1.2\n- pip:\n- azureml-train-automl-runtime==1.44.0\n- inference-schema\n- azureml-interpret==1.44.0\n- azureml-defaults==1.44.0\n- datefinder\n- numpy>=1.18.5,<=1.23.3\n- pynacl<=1.5.0\n- pandas==1.1.5\n- scikit-learn==0.22.2.post1\n- py-xgboost==1.3.3\n- fbprophet==0.7.1\n- holidays==0.11.3.1\n- psutil<=5.9.1\nchannels:\n- anaconda\n- conda-forgeRemoving intermediate container 6f1b1bcf415a\n---> 9205898728ba\nStep 8\/10 : RUN CONDA_ROOT_DIR=$(conda info --root) && if [ -n \"$AZUREML_CONDA_ENVIRONMENT_PATH\" ]; then conda env update -p \"$AZUREML_CONDA_ENVIRONMENT_PATH\" -f '\/var\/azureml-app\/conda_env.yml'; else conda env update -n base -f '\/var\/azureml-app\/conda_env.yml'; fi && conda clean -aqy && rm -rf \/root\/.cache\/pip && rm -rf \"$CONDA_ROOT_DIR\/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name pycache -exec rm -rf {} +\n---> Running in 8f7055e32ad7\nCollecting package metadata: ...working...\ndone\nSolving environment: ...working...\n[91mKilled\n[0mThe command '\/bin\/sh -c CONDA_ROOT_DIR=$(conda info --root) && if [ -n \"$AZUREML_CONDA_ENVIRONMENT_PATH\" ]; then conda env update -p \"$AZUREML_CONDA_ENVIRONMENT_PATH\" -f '\/var\/azureml-app\/conda_env.yml'; else conda env update -n base -f '\/var\/azureml-app\/conda_env.yml'; fi && conda clean -aqy && rm -rf \/root\/.cache\/pip && rm -rf \"$CONDA_ROOT_DIR\/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name pycache -exec rm -rf {} +' returned a non-zero code: 137\n2022\/08\/12 13:17:23 Container failed during run: acb_step_0. No retries remaining.\nfailed to run step ID: acb_step_0: exit status 137\nRun ID: ch1y failed after 9m7s. Error: failed during run, err: exit status 1",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure ML Studio Error CammandLine exceeds Limit",
        "Question_creation_time":1657656469800,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/924104\/azure-ml-studio-error-cammandline-exceeds-limit.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I am setting up ML experiment in Azure ML Studio Designer for K-Means Clustering and have ~750 attributes that I am attempting to cluster with ~4000 rows.\n\nWhen i go to execute this i get the following error:\n\nAzureMLCompute job failed. InvalidPropertyValue: The size of the specified property Job.Properties.CustomToolkitSettings.CommandLine exceeds the limit of 20480 characters\n\nThere isn't much on this error but would someone be able to assist me on how to increase the limit? I don't believe this is an K-Means error but a Azure ML Studio error.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"how can i deploy a non-ML model on azure ML ?",
        "Question_creation_time":1660648529110,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/968884\/how-can-i-deploy-a-non-ml-model-on-azure-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"okay so i built a recommendation system that doesn't rely on any ML ( only linear kernel between entries ) and I want to deploy it and make it available for users through a website, I'm confused as to how the deployment process is any different since in this case there is no machine learning being done ( so no.h5 weights or anything like that )",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-16T16:08:38.277Z",
                "Answer_score":0,
                "Answer_body":"Hello @tarekKerbadj-2515\n\nThanks for using Microsoft Q&A platform. If you have a locally trained or retrained model, you can register it with Azure. After it's registered, you can continue tuning it by using Azure compute or deploy it by using Azure facilities like Azure Kubernetes Service or Triton Inference Server (Preview).\n\nTo be used with the Azure Machine Learning Python SDK, a model must be stored as a serialized Python object in pickle format (a .pkl file). It must also implement a predict(data) method that returns a JSON-serializable object. For example, you might store a locally trained scikit-learn diabetes model with:\n\n import joblib\n    \n from sklearn.datasets import load_diabetes\n from sklearn.linear_model import Ridge\n    \n dataset_x, dataset_y = load_diabetes(return_X_y=True)\n    \n sk_model = Ridge().fit(dataset_x, dataset_y)\n    \n joblib.dump(sk_model, \"sklearn_regression_model.pkl\")\n\n\n\nTo make the model available in Azure, you can then use the register() method of the Model class:\n\n from azureml.core.model import Model\n    \n model = Model.register(model_path=\"sklearn_regression_model.pkl\",\n                        model_name=\"sklearn_regression_model\",\n                        tags={'area': \"diabetes\", 'type': \"regression\"},\n                        description=\"Ridge regression model to predict diabetes\",\n                        workspace=ws)\n\n\n\nYou can then find your newly registered model on the Azure Machine Learning Model tab:\n\n\n\n\n\nTo see step by step guidance, please refer to the document - https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-local\n\nI hope this helps! Let me know if you have more questions, feel free to post under this tag.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AML Workspace Alerting and Application Insight Dashboard Configuration",
        "Question_creation_time":1660054347030,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/960800\/number-of-run-errors-in-ml-workspace-count-is-upda.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi All,\n\nI would need seach query understanding to configure alert for below metrics for AML Workspace and I also need to show metrics in Application Insight dashboard which are associated with AML.\n\nPlease guide on this.\n\nAlert Description :\n\nMetric Name Unit Description\n1. -Warnings -Count -Number of run warnings in this workspace. Count is updated whenever a run encounters a warning.\n2. -Errors -Count -Number of run errors in this workspace. Count is updated whenever run encounters an error.\n3. -Failed Runs -Count -Number of runs failed for this workspace. Count is updated when a run fails.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-10T00:00:20.17Z",
                "Answer_score":0,
                "Answer_body":"Hi @RakeshSharma-8583,\n\nThank you for posting query in Microsoft Q&A Platform. Below content might be helpful.\n\nGo to Portal -Azure Machine Learning (select the workspace) - Logs - The video  explains clearly first you have to set up Azure monitor. Select the categories and send to log Analytics.\n\n\n\n\n.\n\nOnce the logs are stored in log Analytics, go to logs again, select any existing query - Load to editor. \n\nYou can see workspace, JobName, EventType etc field to query. This is KQL -https:\/\/docs.microsoft.com\/en-us\/sharepoint\/dev\/general-development\/keyword-query-language-kql-syntax-reference\n\nSo, modify your query as per your requirement. Once finalized pin to the dashboard.\n\nHope this is helpful.\n\nThanks,\nPritee",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Machine Learning Designer is too slow!",
        "Question_creation_time":1605910757727,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/170450\/machine-learning-designer-is-too-slow.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I am teaching ML next week. I have usually been using ML Studio (Classic), but thought it would be time to transfer to ML the ML Designer. It is great in many ways, but it is just too slow for demo and teaching purposes.\n\n1000 rows from an Azure DB in the same region. The simplest of experiments (Select Columns, Split Rows, Train Boosted Decission Tree, Score and Evaluate) on a STANDARD_DS5_V2 (16 Cores, 56 GB RAM, 112 GB Disk) compute target, which was the most expensive I could choose on my VS subscription. Creating a model takes about eight minutes!\n\nOr to phrase it as a question: Am I doing anything wrong? Is there any way to make the Designer usable?\n\nThanks,\nChristian",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-23T06:48:46.633Z",
                "Answer_score":1,
                "Answer_body":"@CVinter The classic studio used a fixed environment or compute which was always available so it was faster to execute simple tasks but was limited in many ways to the applications that could be run on the compute as there was no flexibility to select the type of compute to perform advanced tasks with a customer's existing compute.\n\nDesigner on the other hand provides the ability to select the required compute type but currently there is a limitation of setting up this compute for the job and hence the time to complete the overall job seems to be higher but for scenarios where heavy compute processing is required the overall time to run the job is significantly reduced. Our team is addressing this scenario to reduce the overhead time to setup this compute which should eventually reduce the time to run simple tasks on designer. One of our team member from Azure ML Designer provided more details on a similar question in this thread. I hope this helps. @LuZhangAI-1027 @LuZhang-4441 FYI.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to use export data module in Azure ML to move ML output to Azure SQL Data Warehouse?",
        "Question_creation_time":1660233242963,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/964452\/how-to-use-export-data-module-in-azure-ml-to-move.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Can anyone help me with the right configuration settings for the Export Data module in Azure ML studio. I am trying to export a data output from the ML studio to the SQL Data warehouse to enable build a visualization report with PowerBI. Find the screenshot of my pipeline, configuration and the error message I'm getting respectively below;\n\n\n\n\n\n\n\n\n\n\n\nI look forward to a prompt assistance from anyone.\n\nThank you.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"NCCL INFO and WARNING logs not present in new AzureML runtime",
        "Question_creation_time":1659780711157,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/957497\/nccl-info-and-warning-logs-not-present-in-new-azur.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi all,\n\nRecently, I have been trying to debug a very weird NCCL OOM issue and I have noticed that if I use the old runtime NCCL prints an OOM warning in 70_driver_log_0.txt but that when I use the new runtime all these NCCL logs magically disappear. My hunch is that warnings are somehow suppressed in the new runtime. Is there a way to activate them again? If I enforce the old runtime by specifying the environment variable pytorch_env.environment_variables = {\"AZUREML_COMPUTE_USE_COMMON_RUNTIME\": \"false\"} in my runs, then the warning is logged. My worry is that warnings like these (i.e. OOM warnings that don't make the job crash) would be difficult to detect if warnings are switched off by default in the new runtime. Otherwise, would there be any other reason why this warning wouldn't make it into the logs? If it does appear, would you be so kind to point me in the right direction? Btw, my job completes successfully even with the warning message below so can't really troubleshoot based on job status.\n\n :200:451 [0] include\/socket.h:423 NCCL WARN Net : Connection closed by remote peer 10.0.0.8<>\n :200:451 [0] NCCL INFO include\/socket.h:445 -> 2\n :200:451 [0] NCCL INFO include\/socket.h:457 -> 2\n :200:451 [0] NCCL INFO bootstrap.cc:229 -> 2\n    \n :200:451 [0] bootstrap.cc:279 NCCL WARN [Rem Allocator] Allocation failed (segment 0, fd 71)\n    \n :200:451 [0] include\/alloc.h:48 NCCL WARN Cuda failure 'out of memory'\n :200:451 [0] NCCL INFO bootstrap.cc:231 -> 1\n    \n :200:451 [0] bootstrap.cc:279 NCCL WARN [Rem Allocator] Allocation failed (segment 0, fd 70)\n    \n :200:451 [0] include\/alloc.h:48 NCCL WARN Cuda failure 'out of memory'\n :200:451 [0] NCCL INFO bootstrap.cc:231 -> 1\n\n\n\nThanks in advance for your time.\n\nBest,\n\nKiki",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-09T07:49:32.753Z",
                "Answer_score":0,
                "Answer_body":"Hi @ramr-msft and thanks for your reply. We are currently using MLflow to log metrics, images, etc... Unfortunately, the logs I am referring to in my question have nothing to do with the model logs, but rather the NCCL library logs which (I don't think) we have any control over and which are produced by the library itself. I am not sure if there are any environment variables I should be setting in the new runtime in order for the NCCL info and warn logs to appear in any of the available log files. Would for example the environment variable AZUREML_CR_HT_LOG_FILTERING_POLICY be relevant here? If so, what values does it accept?\n\nA sample of the 70_driver_log_0.txt file is shown below\n\n bash: \/azureml-envs\/azureml_<REDACTED>\/lib\/libtinfo.so.6: no version information available (required by bash)\n [2022-08-06T10:14:50.915054] Entering context manager injector.\n [2022-08-06T10:14:51.453543] context_manager_injector.py Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=[<REDACTED>])\n This is a PyTorch job. Rank:0\n Script type = None\n [2022-08-06T10:14:51.457604] Entering Run History Context Manager.\n [2022-08-06T10:14:52.089533] Current directory: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/<REDACTED>\n [2022-08-06T10:14:52.089756] Preparing to call script [<REDACTED>]\n [2022-08-06T10:14:52.089847] After variable expansion, calling script [<REDACTED>] with arguments:[<REDACTED>]\n INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0\n INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.\n INFO:root:Device used: cuda:0\n <REDACTED> [0] NCCL INFO Bootstrap : Using eth0:10.0.0.4<0>\n <REDACTED> [0] NCCL INFO NET\/Plugin : No plugin found (libnccl-net.so), using internal implementation\n <REDACTED> [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n <REDACTED> [0] NCCL INFO NET\/Socket : Using [0]eth0:10.0.0.4<0>\n <REDACTED> [0] NCCL INFO Using network Socket\n NCCL version 2.10.3+cuda10.2\n <REDACTED> NCCL INFO Channel 00\/02 :    0   1   2   3\n <REDACTED> NCCL INFO Channel 01\/02 :    0   1   2   3\n <REDACTED> NCCL INFO Trees [0] 1\/-1\/-1->0->-1 [1] 1\/-1\/-1->0->-1\n <REDACTED> NCCL INFO Setting affinity for GPU 0 to 0fff\n <REDACTED> NCCL INFO Channel 00 : 0[846d00000] -> 1[aff500000] via direct shared memory\n <REDACTED> NCCL INFO Channel 01 : 0[846d00000] -> 1[aff500000] via direct shared memory\n <REDACTED> NCCL INFO Connected all rings\n <REDACTED> NCCL INFO Connected all trees\n <REDACTED> NCCL INFO threadThresholds 8\/8\/64 | 32\/8\/64 | 8\/8\/512\n <REDACTED> NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\n <REDACTED> NCCL INFO comm 0x7f9358001240 rank 0 nranks 4 cudaDev 0 busId 846d00000 - Init COMPLETE\n <REDACTED> NCCL INFO Launch mode Parallel\n INFO:root:Epoch 1\n\n\n\nand later on I get the OOM warning\n\n  <REDACTED>:200:451 [0] include\/socket.h:423 NCCL WARN Net : Connection closed by remote peer 10.0.0.8<REDACTED>\n  <REDACTED>:200:451 [0] NCCL INFO include\/socket.h:445 -> 2\n  <REDACTED>:200:451 [0] NCCL INFO include\/socket.h:457 -> 2\n  <REDACTED>:200:451 [0] NCCL INFO bootstrap.cc:229 -> 2\n        \n  <REDACTED>:200:451 [0] bootstrap.cc:279 NCCL WARN [Rem Allocator] Allocation failed (segment 0, fd 71)\n        \n  <REDACTED>:200:451 [0] include\/alloc.h:48 NCCL WARN Cuda failure 'out of memory'\n  <REDACTED>:200:451 [0] NCCL INFO bootstrap.cc:231 -> 1\n        \n  <REDACTED>:200:451 [0] bootstrap.cc:279 NCCL WARN [Rem Allocator] Allocation failed (segment 0, fd 70)\n        \n  <REDACTED>:200:451 [0] include\/alloc.h:48 NCCL WARN Cuda failure 'out of memory'\n  <REDACTED>:200:451 [0] NCCL INFO bootstrap.cc:231 -> 1\n\n\n\nFor comparison, the same run using the new runtime produces the logs below (which are missing the corresponding NCCL info and warning lines).\n\n INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0\n INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.\n INFO:azureml._restclient.clientbase:Created a worker pool for first use\n INFO:root:Device used: cuda:0\n INFO:root:Epoch 1\n\n\n\nI also checked the system_logs\/hosttools_capability\/hosttools-capability.log file and it does not contain any of them.\n\nAny help would be greatly appreciated.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning - endpoint failure 502 when testing the model",
        "Question_creation_time":1642932141937,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/706183\/azure-machine-learning-endpoint-failure-502-tesing.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_comment_count":2,
        "Question_follower_count":15,
        "Question_score":2,
        "Question_body":"Very basic example from ms-learn does not work!!! So frustrating\n\n\n\n\n\n\n\n\n\nfrom: https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/\n\nCreated a model\n\n\nmodel deployment to ACI\n\n\nI copied the generated py code from the Consume tab into a notebook in the same service\n\n\nget 502",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-24T11:38:32.437Z",
                "Answer_score":0,
                "Answer_body":"@maciejg-2112 Is the deployed service or endpoint in a healthy state? On the Details tab of your endpoint the Deployment state should be healthy and if you also use the test tab the response should be successful.\nI have followed the tutorial and have an endpoint setup which is working as expected with the code from consume tab.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-02-01T18:14:01.027Z",
                "Answer_score":1,
                "Answer_body":"Additional details:\n\nRemoving:\n\n ,\n     \"GlobalParameters\": {\n     }\n\n\n\nfrom the data variable (in the Endpoints\/Consume code) will result in a proper result.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-03-03T06:37:08.647Z",
                "Answer_score":4,
                "Answer_body":"I've experienced the same problem and I've made the case to the Microsoft support. And I've got the correct Python code as follows.\n\nThe problem come from lack of GlobalParameters in the next sentence.\ninput_json = json.dumps({\"Inputs\":{\"data\": x}, \"GlobalParameters\": 1.0})\n\nendpoint = 'YOUR_ENDPOINT' #Replace with your endpoint\nkey = 'YOUR_KEY' #Replace with your key\n\nimport json\nimport requests\n\nAn array of features based on five-day weather forecast\n\nx = [[1,1,2022,1,0,6,0,2,0.344167,0.363625,0.805833,0.160446],\n[2,1,2022,1,0,0,0,2,0.363478,0.353739,0.696087,0.248539],\n[3,1,2022,1,0,1,1,1,0.196364,0.189405,0.437273,0.248309],\n[4,1,2022,1,0,2,1,1,0.2,0.212122,0.590435,0.160296],\n[5,1,2022,1,0,3,1,1,0.226957,0.22927,0.436957,0.1869]]\n\nConvert the array to JSON format\n\ninput_json = json.dumps({\"Inputs\":{\"data\": x}, \"GlobalParameters\": 1.0})\n\nSet the content type and authentication for the request\n\nheaders = {\"Content-Type\":\"application\/json\",\n\"Authorization\":\"Bearer \" + key}\n\nSend the request\n\nresponse = requests.post(endpoint, input_json, headers=headers)\n\nIf we got a valid response, display the predictions\n\nif response.status_code == 200:\ny = response.json()\nprint(\"Predictions:\")\nfor i in range(len(x)):\nprint (\" Day: {}. Predicted rentals: {}\".format(i+1, max(0, round(y[\"Results\"][i]))))\nelse:\nprint(response)\n\n\n\n\n\nbest regards,",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-03-08T08:58:30.45Z",
                "Answer_score":0,
                "Answer_body":"Thanks @IIJGlobalYamamotoMitsuyoshi-6912 for the fix.\n\nIt's quite frustrating that it's not true someone taking a beginners training can follow the advice: \"Don't worry too much about the details of the code.\" (https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/7-deploy-model).\nThe persona has to either troubleshoot while the $ counter is running or give up on the exercise.\n\nBTW it would be great to have sandboxes for AI-900 like there are for DP-900",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Resilience Test tools\/services for DevOps and MLOps in Azure",
        "Question_creation_time":1660275015307,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/965012\/resilience-test-toolsservices-for-devops-and-mlops.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"what are the tools or services can be used for Resilience Test for DevOps and MLOps in Azure.\nCan you please suggest any azure native service or 3rd party tools?\n\nI want to cover the below scopes as part of Resilience Test for DevOps and MLOps\nidempotency,\ngraceful degradation\nretry policy\ncircuit breaker\nperformance",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How to connect to KeyVault to azureml real time endpoint using managed identity?",
        "Question_creation_time":1660172274087,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/963249\/how-to-connect-to-keyvault-to-azureml-real-time-en.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":20,
        "Question_score":0,
        "Question_body":"I am trying to connect keyvault to an insanely simple app with score file as follows:\n\n def init():\n     pass\n def run(raw_data):\n     KVUri=\"<<AN ACTUAL KEYVAULT URI>>\"\n     credential = DefaultAzureCredential()\n     client = SecretClient(vault_url=KVUri, credential=credential)\n     retrieved_secret = client.get_secret(\"test-secret\")\n     return  [retrieved_secret]\n\n\n\nI deploy using python SDK as follows:\n\n # create an online endpoint\n endpoint = ManagedOnlineEndpoint(\n     name=local_endpoint_name,\n     description=\"this is a sample online endpoint\",\n     auth_mode=\"key\",\n )\n ml_client.begin_create_or_update(endpoint)\n model = Model(path=\"..\/model\/dummy.txt\")\n env = Environment(\n     conda_file=\".\/conda.yaml\",\n     image=\"mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04:20210727.v1\",\n )\n    \n blue_deployment = ManagedOnlineDeployment(\n     name=\"blue\",\n     endpoint_name=local_endpoint_name,\n     model=model,\n     environment=env,\n     code_configuration=CodeConfiguration(\n         code=\".\", scoring_script=\"app.py\"\n     ),\n     instance_type=\"Standard_F2s_v2\",\n     instance_count=1,\n )\n ml_client.begin_create_or_update(blue_deployment)\n\n\n\nAfter the deployment I add System assigned managed identity to azure key vault (Access Controls IAM > grant access to this resource). I assign access to instance of online endpoint, but when testing I get:\n\nFailed to test real-time endpoint\nDefaultAzureCredential failed to retrieve a token from the included credentials. Attempted credentials: EnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured. Visit https:\/\/aka.ms\/azsdk\/python\/identity\/environmentcredential\/troubleshoot to troubleshoot.this issue. ManagedIdentityCredential: request() got an unexpected keyword argument 'tenant_id' To mitigate this issue, please refer to the troubleshooting guidelines here at https:\/\/aka.ms\/azsdk\/python\/identity\/defaultazurecredential\/troubleshoot.\n\nDo you know what is the source of an error? How should I do it correctly?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-10T23:45:33.143Z",
                "Answer_score":0,
                "Answer_body":"Hi @MateuszMacias-3397\n\nAs mentioned in your error : Attempted credentials: EnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\n\nYou are missing to mention some configuration in your python code\nNo where In your code its mention to retrieve the secret from which client , Mention the client ID or which tenant. This image from the same URL you mentioned.\n\nIm not from Developers side but thought if i could help.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Not Able to Create a Dataset using azure SDK",
        "Question_creation_time":1659602908663,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/954905\/not-able-to-create-a-dataset-using-azure-sdk.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":25,
        "Question_score":0,
        "Question_body":"Hello There,\nI am trying to register dataset from a csv file in my blob container storage using Azure ML SDK. However, I keep getting this error message.(Authentication Failed).\n\nPoint to note - I used the same Authentication key(from the same object) to upload the csv file in the blob container storage using Azure ML SDK, which was successful.\n\n     DatasetValidationError: DatasetValidationError:\n         Message: Failed to validate the data.\n     ScriptExecutionException was caused by StreamAccessException.\n       StreamAccessException was caused by AuthenticationException.\n         Authentication failed for 'AzureBlob GetReference' operation at '[REDACTED]' with '403: AuthenticationFailed'. Please make sure the SAS token or the account key is correct.\n           Failed due to inner exception of type: StorageException\n     | session_id=************\n         InnerException None\n         ErrorResponse \n     {\n         \"error\": {\n             \"code\": \"UserError\",\n             \"message\": \"Failed to validate the data.\\nScriptExecutionException was caused by StreamAccessException.\\r\\n  StreamAccessException was caused by AuthenticationException.\\r\\n    Authentication failed for 'AzureBlob GetReference' operation at '[REDACTED]' with '403: AuthenticationFailed'. Please make sure the SAS token or the account key is correct.\\r\\n      Failed due to inner exception of type: StorageException\\r\\n| session_id=**********\"\n         }\n     }",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-05T07:25:40.59Z",
                "Answer_score":0,
                "Answer_body":"@NandalalLJ-0003 Was there any change or reset of keys with the workspace or your storage account?\nIn any case, have you run re-sync keys after this operation?\n\nIf the keys are not reset and still the issue is seen, then it is most likely an issue with the workspace backend unable to update the storage account keys.\nThere is an option to update authentication of your storage account on the workspace from azure ml portal. Please try to follow below steps and wait for some time and check if you can proceed with dataset creation.\n\nNavigate to ml.azure.com\n\n\nClick on datastores from the left-hand menu\n\n\nClick on the 'workspaceblobstore (Default)' datastore\n\n\nCheck if the keys are incorrect by clicking on 'Browse (preview)' at the top. If you get an error stating the keys are incorrect, use the next steps to fix them\n\n\nGo back to 'Overview' and click the 'Account name' link to open the storage account\n\n\nFrom the storage account window go to 'Access Keys' and click on show button of 'key1' Key and copy the keys\n\n\nGo back to the ML workspace portal, click 'Update authentication' at the top, and paste in the new 'Account key\n\n\nClick save, then go back to 'Browse (preview)' to check if you are able to browse your workspace default datastore\n\nIf you are good at step 4 i.e if you are able to browse the default datastore then the issue might be with a different datastore and you could check the other datastores and follow rest of the steps.\n\nIn any case if none of the steps work then you should consider reporting the issue through a support case from Azure portal.\nI hope this helps!! Thanks!!\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Relation Google node hour to Azure computing hour",
        "Question_creation_time":1659708002537,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/956892\/relation-google-node-hour-to-azure-computing-hour.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":2,
        "Question_score":0,
        "Question_body":"Hey there,\n\nI am writing my masters thesis at the moment.\u00a0In my master thesis I compare the machine learning services of Google and Microsoft for image classification. This also includes the costs. Google uses node hours and Microsoft computing hours for the calculation. Is it possible to compare these units? This would be a crucial part of the comparison.\nThanks a lot!",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"GPT-3 access",
        "Question_creation_time":1605179070400,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/160489\/gpt-3-access.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"I'd like to use GPT-3 for my application. I understand MS has licensed GPT-3 from OpenAI, and that there is pricing too. So how do I get to use GPT-3?\n\n\n\n\nChris Powell",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-12T12:05:07.94Z",
                "Answer_score":0,
                "Answer_body":"@Crispy-1600 Thanks for the question, Innovations from our GPT-3 workstreams will be incorporated in later versions of Azure. In the meantime, If you are interested in participation in the OpenAI GPT-3 and Azure Service partnership please fill out this form to submit a request.\n\nIgnite blog announcement: https:\/\/blogs.microsoft.com\/ai-for-business\/ai-at-scale-ignite\/",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning excel add-ins error",
        "Question_creation_time":1659592116103,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/954559\/azure-machine-learning-excel-add-ins-error.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":1,
        "Question_body":"Hi Everyone,\n\nHas anyone else experienced this issue before ? It was working fine yesterday and the web service is also fine. Just that the Excel Add-Ins is having this problem. It's saying \"The content is blocked because it isn't signed by a valid security certificate\". I am not sure where else to ask. Kindly help.\n\nThanks,\nAiman",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-04T07:07:32.937Z",
                "Answer_score":1,
                "Answer_body":"It seems that this issue is now solved. Thank you.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Text Classification Import Text Files",
        "Question_creation_time":1659040614790,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/946690\/azure-ml-text-classification-import-text-files.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi,\n\nI'm trying to create an Azure Machine Learning model to classify text files. I have hundreds of text files that have been organized into a subfolder named its correct label. Similar to how you train Image classification.\n\nHow would I get this data into a data set. I have been trying to use the python sdk since I was able to successfully get the Image classification to work.\n\nThanks,\nKyle",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-04T04:07:43.577Z",
                "Answer_score":0,
                "Answer_body":"@DomsohnKyle-2610 Thanks for the question. Here is the sample to import text files and explore azure ml text classification.\n\nhttps:\/\/github.com\/microsoft\/nlp-recipes\/blob\/master\/examples\/text_classification\/tc_bert_azureml.ipynb",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"time series training",
        "Question_creation_time":1659301076627,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/949086\/time-series-training.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I see one document mentioned time series training can be done with AutoML: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-forecast is that any sample which from basic build of model?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-01T08:47:41.097Z",
                "Answer_score":0,
                "Answer_body":"Hello @matsuoka-4412\n\nThanks for using Microsoft Q&A platform, we don't have any samples for basic build of a model in AutoML, but we do have quick start for how to use time series in AutoML - https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-automated-ml-forecast\n\nThis is a low code sample for beginning user. Please take a look.\n\n\n\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Thank You to the Microsoft Q&A Community Champions",
        "Question_creation_time":1638285424440,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/646256\/thank-you-to-the-microsoft-qampa-community-champio.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":69,
        "Question_follower_count":118,
        "Question_score":41,
        "Question_body":"We would like to celebrate this month's\u202fCommunity Champions\u202ffor their great contribution to the community on Microsoft Q&A!\n\nMicrosoft Q&A Community Champions\u202fprogram recognizes external technology experts who contribute to the Microsoft Q&A community by providing quality answers to the technical questions. They are our true \u2018champions\u2019 and provide additional help by taking moderator roles and provide suggestions to improve our overall platform as well as user experience. This program includes both MVPs and non-MVP expert users.\n\nWe recognize top contributors by providing incentives like moderator privileges in Microsoft Q&A platform, gift cards and also share about Q&A contributions in social media channels like Azure Support Twitter handle and in Microsoft Q&A Azure Leaderboard.\n\nThank You to all the Microsoft Q&A Community Champions.\nThey are helping make Microsoft Q&A a vibrant place for learning.\n\n@AlanKinane @AlbertoMorillo @AndreasBaumgarten @andriybilous @AndyDavid @arunano @Cooldadtx @CristianSpiridon72 @danguzman @davidlowndes-6766 @dev073 @DSPatrick @glenscales-6756 @JackLee-MVP @jaiverma-7010 @JaliyaUdagedara @kasunraj @learn2skills @LeonLaude @ManuPhilip @MartinCairney-6481 @MatthijsvdVeer @michev @mohamedmustafa-7057 @NandanHegde-7720 @nasreen-akter @nikhilmahajan-8887 @PierreLucGiguere-5297 @Pituach @pvanberlo @rahultherayil-7956 @riteshmishra-6694 @Sam-Cogan @samy-7940 @sandervandevelde42 @sanm-7576 @SashaKranjac @Sean-Liming @shwetamathur @sreejukg @stan @Taz-3478 @thomasboersma @vaibhavchaudhari @svikram\n\nAlso, if you are interested in joining the Microsoft Q&A Community Champions program and help shape the future of Microsoft Q&A, please apply here:\u202fCommunity Champions Application form\n\nSpecial invitation to:\n\n@arkiboys @MarkKromer-2402 @TomPhillips-1744 @jhueppauff\u202f@cooldadtx @RyanAbbey-0701 @BillBell-6414 @David-3633 @sadomovalex @OlafHelper-2800 @yagmoth555 @cakriwut @MalleswarReddy @Rahulkps23 @ehsanzarei-0981 @stoyanchalakov @zhenhuali-3848",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"registering model with its associated data in azure ml",
        "Question_creation_time":1657796790130,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/926828\/registering-model-with-its-associated-data-in-azur.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"i registered a model using the cli command \"az ml model register\" it work fine, but the registered model has no dataset associated with it\n\n\n\n\n\n\nso is there a way to link the dataset that have been used to train the model to appear in the data tab ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-15T02:01:10.157Z",
                "Answer_score":0,
                "Answer_body":"@abdelrahmanadel-2140 Thanks for the question. we are able to see the dataset under data as shown below. Can you please share the sample that you are trying.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"'Error: AADSTS70016: OAuth 2.0 device flow error. Authorization is pending. Continue polling when submitting experiment",
        "Question_creation_time":1657211874993,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/918457\/39error-aadsts70016-oauth-20-device-flow-error-aut.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":46,
        "Question_score":0,
        "Question_body":"Hi I am trying to run an azureml pipeline using a compute instance through Azureml SDK.\n\n\n\n\nAfter over 15 minutes of waiting I get the error 'Error: AADSTS70016: OAuth 2.0 device flow error. Authorization is pending' , if I run the same code but with the computer target as local it runs right,\n\nI know that it is an autetication problem, but it is not clear to me how can I solve it. Thanks for any advice",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-07T22:06:44.683Z",
                "Answer_score":0,
                "Answer_body":"Hello @amoozegarashahrzad-9328, the error is displayed due a browser (interactive authentication) not being available for the pipeline to run. Please take a look to Set up authentication for Azure Machine Learning resources and workflows for more information on authentication options.\n\n\n\n\n\nLet us know if this answer was helpful to you or if you need additional assistance. If it was helpful, please remember to accept it and complete the quality survey so that others in the community with similar questions can more easily find a rated solution.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is it possible to use KFold cross-validation without shuffling in Azure AutoML?",
        "Question_creation_time":1657930963903,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/929194\/is-it-possible-to-use-kfold-cross-validation-witho.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Is it possible to disable shuffling when using kfold cross-validation in Azure AutoML? I have a dataset with significant correlation between adjacent samples and would like to use continuous chunks as validation folds. I'm aware I can manually create a validation set, but as my dataset is small I would prefer to use multiple continuous folds if possible.\n\nAlso, as not shuffling is default behavior in scikit-learn, I'm concerned this could be a trap for naive users.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-18T10:51:55.053Z",
                "Answer_score":0,
                "Answer_body":"@SchibliEric-0296 Thanks for the question. Currently disable shuffling when using kfold cross-validation in Azure AutoML is not supported. We have forwarded to the product team to support in the near future.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"ML pipeline not shown up in Azure Data Factory",
        "Question_creation_time":1657836174723,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/927602\/ml-pipeline-not-shown-up-in-azure-data-factory.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":20,
        "Question_score":0,
        "Question_body":"I would like to trigger azure ml pipeline in ADF and the connection to azure ml is successful, but no pipeline is found in the drop down list. I have several pipeline endpoints (Pipelines > Pipeline endpoints) in Azure ML. Did I miss something?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-19T03:14:00.3Z",
                "Answer_score":0,
                "Answer_body":"@kkc8795 Thanks for the details. Please share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Recommendations on handling the models",
        "Question_creation_time":1657703130580,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/924897\/recommendations-on-handling-the-models.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi,\n\nI'm currently experimenting with ML.NET.\nThe goal is to be able to forecast values for future months based on historical data.\n\n\n\n\nExample scenario:\n\nLet's say a company named XYZ has 10 stores across United States and each branch has it's own historical sales data for the past year.\n\nIf I want to forecast the Net income for each store for the next 6-12 months, does that mean we'll have 1 model for each store since each store has its own set of data?\n\nIf yes, do you have a recommendation on how to organize these models? Are all the models part of the same zip file?\n\nAlso, for any given day, new data comes in for each store, is there a way to automatically add these new data to the model's knowledge?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-14T03:26:58.537Z",
                "Answer_score":0,
                "Answer_body":"@Francis-5653 Thanks for the question. We would recommend using Azure ML for Recommendations.Azure Machine Learning (AML) makes it easy to train, operate, and manage hundreds or even thousands of models. This repo will walk you through the end to end process of creating a many models solution from training to scoring to monitoring.\nThis scenario (MANY MODELS) is very common most of all for Time Series Forecasting. Here is the sample for retails use case.\nhttps:\/\/github.com\/microsoft\/solution-accelerator-many-models\/",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Given allow_reuse set to false and regenerate_outputs set to True when the pipeline is submitted then it stucks at the running stage with first step saying \"Not Started\"",
        "Question_creation_time":1657676507390,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/924406\/given-allow-reuse-set-to-false-and-regenerate-outp.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi,\n\nI am using Azure Machine Learning SDK in python to create a pipeline which needs to read data from Azure SQL Database, perform transformation, model the data as per need and store the output back to Azure SQL Database. In this scenario, I need to run the published pipeline every time(without reusing output from previous run) because underlying data changes. To resolve this problem I set allow_reuse flag to False in PythonScriptStep(). Also, I set regenerate_outputs=True while submitting the pipeline. Following is the code:\n\nfrom azureml.pipeline.steps import PythonScriptStep\ndataprep_source_dir = \".\/\"\nentry_point = \"Fetch_Data.py\"\ndata_fetch_step = PythonScriptStep(\nname=\"Fetch step\",\nscript_name=entry_point,\nsource_directory=dataprep_source_dir,\narguments=[\"--fetched-data\", fetched_data_folder],\noutputs=[fetched_data_folder],\ncompute_target=target_compute,\nrunconfig=aml_run_config,\nallow_reuse=False\n)\n\npipeline_run = Experiment(workspace, 'exp_name').submit(pipeline1, regenerate_outputs=True)\n\nIt was working fine until last month and every time pipeline was generating outputs which I intend to (not using result from previous run) but this week it started to give me another weird problem. When I am submitting the pipeline first time, I see the first step is \"Not Started\" saying that rerun will be used (which it should not as allow_reuse set to false) and weirdly the rerun id of that step and current runId is same. So finally nothing happens and pipeline stays in running stage for like 12 hrs until I cancel it.\n\n\n\n\n\n\n\n\nPlease help me fix this issue. It is very weird that I can't submit pipeline where I don't want to reuse previous job run results.\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-19T03:19:31.13Z",
                "Answer_score":0,
                "Answer_body":"@annushokeenteamtelstracom-0813 Thanks for the details. We would recommend to raise a Azure support desk ticket from Help+Support blade from Azure portal for your resource if you have a support plan for your subscription. This will help you to share the details securely and work with an engineer who can provide more insights about the issue that if it can be replicated.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"No request body provided or error in deserializing the request body.",
        "Question_creation_time":1657494568657,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/921005\/no-request-body-provided-or-error-in-deserializing.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi,\nI used the sample azure ml web service request in R to send a simple request using\nlibrary(\"jsonlite\") since the rson is not able to install to my R studio:\n\nreq = list(\n\n     Inputs = list(\n \n         \"input1\" = list(\n             \"ColumnNames\" = list(\"Log_Type\", \"Ad_Slot_Height\", \"Ad_Slot_Visibility\", \"Ad_Slot_Floor_Price\"),\n             \"Values\" = list( list( \"1\", \"250\", \"FirstView\", \"0\" ),  list( \"2\", \"90\", \"OtherView\", \"20\" )  )\n         )                ),\n     GlobalParameters = setNames(fromJSON('{}'), character(0))\n\n)\nPrint(body):\n{\"Inputs\":{\"input1\":{\"ColumnNames\":[[\"Log_Type\"],[\"Ad_Slot_Height\"],[\"Ad_Slot_Visibility\"],[\"Ad_Slot_Floor_Price\"]],\"Values\":[[[\"1\"],[\"250\"],[\"FirstView\"],[\"0\"]],[[\"2\"],[\"90\"],[\"OtherView\"],[\"20\"]]]}},\"GlobalParameters\":{}}\n\nWhy it's not working?\n\nPlz help asap!\nN.A.W.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-11T16:56:24.807Z",
                "Answer_score":0,
                "Answer_body":"@NAW123-0733 Thanks for the question. Can you please add more details about the error that you are getting.\nYou'd need to use JSON.stringify() method to convert postData value to a JSON string before you send a POST request.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"azure guidance video out of date in YouTube",
        "Question_creation_time":1659301109740,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/949113\/azure-guidance-video-out-of-date-in-youtube.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"hello, I was doing some search in the internet about azure machine learning, I found videos published in YouTube but out of date. Please update it",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-08-01T01:19:53.043Z",
                "Answer_score":0,
                "Answer_body":"Hello @matsuoka-4412\n\nThanks for the feedback, we are aware of this issue and have forwarded the feedback to product group. Sorry for the experience.\n\nActually some of the videos are for some technicle event, I will suggest content team to deliver the video with more version info so that future audience will not be confused.\n\n\n\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Store real time inference data from Azure ML",
        "Question_creation_time":1658947320020,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/944890\/store-real-time-inference-data-from-azure-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"The models trained on Azure have - model object, scoring script and environment settings.\nWe are eying complete MLOps automation and that means that we do not touch anything from from training to deployment to monitoring.\n\nHow can I capture data that came for inference to real time deployed model without touching scoring script (as it is generated as part of training).",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-28T06:56:35.067Z",
                "Answer_score":0,
                "Answer_body":"@82945577 You can enable application insights on the ML endpoint which will log all details of the input without updating your scoring file to log additional data.\nA simple call using the SDK can set this value.\n\n aks_service.update(enable_app_insights=True)\n\n\n\nAdditional ways to set this value and get the data is available in documentation here.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Negative Samples in ML Assisted Image Labeling",
        "Question_creation_time":1658973322783,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/945298\/negative-samples-in-ml-assisted-image-labeling.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"We are evaluating the Azure ML Assisted Object detection labeling and I have some questions:\n1. How do I mark an image as a negative?\n2. How do I rename a label?\n3. How do I go back to a skipped image?\n4. When labeling if I discover that an image should not be in the dataset, how do I delete it from the dataset? The id of the image is no where to be found.\n5. For an autolabeled image, if I accidentally delete the bounding box, how do I undo this operation?\n6. Sometime the autolabeler creates small bounding boxes without any labels. Is this a bug?\n\nThank you",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-28T09:37:46.757Z",
                "Answer_score":0,
                "Answer_body":"@PrashantSaraswat-9512 I think I can answer some of your questions from some of the projects I used for labeling.\n\nHow do I mark an image as a negative?\nUnlike the Azure custom vision labeling experience, there isn't a feature to mark a label as negative. I believe you can add another label and use it as a negative label and tag images.\n\nHow do I go back to a skipped image?\nGo to the Data tab of your project and select Review Labels tab from the side. Using the filters option on right hand side, set the Asset Type as \"Skipped\". This should pull any skipped images and you should be able to assign the required label and a button should be enabled to update label. The same applies for updating any labeled image or bounding box.\n\n\nHow do I rename a label?\nI think a label cannot be renamed after it is created. You can delete all labels and create a new set though. Just stop your project and select the Details-> Label Classes tab and click Add label option to see this screen.\n\n\nWhen labeling if I discover that an image should not be in the dataset, how do I delete it from the dataset? The id of the image is no where to be found.\nI think you can skip the image since the dataset is registered while creating a project there is no option to delete certain images after this action.\n\nFor an autolabeled image, if I accidentally delete the bounding box, how do I undo this operation?\nI have not used auto labeling before but the same step to update the skipped image or label should help you with this step.\n\nSometime the autolabeler creates small bounding boxes without any labels. Is this a bug?\nNot sure about this issue since I haven't come across it. You could report through support or through portal using the smiley image on the top right hand corner.\n\nI hope this helps!!\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Endpoint Deletion",
        "Question_creation_time":1628657145543,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/509079\/endpoint-deletion.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":16,
        "Question_score":0,
        "Question_body":"Hi , I Have tried to deploy a time series model which was created using Auto-Ml,and i tried to deplot that model as a Azure Container instance service ,but it got failed,in the model section it shows deploy status as Failed but in the Endpoints Section it shows that the deployment is in transitioning state,So I'm unable to delete the Endpoint ,can you help me resolve this?\n\nNiranjan",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Unable to deploy model in Real-time \/ Online Endpoint",
        "Question_creation_time":1658225492927,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/932550\/unable-to-deploy-model-in-real-time-online-endpoin.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":1,
        "Question_body":"Hi,\n\nWhile trying to deploy mlflow model in Realtime endpoint , I am getting the following error:-\n\n\"Deployment failed due to missing NCD Model or default environment definition\"\n\n\n\nONLINE DEPLOYMENT FILE CONFIG:-\n\n$schema: https:\/\/azuremlschemas.azureedge.net\/latest\/managedOnlineDeployment.schema.json\nname: aiml-test-deploy-008\nendpoint_name: aiml-online-ep-008\nmodel: azureml:taxi-model@latest\ntype: mlflow_model\ninstance_type: Standard_DS2_v2\ninstance_count: 1\ntype: managed\n\n\n\n\n\n\nI have all those files in Artifacts also. Kindly let me know what was causing the issue",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-26T14:11:18.54Z",
                "Answer_score":1,
                "Answer_body":"Hi @ramr-msft I forget to add type=mlflow_model in the model registration step, so it got registered as custom model. Now after adding it got registered as mlflow model and the error is resolved now. Thank you",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is it possible to write to synapse from ml studio using python SDK?",
        "Question_creation_time":1656484327123,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/907522\/is-it-possible-to-write-to-synapse-from-ml-studio.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi Team,\n\nI am trying to write to Azure SQL database from Azure ML studio. When I create a pipeline in designer, I can use Export Data Component to write data to a table in Azure SQL database. Our platform team has added a datastore with type as Azure SQL database in ML studio workspace. So, I can select the respective datastore, give table name and copy data using export data component in designer.\n\nHowever, my intention is to write a Python script to create a pipeline. I don't find any step in ML Python SDK which can be used same as Export data component in designer. I want to write my results generated within the pipeline back to a table in Azure SQL database.\n\nSolutions tried:\nStoring the result first in blob storage and then using datatransferstep() to copy that result to Azure SQL database. But this can't work for me because it requires ADF instance.\n\nIs there any other way to directly write to Azure SQL databasein ML Python SDK instead of using datatransferstep and copying to blob storage?\nDue to restricted permissions, I can't create ADF instance to use for datatransferstep.\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-29T12:26:10.593Z",
                "Answer_score":0,
                "Answer_body":"@annushokeenteamtelstracom-0813 Unlike the studio version which allows to configure export data module to use an Azure SQL database the SDK does not yet support the same. Similar clarification is provided in this issue on the SDK repo. A workaround that some users use is by using the pyodbc package in the execute python script step module since you cannot use the datatransferstep()",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azurerml v2 Pipeline: Steps not running in the mentioned conda environment",
        "Question_creation_time":1656965879723,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/913607\/azurerml-v2-pipeline-steps-not-running-in-the-ment.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hello I am trying to create a pipeline using the documentation of Azureml v2. But the steps in a Job are not running in the environment mentioned in the yaml script of the pipeline. I don't know where I am going wrong. I am hereby attaching the yaml I created to create the pipeline. Please do let me know how to tackle this issue:\n\n$schema: https:\/\/azuremlschemas.azureedge.net\/latest\/pipelineJob.schema.json\ntype: pipeline\nexperiment_name: ccep_training\ndescription: Training Pipeline to train a model that predicts coke and non coke bottles\ninputs:\n training_images:\n    type: uri_folder\n    mode: download # pick ro_mount, rw_mount or download\n    path: azureml:\/\/datastores\/ccepdatastore\/paths\/yolo\/dummy_dataset\/**\noutputs:\n  step_output_train:\n    type: uri_folder\nsettings:\n  default_datastore: <NAME OF DATASTORE>\n  continue_on_step_failure: false\njobs:\n  train:\n    name: training\n    display_name: Model-training\n    environment: azureml:ccep_train_env@latest\n    code: ..\/..\/ccep\/training\n    command: >-\n      python train_aml.py\n      --model_name ${<!-- -->{inputs.model_name_train}}\n      --step_output ${<!-- -->{outputs.step_output}}\n      \n    inputs:\n      model_name_train: \"ccep.pt\"\n      model_name_tflite: \"ccep-fp16.tflite\"\n      dataset_version: \"latest\"\n      epochs: 1\n      data_file_path: ${<!-- -->{parent.inputs.training_images}}\n      caller_run_id_param: none\n      dataset_name: \"dummy_dataset\"\n    outputs:\n      step_output: ${<!-- -->{parent.outputs.step_output_train}}\n    compute: azureml:ccepcomputeclust\n    resources:\n      instance_count: 1",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-05T12:16:14.39Z",
                "Answer_score":0,
                "Answer_body":"@RachitAhuja-3532 Looking up some of the samples from the azureml previews repo, does the code need to specify the local_path key in the yaml before specifying the path?\n\n code:\n   local_path: .\/train_src",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unable to create Dataset using azureml sdk",
        "Question_creation_time":1657779749267,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/926455\/unable-to-create-dataset-using-azureml-sdk.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi,\nActually I am trying to create dataset using sdk, but keep on getting this error message\n\n DatasetValidationError: DatasetValidationError:\n Message: Failed to validate the data.\n ScriptExecutionException was caused by StreamAccessException.\n StreamAccessException was caused by AuthenticationException.\n Authentication failed for 'AzureBlob GetReference' operation at '[REDACTED]' with '403: AuthenticationFailed'. Please make sure the SAS token or the account key is correct.\n Failed due to inner exception of type: StorageException\n | session_id=***************************\n InnerException None\n ErrorResponse\n {\n \"error\": {\n \"code\": \"UserError\",\n \"message\": \"Failed to validate the data.\\nScriptExecutionException was caused by StreamAccessException.\\r\\n StreamAccessException was caused by AuthenticationException.\\r\\n Authentication failed for 'AzureBlob GetReference' operation at '[REDACTED]' with '403: AuthenticationFailed'. Please make sure the SAS token or the account key is correct.\\r\\n Failed due to inner exception of type: StorageException\\r\\n| session_id=*************************\"\n }\n }\n\n\n\nI changed the key and revalidated it multiple times but it is giving the same error.\nYesterday I had also faced the similar type of issue while creating environment using sdk.\n\n ActivityFailedException: ActivityFailedException:\n     Message: Activity Failed:\n {\n     \"error\": {\n         \"code\": \"UserError\",\n         \"message\": \"Creating conda environment failed with exit code: 1\",\n         \"messageParameters\": {},\n         \"details\": []\n     },\n     \"time\": \"2022-07-14T07:21:34.797598Z\"\n }\n     InnerException None\n     ErrorResponse \n {\n     \"error\": {\n         \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"Creating conda environment failed with exit code: 1\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"2022-07-14T07:21:34.797598Z\\\"\\n}\"\n     }\n }\n\n\n\nPlease note I am not facing any type of issue if I perform actions using the Azure portal.\n\nRegards,\nAlok",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-14T13:46:44.767Z",
                "Answer_score":0,
                "Answer_body":"@AlokNagar-6335 I believe you have updated your storage account keys which fails to create a dataset when you use the SDK?\nIf Yes, then I think you need to run a sync-keys command by using the ML cli and the SDK.\n\n az ml workspace sync-keys -w myworkspace -g myresourcegroup\n\n\n\nRe-register datastores via the Python SDK\n\n # Re-register the blob container\n ds_blob = Datastore.register_azure_blob_container(workspace=ws,\n                                           datastore_name='your datastore name',\n                                           container_name='your container name',\n                                           account_name='your storage account name',\n                                           account_key='new storage account key',\n                                           overwrite=True)\n # Re-register file shares\n ds_file = Datastore.register_azure_file_share(workspace=ws,\n                                       datastore_name='your datastore name',\n                                       file_share_name='your container name',\n                                       account_name='your storage account name',\n                                       account_key='new storage account key',\n                                       overwrite=True)\n\n\n\nIt is important to perform all steps, updating both the workspace using the CLI, and datastores using Python. Updating only one or the other may cause errors until both are updated.\nI think this is what could be causing your updates from SDK to fail. The steps mentioned in referenced document should help to get this fixed.\n\nYou can also re-run the steps from the studio as mentioned in step 3b of the document.\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Can I download onnx model from pipeline create by Azure Machine Learning Designer",
        "Question_creation_time":1658129471700,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/930701\/can-i-download-onnx-model-from-pipeline-create-by.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I don't understand the model format trained by pipeline create by Azure Machine Learning Designer, Like default Linear Regression. Can I download the onnx format model? and How.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-18T12:37:14.667Z",
                "Answer_score":1,
                "Answer_body":"@QingShuang-7885 If the pipeline is created using the designer, then the train model module output would be .ilearner file which is a binary format that encapsulates the statistical patterns learned from the data. You cannot directly modify or read this format; however, other components can use this trained model in your pipelines and you can register the model and deploy it as a endpoint. Please refer this document for more details about the training process.\n\nHowever, if you use the SDK and register a different model format you can download the trained model and convert it to ONNX if it is supported from the listed formats on this page.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Auzre ML realtime endpoint deployment stuck after source folder upload",
        "Question_creation_time":1658139184840,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/930850\/auzre-ml-realtime-endpoint-deployment-stuck-after.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hi,\n\nUsing either Azure CLI or Python SDK V2, realtime endpoint deployment gets stuck forever after source folder is uploaded. Any suggestions? Thanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-21T03:48:41.097Z",
                "Answer_score":1,
                "Answer_body":"@romungi-MSFT It looks like that using CLI or Python SDK, the deployment process always gets stuck after the upload of large files (model or other assets). Only when the model is uploaded and registered beforehand using Azure ML studio UI, the deployment process can succeed whether via CLI, Python SDK or the studio UI.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Cannot Use the ML CLI v2",
        "Question_creation_time":1658311750460,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/934301\/cannot-use-the-ml-cli-v2.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"After installing the ML CLI v2, following the steps here: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-cli?tabs=public,\nI get the following error. For instance, when calling: az ml -h\n\ncannot import name 'ARMChallengeAuthenticationPolicy' from 'azure.mgmt.core.policies' ([FILEPATH]_init_.pyc)\n'ml' is misspelled or not recognized by the system.\n\n\n\n\n{\n\"azure-cli\": \"2.23.0\",\n\"azure-cli-core\": \"2.23.0\",\n\"azure-cli-telemetry\": \"1.0.6\",\n\"extensions\": {\n\"ml\": \"2.6.1\"\n}\n}",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-20T11:37:18.893Z",
                "Answer_score":0,
                "Answer_body":"@MLopsuser-4103 I think this was a known issue with older versions of Azure cli failing to support the Azure ML cli. Is it possible to upgrade the Azure cli version to a version >=2.30?\nA manual upgrade with the following command should work:\n\n az upgrade\n\n\n\nI personally uninstalled older version of azure cli and installed the latest version of Azure cli and then installed the azure ml cli extension. This is the current setup with the latest version that works fine.\n\n az version\n {\n   \"azure-cli\": \"2.38.0\",\n   \"azure-cli-core\": \"2.38.0\",\n   \"azure-cli-telemetry\": \"1.0.6\",\n   \"extensions\": {\n     \"ml\": \"2.6.1\"\n   }\n }\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Hyperparamter optimization in Azure AutoML",
        "Question_creation_time":1625435556057,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/462352\/hyperparamter-optimization-in-azure-automl.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Which type of hyperparameter optimization is used in Azure Automated Machine Learning (not the SDK) as default? Grid Search, Random Search, Bayesian? In the SDK you can specify that but in the AutoML section you can not specify that and there is no further information on that",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-06T02:37:14.027Z",
                "Answer_score":2,
                "Answer_body":"@MagnusEschment-2555 Thanks for the question. Can you please add more details about the document that you are trying.\nTo clarify, what exactly are you optimizing for? Are you optimizing the parameters of the ML model to maximize model accuracy? If so:\n\u2022 Random forest is pretty lightweight, so you may be able to just brute force grid search to get the best model\n\u2022 If that costs is too high, consider using Bayesian (or similar) methods for tuning hyperparameters.\nYou can select the Algorithm name of a completed model to explore its performance details. Please follow the document to explore models.\nSet up AutoML with Python: The primary metric parameter determines the metric to be used during model training for optimization. Azure AutoML supports a specific list of primary metrics per ML task, which are defined in docs, as mentioned below: Set up AutoML with Python - Azure Machine Learning | Microsoft Docs.",
                "Answer_comment_count":5,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is there any additional cost when I attach Azure Databricks cluster in Azure Machine Learning Workspace?",
        "Question_creation_time":1658728943337,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/940007\/is-there-any-additional-cost-when-i-attach-azure-d.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":24,
        "Question_score":0,
        "Question_body":"Is there any additional cost when I attach Azure Databricks cluster in Azure Machine Learning Workspace?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-25T14:38:49.44Z",
                "Answer_score":0,
                "Answer_body":"Hello @DevashishUpadhyay-3566\n\nThanks for reaching out to us about the pricing issue. Let me clarify this for you. I think you are mentioning about a process like this - https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-databricks-automl-environment\n\nFor attachment, there is no additional fees.\n\nFor Azure Machine Learning side pricing, it depends on your setting\/ saving options\/ ..., I would highly recommend you to estimate the price by Azure Calculator, you can add both Databrick and Machine Learning with more details - https:\/\/azure.microsoft.com\/en-us\/pricing\/calculator\/\n\nYou can set everything as below, if you have any question regarding to this question or your estimate, please let us know, we are glad to help further.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Estimate the cost for Machine learning SDK or UI portal",
        "Question_creation_time":1658729307217,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/940045\/estimate-the-cost-for-machine-learning-sdk-or-ui-p.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hello experts, we are working on a medium size solution for our company and we are exploring basic estimate for SDK or studio decision. How I can know?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-25T13:57:02.623Z",
                "Answer_score":0,
                "Answer_body":"Hello @Alexandre-2525\n\nThanks for reachin out to us, the Azure Machine Learnng pricing mainly is consist of CPU pricing and compute pricing, to get a better estimate pricing, a good way to calculate is using the calculator - https:\/\/azure.microsoft.com\/en-us\/pricing\/calculator\/\n\nYou can add your details into it and you will have a general idea about that.\n\nI hope this helps, thank you.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"ML Compute Instance stopped provisioning RStudio",
        "Question_creation_time":1656439437333,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/906921\/ml-compute-instance-stopped-provisioning-rstudio.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":13,
        "Question_score":1,
        "Question_body":"Hi all,\n\nJust wondering if anyone knows why Azure ML compute instance suddenly stopped provisioning RStudio?\n\n\nI have tried to set up a custom app using ghcr.io\/azure\/rocker-rstudio-ml-verse:latest, but it is not able to access the files (e.g. files that are previously accessible via the automatically provisioned RStudio, jupyter, jupyterhub, terminal etc)\n\nWould be great if you could provide any guidance etc.\nthanks a lot.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-06T01:04:49.597Z",
                "Answer_score":1,
                "Answer_body":"Any update there? I have seen some changes but unlucky there is no clear information. Can you share any good way to find the release note?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-07-25T13:39:17.73Z",
                "Answer_score":0,
                "Answer_body":"I just provisioned a new ML instance and can confirm that it does not have RStudio installed.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"deployment issue in Azure.",
        "Question_creation_time":1631818774143,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/555483\/deployement-issue-in-azure.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hello, I am a beginner in Azure ML. I am trying to deploy a machine learning model (consisting of a h5 file and a pickle file) in Azure. But when I call the web-service error is coming up.\n\n  Pip subprocess error:  \n     ERROR: Could not find a version that satisfies the requirement pickle (from -r \/azureml-environment-setup\/condaenv.b2ewzkd8.requirements.txt (line 5)) (from versions: none)  \n\n\n\nI am using Jupiter notebook with SDK 1.34, Python version 3.8.11 and pickle version 4. Can anyone help. Thank you.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-23T03:23:22.897Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nSorry not hear from you back. Since we don't have much information, there are two possible solution:\n\nYou can pip install pickle by running command pip install pickle-mixin. Proceed to import it using import pickle. This can be then used normally.\n\nIf you are using Python 3.7, pickle should be installed by default, you can call it directly by import pickle.\n\n\n\n\nPlease let us know if you still have issue about this.\n\nRegards,\nYutong",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Test section blank after deployment",
        "Question_creation_time":1658298895807,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/933895\/test-section-blank-after-deployment.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":8,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi ,\n\nAm trying to deploy Two-Class Logistic Regression model endpoint using AZML Designer. But I cant get the \"Test\" to show as I expect it to . Please find attached the images and logs",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure machine learning sdk v2 release plan",
        "Question_creation_time":1658322711003,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/934478\/azure-machine-learning-sdk-v2-release-plan.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi, I have seen some questions in this forum saying v2 is in preview, but some functions are there already. Can you share the release plan?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-20T20:29:14.517Z",
                "Answer_score":0,
                "Answer_body":"Hello @Alexandre-2525\n\nSDK v2 is currently in public preview. The preview version is provided without a service level agreement, and it's not recommended for production workloads. Certain features might not be supported or might have constrained capabilities. For more information, see Supplemental Terms of Use for Microsoft Azure Previews. https:\/\/azure.microsoft.com\/en-us\/support\/legal\/preview-supplemental-terms\/\n\nSome of the functions is still in private preview of SDK v2, so at this time, we are not recommending it for production, but you could try it for testing. We are working on bringing features to v2 step by step.\n\nAzure ML Python SDK v2 is an updated Python SDK package, which allows users to:\n\nSubmit training jobs\n\n\nManage data, models, environments\n\n\nPerform managed inferencing (real time and batch)\n\n\nStitch together multiple tasks and production workflows using Azure ML pipelines\n\n\nThe SDK v2 is on par with CLI v2 functionality and is consistent in how assets (nouns) and actions (verbs) are used between SDK and CLI. For example, to list an asset, the list action can be used in both CLI and SDK. The same list action can be used to list a compute, model, environment, and so on.\n-\n\nI hope this helps.\n\n\n\n\nRegards,\nYutong\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"When using AutoML for forecasting, is it possible to include lagged exogenous features?",
        "Question_creation_time":1657059623547,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/915375\/when-using-automl-for-forecasting-is-it-possible-t.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"In the documentation, it states \"When training a model for forecasting future values, ensure all the features used in training can be used when running predictions for your intended horizon. For example, when creating a demand forecast, including a feature for current stock price could massively increase training accuracy. However, if you intend to forecast with a long horizon, you may not be able to accurately predict future stock values corresponding to future time-series points, and model accuracy could suffer,\" which seems to imply only features that are known or can reasonably be estimated in the future should be used. This seems like a pretty severe limitation. Is it really not possible to include exogenous features that should be lagged like the target is?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-06T15:50:57.7Z",
                "Answer_score":0,
                "Answer_body":"@SchibliEric-0296 Thanks for the question. Can you please add more details about the use case?. Please check here, Auto-train a time-series forecast model - Azure Machine Learning | Microsoft Docs\n\nHowever it may not be right to deal with this just by filling using the previous patterns. One suggestion is to include an exogenous variable in the model like the statistics for the region and model how this exogenous variable has influenced the target (which could be zero as well). Retraining the model on regular intervals with additional data on the frequency they collect will be required to keep up to the change in patterns due to external factors.\n\nPlease check the below many models accelerator which models timeseries data (but in a different domain). This can be useful.\nbuswrecker\/energy-many-models: An offshoot of the original AML Many-Models - for the Energy Sector (github.com)",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error invoking the azure ML pipeline from Azure Devops",
        "Question_creation_time":1658316045857,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/934296\/error-invoking-the-azure-ml-pipeline-from-azure-de.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":1,
        "Question_body":"When I tried invoking an Azure ML pipeline from an Azure DevOps pipeline, I keep running into errors, Can you please share any sample that works.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-20T11:47:28.817Z",
                "Answer_score":1,
                "Answer_body":"@Srin-4824 Thanks for the question. yes this is possible just use the Azure CLI task - Azure Pipelines step and run command line or Python scripts inside that to submit your pipelines.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Datadrift in Azure ML SDK v2",
        "Question_creation_time":1657283475557,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/919651\/datadrift-in-azure-ml-sdk-v2.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I can't see a data drift module anywhere in v2 of the Azure ML Python SDK. Is this missing or what's the deal? If so, are there any plans of bringing it into v2?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-20T10:02:04.113Z",
                "Answer_score":0,
                "Answer_body":"Hello @SH-3152\n\nI have a good news for you, I just got confirmation from product team, the datadrift function will be in SDK V2 for sure. But for now we don't have an exact date for when. I have forwarded this feedback to product group and we hope we can bring this feature in near future.\n\n\n\n\nI hope this helps.\n\n\n\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How to upload(write) data(dataframe) to azure SQL datastore from azure machine learning(azureML) using SDK",
        "Question_creation_time":1596612863487,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/59457\/how-to-uploadwrite-datadataframe-to-azure-sql-data.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_follower_count":4,
        "Question_score":2,
        "Question_body":"From the documentation I could find ways to read data from Azure SQL database registered as datastore in azureML,but not ways to upload or write output data to azure SQL database from azureML.Can anyone please guide me on the same? Also can SQL datastore be used as output for the batch inference step",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-08T00:11:04.25Z",
                "Answer_score":0,
                "Answer_body":"Thanks for reaching out. You need to register your storage as a datastore. Then write dataframe to a local file and upload to datastore as shown below (refer to this post as well):\n\n from azureml.core import Workspace, Dataset\n    \n subscription_id = 'id'\n resource_group = 'resource group'\n workspace_name = 'workspace name'\n    \n ws = Workspace(subscription_id, resource_group, workspace_name)\n    \n #write dataframe to a local file (e.g. csv, parquet)\n local_path = 'data\/prepared.csv'\n df.to_csv(local_path)\n    \n # get the datastore to upload prepared data\n datastore = ws.get_default_datastore()\n    \n # upload the local file from src_dir to the target_path in datastore\n datastore.upload(src_dir='data', target_path='data')\n\n\n\nIf you continue to experience errors, please share your code so we can investigate further, thanks.",
                "Answer_comment_count":5,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-08-26T03:52:48.503Z",
                "Answer_score":0,
                "Answer_body":"@JothyBabu-4144 Thanks, Please follow the below repo and docker-instructions to use tools such as pyodbc and SQLAlchemy for writeback within an experiment, ParallelRunStep, etc without the need for multi-step pipelines.\n\nHere is the repo for write to sql.\n\n\n\n\n\n20383-docker-instructions.pdf",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-08-31T06:31:43.787Z",
                "Answer_score":0,
                "Answer_body":"Thanks, Please follow the below pointers for Reading and updating Azure SQL Database from Azure ML pipeline.\nDoc: https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-pipeline-steps\/azureml.pipeline.steps.data_transfer_step.datatransferstep?view=azure-ml-py\nExample: https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-data-transfer.ipynb\n\nNote: When copying data to an Azure SQL Database, data will be appended to an existing table. We also expect the source file to have a header row and the names should exactly match with column names in destination table.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error 404 for design pipelines",
        "Question_creation_time":1658146582847,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/931152\/error-404-for-design-pipelines.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hello,\n\nI am trying to run a ML pipeline that I built on Microsoft Azure design some time ago, approximately six months ago, and I realize the interface for design has changed since then. When I try to run these pipelines, I have tried with several, then I get the attached message error. Please your help to see if there is any solution.\n\nThank you!",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Export custom model\/code",
        "Question_creation_time":1620897291797,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/393890\/export-custom-modelcode.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"If I use transformer\/estimator from the sklearn package it's sufficient to export a model.pkl artifact then simply use it following the various tutorials on microsoft site.\nHowever, when I use scikit-learn's FunctionTransformer or TransformerMixin class to incorporate custom transformations how can I export the custom code to azure machine learning together with the model? (model.pkl do not contains the custom code)\nWhat is the best practice?\n\nThanks.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"403: AuthorizationPermissionMismatch",
        "Question_creation_time":1657807579977,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/926988\/403-authorizationpermissionmismatch.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi,\n\nI have my source data in a storage account and I am trying to access it from my Machine learning workspace. I have assigned system assigned managed identity to my compute cluster and I have also added \"Storage Blob Contributor\/Reader access to my machine learning workspace in the storage account IAM.\n\nBut still I am getting the below error\n\n03: AuthorizationPermissionMismatch'. Please make sure the compute or login identity has 'Storage Blob Data Reader' or 'Storage Blob Data Owner' role in the storage IAM.\nThis request is not authorized to perform this operation using this permission\n\n\n\n\n\n\n\n\nPlease help me to sort out this issue",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-19T05:48:40.483Z",
                "Answer_score":1,
                "Answer_body":"The issue is resolved. The compute managed identity is listed under service principal of IAM Access.. I selected that and I gave Storage Blob Contributor access. It then worked!! Thanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-07-19T07:15:24.157Z",
                "Answer_score":0,
                "Answer_body":"Hello @mumu-3266\n\nThanks for kindly sharing the solution to us and we are glad to know the issue has been resolved.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Delay in Code Output in Azure ML",
        "Question_creation_time":1658194083553,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/931876\/delay-in-code-output-in-azure-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":28,
        "Question_score":0,
        "Question_body":"I have been using Azure ML for last 2 months and since last 3-4 days running notebook is not behaving normal. Since my default notebooks do not have an option for indentation of code, so i manually indented my code and since then there have been issues.\nAlso the code output takes few second 5-8 seconds and sometimes even more to generate the output. My CPU on and off shows 50% consumed and i am not sure why because the data size is only in MB's - around 10k rows of data and 20 off columns.\nI am using a pretty decent compute -\n\n\nAlso here is the greyed out snippet of notebooks where it does not show any output. Could someone please advice on potential reasons for this",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Question on running an experiment",
        "Question_creation_time":1657906415713,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/928739\/question-on-running-an-experiment.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":17,
        "Question_score":0,
        "Question_body":"This is the first time I am creating an experiment with my Microsoft Azure learning machine account. I have created and saved the experiment, but I am unable to run the experiment. The system keeps bringing out error message. What could be responsible for this, please?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Change AML script",
        "Question_creation_time":1657574990310,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/922634\/change-aml-script.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"How can we change the pipeline script OR the output setting of \"regenerate output\" over the AML pipeline description page, instead of submitting the pipeline again?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"AZ ML Designer. Swagger file missing on deployment. Test empty.",
        "Question_creation_time":1657708598787,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/925083\/az-ml-designer-swagger-file-missing-on-deployment.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi Guys,\nAm trying to deploy a very small logistic regression model endpoint using AZML Designer. But I cant get the \"Test\" to show as I expect it to . I think I have narrowed it down to the same issue as the others on this thread. Please find attached the images and logs\n1.This is the inference pipeline\n\n\n\n\n\n2.This is the deployed endpoint\n\n\n\n\n\n3.The test section of the endpoint\n\n\nSwagger missing info from the logs\n\n\n\n\n\n5.Expected test section\n\n\nEntire deployment log dump below signature\n\nregards\nSharath\n\n\n\n\n\n 2022-07-13T09:30:23,130461474+00:00 - iot-server\/run \n 2022-07-13T09:30:23,157246653+00:00 - rsyslog\/run \n 2022-07-13T09:30:23,159450135+00:00 - nginx\/run \n 2022-07-13T09:30:23,197683320+00:00 - gunicorn\/run \n 2022-07-13T09:30:23,199090409+00:00 | gunicorn\/run | \n 2022-07-13T09:30:23,227403276+00:00 | gunicorn\/run | ###############################################\n 2022-07-13T09:30:23,257497428+00:00 | gunicorn\/run | AzureML Container Runtime Information\n 2022-07-13T09:30:23,267026449+00:00 | gunicorn\/run | ###############################################\n 2022-07-13T09:30:23,268411738+00:00 | gunicorn\/run | \n 2022-07-13T09:30:23,276054375+00:00 | gunicorn\/run | \n 2022-07-13T09:30:23,278626954+00:00 | gunicorn\/run | AzureML image information: openmpi3.1.2-ubuntu18.04, Materializaton Build:20220708.v2\n 2022-07-13T09:30:23,286217091+00:00 | gunicorn\/run | \n 2022-07-13T09:30:23,287579180+00:00 | gunicorn\/run | \n 2022-07-13T09:30:23,295279917+00:00 | gunicorn\/run | PATH environment variable: \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/bin:\/opt\/miniconda\/bin:\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin\n 2022-07-13T09:30:23,296728705+00:00 | gunicorn\/run | PYTHONPATH environment variable: \n 2022-07-13T09:30:23,298062894+00:00 | gunicorn\/run | \n 2022-07-13T09:30:23,306503424+00:00 | gunicorn\/run | Pip Dependencies (before dynamic installation)\n    \n EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n 2022-07-13T09:30:23,602722185+00:00 - iot-server\/finish 1 0\n 2022-07-13T09:30:23,604481070+00:00 - Exit code 1 is normal. Not restarting iot-server.\n adal==1.2.7\n applicationinsights==0.11.10\n attrs==21.4.0\n azure-common==1.1.28\n azure-core==1.24.2\n azure-graphrbac==0.61.1\n azure-identity==1.10.0\n azure-mgmt-authorization==0.61.0\n azure-mgmt-containerregistry==10.0.0\n azure-mgmt-core==1.3.1\n azure-mgmt-keyvault==9.3.0\n azure-mgmt-resource==13.0.0\n azure-mgmt-storage==11.2.0\n azure-storage-blob==1.5.0\n azure-storage-common==1.4.2\n azureml-core==1.36.0.post2\n azureml-dataprep==2.24.4\n azureml-dataprep-native==38.0.0\n azureml-dataprep-rslex==2.0.3\n azureml-dataset-runtime==1.36.0\n azureml-defaults==1.36.0\n azureml-designer-classic-modules==0.0.161\n azureml-designer-core==0.0.68\n azureml-designer-internal==0.0.56\n azureml-inference-server-http==0.4.13\n azureml-interpret==1.36.0\n azureml-model-management-sdk==1.0.1b6.post1\n azureml-pipeline-core==1.36.0\n azureml-telemetry==1.36.0\n backports.tempfile==1.0\n backports.weakref==1.0.post1\n blis==0.2.4\n cachetools==4.2.4\n certifi==2022.6.15\n cffi==1.12.3\n chardet==3.0.4\n charset-normalizer==2.0.12\n click==7.1.2\n cloudpickle==2.1.0\n configparser==3.7.4\n contextlib2==21.6.0\n contextvars==2.4\n cryptography==37.0.4\n cycler==0.11.0\n cymem==2.0.6\n dill==0.3.4\n distro==1.4.0\n docker==5.0.3\n dotnetcore2==3.1.23\n en-core-web-sm @ https:\/\/github.com\/explosion\/spacy-models\/releases\/download\/en_core_web_sm-2.1.0\/en_core_web_sm-2.1.0.tar.gz\n Flask==1.0.3\n fusepy==3.0.1\n gensim==3.8.3\n google-api-core==2.8.2\n google-auth==2.9.0\n googleapis-common-protos==1.56.3\n gunicorn==20.1.0\n idna==3.3\n imbalanced-learn==0.4.3\n immutables==0.18\n importlib-metadata==4.8.3\n importlib-resources==5.4.0\n inference-schema==1.3.0\n interpret-community==0.21.0\n interpret-core==0.2.6\n isodate==0.6.1\n itsdangerous==1.1.0\n jeepney==0.7.1\n Jinja2==3.0.3\n jmespath==0.10.0\n joblib==0.14.0\n json-logging-py==0.2\n jsonpickle==2.2.0\n jsonschema==3.0.1\n kiwisolver==1.3.1\n liac-arff==2.5.0\n lightgbm==3.2.1\n llvmlite==0.36.0\n MarkupSafe==2.0.1\n matplotlib==3.1.3\n more-itertools==6.0.0\n msal==1.18.0\n msal-extensions==1.0.0\n msrest==0.7.1\n msrestazure==0.6.4\n murmurhash==1.0.7\n ndg-httpsclient==0.5.1\n nimbusml==1.6.1\n numba==0.53.1\n numpy @ file:\/\/\/home\/conda\/feedstock_root\/build_artifacts\/numpy_1626681920064\/work\n oauthlib==3.2.0\n opencensus==0.10.0\n opencensus-context==0.1.2\n opencensus-ext-azure==1.1.5\n packaging==21.3\n pandas==1.0.4\n pathspec==0.9.0\n Pillow==8.3.2\n plac==0.9.6\n portalocker==2.5.1\n preshed==2.0.1\n protobuf==3.19.4\n psutil==5.9.1\n pyarrow==0.16.0\n pyasn1==0.4.8\n pyasn1-modules==0.2.8\n pycparser==2.21\n pycryptodomex==3.7.3\n PyJWT==2.4.0\n pyOpenSSL==20.0.1\n pyparsing==3.0.9\n pyrsistent==0.18.0\n python-dateutil==2.8.2\n pytz==2022.1\n requests==2.27.1\n requests-oauthlib==1.3.1\n rsa==4.8\n ruamel.yaml==0.16.10\n ruamel.yaml.clib==0.2.6\n scikit-learn==0.22.2\n scikit-surprise==1.0.6\n scipy==1.4.1\n seaborn==0.10.0\n SecretStorage==3.3.2\n shap==0.39.0\n six @ file:\/\/\/home\/conda\/feedstock_root\/build_artifacts\/six_1620240208055\/work\n slicer==0.0.7\n smart-open==6.0.0\n spacy==2.1.7\n srsly==1.0.5\n thinc==7.0.8\n tqdm==4.64.0\n typing-extensions==4.1.1\n urllib3==1.26.10\n wasabi==0.9.1\n websocket-client==1.3.1\n Werkzeug==1.0.1\n wrapt==1.12.1\n zipp==3.6.0\n    \n 2022-07-13T09:30:24,740357515+00:00 | gunicorn\/run | \n 2022-07-13T09:30:24,742081301+00:00 | gunicorn\/run | ###############################################\n 2022-07-13T09:30:24,747351958+00:00 | gunicorn\/run | AzureML Inference Server\n 2022-07-13T09:30:24,750376533+00:00 | gunicorn\/run | ###############################################\n 2022-07-13T09:30:24,752770513+00:00 | gunicorn\/run | \n 2022-07-13T09:30:27,698759963+00:00 | gunicorn\/run | Starting AzureML Inference Server HTTP.\n    \n Azure ML Inferencing HTTP server v0.4.13\n    \n    \n Server Settings\n ---------------\n Entry Script Name: main.py\n Model Directory: \/var\/azureml-app\/azureml-models\/amlstudio-loanv1ep002\/1\n Worker Count: 1\n Worker Timeout (seconds): 300\n Server Port: 31311\n Application Insights Enabled: false\n Application Insights Key: AppInsights key provided\n    \n    \n Server Routes\n ---------------\n Liveness Probe: GET   127.0.0.1:31311\/\n Score:          POST  127.0.0.1:31311\/score\n    \n Starting gunicorn 20.1.0\n Listening at: http:\/\/0.0.0.0:31311 (17)\n Using worker: sync\n Booting worker with pid: 70\n Collecting azureml-designer-serving==0.0.10\n   Downloading azureml_designer_serving-0.0.10-py3-none-any.whl (20 kB)\n Collecting azureml-contrib-services\n   Downloading azureml_contrib_services-1.43.0-py3-none-any.whl (4.8 kB)\n Requirement already satisfied: azureml-defaults in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-serving==0.0.10) (1.36.0)\n Requirement already satisfied: azureml-designer-core[image,model]>=0.0.32 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-serving==0.0.10) (0.0.68)\n Requirement already satisfied: Flask in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-contrib-services->azureml-designer-serving==0.0.10) (1.0.3)\n Requirement already satisfied: azureml-core~=1.36.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-defaults->azureml-designer-serving==0.0.10) (1.36.0.post2)\n Requirement already satisfied: json-logging-py==0.2 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-defaults->azureml-designer-serving==0.0.10) (0.2)\n Requirement already satisfied: azureml-inference-server-http~=0.4.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-defaults->azureml-designer-serving==0.0.10) (0.4.13)\n Requirement already satisfied: configparser==3.7.4 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-defaults->azureml-designer-serving==0.0.10) (3.7.4)\n Requirement already satisfied: azureml-dataset-runtime[fuse]~=1.36.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-defaults->azureml-designer-serving==0.0.10) (1.36.0)\n Requirement already satisfied: pyarrow==0.16.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (0.16.0)\n Requirement already satisfied: jsonschema==3.0.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (3.0.1)\n Collecting numpy==1.18.1\n   Downloading numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)\n Requirement already satisfied: pandas==1.0.4 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (1.0.4)\n Collecting python-dateutil==2.8.1\n   Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n Requirement already satisfied: distro==1.4.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (1.4.0)\n Requirement already satisfied: ruamel.yaml==0.16.10 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (0.16.10)\n Requirement already satisfied: pycryptodomex==3.7.3 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (3.7.3)\n Requirement already satisfied: more-itertools==6.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (6.0.0)\n Requirement already satisfied: Pillow==8.3.2; extra == \"image\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (8.3.2)\n Collecting cloudpickle==1.2.2; extra == \"model\"\n   Downloading cloudpickle-1.2.2-py2.py3-none-any.whl (25 kB)\n Requirement already satisfied: Werkzeug>=0.14 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from Flask->azureml-contrib-services->azureml-designer-serving==0.0.10) (1.0.1)\n Requirement already satisfied: Jinja2>=2.10 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from Flask->azureml-contrib-services->azureml-designer-serving==0.0.10) (3.0.3)\n Requirement already satisfied: click>=5.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from Flask->azureml-contrib-services->azureml-designer-serving==0.0.10) (7.1.2)\n Requirement already satisfied: itsdangerous>=0.24 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from Flask->azureml-contrib-services->azureml-designer-serving==0.0.10) (1.1.0)\n Requirement already satisfied: azure-graphrbac<1.0.0,>=0.40.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (0.61.1)\n Requirement already satisfied: PyJWT<3.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (2.4.0)\n Requirement already satisfied: jmespath<1.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (0.10.0)\n Requirement already satisfied: azure-common<2.0.0,>=1.1.12 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (1.1.28)\n Requirement already satisfied: azure-mgmt-resource<15.0.0,>=1.2.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (13.0.0)\n Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0\n   Downloading cryptography-3.4.8-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n Requirement already satisfied: jsonpickle<3.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (2.2.0)\n Requirement already satisfied: azure-mgmt-containerregistry>=2.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (10.0.0)\n Requirement already satisfied: ndg-httpsclient<=0.5.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (0.5.1)\n Requirement already satisfied: docker<6.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (5.0.3)\n Requirement already satisfied: msrestazure<=0.6.4,>=0.4.33 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (0.6.4)\n Requirement already satisfied: backports.tempfile in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (1.0)\n Requirement already satisfied: pyopenssl<21.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (20.0.1)\n Requirement already satisfied: azure-mgmt-storage<16.0.0,>=1.5.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (11.2.0)\n Requirement already satisfied: msrest<1.0.0,>=0.5.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (0.7.1)\n Requirement already satisfied: adal<=1.2.7,>=1.2.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (1.2.7)\n Requirement already satisfied: azure-mgmt-keyvault<10.0.0,>=0.40.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (9.3.0)\n Requirement already satisfied: requests<3.0.0,>=2.19.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (2.27.1)\n Requirement already satisfied: contextlib2<22.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (21.6.0)\n Requirement already satisfied: SecretStorage<4.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (3.3.2)\n Requirement already satisfied: azure-mgmt-authorization<1.0.0,>=0.40.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (0.61.0)\n Requirement already satisfied: pytz in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (2022.1)\n Collecting urllib3<=1.26.7,>=1.23\n   Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n Requirement already satisfied: pathspec<1.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (0.9.0)\n Requirement already satisfied: opencensus-ext-azure~=1.1.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (1.1.5)\n Requirement already satisfied: inference-schema==1.3.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (1.3.0)\n Requirement already satisfied: gunicorn==20.1.0; platform_system != \"Windows\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (20.1.0)\n Requirement already satisfied: applicationinsights>=0.11.7 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (0.11.10)\n Requirement already satisfied: azureml-dataprep<2.25.0a,>=2.24.0a in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-dataset-runtime[fuse]~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (2.24.4)\n Requirement already satisfied: fusepy<4.0.0,>=3.0.1; extra == \"fuse\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-dataset-runtime[fuse]~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (3.0.1)\n Requirement already satisfied: six>=1.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from pyarrow==0.16.0->azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (1.16.0)\n Requirement already satisfied: attrs>=17.4.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from jsonschema==3.0.1->azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (21.4.0)\n Requirement already satisfied: setuptools in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from jsonschema==3.0.1->azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (58.0.4)\n Requirement already satisfied: pyrsistent>=0.14.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from jsonschema==3.0.1->azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (0.18.0)\n Requirement already satisfied: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.9\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from ruamel.yaml==0.16.10->azureml-designer-core[image,model]>=0.0.32->azureml-designer-serving==0.0.10) (0.2.6)\n Requirement already satisfied: MarkupSafe>=2.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from Jinja2>=2.10->Flask->azureml-contrib-services->azureml-designer-serving==0.0.10) (2.0.1)\n Requirement already satisfied: cffi>=1.12 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (1.12.3)\n Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from jsonpickle<3.0.0->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (4.8.3)\n Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.3.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azure-mgmt-containerregistry>=2.0.0->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (1.3.1)\n Requirement already satisfied: pyasn1>=0.1.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from ndg-httpsclient<=0.5.1->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (0.4.8)\n Requirement already satisfied: websocket-client>=0.32.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from docker<6.0.0->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (1.3.1)\n Requirement already satisfied: backports.weakref in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from backports.tempfile->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (1.0.post1)\n Requirement already satisfied: isodate>=0.6.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from msrest<1.0.0,>=0.5.1->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (0.6.1)\n Requirement already satisfied: azure-core>=1.24.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from msrest<1.0.0,>=0.5.1->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (1.24.2)\n Requirement already satisfied: requests-oauthlib>=0.5.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from msrest<1.0.0,>=0.5.1->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (1.3.1)\n Requirement already satisfied: certifi>=2017.4.17 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from msrest<1.0.0,>=0.5.1->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (2022.6.15)\n Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from requests<3.0.0,>=2.19.1->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (2.0.12)\n Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from requests<3.0.0,>=2.19.1->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (3.3)\n Requirement already satisfied: jeepney>=0.6 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from SecretStorage<4.0.0->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (0.7.1)\n Requirement already satisfied: opencensus<1.0.0,>=0.10.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (0.10.0)\n Requirement already satisfied: psutil>=5.6.3 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (5.9.1)\n Requirement already satisfied: azure-identity<2.0.0,>=1.5.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (1.10.0)\n Requirement already satisfied: wrapt<=1.12.1,>=1.11.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from inference-schema==1.3.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (1.12.1)\n Requirement already satisfied: azureml-dataprep-rslex~=2.0.0dev0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-dataprep<2.25.0a,>=2.24.0a->azureml-dataset-runtime[fuse]~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (2.0.3)\n Collecting dotnetcore2<3.0.0,>=2.1.14\n   Downloading dotnetcore2-2.1.23-py3-none-manylinux1_x86_64.whl (29.3 MB)\n Requirement already satisfied: azureml-dataprep-native<39.0.0,>=38.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azureml-dataprep<2.25.0a,>=2.24.0a->azureml-dataset-runtime[fuse]~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (38.0.0)\n Requirement already satisfied: pycparser in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from cffi>=1.12->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (2.21)\n Requirement already satisfied: zipp>=0.5 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonpickle<3.0.0->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (3.6.0)\n Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonpickle<3.0.0->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (4.1.1)\n Requirement already satisfied: oauthlib>=3.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from requests-oauthlib>=0.5.0->msrest<1.0.0,>=0.5.1->azureml-core~=1.36.0->azureml-defaults->azureml-designer-serving==0.0.10) (3.2.0)\n Requirement already satisfied: opencensus-context>=0.1.2 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from opencensus<1.0.0,>=0.10.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (0.1.2)\n Requirement already satisfied: google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from opencensus<1.0.0,>=0.10.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (2.8.2)\n Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (1.0.0)\n Requirement already satisfied: msal<2.0.0,>=1.12.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (1.18.0)\n Requirement already satisfied: contextvars; python_version >= \"3.6\" and python_version < \"3.7\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from opencensus-context>=0.1.2->opencensus<1.0.0,>=0.10.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (2.4)\n Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.10.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (2.9.0)\n Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.10.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (1.56.3)\n Requirement already satisfied: protobuf<5.0.0dev,>=3.15.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.10.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (3.19.4)\n Requirement already satisfied: portalocker<3,>=1.0; python_version >= \"3.5\" and platform_system != \"Windows\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity<2.0.0,>=1.5.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (2.5.1)\n Requirement already satisfied: immutables>=0.9 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from contextvars; python_version >= \"3.6\" and python_version < \"3.7\"->opencensus-context>=0.1.2->opencensus<1.0.0,>=0.10.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (0.18)\n Requirement already satisfied: pyasn1-modules>=0.2.1 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.10.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (0.2.8)\n Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.10.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (4.8)\n Requirement already satisfied: cachetools<6.0,>=2.0.0 in \/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0; python_version >= \"3.6\"->opencensus<1.0.0,>=0.10.0->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.4.1->azureml-defaults->azureml-designer-serving==0.0.10) (4.2.4)\n Installing collected packages: azureml-contrib-services, azureml-designer-serving, numpy, python-dateutil, cloudpickle, cryptography, urllib3, dotnetcore2\n   Attempting uninstall: numpy\n     Found existing installation: numpy 1.19.5\n     Uninstalling numpy-1.19.5:\n       Successfully uninstalled numpy-1.19.5\n   Attempting uninstall: python-dateutil\n     Found existing installation: python-dateutil 2.8.2\n     Uninstalling python-dateutil-2.8.2:\n       Successfully uninstalled python-dateutil-2.8.2\n   Attempting uninstall: cloudpickle\n     Found existing installation: cloudpickle 2.1.0\n     Uninstalling cloudpickle-2.1.0:\n       Successfully uninstalled cloudpickle-2.1.0\n   Attempting uninstall: cryptography\n     Found existing installation: cryptography 37.0.4\n     Uninstalling cryptography-37.0.4:\n       Successfully uninstalled cryptography-37.0.4\n   Attempting uninstall: urllib3\n     Found existing installation: urllib3 1.26.10\n     Uninstalling urllib3-1.26.10:\n       Successfully uninstalled urllib3-1.26.10\n   Attempting uninstall: dotnetcore2\n     Found existing installation: dotnetcore2 3.1.23\n     Uninstalling dotnetcore2-3.1.23:\n       Successfully uninstalled dotnetcore2-3.1.23\n ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n    \n We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n    \n azureml-dataset-runtime 1.36.0 requires pyarrow<4.0.0,>=0.17.0, but you'll have pyarrow 0.16.0 which is incompatible.\n azureml-dataprep 2.24.4 requires azure-identity==1.7.0, but you'll have azure-identity 1.10.0 which is incompatible.\n Successfully installed azureml-contrib-services-1.43.0 azureml-designer-serving-0.0.10 cloudpickle-1.2.2 cryptography-3.4.8 dotnetcore2-2.1.23 numpy-1.18.1 python-dateutil-2.8.1 urllib3-1.26.7\n Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (urllib3 1.26.10 (\/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages), Requirement.parse('urllib3<=1.26.7,>=1.23'), {'azureml-core'}).\n Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (urllib3 1.26.10 (\/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages), Requirement.parse('urllib3<=1.26.7,>=1.23'), {'azureml-core'}).\n Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (urllib3 1.26.10 (\/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages), Requirement.parse('urllib3<=1.26.7,>=1.23'), {'azureml-core'}).\n Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (urllib3 1.26.10 (\/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages), Requirement.parse('urllib3<=1.26.7,>=1.23')).\n Initializing logger\n 2022-07-13 09:30:57,630 | root | INFO | Starting up app insights client\n logging socket was found. logging is available.\n logging socket was found. logging is available.\n 2022-07-13 09:30:57,631 | root | INFO | Starting up request id generator\n 2022-07-13 09:30:57,631 | root | INFO | Starting up app insight hooks\n 2022-07-13 09:30:57,632 | root | INFO | Invoking user's init function\n Trying to reload werkzeug.\n Successfully reloaded werkzeug.\n pip freeze result:\n adal==1.2.7\n applicationinsights==0.11.10\n attrs==21.4.0\n azure-common==1.1.28\n azure-core==1.24.2\n azure-graphrbac==0.61.1\n azure-identity==1.10.0\n azure-mgmt-authorization==0.61.0\n azure-mgmt-containerregistry==10.0.0\n azure-mgmt-core==1.3.1\n azure-mgmt-keyvault==9.3.0\n azure-mgmt-resource==13.0.0\n azure-mgmt-storage==11.2.0\n azure-storage-blob==1.5.0\n azure-storage-common==1.4.2\n azureml-contrib-services==1.43.0\n azureml-core==1.36.0.post2\n azureml-dataprep==2.24.4\n azureml-dataprep-native==38.0.0\n azureml-dataprep-rslex==2.0.3\n azureml-dataset-runtime==1.36.0\n azureml-defaults==1.36.0\n azureml-designer-classic-modules==0.0.161\n azureml-designer-core==0.0.68\n azureml-designer-internal==0.0.56\n azureml-designer-serving==0.0.10\n azureml-inference-server-http==0.4.13\n azureml-interpret==1.36.0\n azureml-model-management-sdk==1.0.1b6.post1\n azureml-pipeline-core==1.36.0\n azureml-telemetry==1.36.0\n backports.tempfile==1.0\n backports.weakref==1.0.post1\n blis==0.2.4\n cachetools==4.2.4\n certifi==2022.6.15\n cffi==1.12.3\n chardet==3.0.4\n charset-normalizer==2.0.12\n click==7.1.2\n cloudpickle==1.2.2\n configparser==3.7.4\n contextlib2==21.6.0\n contextvars==2.4\n cryptography==3.4.8\n cycler==0.11.0\n cymem==2.0.6\n dill==0.3.4\n distro==1.4.0\n docker==5.0.3\n dotnetcore2==2.1.23\n en-core-web-sm @ https:\/\/github.com\/explosion\/spacy-models\/releases\/download\/en_core_web_sm-2.1.0\/en_core_web_sm-2.1.0.tar.gz\n Flask==1.0.3\n fusepy==3.0.1\n gensim==3.8.3\n google-api-core==2.8.2\n google-auth==2.9.0\n googleapis-common-protos==1.56.3\n gunicorn==20.1.0\n idna==3.3\n imbalanced-learn==0.4.3\n immutables==0.18\n importlib-metadata==4.8.3\n importlib-resources==5.4.0\n inference-schema==1.3.0\n interpret-community==0.21.0\n interpret-core==0.2.6\n isodate==0.6.1\n itsdangerous==1.1.0\n jeepney==0.7.1\n Jinja2==3.0.3\n jmespath==0.10.0\n joblib==0.14.0\n json-logging-py==0.2\n jsonpickle==2.2.0\n jsonschema==3.0.1\n kiwisolver==1.3.1\n liac-arff==2.5.0\n lightgbm==3.2.1\n llvmlite==0.36.0\n MarkupSafe==2.0.1\n matplotlib==3.1.3\n more-itertools==6.0.0\n msal==1.18.0\n msal-extensions==1.0.0\n msrest==0.7.1\n msrestazure==0.6.4\n murmurhash==1.0.7\n ndg-httpsclient==0.5.1\n nimbusml==1.6.1\n numba==0.53.1\n numpy==1.18.1\n oauthlib==3.2.0\n opencensus==0.10.0\n opencensus-context==0.1.2\n opencensus-ext-azure==1.1.5\n packaging==21.3\n pandas==1.0.4\n pathspec==0.9.0\n Pillow==8.3.2\n plac==0.9.6\n portalocker==2.5.1\n preshed==2.0.1\n protobuf==3.19.4\n psutil==5.9.1\n pyarrow==0.16.0\n pyasn1==0.4.8\n pyasn1-modules==0.2.8\n pycparser==2.21\n pycryptodomex==3.7.3\n PyJWT==2.4.0\n pyOpenSSL==20.0.1\n pyparsing==3.0.9\n pyrsistent==0.18.0\n python-dateutil==2.8.1\n pytz==2022.1\n requests==2.27.1\n requests-oauthlib==1.3.1\n rsa==4.8\n ruamel.yaml==0.16.10\n ruamel.yaml.clib==0.2.6\n scikit-learn==0.22.2\n scikit-surprise==1.0.6\n scipy==1.4.1\n seaborn==0.10.0\n SecretStorage==3.3.2\n shap==0.39.0\n six @ file:\/\/\/home\/conda\/feedstock_root\/build_artifacts\/six_1620240208055\/work\n slicer==0.0.7\n smart-open==6.0.0\n spacy==2.1.7\n srsly==1.0.5\n thinc==7.0.8\n tqdm==4.64.0\n typing-extensions==4.1.1\n urllib3==1.26.7\n wasabi==0.9.1\n websocket-client==1.3.1\n Werkzeug==1.0.1\n wrapt==1.12.1\n zipp==3.6.0\n    \n Model: name=amlstudio-loanv1ep002, version=1\n Loading static source Resources\/1\/ - Start:\n Loaded TransformationDirectory(meta={'type': 'TransformationDirectory', 'extension': {}, 'transform_type': 'Pickle', 'file_path': 'data.itransform'}) from studiomodelpackage\/Resources\/1.\n Loading static source Resources\/1\/ - End with 0.1387s elapsed.\n Loading static source Resources\/2\/ - Start:\n Loaded ModelDirectory(meta={'type': 'ModelDirectory', 'extension': {}, 'model': 'model_spec.yaml', 'registerModel': True, 'modelOutputPath': 'trained_model_outputs'}) from studiomodelpackage\/Resources\/2.\n Loading static source Resources\/2\/ - End with 1.5108s elapsed.\n initializing node 1\n ALGHOST 0.0.161\n Load pyarrow.parquet explicitly: <module 'pyarrow.parquet' from '\/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages\/pyarrow\/parquet.py'>\n initializing node 2\n ALGHOST 0.0.161\n Load pyarrow.parquet explicitly: <module 'pyarrow.parquet' from '\/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages\/pyarrow\/parquet.py'>\n initializing node 3\n ALGHOST 0.0.161\n Load pyarrow.parquet explicitly: <module 'pyarrow.parquet' from '\/azureml-envs\/azureml_41d04a9e61995ab9ca33645f37d72150\/lib\/python3.6\/site-packages\/pyarrow\/parquet.py'>\n Init: Graph has been loaded\n 2022-07-13 09:31:00,723 | root | INFO | Users's init has completed successfully\n 2022-07-13 09:31:00,730 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n 2022-07-13 09:31:00,731 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n 2022-07-13 09:31:00,732 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n 2022-07-13 09:31:00,939 | root | INFO | Swagger file not present\n 2022-07-13 09:31:00,939 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:31:00 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:31:01,214 | root | INFO | Swagger file not present\n 2022-07-13 09:31:01,214 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:31:01 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:31:01,229 | root | INFO | Swagger file not present\n 2022-07-13 09:31:01,229 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:31:01 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"curl\/7.80.0\"\n 2022-07-13 09:31:02,201 | root | INFO | Swagger file not present\n 2022-07-13 09:31:02,202 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:31:02 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"curl\/7.80.0\"\n 2022-07-13 09:31:04,052 | root | INFO | Swagger file not present\n 2022-07-13 09:31:04,052 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:31:04 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:31:04,335 | root | INFO | Scoring Timer is set to 60.0 seconds\n Handling http request - Start:\n 2022-07-13 09:31:04,335 studio.azureml.designer.serving.dagengine.request_handler INFO       |   Run: is_classic = False, with_details = False, verbose = True\n 2022-07-13 09:31:04,336 studio.core          INFO       |   Pre-processing - Start:\n 2022-07-13 09:31:04,336 studio.core          INFO       |   Pre-processing - End with 0.0001s elapsed.\n 2022-07-13 09:31:04,336 studio.core          INFO       |   Processing - Start:\n 2022-07-13 09:31:04,360 studio.common        WARNING    |   |   0 and empty string will be converted into False\n 2022-07-13 09:31:04,377 studio.common        WARNING    |   |   0 and empty string will be converted into False\n 2022-07-13 09:31:04,418 studio.core          INFO       |   |   Executing node 1: Apply Transformation - Start:\n 2022-07-13 09:31:04,426 studio.common        DEBUG      |   |   |   Load schema successfully.\n 2022-07-13 09:31:04,429 studio.modulehost    INFO       |   |   |   Return without parsing\n 2022-07-13 09:31:04,429 studio.modulehost    INFO       |   |   |   Return without parsing\n 2022-07-13 09:31:04,435 studio.core          INFO       |   |   |   ApplyTransformationModule.run - Start:\n 2022-07-13 09:31:04,435 studio.core          DEBUG      |   |   |   |   kwargs:\n 2022-07-13 09:31:04,435 studio.core          DEBUG      |   |   |   |   |   transform = <azureml.studio.modules.datatransform.clean_missing_data.clean_missing_transform.CleanMissingValueTransform object at 0x7f72fe544198>\n 2022-07-13 09:31:04,435 studio.core          DEBUG      |   |   |   |   |   data = <azureml.studio.common.datatable.data_table.DataTable object at 0x7f72fdd6afd0>\n 2022-07-13 09:31:04,436 studio.core          DEBUG      |   |   |   |   validated_args:\n 2022-07-13 09:31:04,436 studio.core          DEBUG      |   |   |   |   |   transform = <azureml.studio.modules.datatransform.clean_missing_data.clean_missing_transform.CleanMissingValueTransform object at 0x7f72fe544198>\n 2022-07-13 09:31:04,436 studio.core          DEBUG      |   |   |   |   |   data = <azureml.studio.common.datatable.data_table.DataTable object at 0x7f72fdd6afd0>\n 2022-07-13 09:31:04,436 studio.module        INFO       |   |   |   |   Get column indexes with wanted ratio\n 2022-07-13 09:31:04,436 studio.core          INFO       |   |   |   |   CleanMissingValueTransform.get_column_indexes_with_wanted_ratio - Start:\n 2022-07-13 09:31:04,439 studio.core          INFO       |   |   |   |   CleanMissingValueTransform.get_column_indexes_with_wanted_ratio - End with 0.0026s elapsed.\n 2022-07-13 09:31:04,439 studio.module        INFO       |   |   |   |   Replace row with missing value\n 2022-07-13 09:31:04,439 studio.core          INFO       |   |   |   |   DataTable.clone - Start:\n 2022-07-13 09:31:04,446 studio.core          INFO       |   |   |   |   DataTable.clone - End with 0.0066s elapsed.\n 2022-07-13 09:31:04,446 studio.core          INFO       |   |   |   |   Find row_indexes_to_remove - Start:\n 2022-07-13 09:31:04,449 studio.core          INFO       |   |   |   |   Find row_indexes_to_remove - End with 0.0030s elapsed.\n 2022-07-13 09:31:04,449 studio.core          INFO       |   |   |   |   Remove rows by indexes - Start:\n 2022-07-13 09:31:04,456 studio.core          INFO       |   |   |   |   Remove rows by indexes - End with 0.0012s elapsed.\n 2022-07-13 09:31:04,456 studio.core          DEBUG      |   |   |   |   return:\n 2022-07-13 09:31:04,456 studio.core          DEBUG      |   |   |   |   |   [0] = <DataTable \"Dataset\" (1 Rows, 11 Cols) at 0x00007F72FDD957F0>\n 2022-07-13 09:31:04,456 studio.core          INFO       |   |   |   ApplyTransformationModule.run - End with 0.0211s elapsed.\n 2022-07-13 09:31:04,457 studio.core          INFO       |   |   Executing node 1: Apply Transformation - End with 0.0388s elapsed.\n 2022-07-13 09:31:04,457 studio.core          INFO       |   |   Executing node 2: Score Model - Start:\n 2022-07-13 09:31:04,457 studio.common        DEBUG      |   |   |   Load schema successfully.\n 2022-07-13 09:31:04,466 studio.modulehost    INFO       |   |   |   Return without parsing\n 2022-07-13 09:31:04,466 studio.modulehost    INFO       |   |   |   Return without parsing\n 2022-07-13 09:31:04,466 studio.modulehost    INFO       |   |   |   Parse bool parameter\n 2022-07-13 09:31:04,466 studio.core          INFO       |   |   |   ScoreModelModule.run - Start:\n 2022-07-13 09:31:04,466 studio.core          DEBUG      |   |   |   |   kwargs:\n 2022-07-13 09:31:04,466 studio.core          DEBUG      |   |   |   |   |   learner = <azureml.studio.modules.ml.initialize_models.binary_classifier.logistic_regression_biclassifier.logistic_regression_biclassifier.LogisticRegressionBiClassifier object at 0x7f72fe559978>\n 2022-07-13 09:31:04,466 studio.core          DEBUG      |   |   |   |   |   test_data = <azureml.studio.common.datatable.data_table.DataTable object at 0x7f72fdd6acf8>\n 2022-07-13 09:31:04,467 studio.core          DEBUG      |   |   |   |   |   append_or_result_only = True\n 2022-07-13 09:31:04,467 studio.core          DEBUG      |   |   |   |   validated_args:\n 2022-07-13 09:31:04,467 studio.core          DEBUG      |   |   |   |   |   learner = <azureml.studio.modules.ml.initialize_models.binary_classifier.logistic_regression_biclassifier.logistic_regression_biclassifier.LogisticRegressionBiClassifier object at 0x7f72fe559978>\n 2022-07-13 09:31:04,467 studio.core          DEBUG      |   |   |   |   |   test_data = <azureml.studio.common.datatable.data_table.DataTable object at 0x7f72fdd6acf8>\n 2022-07-13 09:31:04,467 studio.core          DEBUG      |   |   |   |   |   append_or_result_only = True\n 2022-07-13 09:31:04,467 studio.module        INFO       |   |   |   |   Validated testing data has 1 Row(s) and 11 Columns.\n 2022-07-13 09:31:04,474 studio.module        INFO       |   |   |   |   Check if column types of test data are consistent with train data\n 2022-07-13 09:31:04,475 studio.module        INFO       |   |   |   |   Building Normalizer - found Label column=None with encode_label=False\n 2022-07-13 09:31:04,475 studio.module        INFO       |   |   |   |   Building normalizer - found 11 feature columns with normalize_number=True\n 2022-07-13 09:31:04,475 studio.module        DEBUG      |   |   |   |   Building normalizer - found feature columns: \"Gender,Married,Dependents,Education,Self_Employed,ApplicantIncome,CoapplicantIncome,LoanAmount,Loan_Amount_Term,Credit_History,Property_Area\".\n 2022-07-13 09:31:04,476 studio.module        INFO       |   |   |   |   Building normalizer - found 6 numeric feature columns and 5 string feature columns to be encoded\n 2022-07-13 09:31:04,476 studio.module        DEBUG      |   |   |   |   Building normalizer - found numeric feature columns to be encoded: \"Married,Self_Employed,ApplicantIncome,LoanAmount,Loan_Amount_Term,Credit_History\".\n 2022-07-13 09:31:04,476 studio.module        DEBUG      |   |   |   |   Building normalizer - found string feature columns to be encoded: \"Gender,Dependents,Education,CoapplicantIncome,Property_Area\".\n 2022-07-13 09:31:04,476 studio.module        INFO       |   |   |   |   Successfully built normalizer of test data.\n 2022-07-13 09:31:04,476 studio.module        INFO       |   |   |   |   Successfully checked column types. Predicting.\n 2022-07-13 09:31:04,476 studio.core          INFO       |   |   |   |   BaseLearner._apply_normalize - Start:\n 2022-07-13 09:31:04,476 studio.core          INFO       |   |   |   |   |   Applying feature normalization - Start:\n 2022-07-13 09:31:04,476 studio.module        INFO       |   |   |   |   |   |   Start to execute normalizer.transform with column_list: \"Gender,Married,Dependents,Education,Self_Employed,ApplicantIncome,CoapplicantIncome,LoanAmount,Loan_Amount_Term,Credit_History,Property_Area\".\n 2022-07-13 09:31:04,476 studio.module        INFO       |   |   |   |   |   |   Columns of input DataFrame: 11\n 2022-07-13 09:31:04,476 studio.module        INFO       |   |   |   |   |   |   Columns to be transformed: 11\n 2022-07-13 09:31:04,476 studio.module        INFO       |   |   |   |   |   |   Columns to be encoded: 11\n 2022-07-13 09:31:04,476 studio.module        INFO       |   |   |   |   |   |   Transform with label column Loan_Status.\n 2022-07-13 09:31:04,477 studio.core          INFO       |   |   |   |   |   |   Normalizer._transform_str_feature_columns - Start:\n 2022-07-13 09:31:04,494 studio.module        INFO       |   |   |   |   |   |   |   Successfully encoded 5 string feature columns.\n 2022-07-13 09:31:04,494 studio.module        INFO       |   |   |   |   |   |   |   After transformation, 179 string feature column are generated\n 2022-07-13 09:31:04,494 studio.core          INFO       |   |   |   |   |   |   Normalizer._transform_str_feature_columns - End with 0.0174s elapsed.\n 2022-07-13 09:31:04,494 studio.core          INFO       |   |   |   |   |   |   Normalizer._transform_numeric_feature_columns - Start:\n 2022-07-13 09:31:04,497 studio.module        INFO       |   |   |   |   |   |   |   Successfully encoded 6 numeric feature columns.\n 2022-07-13 09:31:04,497 studio.core          INFO       |   |   |   |   |   |   Normalizer._transform_numeric_feature_columns - End with 0.0031s elapsed.\n 2022-07-13 09:31:04,506 studio.module        INFO       |   |   |   |   |   |   Construct train set with Sparse structure.\n 2022-07-13 09:31:04,507 studio.core          INFO       |   |   |   |   |   Applying feature normalization - End with 0.0309s elapsed.\n 2022-07-13 09:31:04,513 studio.core          INFO       |   |   |   |   BaseLearner._apply_normalize - End with 0.0367s elapsed.\n 2022-07-13 09:31:04,513 studio.core          INFO       |   |   |   |   BaseLearner._predict - Start:\n 2022-07-13 09:31:04,513 studio.core          INFO       |   |   |   |   |   Predicting probability - Start:\n 2022-07-13 09:31:04,514 studio.core          INFO       |   |   |   |   |   Predicting probability - End with 0.0004s elapsed.\n 2022-07-13 09:31:04,514 studio.core          INFO       |   |   |   |   |   calculating argmax(Probability) - Start:\n 2022-07-13 09:31:04,514 studio.core          INFO       |   |   |   |   |   calculating argmax(Probability) - End with 0.0000s elapsed.\n 2022-07-13 09:31:04,514 studio.core          INFO       |   |   |   |   BaseLearner._predict - End with 0.0007s elapsed.\n 2022-07-13 09:31:04,514 studio.module        INFO       |   |   |   |   Successfully predicted.\n 2022-07-13 09:31:04,515 studio.module        INFO       |   |   |   |   Found 2 label classes in classes_ attribute.\n 2022-07-13 09:31:04,515 studio.module        INFO       |   |   |   |   Using 1 as probability column.\n 2022-07-13 09:31:04,524 studio.module        INFO       |   |   |   |   Binary Classification Model Scored Columns are: \n 2022-07-13 09:31:04,525 studio.module        INFO       |   |   |   |   There are 2 score columns: \"Binary Class Assigned Labels,Calibrated Score\"\n 2022-07-13 09:31:04,525 studio.core          DEBUG      |   |   |   |   return:\n 2022-07-13 09:31:04,525 studio.core          DEBUG      |   |   |   |   |   [0] = <DataTable \"Dataset\" (1 Rows, 13 Cols) at 0x00007F72FDD6ACF8>\n 2022-07-13 09:31:04,525 studio.core          INFO       |   |   |   ScoreModelModule.run - End with 0.0586s elapsed.\n 2022-07-13 09:31:04,526 studio.core          INFO       |   |   Executing node 2: Score Model - End with 0.0687s elapsed.\n 2022-07-13 09:31:04,526 studio.core          INFO       |   |   Executing node 3: Select Columns in Dataset - Start:\n 2022-07-13 09:31:04,533 studio.common        DEBUG      |   |   |   Load schema successfully.\n 2022-07-13 09:31:04,536 studio.modulehost    INFO       |   |   |   Return without parsing\n 2022-07-13 09:31:04,536 studio.modulehost    INFO       |   |   |   Parse ColumnSelection parameter\n 2022-07-13 09:31:04,542 studio.core          INFO       |   |   |   SelectColumnsModule.run - Start:\n 2022-07-13 09:31:04,542 studio.core          DEBUG      |   |   |   |   kwargs:\n 2022-07-13 09:31:04,543 studio.core          DEBUG      |   |   |   |   |   table = <azureml.studio.common.datatable.data_table.DataTable object at 0x7f72fdd2c128>\n 2022-07-13 09:31:04,543 studio.core          DEBUG      |   |   |   |   |   feature_list = <azureml.studio.common.datatable.data_table.DataTableColumnSelection object at 0x7f72fdd2cda0>\n 2022-07-13 09:31:04,543 studio.core          DEBUG      |   |   |   |   validated_args:\n 2022-07-13 09:31:04,543 studio.core          DEBUG      |   |   |   |   |   table = <azureml.studio.common.datatable.data_table.DataTable object at 0x7f72fdd2c128>\n 2022-07-13 09:31:04,543 studio.core          DEBUG      |   |   |   |   |   feature_list = <azureml.studio.common.datatable.data_table.DataTableColumnSelection object at 0x7f72fdd2cda0>\n 2022-07-13 09:31:04,543 studio.module        INFO       |   |   |   |   Select column indexes from Dataset\n 2022-07-13 09:31:04,545 studio.core          DEBUG      |   |   |   |   return:\n 2022-07-13 09:31:04,545 studio.core          DEBUG      |   |   |   |   |   [0] = <DataTable (1 Rows, 2 Cols) at 0x00007F72FDD2CEB8>\n 2022-07-13 09:31:04,545 studio.core          INFO       |   |   |   SelectColumnsModule.run - End with 0.0027s elapsed.\n 2022-07-13 09:31:04,545 studio.core          INFO       |   |   Executing node 3: Select Columns in Dataset - End with 0.0197s elapsed.\n 2022-07-13 09:31:04,553 studio.core          INFO       |   Processing - End with 0.2173s elapsed.\n 2022-07-13 09:31:04,553 studio.core          INFO       |   Post-processing - Start:\n 2022-07-13 09:31:04,554 studio.core          INFO       |   Post-processing - End with 0.0000s elapsed.\n 2022-07-13 09:31:04,554 studio.core          INFO       Handling http request - End with 0.2182s elapsed.\n 2022-07-13 09:31:04,554 studio.azureml.designer.serving.dagengine.request_handler DEBUG      Run: output data(raw) = {\"Results\": {\"WebServiceOutput0\": [{\"Scored Labels\": true, \"Scored Probabilities\": 0.591091131859528}]}}\n 2022-07-13 09:31:04,554 | root | INFO | run() output is HTTP Response\n 2022-07-13 09:31:04,554 | root | INFO | 200\n 127.0.0.1 - - [13\/Jul\/2022:09:31:04 +0000] \"POST \/score?verbose=true HTTP\/1.0\" 200 104 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:34:34,646 | root | INFO | Swagger file not present\n 2022-07-13 09:34:34,647 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:34:34 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:34:36,197 | root | INFO | Swagger file not present\n 2022-07-13 09:34:36,198 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:34:36 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"curl\/7.80.0\"\n 2022-07-13 09:34:37,162 | root | INFO | Swagger file not present\n 2022-07-13 09:34:37,162 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:34:37 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:50:54,732 | root | INFO | Swagger file not present\n 2022-07-13 09:50:54,732 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:50:54 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:50:55,920 | root | INFO | Swagger file not present\n 2022-07-13 09:50:55,921 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:50:55 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"curl\/7.80.0\"\n 2022-07-13 09:53:43,395 | root | INFO | Swagger file not present\n 2022-07-13 09:53:43,395 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:53:43 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:53:43,679 | root | INFO | Swagger file not present\n 2022-07-13 09:53:43,679 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:53:43 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"curl\/7.80.0\"\n 2022-07-13 09:54:02,867 | root | INFO | Swagger file not present\n 2022-07-13 09:54:02,868 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:54:02 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"Mozilla\/5.0 (X11; Linux x86_64; rv:102.0) Gecko\/20100101 Firefox\/102.0\"\n 2022-07-13 09:54:40,605 | root | INFO | Swagger file not present\n 2022-07-13 09:54:40,605 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:54:40 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:54:49,848 | root | INFO | Swagger file not present\n 2022-07-13 09:54:49,853 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:54:49 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:54:56,064 | root | INFO | Swagger file not present\n 2022-07-13 09:54:56,065 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:54:56 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:55:31,957 | root | INFO | Swagger file not present\n 2022-07-13 09:55:31,958 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:55:31 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.18.1\"\n 2022-07-13 09:55:32,313 | root | INFO | Swagger file not present\n 2022-07-13 09:55:32,313 | root | INFO | 404\n 127.0.0.1 - - [13\/Jul\/2022:09:55:32 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"curl\/7.80.0\"",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Parallel computing with Python SDK V2",
        "Question_creation_time":1657198500433,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/918129\/parallel-computing-with-python-sdk-v2.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hello :)\n\nDo you have any kind of idea when Azure Machine Learning Python SDK V2 could support parallel computing? We are testing things out with the machine learning studio and we are in a bit confusing stage that should we go with the SDK V1 or V2, but seemingly the V2 is not yet supporting multiple nodes in compute clusters.\n\nBest regards,\nTuomas",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-14T04:53:23.743Z",
                "Answer_score":0,
                "Answer_body":"Hello @TuomasPartanen-9618\n\nI have a good news for you, we are testing Parallel Run Step NOW in private preview of V2.\n\nFor your scenario, v1 is stable and serving all production customers. v2 (through DPv2) is still in private preview, and there are some dependency on new dataset\/mltable implementation. So if you want to seriously put some production traffic, I suggest guide to v1; but if you just want to have some prototypes, v2 may be better, as v2 is growing but v1 will not. Also, V2 will have the feature you want - Parallel.\n\nThe estimate time is not confirmed but should be around October.\n\nI hope this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure ML real-time inference endpoint deloyment stuck - with deployment state as Transitioning for over 2 hours.",
        "Question_creation_time":1591823291753,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/34653\/azure-ml-real-time-inference-endpoint-deloyment-st.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":6,
        "Question_follower_count":11,
        "Question_score":2,
        "Question_body":"Hi,\n\nI was deploying a real-time inference pipeline into an AKS compute in East US region today. The endpoint deployment state was stuck at Transitioning for over 2 hours and never finished and I had to delete it. A separate deployment to region East US 2 got stuck as well. I was able to deploy the same pipeline to East US the day before yesterday.\n\nI wonder if this is likely an error related to my account\/resources or a system wide issue? Did anyone else encounter the similar issue?\n\nthanks in advance!",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-12T05:42:20.98Z",
                "Answer_score":1,
                "Answer_body":"Hello All,\n\nWe have deployed a fix now to all regions and this should be fixed. Could you please retry and let us know if there are any issues.\n\n-Rohit",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-07-13T13:45:42.92Z",
                "Answer_score":0,
                "Answer_body":"A \"real-time endpoint deployment\" that \"failed\" cannot be deleted\n\nI also can't update the deployment to a working version.\n\nI tried deleting using \"Azure CLI\", \"Azure Portal\", \"Azure ML Studio\" and Python SDK.\n\nNow I'm trying to update the deployment with \"bicep\" but it's been running for 20 minutes now so I think it will fail again.\n\nI also can't delete the endpoint that contains the deployment.\n\nNow that this is day 3, my next try is to delete the entire \"Azure ML\"",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Behavior of 'allow_reuse' in a published pipeline referencing a versioned dataset \/ Newer datasets are ignored by the pipeline?",
        "Question_creation_time":1647926664217,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/781612\/behavior-of-39allow-reuse39-in-a-published-pipelin.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":9,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hello,\n\nI have built an Azure ML pipeline which will be called from a Data Factory pipeline at a specified interval.\nThe ML pipeline contains PythonScriptSteps which take various datasets as an input. All datasets are registered and versioned in the same Azure ML workspace.\nThe Data Factory pipeline regularly updates the datasets to a new version and then run the registered ML pipeline. The expected behavior is that the ML pipeline will read the latest version of each dataset every time it is run by Data Factory.\n\nEven though I have set the parameter 'allow_reuse' of my PythonScriptStep objects to 'True', I expect the steps to be executed when the input datasets have been updated to a new version. But the problem is they are not executed. In the Experiments details, I can see that each step has its flag 'Reuse' set to 'Yes' and the execution duration is 0 second.\n\nWhen I look at the registered pipeline in 'Azure ML Studio -> Pipelines -> Pipeline endpoints' and I click on the input datasets, I can see that they have a parameter 'version' with an old version of the dataset 'hardcoded' in it (see picture below). It seems like once an ML pipeline has been published, it will always use the same dataset version at every run, even though the dataset have been updated in between. Is this the normal behavior?\n\nHere is a simplified version of my pipeline code.\n\n\n\n # Get a reference to the workspace\n ws = Workspace.from_config()\n    \n # Get the registered dataset\n dataset1 = Dataset.get_by_name(ws, 'dataset1')\n    \n # Pipeline's first step\n script1 = PythonScriptStep(\n     name=\"Script 1\",\n     script_name=\"script.py\",\n     source_directory=\".\/\",\n     inputs=[dataset1.as_named_input('dataset1')], # Passes the dataset path to the script\n     compute_target=compute_target,\n     runconfig=aml_run_config,\n     allow_reuse=True\n )\n    \n # Build the pipeline\n pipeline = Pipeline(workspace=ws, steps=[[script1]])\n    \n from azureml.core import Experiment\n    \n # Submit the pipeline to be run\n pipeline_run = Experiment(ws, 'experiment').submit(pipeline)\n pipeline_run.wait_for_completion()\n    \n published_pipeline = pipeline.publish(name = \"pipeline1\")",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-22T23:40:34.007Z",
                "Answer_score":0,
                "Answer_body":"I created and published a simple pipeline with the code below:\n\n from azureml.core import Workspace, Dataset\n from azureml.core.runconfig import RunConfiguration\n from azureml.pipeline.steps import PythonScriptStep\n from azureml.core.compute import ComputeTarget\n from azureml.pipeline.core import Pipeline\n    \n ws = Workspace.from_config()\n    \n compute_target = ComputeTarget(workspace=ws, name='DS3-v2-standard-cpu')\n compute_target.wait_for_completion(show_output=True)\n    \n aml_run_config = RunConfiguration()\n aml_run_config.target = compute_target\n    \n da_rolled = Dataset.get_by_name(ws, 'da_rolled', version = 'latest')\n    \n step1 = PythonScriptStep(\n     name=\"Step1\",\n     script_name=\"test.py\",\n     source_directory=\".\/\",\n     inputs=[da_rolled.as_named_input('da_rolled')],\n     compute_target=compute_target,\n     runconfig=aml_run_config,\n     allow_reuse=False\n )\n    \n pipeline = Pipeline(workspace=ws, steps=[[step1]])\n    \n published_pipeline = pipeline.publish(name = \"TestPipeline\")\n\n\n\nYou can see in the image below that the version of the dataset (23, which is the latest version at the time the pipeline is published) is hardcoded in the pipeline definition.\n\nAnd this is my dataset.\n\nNow if I run my Data Factory pipeline to update the dataset to a new version (which will make it version 24), the version in the pipeline definition will still be 23.\nIt seems like I need to republish the pipeline every time the dataset is updated.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Not able to make data working in the Studio",
        "Question_creation_time":1657242496467,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/918864\/not-able-to-make-data-working-in-the-studio.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi,\nI am using Azure classic studio for ML. Reading large CSV files with 20 columns. One column has a Timestamp which becomes 2.01E+16 after I cleaned the data using Excel.\n\nEach time I run it, it says:\n[Information] In [<-.factor(*tmp*, ri, value = c(0L, 148L, 50L, 4L, 39L, 5L, :\n[Information] invalid factor level, NA generated\n[Stop] DllModuleMethod::Execute. Duration = 00:09:24.4753205\n[Critical] Error: Error 0063: The following error occurred during evaluation of R script:\n---------- Start of error message from R ----------\nreplacement has 1 row, data has 0\n\nI used colSums to print it: colSums(is.na(test). It shows this column has 3 na VALUES in data and 2 in test.\nI replace na with test[is.na(test$Timestamp),]$Timestamp<-\"2.01E+16\"\nStill the same error.\n\nIt's so exhausting to test line by line with no way to debug it to pinpoint exactly where is the problem.\n\nPlz help!\nNWA",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Specifying input type as number in ComponentCommand and registing command with Python SDK v2 causes error",
        "Question_creation_time":1655446170600,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/893075\/specifying-input-type-as-number-in-componentcomman.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Specifying input type as number in ComponentCommand and registing component with Python SDK v2 causes error Input string was not in a correct format. The error is gone by removing the number-typed inputs and the relevant references to the inputs. It is noted that registering the component loaded from a YML spec does not have such a problem.\n\nProgrammically build ComponentCommand:\n\ndata_prep_comp = CommandComponent(\n        name='stock_pred_data_prep',\n        display_name='Preprocess data for training',\n        description='reads raw price data, normalize and split the data',\n        inputs={\n            'data': Input(type='uri_folder', mode='ro_mount'),\n            # the inputs below will cause error \"Input string was not in a correct format\"\n            'test_ratio': Input(type='number'),\n            'window': Input(type='number')\n        },\n        outputs={\n            'scaler': Output(type='uri_file'),\n            'train_data_x': Output(type='uri_file'),\n            'train_data_y': Output(type='uri_file'),\n            'test_data_x': Output(type='uri_file'),\n            'test_data_y': Output(type='uri_file')\n        },\n        # TODO: reorganize code to minimize the code context\n        code='.',\n        command='''PYTHONPATH=$PYTHONPATH:$(pwd) \\\n                python azure_pipeline\/preproc_data\/preproc_data.py \\\n                    --data=${{inputs.data}} --test_ratio=0.2 \\\n                    --window=50 \\\n                    --scaler=${{outputs.scaler}} \\\n                    --train_data_x=${{outputs.train_data_x}} --train_data_y=${{outputs.train_data_y}} \\\n                    --test_data_x=${{outputs.test_data_x}} --test_data_y=${{outputs.test_data_y}}\n                ''',\n        environment=f'{my_env.name}:{my_env.version}'\n    )\n    data_prep_comp = ml_client.components.create_or_update(data_prep_comp)\n\n\n\n\nOutput:\n\nUploading stock-pred (7.61 MBs): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7605532\/7605532 [00:02<00:00, 3504713.55it\/s] \n---------------------------------------------------------------------------\nHttpResponseError                         Traceback (most recent call last)\nInput In [23], in <cell line: 38>()\n      7 else:\n      8     data_prep_comp = CommandComponent(\n      9         name='stock_pred_data_prep',\n     10         display_name='Preprocess data for training',\n   (...)\n     35         environment=f'{my_env.name}:{my_env.version}'\n     36     )\n---> 38 data_prep_comp = ml_client.components.create_or_update(data_prep_comp)\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azure\/ai\/ml\/_telemetry\/activity.py:230, in monitor_with_telemetry_mixin.<locals>.monitor.<locals>.wrapper(*args, **kwargs)\n    228 dimensions = {**parameter_dimensions, **(custom_dimensions or {})}\n    229 with log_activity(logger, activity_name or f.__name__, activity_type, dimensions) as activityLogger:\n--> 230     return_value = f(*args, **kwargs)\n    231     if not parameter_dimensions:\n    232         # collect from return if no dimensions from parameter\n    233         activityLogger.activity_info.update(_collect_from_return_value(return_value))\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azure\/ai\/ml\/operations\/_component_operations.py:263, in ComponentOperations.create_or_update(self, component, **kwargs)\n    254             result = self._version_operation.create_or_update(\n    255                 name=rest_component_resource.name,\n    256                 version=component.version,\n   (...)\n    260                 **self._init_args,\n    261             )\n    262 except Exception as e:\n--> 263     raise e\n    265 if not result:\n    266     return self.get(name=component.name, version=component.version)\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azure\/ai\/ml\/operations\/_component_operations.py:244, in ComponentOperations.create_or_update(self, component, **kwargs)\n    242 else:\n    243     if component._auto_increment_version:\n--> 244         result = _create_or_update_autoincrement(\n    245             name=component.name,\n    246             body=rest_component_resource,\n    247             version_operation=self._version_operation,\n    248             container_operation=self._container_operation,\n    249             resource_group_name=self._operation_scope.resource_group_name,\n    250             workspace_name=self._workspace_name,\n    251             **self._init_args,\n    252         )\n    253     else:\n    254         result = self._version_operation.create_or_update(\n    255             name=rest_component_resource.name,\n    256             version=component.version,\n   (...)\n    260             **self._init_args,\n    261         )\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azure\/ai\/ml\/_utils\/utils.py:496, in retry.<locals>.retry_decorator.<locals>.func_with_retries(*args, **kwargs)\n    494 delay = delay_multiplier * 2**counter + random.uniform(0, 1)\n    495 try:\n--> 496     return f(*args, **kwargs)\n    497 except exceptions as e:\n    498     tries -= 1\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azure\/ai\/ml\/_utils\/_asset_utils.py:287, in _create_or_update_autoincrement(name, body, version_operation, container_operation, resource_group_name, workspace_name, **kwargs)\n    284 except ResourceNotFoundError:\n    285     version = \"1\"\n--> 287 result = version_operation.create_or_update(\n    288     name=name,\n    289     version=version,\n    290     resource_group_name=resource_group_name,\n    291     workspace_name=workspace_name,\n    292     body=body,\n    293     **kwargs,\n    294 )\n    295 return result\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azure\/core\/tracing\/decorator.py:78, in distributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer(*args, **kwargs)\n     76 span_impl_type = settings.tracing_implementation()\n     77 if span_impl_type is None:\n---> 78     return func(*args, **kwargs)\n     80 # Merge span is parameter is set, but only if no explicit parent are passed\n     81 if merge_span and not passed_in_parent:\nFile \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azure\/ai\/ml\/_restclient\/v2022_05_01\/operations\/_component_versions_operations.py:516, in ComponentVersionsOperations.create_or_update(self, resource_group_name, workspace_name, name, version, body, **kwargs)\n    514     map_error(status_code=response.status_code, response=response, error_map=error_map)\n    515     error = self._deserialize.failsafe_deserialize(_models.ErrorResponse, pipeline_response)\n--> 516     raise HttpResponseError(response=response, model=error, error_format=ARMErrorFormat)\n    518 if response.status_code == 200:\n    519     deserialized = self._deserialize('ComponentVersionData', pipeline_response)\nHttpResponseError: (ServiceError) Received 500 from a service request\nCode: ServiceError\nMessage: Received 500 from a service request\nTarget: POST https:\/\/component.vienna-southeastasia.svc\/component\/v2.0\/subscriptions\/3ceb9ed0-8ef8-49a5-ae9d-c2381ba5752e\/resourceGroups\/resource-group-1\/providers\/Microsoft.MachineLearningServices\/workspaces\/mlops\/componentversions\/?componentName=stock_pred_data_prep&componentVersion=2022-06-17-05-57-08-6940895&validateOnly=False&upgradeIfExists=True\nException Details:    (InternalServerError) {\n      \"error\": {\n        \"code\": \"ServiceError\",\n        \"severity\": null,\n        \"message\": \"Input string was not in a correct format.\",\n        \"messageFormat\": null,\n        \"messageParameters\": null,\n        \"referenceCode\": null,\n        \"detailsUri\": null,\n        \"target\": null,\n        \"details\": [],\n        \"innerError\": null,\n        \"debugInfo\": null,\n        \"additionalInfo\": null\n      },\n      \"correlation\": {\n        \"operation\": \"85a19cb768484844855b3015cc5e60d6\",\n        \"request\": \"df050dc38daa8391\"\n      },\n      \"environment\": \"southeastasia\",\n      \"location\": \"southeastasia\",\n      \"time\": \"2022-06-17T05:57:28.1610781+00:00\",\n      \"componentName\": \"component\"\n    }\n    Code: InternalServerError\n    Message: {\n      \"error\": {\n        \"code\": \"ServiceError\",\n        \"severity\": null,\n        \"message\": \"Input string was not in a correct format.\",\n        \"messageFormat\": null,\n        \"messageParameters\": null,\n        \"referenceCode\": null,\n        \"detailsUri\": null,\n        \"target\": null,\n        \"details\": [],\n        \"innerError\": null,\n        \"debugInfo\": null,\n        \"additionalInfo\": null\n      },\n      \"correlation\": {\n        \"operation\": \"85a19cb768484844855b3015cc5e60d6\",\n        \"request\": \"df050dc38daa8391\"\n      },\n      \"environment\": \"southeastasia\",\n      \"location\": \"southeastasia\",\n      \"time\": \"2022-06-17T05:57:28.1610781+00:00\",\n      \"componentName\": \"component\"\n    }\nAdditional Information:Type: ComponentName\nInfo: {\n    \"value\": \"managementfrontend\"\n}Type: Correlation\nInfo: {\n    \"value\": {\n        \"operation\": \"85a19cb768484844855b3015cc5e60d6\",\n        \"request\": \"8b85fb5624fdd21e\"\n    }\n}Type: Environment\nInfo: {\n    \"value\": \"southeastasia\"\n}Type: Location\nInfo: {\n    \"value\": \"southeastasia\"\n}Type: Time\nInfo: {\n    \"value\": \"2022-06-17T05:57:28.198017+00:00\"\n}\n\n\n\n\nYML spec:\n\nname: stock_pred_data_prep\ndisplay_name: Preprocess data for training\ndescription: reads raw price data, normalize and split the data\n# version: 1 # Not specifying a version will automatically update the version\ntype: command\ninputs:\n  data: {type: uri_folder}\n  test_ratio: {type: number}\n  window: {type: number}\noutputs:\n  scaler: {type: uri_file}\n  train_data_x: {type: uri_file}\n  train_data_y: {type: uri_file}\n  test_data_x: {type: uri_file}\n  test_data_y: {type: uri_file}\ncode: ..\/..\nenvironment:\n  azureml:tensorflow_sklean_cpu:1.0\ncommand: >-\n  PYTHONPATH=$PYTHONPATH:$(pwd) \n  PYTHONPATH=$PYTHONPATH:$(pwd)  python azure_pipeline\/preproc_data\/preproc_data.py \n      --data=${{inputs.data}} --test_ratio=${{inputs.test_ratio}} \n      --window=${{inputs.window}} \n      --scaler=${{outputs.scaler}} \n      --train_data_x=${{outputs.train_data_x}} --train_data_y=${{outputs.train_data_y}} \n      --test_data_x=${{outputs.test_data_x}} --test_data_y=${{outputs.test_data_y}}",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-17T22:50:08.357Z",
                "Answer_score":1,
                "Answer_body":"Hello @PengGeorge-1261\n\nThanks for reaching out to us and thanks for sharing the solution. I will forward this issue to product group to fix.\n\nPlease do let us know if you have more issues, we are glad to help you.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Visual Code red underline",
        "Question_creation_time":1617894794830,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/349688\/visual-code-red-underline.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hello! I'm studying the Phyton First Steps course and I have questions about the Video Code. When I type \"Print\" in the code thing it doesn't get a red underline as they said it should. I want to know if I need to enable that type of thing",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-21T01:33:55.777Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nRed underline in VS code means that there is an error, which is not expected to appear. If you get it you need to fix it. Please let us know the code if you need help.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to access to the featurized dataset in Automated ML",
        "Question_creation_time":1618306428473,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/355323\/how-to-access-to-the-featurized-dataset-in-automat.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I\u2019m performing a series of experiments with AutoML and I need to see the featurized data. I mean, not just the new features names retrieved by method get_engineered_feature_names() or the featurization details retrieved by get_featurization_summary(), I refer to the whole transformed dataset, the one obtained after scaling\/normalization\/featurization that is then used to train the models.\n\nIs it possible to access to this dataset or download it as a file?\n\nThanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-13T19:09:15.137Z",
                "Answer_score":0,
                "Answer_body":"Hi, currently, we don't store the dataset from scaling\/normalization\/featurization after the run is complete. This feature isn't supported at this time. Sorry for the inconvenience.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure machine learning",
        "Question_creation_time":1656618921300,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/909965\/azure-machine-learning-2.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Is there any way to integrate MS Dynamics Customer Insights with Azure Machine Learning (designer)?I know there is an integration between CI and Azure Machine Learning studio (classic). Please help to integrate these two services.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-30T23:43:14.977Z",
                "Answer_score":0,
                "Answer_body":"Hello @Yasuo-9899\n\nThanks for reaching out to us for this question. Are you looking for this document? https:\/\/docs.microsoft.com\/en-us\/dynamics365\/customer-insights\/azure-machine-learning-experiments\n\nI have found one pic which is described the structure well:\n\n\n\n\n\nAnd also a repo you may want to refer to: https:\/\/github.com\/ArtisConsulting\/customer-insights-azure-data-workshop\/blob\/main\/README.md\n\nPlease let us know more details you are interested in so that we can help. Thanks.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-07-01T22:59:10.557Z",
                "Answer_score":0,
                "Answer_body":"Hi @Yasuo-9899 ,\n\nI believe below document will be helpful.\nGeneral Documentation: https:\/\/docs.microsoft.com\/en-us\/dynamics365\/customer-insights\/custom-models\n\nPre-requisites for correct configuration of a pipeline: https:\/\/docs.microsoft.com\/en-us\/dynamics365\/customer-insights\/azure-machine-learning-experiments\n\nTutorial Documentation: https:\/\/github.com\/naravill\/CustomerInsightsML\n\nRegards,\nPritee",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AzureML Pipeline step gets stuck on Finalizing status, eventually gets marked as failed.",
        "Question_creation_time":1657029836827,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/914821\/azureml-pipeline-step-gets-stuck-on-finalizing-sta.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"My python file finishes the job( verified in driver logs file), but the step file when finalizing takes lot of time and eventually gets marked as failed step.\n\n\n\n\nLogs from job post log file\n\n\n\n\n[2022-07-05T13:44:27.063561] Entering job release\n[2022-07-05T13:44:28.612901] Starting job release\n[2022-07-05T13:44:28.613665] Logging experiment finalizing status in history service.\nStarting the daemon thread to refresh tokens in background for process with pid = 330\n[2022-07-05T13:44:28.614116] job release stage : upload_datastore starting...\n[2022-07-05T13:44:28.616222] job release stage : start importing azureml.history._tracking in run_history_release.\n[2022-07-05T13:44:28.616341] job release stage : execute_job_release starting...\n[2022-07-05T13:44:28.616970] Entering context manager injector.\n[2022-07-05T13:44:28.626569] job release stage : copy_batchai_cached_logs starting...\n[2022-07-05T13:44:28.626790] job release stage : copy_batchai_cached_logs completed...\n[2022-07-05T13:44:28.631233] job release stage : upload_datastore completed...\n[2022-07-05T13:44:28.894740] job release stage : execute_job_release completed...\nFailed to set run status: Finalizing\n<urlopen error timed out>\n\nRetrying...\nFailed to set run status: Finalizing\n<urlopen error timed out>\n\nRetrying...\n[2022-07-05T13:44:41.757229] job release stage : send_run_telemetry starting...\n[2022-07-05T13:44:41.776454] get vm size and vm region successfully.\n[2022-07-05T13:44:41.783878] get compute meta data successfully.\nFailed to upload compute record artifact, error_details=<urlopen error [Errno 110] Connection timed out>\n[2022-07-05T13:45:13.220949] job release stage : send_run_telemetry completed...\n[2022-07-05T13:45:13.221247] Job release is complete\n\nAttached error log screenshots for reference.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Numbers of columns of arguments do not match",
        "Question_creation_time":1656632530313,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/910151\/numbers-of-columns-of-arguments-do-not-match.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":7,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I input data from a zip file that contains 10 cvs files with equals columns that I checked on excel that range from A-T.\n\nWhen I run it, it says: numbers of columns of arguments do not match\n\nDon't know what can I do to check\/correct it.\n\nHere's the log:\n\n[Stop] DllModuleMethod::Execute. Duration = 00:07:15.6892939\n[Critical] Error: Error 0063: The following error occurred during evaluation of R script:\n---------- Start of error message from R ----------\nnumbers of columns of arguments do not match\n\n\n\n\nnumbers of columns of arguments do not match\n----------- End of error message from R -----------\n[Critical] {\"InputParameters\":{\"Generic\":{\"bundlePath\":\"..\\..\\\\Script Bundle\\\\Script Bundle.zip\",\"rLibVersion\":\"R344\"},\"Unknown\":[\"Key: rStreamReader, ValueType : System.IO.StreamReader\"]},\"OutputParameters\":[],\"ModuleType\":\"LanguageWorker\",\"ModuleVersion\":\" Version=6.0.0.0\",\"AdditionalModuleInfo\":\"LanguageWorker, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca;Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS;RunRSNR\",\"Errors\":\"Microsoft.Analytics.Exceptions.ErrorMapping+ModuleException: Error 0063: The following error occurred during evaluation of R script:\\r\\n---------- Start of error message from R ----------\\r\\nnumbers of columns of arguments do not match\\r\\n\\r\\n\\r\\nnumbers of columns of arguments do not match\\r\\n----------- End of error message from R -----------\\r\\n at Microsoft.Analytics.Exceptions.ErrorMapping.Throw(ExceptionID id, Object[] arguments)\\r\\n at Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS.ExecuteR(NewRWorker worker, DataTable dataset1, DataTable dataset2, IEnumerable`1 bundlePath, StreamReader rStreamReader, Nullable`1 seed) in m:\\\\AzureMLVS15-004\\_work\\\\117\\\\s\\\\Product\\\\Source\\\\Modules\\\\LanguageWorker\\\\LanguageWorker.Dll\\\\EntryPoints\\\\RModule.cs:line 284\\r\\n at Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS._RunImpl(NewRWorker worker, DataTable dataset1, DataTable dataset2, String bundlePath, StreamReader rStreamReader, Nullable`1 seed, ExecuteRScriptExternalResource source, String url, ExecuteRScriptGitHubRepositoryType githubRepoType, SecureString accountToken) in m:\\\\AzureMLVS15-004\\_work\\\\117\\\\s\\\\Product\\\\Source\\\\Modules\\\\LanguageWorker\\\\LanguageWorker.Dll\\\\EntryPoints\\\\RModule.cs:line 208\\r\\n at Microsoft.MetaAnalytics.LanguageWorker.LanguageWorkerClientRS.RunRSNR(DataTable dataset1, DataTable dataset2, String bundlePath, StreamReader rStreamReader, Nullable`1 seed, ExecuteRScriptRVersion rLibVersion) in m:\\\\AzureMLVS15-004\\_work\\\\117\\\\s\\\\Product\\\\Source\\\\Modules\\\\LanguageWorker\\\\LanguageWorker.Dll\\\\EntryPoints\\\\REntryPoint.cs:line 97\",\"Warnings\":[],\"Duration\":\"00:07:15.5925361\"}\nModule finished after a runtime of 00:07:16.8387443 with exit code -2\nModule failed due to negative exit code of -2\n\nThanks,\nN.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How to use Azure files for model endpoints created in AML hosted on AKS?",
        "Question_creation_time":1656329447103,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/904580\/how-to-use-azure-files-for-model-endpoints-created.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":23,
        "Question_score":0,
        "Question_body":"Hello,\nwe have a complex data processing pipeline, including multiple different Models.\nOne of those models is a GPU-Model, which will be hosted as an API via AML.\nTherefore, we are also using an AKS for the hosting\/compute. This is working fine.\nHowever, the model itself is supposed to use data generated by prior steps.\nDownloading the data from a storage account into the container, is not a good solution.\nWe would like to \"mount\" the storage account directly and use the data therein (similar to databricks).\n\nI also know, that for persistent volumes in AKS, you can use Azure Files.\nHowever, normally you set this is up in the AKS and in the deployment-yaml.\nWith AML I did not find a way, to modify the deployments to use persistent volumes.\nIs there really no way? Or did I just not find the documentation for that?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-28T03:25:38.337Z",
                "Answer_score":1,
                "Answer_body":"Hello @83226169 ,\n\nThank you for posting query in Microsoft Q&A Platform. Is this for inference?\n\nBelow content might be helpful.\nhttps:\/\/www.youtube.com\/watch?v=SmVHNpKVs3Y\nAre you looking for something like below?\n\n\nhttps:\/\/www.youtube.com\/watch?v=D0qsjJYj5Ow\n\nAzure Machine Learning team has a dedicated ARM template within Azure QuickStart templates that deploys secure configurations.\nhttps:\/\/microsoft.github.io\/azureml-ops-accelerator\/3-Deploy\/ARMTemplates\/\n\n\n\n\n\n\n\nRegards,\nPritee",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-29T08:21:12.187Z",
                "Answer_score":0,
                "Answer_body":"Thanks for the replies.\nI was initially looking for a way to use azure files with AML. And actually I found something in the depth of the documentation: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/reference-kubernetes (at the bottom \u201cAzureML jobs connect with custom data storage\u201d).\n\nHowever, we re-evaluated our design and concluded, that the connection to the blob storage is actually enough and preferred to Azure Files. Therefore, your hints and links are helpful to create the more secure setup with the Storage Account, than just using the account key.\n\n\n\n\nKind regards,\nTobias",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Best practice for migration",
        "Question_creation_time":1656613684597,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/909885\/best-practice-for-migration.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Anyone has been migrated to new studio? Please share experience. I am confused about the migration, how should I copy paste my model from studio",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-30T22:44:31.167Z",
                "Answer_score":0,
                "Answer_body":"Hello @Alexandre-2525\n\nThanks for reaching out to us, I think you are talking about move from Studio classc to Designer, please refer to below document:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview\n\nBasically yes for your other thread, you need to rebuild the whole pipeline since we can not copy - paste your orignal structure to Designer.\n\nI am sorry for the inconveniences since the new studio has a disfferent structure to make this migration not that easy. Please let me know if you have any question during this process, we will provide help.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning Studio environment fails to build with context",
        "Question_creation_time":1654178870087,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/874583\/azure-machine-learning-studio-environment-fails-to.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"I'm trying to build an environment for ML Studio which requires some private compiled binaries. I packed these files into a Tar (about 2.8 MB, if it's relevant) and added them to the context tab of an existing environment (I want to update it). I then added this Tar in my Dockerfile and built the environment, but it failed instantly. The log tab also doesn't open (it just sits loading).\n\nI tried changing things around to eliminate as many variables as possible:\n\nInstead of using ADD I tried COPY: No change\n\n\nI tested building the Dockerfile locally in a folder containing only the Dockerfile and the tar: It worked\n\n\nI tested clicking the \"Download Content\" button and building the image in the downloaded folder: It worked\n\n\nI tried removing all references to the Tar from the Dockerfile but still uploading the file: It failed instantly\n\n\nI tried uploading an equivalent Zip file: It failed in the same way\n\n\nI uploaded a single text file instead of the Tar: It worked\n\nHow can I get this to work?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-07T19:09:21.2Z",
                "Answer_score":0,
                "Answer_body":"@romungi-MSFT I managed to get the environment to run by manual building it in the registry, then registering a new environment with this registry image. However, it's annoying to have to redo this every time I need to change something. Anything else I should try to get the portal to work properly?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"OrchestrateJobError - When according to Tutorials about Submit the run to Azure Machine Learning",
        "Question_creation_time":1654592788387,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/879639\/orchestratejoberror-when-according-to-tutorials-ab.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-sdk-train\n\nwhen I submitted the run to Azure Machine Learning according to the tutorials, the computer cluster's status running keep so long, and finally failed.\nThe error info is as fallows:\n\n\nService Error:\nAzureMLCompute job failed.\nOrchestrateJobError: Failed to execute command group with error Unexpected CommandError: Failed to pull Docker image CreateImageOptions { from_image: \"viennaglobal.azurecr.io\/cap\/hosttools-capability\/installed:eastus2-stable\", from_src: \"\", repo: \"\", tag: \"\", platform: \"\" } due to: Some(ErrorInfo(\"received unexpected HTTP status: 500 Operation could not be completed within the specified time.\"))",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-07T11:01:35.773Z",
                "Answer_score":1,
                "Answer_body":"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-environments#manage-environments\n\n # Instantiate environment\n myenv = Environment(name=\"myenv\")\n    \n # Configure the ScriptRunConfig and specify the environment\n src = ScriptRunConfig(source_directory=\".\", script=\"train.py\", compute_target=\"local\", environment=myenv)",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-07-04T11:59:06.91Z",
                "Answer_score":0,
                "Answer_body":"@YingDing-9450 Thanks for the question. We are able to create the compute cluster successfully.\n\nHere is link to sample notebook that can help to setup.\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/training\/train-on-amlcompute\/train-on-amlcompute.ipynb",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AzureML pipeline not working",
        "Question_creation_time":1654438612767,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/877179\/azureml-pipeline-not-working.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I have designed a pipeline that makes predictions and saves the results to a blob container.\nThe pipeline works fine after submitting the experiment. However, after I publish it and call it via its REST endpoint, it does not work (I don't get my results). The portal shows that the job has been completed, without any error.\nCan someone enlighten me on how to use a publish pipeline?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-07T12:23:00.923Z",
                "Answer_score":0,
                "Answer_body":"Thanks for the details. All published pipelines have a REST endpoint. With the pipeline endpoint, you can trigger a run of the pipeline from external systems, such as non-Python clients. For information about how to authenticate when calling REST endpoints, see https:\/\/aka.ms\/pl-restep-auth.\n\nUsing the endpoint enables \"managed repeatability\" in batch scoring and retraining scenarios, for example. For more information, see https:\/\/aka.ms\/pl-first-pipeline.\n\nhttps:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-pipeline-core\/azureml.pipeline.core.graph.publishedpipeline?view=azure-ml-py\n\nHere is the sample and document for publish.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning Compute Cost - Detailed information for each compute",
        "Question_creation_time":1654075947357,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/872840\/azure-machine-learning-compute-cost-detailed-infor.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":16,
        "Question_score":1,
        "Question_body":"Hi all,\n\nI need to have the cost detail for each compute (compute instance, compute clusters) configured within Azure Machine Learning.\nRight now from portal I can only retrieve an aggregate cost per compute type, but I need to have the detail per individual compute.\n\nHow can I get this information? Not necessarily from portal, but it's fine via SDK, Rest API, querying logs, etc. Just having this information is enough.\n\nThanks!\n\nG",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-06T13:58:23.183Z",
                "Answer_score":1,
                "Answer_body":"Hi all,\n\nshould anyone else be interested in tracking the actual costs of individual computes within AML, here is an Azure CLI command that is a great place to start. Within the \"additionalProperties\" field is the cluster detail information.\n\n(az consumption usage list --subscription $subscription --start-date $start_date --end-date $end_date --query \"[?contains(consumedService, 'Microsoft.MachineLearningServices') && contains(instanceName, $resource_group) && contains(product, 'Virtual Machine')]\" --include-additional-properties | ConvertFrom-Json) | select additionalProperties, pretaxCost, product, usageStart, usageEnd\n\n\n\n\nThis command can be used to retrieve the cost detail of all resources on Azure.\n\nGCocci",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unable to change input data of \"Web Service Output\" component in Designer in Azure ML Studio",
        "Question_creation_time":1654040427400,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/872177\/unable-to-change-input-data-of-34web-service-outpu.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I am trying to complete the following unit in a MS Learn module:\nhttps:\/\/docs.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/7-inference-pipeline\n\nI added a \"Execute Python Script\" between \"Score Model\" and \"Web Service Output\" as the following capture and saved the model in Designer.\n(Previously \"Score Model\" was directly connected to \"Web Service Output\".)\n\n\nAnd then I revisited the model, the connection between \"Execute Python Script\" and \"Web Service Output\" was disabled, and again \"Score Model\" was directory connected to \"Web Service Output\".\n\n\nDoes anyone tell me how to keep the connection between \"Execute Python Script\" and \"Web Service Output\".\n\nBest regards,",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-07T15:00:01.877Z",
                "Answer_score":1,
                "Answer_body":"@keijimscom @williamsandres-0381 I have confirmation that this issue has been fixed in all regions by development. Could you retry and let us know if it is successful?\nIf it still fails additional information might be required related to your workspace and runs. We will let you know details on sharing this information if required. Thanks!!\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML \"Real-time Endpoint Deploy\" not working",
        "Question_creation_time":1656130037907,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/903147\/azure-ml-34real-time-endpoint-deploy34-not-working.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I am trying to deploy as Kubernetes service (AKS) on Azure ML studio.\nI get a notification stating \"Preparing to deploy\", but Nothing shows up after that. I checked the endpoints list after a while and it is not there either.\n\nAfter that \"Preparing to deploy\" notification I don't receive any success or failure notification.\n\nIf anyone has any solution to this issue, the help is much appreciated.\n\nI have attached screenshots of the notification and ml pipeline I tried to deploy for context.\n\nFacing the above issues when using container instances as well...\n\n\n\n\nThe notification:\n\n\n\n\nThe pipeline I tried to deploy:\n\n\n\n\n\n\n\nUpdate:\nI think the problem was with the pipeline... I removed the web services, ran the pipeline, then created an inference pipeline from that, and then I was able to deploy using AKS. Although would be good to know the reason behind this... and why this workaround made all the difference",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"how to export trained azure ml model to production environment",
        "Question_creation_time":1656249928277,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/903600\/how-to-export-trained-azure-ml-model-to-production.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"How we can copying trained azure ml model from dev environment to production. Its possible to use trained model from one resource group to another resource group with same trained data.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-27T11:04:35.717Z",
                "Answer_score":1,
                "Answer_body":"@Dhineshkumar-1686 Currently, Azure ML supports mlflow for model management which can be used to register and query models using the mlflow client. Stages are assigned to a model's version (instead of models) which means that a given model can have multiple versions on different stages. You can use this documentation to refer the capabilities of the mlflow client. However, the following is also a current limitation.\n\nStages can only be accessed using the MLflow SDK. They don't show up in the Azure ML Studio portal and can't be retrieved using neither Azure ML SDK, Azure ML CLI, or Azure ML REST API. Creating deployment from a given model's stage is not supported by the moment.\n\n\n\n\nMoving of Azure ML workspace from one resource group to another is currently not supported.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Working bicep example for Azure ML environments",
        "Question_creation_time":1652269980557,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/845199\/working-bicep-example-for-azure-ml-environments.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi\n\nI'm trying to deploy an environment and environment version to Azure ML using Bicep. The documentation doesn't have any examples, and I keep getting an unhelpful error stating:\n\n\n\n\n\"The response for resource had empty or invalid content.\"\n\nCan anyone provide a working example deploying the following two resources:\n\nMicrosoft.MachineLearningServices\/workspaces\/environments@2021-03-01-preview\nMicrosoft.MachineLearningServices\/workspaces\/environments\/versions@2021-03-01-preview\n\nMy config is like this and it can successfully deploy the cluster, but not the environment and version:\n\nparam location string = resourceGroup().location\nresource amlCluster 'Microsoft.MachineLearningServices\/workspaces\/computes@2022-01-01-preview' = {\n  name: 'workspaceA\/cluster'\n  location: location\n  tags: {\n    project: 'projectA'\n  }\n  identity: {\n    type: 'SystemAssigned'\n  }\n  properties: {\n    computeLocation: location\n    computeType: 'AmlCompute'\n    properties: {\n      osType: 'Linux'\n      vmSize: 'STANDARD_D1'\n      scaleSettings: {\n        minNodeCount: 0\n        maxNodeCount: 2\n      }\n      subnet: null\n    }\n  }\n}\n\/\/ Create environment\nresource amlEnv 'Microsoft.MachineLearningServices\/workspaces\/environments@2021-03-01-preview' = {\n  name: 'workspaceA\/env'\n  properties: {\n    properties: {}\n    tags: {}\n  }\n  \n}\nresource amlEnvVersion 'Microsoft.MachineLearningServices\/workspaces\/environments\/versions@2021-03-01-preview' = {\n  name: 'env-version'\n  parent: amlEnv\n  properties: {\n    properties: {}\n    isAnonymous: false\n    docker: {\n        platform: {\n            operatingSystemType: 'Linux'\n        }\n        dockerSpecificationType: 'Image'\n        dockerImageUri: 'mcr.microsoft.com\/azureml\/base:intelmpi2018.3-ubuntu16.04'\n    }\n    condaFile: 'conda.yml'\n  }\n}",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-07T16:10:59.04Z",
                "Answer_score":0,
                "Answer_body":"Check on this - https:\/\/medium.com\/codex\/using-bicep-to-create-workspace-resources-and-get-started-with-azure-machine-learning-bcc57fd4fd09\n\nAzure create no bicep related, you need to search for external resource",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-07-02T10:13:41.05Z",
                "Answer_score":0,
                "Answer_body":"Hi, I had the same issue. I could not create a custom environment and then a version as stated in the documentation and even when you export the ARM template from existing resources. Then by the 'try\/fail' approach, I found that I don't need to create an 'environments' resource at all, only the 'environments\/version' is enough, but need to specify the valid path in the 'name' property.\n\n param ml_workspace_name string = 'my-workspace'\n param ml_cust_env_name string = 'MY_CUSTOM_ENV'\n param ml_cust_env_version string = '1'\n param ml_cust_env_image string = 'myacr.azurecr.io\/my-image:dev'\n    \n resource ml_cust_env 'Microsoft.MachineLearningServices\/workspaces\/environments\/versions@2022-05-01' = {\n   name: '${ml_workspace_name}\/${ml_cust_env_name}\/${ml_cust_env_version}'\n   properties: {\n     image: ml_cust_env_image\n     osType: 'Linux'\n   }\n }",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error running an Azure Experiment script (Azure Notebook)",
        "Question_creation_time":1656584703123,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/909355\/error-running-an-azure-experiment-script-azure-not.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hello,\n\nI am attempting to run an experiment script using Azure Notebooks as per this example,\nhttps:\/\/github.com\/MicrosoftLearning\/mslearn-dp100\/blob\/main\/04%20-%20Run%20Experiments.ipynb\n\nbut receive the following error;\n\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (azure-core 1.22.1 (\/azureml-envs\/sklearn-0.24.1\/lib\/python3.7\/site-packages), Requirement.parse('azure-core<2.0.0,>=1.23.0'), {'azure-mgmt-core'}).\nMSI: Failed to retrieve a token from 'identity-responder-not-enabled\/?resource=https:\/\/management.core.windows.net\/&api-version=2017-09-01' with an error of 'No connection adapters were found for 'identity-responder-not-enabled\/?resource=https:\/\/management.core.windows.net\/&api-version=2017-09-01''.\nPerforming interactive authentication. Please follow the instructions on the terminal.\nTo sign in, use a web browser to open the page https:\/\/microsoft.com\/devicelogin and enter the code XXXXXXX to authenticate.\n\nCould someone please advise a work around.\n\nThank you",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-07-02T00:46:34.9Z",
                "Answer_score":0,
                "Answer_body":"@ramr-msft\n\nThank you for your reply @ramr-msft\n\nAs suggested in the notebook I tried using interactive authentication -\n\nfrom azureml.core.authentication import InteractiveLoginAuthentication\n\ninteractive_auth = InteractiveLoginAuthentication(tenant_id=\"my-tenant-id\")\n\nbut received a similar message in the log file;\n\n2022-07-01 10:42:10,493|azureml._vendor.azure_cli_core._profile|INFO|No web browser is available. Fall back to device code.\n2022-07-01 10:42:10,592|azureml._vendor.azure_cli_core.auth.identity|WARNING|To sign in, use a web browser to open the page https:\/\/microsoft.com\/devicelogin and enter the code Q6AU753VQ to authenticate.\n\nThe command print(azureml.core.VERSION) tells me I am running 1.34.0",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to input data(csv) TO R-script model?",
        "Question_creation_time":1654040013303,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/872215\/how-to-input-datacsv-to-r-script-model.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi,\nI loaded all csv files, but R-script only allow two files for input ports. So I zipped all use 7-zip and verifed all files are same as not zipped before and loaded to Azure ml studio and connect it to R-script on 3rd port.\n\nEach time I run it, it says no connection, zip file corrupt.\n\nPLZ point out what is it and how to input datasets?\n\nThanks,\nN.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-01T12:53:20.8Z",
                "Answer_score":0,
                "Answer_body":"@NAW123-0733 While using the script bundle i.e 3rd port you need to place all the required files in a folder on your local machine and then zip the folder and upload it as a file dataset. If you try to select all files & create a zip without placing them in a folder the module will be unable to read.\n\nFor example, I tried with a sample csv where the file is placed in a folder and then the folder is zipped. I then, uploaded the zip file as file dataset to Azure ML studio, use this dataset in the designer canvas and connect it to the 3rd port and access the same using the corresponding path as of zipped file with a prefix of Script Bundle.\n\nThe result in this case is displaying the CSV data as output from result dataset 2.\n\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-30T21:51:41.57Z",
                "Answer_score":0,
                "Answer_body":"I tried folder thing, not working. Then I select all from within the folder, right click-> send to compression file.\n\nNow, it's connected, can open it. It worked!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning Monitoring",
        "Question_creation_time":1656094570340,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/902953\/azure-machine-learning-monitoring.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"How can we setup monitor for Azure Machine Learning pipeline\/job failures ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-24T20:56:50.727Z",
                "Answer_score":0,
                "Answer_body":"Hello @NirenAdhikaryNAD-1870\n\nWelcome to Microsoft Q&A Platform,\n\nPlease refer to the next article:\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/monitor-azure-machine-learning\n\nI hope this helps!\n\nPlease don\u2019t forget to \"Accept the answer\" and \u201cup-vote\u201d wherever the information provided helps you, this can be beneficial to other community members.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"will experiments disappear if I don\u2019t migrate to Designer?",
        "Question_creation_time":1654743684097,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/882424\/will-experiments-disappear-if-i-dont-migrate-to-de.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"do I still have the access to it?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-15T17:52:19.55Z",
                "Answer_score":0,
                "Answer_body":"Hello @Alexandre-2525\n\nI hope Rohit's reponse is helpful, please let us know if you have more question. All the data of studio will be avaiable till August 2024, you still have time to decide if you want to keep them, but Designer will provide the same experience and supporting the same function, you may want to try.\n\nPlease kindly accept the answer if you feel helpful to support the community, thanks a lot.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-06-09T12:15:18.483Z",
                "Answer_score":1,
                "Answer_body":"@Alexandre-2525 Do you mean migrating your experiments from Azure ML classic studio to Azure ML Designer studio?\nIf Yes, Then there is no direct way of moving all your experiments to the new studio. You would need to rebuild the models in the designer studio.\nIf you have an existing classic workspace it will be available till August 2024 if your subscription is active but after that the support will end and you might not be able to view any data from the classic studio.\nI hope this helps!!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-30T17:44:53.507Z",
                "Answer_score":0,
                "Answer_body":"Thank you both, sorry I can not accept both answer it return error.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Getting an SSL error azureml",
        "Question_creation_time":1656434118017,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/906759\/getting-an-ssl-error-azureml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I'm getting this error:\n\nssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1131)\n\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='eastus.api.azureml.ms', port=443): Max retries exceeded with url: \/rp\/workspaces\/subscriptions\/. . .\n\n\n\n\nwhile trying to do anything with azureml sdk\n\n from azureml.core import Workspace\n    \n ws = Workspace.from_config()\n    \n for compute_name in ws.compute_targets:\n     compute = ws.compute_targets[compute_name]\n     print(compute.name, \":\", compute.type)\n\n\n\nHow would I go about fixing this and running any kind of operation with the azureml-sdk?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-29T14:24:25.777Z",
                "Answer_score":1,
                "Answer_body":"@AsimAryal-5631 Thanks for the question. Here is the sample notebook to run authentication in azure machine learning.\n\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/1f05157d24c8bd9866121b588e75dc95764ae898\/how-to-use-azureml\/manage-azureml-service\/authentication-in-azureml\/authentication-in-azureml.ipynb\n\nWe are able to execute successfully and get the compute name and type as shown below.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to run next step as a graph in azure ai ml sdk2",
        "Question_creation_time":1656513973487,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/908194\/how-to-run-next-step-as-a-graph-in-azure-ai-ml-sdk.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I am running different steps in azure ai ml using command api. But they are running in random order. I want to run them sequentially. I don't have any data injection from previous step to next step as I am saving the output of one step on cloud storage and next step will fetch that one once the previous step is finished running. I tried to create fake_op (uri_string) for one step and gave input to the very next step. Doing this I am getting error.\n\n\n\n {'code': data-capability.UriMountSession.UserErrorException, 'message': UserErrorException:\n     Message: DataAccessError(NotFound)\n     InnerException None\n     ErrorResponse \n {\n     \"error\": {\n         \"code\": \"UserError\",\n         \"message\": \"DataAccessError(NotFound)\"\n     }\n }, 'target': , 'category': UserError, 'error_details': [{'key': NonCompliantReason, 'value': UserErrorException:\n     Message: DataAccessError(NotFound)\n     InnerException None\n     ErrorResponse \n {\n     \"error\": {\n         \"code\": \"UserError\",\n         \"message\": \"DataAccessError(NotFound)\"\n     }\n }}, {'key': StackTrace, 'value':   File \"\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/data_capability\/data_sessions.py\", line 331, in start\n     options=mnt_options\n    \n   File \"\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/fuse\/dprepfuse.py\", line 696, in rslex_uri_volume_mount\n     raise e\n    \n   File \"\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/fuse\/dprepfuse.py\", line 690, in rslex_uri_volume_mount\n     mount_context = RslexDirectURIMountContext(mount_point, uri, options)\n }, ], 'inner_error': null}\n\n\n\n\nAlso, would u suggest to move to azure ml sdk v2 now or should we wait until it is stable.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure : \"message\": \"Error: Scoring was unsuccessful.\" when we run forecasting.",
        "Question_creation_time":1655568786827,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/894519\/azure-34message34-34error-scoring-was-unsuccessful.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hi,\n\ninit() function in score.py is executed properly but I am getting error in run function. As shown in image I am getting below error.\n\n \"error\": {\n\"message\": \"Error: Scoring was unsuccessful.\"\n}\n\nThank you,\nSaswat",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-20T08:46:56.897Z",
                "Answer_score":0,
                "Answer_body":"@SaswatMahapatra-4328 Do you see the same error when you test the prediction through the consume tab of the endpoint from the Azure ML portal?\nIf the above works for same data through portal then it is most likely a data issue, but it looks like not much detail of the error is printed here. Can you also check what the swagger API prints about the data format that needs to be passed?\n\n print(service.swagger_uri)",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"proportion of ML is in Azure data centers",
        "Question_creation_time":1655642379753,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/894789\/proportion-of-ml-is-in-azure-data-centers.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Dear Azure Support,\nMy Name is Erim and I study computer sciene in Germany.\nI am currently preparing a presentation on machine learning and energy consumption. Next Friday is the deadline.\n\nI would like to know how high the proportion of ML is in your data centers, like how many customers use you date centers for ML? Since I could not find any data on this, I am contacting you directly. I hope you can help me\n\nBest regards\nErim Medi",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-20T09:38:53.46Z",
                "Answer_score":0,
                "Answer_body":"@erimMedi-6129 Thanks for the question. This sensitive data will not be shared publicly for privacy concerns.\n\nHere is the link to the customers that uses the Azure ML.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"how i can recover my compute instance ?",
        "Question_creation_time":1655132409567,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/887255\/how-i-can-recover-my-compute-instance.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"error: The specified Azure ML Compute Instance cs-bi-cloud2 encountered an unusable node. Please try to restart the compute instance to recover. If it failed at creation time, please delete and try to recreate the compute instance. If the problem persists, please follow up with Azure Suppor",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-27T16:42:10.383Z",
                "Answer_score":0,
                "Answer_body":"Hello @csbicloudcsbicloud-1019\n\nHope you have solved this issue since you have not respponded to Ram's comment.\n\nAs the error message said, please try to restart the compute instance to recover. If it failed at creation time, please delete and try to recreate the compute instance. If the problem persists, please follow up with Azure Support.\n\nPlease let us know if you still see this error and we can help you to connect with support to check on the backend, we are glad to help more. Thanks a lot.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to export data from compute instance to Datastore",
        "Question_creation_time":1631557345167,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/550288\/how-to-export-data-from-compute-instance-to-datast.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I pull in data from a Datastore to the compute instance using the code below. I then do stuff with that data. What I'd like to do is to push the modified data back to the Datastore but I'm not finding the documentation that can show me how this is done.\n\n# Azure management\nfrom azureml.core import Workspace, Dataset\n# MetaData\nsubscription_id = '09b5fdb3-165d-4e2b-8ca0-34f998d176d5'\nresource_group = 'xCloudData'\nworkspace_name = 'xCloudML'\n# Create workspace \nworkspace = Workspace(subscription_id, resource_group, workspace_name)\n# Retention_Engagement_CombinedData from cosmos ss\ndataset = Dataset.get_by_name(workspace, name='retention-engagement-combineddata')\n# Save data to file\ndf = dataset.to_pandas_dataframe()\ndf.to_csv('\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/v-aantico1\/code\/RetentionEngagement_CombinedData.csv')\n# Do stuff with data\n...\n# Push data back to Datastore\n...",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-04T15:25:09.183Z",
                "Answer_score":0,
                "Answer_body":"@AdrianAnticoTEKsystemsInc-1526\n\nThanks for the feedback again, I saw the deprecated method as well. I have forwarded this topic to product team, hope we can have some official guidance about this or workaround to help.\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Web service REST Type POST in Azure Machine learning from data factory",
        "Question_creation_time":1654098119170,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/873192\/web-service-rest-type-post-in-azure-machine-learni.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":27,
        "Question_score":0,
        "Question_body":"I try to use en the pipe line the web activity i cant to vinculate the dataset, but only with de body its succesfull de calling\n\n\n\n\n{\n\"name\": \"pipeline1\",\n\"properties\": {\n\"activities\": [\n{\n\"name\": \"Web1\",\n\"type\": \"WebActivity\",\n\"dependsOn\": [],\n\"policy\": {\n\"timeout\": \"7.00:00:00\",\n\"retry\": 0,\n\"retryIntervalInSeconds\": 30,\n\"secureOutput\": false,\n\"secureInput\": false\n},\n\"userProperties\": [],\n\"typeProperties\": {\n\"url\": \"http:\/\/80a36f92-5b73-4852-8e72-247379fa0bd6.westeurope.azurecontainer.io\/score\",\n\"method\": \"POST\",\n\"body\": {\n\"Inputs\": {\n\"data\": [\n{\n\"Product ID\": \"410\",\n\"Week\": 24,\n\"Year\": 2022,\n\"Customer ID\": \"3959\",\n\"Score\": 12\n}\n]\n},\n\"GlobalParameters\": 1\n},\n\"datasets\": [\n{\n\"referenceName\": \"Json2\",\n\"type\": \"DatasetReference\"\n}\n]\n}\n}\n],\n\"annotations\": [],\n\"lastPublishTime\": \"2022-05-20T11:40:24Z\"\n}\n}\n\n\n\n\nAnswer: Error Code 2108. user configuration issue. run () got an unexpected keyword argument 'datasets', i use postman and everything ist ok\n\n\n\n\nin other way, in the dataflow i use the external call bur the error its, connection failed. Error Code DFExecutorUserError. Some(list index out of range), Status code: 502. Please check your request url and body.\n\nWhen i probe the conection in the edit linked service, the test conection its ok. but in the property linked service the conection ist failed\n\nI consume this web service without any problem in power bi.\n\n\n\n\n{\n\"name\": \"dataflow_RFM\",\n\"properties\": {\n\"type\": \"MappingDataFlow\",\n\"typeProperties\": {\n\"sources\": [\n{\n\"dataset\": {\n\"referenceName\": \"Salmonsurdb\",\n\"type\": \"DatasetReference\"\n},\n\"name\": \"TransWeekCPto\"\n},\n{\n\"dataset\": {\n\"referenceName\": \"Salmonsurdb\",\n\"type\": \"DatasetReference\"\n},\n\"name\": \"RFM\"\n},\n{\n\"dataset\": {\n\"referenceName\": \"Salmonsurdb\",\n\"type\": \"DatasetReference\"\n},\n\"name\": \"PredictData\"\n}\n],\n\"sinks\": [\n{\n\"dataset\": {\n\"referenceName\": \"SSTransRFM\",\n\"type\": \"DatasetReference\"\n},\n\"name\": \"RFM11\"\n},\n{\n\"dataset\": {\n\"referenceName\": \"SSTransRFM\",\n\"type\": \"DatasetReference\"\n},\n\"name\": \"SSTransRFM\"\n},\n{\n\"dataset\": {\n\"referenceName\": \"SSTransRFM\",\n\"type\": \"DatasetReference\"\n},\n\"name\": \"RFM15\"\n},\n{\n\"dataset\": {\n\"referenceName\": \"BStorageSSFRQ\",\n\"type\": \"DatasetReference\"\n},\n\"name\": \"RFM14\"\n},\n{\n\"dataset\": {\n\"referenceName\": \"SSTransRFM\",\n\"type\": \"DatasetReference\"\n},\n\"name\": \"RFM13\"\n},\n{\n\"dataset\": {\n\"referenceName\": \"BStorageSSFRQ\",\n\"type\": \"DatasetReference\"\n},\n\"name\": \"RFM12\"\n},\n{\n\"dataset\": {\n\"referenceName\": \"SSTransRFM\",\n\"type\": \"DatasetReference\"\n},\n\"name\": \"RFQ10\"\n},\n{\n\"dataset\": {\n\"referenceName\": \"SSTransRFM\",\n\"type\": \"DatasetReference\"\n},\n\"name\": \"RFM9\"\n},\n{\n\"dataset\": {\n\"referenceName\": \"SSTransRFM\",\n\"type\": \"DatasetReference\"\n},\n\"name\": \"RFM8\"\n},\n{\n\"dataset\": {\n\"referenceName\": \"BStorageSSFRQ\",\n\"type\": \"DatasetReference\"\n},\n\"name\": \"RFM7\"\n},\n{\n\"dataset\": {\n\"referenceName\": \"BStorageSSFRQ\",\n\"type\": \"DatasetReference\"\n},\n\"name\": \"RFM6\"\n},\n{\n\"dataset\": {\n\"referenceName\": \"SSTransRFM\",\n\"type\": \"DatasetReference\"\n},\n\"name\": \"RFM5\"\n},\n{\n\"dataset\": {\n\"referenceName\": \"BStorageSSFRQ\",\n\"type\": \"DatasetReference\"\n},\n\"name\": \"RFM4\"\n},\n{\n\"dataset\": {\n\"referenceName\": \"SSTransRFM\",\n\"type\": \"DatasetReference\"\n},\n\"name\": \"RFM3\"\n},\n{\n\"linkedService\": {\n\"referenceName\": \"AzureBlobStorage1\",\n\"type\": \"LinkedServiceReference\"\n},\n\"name\": \"sink1\"\n},\n{\n\"dataset\": {\n\"referenceName\": \"SSTransRFM\",\n\"type\": \"DatasetReference\"\n},\n\"name\": \"sink2\"\n}\n],\n\"transformations\": [\n{\n\"name\": \"externalCall1\",\n\"linkedService\": {\n\"referenceName\": \"RestService1\",\n\"type\": \"LinkedServiceReference\"\n}\n},\n{\n\"name\": \"join1\"\n},\n{\n\"name\": \"RemoveColumns11\",\n\"description\": \"Generado autom\u00e1ticamente por acciones de vista previa de datos\"\n},\n{\n\"name\": \"Cluster14\"\n},\n{\n\"name\": \"Cluster15\"\n},\n{\n\"name\": \"Cluster11\"\n},\n{\n\"name\": \"Cluster13\"\n},\n{\n\"name\": \"Cluster12\"\n},\n{\n\"name\": \"Cluster10\"\n},\n{\n\"name\": \"Cluster9\"\n},\n{\n\"name\": \"Cluster8\"\n},\n{\n\"name\": \"Cluster7\"\n},\n{\n\"name\": \"Cluster6\"\n},\n{\n\"name\": \"Cluster5\"\n},\n{\n\"name\": \"Cluster4\"\n},\n{\n\"name\": \"Cluster3\"\n},\n{\n\"name\": \"filter1\"\n},\n{\n\"name\": \"join2\"\n},\n{\n\"name\": \"RemoveColumns12\",\n\"description\": \"Autogenerated by data preview actions\"\n},\n{\n\"name\": \"filter2\"\n}\n],\n\"scriptLines\": [\n\"source(output(\",\n\" {Customer ID} as string,\",\n\" {Product ID} as string,\",\n\" Week as integer,\",\n\" Year as integer,\",\n\" Quantity as decimal(19,4)\",\n\" ),\",\n\" allowSchemaDrift: true,\",\n\" validateSchema: false,\",\n\" isolationLevel: 'READ_UNCOMMITTED',\",\n\" query: 'SELECT --p.[document no_] AS \\\\'Sales ID\\\\',\\\\n --p.[entry type],\\\\n p.[source no_] AS \\\\'Customer ID\\\\',\\\\n p.[item no_] AS \\\\'Product ID\\\\',\\\\n --p.[document type] AS \\\\'Type\\\\',\\\\n --p.[posting date] AS \\\\'Transaction Date\\\\',\\\\n Datepart(wk,p.[posting date] ) AS \\\\'Week\\\\',\\\\n Year(p.[posting date] ) AS \\\\'Year\\\\',\\\\n SUM( CONVERT(MONEY, p.[Shipped Qty_ Not Returned]))-1 AS \\\\'Quantity\\\\'\\\\n\\\\n FROM [dbo].[salmonsur,s_a_$item ledger entry$437dbf0e-84ff-417a-965d-ed2bb9650972] p\\\\n where p.[document type] = 1\\\\n GROUP BY p.[document no_],\\\\n p.[source no_],\\\\n p.[item no_],\\\\n p.[document type],\\\\n p.[posting date],\\\\n quantity\\\\n',\",\n\" format: 'query') ~> TransWeekCPto\",\n\"source(output(\",\n\" {Customer ID} as string,\",\n\" Recency as integer,\",\n\" Frecuency as integer,\",\n\" MonetaryValue as decimal(19,4),\",\n\" R as long,\",\n\" F as long,\",\n\" M as long,\",\n\" Score as long\",\n\" ),\",\n\" allowSchemaDrift: false,\",\n\" validateSchema: false,\",\n\" isolationLevel: 'READ_UNCOMMITTED',\",\n\" query: 'select RFM.[Customer ID]\\\\n --,RFM.[Product ID]\\\\n ,AVG(RFM.[Recency]) AS \\\\'Recency\\\\'\\\\n ,AVG(RFM.[Frecuency]) AS \\\\'Frecuency\\\\' \\\\n ,AVG(RFM.[Sales Amount]) As \\\\'MonetaryValue\\\\'\\\\n ,NTILE(5) OVER(ORDER BY AVG(RFM.[Recency]) DESC) As \\\\'R\\\\'\\\\n ,NTILE(5) OVER(ORDER BY AVG(RFM.[Frecuency])ASC) As \\\\'F\\\\'\\\\n ,NTILE(5) OVER(ORDER BY AVG(RFM.[Sales Amount])ASC) As \\\\'M\\\\'\\\\n ,NTILE(5) OVER(ORDER BY AVG(RFM.[Recency]) DESC) \\\\n +NTILE(5) OVER(ORDER BY AVG(RFM.[Frecuency]))\\\\n +NTILE(5) OVER(ORDER BY AVG(RFM.[Sales Amount])) as \\\\'Score\\\\'\\\\n\\\\nfrom (\\\\n-- Consulta con informaci\u00f3n de RFM \\\\n-- Recency: D\u00edas ultima compra\\\\n-- Frecuency: Promedio de Frecuencia de compra del cliente Mensual\\\\n-- SalesAmount: Promedio del valor de la factura de venta Mensual\\\\n\\\\n SELECT \\\\n p.[source no_] AS \\\\'Customer ID\\\\'\\\\n ,p.[item no_] AS \\\\'Product ID\\\\'\\\\n ,p.[document type] AS \\\\'Type\\\\'\\\\n ,year(p.[posting date]) AS \\\\'TransactionYear\\\\'\\\\n ,Month(p.[posting date]) AS \\\\'TransactionMonth\\\\'\\\\n ,max(ti.Recency) AS \\\\'Recency\\\\'\\\\n ,Count(p.[document no_]) AS \\\\'Frecuency\\\\'\\\\n ,SUM(Ve.[Sales Amount]) AS \\\\'Sales Amount\\\\' \\\\n \\\\n FROM\\\\n [dbo].[salmonsur,s_a_$item ledger entry$437dbf0e-84ff-417a-965d-ed2bb9650972] p\\\\n outer apply(\\\\n select \\\\n pp.[source no_] AS \\\\'Customer ID\\\\'\\\\n ,pp.[item no_] AS \\\\'Product ID\\\\'\\\\n ,datediff(day,max(pp.[posting date]), getdate()) AS \\\\'Recency\\\\'\\\\n From [dbo].[salmonsur,s_a_$item ledger entry$437dbf0e-84ff-417a-965d-ed2bb9650972] pp\\\\n where pp.[source no_] = p.[source no_] \\\\n and pp.[item no_] = p.[item no_]\\\\n \\\\n group by pp.[source no_] , pp.[item no_]\\\\n ) ti\\\\n \\\\n \\\\n LEFT OUTER JOIN ( SELECT [Item Ledger Entry No_]\\\\n , Iif( Sum(CONVERT(MONEY, [Sales Amount (Actual)], 0)) = 0, \\\\n Sum(CONVERT(MONEY, [Sales Amount (Expected)], 0)), \\\\n Sum(CONVERT(MONEY, [Sales Amount (Actual)], 0))) AS \\\\'Sales Amount\\\\'\\\\n ,Iif(CONVERT(MONEY, Sum([Cost Amount (Actual)]), 0) = 0,\\\\n CONVERT(MONEY, Sum([Cost Amount (Expected)]), 0),\\\\n CONVERT(MONEY, Sum([Cost Amount (Actual)]), 0)) AS \\\\'Cost amount\\\\'\\\\n ,CONVERT(MONEY, Sum([Discount Amount]), 0) AS \\\\'Discount amount\\\\'\\\\n FROM [salmonsur,s_a_$value entry$437dbf0e-84ff-417a-965d-ed2bb9650972] \\\\n GROUP BY [Item Ledger Entry No_]\\\\n ) Ve\\\\n ON p.[entry no_]= Ve.[Item Ledger Entry No_]\\\\n\\\\n \\\\n\\\\n where --p.[source no_] = \\\\'2772\\\\' \\\\n --and p.[item no_] = \\\\'215\\\\' and\\\\n p.[posting date] >= DATEADD(month,-12,GETDATE())\\\\n and p.[document type] = \\\\'1\\\\'\\\\n\\\\n GROUP BY \\\\n p.[source no_],\\\\n p.[item no_],\\\\n p.[document type],\\\\n Year(p.[posting date]),\\\\n Month(p.[posting date])\\\\n )RFM\\\\n\\\\n--Where RFM.[Customer ID] = \\\\'2772\\\\' \\\\n\\\\nGroup by\\\\n RFM.[Customer ID]\\\\n --,RFM.[Product ID]\\\\n\\\\n--Order by RFM.[Customer ID]\\\\n \\\\n',\",\n\" format: 'query',\",\n\" partitionBy('hash', 1)) ~> RFM\",\n\"source(output(\",\n\" {Customer ID} as string,\",\n\" {Product ID} as string,\",\n\" Week as integer,\",\n\" Year as integer\",\n\" ),\",\n\" allowSchemaDrift: true,\",\n\" validateSchema: false,\",\n\" isolationLevel: 'READ_UNCOMMITTED',\",\n\" query: 'select A.[Customer ID] AS \\\\'Customer ID\\\\'\\\\n ,a.[Product ID] AS \\\\'Product ID\\\\'\\\\n ,Datepart(wk,B.[Transaction Date]) As \\\\'Week\\\\'\\\\n ,year(B.[Transaction Date]) As \\\\'Year\\\\'\\\\n , \\\\'1\\\\' as \\\\'Predict\\\\'\\\\n\\\\nfrom (\\\\n\\\\n SELECT p.[source no_] AS \\\\'Customer ID\\\\'\\\\n ,p.[item no_] AS \\\\'Product ID\\\\'\\\\n --convert(date, p.[posting date]) AS \\\\'Transaction Date\\\\',\\\\n --Datepart(wk,p.[posting date] ) AS \\\\'Week\\\\',\\\\n --Year(p.[posting date] ) AS \\\\'Year\\\\',\\\\n --SUM(CONVERT(MONEY, p.[Shipped Qty_ Not Returned]))-1 AS \\\\'Quantity\\\\'\\\\n\\\\n FROM [dbo].[salmonsur,s_a_$item ledger entry$437dbf0e-84ff-417a-965d-ed2bb9650972] p\\\\n where p.[document type] = 1\\\\n GROUP BY p.[source no_],\\\\n p.[item no_]\\\\n ) A, \\\\n (\\\\n select convert(date, max(p.[posting date])+8) AS \\\\'Transaction Date\\\\' FROM [dbo].[salmonsur,s_a_$item ledger entry$437dbf0e-84ff-417a-965d-ed2bb9650972] p\\\\n UNION ALL\\\\n select convert(date, max(p.[posting date])+16) AS \\\\'Transaction Date\\\\' FROM [dbo].[salmonsur,s_a_$item ledger entry$437dbf0e-84ff-417a-965d-ed2bb9650972] p\\\\n UNION ALL\\\\n select convert(date, max(p.[posting date])+24) AS \\\\'Transaction Date\\\\' FROM [dbo].[salmonsur,s_a_$item ledger entry$437dbf0e-84ff-417a-965d-ed2bb9650972] p\\\\n UNION ALL\\\\n select convert(date, max(p.[posting date])+32) AS \\\\'Transaction Date\\\\' FROM [dbo].[salmonsur,s_a_$item ledger entry$437dbf0e-84ff-417a-965d-ed2bb9650972] p\\\\n )B\\\\n',\",\n\" format: 'query') ~> PredictData\",\n\"filter2 call(output(\",\n\" headers as [string,string],\",\n\" status as string\",\n\" ),\",\n\" allowSchemaDrift: true,\",\n\" format: 'rest',\",\n\" store: 'restservice',\",\n\" timeout: 5,\",\n\" requestInterval: 5000,\",\n\" httpMethod: 'POST',\",\n\" headerColumnName: 'headers',\",\n\" statusColumnName: 'status',\",\n\" addResponseCode: true,\",\n\" requestFormat: ['type' -> 'json'],\",\n\" responseFormat: ['type' -> 'json', 'documentForm' -> 'arrayOfDocuments']) ~> externalCall1\",\n\"TransWeekCPto, RFM join(TransWeekCPto@{Customer ID} == RFM@{Customer ID},\",\n\" joinType:'right',\",\n\" broadcast: 'auto')~> join1\",\n\"join1 select(mapColumn(\",\n\" {Customer ID} = TransWeekCPto@{Customer ID},\",\n\" {Product ID},\",\n\" Week,\",\n\" Year,\",\n\" Quantity,\",\n\" Score\",\n\" ),\",\n\" skipDuplicateMapInputs: true,\",\n\" skipDuplicateMapOutputs: true) ~> RemoveColumns11\",\n\"RemoveColumns11 filter({Customer ID}!='' && Score == 14) ~> Cluster14\",\n\"RemoveColumns11 filter({Customer ID}!='' && Score == 15) ~> Cluster15\",\n\"RemoveColumns11 filter({Customer ID}!='' && Score == 11) ~> Cluster11\",\n\"RemoveColumns11 filter({Customer ID}!='' && Score == 13) ~> Cluster13\",\n\"RemoveColumns11 filter({Customer ID}!='' && Score == 12) ~> Cluster12\",\n\"RemoveColumns11 filter({Customer ID}!='' && Score == 10) ~> Cluster10\",\n\"RemoveColumns11 filter({Customer ID}!='' && Score == 9) ~> Cluster9\",\n\"RemoveColumns11 filter({Customer ID}!='' && Score == 8) ~> Cluster8\",\n\"RemoveColumns11 filter({Customer ID}!='' && Score == 7) ~> Cluster7\",\n\"RemoveColumns11 filter({Customer ID}!='' && Score == 6) ~> Cluster6\",\n\"RemoveColumns11 filter({Customer ID}!='' && Score == 5) ~> Cluster5\",\n\"RemoveColumns11 filter({Customer ID}!='' && Score == 4) ~> Cluster4\",\n\"RemoveColumns11 filter({Customer ID}!='' && Score == 3) ~> Cluster3\",\n\"RemoveColumns11 filter({Customer ID}!='') ~> filter1\",\n\"PredictData, RFM join(PredictData@{Customer ID} == RFM@{Customer ID},\",\n\" joinType:'right',\",\n\" partitionBy('hash', 1),\",\n\" broadcast: 'auto')~> join2\",\n\"join2 select(mapColumn(\",\n\" {Product ID},\",\n\" Week,\",\n\" Year,\",\n\" {Customer ID},\",\n\" Score,\",\n\" {Customer ID} = PredictData@{Customer ID}\",\n\" ),\",\n\" skipDuplicateMapInputs: true,\",\n\" skipDuplicateMapOutputs: true) ~> RemoveColumns12\",\n\"RemoveColumns12 filter({Customer ID}!='') ~> filter2\",\n\"Cluster11 sink(allowSchemaDrift: true,\",\n\" validateSchema: false,\",\n\" input(\",\n\" {Customer ID} as string,\",\n\" { Product ID} as string,\",\n\" { Week} as string,\",\n\" { Year} as string,\",\n\" { Quantity} as string,\",\n\" { Score} as string\",\n\" ),\",\n\" partitionFileNames:['RFM11.csv'],\",\n\" skipDuplicateMapInputs: true,\",\n\" skipDuplicateMapOutputs: true,\",\n\" header: ([\\\"Customer ID, Product ID, Week, Year, Quantity, Score\\\"]),\",\n\" partitionBy('hash', 1)) ~> RFM11\",\n\"filter1 sink(allowSchemaDrift: true,\",\n\" validateSchema: false,\",\n\" input(\",\n\" {Customer ID} as string,\",\n\" { Product ID} as string,\",\n\" { Week} as string,\",\n\" { Year} as string,\",\n\" { Quantity} as string,\",\n\" { Score} as string\",\n\" ),\",\n\" partitionFileNames:['TransRFM.csv'],\",\n\" skipDuplicateMapInputs: true,\",\n\" skipDuplicateMapOutputs: true,\",\n\" header: ([\\\"Customer ID, Product ID, Week, Year, Quantity, Score\\\"]),\",\n\" partitionBy('hash', 1)) ~> SSTransRFM\",\n\"Cluster15 sink(allowSchemaDrift: true,\",\n\" validateSchema: false,\",\n\" input(\",\n\" {Customer ID} as string,\",\n\" { Product ID} as string,\",\n\" { Week} as string,\",\n\" { Year} as string,\",\n\" { Quantity} as string,\",\n\" { Score} as string\",\n\" ),\",\n\" partitionFileNames:['RFM15.csv'],\",\n\" skipDuplicateMapInputs: true,\",\n\" skipDuplicateMapOutputs: true,\",\n\" header: ([\\\"Customer ID, Product ID, Week, Year, Quantity, Score\\\"]),\",\n\" partitionBy('hash', 1)) ~> RFM15\",\n\"Cluster14 sink(allowSchemaDrift: true,\",\n\" validateSchema: false,\",\n\" input(\",\n\" Column_1 as string\",\n\" ),\",\n\" partitionFileNames:['RFM14.csv'],\",\n\" skipDuplicateMapInputs: true,\",\n\" skipDuplicateMapOutputs: true,\",\n\" header: ([\\\"Customer ID, Product ID, Week, Year, Quantity, Score\\\"]),\",\n\" partitionBy('hash', 1)) ~> RFM14\",\n\"Cluster13 sink(allowSchemaDrift: true,\",\n\" validateSchema: false,\",\n\" input(\",\n\" {Customer ID} as string,\",\n\" { Product ID} as string,\",\n\" { Week} as string,\",\n\" { Year} as string,\",\n\" { Quantity} as string,\",\n\" { Score} as string\",\n\" ),\",\n\" partitionFileNames:['RFM13.csv'],\",\n\" skipDuplicateMapInputs: true,\",\n\" skipDuplicateMapOutputs: true,\",\n\" header: ([\\\"Customer ID, Product ID, Week, Year, Quantity, Score\\\"]),\",\n\" partitionBy('hash', 1)) ~> RFM13\",\n\"Cluster12 sink(allowSchemaDrift: true,\",\n\" validateSchema: false,\",\n\" input(\",\n\" Column_1 as string\",\n\" ),\",\n\" partitionFileNames:['RFM12.csv'],\",\n\" skipDuplicateMapInputs: true,\",\n\" skipDuplicateMapOutputs: true,\",\n\" header: ([\\\"Customer ID, Product ID, Week, Year, Quantity, Score\\\"]),\",\n\" partitionBy('hash', 1)) ~> RFM12\",\n\"Cluster10 sink(allowSchemaDrift: true,\",\n\" validateSchema: false,\",\n\" input(\",\n\" {Customer ID} as string,\",\n\" { Product ID} as string,\",\n\" { Week} as string,\",\n\" { Year} as string,\",\n\" { Quantity} as string,\",\n\" { Score} as string\",\n\" ),\",\n\" partitionFileNames:['RFM10.csv'],\",\n\" skipDuplicateMapInputs: true,\",\n\" skipDuplicateMapOutputs: true,\",\n\" header: ([\\\"Customer ID, Product ID, Week, Year, Quantity, Score\\\"]),\",\n\" partitionBy('hash', 1)) ~> RFQ10\",\n\"Cluster9 sink(allowSchemaDrift: true,\",\n\" validateSchema: false,\",\n\" input(\",\n\" {Customer ID} as string,\",\n\" { Product ID} as string,\",\n\" { Week} as string,\",\n\" { Year} as string,\",\n\" { Quantity} as string,\",\n\" { Score} as string\",\n\" ),\",\n\" partitionFileNames:['RFM9.csv'],\",\n\" skipDuplicateMapInputs: true,\",\n\" skipDuplicateMapOutputs: true,\",\n\" header: ([\\\"Customer ID, Product ID, Week, Year, Quantity, Score\\\"]),\",\n\" partitionBy('hash', 1)) ~> RFM9\",\n\"Cluster8 sink(allowSchemaDrift: true,\",\n\" validateSchema: false,\",\n\" input(\",\n\" {Customer ID} as string,\",\n\" { Product ID} as string,\",\n\" { Week} as string,\",\n\" { Year} as string,\",\n\" { Quantity} as string,\",\n\" { Score} as string\",\n\" ),\",\n\" partitionFileNames:['RFM8.csv'],\",\n\" skipDuplicateMapInputs: true,\",\n\" skipDuplicateMapOutputs: true,\",\n\" header: ([\\\"Customer ID, Product ID, Week, Year, Quantity, Score\\\"]),\",\n\" partitionBy('hash', 1)) ~> RFM8\",\n\"Cluster7 sink(allowSchemaDrift: true,\",\n\" validateSchema: false,\",\n\" input(\",\n\" Column_1 as string\",\n\" ),\",\n\" partitionFileNames:['RFM7.csv'],\",\n\" skipDuplicateMapInputs: true,\",\n\" skipDuplicateMapOutputs: true,\",\n\" header: ([\\\"Customer ID, Product ID, Week, Year, Quantity, Score\\\"]),\",\n\" partitionBy('hash', 1)) ~> RFM7\",\n\"Cluster6 sink(allowSchemaDrift: true,\",\n\" validateSchema: false,\",\n\" input(\",\n\" Column_1 as string\",\n\" ),\",\n\" partitionFileNames:['RFM6.csv'],\",\n\" skipDuplicateMapInputs: true,\",\n\" skipDuplicateMapOutputs: true,\",\n\" header: ([\\\"Customer ID, Product ID, Week, Year, Quantity, Score\\\"]),\",\n\" partitionBy('hash', 1)) ~> RFM6\",\n\"Cluster5 sink(allowSchemaDrift: true,\",\n\" validateSchema: false,\",\n\" input(\",\n\" {Customer ID} as string,\",\n\" { Product ID} as string,\",\n\" { Week} as string,\",\n\" { Year} as string,\",\n\" { Quantity} as string,\",\n\" { Score} as string\",\n\" ),\",\n\" partitionFileNames:['RFM5.csv'],\",\n\" skipDuplicateMapInputs: true,\",\n\" skipDuplicateMapOutputs: true,\",\n\" header: ([\\\"Customer ID, Product ID, Week, Year, Quantity, Score\\\"]),\",\n\" partitionBy('hash', 1)) ~> RFM5\",\n\"Cluster4 sink(allowSchemaDrift: true,\",\n\" validateSchema: false,\",\n\" input(\",\n\" Column_1 as string\",\n\" ),\",\n\" partitionFileNames:['RFM4.csv'],\",\n\" skipDuplicateMapInputs: true,\",\n\" skipDuplicateMapOutputs: true,\",\n\" header: ([\\\"Customer ID, Product ID, Week, Year, Quantity, Score\\\"]),\",\n\" partitionBy('hash', 1)) ~> RFM4\",\n\"Cluster3 sink(allowSchemaDrift: true,\",\n\" validateSchema: false,\",\n\" input(\",\n\" {Customer ID} as string,\",\n\" { Product ID} as string,\",\n\" { Week} as string,\",\n\" { Year} as string,\",\n\" { Quantity} as string,\",\n\" { Score} as string\",\n\" ),\",\n\" partitionFileNames:['RFM3.csv'],\",\n\" skipDuplicateMapInputs: true,\",\n\" skipDuplicateMapOutputs: true,\",\n\" header: ([\\\"Customer ID, Product ID, Week, Year, Quantity, Score\\\"]),\",\n\" partitionBy('hash', 1)) ~> RFM3\",\n\"filter2 sink(allowSchemaDrift: true,\",\n\" validateSchema: false,\",\n\" format: 'json',\",\n\" container: 'azureml-blobstore-282b5a81-86c2-4495-83cf-ebc234b5549c',\",\n\" folderPath: 'RFM',\",\n\" partitionFileNames:['jsonPredict'],\",\n\" skipDuplicateMapInputs: true,\",\n\" skipDuplicateMapOutputs: true,\",\n\" partitionBy('hash', 1)) ~> sink1\",\n\"filter2 sink(allowSchemaDrift: true,\",\n\" validateSchema: false,\",\n\" input(\",\n\" {Customer ID} as string,\",\n\" { Product ID} as string,\",\n\" { Week} as string,\",\n\" { Year} as string,\",\n\" { Quantity} as string,\",\n\" { Score} as string\",\n\" ),\",\n\" partitionFileNames:['RFMPredict.csv'],\",\n\" skipDuplicateMapInputs: true,\",\n\" skipDuplicateMapOutputs: true,\",\n\" partitionBy('hash', 1)) ~> sink2\"\n]\n}\n}\n}",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-03T15:38:32.127Z",
                "Answer_score":0,
                "Answer_body":"Hi @LuisVivarDQS-9277 ,\n\nThank you for posting query in Microsoft Q&A Platform.\n\nI was able to reproduce your scenario and error.\n\nTo avoid this error, kindly remove dataset selection inside web activity.\n\nPlease check below screenshots for better idea.\n![208249-image.png][1]\n\n![208217-image.png][2]\n\nPlease note, when you want to supply pass your dataset\n[1]: \/answers\/storage\/attachments\/208249-image.png\n[2]: \/answers\/storage\/attachments\/208217-image.png",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-03T15:39:56.397Z",
                "Answer_score":0,
                "Answer_body":"Hi @LuisVivarDQS-9277 ,\n\nThank you for posting query in Microsoft Q&A Platform.\n\nI was able to reproduce your scenario and error.\n\nTo avoid this error, kindly remove dataset selection inside web activity.\n\nPlease check below screenshots for better idea.\n\n\nPlease note, when you want to supply pass your datasets to be passed to your end point then only we need these dataset references. Click here to know more about web activity properties.\n\nHope this helps.\n\nPlease consider hitting Accept Answer button. Accepted answers help community as well.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Using Tabular data from a SQL datastore already in Azure ML in the pipeline",
        "Question_creation_time":1655995821250,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/901060\/using-tabular-data-from-a-sql-datastore-already-in.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I have a dataset, Tabular type, created from a SQL connection in AzureML.\nNow I can consume the table inside my python script using Workspace credentials.\n\n dataset = Dataset.get_by_name(workspace, name='.....')\n dataset.to_pandas_dataframe()\n\n\n\nI would like to use this table as an input (possibly as a uri_file or mltable) in my pipeline, but the only mode that works is direct. In direct mode, the input I get inside the job is just a url of the table.\nHow can I mount or download this kind of Tables directly in a job, like blob storage files or folders?\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-24T08:10:49.193Z",
                "Answer_score":0,
                "Answer_body":"@IsmaelGarciaSerrano-8363 Thanks for the question. We might need to use an private wheel at the moment. we recently fixed one bug with SQL datastore and it's yet to be published.\n\nmltable has its own SDK which is basically a replacement to the TabularDataset class: mltable \u00b7 PyPI. If you install that in your environment, you can then pass in the url you get to the load method:\n\n from mltable import mltable\n tbl = mltable.load(the_url_you_get_in_direct_mode)\n df = tbl.to_pandas_dataframe()",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error testing batch endpoint",
        "Question_creation_time":1655371158430,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/891782\/error-testing-batch-endpoint.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hello,\n\nI'm trying to deploy a batch endpoint in AzureML. Below are screenshots of the code I'm using.\n\nThe deployment of the endpoint seems to work okay - says it is successful.\n\nWhen I come to testing the endpoint - I get the attached errors within the studio relating to mini batch items.\n\nAny idea of things I can try to fix this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-17T05:41:40.293Z",
                "Answer_score":0,
                "Answer_body":"@CameronGrimshawJones-8148 Thanks for the question. Can you please share the code sample notebook, also please add details Azure ML SDK version.\nHere is link to the document to test the batch endpoint and troubleshooting guide.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure AML - Diagnostic Logs AmlModelsEvent not collected",
        "Question_creation_time":1655976210980,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/900632\/azure-aml-diagnostic-logs-amlmodelsevent-not-colle.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi,\nI have configured a DiagnosticLogs setting in my AML resource, but when I check within the Log Analytcs Workspace I see all logs but no AmlModelsEvent.\nI tested by accessing my AML models and modifyng them. Why I cannot see these logs?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-24T13:11:20.163Z",
                "Answer_score":0,
                "Answer_body":"Hi @ramr-msft I cannot see that menu in the portal, I see only a right-side menu\n\n\nAnyway I see the logs in my log analytcs workspace and it already collects other AML diagnostic logs (like AmlDeploymentsEvents, AmlClusterEvents, ...) but no AmlModelsEvents.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to use blob storage file as input to azure ml endpoint",
        "Question_creation_time":1655374179990,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/891865\/how-to-use-blob-storage-file-as-input-to-azure-ml.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":21,
        "Question_score":1,
        "Question_body":"I have big data that I need to pass it to already trained Machine Learning model on Azure and has been deployed as online endpoint, I realize that batch endpoints supports adding a reference to blob file as input, my question is: how to do the same for online enpdoints ?\n\nSo far all examples I see are passing the payload as json (Even in the test tab of the online enpoints) but i don't know how to simply pass a blob storage file's uri as the payload.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-24T06:20:12.08Z",
                "Answer_score":1,
                "Answer_body":"@MostafaMansour-4203 Thanks for the question. I have checked internally with the product team, Currently Online endpoints are for Realtime synchronous requests.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-06-24T07:11:52.483Z",
                "Answer_score":1,
                "Answer_body":"Answering my own question: real time endpoints doesn't support blob storage file\/folder as input, will have to use batch endpoints",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"error - unable to find ggplot function",
        "Question_creation_time":1655169164353,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/887802\/error-unable-to-find-ggplot-function.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"Hi, could assist to advise me?\nR-script in Azure machine.\n\nerror message: unable to find ggplot function.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-14T01:55:55.307Z",
                "Answer_score":0,
                "Answer_body":"@DawnChin-3362 - Welcome to Microsoft Q&A and thanks for reaching out.\n\nIf you ever see the Error in ggplot(...): could not find function \"ggplot\", it suggests that this ggplot() function is not available because the package that holds the function (ggplot2) did not load with library(ggplot2).\n\nTherefore, you cannot utilize the ggplot() function without that ggplot2 package being loaded first.\n\nHope this helps. and please feel free to reach out if you have any further questions.\n\n\n\n\nIf the above response was helpful, please feel free to \"Accept as Answer\" and \"Upvote\" the same so it can be beneficial to the community.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Connecting to an existing Databricks Cluster in AMLS",
        "Question_creation_time":1654614267930,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/880189\/connecting-to-an-existing-databricks-cluster-in-am.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":16,
        "Question_score":0,
        "Question_body":"Hello,\n\nwe have also found this example of using Databricks as a Compute Target for an Azure Machine Learning Pipeline.\n\nHowever, we want to use an existing Databricks Cluster as compute target within Azure Machine Learning Studio for our Azure Machine Learning Pipeline.\nCould you help us in accomplishing this, please?\n\n\n\n\nWith best regards\nAlex",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-08T05:07:31.167Z",
                "Answer_score":0,
                "Answer_body":"@AlexanderPakakis-0994 Are you looking at adding the cluster from the UI of ML studio rather than using the SDK as mentioned in the notebook you referenced?\nIf Yes, you need to add the same attached compute.\n\nOnce you select Azure Databricks the following option to add the existing databricks workspace is seen.\n\nI hope this helps!!\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":10,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Run experiment crashes when using a pre-build Docker image as environment",
        "Question_creation_time":1654697991800,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/881670\/run-experiment-crashes-when-using-a-pre-build-dock.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I duplicated my question because I have not received a proper answer, yet.\nThe reason why I duplicated the question is that I need to implement something within Azure for a customer where I need to use a pre-build Docker image as an environment.\nUnfortunately, it is not working because AMLS cannot download the pre-build Docker image when you need credentials for downloading the pre-build Docker image.\nIn my opinion, the credentials for using the pre-build Docker image are not saved correctly in Azure Machine Learning Studio. This is the reason why AMLS cannot download the pre-build Docker image. I will be very grateful if someone can test the code snippets below and give me feedback if they worked or not.\n\nHere is the backstory:\nMy co-workers are using pre-build docker images for our developing environment in Azure Machine Learning Service.\nIn a separate script, they have registered these environments with the command myenv.register(workspace=ws). In another script, I should use their environment for testing our model.\n\nIn order to get one of their environments, I use the command registered_env = Environment.get(ws, 'the-specific-environment-name')\n\nUnfortunately, this does not work when I use registered_env for the experiment. I get the error \"Authentication failed for container registry name_of_their_container_registry.azurecr.io\". The experiment run works perfectly when I copy their environment definition code into my script instead of using the command registered_env = Environment.get(ws, 'the-specific-environment-name').\n\nHowever, I cannot copy every time their environment definition code into my script.\nHow can I get the environment into my script which has been defined in another script?\n\nThis StackOverFlow post is quite related to my problem:\nhttps:\/\/stackoverflow.com\/questions\/71131403\/registering-and-getting-an-environment-in-azure-machine-learning-studio-that-der\n\n\n\n\n\nTo illustrate what my problem is, here are some code samples.\n\nThis code sample is working:\n\n registry = ContainerRegistry()\n registry.address = <DockerRegistryAddress>\n registry.username = <UserName>\n registry.password = <Password>\n exemplarily_env_docker_image = Environment.from_docker_image('exemplarily-env_Docker-image-AzureRegistry', <DockerImageAddress>, container_registry=registry, conda_specification=None, pip_requirements=None)\n    \n exemplarily_env_docker_image.python.user_managed_dependencies = True\n    \n # Registering and getting of an environment that derives from a Docker Image is not working because the credentials are not saved\n exemplarily_env_docker_image.register(workspace=ws)\n model = Model(ws, 'exemplarily_model')\n    \n inference_config = InferenceConfig(environment=exemplarily_env_docker_image, \n                                    source_directory='.\/source_dir', \n                                    entry_script='.\/score.py') \n deployment_config = LocalWebservice.deploy_configuration(port=6789)\n    \n service = Model.deploy(\n     ws,\n     \"myservice\",\n     [model],\n     inference_config,\n     deployment_config,\n     overwrite=True,\n )\n    \n service.wait_for_deployment(show_output=True)\n print(service.get_logs())\n\n\n\n\nNow, I do a small change and the code sample is not working anymore:\n\n registry = ContainerRegistry()\n registry.address = <DockerRegistryAddress>\n registry.username = <UserName>\n registry.password = <Password>\n exemplarily_env_docker_image = Environment.from_docker_image('exemplarily-env_Docker-image-AzureRegistry', <DockerImageAddress>, container_registry=registry, conda_specification=None, pip_requirements=None)\n    \n exemplarily_env_docker_image.python.user_managed_dependencies = True\n # Registering and getting of an environment that derives from a Docker Image is not working because the credentials are not saved\n exemplarily_env_docker_image.register(workspace=ws)\n model = Model(ws, 'exemplarily_model')\n    \n reg_env = Environment.get(ws, \"exemplarily-env_Docker-image-AzureRegistry\")\n inference_config = InferenceConfig(environment=reg_env, \n                                    source_directory='.\/source_dir', \n                                    entry_script='.\/score.py') \n    \n deployment_config = LocalWebservice.deploy_configuration(port=6789)\n    \n service = Model.deploy(\n     ws,\n     \"myservice\",\n     [model],\n     inference_config,\n     deployment_config,\n     overwrite=True,\n )\n    \n service.wait_for_deployment(show_output=True)\n print(service.get_logs())\n\n\n\n\nWhat is working:\n\n registry = ContainerRegistry()\n registry.address = <DockerRegistryAddress>\n registry.username = <UserName>\n registry.password = <Password>\n exemplarily_env_docker_image = Environment.from_docker_image('exemplarily-env_Docker-image-AzureRegistry', <DockerImageAddress>, container_registry=registry, conda_specification=None, pip_requirements=None)\n    \n exemplarily_env_docker_image.python.user_managed_dependencies = True\n # Registering and getting of an environment that derives from a Docker Image is not working because the credentials are not saved\n exemplarily_env_docker_image.save_to_directory(path=\".\/env\", overwrite=True)\n model = Model(ws, 'exemplarily_model')\n    \n reg_env = Environment.load_from_directory(path=\".\/env\")\n inference_config = InferenceConfig(environment=reg_env, \n                                    source_directory='.\/source_dir', \n                                    entry_script='.\/score.py') \n    \n deployment_config = LocalWebservice.deploy_configuration(port=6789)\n    \n service = Model.deploy(\n     ws,\n     \"myservice\",\n     [model],\n     inference_config,\n     deployment_config,\n     overwrite=True,\n )\n    \n service.wait_for_deployment(show_output=True)\n print(service.get_logs())\n\n\n\n\nWhy is the middle code sample not working? Is this a bug?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"What is the difference between uri_file and uri_folder in components?",
        "Question_creation_time":1655434518570,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/892897\/what-is-the-difference-between-uri-file-and-uri-fo.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_follower_count":11,
        "Question_score":1,
        "Question_body":"What is the difference between uri_file and uri_folder in components?\n\nNo matter I specify uri_file or uri_folder in a component input\/output type, in Azure ML Studio jobs it is displayed as uri_folder and I still need to manually append a file name to the path derefernced by uri_file to access a single file. Is there any convenience or difference to specify uri_file if I only intend to access a single file?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-22T01:30:38.64Z",
                "Answer_score":1,
                "Answer_body":"Thanks.\nWe are planning for some smart deduction or inheriting the type from component to job runtime, we still have some open questions that need to close.\nAlso, we will add doc\/sample explicitly call out the default type in job level.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-06-20T01:10:08.487Z",
                "Answer_score":1,
                "Answer_body":"Hi @ramr-msft , I am using the YML spec as posted in #893075 Specifying input type as number in ComponentCommand and registing command with Python SDK v2 causes error:\n\nname: stock_pred_data_prep\ndisplay_name: Preprocess data for training\ndescription: reads raw price data, normalize and split the data\n# version: 1 # Not specifying a version will automatically update the version\ntype: command\ninputs:\n  data: {type: uri_folder}\n  test_ratio: {type: number}\n  window: {type: number}\noutputs:\n  scaler: {type: uri_file}\n  train_data_x: {type: uri_file}\n  train_data_y: {type: uri_file}\n  test_data_x: {type: uri_file}\n  test_data_y: {type: uri_file}\ncode: ..\/..\nenvironment:\n  azureml:tensorflow_sklean_cpu:1.0\ncommand: >-\n  PYTHONPATH=$PYTHONPATH:$(pwd) \n  PYTHONPATH=$PYTHONPATH:$(pwd)  python azure_pipeline\/preproc_data\/preproc_data.py \n      --data=${\n                 {inputs.data}} --test_ratio=${\n                 {inputs.test_ratio}} \n      --window=${\n                 {inputs.window}} \n      --scaler=${\n                 {outputs.scaler}} \n      --train_data_x=${\n                 {outputs.train_data_x}} --train_data_y=${\n                 {outputs.train_data_y}} \n      --test_data_x=${\n                 {outputs.test_data_x}} --test_data_y=${\n                 {outputs.test_data_y}}\n\n\n\n\n\nIn Azure ML Studtio, it is displayed correctly as uri_file:\n\n\nHowever, in Data asset, it is displayed as uri_folder, even though uri_file is said to be supported:\n\n\nAnd I need to save data by appending a filename to the input path like this, since the input path is considered a folder by Python:\n\nnp.save(os.path.join(args.train_data_x, 'x_train.npy'), xtrain)",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning - Deploy model with DockerFile",
        "Question_creation_time":1654794549783,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/883631\/azure-machine-learning-deploy-model-with-dockerfil.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":1,
        "Question_body":"Hi all,\n\nI'm trying to deploy a model with the azure-cli-ml with the following command:\n\naz ml model deploy --name local-test-endpoint --model name:version --compute-type local --ic inference_config.json --dc deployment_config_local.json -g rg --workspace-name amw\n\nwith the following inference configuration:\n\ninference_config.json\n\n\n\n {\n     \"entryScript\": \"score.py\",\n     \"environment\": {\n         \"docker\": {\n             \"arguments\": [],\n             \"baseDockerfile\": \"dockerFile\",\n             \"baseImage\": null,\n             \"enabled\": true,\n             \"sharedVolumes\": true,\n             \"shmSize\": \"2g\"\n         },\n         \"name\": \"test-environment\",\n         \"python\": {\n             \"baseCondaEnvironment\": null,\n             \"condaDependencies\": {\n                 \"channels\": [\n                     \"conda-forge\"\n                 ],\n                 \"dependencies\": [\n                     \"python=3.7\"\n                 ],\n                 \"name\": \"project_environment\"\n             },\n             \"condaDependenciesFile\": null,\n             \"interpreterPath\": \"python\",\n             \"userManagedDependencies\": false\n         },\n         \"version\": \"1\"\n     }\n }\n\n\n\n\nand this is the dockerFile:\n\n\n\n FROM pytorch\/pytorch:1.11.0-cuda11.3-cudnn8-runtime\n    \n RUN pip install \\\n     'azureml-mlflow==1.37.0' \\\n     'mlflow-skinny' \\\n     'pytorch-accelerated>=0.1.22' \\\n     'torchmetrics>=0.7.2' \\\n     'func_to_script' \\\n     'albumentations==1.1.0' \\\n     'pandas==1.3.4' \\\n     'matplotlib' \\\n     'sklearn'\n\n\n\nRunning the deploy command I get the following error message:\n\n\n\n\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\nfatal: not a git repository (or any parent up to mount point \/)\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\nunexpected dockerfile format\nfailed to run step ID: acb_step_0: failed to scan dependencies: exit status 1\n\nI get the same error even deploying to ACI and AKS.\nWhat am I doing wrong in the configuration?\n\nThanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-14T09:43:51.18Z",
                "Answer_score":1,
                "Answer_body":"@GCocci Thanks for the details. Can you please add more details about the version that you are using? environment creation in v1 requires you to provide the dockerfile INLINE, not as a reference. We highly recommend using v2.\n\n\"baseDockerfile\": \"dockerFile\",\n\nHere is the document to troubleshoot environment image builds.\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to change Sklearn flavors version in mlflow on azure machine learning?",
        "Question_creation_time":1655725906710,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/895819\/how-to-change-sklearn-flavors-version-in-mlflow-on.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":1,
        "Question_body":"I need to change the flavors \"sklearn_version\" in mlflow from \"0.22.1\" to \"1.0.0\" on azure machine learning when I log my trained model, since this model will be incompatible with the sklearn version that I am using for deployment during inference. I could change the version of conda by setting \"conda_env\" in\n\nmlflow.sklearn.log_model(conda_env= 'my_env')\n\n\n\n\nin the conda.yaml file, however it still remains unchanged in flavors in MLmodel file\n\nand here is script that I use to create this mlflow experiment in azure machine learning notebooks.\n\n import mlflow\n from sklearn.tree import DecisionTreeRegressor\n    \n from azureml.core import Workspace\n from azureml.core.model import Model\n from azureml.mlflow import register_model\n    \n    \n def run_model(ws, experiment_name, run_name, x_train, y_train):\n        \n     # set up MLflow to track the metrics\n     mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n     mlflow.set_experiment(experiment_name)  \n        \n     with mlflow.start_run(run_name=run_name) as run:\n            \n         # fit model\n         regression_model = DecisionTreeRegressor()\n         regression_model.fit(x_train, y_train)\n        \n         # log training score \n         training_score = regression_model.score(x_train, y_train)\n         mlflow.log_metric(\"Training score\", training_score)\n    \n         my_conda_env = {\n                     \"name\": \"mlflow-env\",\n                     \"channels\": [\"conda-forge\"],\n                     \"dependencies\": [\n                         \"python=3.8.5\",\n                         {\n                             \"pip\": [\n                                 \"pip\",\n                                 \"scikit-learn~=1.0.0\",\n                                 \"uuid==1.30\",\n                                 \"lz4==4.0.0\",\n                                 \"psutil==5.9.0\",\n                                 \"cloudpickle==1.6.0\",\n                                 \"mlflow\",\n                             ],\n                         },\n                     ],\n                 }\n    \n            \n         # register the model\n         mlflow.sklearn.log_model(regression_model, \"model\", conda_env=my_conda_env)\n    \n     model_uri = f\"runs:\/{run.info.run_id}\/model\"\n     model = mlflow.register_model(model_uri, \"sklearn_regression_model\")\n    \n if __name__ == '__main__':\n    \n     # connect to your workspace\n     ws = Workspace.from_config()\n    \n     # create experiment and start logging to a new run in the experiment\n     experiment_name = \"exp_name\"\n    \n     # mlflow run name\n     run_name= '1234'\n    \n      \n     # get train data\n     x_train, y_train  = get_train_data()\n        \n     run_model(ws, experiment_name, run_name, x_train, y_train)\n\n\n\nAny idea how can change the flavor sklearn version in \"MLmodel\" file in my script?\n\n\n\n\nWith many thanks in advance!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-21T10:43:01.38Z",
                "Answer_score":0,
                "Answer_body":"@SaeidHedayati-9187 Thanks for the question. Which version of Azure ML SDK are you using?. Here is the sample that could help to custom MLmodel.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-21T16:26:59.363Z",
                "Answer_score":1,
                "Answer_body":"Thanks for your response!! I was able to solve this issue by updating scikit-learn within my workspace. Mlflow MLmodel takes that version of scikit-learn to generate flavors. But I think your solution is also correct.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AzureML No Module Found Error on Deployment of Inference model: Xgboost",
        "Question_creation_time":1641912514007,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/690970\/azureml-no-module-found-error-on-deployment-of-inf.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"We're getting in an error in one environment deploying a ML endpoint with stating that xgboost cannot be found although it's included in the Dockerfile. We do not see this issue in 3 other environments and the model is able to deploy fine without this package error.\n\n\n\n\nDockerfile:\n\n FROM mcr.microsoft.com\/azureml\/openmpi3.1.2-cuda10.0-cudnn7-ubuntu16.04:20210220.v1\n USER root\n RUN mkdir -p \/etc\/OpenCL\/vendors && echo \"libnvidia-opencl.so.1\" > \/etc\/OpenCL\/vendors\/nvidia.icd\n RUN apt-get update && echo 'success updated apt-get!'\n RUN apt-get install -y --no-install-recommends cmake libboost-dev libboost-system-dev libboost-filesystem-dev\n RUN conda create -n gpuexp python=3.6.2 -y\n    \n ###############################\n # Pre-Build LightGBM\n ###############################\n RUN cd \/usr\/local\/src && mkdir lightgbm && cd lightgbm && \\\n     git clone --recursive --branch v2.3.0 --depth 1 https:\/\/github.com\/microsoft\/LightGBM && \\\n  cd LightGBM && mkdir build && cd build && \\\n  cmake -DUSE_GPU=1 -DOpenCL_LIBRARY=\/usr\/local\/cuda\/lib64\/libOpenCL.so -DOpenCL_INCLUDE_DIR=\/usr\/local\/cuda\/include\/ .. && \\\n  make -j4\n    \n ###############################\n # Install GPU LightGBM and XgBoost\n ###############################\n RUN \/bin\/bash -c \"source activate gpuexp && \\\n     cd \/usr\/local\/src\/lightgbm\/LightGBM\/python-package && python setup.py install --precompile && \\\n  pip install --upgrade --force-reinstall xgboost==1.1.1 && \\ \n  source deactivate\"\n\n\n\n\nConda:\n\n channels:\n   - anaconda\n   - conda-forge\n   - pytorch\n dependencies:\n   - python=3.6.2\n   - pip=20.2.4\n   - pip:\n       - azureml-core==1.27.0\n       - azureml-pipeline-core==1.27.0\n       - azureml-telemetry==1.27.0\n       - azureml-defaults==1.27.0\n       - azureml-interpret==1.27.0\n       - azureml-automl-core==1.27.0\n       - azureml-automl-runtime==1.27.0.post2\n       - azureml-train-automl-client==1.27.0\n       - azureml-train-automl-runtime==1.27.0.post1\n       - azureml-dataset-runtime==1.27.0\n       - azureml-mlflow==1.27.0\n       - inference-schema\n       - py-cpuinfo==5.0.0\n       - boto3==1.15.18\n       - botocore==1.18.18\n       - azure-storage-file-datalake\n       - azure-identity<1.5.0\n       - azure-keyvault\n       - azure-servicebus\n   - numpy~=1.18.0\n   - scikit-learn==0.22.1\n   - pandas~=0.25.0\n   - fbprophet==0.5\n   - holidays==0.9.11\n   - setuptools-git\n   - 'psutil>5.0.0,<6.0.0'\n\n\n\nI haven't included the name in the conda file intentionally.\n\nIs there something we're missing in the container set up for this issue that could cause it to fail for one environment and not the other?\n\nWe are able to see the model within our endpoints section in the Azure Machine Learning Studio, but this error is visible on the deployment logs and the endpoint is a Failed state.\n\nIn our three other environments, the endpoint is visible and in a healthy state.\n\nFull error message:\n\n     2022-01-11T19:46:08,279016451+00:00 - rsyslog\/run \n     2022-01-11T19:46:08,277445539+00:00 - gunicorn\/run \n     2022-01-11T19:46:08,280042359+00:00 - iot-server\/run \n     \/usr\/sbin\/nginx: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libcrypto.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n     2022-01-11T19:46:08,285741101+00:00 - nginx\/run \n     \/usr\/sbin\/nginx: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libcrypto.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n     \/usr\/sbin\/nginx: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libssl.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n     \/usr\/sbin\/nginx: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libssl.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n     \/usr\/sbin\/nginx: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libssl.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n     rsyslogd: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libuuid.so.1: no version information available (required by rsyslogd)\n     EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n     2022-01-11T19:46:08,407862719+00:00 - iot-server\/finish 1 0\n     2022-01-11T19:46:08,409832434+00:00 - Exit code 1 is normal. Not restarting iot-server.\n     Starting gunicorn 19.9.0\n     Listening at: http:\/\/127.0.0.1:31311 (11)\n     Using worker: sync\n     worker timeout is set to 300\n     Booting worker with pid: 37\n     SPARK_HOME not set. Skipping PySpark Initialization.\n     Generating new fontManager, this may take some time...\n     Initializing logger\n     2022-01-11 19:46:09,674 | root | INFO | Starting up app insights client\n     2022-01-11 19:46:09,675 | root | INFO | Starting up request id generator\n     2022-01-11 19:46:09,675 | root | INFO | Starting up app insight hooks\n     2022-01-11 19:46:09,675 | root | INFO | Invoking user's init function\n     Loading model from path.\n     2022-01-11 19:46:11,728 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n     Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n     2022-01-11 19:46:12,132 | root | ERROR | User's init function failed\n     2022-01-11 19:46:12,133 | root | ERROR | Encountered Exception Traceback (most recent call last):\n       File \"\/var\/azureml-server\/aml_blueprint.py\", line 182, in register\n         main.init()\n       File \"\/var\/azureml-app\/main.py\", line 35, in init\n         driver_module.init()\n       File \"\/structure\/azureml-app\/scripts\/inference\/score.py\", line 67, in init\n         raise e\n       File \"\/structure\/azureml-app\/scripts\/inference\/score.py\", line 64, in init\n         model = joblib.load(model_path)\n       File \"\/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/python3.6\/site-packages\/joblib\/numpy_pickle.py\", line 605, in load\n         obj = _unpickle(fobj, filename, mmap_mode)\n       File \"\/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/python3.6\/site-packages\/joblib\/numpy_pickle.py\", line 529, in _unpickle\n         obj = unpickler.load()\n       File \"\/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/python3.6\/pickle.py\", line 1050, in load\n         dispatch[key[0]](self)\n       File \"\/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/python3.6\/pickle.py\", line 1347, in load_stack_global\n         self.append(self.find_class(module, name))\n       File \"\/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/python3.6\/pickle.py\", line 1388, in find_class\n         __import__(module, level=0)\n     ModuleNotFoundError: No module named 'xgboost'\n        \n     2022-01-11 19:46:12,134 | root | INFO | Waiting for logs to be sent to Application Insights before exit.\n     2022-01-11 19:46:12,137 | root | INFO | Waiting 30 seconds for upload.\n     Worker exiting (pid: 37)\n     Shutting down: Master\n     Reason: Worker failed to boot.\n     2022-01-11T19:46:42,562394399+00:00 - gunicorn\/finish 3 0\n     2022-01-11T19:46:42,563843910+00:00 - Exit code 3 is not normal. Killing image.\n\n\n\nPartial deployment logs for a successfully deployed endpoint using the same pkl file:\n\n 2022-01-10T20:02:28,608154878+00:00 - rsyslog\/run \n 2022-01-10T20:02:28,608160978+00:00 - iot-server\/run \n 2022-01-10T20:02:28,609567614+00:00 - gunicorn\/run \n 2022-01-10T20:02:28,619823782+00:00 - nginx\/run \n \/usr\/sbin\/nginx: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libcrypto.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n \/usr\/sbin\/nginx: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libcrypto.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n \/usr\/sbin\/nginx: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libssl.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n \/usr\/sbin\/nginx: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libssl.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n \/usr\/sbin\/nginx: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libssl.so.1.0.0: no version information available (required by \/usr\/sbin\/nginx)\n rsyslogd: \/azureml-envs\/azureml_5ea1391fd04105b52a0d9fc3d6d367ac\/lib\/libuuid.so.1: no version information available (required by rsyslogd)\n EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n 2022-01-10T20:02:28,789369303+00:00 - iot-server\/finish 1 0\n 2022-01-10T20:02:28,791654562+00:00 - Exit code 1 is normal. Not restarting iot-server.\n Starting gunicorn 19.9.0\n Listening at: http:\/\/127.0.0.1:31311 (14)\n Using worker: sync\n worker timeout is set to 300\n Booting worker with pid: 40\n SPARK_HOME not set. Skipping PySpark Initialization.\n Generating new fontManager, this may take some time...\n Initializing logger\n 2022-01-10 20:02:30,434 | root | INFO | Starting up app insights client\n 2022-01-10 20:02:30,435 | root | INFO | Starting up request id generator\n 2022-01-10 20:02:30,435 | root | INFO | Starting up app insight hooks\n 2022-01-10 20:02:30,435 | root | INFO | Invoking user's init function\n Loading model from path.\n 2022-01-10 20:02:32,892 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n Model loaded succesfully.\n ManagedIdentityCredential will use IMDS\n\n\n\n\nI have tried utilizing py-xgboost in the Conda File and updating packages, however, I get the following error message:\n\n Traceback (most recent call last):\n   File \"\/var\/azureml-server\/aml_blueprint.py\", line 182, in register\n     main.init()\n   File \"\/var\/azureml-app\/main.py\", line 35, in init\n     driver_module.init()\n   File \"\/structure\/azureml-app\/scripts\/inference\/score.py\", line 67, in init\n     raise e\n   File \"\/structure\/azureml-app\/scripts\/inference\/score.py\", line 64, in init\n     model = joblib.load(model_path)\n   File \"\/azureml-envs\/azureml_a6a4caa8ade8fc5dac7282e2e275c022\/lib\/python3.6\/site-packages\/joblib\/numpy_pickle.py\", line 605, in load\n     obj = _unpickle(fobj, filename, mmap_mode)\n   File \"\/azureml-envs\/azureml_a6a4caa8ade8fc5dac7282e2e275c022\/lib\/python3.6\/site-packages\/joblib\/numpy_pickle.py\", line 529, in _unpickle\n     obj = unpickler.load()\n   File \"\/azureml-envs\/azureml_a6a4caa8ade8fc5dac7282e2e275c022\/lib\/python3.6\/pickle.py\", line 1050, in load\n     dispatch[key[0]](self)\n   File \"\/azureml-envs\/azureml_a6a4caa8ade8fc5dac7282e2e275c022\/lib\/python3.6\/pickle.py\", line 1347, in load_stack_global\n     self.append(self.find_class(module, name))\n   File \"\/azureml-envs\/azureml_a6a4caa8ade8fc5dac7282e2e275c022\/lib\/python3.6\/pickle.py\", line 1390, in find_class\n     return _getattribute(sys.modules[module], name)[0]\n   File \"\/azureml-envs\/azureml_a6a4caa8ade8fc5dac7282e2e275c022\/lib\/python3.6\/pickle.py\", line 272, in _getattribute\n     .format(name, obj))\n AttributeError: Can't get attribute 'XGBoostLabelEncoder' on <module 'xgboost.compat' from '\/azureml-envs\/azureml_a6a4caa8ade8fc5dac7282e2e275c022\/lib\/python3.6\/site-packages\/xgboost\/compat.py'>\n\n\n\n\nThe hyper parameters within the model created by Azure Auto ML include a XGBoost package from Azure ML:\n\n {\n     \"spec_class\": \"sklearn\",\n     \"class_name\": \"XGBoostClassifier\",\n     \"module\": \"automl.client.core.common.model_wrappers\",\n     \"param_args\": [],\n     \"param_kwargs\": {\n         \"tree_method\": \"auto\"\n     },\n     \"prepared_kwargs\": {}\n }",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Proxy Support on AML Compute Instance and Compute Clusters",
        "Question_creation_time":1655714307587,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/895509\/proxy-support-on-aml-compute-instance-and-compute.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Currently , AML CIs and Clusters do not support proxy configuration. So we are forced to use firewall for the outbound internet access. When we use a firewall using whitelist approach is best way however it is suitable for the AML CIs and CCs given the large number of URLs used by the Data scientist. The need of the hour is the proxy configuration support on the AML CIs and CCs. Can we have proxy support asap ?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How to install python package in hardware accelerated GPU spark pool ?",
        "Question_creation_time":1654683175267,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/881432\/how-to-install-python-package-in-hardware-accelera.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":16,
        "Question_score":0,
        "Question_body":"I've a azure synapse analytics workspace in region North Europe, as the region has hardware Accelerated pools, GPU base pools so to say. But i don't see the packages setting.\nhere is the comparison for 2 workspace, 1 in north Europe and other one in West Europe.\n vs \n\nEven the package setting in the Workspace itself is disabled for me: here is the screenshot.\n\n\nI've 2 questions in this reagrd:\n- Am I missing any configuration for the GPU pool or this feature is not released?\n- Is there any alternate way to install a package? pip install or pip3 install are not working.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-09T10:30:59.817Z",
                "Answer_score":1,
                "Answer_body":"Hello @PrateekNarula-5198,\n\nThanks for the question and using MS Q&A platform.\n\n(UPDATE:6\/10\/2022): Unfortunately, we do not have Library Management (Package) support for GPU spark pools in Azure Synapse Analytics.\n\nAs per the repro, I had noticed similar behaviour.\n\nLooks like packages are only supported for Node size family: \"Memory Optimized\" - let me get a confirmation from the product team.\n\nWe are reaching out to internal team to get more information related to this issue and will get back to you as soon as we have an update.\n\nHope this will help. Please let us know if any further queries.\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Is there any limitations for the number of runs per user in each experiment in Azure ML?",
        "Question_creation_time":1654530231357,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/878540\/is-there-any-limitations-for-the-number-of-runs-pe.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":22,
        "Question_score":0,
        "Question_body":"I and my team members are working on a machine learning project through the Azure ML portal. We have created a specific experiment in our workspace in Azure ML and are submitting our Python script runs from our local or remote machines in this experiment.\n\nAlthough I'm collaborating with my colleagues, most of the runs in this specific experiment are submitted by me.\n\nRecently, I have faced a problem with experiment submissions. The problem is that after some number of experiments created by me, I cannot add any other runs to this experiment, but my colleagues can!!!\n\nUnfortunately, the Azure ML portal does not show any clear error message for this problem. It continues submitting the run till a timeout exception occurs!\n\nAs a temporary solution, I've just changed the name of the experiment and I could conquer this problem.\n\nThis solution helped me to submit my run on Azure ML but it didn\u2019t satisfy me because. We want to collect all related runs under a specific experiment. On the other hand creating multiple number of experiments for each run is overwhelming!\n\nWhat I know is that there are some service limits for the number of runs in a workspace on this page. I am sure that the number of runs in our workspace has not reached to the 10 millions, because I can created new runs under new experiments dashboard. But I don\u2019t know anything about the limitations on the number of runs in a specific experiment or even any limitations for the number of runs per users in a specific experiment. I couldn't find any clear document explaining this fact.\n\nIs there anyone who can help me for this issue?\n\nI have also put myquestion in StackoverFlow. I would be grateful if you could help me with this issue.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Build Azure Bot",
        "Question_creation_time":1655232434093,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/889331\/build-azure-bot.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":21,
        "Question_score":0,
        "Question_body":"How I can build an Azure Bot from our hand book",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-14T20:49:15.733Z",
                "Answer_score":1,
                "Answer_body":"Hello @DhavalPatel-7263\n\nWelcome to Microsoft Q&A Platform,\n\nI'd suggest checking the links that you can find below as starting point:\n\nhttps:\/\/docs.microsoft.com\/en-us\/composer\/quickstart-create-bot-with-azure\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/bot-service\/bot-service-quickstart-create-bot?view=azure-bot-service-4.0&tabs=csharp%2Cvs\nhttps:\/\/m.youtube.com\/watch?v=ZIlLvKg7owM\n\nI hope this helps!\n\nPlease don\u2019t forget to \"Accept the answer\" and \u201cup-vote\u201d wherever the information provided helps you, this can be beneficial to other community members.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Why is my Hyperdrive step not completing even when the child jobs have completed?",
        "Question_creation_time":1655222646607,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/889157\/why-is-my-hyperdrive-step-not-completing-even-when.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi,\n\nWhat conditions need to be met to complete a HyperDriveStep in an Azure ML pipeline?\n\nContext:\nI'm trying to run a hyperparameter sweep in Azure ML using a pipeline with a HyperDriveStep (HDS) followed by a PythonScriptStep (PSS) . The HDS step has a singular child job of the Sweep type that runs successfully and completes, with a \"best_child_by_primary_metric\" metric logged (implying that a best model has been identified). However, the HDS keeps on running despite there being nothing else for it to do other than complete and trigger the PSS. The template I've followed is the one here, as recommended in the Azure ML documentation for the HyperDriveStep Class. There doesn't seem to be anything in the output logs either indicating some computational process is occurring, so I can't figure out what's keeping it idling.\n\nThanks in advance",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"VS-Code unable to connect to AML Instance",
        "Question_creation_time":1655366375100,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/891682\/vs-code-unable-to-connect-to-aml-instance.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi\n\nI have a compute instance on AML Studio. I downloaded the VS Code and trying to connect to compute instance . But it shows error \"Failed to connect to the remote extension host server (Error: WebSocket close with status code 1006)\" . AML Storage is Public Access. I am able to start the Compute instance but connect is not happening. Any workaround or solution?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-16T12:44:45.4Z",
                "Answer_score":0,
                "Answer_body":"@KrishnamohanNadimpalli-6337 Thanks for the question. Is the accounts same in Azure ML studio and Vs code?\n\nIn order to connect to your remote compute instance from Visual Studio Code, make sure that the account you're logged into in Azure Machine Learning studio is the same one you use in Visual Studio Code.\n\nWe are able to connect successfully, Here is link to the document to Connect to an Azure Machine Learning compute instance in Visual Studio Code.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure-ML>>ImportError: DLL load failed while importing win32file: The specified procedure could not be found.",
        "Question_creation_time":1648195247070,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/787222\/importerror-dll-load-failed-while-importing-win32f.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_follower_count":14,
        "Question_score":1,
        "Question_body":"I have been using the Azure ML python SDK and it has been working fine until I started getting this error:\n\"ImportError: DLL load failed while importing win32file: The specified procedure could not be found.\" when I tried to access my workspace\n\nI am using a conda virtual environment with Python 3.9 and I was running all my codes in a jupyter notebook on a windows computer.\n\nIt's been many hours now and I cannot find a solution. Can you help?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-31T12:51:13.093Z",
                "Answer_score":1,
                "Answer_body":"I had the same issue, but the fix here seems to have solved it.\n\nSpecifically:\n\n conda install pywin32",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Request help with Azure machine learning workspace",
        "Question_creation_time":1655371059130,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/891716\/request-help-with-azure-machine-learning-workspace.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":1,
        "Question_body":"I have enrolled myself in Azure Machine Learning course and the first step there is to create an azure ML workspace with subscription, resource group, region, storage account etc. I am a new joiner and I am doing this for my learning. Not sure which option to select. Is there any guidance or doc to follow? I have checked with my team and they are suggesting to use my personal account to get a demo account and free azure subscription to do the course and not my microsoft credentials. Require assistance in this regard.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-16T12:53:52.827Z",
                "Answer_score":0,
                "Answer_body":"@SanjanaDas-0274 Thanks for the question. Here is the document to Create workspace resources you need to get started with Azure Machine Learning. You can use your personal account to get free azure subscription.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/quickstart-create-resources\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Online deployment startup failed",
        "Question_creation_time":1655197807017,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/888458\/online-deployment-startup-failed.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":1,
        "Question_body":"Online deployment (locally) startup failed with this error message (full log is at the end):\n\nModuleNotFoundError: No module named 'sklearn'\n\n\n\n\nThe import is from this line of the train.py python script:\n\nfrom sklearn.preprocessing import StandardScaler\n\n\n\n\nBy running a local Docker container manually, this above import statement works if I activate the inf-conda-env conda environment, where scikit-learn>=1.0.2 as specified in my environment ile is installed.\n\nLooking into the full logs, it seems that the container is using the amlenv conda environment instead when this error happends. I could not change the actual environment where scikit-learn is installed by changing the name within both the environment YML file and the deployment YML file. This dependent package is always installed in inf-conda-env and the inference server is always run in amlenv.\n\nenv_azure.yml:\n\nname: myenv\ndependencies:\n  - python=3.7\n  - pip:\n    - scikit-learn>=1.0.2\n\n\n\n\nblue-deployment.yml:\n\n$schema: https:\/\/azuremlschemas.azureedge.net\/latest\/managedOnlineDeployment.schema.json\nname: blue\nendpoint_name: george-mlops-endpoint\nmodel: azureml:stock-pred-lstm:2\ncode_configuration:\n  code: ..\/\n  scoring_script: score_azure.py\nenvironment:\n  name: myenv\n  conda_file: ..\/env_azure.yml\n  image: mcr.microsoft.com\/azureml\/tensorflow-2.4-ubuntu18.04-py37-cpu-inference:latest\ninstance_type: Standard_D2as_v4\ninstance_count: 1\n\n\n\n\n\n\nfull log:\n\n$ az ml online-deployment get-logs -n blue -e $ENDPOINT_NAME_2 --local\n2022-06-14T08:54:05,693704187+00:00 - gunicorn\/run \n2022-06-14T08:54:05,695924060+00:00 | gunicorn\/run | \n2022-06-14T08:54:05,698181633+00:00 | gunicorn\/run | ###############################################\n2022-06-14T08:54:05,701762750+00:00 | gunicorn\/run | AzureML Container Runtime Information\n2022-06-14T08:54:05,702955089+00:00 | gunicorn\/run | ###############################################\n2022-06-14T08:54:05,704188929+00:00 | gunicorn\/run | \n2022-06-14T08:54:05,705658377+00:00 | gunicorn\/run | \n2022-06-14T08:54:05,707062223+00:00 - rsyslog\/run \n2022-06-14T08:54:05,710995351+00:00 - nginx\/run \n2022-06-14T08:54:05,714649671+00:00 | gunicorn\/run | AzureML image information: tensorflow-2.4-ubuntu18.04-py37-cpu-inference:20220516.v10\nnginx: [warn] the \"user\" directive makes sense only if the master process runs with super-user privileges, ignored in \/etc\/nginx\/nginx.conf:1\n2022-06-14T08:54:05,721274687+00:00 | gunicorn\/run | \n2022-06-14T08:54:05,722691033+00:00 | gunicorn\/run | \n2022-06-14T08:54:05,723795369+00:00 | gunicorn\/run | PATH environment variable: \/opt\/miniconda\/envs\/inf-conda-env\/bin:\/opt\/miniconda\/condabin:\/opt\/miniconda\/envs\/amlenv\/bin:\/opt\/miniconda\/bin:\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin\n2022-06-14T08:54:05,724812902+00:00 | gunicorn\/run | PYTHONPATH environment variable: \n2022-06-14T08:54:05,726167546+00:00 | gunicorn\/run | \n2022-06-14T08:54:05,727421387+00:00 | gunicorn\/run | Pip Dependencies (before dynamic installation)\ncertifi==2022.5.18.1\njoblib==1.1.0\nnumpy==1.21.6\nscikit-learn==1.0.2\nscipy==1.7.3\nthreadpoolctl==3.1.0\n2022-06-14T08:54:05,972350679+00:00 | gunicorn\/run | \n2022-06-14T08:54:05,973666822+00:00 | gunicorn\/run | Entry script directory: \/var\/azureml-app\/stock-pred\/\/.\n2022-06-14T08:54:05,974753257+00:00 | gunicorn\/run | \n2022-06-14T08:54:05,975907695+00:00 | gunicorn\/run | ###############################################\n2022-06-14T08:54:05,977260339+00:00 | gunicorn\/run | Dynamic Python Package Installation\n2022-06-14T08:54:05,978331974+00:00 | gunicorn\/run | ###############################################\n2022-06-14T08:54:05,979721920+00:00 | gunicorn\/run | \n2022-06-14T08:54:05,981003161+00:00 | gunicorn\/run | Dynamic Python package installation is disabled.\n2022-06-14T08:54:05,982319204+00:00 | gunicorn\/run | \n2022-06-14T08:54:05,983685849+00:00 | gunicorn\/run | ###############################################\n2022-06-14T08:54:05,984905389+00:00 | gunicorn\/run | AzureML Inference Server\n2022-06-14T08:54:05,986270433+00:00 | gunicorn\/run | ###############################################\n2022-06-14T08:54:05,987434371+00:00 | gunicorn\/run | \n2022-06-14T08:54:06,001278423+00:00 | gunicorn\/run | Starting AzureML Inference Server HTTP.\nAzure ML Inferencing HTTP server v0.6.1\nServer Settings\n---------------\nEntry Script Name: score_azure.py\nModel Directory: \/var\/azureml-app\/azureml-models\/\/stock-pred-lstm\/2\nWorker Count: 1\nWorker Timeout (seconds): 300\nServer Port: 31311\nApplication Insights Enabled: false\nApplication Insights Key: None\nInferencing HTTP server version: azmlinfsrv\/0.6.1\nServer Routes\n---------------\nLiveness Probe: GET   127.0.0.1:31311\/\nScore:          POST  127.0.0.1:31311\/score\nStarting gunicorn 20.1.0\nListening at: http:\/\/0.0.0.0:31311 (26)\nUsing worker: sync\nBooting worker with pid: 69\nException in worker process\nTraceback (most recent call last):\n  File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py\", line 589, in spawn_worker\n    worker.init_process()\n  File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 134, in init_process\n    self.load_wsgi()\n  File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 146, in load_wsgi\n    self.wsgi = self.app.wsgi()\n  File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py\", line 67, in wsgi\n    self.callable = self.load()\n  File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 58, in load\n    return self.load_wsgiapp()\n  File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 48, in load_wsgiapp\n    return util.import_app(self.app_uri)\n  File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/util.py\", line 359, in import_app\n    mod = importlib.import_module(module)\n  File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/importlib\/__init__.py\", line 127, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n  File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/azureml_inference_server_http\/server\/entry.py\", line 1, in <module>\n    import create_app\n  File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/azureml_inference_server_http\/server\/create_app.py\", line 24, in <module>\n    from routes import main\n  File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/azureml_inference_server_http\/server\/routes.py\", line 39, in <module>\n    from aml_blueprint import AMLBlueprint\n  File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/azureml_inference_server_http\/server\/aml_blueprint.py\", line 33, in <module>\n    main_module_spec.loader.exec_module(main)\n  File \"\/var\/azureml-app\/stock-pred\/score_azure.py\", line 7, in <module>\n    from train import load_data, load_model, load_scaler, extract_x_y\n  File \"\/var\/azureml-app\/stock-pred\/train.py\", line 5, in <module>\n    from sklearn.preprocessing import StandardScaler\nModuleNotFoundError: No module named 'sklearn'\nWorker exiting (pid: 69)\nShutting down: Master\nReason: Worker failed to boot.\n2022-06-14T08:54:07,134158894+00:00 - gunicorn\/finish 3 0\n2022-06-14T08:54:07,135337927+00:00 - Exit code 3 is not normal. Killing image.\nERROR conda.cli.main_run:execute(34): Subprocess for 'conda run ['runsvdir', '\/var\/runit']' command failed.  (See above for error)\n2022-06-14T08:54:07,141403097+00:00 - rsyslog\/finish 0 0\n2022-06-14T08:54:07,143002342+00:00 - Exit code 0 is not normal. Restarting rsyslog.\n2022-06-14T08:54:07,153991050+00:00 - nginx\/finish 0 0\n2022-06-14T08:54:07,156038707+00:00 - Exit code 0 is not normal. Killing image.\nrunsvdir: no process found",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-15T07:45:10.197Z",
                "Answer_score":1,
                "Answer_body":"After a few more tries today, I found the problem stemed from the use of the mcr.microsoft.com\/azureml\/tensorflow-2.4-ubuntu18.04-py37-cpu-inference image. When I replace it with a base image mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04:latest and modify the related YML files, it works finally!\n\nI thought the documentation should explicitly mention that curated images are not meant for user extension.\n\nupdated blue-deployment.yml:\n\n$schema: https:\/\/azuremlschemas.azureedge.net\/latest\/managedOnlineDeployment.schema.json\nname: blue\nendpoint_name: george-mlops-endpoint\nmodel: azureml:stock-pred-lstm:2\ncode_configuration:\n  code: ..\/\n  scoring_script: score_azure.py\nenvironment:\n  conda_file: ..\/env_azure.yml\n  image: mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04:latest\ninstance_type: Standard_D2as_v4\ninstance_count: 1\n\n\n\n\nupdated env_azure.yml:\n\nname: model-env\nchannels:\n  - conda-forge\ndependencies:\n  # flask 1.1.* is needed by azureml inference server\n  - flask=1.1.4\n  - python=3.8\n  - pip=21.2.4\n  - scikit-learn>=1.0.2\n  - tensorflow==2.8.0\n  - pip:\n    - inference-schema[numpy-support]==1.3.0\n    - mlflow== 1.26.0\n    - azureml-mlflow==1.41.0\n    - opencensus-ext-azure==1.1.4",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Getting error while translating document using Azure translator - \"Cannot access source document location with the current permissions\" InvalidRequest",
        "Question_creation_time":1635709097990,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/610532\/getting-error-while-translating-document-using-azu.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":14,
        "Question_score":1,
        "Question_body":"I am using translator resource to translate the one document at a time from the source container through python code.\n\nFollowing the documentation, generated the container level SAS for existing containers.\n\nTried different combinations of request body formats to meet the requirement of translating the single file from source container using \"Container level SAS\".\n\nI was able to translate various documents but suddenly the python code is failing with the error -\n{ 'status': 'ValidationFailed', 'error': {'code': 'InvalidRequest', 'message': 'Cannot access source document location with the current permissions.', 'target': 'Operation', 'innerError': {'code': 'InvalidDocumentAccessLevel', 'message': 'Cannot access source document location with the current permissions.'}\u200b}, 'summary': {'total': 0, 'failed': 0, 'success': 0, 'inProgress': 0, 'notYetStarted': 0, 'cancelled': 0, 'totalCharacterCharged': 0}\u200b}\n\nWhen same request bodies are tried for newly created containers, documents are translating successfully.\nDoes existing containers gives this issue sometimes and we should always use the newly created containers?\n\nOld container's SAS urls are generated with appropriate permissions i.e. Read,list for source and Write.List for Target container.\n\nPlease suggest me the correct way.\n\nAlso attaching the different request body formats I am using to take single file at a time using \"Container level SAS\"\n\nSpecifying the file name in source url and target url\n\n    {\n                 \"inputs\": [\n                     {\n                         \"storageType\": \"File\",\n                         \"source\": {\n                             \"sourceUrl\": \"https:\/\/myblob.blob.core.windows.net\/src_container\/file.docx?<SAS>\"\n                         },\n                         \"targets\": [\n                             {   \n                        \"targetUrl\":\"https:\/myblob.blob.core.windows.net\/container\/<target_blob_name_without_any_extension>? \n                            <SAS>\",\n                                 \"language\": \"fr\"\n                             }\n                         ]\n                     }\n                 ]\n             }\n\n\n\nSpecifying the file name as suffix in the source\n\n {\n         \"inputs\": [\n             {\n                \n                 \"source\": {\n                     \"sourceUrl\": \"https:\/\/myblob.blob.core.windows.net\/src_container\/file.docx?<SAS>\",\n \"suffix\":\"file.docx\"\n                 },\n                 \"targets\": [\n                     {\n                            \n                \"targetUrl\":\"https:\/myblob.blob.core.windows.net\/container\/<target_blob_name_without_any_extension>? \n                    <SAS>\",\n                         \"language\": \"fr\"\n                     }\n                 ]\n             }\n         ]\n     }\n\n\n\nWhich is the correct way of achieving the use case using \"Container level SAS\".\nAm I doing something wrong in request body ?\nQuick help is needed. Can anyone guide me please?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-01T22:15:30.413Z",
                "Answer_score":1,
                "Answer_body":"Hi, please follow the instructions for Document Translation using the Python Client Library. Here's another sample. Based on the error message, I recommend that you generate a new SAS token and pay close attention to the Start and Expiry date and time.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is it possible to connect Azure ML studio to Visual Studio?",
        "Question_creation_time":1655215688467,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/888888\/is-it-possible-to-connect-azure-ml-studio-to-visua.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Is it possible to connect a model from Azure ML studio to Visual Studio in order to create an user-interactive front-end for the model?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-15T01:34:09.553Z",
                "Answer_score":0,
                "Answer_body":"Hello @JonathanSrinivasan-3957\n\nThanks for reaching out to us, for now, we are not supporting this feature.\n\nBut this feature sounds interesting, if you are willing to share more details, I would like to forward it to the pm for future roadmap.\n\nI hope this helps!\n\nRegards,\nYutong\n\n\n\n\n-Please kindly accept the answer if you feel helpful to help the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How should I create a scoring script for object detection (pytorch) in Azure ML?",
        "Question_creation_time":1655225088730,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/889212\/how-should-i-create-a-scoring-script-for-object-de.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hi there,\n\nI have trained a PyTorch vision model on a local computer for object detection and want to deploy it on Azure ML. I have found a similar script for classification using pytorch where they are using the following scoring script. link: https:\/\/github.com\/Azure\/MachineLearningNotebooks\/tree\/master\/how-to-use-azureml\/ml-frameworks\/pytorch\/train-hyperparameter-tune-deploy-with-pytorch\n\n # Copyright (c) Microsoft. All rights reserved.\n # Licensed under the MIT license.\n import os\n import torch\n import torch.nn as nn\n from torchvision import transforms\n import json\n from azureml.core.model import Model\n def init():\n     global model\n     # AZUREML_MODEL_DIR is an environment variable created during deployment.\n     # It is the path to the model folder (.\/azureml-models\/$MODEL_NAME\/$VERSION)\n     # For multiple models, it points to the folder containing all deployed models (.\/azureml-models)\n     model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.pt')\n     model = torch.load(model_path, map_location=lambda storage, loc: storage)\n     model.eval()\n def run(input_data):\n     input_data = torch.tensor(json.loads(input_data)['data'])\n     # get prediction\n     with torch.no_grad():\n         output = model(input_data)\n         classes = ['chicken', 'turkey']\n         softmax = nn.Softmax(dim=1)\n         pred_probs = softmax(output).numpy()[0]\n         index = torch.argmax(output, 1)\n     result = {\"label\": classes[index], \"probability\": str(pred_probs[index])}\n     return result\n\n\n\nI have a few questions regarding this script. I am wondering what is 'input_data' in this case, is it an image in jpg format?\nAlso can my 'result' be in any dict format or it should have a specific format?\n\nI have written a similar script for my purpose.\n\n # Copyright (c) Microsoft. All rights reserved.\n # Licensed under the MIT license.\n import os\n import torch\n import torchvision\n #import torch.nn as nn\n from torchvision import transforms\n import json\n import cv2\n from azureml.core.model import Model\n import numpy as np\n from PIL import Image\n import os\n def init():\n     global model\n     # AZUREML_MODEL_DIR is an environment variable created during deployment.\n     # It is the path to the model folder (.\/azureml-models\/$MODEL_NAME\/$VERSION)\n     # For multiple models, it points to the folder containing all deployed models (.\/azureml-models)\n     # model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.pt')\n     # model = torch.load(model_path, map_location=lambda storage, loc: storage)\n     # #model_path = Model.get_model_path(model_name='pytorch_external_model-test')\n     # model = torch.load(model_path)\n     model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'),'model.pt')\n     model = torch.load(model_path, map_location=lambda storage, loc: storage)\n     #model = torch.load(model_path)\n     model.eval()\n # the function takes the original prediction and the iou threshold.\n def apply_nms(orig_prediction, iou_thresh=0.3):\n # torchvision returns the indices of the bboxes to keep\n keep = torchvision.ops.nms(orig_prediction['boxes'], orig_prediction['scores'], iou_thresh)\n    \n final_prediction = orig_prediction\n #print(final_prediction['boxes'])\n final_prediction['boxes'] = final_prediction['boxes'][keep].cpu() # had to add .cpu() after each tensor \n final_prediction['scores'] = final_prediction['scores'][keep].cpu() \n final_prediction['labels'] = final_prediction['labels'][keep].cpu() \n return final_prediction\n # def preprocess(input_data): # doesn't convert to tensor, while input for prediction needs to be in tensor\n #     img = cv2.imread(input_data)\n #     img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n #     img_res = cv2.resize(img_rgb, (704, 480), cv2.INTER_AREA)\n #     # diving by 255\n #     img_res \/= 255.0\n #     return img_res\n def run(input_data):\n     img = Image.open(input_data).convert('RGB')\n     # set up transformation to resize the image\n     resize = transforms.Resize([704, 480])\n     img = resize(img)\n     to_tensor = transforms.ToTensor()\n     # apply transformation and convert to Pytorch tensor\n     tensor = to_tensor(img) # output shape [3, 704, 480] \n     #tensor = tensor.unsqueeze(0) # no need for [1, 3, 704, 480]\n     # link for converting image to tensor https:\/\/towardsdatascience.com\/convert-images-to-tensors-in-pytorch-and-tensorflow-f0ab01383a03\n     #input_data = torch.tensor(json.loads(input_data)['data'])\n     #image = preprocess(input_data)\n     device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n     with torch.no_grad():\n         prediction = model([tensor.to(device)])[0]\n     nms_prediction = apply_nms(prediction, iou_thresh=0.3)\n     result = {\"label\": nms_prediction['labels'], \"box\": nms_prediction['boxes'], \"score\": nms_prediction['scores']}\n     return result\n\nI followed this colab tutorial for training the object detection model. I am not using any transform to make the problem easy for now.\nhttps:\/\/colab.research.google.com\/drive\/1NziO_b-SW9KmWFh-6C8to9H_QAdpmCBZ?usp=sharing#scrollTo=WOrNovPGh_k6\n\nModel is deployed successfully. But getting this error\n\nprint(service.get_logs())\n\n \/bin\/bash: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)\n \/bin\/bash: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)\n \/bin\/bash: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)\n \/bin\/bash: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)\n 2022-06-15T00:14:38,162168400+00:00 - gunicorn\/run \n 2022-06-15T00:14:38,166094000+00:00 - rsyslog\/run \n 2022-06-15T00:14:38,171921600+00:00 - iot-server\/run \n bash: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/libtinfo.so.5: no version information available (required by bash)\n 2022-06-15T00:14:38,190831400+00:00 | gunicorn\/run | \n 2022-06-15T00:14:38,197941200+00:00 | gunicorn\/run | ###############################################\n 2022-06-15T00:14:38,242881800+00:00 | gunicorn\/run | AzureML Container Runtime Information\n 2022-06-15T00:14:38,300863500+00:00 | gunicorn\/run | ###############################################\n 2022-06-15T00:14:38,351919200+00:00 - nginx\/run \n 2022-06-15T00:14:38,377608200+00:00 | gunicorn\/run | \n 2022-06-15T00:14:38,413561500+00:00 | gunicorn\/run | \n 2022-06-15T00:14:38,436442300+00:00 | gunicorn\/run | PATH environment variable: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/bin:\/opt\/miniconda\/bin:\/usr\/local\/nvidia\/bin:\/usr\/local\/cuda\/bin:\/usr\/local\/sbin:\/usr\/local\/bin:\/usr\/sbin:\/usr\/bin:\/sbin:\/bin\n 2022-06-15T00:14:38,472313100+00:00 | gunicorn\/run | PYTHONPATH environment variable: \n 2022-06-15T00:14:38,478958600+00:00 | gunicorn\/run | \n 2022-06-15T00:14:38,501877400+00:00 | gunicorn\/run | Pip Dependencies (before dynamic installation)\n EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n \/bin\/bash: \/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/libtinfo.so.5: no version information available (required by \/bin\/bash)\n 2022-06-15T00:14:38,787582000+00:00 - iot-server\/finish 1 0\n 2022-06-15T00:14:38,793119200+00:00 - Exit code 1 is normal. Not restarting iot-server.\n adal==1.2.7\n albumentations==0.4.6\n applicationinsights==0.11.10\n argcomplete==2.0.0\n attrs==21.4.0\n azure-common==1.1.28\n azure-core==1.22.1\n azure-graphrbac==0.61.1\n azure-identity==1.7.0\n azure-mgmt-authorization==2.0.0\n azure-mgmt-containerregistry==9.1.0\n azure-mgmt-core==1.3.0\n azure-mgmt-keyvault==9.3.0\n azure-mgmt-resource==21.0.0\n azure-mgmt-storage==20.0.0\n azureml-core==1.42.0.post1\n azureml-dataprep==4.0.3\n azureml-dataprep-native==38.0.0\n azureml-dataprep-rslex==2.6.3\n azureml-dataset-runtime==1.42.0\n azureml-defaults==1.42.0\n azureml-inference-server-http==0.4.13\n backports.tempfile==1.0\n backports.weakref==1.0.post1\n bcrypt==3.2.2\n cachetools==4.2.4\n certifi==2022.5.18.1\n cffi==1.15.0\n charset-normalizer==2.0.12\n click==7.1.2\n cloudpickle==2.1.0\n configparser==3.7.4\n contextlib2==21.6.0\n contextvars==2.4\n cryptography==36.0.2\n cycler==0.11.0\n dataclasses==0.8\n decorator==4.4.2\n distro==1.7.0\n docker==5.0.3\n dotnetcore2==3.1.23\n Flask==1.0.3\n fusepy==3.0.1\n future==0.18.2\n google-api-core==2.8.1\n google-auth==2.8.0\n googleapis-common-protos==1.56.2\n gunicorn==20.1.0\n humanfriendly==10.0\n idna==3.3\n imageio==2.15.0\n imgaug==0.4.0\n immutables==0.18\n importlib-metadata==4.8.3\n inference-schema==1.3.0\n isodate==0.6.1\n itsdangerous==1.1.0\n jeepney==0.7.1\n Jinja2==3.0.3\n jmespath==0.10.0\n json-logging-py==0.2\n jsonpickle==2.2.0\n jsonschema==3.2.0\n kiwisolver==1.3.1\n knack==0.9.0\n MarkupSafe==2.0.1\n matplotlib==3.3.4\n msal==1.18.0\n msal-extensions==0.3.1\n msrest==0.6.21\n msrestazure==0.6.4\n ndg-httpsclient==0.5.1\n networkx==2.5.1\n numpy==1.19.5\n oauthlib==3.2.0\n opencensus==0.9.0\n opencensus-context==0.1.2\n opencensus-ext-azure==1.1.4\n opencv-python==4.6.0.66\n opencv-python-headless==4.6.0.66\n packaging==21.3\n paramiko==2.11.0\n pathspec==0.9.0\n Pillow==8.4.0\n pkginfo==1.8.3\n portalocker==2.4.0\n protobuf==3.19.4\n psutil==5.9.1\n pyarrow==3.0.0\n pyasn1==0.4.8\n pyasn1-modules==0.2.8\n pycocotools==2.0.4\n pycparser==2.21\n Pygments==2.12.0\n PyJWT==2.4.0\n PyNaCl==1.5.0\n pyOpenSSL==22.0.0\n pyparsing==3.0.7\n pyrsistent==0.18.0\n PySocks==1.7.1\n python-dateutil==2.8.2\n pytz==2022.1\n PyWavelets==1.1.1\n PyYAML==6.0\n requests==2.27.1\n requests-oauthlib==1.3.1\n rsa==4.8\n scikit-image==0.17.2\n scipy==1.5.4\n SecretStorage==3.3.2\n Shapely==1.8.2\n six==1.16.0\n tabulate==0.8.9\n tifffile==2020.9.3\n torch==1.10.1\n torchvision==0.11.2\n typing_extensions==4.1.1\n urllib3==1.26.9\n websocket-client==1.3.1\n Werkzeug==1.0.1\n wrapt==1.12.1\n zipp==3.6.0\n 2022-06-15T00:14:40,561943700+00:00 | gunicorn\/run | \n 2022-06-15T00:14:40,563774900+00:00 | gunicorn\/run | ###############################################\n 2022-06-15T00:14:40,569936200+00:00 | gunicorn\/run | AzureML Inference Server\n 2022-06-15T00:14:40,571682900+00:00 | gunicorn\/run | ###############################################\n 2022-06-15T00:14:40,573373400+00:00 | gunicorn\/run | \n 2022-06-15T00:14:40,580170100+00:00 | gunicorn\/run | \n 2022-06-15T00:14:40,584523000+00:00 | gunicorn\/run | Starting HTTP server\n 2022-06-15T00:14:40,590038900+00:00 | gunicorn\/run | \n Starting gunicorn 20.1.0\n Listening at: http:\/\/127.0.0.1:31311 (77)\n Using worker: sync\n worker timeout is set to 300\n Booting worker with pid: 125\n SPARK_HOME not set. Skipping PySpark Initialization.\n Initializing logger\n 2022-06-15 00:14:45,845 | root | INFO | Starting up app insights client\n logging socket was found. logging is available.\n logging socket was found. logging is available.\n 2022-06-15 00:14:45,846 | root | INFO | Starting up request id generator\n 2022-06-15 00:14:45,846 | root | INFO | Starting up app insight hooks\n 2022-06-15 00:14:45,847 | root | INFO | Invoking user's init function\n 2022-06-15 00:14:46,111 | root | INFO | Users's init has completed successfully\n 2022-06-15 00:14:46,115 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n 2022-06-15 00:14:46,116 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n 2022-06-15 00:14:46,121 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n 2022-06-15 00:14:49,997 | root | INFO | Swagger file not present\n 2022-06-15 00:14:49,998 | root | INFO | 404\n 127.0.0.1 - - [15\/Jun\/2022:00:14:49 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"Go-http-client\/1.1\"\n 2022-06-15 00:14:54,621 | root | INFO | Swagger file not present\n 2022-06-15 00:14:54,622 | root | INFO | 404\n 127.0.0.1 - - [15\/Jun\/2022:00:14:54 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"Go-http-client\/1.1\"\n 2022-06-15 00:14:54,974 | root | INFO | Scoring Timer is set to 60.0 seconds\n 2022-06-15 00:14:54,979 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n File \"\/var\/azureml-server\/routes.py\", line 294, in run_scoring\n     response, time_taken_ms = invoke_user_with_timer(service_input, request_headers)\n File \"\/var\/azureml-server\/routes.py\", line 341, in invoke_user_with_timer\n     result, time_taken_ms = capture_time_taken(user_main.run)(**params)\n File \"\/var\/azureml-server\/routes.py\", line 322, in timer\n     result = func(*args, **kwargs)\n File \"\/var\/azureml-app\/score2.py\", line 57, in run\n     img = Image.open(input_data).convert('RGB')\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/PIL\/Image.py\", line 2975, in open\n     fp = builtins.open(filename, \"rb\")\n FileNotFoundError: [Errno 2] No such file or directory: 'test_img.jpg'\n During handling of the above exception, another exception occurred:\n Traceback (most recent call last):\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1832, in full_dispatch_request\n     rv = self.dispatch_request()\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1818, in dispatch_request\n     return self.view_functions[rule.endpoint](**req.view_args)\n File \"\/var\/azureml-server\/routes.py\", line 270, in score_realtime\n     service_input, request.headers, request.environ.get(\"REQUEST_ID\", \"00000000-0000-0000-0000-000000000000\")\n File \"\/var\/azureml-server\/routes.py\", line 303, in run_scoring\n     raise RunFunctionException(str(exc))\n run_function_exception.RunFunctionException\n 2022-06-15 00:14:54,979 | root | INFO | 500\n 127.0.0.1 - - [15\/Jun\/2022:00:14:54 +0000] \"POST \/score HTTP\/1.0\" 500 51 \"-\" \"python-requests\/2.26.0\"\n 2022-06-15 00:14:54,988 | root | INFO | Scoring Timer is set to 60.0 seconds\n 2022-06-15 00:14:54,988 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n File \"\/var\/azureml-server\/routes.py\", line 294, in run_scoring\n     response, time_taken_ms = invoke_user_with_timer(service_input, request_headers)\n File \"\/var\/azureml-server\/routes.py\", line 341, in invoke_user_with_timer\n     result, time_taken_ms = capture_time_taken(user_main.run)(**params)\n File \"\/var\/azureml-server\/routes.py\", line 322, in timer\n     result = func(*args, **kwargs)\n File \"\/var\/azureml-app\/score2.py\", line 57, in run\n     img = Image.open(input_data).convert('RGB')\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/PIL\/Image.py\", line 2975, in open\n     fp = builtins.open(filename, \"rb\")\n FileNotFoundError: [Errno 2] No such file or directory: 'test_img.jpg'\n During handling of the above exception, another exception occurred:\n Traceback (most recent call last):\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1832, in full_dispatch_request\n     rv = self.dispatch_request()\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1818, in dispatch_request\n     return self.view_functions[rule.endpoint](**req.view_args)\n File \"\/var\/azureml-server\/routes.py\", line 270, in score_realtime\n     service_input, request.headers, request.environ.get(\"REQUEST_ID\", \"00000000-0000-0000-0000-000000000000\")\n File \"\/var\/azureml-server\/routes.py\", line 303, in run_scoring\n     raise RunFunctionException(str(exc))\n run_function_exception.RunFunctionException\n 2022-06-15 00:14:54,988 | root | INFO | 500\n 127.0.0.1 - - [15\/Jun\/2022:00:14:54 +0000] \"POST \/score HTTP\/1.0\" 500 51 \"-\" \"python-requests\/2.26.0\"\n 2022-06-15 00:14:56,004 | root | INFO | Scoring Timer is set to 60.0 seconds\n 2022-06-15 00:14:56,005 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n File \"\/var\/azureml-server\/routes.py\", line 294, in run_scoring\n     response, time_taken_ms = invoke_user_with_timer(service_input, request_headers)\n File \"\/var\/azureml-server\/routes.py\", line 341, in invoke_user_with_timer\n     result, time_taken_ms = capture_time_taken(user_main.run)(**params)\n File \"\/var\/azureml-server\/routes.py\", line 322, in timer\n     result = func(*args, **kwargs)\n File \"\/var\/azureml-app\/score2.py\", line 57, in run\n     img = Image.open(input_data).convert('RGB')\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/PIL\/Image.py\", line 2975, in open\n     fp = builtins.open(filename, \"rb\")\n FileNotFoundError: [Errno 2] No such file or directory: 'test_img.jpg'\n During handling of the above exception, another exception occurred:\n Traceback (most recent call last):\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1832, in full_dispatch_request\n     rv = self.dispatch_request()\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1818, in dispatch_request\n     return self.view_functions[rule.endpoint](**req.view_args)\n File \"\/var\/azureml-server\/routes.py\", line 270, in score_realtime\n     service_input, request.headers, request.environ.get(\"REQUEST_ID\", \"00000000-0000-0000-0000-000000000000\")\n File \"\/var\/azureml-server\/routes.py\", line 303, in run_scoring\n     raise RunFunctionException(str(exc))\n run_function_exception.RunFunctionException\n 2022-06-15 00:14:56,005 | root | INFO | 500\n 127.0.0.1 - - [15\/Jun\/2022:00:14:56 +0000] \"POST \/score HTTP\/1.0\" 500 51 \"-\" \"python-requests\/2.26.0\"\n 2022-06-15 00:14:58,028 | root | INFO | Scoring Timer is set to 60.0 seconds\n 2022-06-15 00:14:58,029 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n File \"\/var\/azureml-server\/routes.py\", line 294, in run_scoring\n     response, time_taken_ms = invoke_user_with_timer(service_input, request_headers)\n File \"\/var\/azureml-server\/routes.py\", line 341, in invoke_user_with_timer\n     result, time_taken_ms = capture_time_taken(user_main.run)(**params)\n File \"\/var\/azureml-server\/routes.py\", line 322, in timer\n     result = func(*args, **kwargs)\n File \"\/var\/azureml-app\/score2.py\", line 57, in run\n     img = Image.open(input_data).convert('RGB')\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/PIL\/Image.py\", line 2975, in open\n     fp = builtins.open(filename, \"rb\")\n FileNotFoundError: [Errno 2] No such file or directory: 'test_img.jpg'\n During handling of the above exception, another exception occurred:\n Traceback (most recent call last):\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1832, in full_dispatch_request\n     rv = self.dispatch_request()\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1818, in dispatch_request\n     return self.view_functions[rule.endpoint](**req.view_args)\n File \"\/var\/azureml-server\/routes.py\", line 270, in score_realtime\n     service_input, request.headers, request.environ.get(\"REQUEST_ID\", \"00000000-0000-0000-0000-000000000000\")\n File \"\/var\/azureml-server\/routes.py\", line 303, in run_scoring\n     raise RunFunctionException(str(exc))\n run_function_exception.RunFunctionException\n 2022-06-15 00:14:58,030 | root | INFO | 500\n 127.0.0.1 - - [15\/Jun\/2022:00:14:58 +0000] \"POST \/score HTTP\/1.0\" 500 51 \"-\" \"python-requests\/2.26.0\"\n Exception in worker process\n Traceback (most recent call last):\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/gunicorn\/arbiter.py\", line 589, in spawn_worker\n     worker.init_process()\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py\", line 142, in init_process\n     self.run()\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py\", line 125, in run\n     self.run_for_one(timeout)\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py\", line 84, in run_for_one\n     self.wait(timeout)\n File \"\/azureml-envs\/azureml_8003354dcfcc0ac94ef7d92e5607092f\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py\", line 36, in wait\n     ret = select.select(self.wait_fds, [], [], timeout)\n File \"\/var\/azureml-server\/routes.py\", line 159, in alarm_handler\n     raise TimeoutException(error_message)\n timeout_exception.TimeoutException\n Worker exiting (pid: 125)\n worker timeout is set to 300\n Booting worker with pid: 157\n SPARK_HOME not set. Skipping PySpark Initialization.\n Initializing logger\n 2022-06-15 00:16:03,376 | root | INFO | Starting up app insights client\n logging socket was found. logging is available.\n logging socket was found. logging is available.\n 2022-06-15 00:16:03,376 | root | INFO | Starting up request id generator\n 2022-06-15 00:16:03,377 | root | INFO | Starting up app insight hooks\n 2022-06-15 00:16:03,377 | root | INFO | Invoking user's init function\n 2022-06-15 00:16:03,624 | root | INFO | Users's init has completed successfully\n 2022-06-15 00:16:03,626 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n 2022-06-15 00:16:03,626 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n 2022-06-15 00:16:03,633 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n 127.0.0.1 - - [15\/Jun\/2022:00:20:12 +0000] \"POST \/ HTTP\/1.0\" 405 178 \"-\" \"Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/81.0.4044.129 Safari\/537.36\"\n 127.0.0.1 - - [15\/Jun\/2022:00:20:13 +0000] \"GET \/.env HTTP\/1.0\" 404 232 \"-\" \"Mozilla\/5.0 (X11; Linux x86_64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/81.0.4044.129 Safari\/537.36\"\n 2022-06-15 00:35:48,752 | root | INFO | Swagger file not present\n 2022-06-15 00:35:48,753 | root | INFO | 404\n 127.0.0.1 - - [15\/Jun\/2022:00:35:48 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"Go-http-client\/1.1\"\n\n\n\nresult = service.run(input_data=\"test_img.jpg\")\nprint(result)\n\n Received bad response from service. More information can be found by calling `.get_logs()` on the webservice object.\n Response Code: 502\n Headers: {'Connection': 'keep-alive', 'Content-Length': '51', 'Content-Type': 'text\/html; charset=utf-8', 'Date': 'Wed, 15 Jun 2022 00:50:21 GMT', 'Server': 'nginx\/1.14.0 (Ubuntu)', 'X-Ms-Request-Id': 'dacf03b8-adb6-4cbf-8cea-d0c4086712f4', 'X-Ms-Run-Function-Failed': 'True'}\n Content: b\"[Errno 2] No such file or directory: 'test_img.jpg'\"\n ---------------------------------------------------------------------------\n WebserviceException                       Traceback (most recent call last)\n <ipython-input-18-c76911546a4f> in <module>\n ----> 1 result = service.run(input_data=\"test_img.jpg\")\n     2 print(result)\n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/webservice\/aci.py in run(self, input_data)\n     403                                       'Headers: {}\\n'\n     404                                       'Content: {}'.format(resp.status_code, resp.headers, resp.content),\n --> 405                                       logger=module_logger)\n     406 \n     407     def update(self, image=None, tags=None, properties=None, description=None, auth_enabled=None, ssl_enabled=None,\n WebserviceException: WebserviceException:\n     Message: Received bad response from service. More information can be found by calling `.get_logs()` on the webservice object.\n Response Code: 502\n Headers: {'Connection': 'keep-alive', 'Content-Length': '51', 'Content-Type': 'text\/html; charset=utf-8', 'Date': 'Wed, 15 Jun 2022 00:50:21 GMT', 'Server': 'nginx\/1.14.0 (Ubuntu)', 'X-Ms-Request-Id': 'dacf03b8-adb6-4cbf-8cea-d0c4086712f4', 'X-Ms-Run-Function-Failed': 'True'}\n Content: b\"[Errno 2] No such file or directory: 'test_img.jpg'\"\n     InnerException None\n     ErrorResponse \n {\n     \"error\": {\n         \"message\": \"Received bad response from service. More information can be found by calling `.get_logs()` on the webservice object.\\nResponse Code: 502\\nHeaders: {'Connection': 'keep-alive', 'Content-Length': '51', 'Content-Type': 'text\/html; charset=utf-8', 'Date': 'Wed, 15 Jun 2022 00:50:21 GMT', 'Server': 'nginx\/1.14.0 (Ubuntu)', 'X-Ms-Request-Id': 'dacf03b8-adb6-4cbf-8cea-d0c4086712f4', 'X-Ms-Run-Function-Failed': 'True'}\\nContent: b\\\"[Errno 2] No such file or directory: 'test_img.jpg'\\\"\"\n     }\n }\n\n\n\nWhat kind of response is needed? I have test_img.jpg file in the same directory.\n\nAny help is appreciated.\n\nThank you.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Unable to create labelling project",
        "Question_creation_time":1654602922600,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/879956\/unable-to-create-labelling-project.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I've been trying to create a Labeling project in AzureML. I have succesfully registered the datastore (without credentials, so AzureML should use the users's AD Credential), I have succesfully created a dataset from the datastore (approx 15k images in the dataset) and can explore the dataset from the portal.\n\nWhen I then create a labelling project, I finish the creation wizard and get back to the label project overview with. For a few seconds the project shows it's initializing but then shows the project as Failed. The only information I get is:\n\nThe dataset refresh has failed. Verify the project's datastore credentials are correct and the dataset contains datapoints.\n\nHowever, as far as I can tell the credentials are correct and the dataset does contain datapoints as evidenced by me being able to 'explore' the dataset from the portal.\n\nWhat other issues can cause this error and\/or how can I get a more detailed explanation for what went wrong?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-09T20:40:37.01Z",
                "Answer_score":0,
                "Answer_body":"@BokkersLARLars-7370 If your dataset was not created from a blob datastore, that might be the issue.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Hi team, I can't see create inference pipeline in my top pane beside submit button on Azure ML designer",
        "Question_creation_time":1616146270477,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/322365\/hi-team-i-can39t-see-create-inference-pipeline-in.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":2,
        "Question_body":"![79621-free-trail-designer.png][1] [1]: \/answers\/storage\/attachments\/79621-free-trail-designer.png",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-19T14:33:08.65Z",
                "Answer_score":2,
                "Answer_body":"@Geethesh-6549 Could you please try to submit the pipeline and then check if the option to deploy real time inference pipeline is available.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-13T22:53:23.45Z",
                "Answer_score":2,
                "Answer_body":"I have the same problem",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-20T02:12:54.987Z",
                "Answer_score":4,
                "Answer_body":"For all those who are having this same issue: it happened to me that, suddenly, the pipeline design page changed and, after this, the pipelines modules weren't and couldn't be sorted by type:\n\nHow it was before the change (according to Msft doc https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score):\n\nHow it is now after the change:\n\n\n\n\nOther consequence of the change was that the top right button 'Create inference pipeline' dissappeared:\n\nHow it was before the change (according to Msft doc https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy):\n\n\n\n\nAs consequence, after this sudden change, in order to be able to deploy a no-code machine learning model in Azure you have to go to the 'jobs' page and there you can find the 'Create inference pipeline' drop-down list:\n\n\n\n\nIt's a shame that after one year, no one in Microsoft have been able to answer this question satisfactorily and to solve this problem that, furthermore, is 'magically' generated by Azure from one moment to another... A lot of wanting to promote the no code tool but afterwards, when people get stucked (normally not deep tech people), no help at all.\n\nHope this answer can help to those who were lost like me.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Python code for a generalized lineare model in Azure machine learning",
        "Question_creation_time":1654699584787,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/881821\/glm-with-azure-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hello guys,\nI am currently training a model to price boat types around the world using about 30,000 records of historical sales from the last 7 years. The approach is currently a linear regression in Azure ML studios.\n\nUsing 60 variables such as number of engines, year of construction, bedroom, brand etc. which have already been normalized and split into a training set and a testing set, the purchase price of a given boat is evaluated, depending on the port.\n\nNow I would like to use a generalized linear model with family gamma and the link function identity to train a better model and thus get a better price estimation.\n\nUnfortunately there is no module included in Azure machine learning for this. Has anyone ever written code for a GLM in Azure machine learning or can tell me how complex this is?\n\nI would appreciate any help and have a nice weekend!",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"[SOLVED] AML Pipeline publish error: Identity(object id: __) does not have permissions for Microsoft.MachineLearningServices\/workspaces\/metadata\/snapshots\/write actions.",
        "Question_creation_time":1654848921463,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/884432\/aml-pipeline-publish-error-identityobject-id-does.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I get the following error while trying to publish some new pipelines to an AML workspace:\n\nSnapshotException:\nMessage: {\n\"error_details\": {\n\"componentName\": \"project\",\n\"correlation\": {\n\"operation\": \"038f38ce5375f4cda9b0a50df5bb9c1b\",\n\"request\": \"e874ef090203af05\"\n},\n\"environment\": \"eastasia\",\n\"error\": {\n\"code\": \"UserError\",\n\"innerError\": {\n\"code\": \"ForbiddenError\"\n},\n\"message\": \"Identity(object id: bb0511d8-d57a-4442-89a1-1986cac268c9) does not have permissions for Microsoft.MachineLearningServices\/workspaces\/metadata\/snapshots\/write actions. Please refer to https:\/\/aka.ms\/azureml-auth-troubleshooting to fix the permissions issue.\"\n},\n\"location\": \"eastasia\",\n\"time\": \"2022-06-10T08:07:13.3168371+00:00\"\n},\n\"status_code\": 403,\n\"url\": \"__\"\n}\n\nDo note that I'm publishing multiple pipelines to multiple workspaces - only 2 of the pipelines on our Asia workspace are failing with this (and 1 other on Asia completed successfully)... I see that similar issues had existed before and were internal to Azure and fixed promptly, i.e. - https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/407580\/permission-error-while-finishing-auto-ml-run.html\n\nAny idea if this is a similar thing, or did we do something wrong? Thanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-10T08:56:46.643Z",
                "Answer_score":0,
                "Answer_body":"Rerun after a while works fine...",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Use register trained .ilearner model and deploy it as Real-Time-Inference Endpoint",
        "Question_creation_time":1653486198093,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/863786\/use-register-trained-ilearner-model-and-deploy-it.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Dear Community, since more than 2 weeks I'm struggeling on Azure Machine Learning Studio. Our Training-Pipeline generates a Trained-Best-Model folder containing the following files _meta.yaml _samples.json _schema.json conda_env.yaml data.ilearner model_spec.yaml score.py In the designer I can just run my training Pipeline, Update my Inference Pipeline and\u00b4once this finishied the progress, I press the \"Deploy\" Button. This creates some kind of deployment package, registers the model and deploys it to a kubernetes cluster. I'm completly happy with the setting of my pipeline and my resulting endpoint. But our customer wants us to automate it so there is a weekly deployment shedule on the endpoint. All tutorial and informations I found use other file formats (like .pkl and .onnx) but really not a single Jupyter notebook shows me how a) To Read my mltable Dataset (Type File, contains the folder of the listed filnames above ) and \"convert it\" to a model b) package this model c) deploy it to an existing kubernetes webservice If i could just automate those 2 clicks from the Inference Pipeline Run in python, it would all be done. But this issue already consumed more like 2 weeks of constant failing. Is it so hard or is it just me? ![205506-image.png][1] [1]: \/answers\/storage\/attachments\/205506-image.png",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-10T09:25:06.88Z",
                "Answer_score":0,
                "Answer_body":"@ramr-msft @romungi-MSFT Is there somthing new here? Or do I have to create a suppor ticket?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Adding input and output parameter to a DatabricksStep",
        "Question_creation_time":1654710154713,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/881980\/adding-input-and-output-parameter-to-a-databrickss.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":17,
        "Question_score":0,
        "Question_body":"@romungi-MSFT\n\nHello,\n\nWe are using AMLS for creating and registering a pipeline which runs on a pre-defined Databricks cluster.\nIn the AMLS workspace, there is our Databricks notebook which should be executed in the DatabricksStep.\n\nWe want to save a file into a Blob-storage container. Therefore, we have added the parameters \"outputs\" and \"notebook_params\" to the DatabricksStep:\n\n\nWe would like to know how we can retrieve the output folder path within the Databricks notebook with the name \"basic_DatabricksStep_script.py\".\nWith PythonScriptStep this worked using the following commands:\n\n import argparse\n parser = argparse.ArgumentParser()\n parser.add_argument('output', type=str, dest='output', default='output', help='given output data folder name') \n args = parser.parse_args()\n output_data_folder_path = args.output\n\n\n\nHow will this work with a DatabricksStep?\n\nWe are aware of this notebook, but we need additional support to solve our issue.\nIt would be great if you could provide exemplary code and also show us how we can add the input parameter to the DatabricksStep so that we can read Datasets which are registered in AMLS.\n\n\n\n\nThank you in advance for your efforts!\n\n\n\n\nWith best regards\nAlex",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-10T09:15:46.96Z",
                "Answer_score":0,
                "Answer_body":"@romungi-MSFT\n\n\n\n\nThank you for the answer.\n\nWe are still not able to save a file into a Blob storage container.\nIt is important that we use the DatabricksStep, but irrelevant whether the Notebook (Python script basic_DatabricksStep_script.py) is in AMLS or the Databricks workspace.\n\nHow we try to save a file into the Blob storage container:\n\nHere is the Python script, which should be executed in the DatabricksStep\n\n %%writefile $source_directory\/basic_DatabricksStep_script.py\n    \n dbutils.widgets.get(\"input\")\n i = getArgument(\"input\")\n print (\"Param -\\'input':\")\n print (i)\n    \n dbutils.widgets.get(\"output\")\n dbutils.widgets.get(\"output\")\n o = getArgument(\"output\")\n print (\"Param -\\'output':\")\n print (o)\n data = [('value1', 'value2')]\n df2 = spark.createDataFrame(data)\n    \n z = o + \"\/output.txt\"\n df2.write.csv(z)\n\n\n\nThis is how we define the DatabricksStep\n\n\n\n def_blob_store = Datastore(ws, \"input_datastore\")\n step_1_input = DataReference(datastore=def_blob_store, path_on_datastore=\"dbtest\",\n                                      data_reference_name=\"input\")\n    \n output_data_folder_name = \"output\"\n output_data_folder = PipelineData(output_data_folder_name, Datastore.get(ws, \"output_datastore\"))\n     \n dbNbWithExistingClusterStep = DatabricksStep(\n     name=\"DBFSReferenceWithExisting\",\n     run_name='DBFS_Reference_With_Existing',\n     source_directory = source_directory,\n     python_script_name = \"basic_DatabricksStep_script.py\",\n  inputs=[step_1_input],\n     outputs=[output_data_folder],\n     compute_target=databricks_compute,\n     existing_cluster_id=\"XXXXXX\",\n     allow_reuse=True,\n     permit_cluster_restart=True\n )\n\n\n\n\nHere is a picture for making it clearer what we want to achieve:\n\n\n\n\n\nCurrently, our pipeline is not getting built by AMLS even though we followed the examples of the official GitHub notebook for learning about the DatabricksStep class.\nCan you make our pipeline work, please?\n\n\n\n\nThank you in advance for your support!\n\n\n\n\nWith best regards,\nAlex",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AzureML model predictions do not match scored model",
        "Question_creation_time":1644551791223,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/731481\/azureml-model-predictions-do-not-match-scored-mode.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I have deployed a model to an endpoint but the predictions that come back do not match what is output from the scored model in the experiment.\n\nThe model is a Multiclass Neural Network for classifying emails - it takes approx. 1,000 elements of text and puts them into one of about 18 possible categories.\n\nReviewing the scored model outputs in the experiment, the accuracy is reasonable; however once deployed it always predicts any input into a single category with near 100% confidence. The input is correctly formatted (this is validated in the model output) so I'm assuming something is misconfigured in the model deployment, but I'm not seeing any indication as to what.\n\nAppreciate any help from MSFT in investigating this issue.\n\nCheers, James",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-11T11:43:59.53Z",
                "Answer_score":0,
                "Answer_body":"@JamesB-9842 Thanks for the question. There are multiple ways to create a multiclass DNN on various AzureML products. Is this from some tensorflow or pytorch code, or from the AML Designer? Screenshots or sample notebooks might help a lot.",
                "Answer_comment_count":7,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to specify do not allow reuse in Azure Machine Learning designer",
        "Question_creation_time":1617640132493,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/344626\/how-to-specify-do-not-allow-reuse-in-azure-machine.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":5,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Is there a way in the AML designer to set a pipeline and\/or specific step to now allow reuse between runs? I've seen quite a few posts on how to do this in code, but I can't seem to find a way to set that property in the designer.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-06T01:12:37.013Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nUse the following steps to update a module pipeline parameter:\n\nAt the top of the canvas, select the gear icon.\nIn the Pipeline parameters section, you can view and update the name and default value for all of your pipeline parameter.\n\n\n\n\nHope this helps. Thanks.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-04-20T18:43:02.643Z",
                "Answer_score":0,
                "Answer_body":"Thanks Youtong. Unfortunately, that doesn't seem to be working for me. I tried to add that as a pipeline parameter, but when I go to submit the pipeline again, it just reused the output from the prior run for each module. Here is an example for the first step where I set the Train Dataset. As you can see, it's reusing the dataset.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-04-20T19:11:29.31Z",
                "Answer_score":0,
                "Answer_body":"Yutong,\nPlease disregard my prior email. I went back and recreated all of the pipeline parameters and now the allow_reuse is working as you described. I must have made a typo or some other error the first time around.\n\nThank you for this solution!",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-29T08:45:01.937Z",
                "Answer_score":0,
                "Answer_body":"@YutongTie-MSFT Hi I experience the exact same issue (commented in the initial post above with screenshots)\nI recreated all the queries and and used the parameter correnctly (i think) but it keeps getting ignored. Its kind of time critial for me. How can I get this to work?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-09T07:06:40.9Z",
                "Answer_score":0,
                "Answer_body":"Hi. I resolved this by checking the 'Regenerate Output' option for a root component.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"NEW Azure ML vs On-Prem SQL",
        "Question_creation_time":1638277834353,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/646058\/new-azure-ml-vs-on-prem-sql.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_follower_count":22,
        "Question_score":0,
        "Question_body":"Hello,\n\nI understand there was a process how to connect to on-prem sql db from Azure ML studio, but with the transition to the new UI, I don't see the option to connect to the gateway. I have it successfully installed and registered in MS Azure, but from Studio it simply does not offer it as a dataset type when using the Import Data module.\nI can't find any documentation regarding the new UI nor any useful guides for this.\n\nWould anybody know whether this function is still available in the new studio and if so how can an on-prem gateway be connected?\n\nThank you,\nVS",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-01T09:36:28.393Z",
                "Answer_score":0,
                "Answer_body":"@sorcrow-1800\n\nThanks for reaching out to us. I just got confirmation from the pm of AML, on-prem SQL is not supported in AML yet, but it's now on our plan.\n\nI will forward your feedback to product team as well.\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-12-01T07:17:41.387Z",
                "Answer_score":0,
                "Answer_body":"Hi @sorcrow-1800,\n\n\n\n\nThis is the procedure to connect On-prem SQL\n\n\n\n\n\nIf the answer is the right solution, please click \"Accept Answer\" and kindly upvote it. If you have extra questions about this answer, please click \"Comment\".\n\nNote: Please follow the steps in our documentation to enable e-mail notifications if you want to receive the related email notification for this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-12-01T10:23:32.107Z",
                "Answer_score":0,
                "Answer_body":"I'm sorry, but are you sure??? Machine learning is obviously fully dependent on data and you are telling me MS just cut off a significant portion of source types and isolated it to cloud only datasets?",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-08T12:20:05.67Z",
                "Answer_score":0,
                "Answer_body":"Hi Yutong\nAny news on the 2022 Q2 release regarding on-prem and Azure ML?\nThanks in advance",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"error accessing azure dataset from local project in pipeline , gives a wrong path of dataset",
        "Question_creation_time":1653853868117,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/868657\/error-accessing-azure-dataset-from-local-project-i.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"hi, I am new to azure and i work in a project where I have to launch a pipeline to prep data and train , so first thing I used my_dataset.as_named_input('name_dataset') as an input like this :\n\ndata_prep_step = PythonScriptStep(\nscript_name=prep_entry_point,\nsource_directory=source_dir,\narguments=[ \"--prep_output\", output_data1],\ncompute_target=pipeline_cluster,\ninputs=[my_dataset.as_named_input(my_dataset)],\nrunconfig=aml_run_config,\nallow_reuse=True\n)\n\nbut when testing the pipeline I get the error because of my_dataset.as_named_input('name_dataset') returns diffrent path to my dataset\nwhen testing in Azure ml workspace it works fine , can anyone help me please ..",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-07T23:04:55.217Z",
                "Answer_score":0,
                "Answer_body":"Hello anonymous user\n\nSorry we did not hear from you, have you check Ram's response above for your issue? Does it help?\n\nPlease let us know if you have more issues and need futher help, we are glad to help.\n\nMore references here: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-read-write-data-v2?tabs=Python-SDK\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning Designer - Webservice input\/output disappear",
        "Question_creation_time":1653385681273,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/861882\/azure-machine-learning-designer-webservice-inoputo.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":8,
        "Question_comment_count":1,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"Hi all,\n\nI'm trying to create an inference pipeline with the AML designer.\nI clicked on the \"Create inference pipeline\" button:\n\n\n\n\nand now I want to do some changes in the pipeline. I added at the end two more steps and linked the Webservice output component to the last step:\n\n\n\n\nI clicked on save and submit it.\nThe result is the following:\n\n\n\n\nThe two new steps are present and executed, but the webservice output step is disappeared! I've tried multiple time with the same result.\nThe webservice input step is correctly present at the beginning of the pipeline.\n\nAlso, after making the change and saving correctly, if I exit and reopen the pipeline the step \"Web Service Output\" is no longer there\n\nCan you help me?\n\nThanks!\n\nG",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-07T13:36:56.26Z",
                "Answer_score":2,
                "Answer_body":"Hi @Antonio-9417,\n\nSorry for the inconvenience caused.\nThis is a known bug and we've fixed. Could you please retry to see if you can still repro? I tried from my side either manually build an inference pipeline or modify the auto-gen inference pipeline, the web service input\/output components are still there.\n\nIf you can still repro, could you please provide following info for us to investigate?\n- your inference pipeline draft URL\n- inference pipeline job URL of which the webservice input\/output components disappear\n- Is your workspace in Vnet?\n\nWe're also happy to set up a call to investigate, could you please send me an email so that I can send the meeting request?\nWe're based in Beijing (UTC+8).\n\nThanks!",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-05-28T23:49:14.153Z",
                "Answer_score":0,
                "Answer_body":"I have the exact same problem, Web Service Input disappears. Because of that (I guess), after submitting the pipeline there is no \"deploy\" option available.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-30T13:47:05.607Z",
                "Answer_score":0,
                "Answer_body":"I'm having the same issue here! There's something wrong with the transition between training and inference pipelines!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-31T09:51:44.197Z",
                "Answer_score":0,
                "Answer_body":"Same for me. Also when following https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/create-classification-model-azure-machine-learning-designer\/inference-pipeline , sometimes deleting the connection between \"Score Model\" and \"Web Service Output\" has no effect (the pipeline displays as modified in the designer, but after submitting, or reloading from the drafts, shows the old connection)",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-06T12:59:22.007Z",
                "Answer_score":0,
                "Answer_body":"Hi, this is Blanca, a PM from AML Designer team.\nSorry for the inconvenience caused.\nWe will investigate this issue, and firstly we'd like to know more details about how to repro such issue.\nCould you please send an email to me and let me know what time works for you to have a quick call?\nMy email is keli19@microsoft.com, and our team is based in Beijing (UTC+8).\nThanks!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-06T13:39:37.06Z",
                "Answer_score":0,
                "Answer_body":"Hi @BlancaLi-3542 , I'm following https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/create-classification-model-azure-machine-learning-designer\/inference-pipeline.\n\nDoes it work for you?\n\nRegards",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-07T14:02:47.9Z",
                "Answer_score":1,
                "Answer_body":"I've tested it on the clustering example. It seems to be working now. Thanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-07T15:14:43.58Z",
                "Answer_score":1,
                "Answer_body":"Hi @BlancaLi-3542,\n\nI did more tests in my environment and the bug didn't appear anymore, thanks!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Custom docker based Azure Environment is failing",
        "Question_creation_time":1653668695787,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/867368\/custom-docker-based-azure-environment-is-failing.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_follower_count":15,
        "Question_score":1,
        "Question_body":"I have an custom docker based environment for running R scripts inside AzureML pipeline. It was working fine last week. Today I see some weird error.\n\nResponse status code does not indicate success: 400 (BaseImage, BaseDockerfile, or BuildContext must be set for Docker-based environments.).\nMicrosoft.RelInfra.Common.Exceptions.ErrorResponseException: BaseImage, BaseDockerfile, or BuildContext must be set for Docker-based environments.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Can not use AutoML models",
        "Question_creation_time":1653642599833,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/866814\/can-not-use-automl-models.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_follower_count":11,
        "Question_score":1,
        "Question_body":"Hello,\n\nI have run an autoML model and in the jobs window of the studio, I can see it worked as I can see all the models generated under different algorithms and their performance. Then in notebook I am trying to retrive the best performing model and I am calling the AUTOML model using:\n\nlocal_run = AutoMLRun(experiment, \"AutoML_5970dd9a-1dae-4e6b-90ff-47878565822f_0\",outputs=None)\n\nwhich works just fine and then:\n\nbest_run, fitted_model = local_run.get_output()\n\nand there is an error that I dont know how to solve: TypeError: the JSON object must be str, bytes or bytearray, not NoneType\n\nSo please your help to solve this!\n\nThank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-04T07:13:57.28Z",
                "Answer_score":1,
                "Answer_body":"I just solved this, it was caused by my Wrong JSON format. You need to check it too",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-07T14:34:12.013Z",
                "Answer_score":0,
                "Answer_body":"Thanks for the update, Yes this issue caused due to the wrong format of json str.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Autoscaling issue with AKS attached as ML inference cluster",
        "Question_creation_time":1651848877503,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/839654\/autoscaling-issue-with-aks-attached-as-ml-inferenc.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":16,
        "Question_score":0,
        "Question_body":"We have a AKS cluster defined inside a VNet. This AKS cluster is used as an Inference cluster for Azure ML and models are deployed on the AKS from ML. Due to this reason, AKS cluster of \"loadBalancer\" outbound type is created which creates a load balancer of Public IP [a requirement of ML]\n\nAs this is inside a VNet, PublicIP is not routable and to access the scoring endpoints deployed on AKS, we have created a NGINX Ingress controller, with an Internal IP\n\nNow, everything is working fine, but PODs (and Nodes) aren't Autoscaling. Have enabled cluster autoscaler and per MS advice, not enabled HPA.\n\nWhat could be the reason? Can you please advice?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-09T08:22:14.26Z",
                "Answer_score":0,
                "Answer_body":"@SureshBettadapur-4155 I think the number of nodes is not increased as part of autoscaling for an AKS deployment of Azure ml model. Please refer the note here in the documentation.\nThe azureml-fe component scales the number of replicas for the model within the physical cluster boundaries. I think in your case the Azure ML router azureml-fe might not be started.\nHave you tried to check if autoscaling works when you deploy to a new cluster which is created from the azure ml portal with advanced network settings that enables you to select the virtual network instead of using an existing AKS cluster?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-09T08:59:44.887Z",
                "Answer_score":0,
                "Answer_body":"Thanks for the response\n\nI can see azureml-fe service in default namespace when I run the below command\n\nkubectl get svc -A\n\ndefault azureml-fe LoadBalancer <Cluster-IP> <External-IP>\n\nPOD autoscaling is also not happening\n\nML service and AKS cluster are created using Terraform scripts. Existing AKS cluster is attached as Inference cluster",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error Running Azure ML Training Script",
        "Question_creation_time":1651574593590,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/834730\/error-running-azure-ml-training-script.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hello,\n\nI am receiving the following error message when running an experiment script in Azure Machine Learning Studio\n\n\"AADSTS70016: OAuth 2.0 device flow error. Authorization is pending. Continue polling\"\n\nMicrosoft have stated;\n\n\"This is not an error scenario, but is handled like one by Azure AD to handle certain authentication flows. This is not an indication that anything went wrong.\"\n\nHowever my experiment run has failed as can ben seen below;\n\n\n\n\nCould someone please advise how to correct this error.. thank you",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-04T09:47:03.277Z",
                "Answer_score":0,
                "Answer_body":"Hello @YutongTie-MSFT - log file attached.198812-70-driver-log.txt\n\n\n\n\n\nThank you.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-04T19:25:14.49Z",
                "Answer_score":0,
                "Answer_body":"Hi I'm having the exactly same bug when i'm trying to launch an experiment from runscript in Azure Ml Studio.\n\nErrorResponse\n{\n\"error\": {\n\"code\": \"UserError\",\n\"message\": \"AADSTS70016: OAuth 2.0 device flow error. Authorization is pending. Continue polling. }\n}",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-07T11:19:28.317Z",
                "Answer_score":0,
                "Answer_body":"Hello\n\nSame here, I have the same Error\n\nIs there any information about this?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Recover a missing AML Run",
        "Question_creation_time":1653661664120,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/867216\/recover-a-missing-aml-run.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi,\n\nIs it possible to recover an Azure ML Run that seems to have been deleted? I can still see the files in Blob Storage, but it's not showing up in the AML portal.\n\nThanks,\nMelissa",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-30T07:17:01.007Z",
                "Answer_score":0,
                "Answer_body":"@mbristow I would recommend to raise a support case from Azure portal through Help + Support blade. The service team of Azure ML would assess your setup to check if a particular run can be restored. The longer it is since the run got deleted the chances of restoring it would be lower.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML - Managed Identity for Compute Instance",
        "Question_creation_time":1637143820660,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/630520\/azure-ml-managed-identity-for-compute-instance.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":2,
        "Question_body":"We need to connect Azure Data Lake Storage Gen2 to Azure Machine Learning by means of a datastore. For security reasons we do not want to provide the credential-based authentication credentials (service principal or SAS token). Instead we want to connect with identity based access.\n\nThe problem we face is that we are not able to assign a managed identity to a compute instance, so we can connect from notebooks to the Data Lake. In the documentation is explained how to assign a managed identity to a cluster, but we need the same for the compute instance, as it is the only way to run commands directly from the notebook.\n\nIs there a way to assign managed identity to an Azure Machine Learning Compute Instance? Otherwise, we would like to know the best approach to overcome this issue, considering that we do not want to introduce the credentials in the code.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-17T13:54:33.153Z",
                "Answer_score":1,
                "Answer_body":"@Nimbeo-7089 Thanks for the question. Currently It\u2019s not supported yet to assign managed identity to an Azure Machine Learning Compute Instance, you\u2019d need to use credential-based access. We have forwarded to the product team to support in the near future.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"memory outage while running module",
        "Question_creation_time":1653902834057,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/869594\/memory-outage-while-running-module.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I am encountering an issue of error 0138, while training the data, at the end it shows memory has been exhausted exception\n\nI do not think my data has exceed the limit of azure ML studio, is there any way to solve this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-30T20:29:41.987Z",
                "Answer_score":0,
                "Answer_body":"Hello @darya-9510\n\nThanks for reaching out to us. This issue seldoms happen. Could you please share your structure to us and how is your dataset size? Based on the error info, too many steps in your experiment may cause that.\n\nI would suggest you try to remove some unnecessary one to try and see. If you believe your structure is reasonable, please share it to us. But it should be fine if you have not put too much.\n\nRegards,\nYutong\n\n-Please kindly accept the answer to help the community if you feel helpful, thanks.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Designer Or SDK",
        "Question_creation_time":1654023398370,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/871933\/designer-or-sdk.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I have tried both of them, I feel like Designer is more convenient but some of the function lack. Will same feature support in Designer or Designer just junior toy? Thx.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-31T22:57:37.797Z",
                "Answer_score":0,
                "Answer_body":"Hello @Chungsun-1776\n\nIt's not the truth. Designer is under develoment, while there are some feature not available in Designer but n SDK, they will be implemented eventually in Designer.\n\nMoreover, Designer is more friendly to new user who is not good at coding.\n\nIt just depends on your habit and preference.\n\n\n\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-05-31T23:06:32.64Z",
                "Answer_score":0,
                "Answer_body":"Design is better for new users who aren't good at coding",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"azure machine learning SDK",
        "Question_creation_time":1654035149473,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/872050\/azure-machine-learning-sdk.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"How to import data not by passing it as an argument,\nI do not want to do as the tutorial https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-with-datasets?source=docs",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-01T17:54:59.667Z",
                "Answer_score":0,
                "Answer_body":"Hello @benwu-8989\n\nThanks for reaching out to us, there is the code sample from engineering team\n\n from azureml.core import ScriptRunConfig\n    \n input_data=titanic_ds.as_named_input('input_data').as_mount()\n src = ScriptRunConfig(source_directory=script_folder,\n                       script='train_titanic.py',\n                       compute_target=compute_target)\n src.run_config.data = {input_data.name: input_data }\n # Submit the run configuration for your training run\n run = experiment.submit(src)\n run.wait_for_completion(show_output=True)  \n\n\n\nIn your script, you can get the mounted path via environment variable, which is the value you specified in as_named_input. For the sample code above, the environment variable will be input_data.\n\nI hopet this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful to support the community, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Migrate to portal studio",
        "Question_creation_time":1653988049527,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/871064\/migrate-to-portal-studio.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Experts,\n\nI just try studio classic which is good but retired soon\n\nI am moving to the new studio in azure portal. Any guidance for newbie?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-31T09:15:25.023Z",
                "Answer_score":0,
                "Answer_body":"Hello @Alexandre-4252\n\nWelcome to Microsoft Q&A Platform,\n\nI would start checking the docs below:\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/overview-what-is-machine-learning-studio\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/migrate-rebuild-experiment\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/migrate-register-dataset\n\nI hope this helps!\n\nPlease don\u2019t forget to \"Accept the answer\" and \u201cup-vote\u201d wherever the information provided helps you, this can be beneficial to other community members.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-05-31T09:19:47.13Z",
                "Answer_score":0,
                "Answer_body":"Can data from classic be transferred to new one?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Notebook files have disaperred",
        "Question_creation_time":1652875560357,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/854288\/notebook-files-have-disaperred.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hello,\n\nIn my MLStudio my notebook files window has disappeared so I can not access any of my data (as seen on the image) and I do not know what to do.\n\nPlease your help to solve this as soon as poosible.\n\nThank you.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-19T02:46:25.6Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us. Could you please check the access of Storage? https:\/\/docs.microsoft.com\/en-us\/azure\/storage\/blobs\/assign-azure-role-data-access?tabs=portal#assign-an-azure-role\n\nTo access these storage services, you must have at least Storage Blob Data Reader access to the storage account. Only storage account owners can change your access level via the Azure portal.\n\nOr, your admin put the data storage behind V-Net and you can not get access to it- https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-identity-based-data-access#work-with-virtual-networks\nIn this situation, you need to ask permission from your admin.\n\nCould you please share which situation you are in?\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure ML - A child experiment runs the parent's script not the child's script",
        "Question_creation_time":1654187375363,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/874717\/azure-ml-a-child-experiment-runs-the-parent39s-scr.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"As from today the behavior of child experiments in Azure Machine Learning has changed. Instead of running the child's script it will run the parent's script again. Anyone have any thoughts on the issue?\n\nTake the following:\nSubmit the parent with:\n\n from azureml.core import Experiment, ScriptRunConfig, Workspace\n    \n ws = Workspace.from_config()\n exp = Experiment(workspace=ws, name=\"tests\")\n    \n config = ScriptRunConfig(\n     source_directory=\".\",\n     script=\"test_parent.py\",\n     compute_target=\"cluster-00\",\n )\n run = exp.submit(config=config)\n\n\n\n\ntest_parent.py\n\n from azureml.core import Run, ScriptRunConfig\n    \n print(\"Inside parent.\")\n    \n run = Run.get_context()\n    \n child_config = ScriptRunConfig(\n     source_directory=\".\",\n     script=\"test_child.py\",\n     compute_target=\"cluster-00\",\n )\n run.submit_child(config=child_config)\n\n\n\ntest_child.py\n\n print(\"Inside child.\")\n\n\n\n\nstd_log.txt of parent run:\n\n Inside parent.\n Cleaning up all outstanding Run operations, waiting 300.0 seconds\n 2 items cleaning up...\n Cleanup took 0.1929168701171875 seconds\n\nstd_log.txt of child run:\n\n Inside parent.\n leaning up all outstanding Run operations, waiting 300.0 seconds\n 0 items cleaning up...\n Cleanup took 7.152557373046875e-07 seconds\n\n\n\nEven though the details of the child include the correct script:\n\nOn a side note, things have changed overnight. The interface is slightly different, especially the output of runs, even the file names. Even I was suddenly having permission issues with python's subprocess.run. So, I'm guessing something changed in the SDK I am unaware of.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure ML Studio Quotas for Assisted Labeling and Training Object Detection Model",
        "Question_creation_time":1653585502077,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/865733\/azure-ml-studio-quotas-for-assited-labeling-and-tr.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"In an Azure ML Studio labeling project, I have tried to enable Assisted Labeling. I get the error message \"Error: There is insufficient quota to create a gpu compute target. You can request more quota and create a custom compute to enable ML assisted labeling.\"\n\nI also get a similar error message when I try to train an object detection model, \"\u201cSTANDARD_D2AS_V4 is not supported for image tasks. Please choose a VM type that is in the NC-family or the ND-family.\"\n\nI requested and was granted \"Standard NC Family Cluster Dedicated vCPUs\/GPUs. These show up in my quota, but if I go to create a compute target and select GPU, I get a message saying: \"You do not have enough quota for the following VM sizes.\" followed by a list of all the VMs that it says aren't in my quota including the NC family VMs.\n\nAnd I still get the same two error messages saying I don't have enough quota for either Assisted Labeling or training an object detection model.\n\nDoes anyone know what I need to do to get these two services to work?\n\nThanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-31T09:04:55.187Z",
                "Answer_score":0,
                "Answer_body":"Hi there\n\nI have the same quota issue when I just created my project. I contacted the support team and they solved issue for me. You should try it too.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-31T11:46:07.927Z",
                "Answer_score":0,
                "Answer_body":"Thanks Alexandre,\n\nDo you have any info on how they solved this issue?\n\nI opened a case a week or so ago. The initial support team thought they were the wrong team, and referred me to the Global Capacity team. The global capacity team has been slow to respond, most likely due to the Memorial day weekend.\n\nHopefully they will get back to me soon.\n\nBut I think this may be more of an issue with Azure ML Studio rather than the quota team.\n\nAny thoughts?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-06T22:22:29.86Z",
                "Answer_score":0,
                "Answer_body":"@YutongTie-MSFT this continues unresolved. TrackingID#2205240040008434",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning Integration with S3",
        "Question_creation_time":1627977757003,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/499465\/azure-machine-learning-integration-with-s3.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"Hi Everyone,\n\nI have a model in Azure Machine Learning service and the data for that model is residing in one of the S3 buckets of AWS, is there a way i can connect AMLS to AWS S3 as a data store and run my model on top of it.?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-03T15:36:03.437Z",
                "Answer_score":0,
                "Answer_body":"@AmandeepBajaj-2011 Thanks for the question. The following are the Data - sources supported in Azure ML.\n\u2022 Training data can be loaded from local files, Azure datastore, web files or open datasets\n\u2022 Data can be accessed via AzureML Datasets\n\u2022 Local runs also support reading data into Pandas dataframes.\n\nWe have forwarded to the product team to check for the requested.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How do I export my project from Azure",
        "Question_creation_time":1654324217247,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/876500\/how-do-i-export-my-project-from-azure.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi\n\nI would like to know how I keep the studio and all the elements I have done in Azure.\n\nI need them for a project but my subscription is expired and I'd like to keep what I've done.\n\nI can't afford paying for a new subscription.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-06T10:36:08.77Z",
                "Answer_score":0,
                "Answer_body":"@DavidGORGETTE-3670 You can export and delete your data from Azure using the guidance from this documentation.\nPlease note Azure ML workspace uses resources like storage account, container registry, app insights and key vault to store information related to ML experiments, jobs and environments. Your run history is basically available from the storage containers along with the supporting data. You can download specific models that are required directly from Azure ML portal for easy identification. I hope this helps!!\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How do I create a resource group when creating a workspace?",
        "Question_creation_time":1638162185497,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/643801\/how-do-i-create-a-resource-group-when-creating-a-w.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":1,
        "Question_body":"I am going through the Azure AI training and need to create a workspace under machine learning. When it asks me to select a resource group there are no options. When I want to create a new resource group it says I dont have permissions under my subscription. What do I need to do?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-29T05:11:17.963Z",
                "Answer_score":1,
                "Answer_body":"I believe you need to be a subscription-level owner or contributor.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Real-time Endpoint Security",
        "Question_creation_time":1654120145047,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/873592\/azure-ml-real-time-endpoint-security.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Our security team ran a scan against the real-time managed endpoint we just deployed in Azure ML. There was a critical risk regarding an outdated version of Squid being susceptible to a DoS attack. The recommended fix was to \"Upgrade to version 5.0.6 or higher for 5.x, 4.15 or higher for 4.x, or contact the vendor for a fix.\".\n\nIs Squid being used on the managed endpoints (is this an actual issue)?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Passing data between AzureML pipeline steps with OutputFileDatasetConfig: difference between 'inputs\/outputs' and 'arguments'?",
        "Question_creation_time":1654156643450,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/874019\/passing-data-between-azureml-pipeline-steps-with-o.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hello,\n\nI have been successfully building and operating machine learning pipelines with Azure SDK, but there is something I fail to fully understand, and I'm wondering if my code can be simplified in some way.\n\nLet's say I have a simple pipeline with two steps: the first step processes data located at 'training_data_path' in Blob storage and then saves it to the same location, and the second step reads that processed data to do something else. So my code is as follows:\n\n def_data_store = ws.get_default_datastore()\n training_data_path = (def_data_store, 'training_data')\n    \n step_1_config = OutputFileDatasetConfig(destination = training_data_path)\n step_2_config = OutputFileDatasetConfig(destination = training_data_path)\n    \n step_1 = PythonScriptStep(\n     name=\"Step 1\",\n     script_name=\"step_1.py\",\n     source_directory=\".\/\",\n     outputs=[step_1_config],\n     arguments = [\n         \"--training-data-path\", step_1_config\n         ],    \n     compute_target=compute_target,\n     runconfig=aml_run_config,\n     allow_reuse=False\n )\n    \n step_2 = PythonScriptStep(\n     name=\"Step 2\",\n     script_name=\"step_2.py\",\n     source_directory=\".\/\",\n     inputs=[step_1_config.as_input('training_data')],\n     arguments = [\n         \"--training-data-path\", step_2_config\n         ],    \n     compute_target=compute_target,\n     runconfig=aml_run_config,\n     allow_reuse=False\n )\n\n\n\n\nI have two questions about that:\n\n1) Even though the path to the data is the same in each step, it seems like I have to create a separate OutputFileDatasetConfig object for each step. So if my pipeline has 10 steps, I will create step_1_config, step_2_config, step_3_config... Isn't there a way to reuse the same OutputFileDatasetConfig object for multiple steps?\n\n2) As far as I know, in step 2, I could delete the 'inputs' parameter and modify the 'arguments' parameter as follows, the result would be the same.\n\n step_2 = PythonScriptStep(\n     name=\"Step 2\",\n     script_name=\"step_2.py\",\n     source_directory=\".\/\",\n     arguments = [\n         \"--training-data-path\", step_1_config.as_input('training_data')\n         ],    \n     compute_target=compute_target,\n     runconfig=aml_run_config,\n     allow_reuse=False\n )\n\n\n\nMy question is: is there any difference when specifying the input using both the 'inputs' and 'arguments' parameters Vs. using only the 'arguments' parameter?\n\nThanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-03T13:02:24.427Z",
                "Answer_score":0,
                "Answer_body":"@ThierryL-3166 I think the recommendation to use separate OutputFileDatasetConfig objects for different steps is to avoid concurrent writes to a single object. As stated in a note in documentation:\n\n Concurrent writes to a OutputFileDatasetConfig will fail. Do not attempt to use a single OutputFileDatasetConfig concurrently. Do not share a single OutputFileDatasetConfig in a multiprocessing situation, such as when using distributed training.\n\nIf your steps do not run in parallel then you can try to use a single object and check though.\n\nWith respect to using inputs or arguments, If you are using the same for the same operation then arguments would pass the same as input to the script used in the same step and you would need to use an argparser to retrieve the value in the script. Whereas, inputs would provide the same value as the run objects context in the same script. The section access datasets within script provides an example here for a train and test dataset where train is passed with arguments and test with inputs.\n\n smaller_dataset = iris_dataset.take_sample(0.1, seed=seed) # 10%\n train, test = smaller_dataset.random_split(percentage=0.8, seed=seed)\n    \n # In pipeline definition script:\n # Code for demonstration only: It would be very confusing to split datasets between `arguments` and `inputs`\n train_step = PythonScriptStep(\n     name=\"train_data\",\n     script_name=\"train.py\",\n     compute_target=cluster,\n     arguments=['--training-folder', train.as_named_input('train').as_download()],\n     inputs=[test.as_named_input('test').as_download()]\n )\n    \n # In pipeline script\n parser = argparse.ArgumentParser()\n parser.add_argument('--training-folder', type=str, dest='train_folder', help='training data folder mounting point')\n args = parser.parse_args()\n training_data_folder = args.train_folder\n    \n testing_data_folder = Run.get_context().input_datasets['test']",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"AutoML : TensorFlowDNN and TensorFlowLinearRegressor are blacklisted by default",
        "Question_creation_time":1653464529937,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/863297\/automl-tensorflowdnn-and-tensorflowlinearregressor.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":11,
        "Question_score":1,
        "Question_body":"Hello,\n\nI am running an AutoML experiment for a regression task, and looking at the YAML file which is generated it seems that TensorFlowLinearRegressor and TensorFlowDNN models are listed as both 'supported_models' and 'blacklist_algos'.\n\nI tried to deactivate the automatic blacklisting of models by specifying the parameter 'auto_blacklist' to False, and 'blacklist_models' and 'blacklist_algos' parameters to Null, but it doesn't change anything.\n\n automl_settings = {\n     \"primary_metric\": 'normalized_mean_absolute_error',\n     \"featurization\": 'auto',\n     \"verbosity\": logging.INFO,\n     \"n_cross_validations\": 5,\n     \"auto_blacklist\": False,\n     \"blacklist_models\": None,\n     \"blacklist_algos\": None\n }\n run = experiment.submit(automl_config, show_output=True)\n\n\n\nThe generated YAML file (excerpt):\n\n \"whitelist_models\":null,\n \"blacklist_algos\":[\"TensorFlowDNN\",\"TensorFlowLinearRegressor\"],\n \"supported_models\":[\"ElasticNet\",\"GradientBoosting\",\"LightGBM\",\"TensorFlowLinearRegressor\",\"TensorFlowDNN\",\"LassoLars\",\"DecisionTree\",\"RandomForest\",\"FastLinearRegressor\",\"OnlineGradientDescentRegressor\",\"ExtremeRandomTrees\",\"TabnetRegressor\",\"XGBoostRegressor\",\"KNN\",\"SGD\"],\n \"private_models\":[],\n \"auto_blacklist\":false\n\n\n\nMaybe the problem comes from the fact that Deep learning is set to 'Disabled' in the configuration settings, as shown on the following picture:\n\nAre deep learning models not supported anymore by AutoML?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-03T06:03:46.443Z",
                "Answer_score":0,
                "Answer_body":"@ThierryL-3166 Thanks for the question.\n\nAs mentioned in the below document The following support models in AutoML TensorFlowDNN, TensorFlowLinearRegressor are deprecated.\nhttps:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-automl-core\/azureml.automl.core.shared.constants.supportedmodels.regression?view=azure-ml-py",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Pickle Load- File Not Found when deploying using Azure ML Studio",
        "Question_creation_time":1653375158970,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/861537\/pickle-load-file-not-found-when-deploying-using-az.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I have saved a classifier model with pickle using the following code-\n\n import pickle\n with open('skm.pickle', 'wb') as fid:\n     pickle.dump(clf, fid) \n\n\n\nNow, during deployment, when I try to load this same model, it is giving an error-\n\n Error:\n {\n   \"code\": \"AciDeploymentFailed\",\n   \"statusCode\": 400,\n   \"message\": \"Aci Deployment failed with exception: Error in entry script, FileNotFoundError: [Errno 2] No such file or directory: '.\/skm.pickle', please run print(service.get_logs()) to get details.\",\n   \"details\": [\n     {\n       \"code\": \"CrashLoopBackOff\",\n       \"message\": \"Error in entry script, FileNotFoundError: [Errno 2] No such file or directory: '.\/skm.pickle', please run print(service.get_logs()) to get details.\"\n     }\n   ]\n }\n\n\n\nThis is the score.py file where I am loading the pickle model and the same file is called during deployment. Also note that, all these files (code, pickle file and related files) are in the same directory.\n\n %%writefile sklearnscore.py\n    \n import json\n import pandas as pd\n from sklearn.preprocessing import MinMaxScaler\n from sklearn.ensemble import RandomForestClassifier\n import pickle\n    \n # Initialize the deployment environment\n def init():\n     # read in the model file\n     from sklearn.pipeline import Pipeline\n     global obj\n     with open('.\/skm.pickle', 'rb') as f:\n         obj = pickle.load(f)\n\n\n\n\nI am registering the model using- model = Model.register(ws, model_name=\"utility15\", model_path=\".\/skm.pickle\")\n\nAnd the deployment code is-\n\n service_name = 'my-custom-env-service-4'\n sklearn_env = Environment.from_conda_specification(name='sklearn-env', file_path='Sklearn.yaml')\n    \n inference_config = InferenceConfig(entry_script='sklearnscore.py', environment=sklearn_env)\n    \n aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=4,tags={'Createdby':'xyz'})\n    \n service = Model.deploy(workspace=ws,\n                         name=service_name,\n                         models=[model],\n                         inference_config=inference_config,\n                         deployment_config=aci_config,\n                         overwrite=True)\n service.wait_for_deployment(show_output=True)\n\n\n\nWhen this script is run, it calls the score.py file and the file not found error comes up for pickle file. I have even tried loading the model without the .\/ thing, but the same error comes up.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-25T09:13:41.897Z",
                "Answer_score":0,
                "Answer_body":"@AmberBhanarkar-3639 Thanks for the question. Can you please share the sample that you are trying.\n\nTake a look at this notebook for one way to do this, another way would be to create a yaml file with all of the dependencies:\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/explain-model\/azure-integration\/remote-explanation\/explain-model-on-amlcompute.ipynb\n\nPlease run print(service.get_logs()) to get details.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Code: AuthorizationFailed",
        "Question_creation_time":1651917005187,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/840311\/code-authorizationfailed.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Unit 4 of 7\nExercise - Back up an Azure virtual machine\nCreate a backup for Azure virtual machines\n\nI am unable to run the following command in cloud shell to set up the environment:\nRGROUP=$(az group create --name vmbackups --location westus2 --output tsv --query name)\n\nFollowing error pop up:\nERROR: (AuthorizationFailed) The client 'live.com#...... does not have authorization to perform action 'Microsoft.Resources\/subscriptions\/resourcegroups\/write' over scope '\/subscriptions\/.......\/resourcegroups\/vmbackups' or the scope is invalid. If access was recently granted, please refresh your credentials.\nCode: AuthorizationFailed\nMessage: The client 'live.com#l...... with object id '.......' does not have authorization to perform action 'Microsoft.Resources\/subscriptions\/resourcegroups\/write' over scope '\/subscriptions\/.....\/resourcegroups\/vmbackups' or the scope is invalid. If access was recently granted, please refresh your credentials.\n\nWhen I do refresh, sign out or sign in do not helps. Anybody has any idea what to do?\nThank you",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-07T10:07:44.643Z",
                "Answer_score":1,
                "Answer_body":"Hello @Krisztian-8931\n\nWelcome to Microsoft Q&A community.\n\nHave you tried to do this first?\n\n\n\n\n\n\n\n\n\nCheers,\n\nPlease \"Accept the answer\" if the information helped you. This will help us and others in the community as well.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure ML Studio \"Failed to Authenticate to Compute\"",
        "Question_creation_time":1652041246053,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/840948\/azure-ml-studio-34failed-to-authenticate-to-comput.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I was working in Azure ML Studio and suddenly I got a yellow banner across the top of my notebook saying\n\n\"You need to be authenticated to the compute to use any Azure SDK. Please use the authenticate button to get authenticated.\"\n\nI clicked the button, but the login doesn't work. Sometimes trying to login just loops the login page over and over. Other times it flickers for a few seconds then says that I could not authenticate. Either way, when I return to ML Studio I now see a red banner over the notebook saying\n\n\"Failed to authenticate to the compute.\"\n\nThis has been ongoing for days, and nothing I have tried has solved it. I have restarted the compute, cleared the browser cookies and cache, deleted the compute and created a new one. The only other thread I've found that seemed to have this exact issue was apparently resolved with a hot fix, but it is currently happening to me.\n\nI can't get any work done since I'm blocked from using any compute.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-23T08:21:42.777Z",
                "Answer_score":0,
                "Answer_body":"@AJV-7655 Thanks, Please share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How can I access my trained model file in Azure ML?",
        "Question_creation_time":1653451827867,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/863039\/how-can-i-access-my-trained-model-file-in-azure-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I am developing a machine learning model with Azure ML using the Python SDK.\n\nThe saved model is in the location shown in the screenshot (from the log file).\nI would like to ask the followings;\n\nHow can I access that location?\n\n\nI want to use the saved model in another script. Is it possible to save the model on my local computer (during the training) where my script is?\n\nThank you.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-26T02:43:21.67Z",
                "Answer_score":0,
                "Answer_body":"@GY-2026 Thanks for the question. Can you please share the sample\/code that you are trying.\n\nIn Azure ML\u2019s Model.register, you can point to a file folder. You would have every version of the model in that folder (model01.pkl, model02.pkl, \u2026 , modelN.pkl)\nazureml.core.model.Model class - Azure Machine Learning Python | Microsoft Docs\n\nEach additional version would have to carry all previous versions.\n\nYour score.py\u2019s init function would load all of the modelX.pkl files and their objects into a dictionary.\n\n def init():\n     global models\n     models = {\n          \u201cv1\u201d: joblib.load(os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), \"model01.pkl\")),\n          \u201cv2\u201d:joblib.load(os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), \"model02.pkl\")),\n          \u201cvN\u201d:joblib.load(os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), \"modelN.pkl\"))\n     }",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-31T18:47:58.927Z",
                "Answer_score":0,
                "Answer_body":"You can use the path to retrieve your model by SDK. If you want to find the pkl, \/mnt is under Linux VM.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Why PyTorch is using only one GPU ?",
        "Question_creation_time":1653503234337,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/864175\/why-pytorch-is-using-only-one-gpu.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Azure does not use the two GPUs of my node with PyTorch (and Hugging Face). The monitoring tool of Azure shows the GPU usage is stuck at 50%.\nIts a Standard_NC12, so it has two K80s.\n\n\n\n\nI tried this way :\nhttps:\/\/azure.github.io\/azureml-cheatsheets\/docs\/cheatsheets\/python\/v1\/distributed-training\/#distributeddataparallel-per-process-launch\nand it looked like this in my notebook :\n\n\n\n\n\nI copied the docker file from the curated environments and added the libraries I needed successfully :\n\n FROM mcr.microsoft.com\/azureml\/openmpi4.1.0-cuda11.1-cudnn8-ubuntu18.04:20220329.v1\n    \n ENV AZUREML_CONDA_ENVIRONMENT_PATH \/azureml-envs\/pytorch-1.10\n    \n # Create conda environment\n RUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\\n     python=3.8 \\\n     pip=20.2.4 \\\n     pytorch=1.10.0 \\\n     torchvision=0.11.1 \\\n     torchaudio=0.10.0 \\\n     cudatoolkit=11.1.1 \\\n     nvidia-apex=0.1.0 \\\n     gxx_linux-64 \\\n     -c anaconda -c pytorch -c conda-forge\n    \n # Prepend path to AzureML conda environment\n ENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/bin:$PATH\n    \n # Install pip dependencies\n RUN pip install 'matplotlib>=3.3,<3.4' \\\n                 'psutil>=5.8,<5.9' \\\n                 'tqdm>=4.59,<4.63' \\\n                 'pandas>=1.3,<1.4' \\\n                 'scipy>=1.5,<1.8' \\\n                 'numpy>=1.10,<1.22' \\\n                 'ipykernel~=6.0' \\\n                 'azureml-core==1.40.0' \\\n                 'azureml-defaults==1.40.0' \\\n                 'azureml-mlflow==1.40.0' \\\n                 'azureml-telemetry==1.40.0' \\\n                 'tensorboard==2.6.0' \\\n                 'tensorflow-gpu==2.6.0' \\\n                 'onnxruntime-gpu>=1.7,<1.10' \\\n                 'horovod==0.23' \\\n                 'future==0.18.2' \\\n                 'wandb' \\\n                 'transformers' \\\n                 'einops' \\\n                 'torch-tb-profiler==0.3.1'\n    \n    \n # This is needed for mpi to locate libpython\n ENV LD_LIBRARY_PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/lib:$LD_LIBRARY_PATH\n    \n RUN export CUDA_VISIBLE_DEVICES=0,1\n\n\n\nI tried everything, I even added the CUDA_VISIBLE_DEVICES=0,1 inside the docker file.\n\nMy cluster is correctly configured because my colleague can use another tool (Detr with Lightning) and use 100% of the computing power.\nI copied his docker file and the result was the same, so our guess is that his tool is automatically managing all GPUs for him.\n\nDoes anyone know why the cluster is using only one GPU ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-27T15:37:03Z",
                "Answer_score":0,
                "Answer_body":"That's interesting because it was written :\nVirtual machine size\nStandard_NC12 (12 cores, 112 GB RAM, 680 GB disk)\nProcessing unit\nGPU - 2 x NVIDIA Tesla K80\nThen I guess I did not understand it properly and I am stuck using 50% of 1 K80.\n\nprint(torch.cuda.device_count()) gives :\n2\n\nnode_count = 2 leads to :\nRequested 2 nodes but AzureMLCompute cluster only has 1 maximum nodes.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-01T08:42:04.183Z",
                "Answer_score":0,
                "Answer_body":"(I also realized in the job's properties raw json that gpuCount is 0 in the compute and computeRequest sections)",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-06-02T12:19:04.443Z",
                "Answer_score":1,
                "Answer_body":"model = nn.DataParallel(model)\ndid the job.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is machine learning SDK and designer pricing the same",
        "Question_creation_time":1654035275890,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/872161\/is-machine-learning-sdk-and-designer-pricing-the-s.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I am able to find the pricing the page for SDK or designer, are they pricing the same?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-06-01T10:42:58.613Z",
                "Answer_score":0,
                "Answer_body":"@benwu-8989 Adding to @DSPatrick response, Since you have used the tag azure-machine-learning tag I think you are using the latest version of Azure Machine Learning rather than classic studio. In the case of the new Azure Machine Learning studio and the SDK there will be no charge for using the service. You will only be charged for the compute used for your experiments and other Azure services consumed, including but not limited to Azure Blob Storage, Azure Key Vault, Azure Container Registry and Azure Application Insights. Please check the details of pricing for compute for Azure ML on this page.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-05-31T22:19:12.183Z",
                "Answer_score":0,
                "Answer_body":"Maybe this one answers your question?\nhttps:\/\/azure.microsoft.com\/en-us\/pricing\/details\/machine-learning-studio\/",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML realtime endpoint provisioning fail can't find azureml-studio",
        "Question_creation_time":1654010449827,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/871653\/azure-ml-realtime-endpoint-provisioning-fail-can39.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I have been following this tutorial and been trying to deploy the model to real-time endpoint but the provisioning fails with the following logs:\n\n Exception in worker process\n Traceback (most recent call last):\n   File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py\", line 589, in spawn_worker\n     worker.init_process()\n   File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 134, in init_process\n     self.load_wsgi()\n   File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 146, in load_wsgi\n     self.wsgi = self.app.wsgi()\n   File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py\", line 67, in wsgi\n     self.callable = self.load()\n   File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 58, in load\n     return self.load_wsgiapp()\n   File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 48, in load_wsgiapp\n     return util.import_app(self.app_uri)\n   File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/gunicorn\/util.py\", line 359, in import_app\n     mod = importlib.import_module(module)\n   File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/importlib\/__init__.py\", line 127, in import_module\n     return _bootstrap._gcd_import(name[level:], package, level)\n   File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n   File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n   File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n   File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n   File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n   File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/azureml_inference_server_http\/server\/entry.py\", line 1, in <module>\n     import create_app\n   File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/azureml_inference_server_http\/server\/create_app.py\", line 24, in <module>\n     from routes import main\n   File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/azureml_inference_server_http\/server\/routes.py\", line 39, in <module>\n     from aml_blueprint import AMLBlueprint\n   File \"\/opt\/miniconda\/envs\/amlenv\/lib\/python3.7\/site-packages\/azureml_inference_server_http\/server\/aml_blueprint.py\", line 33, in <module>\n     main_module_spec.loader.exec_module(main)\n   File \"\/var\/azureml-app\/220531140810-739039939\/score.py\", line 4, in <module>\n     from azureml.studio.core.io.model_directory import ModelDirectory\n ModuleNotFoundError: No module named 'azureml.studio'\n Worker exiting (pid: 58)\n Shutting down: Master\n Reason: Worker failed to boot.\n 2022-05-31T15:15:17,378909181+00:00 - gunicorn\/finish 3 0\n 2022-05-31T15:15:17,380384002+00:00 - Exit code 3 is not normal. Killing image.\n\n\n\nscore.py\n\n import os\n import json\n    \n from azureml.studio.core.io.model_directory import ModelDirectory\n from pathlib import Path\n from azureml.studio.modules.ml.score.score_generic_module.score_generic_module import ScoreModelModule\n from azureml.designer.serving.dagengine.converter import create_dfd_from_dict\n from collections import defaultdict\n from azureml.designer.serving.dagengine.utils import decode_nan\n from azureml.studio.common.datatable.data_table import DataTable\n    \n    \n model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'trained_model_outputs')\n schema_file_path = Path(model_path) \/ '_schema.json'\n with open(schema_file_path) as fp:\n     schema_data = json.load(fp)\n    \n    \n def init():\n     global model\n     model = ModelDirectory.load(model_path).model\n    \n    \n def run(data):\n     data = json.loads(data)\n     input_entry = defaultdict(list)\n     for row in data:\n         for key, val in row.items():\n             input_entry[key].append(decode_nan(val))\n    \n     data_frame_directory = create_dfd_from_dict(input_entry, schema_data)\n     score_module = ScoreModelModule()\n     result, = score_module.run(\n         learner=model,\n         test_data=DataTable.from_dfd(data_frame_directory),\n         append_or_result_only=True)\n     return json.dumps({\"result\": result.data_frame.values.tolist()})\n\n\n\n\nconda.yml\n\nname: project_environment\nchannels:\n- conda-forge\ndependencies:\n- python=3.6.8\n- pip=20.2\n- pip:\n- azureml-defaults\n- azureml-designer-classic-modules==0.0.161\n- azureml-designer-serving==0.0.10\n- azureml-core==1.36.0\n\n\n\n\n\np.s. real-time endpoint doesn't ask for conda file during deployment.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-31T18:52:40.47Z",
                "Answer_score":0,
                "Answer_body":"This happened to me when I did not set the workspace well as the first and second part in the document. You need to check if your ws has everything as the QuickStart. Prepare the env then run the code.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Anyways to have multiple webservice output?",
        "Question_creation_time":1653904138797,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/869627\/anyways-to-have-multiple-webservice-output.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Is training two web service at the same time doable in studio ? Since I want to train with multiple models but it seems only one would work",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-30T22:54:40.947Z",
                "Answer_score":0,
                "Answer_body":"Hello @carter-5275\n\nThanks for reaching out to us. If you are asking about studio classic, for your question, quick answer is Yes.\n\nWhat you need to do is, using the \"save as train model\" function to save your models so that you could use it directly in the future. Both studio classic and studio can do it.\n\nThen you can pull all saved models you want to use to your structure so that you can have multi-webservice directly in the studio.\n\nIf you are asking studio, the answer is yes as well. What you need to do is only drag another webservice output directly to you structure.\n\nI hope this helps.\n\nRegards,\nYutong\n\n\n\n\n-Please kindly accept the answer if you feel helpful, thanks.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to predict train model time",
        "Question_creation_time":1653903513477,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/869641\/how-to-predict-train-model-time.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"How to predict the time for train model for data with 10 millions lines and zero columns with decision tree?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-30T20:34:28.677Z",
                "Answer_score":0,
                "Answer_body":"Hello @Jack-1854\n\nI am a little bit confused about your zero columns. Let's say x columns.\n\nFirst, I don't think there is an official way to estimate the time for now, since the data and the algorithms will both effect it. But for your model, you can absolutely estimat it by reudce the dataset as a test to see the time, like, you can give 10k data first to see how long the studio takes to train it, then you can estimate the time.\n\nPlease let me know if you are doing something special since you are mentioning zero column.\n\nI hope this helps.\n\nRegards,\nYutong\n\n\n\n\n-Please kindly accept the answer if you feel helpful to help the community, thanks.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Can't add modules to Pipeline Design (Azure)",
        "Question_creation_time":1653921047177,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/869925\/can39t-add-modules-to-pipeline-design-azure.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"I'm doing the training and I have to design a pipeline. However, when adding modules, in the components' column, only 2 modules show (web services related) when there should be at least 20. Of course, all filters are deactivated. I don't know why this happens but I can't continue my work.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Tensorflow and Azure machine learning",
        "Question_creation_time":1653989511207,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/871068\/tensorflow-and-azure-machine-learning.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Is azure working well with Tensorflow framework? I don\u2019t see any document about it. Any help is good.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-31T10:26:09.017Z",
                "Answer_score":1,
                "Answer_body":"Hello @Chungsun-1776\n\nWelcome to the Microsoft Q&A Platform,\n\nTensorFlow is supported on Azure Machine Learning:\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-tensorflow\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/azure-functions\/functions-machine-learning-tensorflow?tabs=bash\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-keras\n\nI hope this helps!\n\nPlease don\u2019t forget to \"Accept the answer\" and \u201cup-vote\u201d wherever the information provided helps you, this can be beneficial to other community members.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"azure machine learning SubscriptionNotFound",
        "Question_creation_time":1653319804270,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/860631\/azure-machine-learning-subscriptionnotfound.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I have created a workspace for azure machine learning and I am trying to create processes, but I get the following error: BatchARMResponseError:\n\n{\"error\":{\"code\": \"SubscriptionNotFound\", \"message\": \"The specified subscription XXXXXXXXXXXXXXXXXXXXXXXXXX is not found\"}}}\n\nRequest error with status code 500.\nat b (https:\/\/ml.azure.com\/static\/js\/index.29c4b58c.chunk.js)",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-24T18:43:13.09Z",
                "Answer_score":0,
                "Answer_body":"Hi @YutongTie-MSFT\n\nI was able to solve it, apparently the service does not have any availability in the region I chose first, I changed it and it is already working.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Run Python Script in Azure Machine Learning pipeline",
        "Question_creation_time":1652785260630,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/852593\/run-python-script-in-azure-machine-learning-pipeli.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hi\n\nI have a python script which will take parameters from Azure Data Factory and automatically register Datasets in Azure ML Workspace. I have already prepared this script. And I have run in the Notebooks and is working fine.\n\nI want to create a Pipeline in AML and call this python Script which will not have any input datasets and call this pipeline from ADF using PipelineID.\n\nBut when I am creating a Pipeline, system is showing default function azureml_main. I do not want to use this. How to solve this issue",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-31T09:35:36.767Z",
                "Answer_score":0,
                "Answer_body":"Python SDK is more flexible obviously. I was suffering from the complicated UI then back to SDK. You can publish model in SDk then back to studio.\n\nBut they do integrate useful thing.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Parallel training",
        "Question_creation_time":1653904605807,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/869619\/parallel-training.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Can I train models in parallel? Is is possible to train model in parallel on like hyperdrive?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-30T14:48:50.807Z",
                "Answer_score":0,
                "Answer_body":"@Chungsun-1776 Thanks for the question. The max number of parallel tasks is limited by number of cores in the cluster (excluding master node).\nThe demand for parallelism comes from two sources: 1. The cross validation which address multiple combination of train-val datasets & parameters 2. The training algorithm itself which can be parallelized.\n\n\u2022 You can run multiple runs in a distributed fashion across AML clusters, meaning that each cluster node can be running a run in parallel to other nodes running other runs. For instance, that\u2019s what we also do with Pipeline steps, HyperParameter Tunning child runs and for Azure AutoML child runs.\n\nhttps:\/\/aka.ms\/many-models is a solution accelerator that will help you walk through to run many models.\nIn the HyperDriveConfig there is AMLcompute max_concurrent_runs map to maximum number of nodes that will be used to run a hyperparameter tuning run. So there would be 1 execution per node.\n\n\n\n\nhttps:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-train-core\/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How to deploy pipeline in Azure ML Studio?",
        "Question_creation_time":1653529001740,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/864494\/how-to-deploy-pipeline-in-azure-ml-studio.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Doesn't seem to find the button for deploying pipeline...",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-31T09:14:09.033Z",
                "Answer_score":0,
                "Answer_body":"Hi\n\nI am a newbie and learning how to do it just now.\n\nYou should publish the pipeline then you are able to use it in Azure portal\n\nRead the document https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-pipelines#use-published-pipelines-in-the-studio",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Copy experiment within workspace",
        "Question_creation_time":1653905030690,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/869578\/copy-experiment-within-workspace.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"How to duplicate experiments within workspace during debugging",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-31T08:54:44.413Z",
                "Answer_score":0,
                "Answer_body":"Hello @Alexandre-4252\n\nAre you mentioning studio classic? You can click the save as buttion and then you can save the experience and duplicate it, if you are mentioning studio, sorry, you can not do that.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"inference pipeline option not available",
        "Question_creation_time":1626831334850,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/483466\/inference-pipeline-option-not-available.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":5,
        "Question_comment_count":0,
        "Question_follower_count":17,
        "Question_score":1,
        "Question_body":"After running the pipeline, I do not see the dropdown option for create inference pipeline, only the Run or clone option...any idea?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-21T17:07:26.3Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nI have the same issue. Since today. The day before yesterday, so Monday I had the option Inference pipeline in real-time but not anymore.\n\nI can't contact the support because I have only a student account.\n\nSomebody can help us please ?\n\nThx.",
                "Answer_comment_count":11,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-28T00:03:05.747Z",
                "Answer_score":1,
                "Answer_body":"@LuciaCasucci-9483 I just deleted your answer since it contains your private message. I will send out an email and cc you to product group with more details.\n\nCurrently, resubmit\/ clone\/ refresh the page all help for this issue. If anyone who has the same issue, may try those ways first to see if that works. Please let us know if you still have more question.\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-08-26T20:13:48.72Z",
                "Answer_score":1,
                "Answer_body":"This issue still exists. I had the option to create an Inference pipeline in real-time. When I chose that, there was a message about not being able to for some reason. After this, the option was no longer available.\n\nI cloned and refreshed the page, but the option is no longer available either in the cloned or the original pipeline. I don't want to re-submit, as this will incur more cost and take some time.\n\n@YutongTie-MSFT , is this a known issue we can track somewhere, or is the designer not being developed at this time?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-01-03T16:53:33.553Z",
                "Answer_score":0,
                "Answer_body":"I'm having the same issue where the option to create inference pipeline is not available. Even when i click the \"...\" the only option i have is to clone.\ni've tried refreshing and toggling back and forth from the designer page to my pipeline and it is still not available",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-20T02:11:20.1Z",
                "Answer_score":1,
                "Answer_body":"For all those who are having this same issue: it happened to me that, suddenly, the pipeline design page changed and, after this, the pipelines modules weren't and couldn't be sorted by type:\n\nHow it was before the change (according to Msft doc https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score):\n\nHow it is now after the change:\n\n\n\n\nOther consequence of the change was that the top right button 'Create inference pipeline' dissappeared:\n\nHow it was before the change (according to Msft doc https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy):\n\n\n\n\nAs consequence, after this sudden change, in order to be able to deploy a no-code machine learning model in Azure you have to go to the 'jobs' page and there you can find the 'Create inference pipeline' drop-down list:\n\n\n\n\nIt's a shame that after one year, no one in Microsoft have been able to answer this question satisfactorily and to solve this problem that, furthermore, is 'magically' generated by Azure from one moment to another... A lot of wanting to promote the no code tool but afterwards, when people get stucked (normally not deep tech people), no help at all.\n\nHope this answer can help to those who were lost like me.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML and ML.net which is better",
        "Question_creation_time":1653905877517,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/869589\/azure-ml-and-mlnet-which-is-better.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I am newly starting in machine learning field with basic training now.\nI am not sure about the difference and whichever should be used for beginner",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-30T14:36:14.097Z",
                "Answer_score":0,
                "Answer_body":"@Joel-9367 Thanks for the question. Azure ML is a cloud service where you pay for the compute power that you \"burn\" whereas ML.NET is a Toolkit for . net that you can run anywhere. You don't pay anything for using ML.NET itself.\n\nAzure ML Empower data scientists and developers to build, deploy, and manage high-quality models faster and with confidence. Here is the document for Azure ML.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Problems submittimg azure machine learning pipelines",
        "Question_creation_time":1653665897827,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/867306\/problems-submitimg-azure-machine-learning-pipeline.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I have a problem submitting my azure machine learning pipeline. I used the Import Data model to import data from a ULR via HTTP. When I clicked on submit, it submitted successfully with no green vertical line indication usually on the left side of the rectangular Import Data model. However, I got a green tick on the left pain that the job is completed. To continue building the pipeline, I added Select Columns in Dataset model to select the required columns. But as you can see from the screen shots, the select columns by name option is disabled and there are no names to select from.\nWhen I click the job details on the left pain on the Authoring page, it opens a read-only pipeline which cannot be edited. When I clone it, I am able to edit it but I am unable to add Select Columns in Dataset model to select the required columns as previously.\nI never experienced this problem with the Azure machine learning (Classic) or earlier versions of the Microsoft Azure Machine Learning Studio. I started experiencing this as soon as Microsoft changed the interface recently. Can someone please help me?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-30T08:18:39.733Z",
                "Answer_score":0,
                "Answer_body":"@EbenezerDansoAmoako-4939 Yes, with the change in UI the functionality to load the data from the downstream module is not being displayed, in this case it is select columns from dataset.\nYou can however enter the column names during authoring by first previewing the data from the import data module and note down the column names that needs to be added in downstream module.\n\nWe will pass the feedback of this change to the product team for review. Thanks!!\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Volume mount failed with: DataAccessError(PermissionDenied) Azure-ML",
        "Question_creation_time":1649877484300,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/811757\/volume-mount-failed-with-dataaccesserrorpermission.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I have created AzureML experiment where i am ingesting a dataset with azure SQL Server as source. below is the code.\n\n from azureml.core import Experiment, ScriptRunConfig, Environment\n input_data = ws.datasets.get('azure_sql_data')\n experiment_folder = 'experiment'\n env = Environment.from_conda_specification(\"env\", \"environment.yml\")\n script_config = ScriptRunConfig(source_directory=experiment_folder,\n                                 script='tranformer.py',\n                                 arguments = ['--input-data', input_data.as_named_input('input_data')],\n                                 environment=env)\n\n\n\nWhen i run this experiment i am getting following error. Dataset initialization failed: DataAccessError(PermissionDenied)\n\nAm i missing something here?\n\nI can access the azure SQL server data in while running it in aml notebook but when i run experiment i am getting above error.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Problem with connecting python script with web service output",
        "Question_creation_time":1653133927230,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/858550\/problem-with-connecting-python-script-with-web-ser.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":12,
        "Question_score":1,
        "Question_body":"Azure ML studio got new apperance and some problems happen. I did pipeline like this:\n\n\n\n\n\nand then created inference pipeline:\n\n\n\n\n\nI would like to connect python script like this(in the previous version on azure it works) to Web Service Output:\n\n\n\n\n\nBut when i submit it now the connection is changing and execution is not apply.\n\n\n\n\n\n\nHow to fix this issue?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-29T02:11:07.41Z",
                "Answer_score":0,
                "Answer_body":"@KamilaSoko-2127 I also got the same problem by following the same tutorial. Do you find any solution??",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Install and load Tidymodels package in AML",
        "Question_creation_time":1653509127043,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/864244\/install-and-load-tidymodels-package-in-aml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I'm trying install and load some R packages in the Execute R Script in Azure Machine Learning for to run models, such as tidymodels, timetk, modeltime, modeltime.ensemble.\n\n library(forecast)\n library(tidyverse)\n library(lubridate)\n install.packages(\"quantdates\",repos = \"https:\/\/cloud.r-project.org\")\n install.packages(\"tidymodels\",repos = \"https:\/\/cloud.r-project.org\")\n library(quantdates)\n library(tidymodels) \n library(timetk) \n library(modeltime) \n library(modeltime.resample) \n library(modeltime.ensemble)\n\n\n\nHowever I get the following error:\n\n Error: package or namespace load failed for \u2018tidymodels\u2019 in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):\n namespace \u2018rlang\u2019 0.4.5 is already loaded, but >= 1.0.2 is required\n azureml_main(input_dataframe_1), library(tidymodels), tryCatch({\n     attr(package, \"LibPath\") <- which.lib.loc\n     ns <- loadNamespace(package, lib.loc)\n     env <- attachNamespace(ns, pos = pos, deps)\n }, error = function(e) {\n     P <- if (!is.null(cc <- conditionCall(e))) \n         paste(\" in\", deparse(cc)[1])\n     else \"\"\n     msg <- gettextf(\"package or namespace load failed for %s%s:\\n %s\", sQuote(package), P, conditionMessage(e))\n     if (logical.return) \n         message(paste(\"Error:\", msg), domain = NA)\n     else stop(msg, call. = FALSE, domain = NA)\n }), tryCatchList(expr, classes, parentenv, handlers), tryCatchOne(expr, names, parentenv, handlers[[1]]), value[[3]](cond), stop(msg, call. = FALSE, domain = NA), .handleSimpleError(function (e) \n {\n     error_msg <<- paste(toString(e), toString(sys.calls()[-c(1:3)]), sep = \"\\n\")\n     stop(e)\n }, \"package or namespace load failed for \u2018tidymodels\u2019 in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):\\n namespace \u2018rlang\u2019 0.4.5 is already loaded, but >= 1.0.2 is required\", quote(NULL)), h(simpleError(msg, call))\n '.\n ---------- End of error message from R  interpreter  ----------\n\n\n\nI have also tried with devtools package for install a particular version but I keep getting the same error with the rlang package. Sometimes, I get the same error with the cli package.\n\nIn my local machine, the R code runs fine. I have the R version 4.1.3 and the Azure Machine Learning has the R version 3.5.1.\n\nDoes anyone know how I can solve this problem?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-26T10:49:40.953Z",
                "Answer_score":0,
                "Answer_body":"@JeanPaulPiedrahitaGarca-3958 I think the reason that tidymodels failed to install is because it is built on windows as per the Description file of the package.\n\n Built: R 4.2.0; ; 2022-05-24 05:31:20 UTC; windows\n\n\n\nThe note and warning section of Installing R packages from documentation details the way to check if a package can be installed with the Execute R script module.\n\nDo not install packages which are pre-built on\/for Windows, since the designer components are running on Ubuntu. To check whether a package is pre-built on windows, you could go to CRAN and search your package, download one binary file according to your OS, and check Built: part in the DESCRIPTION file.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-27T13:25:28.763Z",
                "Answer_score":1,
                "Answer_body":"@romungi-MSFT After everything I've managed to consult, I think the problem is in the R version 3.5.1: tidymodels package require a rlang version package greater than o equal to 1.0.2. However, the rlang version 1.0.2 only works for R versions starting from 4.0.0:\n\n        Package  Version  Published\n 96           R    3.5.1 2018-07-02\n 97  tidymodels    0.0.1 2018-07-27\n 98       rlang    0.2.2 2018-08-16\n 99       rlang    0.3.0 2018-10-22\n 100      rlang  0.3.0.1 2018-10-25\n 101 tidymodels    0.0.2 2018-11-27\n 102          R    3.5.2 2018-12-20\n 103      rlang    0.3.1 2019-01-08\n 104          R    3.5.3 2019-03-11\n 105      rlang    0.3.2 2019-03-21\n 106      rlang    0.3.3 2019-03-29\n 107      rlang    0.3.4 2019-04-07\n 108          R    3.6.0 2019-04-26\n 109      rlang    0.4.0 2019-06-25\n 110          R    3.6.1 2019-07-05\n 111 tidymodels    0.0.3 2019-10-04\n 112      rlang    0.4.1 2019-10-24\n 113      rlang    0.4.2 2019-11-23\n 114          R    3.6.2 2019-12-12\n 115      rlang    0.4.3 2020-01-24\n 116      rlang    0.4.4 2020-01-28\n 117 tidymodels    0.1.0 2020-02-16\n 118          R    3.6.3 2020-02-29\n 119      rlang    0.4.5 2020-03-01\n 120          R    4.0.0 2020-04-24\n 121      rlang    0.4.6 2020-05-02\n 122          R    4.0.1 2020-06-06\n 123          R    4.0.2 2020-06-22\n 124      rlang    0.4.7 2020-07-09\n 125 tidymodels    0.1.1 2020-07-14\n 126      rlang    0.4.8 2020-10-08\n 127          R    4.0.3 2020-10-10\n 128 tidymodels    0.1.2 2020-11-22\n 129      rlang    0.4.9 2020-11-26\n 130      rlang   0.4.10 2020-12-30\n 131          R    4.0.4 2021-02-15\n 132          R    4.0.5 2021-03-31\n 133 tidymodels    0.1.3 2021-04-19\n 134      rlang   0.4.11 2021-04-30\n 135          R    4.1.0 2021-05-18\n 136          R    4.1.1 2021-08-10\n 137 tidymodels    0.1.4 2021-10-01\n 138      rlang   0.4.12 2021-10-18\n 139      rlang    1.0.0 2022-01-26\n 140      rlang    1.0.1 2022-02-03\n 141      rlang    1.0.2 2022-03-04\n 142 tidymodels    0.2.0 2022-03-19\n\n\n\nFor this reason, in the AML only loaded (or manages to load) the rlang version 0.4.5, which the last compatible version for R 3.0.0. The rlang version 1.0.2 only is compatible for R 4.0.0. I wish there was a possibility that AML had a more recent version of R. Thank you again.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Web Service - An existing connection was forcibly closed by the remote host",
        "Question_creation_time":1653362218797,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/861245\/azure-ml-web-service-an-existing-connection-was-fo.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I have some Azure ML Web services (Machine Learning Studio (classic) workspace) that have just stopped responding. I haven't changed anything on my end. The error suggests I might have ran out of credit or something but the service scales automatically. This is a business-critical service that has just stopped responding...\n\nI've tried redeploying the services but I still get the same error. I also tried 'Deploy Service [New] Preview' but I get another error:\n\"Web Service deployment failed. This account does not have sufficient access to the Azure subscription that contains the Workspace. In order to deploy a Web Service to Azure, the same account must be invited to the Workspace and be given access to the Azure subscription that contains the Workspace.\"- even though I am logged in on the correct account.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-25T01:42:46.7Z",
                "Answer_score":1,
                "Answer_body":"Thanks @romungi-MSFT ,\n\nI had raised a support ticket and the issue is now resolved though neither the agent, nor myself, changed anything...\n\nI did just pay my overdue bill for last month but I would expect a warning before services a turned off for an overdue bill.\nHopefully it doesn't happen again!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Predictions on new data with a deployed ML model as a pipeline - problem with data input format",
        "Question_creation_time":1653475763427,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/863614\/predictions-on-new-data-with-a-deployed-ml-model-a.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"My question is somehow related to https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/217305\/data-input-format-call-the-service-for-azure-ml-ti.html - however, the provided solution does not seem to work.\n\nI am constructing a simple model with heart-disease dataset but I wrap it into Pipeline as I use some featurization steps (scaling, encoding etc.) The full script below:\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport joblib\nimport pickle\n# data input\ndf = pd.read_csv('heart.csv')\n# numerical variables\nnum_cols = ['age',\n            'trestbps',\n            'chol',\n            'thalach',\n            'oldpeak'\n]\n# categorical variables\ncat_cols = ['sex',\n            'cp',\n            'fbs',\n            'restecg',\n            'exang',\n            'slope',\n            'ca',\n            'thal']\n# changing format of the categorical variables\ndf[cat_cols] = df[cat_cols].apply(lambda x: x.astype('object'))\n# target variable\ny = df['target']\n# features\nX = df.drop(['target'], axis=1)\n# data split:\n# random seed\nnp.random.seed(42)\n# splitting the data\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size=0.2,\n                                                    stratify=y)\n# double check\nX_train.shape, X_test.shape, y_train.shape, y_test.shape\n# pipeline for numerical data\nnum_preprocessing = Pipeline([('num_imputer', SimpleImputer(strategy='mean')), # imputing with mean\n                                                   ('minmaxscaler', MinMaxScaler())]) # scaling\n# pipeline for categorical data\ncat_preprocessing = Pipeline([('cat_imputer', SimpleImputer(strategy='constant', fill_value='missing')), # filling missing values\n                                                ('onehot', OneHotEncoder(drop='first', handle_unknown='error'))]) # One Hot Encoding\n# preprocessor - combining pipelines\npreprocessor = ColumnTransformer([\n                                                           ('categorical', cat_preprocessing, cat_cols),\n                                                           ('numerical', num_preprocessing, num_cols)\n                                                           ])\n# initial model parameters\nlog_ini_params = {'penalty': 'l2', \n                  'tol': 0.0073559740277086005, \n                  'C': 1.1592424247511928, \n                  'fit_intercept': True, \n                  'solver': 'liblinear'}\n# model - Pipeline\nlog_clf = Pipeline([('preprocessor', preprocessor),\n                  ('clf', LogisticRegression(**log_ini_params))])\nlog_clf.fit(X_train, y_train)\n# dumping the model\nf = 'model\/log.pkl'\nwith open(f, 'wb') as file:\n    pickle.dump(log_clf, file)\n# loading it\nloaded_model = joblib.load(f)\n# double check on a single datapoint\nnew_data = pd.DataFrame({'age': 71,\n                                            'sex': 0,\n                                            'cp': 0,\n                                            'trestbps': 112,\n                                            'chol': 203,\n                                            'fbs': 0,\n                                            'restecg': 1,\n                                            'thalach': 185,\n                                            'exang': 0,\n                                            'oldpeak': 0.1,\n                                            'slope': 2,\n                                            'ca': 0,\n                                            'thal': 2\n                                            }, index=[0])\nloaded_model.predict(new_data)\n\n\n\n\n...and it works just fine. Then I deploy the model to the Azure Web Service using these steps:\n\nI create the score.py file\n\nimport joblib\nfrom azureml.core.model import Model\nimport json\ndef init():\n    global model\n    model_path = Model.get_model_path('log') # logistic\n    print('Model Path is  ', model_path)\n    model = joblib.load(model_path)\ndef run(data):\n    try:\n        data = json.loads(data)\n        result = model.predict(data['data'])\n        # any data type, as long as it is JSON serializable.\n        return {'data' : result.tolist() , 'message' : 'Successfully classified heart diseases'}\n    except Exception as e:\n        error = str(e)\n        return {'data' : error , 'message' : 'Failed to classify heart diseases'}\n\n\n\n\nI deploy the model:\n\nfrom azureml.core import Workspace\nfrom azureml.core.webservice import AciWebservice\nfrom azureml.core.webservice import Webservice\nfrom azureml.core.model import InferenceConfig\nfrom azureml.core.environment import Environment\nfrom azureml.core import Workspace\nfrom azureml.core.model import Model\nfrom azureml.core.conda_dependencies import CondaDependencies\nws = Workspace.from_config()\nmodel = Model.register(workspace = ws,\n              model_path ='model\/log.pkl',\n              model_name = 'log',\n              tags = {'version': '1'},\n              description = 'Heart disease classification',\n              )\n# to install required packages\nenv = Environment('env')\ncd = CondaDependencies.create(pip_packages=['pandas==1.1.5', 'azureml-defaults','joblib==0.17.0'], conda_packages = ['scikit-learn==0.23.2'])\nenv.python.conda_dependencies = cd\n# Register environment to re-use later\nenv.register(workspace = ws)\nprint('Registered Environment')\nmyenv = Environment.get(workspace=ws, name='env')\nmyenv.save_to_directory('.\/environ', overwrite=True)\naciconfig = AciWebservice.deploy_configuration(\n            cpu_cores=1,\n            memory_gb=1,\n            tags={'data':'heart disease classifier'},\n            description='Classification of heart diseases',\n            )\ninference_config = InferenceConfig(entry_script='score.py', environment=myenv)\nservice = Model.deploy(workspace=ws,\n                name='hd-model-log',\n                models=[model],\n                inference_config=inference_config,\n                deployment_config=aciconfig, \n                overwrite = True)\nservice.wait_for_deployment(show_output=True)\nurl = service.scoring_uri\nprint(url)\n\n\n\n\nThe deployment is succeded:\n\nSucceeded\nACI service creation operation finished, operation \"Succeeded\"\n\nBut I can not make any predictions with the new data. I try to use:\n\nimport pandas as pd\nnew_data = pd.DataFrame([[71, 0, 0, 112, 203, 0, 1, 185, 0, 0.1, 2, 0, 2],\n                                             [80, 0, 0, 115, 203, 0, 1, 185, 0, 0.1, 2, 0, 0]],\n                                            columns=['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal'])\n\n\n\n\nFollowing the answer from this topic (https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/217305\/data-input-format-call-the-service-for-azure-ml-ti.html) I transform the data:\n\ntest_sample = json.dumps({'data': new_data.to_dict(orient='records')})\n\n\n\nAnd try to make some predictions:\n\nimport json\nimport requests\ndata = test_sample\nheaders = {'Content-Type':'application\/json'}\nr = requests.post(url, data=data, headers = headers)\nprint(r.status_code)\nprint(r.json())\n\n\n\n\nHowever, I encounter an error:\n\n200\n{'data': \"Expected 2D array, got 1D array instead:\\narray=[{'age': 71, 'sex': 0, 'cp': 0, 'trestbps': 112, 'chol': 203, 'fbs': 0, 'restecg': 1, 'thalach': 185, 'exang': 0, 'oldpeak': 0.1, 'slope': 2, 'ca': 0, 'thal': > 2}\\n {'age': 80, 'sex': 0, 'cp': 0, 'trestbps': 115, 'chol': 203, 'fbs': 0, 'restecg': 1, 'thalach': 185, 'exang': 0, 'oldpeak': 0.1, 'slope': 2, 'ca': 0, 'thal': 0}].\\nReshape your data either using array.reshape(-1, > 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\", 'message': 'Failed to classify heart diseases'}\n\nHow is it possible to adjust the input data to this form of predictions and add other output like predict_proba so I could store them in a separate output dataset?\n\nI know this error is somehow related either with the \"run\" part of the score.py file or the last code cell that calls the webservice, but I'm unable to find it.\n\nBest!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-26T09:53:19.373Z",
                "Answer_score":1,
                "Answer_body":"I believe I managed to solve the problem - even though I encountered some serious issues. :) However - I would still use some info from the community expert to have an idea if this solution is acceptable!\n\nAs described here here - I edited the score.py script:\n\nimport joblib\nfrom azureml.core.model import Model\nimport numpy as np\nimport json\nimport pandas as pd\nimport numpy as np\nfrom inference_schema.schema_decorators import input_schema, output_schema\nfrom inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\nfrom inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\nfrom inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType\n    \ndata_sample = PandasParameterType(pd.DataFrame({'age': pd.Series([0], dtype='int64'),\n                                                'sex': pd.Series(['example_value'], dtype='object'),\n                                                'cp': pd.Series(['example_value'], dtype='object'),\n                                                'trestbps': pd.Series([0], dtype='int64'),\n                                                'chol': pd.Series([0], dtype='int64'),\n                                                'fbs': pd.Series(['example_value'], dtype='object'),\n                                                'restecg': pd.Series(['example_value'], dtype='object'),\n                                                'thalach': pd.Series([0], dtype='int64'),\n                                                'exang': pd.Series(['example_value'], dtype='object'),\n                                                'oldpeak': pd.Series([0.0], dtype='float64'),\n                                                'slope': pd.Series(['example_value'], dtype='object'),\n                                                'ca': pd.Series(['example_value'], dtype='object'),\n                                                'thal': pd.Series(['example_value'], dtype='object')}))\ninput_sample = StandardPythonParameterType({'data': data_sample})\nresult_sample = NumpyParameterType(np.array([0]))\noutput_sample = StandardPythonParameterType({'Results':result_sample})\ndef init():\n    global model\n    # Example when the model is a file\n    model_path = Model.get_model_path('log') # logistic\n    print('Model Path is  ', model_path)\n    model = joblib.load(model_path)\n@input_schema('Inputs', input_sample)\n@output_schema(output_sample)\ndef run(Inputs):\n    try:\n        data = Inputs['data']\n        result = model.predict_proba(data)\n        return result.tolist()\n    except Exception as e:\n        error = str(e)\n        return error\n\n\n\n\nIn the deployment step I adjusted the CondaDependencies:\n\n# to install required packages\nenv = Environment('env')\ncd = CondaDependencies.create(pip_packages=['pandas==1.1.5', 'azureml-defaults','joblib==0.17.0', 'inference-schema==1.3.0'], conda_packages = ['scikit-learn==0.22.2.post1'])\nenv.python.conda_dependencies = cd\n# Register environment to re-use later\nenv.register(workspace = ws)\nprint('Registered Environment')\n\n\n\n\nas\n\na) It is necessary to include inference-schema in the Dependencies file\nb) I downgraded scikit-learn to scikit-learn==0.22.2.post1 version because of this issue\n\nNow, when I feed the model with new data:\n\nnew_data = {\n  \"Inputs\": {\n    \"data\": [\n      {\n        \"age\": 71,\n        \"sex\": \"0\",\n        \"cp\": \"0\",\n        \"trestbps\": 112,\n        \"chol\": 203,\n        \"fbs\": \"0\",\n        \"restecg\": \"1\",\n        \"thalach\": 185,\n        \"exang\": \"0\",\n        \"oldpeak\": 0.1,\n        \"slope\": \"2\",\n        \"ca\": \"0\",\n        \"thal\": \"2\"\n      }\n    ]\n  }\n}\n\n\n\n\nAnd use it for prediction:\n\nimport json\nimport requests\ndata = new_data\nheaders = {'Content-Type':'application\/json'}\nr = requests.post(url, str.encode(json.dumps(data)), headers = headers)\nprint(r.status_code)\nprint(r.json())\n\n\n\n\nI get:\n\n200 [[0.02325369841858338, 0.9767463015814166]]\n\nUff! Maybe someone will benefit from my painful learning path! :)",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Accessing different model versions from same endpoint",
        "Question_creation_time":1653539509343,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/864579\/accessing-different-model-versions-from-same-endpo.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I am using model versioning and would like to have different model versions accessible via the same endpoint. Any best practices to access the multiple models from the same endpoint.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-26T07:43:19.48Z",
                "Answer_score":0,
                "Answer_body":"@Srin-4824 Thanks, You may deploy \u201clocally\u201d to a Azure Machine Learning compute instance, by specifying different port # for each version. They are converted to a URL according to the format https:\/\/<compute instance\u2019s name>-port.region.instances.azureml.ms\/score\n\nModel v1: service_url = https:\/\/azure-ml-compute-instance-name-8001.westeurope.instances.azureml.ms\/score\nModel v2: service_url = https:\/\/ azure-ml-compute-instance-name-8002.westeurope.instances.azureml.ms\/score\n\nThere\u2019s sample code in documentation. You can specify port to deploy with the following parameter.\ndeployment_config = LocalWebservice.deploy_configuration(port=8001)\n\nWe recommend using the new ML Endpoints (Preview) What are endpoints (preview) - Azure Machine Learning | Microsoft Docs.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Run dataset.register method multiple Times",
        "Question_creation_time":1653460894327,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/863226\/run-datasetregister-method-multiple-times.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi\n\nI am using the following code to register the dataset.\ndataset.register(\nworkspace = ws,\nname = dataset_name,\ntags = tags,\ncreate_new_version = True,\ndescription = \"\"\n)\n\nWhen I use the above for the first time too create a dataset , a new version is creation which is version 1. But when I re-run the same command again, one more new version is not created like version 2 is not created. Why? For the second-run my Data is same, Tags are same.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-26T03:03:28.543Z",
                "Answer_score":1,
                "Answer_body":"@KrishnamohanNadimpalli-6337 Thanks for the question. Dataset is a reference to the files to your data in storage.\n\nPlease follow the document to register dataset as version. Still facing an issue add more details about the error.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML workspace authorization failing when running via pipeline - OAuth 2.0 device flow error",
        "Question_creation_time":1653103826547,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/858468\/azure-ml-workspace-authorization-failing-when-runn-1.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I followed the instructions here: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-machine-learning-pipelines to publish and run a pipeline.\n\nBut the pipeline steps throws the following error:\n\n\"error\": {\n\"message\": \"AADSTS70016: OAuth 2.0 device flow error. Authorization is pending. Continue polling. Timestamp: 2022-05-20 18:17:51Z\"\n}\n\n\n\n\nFrom the error message, it looks like the pipeline step is stuck at the 'interactive authorization' step and timesout after 900.0 sec.\n\nAt the moment we are just testing this in lower environment, hence I have not used service principal for authorization.\n\nCan someone please suggest how to fix this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-24T07:37:20.3Z",
                "Answer_score":0,
                "Answer_body":"@tender-honey Thanks for the details. We are able to successfully authenticate. Interactive authentication uses your browser, and requires cookies (including 3rd party cookies). If you have disabled cookies. The error may also occur if you have enabled Azure AD Multi-Factor Authentication.\n\nPlease follow the document to setup authentication.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-25T23:21:03.047Z",
                "Answer_score":0,
                "Answer_body":"@ramr-msft - I ended up using a service principal to authenticate. Still not sure how to use interactive authorization in pipelines.\n\nBut now I am stuck at another point, below is the code for my pipeline:\n\n*datastore_name = 'tmp'\ndatastore = Datastore.get(workspace, datastore_name)\nstep1_output_data = OutputFileDatasetConfig(name=\"step1_output_data\", destination=(datastore, \"{run-id}\/\"))\ncurated_env_name = 'my-env'\npytorch_env = Environment.from_conda_specification(name=curated_env_name, file_path='.\/conda_dependencies.yml')\ncluster_name = 'cpu64'\n\nsrc = ScriptRunConfig(\nsource_directory='..\/..\/python-pipeline',\nscript=\"1.py\",\ncompute_target=cluster_name,\nenvironment=pytorch_env,\n)\n\nstep_1 = PythonScriptStep(\nname=\"step_1\",\nscript_name=\"1.py\",\nsource_directory='..\/..\/python-pipeline',\ncompute_target=cluster_name,\narguments=[step1_output_data],\nallow_reuse=True,\nrunconfig=src.run_config,\n)\n\nstep_2 = PythonScriptStep(\nname=\"step_2\",\nscript_name=\"2.py\",\nsource_directory='..\/..\/python-pipeline',\ncompute_target=cluster_name,\narguments=[step1_output_data.as_input(name='step1_output_data')],\nallow_reuse=True,\n)*\n\nWhen I run the above pipeline, the step_1 shows complete, BUT when I read through the logs, i see this:\n\n{\"FileSystemName\":\"data\",\"Uri\":null,\"Account\":\"storage_acc_name\",\"RelativePath\":\"6666666-8888-4444-bbbb-fffffffffffff\/step1_output_data\",\"PathType\":0,\"AmlDataStoreName\":\"tmp\"}\n\nI would expect this step1_output_data to be written out in the adls gen 2, but as the URI above is null, it is not writing anything.\n\nAnd as a result of this, step_2 fails with :\n\n\"error\": {\n\"code\": \"UserError\",\n\"message\": \"Cannot mount Dataset(id='6666666-8888-4444-bbbb-fffffffffffff', name='None', version=None). Error Message: DataAccessError(NotFound)\"\n}",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Studio Failed to Authenticate to the compute",
        "Question_creation_time":1632489823347,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/565326\/azure-ml-studio-failed-to-authenticate-to-the-comp.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":12,
        "Question_comment_count":10,
        "Question_follower_count":21,
        "Question_score":4,
        "Question_body":"Hi,\n\nI have created a compute in my ML Studio and was running it for hours. However, it suddenly disconnected, and when I signed back in, it shows that \"\nYou need to be authenticated to the compute to use any Azure SDK. Please use the authenticate button to get authenticated.\" But when I click the authenticate button, I got an error with the message saying \"InternalServerError\".\n\nI have tried to sign out and sign back in, delete the current compute and create a new one. Neither worked.\n\nDoes anybody have any suggestions on this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-25T19:45:40.31Z",
                "Answer_score":0,
                "Answer_body":"same issue",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-26T05:26:28.03Z",
                "Answer_score":0,
                "Answer_body":"Im also facing similar issue. when opened the notebook in vscode, i was able to authenticate and run.",
                "Answer_comment_count":5,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-27T13:49:18.34Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nI am also facing this issue. I am prompt to Authentic to use the cluster and later I am getting below error: \"We couldn't sign you in. Please try again.\"",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-27T20:07:28.897Z",
                "Answer_score":0,
                "Answer_body":"Hi Ms Team,\n\nI am facing the Same Issue.\n\nAny Idea??",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-28T03:43:40.357Z",
                "Answer_score":0,
                "Answer_body":"Same issue.\nAny one provide solution for above error.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-28T18:01:08.687Z",
                "Answer_score":1,
                "Answer_body":"I am having the same issue.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-29T02:00:51.95Z",
                "Answer_score":0,
                "Answer_body":"I have the same issue here. Region is EastUS",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-29T18:56:24.713Z",
                "Answer_score":0,
                "Answer_body":"Same issue, can't even open the terminal",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-29T19:01:46.253Z",
                "Answer_score":0,
                "Answer_body":"@GiftA-MSFT - can you provide us an update?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-30T15:20:01.827Z",
                "Answer_score":0,
                "Answer_body":"Same issue for myself, cant run a compute instance even with an upgrade. It is also East coast. Any idea when it will be running properly?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Compute Instance Keeps Failing on Azure Machine Learning",
        "Question_creation_time":1653284199793,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/859594\/compute-instance-keeps-failing-on-azure-machine-le.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_follower_count":20,
        "Question_score":0,
        "Question_body":"I am new to Azure Machine Learning. I created a new workspace on Azure Machine Learning Studio and ran Compute Instance, but it keeps failing. I tried recreating the Compute Instances and Workspaces, but I keep getting the following error:\n\nProvisioning error\n{\"error\":{\"code\":\"SubscriptionRegistrationIsNotFinished\",\"message\":\"The subscription xxxx-xxxx-xxxx-xxxx-xxxxxxx is being registered, please wait for its completion and retry later.\"}}\n\nAs the error message seems to indicate that there is an issue with my subscription, but when I look at my subscriptions, they look to be properly registered. Does anyone have any suggestions on how to resolve this issue?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-24T03:11:23.53Z",
                "Answer_score":0,
                "Answer_body":"@LopezMarissa-8427 Thanks for the details. Migration hotfix rolled out. Wait for some time, the subscription registration will finish and then you can retry.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"UserScriptFilledDisk - what disk?",
        "Question_creation_time":1617995934433,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/351791\/userscriptfilleddisk-what-disk.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"I am using AZ Machine Learning and have been running python scripts on VMs to train mnist and output some summary statistics on the trained networks. It worked fine for the first few jobs, but when I submitted a few more, all of them failed with a USerScriptFilledDisk error:\n\n\"UserError: AzureMLCompute job failed. UserScriptFilledDisk: User script filled the disk. Consider using VM SKU with larger disk size. If the issue persists contact Azure Support.\"\n\nI am using nodes with only 7GB disk space, but it still does not make sense to me that I should have exceeded that just with mounting mnist and writing less than 1MB of numpy arrays to '.\/outputs\/'. The problem does not seem to be specific to any one or few nodes on my cluster. I made a new cluster and tried running my scripts on it. It still throws the same error. So how can I find out what disk I have filled up and how do fix it and keep it from happening again?\n\nThanks in advance!\n\nMore details:\n\nI created an Azure machine learning compute cluster\n\n compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpu-main1\")\n compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 100)\n vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_DS1_V2\")\n    \n if compute_name in ws.compute_targets:\n     compute_target = ws.compute_targets[compute_name]\n else:\n     provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n                                                                 min_nodes = compute_min_nodes, \n                                                                 max_nodes = compute_max_nodes)\n    \n     compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)    \n     compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n\n\n\nI added a data set\n\n workspace = Workspace(subscription_id, resource_group, workspace_name)\n dataset = Dataset.get_by_name(workspace, name='mnist_zip')\n dataset.download(target_path='.', overwrite=True)\n dataset = dataset.register(workspace=ws,\n                            name='mnist_zip',\n                            description='zip file with preprocesses mnist data set',\n                            create_new_version=False)\n\n\n\nI submitted jobs to the cluster\n\n runs = [ 0 for _ in range(30)]\n for i in range(30):\n     args = ['--dataset', dataset.as_mount(), '--id', i] \n     #also tried '.as_download()' - did not seem to make a difference\n     src = ScriptRunConfig(source_directory=script_folder,\n                           script='script.py', \n                           arguments=args,\n                           compute_target=compute_target,\n                           environment=env)\n     runs[i] = exp.submit(config=src)",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-27T04:22:07.893Z",
                "Answer_score":0,
                "Answer_body":"@schwarze-7702 Thanks for the details. We would recommend to raise a Azure support desk ticket from Help+Support blade from Azure portal for your resource. This will help you to share the details securely and work with an engineer who can provide more insights about the issue that if it can be replicated.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-25T09:24:54.727Z",
                "Answer_score":0,
                "Answer_body":"Is there any update regarding this question? I experience the same issue, I am trying to register the dataset and UserScriptFilledDisk error occurs without any specific reason during the operation",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Compute Instances - SubscriptionRegistrationIsNotFinished",
        "Question_creation_time":1653323984290,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/860702\/compute-instances-subscriptionregistrationisnotfin.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":7,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"I created a new workspace on Azure Machine Learning Studio and ran Compute Instance, but it keeps failing. I tried recreating the Compute Instances and Workspaces, but I keep getting the following error:\n\n{\"error\":{\"code\":\"SubscriptionRegistrationIsNotFinished\",\"message\":\"The subscription xxxxxxx-ffc4-452e-9cb7-40c706e8738f is being registered, please wait for its completion and retry later.\"}}\n\nAs the error message seems to indicate that there is an issue with my subscription, but when I look at my subscriptions, they look to be properly registered. Does anyone have any suggestions on how to resolve this issue?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How to use MLFlow models with managed endpoints and private pip",
        "Question_creation_time":1650549331407,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/821194\/how-to-use-mlflow-models-with-managed-endpoints-an.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"How do you create a batch endpoint using an MLFlow with a private package installed via a private pip?\n\nI have tried multiple ways (see this github issue: https:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/22441#issuecomment-1104082706) but I'm not really getting anywhere.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-02T16:04:56.39Z",
                "Answer_score":0,
                "Answer_body":"Is this doable? I explored several times but all failed.\n\nCan Microsoft add documentation about that?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Mount AML dataset on Windows",
        "Question_creation_time":1653326462743,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/860774\/mount-aml-dataset-on-windows.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I came across this page which describes how to work with AML datasets. I'm specifically interested in mounting. It states that \"Mounting is supported for Linux-based computes\". Is there no way to do this on Windows?\n\nThanks,\nYordan",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-24T08:59:57.127Z",
                "Answer_score":1,
                "Answer_body":"@YordanZaykov-7763 Yes, currently this is only supported for linux based computes for Azure ML. Windows only supports download option.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Deploy inference pipeline with Cross Validate Model component",
        "Question_creation_time":1652979147437,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/856618\/deploy-inference-pipeline-with-cross-validate-mode.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"In Azure ML Studio I have created a pipeline that uses the Cross Validate Model component. According to the reference docs:\n(https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/component-reference\/cross-validate-model#how-to-use-cross-validate-model)\nthis component trains the model multiple times. Now that I have run the pipeline successfully, I'd like to create an inference pipeline. Unfortunately, regardless of the type of inference pipeline I choose (\"real time\" or \"batch\") I receive the following message and I don't understand WHY as I have trained the model using the cross validate model component. I am new so if I'm missing something \"intuitively obvious\" I accept that...just need to move my project forward. Thanks in advance for your help!\n\nBelow is my full pipeline:",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-22T15:57:15.453Z",
                "Answer_score":0,
                "Answer_body":"@FrankFazekas-6682 Thanks for the question. Please share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Recommended way to get to know the location of various folders within a Docker image",
        "Question_creation_time":1646753339290,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/763779\/recommended-way-to-get-to-know-the-location-of-var.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I am creating a pipeline in Azure Machine Learning Studio. The pipeline consists of various steps of the type \"PythonScriptStep\". In each step I need to read from the input data and write data to the defined output folder of the type \"PipelineData\".\n\nUntil yesterday, I used the environment variables of the build docker image to get to know various locations, e.g. the location of the \"wd\"-directoy.\nThe directory folder path of the \"wd\"-directoy was stored in the environment variable 'AZ_BATCHAI_JOB_TEMP'. Now, as it seems to me, the environment variable name has been changed. The directory folder path of the \"wd\"-directoy can now be found in the environment variable 'AZUREML_CR_DATA_CAPABILITY_PATH'.\n\nThe environment variable 'AZ_BATCHAI_JOB_MOUNT_ROOT' has been removed completely.\n\nSince environment variable names are changing from one day to another and are not constant, I would like to ask for the recommended way to get to know the location of various folders within the Docker image.\n\n\n\n\nWith best regards\nAlexander Pakakis",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-09T09:25:59.46Z",
                "Answer_score":0,
                "Answer_body":"@AlexanderPakakis-0994 Thanks for the question. The most basic way to achieve this is to use PipelineData and specify the output as a directory.\nfrom azureml.pipeline.core import PipelineData\noutput_dir = PipelineData(\nname=\"output_dir\",\ndatastore=pipeline_datastore,\npipeline_output_name=\"output_dir\",\nis_directory=True,\n)\n\nOutputFileDatasetConfig very powerful, Here is how It can be used for pipelines:\n\nfrom azureml.core import ScriptRunConfig, Experiment\nfrom azureml.data import OutputFileDatasetConfig\noutput_port = OutputFileDatasetConfig(\ndestination=(def_data_store, \"outputs\/test_diroutputFileDatasetConfig\/\"), name=\"dir_test\"\n)\n\n\n\n\nexperiment = Experiment(ws, 'MyExperiment')\nconfig = ScriptRunConfig(source_directory='modules\/test_output_dir\/',\nscript='copy.py',\narguments = ['--output',\noutput_port],\ncompute_target=\"local\")\nscript_run = experiment.submit(config)",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Question about ML output",
        "Question_creation_time":1650351269333,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/817010\/question-about-ml-output.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Dear Support,\n\nI have draft a pipeline as following:\n\n\n\n\n\n\nyou can see it has 2 webservice output,\n\nmay I know where I can see the 2 output and how to use it ? thnaks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-20T02:33:37.447Z",
                "Answer_score":0,
                "Answer_body":"@SeiyaZelinShen-9380 Thanks for the question. Can you please share the sample link that you are trying.\n\nHere is the document for web service output. Did you deploy the inference pipeline, if yes After deployment finishes, you can view your real-time endpoint by going to the Endpoints page.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML deployment fails",
        "Question_creation_time":1644780118307,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/733521\/azure-ml-deployment-fails.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I'm trying to deploy an ML model as a WebService using Azure ML Endpoints, but it fails. Below is the code and the error I get. I'm using azureml-core SDK for this.\n\n\n\n\nI'm using this link as a reference for my deployment:\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/deployment\/deploy-multi-model\/multi-model-register-and-deploy.ipynb",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-14T13:00:22.453Z",
                "Answer_score":0,
                "Answer_body":"@RajamannarAK-6287 Thanks for the question. Below is the document for common errors to Troubleshooting remote model deployment.\n\nIf you have problems when deploying a model to ACI or AKS, deploy it as a local web service. Using a local web service makes it easier to troubleshoot problems. To troubleshoot a deployment locally, see the local troubleshooting article.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment?tabs=azcli",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to Register a ML model using MLflow",
        "Question_creation_time":1638981630093,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/656507\/how-to-register-a-ml-model-using-mlflow.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hi,\n\nI have a PyTorch model which I have pushed into the dbfs now I want to serve the model using MLflow. I saw that the model needs to be in python_function model.\n\nTo do that I did the following methods\n1. load the model from dbfs using torch load option\n2. Then save the model in python_function model using the pyfunc.save_model function\n3. After this when I register the model I get a decode error\n\nI'm not training any model in the Databricks.\n\nimport mlflow\nimport mlflow.pyfunc\nfrom torch import load as torch_load\npy_model = torch_load( \"\/dbfs\/FileStore\/ml\/ner_model\" , map_location = torch_device(ner_gpu_device))\nmlflow.pytorch.save_model(py_model,path=\"\/dbfs\/FileStore\/pyfunc\/ner_model\")\nmodel = mlflow.pyfunc.load_model(\"\/dbfs\/FileStore\/pyfunc\/ner_model\")\nmlflow.register_model(model,\"ner_model\")\n# loading the python_function model to register\nmodel = mlflow.pyfunc.load_model(\"\/dbfs\/FileStore\/pyfunc\/ner_model\")\nmodel_version = mlflow.register_model(model,\"ner_model\")\n\n\n\n\nthis is the error which I get while running the register model line",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-09T06:06:13.953Z",
                "Answer_score":0,
                "Answer_body":"@RajamannarAK-6287 Thanks for the question. Can you please add more details about the trained model and deployment that you are trying.\n\nHere is link to an example of how to deploy and use object detection model in Azure ML with MLFlow option.\n\nthe process to do MLFlow using a custom python flavor then deploy to Azure ML using the Azure version of MLFlow.\nCreated the template here:\n1. Main deployment script to AML: aml_mlflow_deployment\/mlflow_aml_deployment.ipynb at main \u00b7 james-tn\/aml_mlflow_deployment (github.com)\n2. Custom mlflow.pyfunc module: aml_mlflow_deployment\/model_loader.py at main \u00b7 james-tn\/aml_mlflow_deployment (github.com)\n\n\n\n\nThere's also the option of simply using Azure DevOps to pull the model out of the MLFlow model repo in Azure Databricks, containerize it, and put it directly to ACI\/AKS for API scoring outside of Azure Databricks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"\"PermissionError: [Errno 13] Permission denied\" when trying to access a local file for a conda environment",
        "Question_creation_time":1652041850827,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/840929\/34permissionerror-errno-13-permission-denied34-whe.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"After Azure ML Studio blocking me from using any compute due to an as-of-yet unresolved authentication error, I moved to using a Jupyter Notebook on my local workstation to try to configure my experiments locally then send the job to an Azure compute cluster. I have two lines of Python that tries to create an environment class by accessing a .yml file on my local computer:\n\nyml_path = r\"C:\\Users\\me\\Desktop\\azure_training\\training_env\"\npytorch_env = Environment.from_conda_specification(name='pytorch-1.11-gpu', file_path=yml_path)\n\nThis causes the following error:\n\nPermissionError: [Errno 13] Permission denied: 'C:\\\\Users\\\\me\\\\Desktop\\\\azure_training\\\\training_env'\n\nI am unsure of what is causing this. When the file doesn't need to be private, I have solved permission denied issues in the past that resulted from locally run tools such as PostgreSQL by going to the file's properties>>security and adding the user \"Everyone\" with full control. I tried doing that in this case, but it had no impact. I still get permission denied even though \"Everyone\" has full control over the file.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-10T02:50:53.773Z",
                "Answer_score":0,
                "Answer_body":"@AJV-7655 Thanks for the question. if you don't want to \"bake\" your personal access token (essentially a password) into your Conda environment file, is to follow Use private Python packages - Azure Machine Learning | Microsoft Docs and connect the authenticated feed with your workspace.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Consuming ML models on Power BI",
        "Question_creation_time":1653284389440,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/859568\/consuming-ml-models-on-power-bi.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"When I connect the ML model endpoint with Power BI, it doesn't show me the model attributes that match the PBI dataset. Can you please help with the expected data format in Power BI.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-23T06:38:24.97Z",
                "Answer_score":0,
                "Answer_body":"@Arjun-1257 Thanks, Can you try define the input schema and follow the below sample.\n\nHere is the sample to Deploy trained model to Azure ML and use Power BI to score new data.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Connect Azure ML with Snowflake using Private endpoint?",
        "Question_creation_time":1652948258440,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/855820\/connect-azure-ml-with-snowflake-using-private-endp.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Can we connect Azure ML Notebooks directly to Snowflake using Private end-points, my ML Workspace is inside a VNet.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-20T08:20:45.86Z",
                "Answer_score":0,
                "Answer_body":"Hello @Varun-6424\n\nThanks for reaching out to us, currently there is no internal way in Azure Machine Learning Studio to connect to Snowflake. I am sorry for all inconveniences.\n\nBut you can run a Python 3 code to use the Snowflake python connector - https:\/\/docs.snowflake.com\/en\/user-guide\/python-connector.html\n\nWith Azure ML Studio, there's no built-in support for SnowFlake, I will forward your feedback to product group to see if there any plan in the future.\n\nHope this helps!\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks a lot for supporting the community.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-05-20T15:47:36.443Z",
                "Answer_score":1,
                "Answer_body":"Sure, thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Filter Based Feature Selection or Permutation Feature Importance",
        "Question_creation_time":1651765090787,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/838182\/filter-based-feature-selection-or-permutation-feat.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi\n\nI am aware that Feature Based Selection kind of measure the prediction power of each variable before any model has been built.\n\nI know that Permutation Feature importance measures, once the model has been built, how relevant each variable is. Thanks to this we can prune our model and strike a good balance between accuracy and simplicity. Fair enough.\n\nHowever, most of the time I encounter contradictory messages. There is a variable with 0 importance on the Feature Based Selection but it ends up becoming one of the most relevant variables of my model according to its ranking on Permutation Feature importance.\n\nSo I guess I cannot rely on what Feature Based Selection says in order to do a preliminary assessment. I guess I should see it as some theoretical exercise.\n\nThank you",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-06T09:01:39.627Z",
                "Answer_score":0,
                "Answer_body":"@IvanCasanaGallen-3736 Thanks for adding details about your observations. As documented under Permutation feature importance module the rankings the component provides are often different from the ones we get from Filter Based Feature Selection as the Filter Based Feature Selection calculates scores before a model is created. Thanks!!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"InvalidPorpertyValue. The size of the specified..........the limit of 20480 characters",
        "Question_creation_time":1651656606393,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/836030\/invalidporpertyvalue-the-size-of-the-specifiedthe.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"when we edit the source code at machine learning studio - Designer, seems when the row more than 280 rows, it shows the error like following:\n\n\n\n\nI am not sure whether the rows is exceed or the total number of chacters exceed, anyone encounter this issue before ? how to resolved ? thanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-04T12:16:37.773Z",
                "Answer_score":0,
                "Answer_body":"@SeiyaZelinShen-9380 I think this thread is a duplicate of earlier issues.\n\nhttps:\/\/docs.microsoft.com\/en-us\/answers\/questions\/818094\/unknow-error-of-azuremlcompute.html\nhttps:\/\/docs.microsoft.com\/en-us\/answers\/questions\/835758\/index.html\n\nAdding the threads here for reference as the threads are already active.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"To update keys between workspace and storage",
        "Question_creation_time":1652953898103,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/856066\/to-update-keys-between-workspace-and-storage.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":26,
        "Question_score":0,
        "Question_body":"Hello\n\nMy storage keys have been updated and so I am trying to update to connect with the ML Studio.\n\nI am following this link:\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-change-storage-access-key\n\nHowever in this step:\n\nRe-register the blob container\n\nds_blob = Datastore.register_azure_blob_container(workspace=ws,\ndatastore_name='your datastore name',\ncontainer_name='your container name',\naccount_name='your storage account name',\naccount_key='new storage account key',\noverwrite=True)\n\nRe-register file shares\n\nds_file = Datastore.register_azure_file_share(workspace=ws,\ndatastore_name='your datastore name',\nfile_share_name='your container name',\naccount_name='your storage account name',\naccount_key='new storage account key',\noverwrite=True)\n\nI get the following error message: ErrorResponseException: (Immutable) Update to datastore is not allowed. Only credentials of a datastore can be updated.\n\nPlease your help to solve this.\n\n\n\n\nThank you!",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Accepting ADF parameters in Azure ML Pipeline Python",
        "Question_creation_time":1652940523997,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/855597\/accepting-adf-parameters-in-azure-ml-pipeline-pyth.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi\n\nI am using ML Execute activity in ADF and passing the parameters. For Example Business_Unit = ABC\n\nNow how to access this parameter in Azure ML Pipeline Python Code. What exact command to be used?, is there any documentation for the same?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"\"no module named azure.storage\" while using ScriptRunConfig to submit run.",
        "Question_creation_time":1652751214187,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/851738\/34no-module-named-azurestorage34-while-using-scrip.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":20,
        "Question_score":0,
        "Question_body":"I am trying to download pickle files from blob container and using ScriptRunConfig object to submit a Run.\n\nI am stuck and getting the following error:\n\nModuleNotFoundError: No module named 'azure.storage'\n\nAny help is appreciated please.......\n\nmy environment.yml file consists of the following below:\n\n name: azuremlenv\n dependencies:\n - python=3.8\n - pip=21.0.1\n - pip:\n   - azureml-defaults\n   - azureml-core\n   - azureml-mlflow\n   - azureml-sdk\n   - azure-storage\n   - azure-storage-blob\n   - azure-mgmt-datafactory\n   - azure-functions\n   - azure-functions-durable\n   - scikit-learn==0.24.1\n   - pandas==1.2.4\n   - seaborn==0.11.1\n   - tqdm==4.61.2\n   - matplotlib==3.3.4\n   - pandas-schema==0.3.6",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure Automated ML Model Deployment to Online Endpoint Stuck in Transitioning",
        "Question_creation_time":1650137939707,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/814684\/azure-automated-ml-model-deployment-to-online-endp.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I have a model produced by Azure's Automated ML service. I am following this tutorial (https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-automl-endpoint?tabs=Studio) to deploy to an online endpoint via the portal. Currently, the endpoint is successfully created but the actual deployment fails. It hangs for around 2.5 hours before crashing on a timeout error. The deployment logs are empty.\n\nOther posts suggest that this might be due to some kind of issue in the configuration file or specification of dependencies. However, those files are being generated and provided by azure. I am at a loss for how to proceed. Thought about trying to deploy from the CLI but the ml extension fails to install citing version conflicts in Docker. Any advice on what might be going wrong or ways to investigate this would be greatly appreciated!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-11T10:24:50.27Z",
                "Answer_score":0,
                "Answer_body":"@SamMcKinleyHinson-6915 Thanks, Can you try this notebook for deployment and if that works for you (it should), compare with your code?\nhttps:\/\/github.com\/CESARDELATORRE\/Easy-AutoML-MLOps\/blob\/master\/notebooks\/5-automl-model-service-deployment-and-inference\/automl-model-service-deployment-and-inference-safe-driver-classifier.ipynb\n\nYou can also use the notebook with a simple AutoML remote run, but you might need to change the name of the model when registering it in the Workspace since it\u2019s a different name to what the deployment notebook is using:\nhttps:\/\/github.com\/CESARDELATORRE\/Easy-AutoML-MLOps\/blob\/master\/notebooks\/3-automl-remote-compute-run\/automl-remote-compute-run-safe-driver-classifier.ipynb",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"great_expectations package",
        "Question_creation_time":1650353065060,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/817164\/great-expectations-package.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"Hi,\n\nI am trying to run great_expectations on an azure machine learning environment, but when I do so it tells me that great_expectations is not a package. My environment is defined by the following code :\n\ncreating an environment\n\nfrom azureml.core.runconfig import RunConfiguration\nfrom azureml.core.conda_dependencies import CondaDependencies\naml_run_config = RunConfiguration()\naml_run_config.target = compute_target\n\naml_run_config.environment.docker.enabled = True\naml_run_config.environment.docker.base_image = \"mcr.microsoft.com\/azureml\/base:latest\"\n\naml_run_config.environment.python.user_managed_dependencies = False\nconda_dep = CondaDependencies()\nconda_dep.add_conda_package(\"python=3.8\")\nconda_dep.add_conda_package(\"pandas\")\nconda_dep.add_conda_package(\"packaging\")\nconda_dep.add_conda_package('pip')\n\nconda_dep.add_pip_package(\"azureml-defaults\")\n\nconda_dep.add_pip_package(\"great_expectations\")\naml_run_config.environment.python.conda_dependencies = conda_dep\n\nIn the logs I can see that the package is being downloaded, but it is not being installed, which is kind of strange. Is there somebody who has experience with great_expectations on Azure Machine Learning?\n\nKind regards,\n\nOlivier Leflere",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure Machine Learning Designer Preview data error",
        "Question_creation_time":1651158995620,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/830467\/azure-machine-learning-designer-preview-data-error.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I am using Azure Machine Learning designer to go through one of the introduction Microsoft course. I have built a pipeline in Designer, but whenever I try to use \"Preview Data\" option of any step of the pipeline, this option disappears and nothing happens. The above 2 images reflect the situation before clicking \"Preview Data\" and right after it.\nBefore:\n\nAfter:\n\n\nIs this known bug?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-28T19:15:16.057Z",
                "Answer_score":1,
                "Answer_body":"Hi, thanks for sharing this feedback. This seems to be a bug. I've forwarded the feedback to the product team, will share updates soon.\n\nUpdates: This issue has already been fixed. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Can an AzureML Notebook on a workspace be linked to an specific AzureML Environment",
        "Question_creation_time":1651165609177,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/830652\/can-an-azureml-notebook-on-a-workspace-can-be-link.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I have seen how to link an AzureML Notebook inside a Workspace to a Compute Target within the same Workspace\n\nI am wondering if it could be also linked to an specific AzureML Environment as the notebook requires software from the container used to instantiate the Environment",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-29T06:33:33.83Z",
                "Answer_score":0,
                "Answer_body":"@ManuelReyesGomez-1028 Do you want to use a specific package with the notebook to process data that is required before submitting your experiment? If Yes, then you can create a custom environment or kernel with your notebook. The details of the steps are mentioned in this thread. With this process you are basically using the terminal to install the packages and create a conda environment that can be used as kernel listed in the dropdown of your notebook.\n\nIf you want to use a specific environment for your experiments then you can use curated environments or create a custom environment and register it with your workspace that can be used with any experiment.\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azureml compute instance spark dependencies missing",
        "Question_creation_time":1651594378717,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/835171\/azureml-compute-instance-spark-dependencies-missin.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Currently, I'm trying to use the AzureML SDK's, dataset.to_spark_dataframe() method, and facing a weird error(see below).\nThe ClassNotFoundExceptions suggest that some Jars might be missing from the base environment's Spark classpath. Some sources suggest hadoop-azure concretely: https:\/\/community.cloudera.com\/t5\/Support-Questions\/Class-org-apache-hadoop-fs-azure-NativeAzureFileSystem-not\/m-p\/270675)\n\nIs there a way to add these dependencies to the environment?\n\nError:\nAzureMLException: AzureMLException:\nMessage: Execution failed in operation 'to_spark_dataframe' for Dataset(id='54df6c30-fb46-4c75-a084-d10c17cd3795', name='temperatures_parq', version=1, error_code=None, exception_type=Py4JJavaError)\nInnerException An error occurred while calling o39.getFiles.\n: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure not found\nat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2667)\nat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3431)\nat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\nat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\nat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\nat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\nat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\nat com.microsoft.dprep.io.FileSystemStreamInfoHandler.globStatus(FileSystemStreamInfoHandler.scala:46)\nat com.microsoft.dprep.io.StreamInfoFileSystem.globStatus(StreamInfoFileSystem.scala:206)\nat com.microsoft.dprep.io.StreamInfoFileSystem.globStatus(StreamInfoFileSystem.scala:201)\nat com.microsoft.dprep.execution.Storage$.expandHdfsPath(Storage.scala:44)\nat com.microsoft.dprep.execution.executors.GetFilesExecutor$.$anonfun$getFiles$1(GetFilesExecutor.scala:18)\nat scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)\nat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\nat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\nat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\nat scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)\nat scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)\nat scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)\nat com.microsoft.dprep.execution.executors.GetFilesExecutor$.getFiles(GetFilesExecutor.scala:12)\nat com.microsoft.dprep.execution.LariatDataset$.getFiles(LariatDataset.scala:32)\nat com.microsoft.dprep.execution.PySparkExecutor.getFiles(PySparkExecutor.scala:201)\nat java.base\/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nat java.base\/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nat java.base\/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat java.base\/java.lang.reflect.Method.invoke(Method.java:566)\nat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\nat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\nat py4j.Gateway.invoke(Gateway.java:282)\nat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\nat py4j.commands.CallCommand.execute(CallCommand.java:79)\nat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\nat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\nat java.base\/java.lang.Thread.run(Thread.java:829)\nCaused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure not found\nat org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2571)\nat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2665)",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-04T09:56:50.2Z",
                "Answer_score":0,
                "Answer_body":"@KutiKreszacsMatyasRBROPJDT-0321 I think dataset.to_spark_dataframe() is now deprecated since dataset class is categorized into two classes tabular and file. Deprecation notice about the changes are available here. Could you try using the latest SDK with TabularDataset class?\n\nExample:\n\n from azureml.core import Dataset\n dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, 'train-dataset\/tabular\/iris.csv')])\n    \n # preview the first 3 rows of the dataset\n dataset.take(3).to_spark_dataframe()",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Length of charater is long, ML will pop error.",
        "Question_creation_time":1651647844370,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/835758\/length-of-charater-is-long-ml-will-pop-error.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"when I put the source code in the ML studio, if the charater length is long, it will popup the error and cannot submit. can someone help me ? thanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-04T10:23:04.917Z",
                "Answer_score":0,
                "Answer_body":"@SeiyaSum-3219 This is a character limit on the script that can be used with the execute python script module.\nCould you please check if you can reduce the number of characters, probably by renaming some variables to a shorter name?\nAlso, have you copy pasted from any previous script in the module configuration? Please try to key in the script if reducing the characters is still reporting the issue. Thanks!!\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"NameError: name 'load_workspace_from_config' is not defined",
        "Question_creation_time":1651777443857,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/838280\/nameerror-name-39load-workspace-from-config39-is-n.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"i simply want to get the datastore name from my azure workspace so I can use it in databricks. i found this code\nimport azureml.core\nfrom azureml.core import Workspace, Datastore\n\n\n\n\nws = load_workspace_from_config(path=\"config.json\")\nds = get_default_datastore(ws)\nprint(ds)\n\nI am facing error on this that\nNameError: name 'load_workspace_from_config' is not defined",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-06T06:00:33.793Z",
                "Answer_score":0,
                "Answer_body":"@MuqaddasAbbas-2550 In this case you will have to use Workspace.from_config() This call will then prompt an interactive login to Azure portal.\n\nEx:\n\n    ws = Workspace.from_config()\n    ws.get_details()\n\n\n\nBefore calling this you will have to specify the config file path with details of your subscription and workspace.\n\n    ws.write_config(path=\".\/file-path\", file_name=\"ws_config.json\")\n\n\n\nThe JSON file should contain details of your subscription, resource group and workspace.\n\n {\n     \"subscription_id\": \"<subscription-id>\",\n     \"resource_group\": \"<resource-group>\",\n     \"workspace_name\": \"<workspace-name>\"\n }\n\n\n\nPlease refer the documentation for more details.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"I am unable to create compute instance",
        "Question_creation_time":1648817598023,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/797009\/i-am-unable-to-create-compute-instance.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":5,
        "Question_comment_count":3,
        "Question_follower_count":17,
        "Question_score":4,
        "Question_body":"\u200bI am unable to create compute instance in my azure ml resource. I am using a free trial and already have 6 unused cores left in my quota. I have used central India as my location. While making the compute instance, It shows - \"You do not have enough quota for the following VM sizes\".\n\nI've added a screenshot.\n\n\n\n\n\n\nPlease let me know what is the solution to this problem.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-20T20:05:25.223Z",
                "Answer_score":1,
                "Answer_body":"Having the same issue here, first i tried to set up the region in west germany then to eastus, nothing works since I am not able to set select any virtual machine with my free trial account\n\nI was following the DP-100 tutorial for deep-learning and it suggests the free trial account would be enough:\n\nhttps:\/\/docs.microsoft.com\/en-us\/learn\/modules\/train-evaluate-deep-learn-models\/3-exercise-train-deep-neural-network\n\nA Microsoft Azure subscription. If you don't already have one, you can sign up for a free trial at https:\/\/azure.microsoft.com\/free.\n\nAn Azure Machine Learning workspace with a compute instance and the ml-basics repository cloned.\n\nIts seems to be misleading given the case\n\nEdit: Upgrading to pay-as-you-go does not solve the problem",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-21T06:24:00.62Z",
                "Answer_score":1,
                "Answer_body":"You have to request an increase in Quota through Microsoft, it can take awhile but it will work. It does not make sense to me why the default would be 0 VM cores.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-21T12:19:07.727Z",
                "Answer_score":1,
                "Answer_body":"I was able to create a compute instance after I recreated the Azure ML workspace in AustraliaEast. But when i tried it 3 days later it is not allowing me to create one ( have to check quotas i think).\n\nBut bottom line AustraliaEast seemed to work",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-26T17:14:31.243Z",
                "Answer_score":1,
                "Answer_body":"I have the same problem with eastus2 region, that it didn't allow me to select any virtual machines",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-09T20:02:31.683Z",
                "Answer_score":1,
                "Answer_body":"I am having the same issue with the West US region",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"My Azure ML studio is not loading",
        "Question_creation_time":1651477263057,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/833332\/my-azure-ml-studio-is-not-loading.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_follower_count":21,
        "Question_score":0,
        "Question_body":"Hello,\n\nI am trying to enter my ML studio, however when I launch it, the window opens and appears to be loading (it says: loading workspace) but it reamins this way for a long time and I cannot access it. I have had this problem for a couple of days now and have tried it on different web browser and the result is the same.\n\nPlease your help or feedback to solve this as soon as possible.\n\nThank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-02T16:00:03.39Z",
                "Answer_score":0,
                "Answer_body":"Hi @CASTANOSANCHEZMariaJoseA-3582,\n\nHave you tried it by using a Chrome browser?\n\nHere is a quite similar issue.\n\nhttps:\/\/docs.microsoft.com\/en-us\/answers\/questions\/576536\/not-able-to-access-to-microsoft-machine-learning-s.html",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-03T07:45:11.707Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nYes I am still experiencing this issue. The region of my resource is West Europe. I can access my account perfectly but then when I try to launch the ML Studio it goes on a loop saying \"Loading workspace\" and I can never enter. I have tried with different browsers (Chrome, Firefox, Safari, and microsoft edge) and also private windows and nothing is working.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-03T08:24:37.73Z",
                "Answer_score":0,
                "Answer_body":"Also the problem is only with my account, as there is other people that work with me in the same resource group (azrgy-ml4p-01) and their accounts are working perfectly, they can log in into their Azure ML studio and even mine without an issue. However, on my side I cannot log into any Azure ML Studio, nor mine and theirs. I have also checked with the IT department at my organization and from this side my account should be working just fine, I can enter other Azure platforms except for Azure ML studios, which is the focus of my projects.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error in init() function during azurel ML deployment due to model path definition",
        "Question_creation_time":1650517247760,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/820362\/error-in-init-function-during-azurel-ml-deployment.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello Team,\n\nWe are trying to deploy a model to Azure ML workspace containing a saved model & One Hot Encoded joblib file.\nWe are facing issue in init() function.\n\nPlease find the below error message:\n\n\"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\n\n\n\nPFB screenshot of scoring file:",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-29T15:27:10.893Z",
                "Answer_score":0,
                "Answer_body":"@SahanaGurumurthyAccentureInternati-9832 Thanks, I think the problem is that you rely on AML background process to automatically upload content under .\/outputs to AML workspace.\nBut when the upload is not complete and we immediately call run.register_model which takes the content from AML workspace then the error will happen.\nTo avoid that situation, you can do it like this:\n- Persist model (joblib.dump) to a custom folder other than outputs\n- Manually run upload_file to upload the model AML workspace. Name the destination same name with your model file.\n- Then run run.register_model.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"how to fix the parameters error after running the data to produce the evaluate model results",
        "Question_creation_time":1650867535663,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/824528\/how-to-fix-the-parameters-error-after-running-the.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Currently, our research model results are encountering Mean Absolute Error, Root Mean Squared Error, Relative Absolute Error, Relative Squared Error. I don't know what is the reason for this error, can someone explain it to me.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-29T15:33:22.7Z",
                "Answer_score":0,
                "Answer_body":"@Wendy2701bbbb-0563 Just checking any update on the experiment details.\nHere is link to the document for the metrics.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-understand-automated-ml#regressionforecasting-metrics",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Converting textanalytics result to JSON Format",
        "Question_creation_time":1650967532993,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/826603\/converting-textanalytics-result-to-python.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hello,\nI am using the example provided in the Machine Learning Studio Docs for extracting Health Entities from a given string.\nThe code is shown below.\n\nMy question is: what is the easiest way to convert the output result into JSON format?\n\n from azure.core.credentials import AzureKeyCredential\n from azure.ai.textanalytics import TextAnalyticsClient\n import json\n    \n credential = AzureKeyCredential(\"**********************************\")\n endpoint=\"https:\/\/eastus.api.cognitive.microsoft.com\/\"\n    \n text_analytics_client = TextAnalyticsClient(endpoint, credential)\n    \n documents = [\"Subject is taking 100mg of ibuprofen twice daily\"]\n    \n poller = text_analytics_client.begin_analyze_healthcare_entities(documents)\n result = poller.result()\n    \n docs = [doc for doc in result if not doc.is_error]\n    \n print(\"Results of Healthcare Entities Analysis:\")\n for idx, doc in enumerate(docs):\n     for entity in doc.entities:\n         print(\"Entity: {}\".format(entity.text))\n         print(\"...Normalized Text: {}\".format(entity.normalized_text))\n         print(\"...Category: {}\".format(entity.category))\n         print(\"...Subcategory: {}\".format(entity.subcategory))\n         print(\"...Offset: {}\".format(entity.offset))\n         print(\"...Confidence score: {}\".format(entity.confidence_score))\n         if entity.data_sources is not None:\n             print(\"...Data Sources:\")\n             for data_source in entity.data_sources:\n                 print(\"......Entity ID: {}\".format(data_source.entity_id))\n                 print(\"......Name: {}\".format(data_source.name))\n         if entity.assertion is not None:\n             print(\"...Assertion:\")\n             print(\"......Conditionality: {}\".format(entity.assertion.conditionality))\n             print(\"......Certainty: {}\".format(entity.assertion.certainty))\n             print(\"......Association: {}\".format(entity.assertion.association))\n         for relation in doc.entity_relations:\n             print(\"Relation of type: {} has the following roles\".format(relation.relation_type))\n         for role in relation.roles:\n             print(\"...Role '{}' with entity '{}'\".format(role.name, role.entity.text))\n     print(\"------------------------------------------\")",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-26T14:18:10.653Z",
                "Answer_score":0,
                "Answer_body":"@KamranAli-0346 The result does not seem to be directly serializable to JSON. I found a library JSONS that can do the heavy lifting if you are using python 3.5 or higher.\n\nInstall jsons\n\n pip install jsons\n\n\n\nImport JSONS and using jsons.dump() on docs object.\n\n import jsons #import in the import section\n print(jsons.dump(docs)) #Printing the json after docs is created\n\n\n\nThis should give a file of this format in this case. Uploaded the file in .txt format since JSON files cannot be uploaded on Q&A, download the file and rename it to .json\nI hope this helps!!\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.\n\n\n\n\n196624-health.txt",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Swagger file not present -- Azure Machine Learning",
        "Question_creation_time":1624015775073,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/442305\/swagger-file-not-present-azure-machine-learning.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":10,
        "Question_follower_count":13,
        "Question_score":2,
        "Question_body":"I am currently training and deploying machine learning models through Azure Devops Pipelines to Azure ML Studio.\n\nWhen I deploy the model to endpoint through the pipeline to an endpoint I am getting the following error:\n\n     \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"hackney\/1.17.4\"\n Swagger file not present\n \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"curl\/7.67.0\"\n Swagger file not present\n\n\n\n\nI have no code related to swagger. So I could not understand.\n\nIt was successfully building the endpoint before. It just suddenly popped out.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"AFx Library library exception FOR R Modules",
        "Question_creation_time":1651358872440,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/832546\/afx-library-library-exception-for-r-modules.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":8,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi,\nI output a dataset from port1, input it to another R module Input port 1, but every time, it gives me:\nrequestId = 04c3444f096f4ff8b17edd1d055cfa4a errorComponent=Module. taskStatusCode=400. {\"Exception\":{\"ErrorId\":\"LibraryException\",\"ErrorCode\":\"1000\",\"ExceptionType\":\"ModuleException\",\"Message\":\"Error 1000: AFx Library library exception: Column names cannot be null or empty.\",\"Exception\":{\"Library\":\"AFx Library\",\"ErrorId\":\"EmptyColumnName\",\"ErrorCode\":\"151\",\"ExceptionType\":\"LibraryException\",\"Message\":\"Column names cannot be null or empty.\"}}}Error: Error 1000: AFx Library library exception: Column names cannot be null or empty. Process exited with error code -2\n\nI can not print anything in the second r module, what's wrong?\n\nNAW.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Can't deploy a VM on the Azure Machine Learning.",
        "Question_creation_time":1623772014863,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/437136\/can39t-deploy-a-vm-on-the-azure-machine-learning.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":6,
        "Question_comment_count":0,
        "Question_follower_count":19,
        "Question_score":4,
        "Question_body":"I tried to deploy a VM to Azure Machine Learning, but I get the error message \"You do not have enough quota for the following VM sizes. Click here to view and request quota.\" And the VM cannot be deployed.\n\nBut I have enough quota (24 CPUs).\n\nWhat is causing the problem?\n\nI'm using Azure's Free trial plan.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-15T16:02:14.643Z",
                "Answer_score":2,
                "Answer_body":"Hi @Sss-1842 ,\n\nthere are different quotas in Azure:\n\nThere are quotas for vCPUs per Azure Region\n\n\nIn addition there are quotas for vCPUs per VM Series\n\nBoth quotas (for Azure Region and VM Series) must fit the requirements.\n\nIt seems like the quota for vCPUs per region is ok but you haven't enough vCPUs per VM series.\nYou can check your quotas by the link you marked with the red line in your screenshot.\n\n(If the reply was helpful please don't forget to upvote and\/or accept as answer, thank you)\n\nRegards\nAndreas Baumgarten",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-06-16T13:48:30.697Z",
                "Answer_score":2,
                "Answer_body":"Hi AndreasBaumgarten\n\nYour reply was correct.\nThe problem was \"vCPUs per VM Series\".\n\nThe VM series that can be used differs depending on the region,\nI changed the region to the western United States and it was resolved.\n\nThank you so much.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-12-09T13:20:50.753Z",
                "Answer_score":0,
                "Answer_body":"I face the same issue as @Sss-1842 All the options seem to be greyed out. I am also going through the MS Azure AI Fundamentals module with the free subscription and cannot create the compute instance. Already changed the region from East US to SouthCentral US, and nothing changes.\n\nAny help would be greatly appreciated.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-12-27T22:36:41.117Z",
                "Answer_score":1,
                "Answer_body":"Hi I tried canadacentral and worked",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-03-31T23:29:07.833Z",
                "Answer_score":1,
                "Answer_body":"I had the same issue while going through the Azure AI Fundamentals course. And no region change would make it work.\n\nSo I went against what the instructions explicitly say for the settings & checked \"Low priority\" instead of \"Dedicated\" and it immediately resolved the issue.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-06T03:54:36.943Z",
                "Answer_score":0,
                "Answer_body":"Probe con Australia East y funciono.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"azure.ai.textanalytics not resolved in Machine Learning Studio",
        "Question_creation_time":1650885782980,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/825079\/azureaitextanalytics-not-resolved-in-machine-learn.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hello,\nI am using a Python notebook in the Machine Learning Studio for extracting Health Info from a given text.\nHowever, the Machine Learning Studio refuses to recognize the below line of code:\n\n from azure.ai.textanalytics import TextAnalyticsClient\n\n\n\nThe error received is as below:\n\n ModuleNotFoundError                       Traceback (most recent call last)\n <ipython-input-4-54158a600368> in <module>\n       1 from azure.core.credentials import AzureKeyCredential\n ----> 2 from azure.ai.textanalytics import TextAnalyticsClient\n       3 \n       4 \n       5 credential = AzureKeyCredential(\"***************************\")\n    \n ModuleNotFoundError: No module named 'azure.ai'\n\n\n\nDoes anyone has an idea what to do here?\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-02T14:44:42.647Z",
                "Answer_score":0,
                "Answer_body":"You should check the path, this happened to me when I install packages from local but run it from local machine.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning Studio does not connect to Azure Table Storage",
        "Question_creation_time":1650452975323,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/819266\/azure-machine-learning-studio-does-not-connect-to.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hi Team,\n\nI am trying to create a DataStore in Azure Machine learning to read data from Azure Table Storage.\n\nThere is no option available, Is it really possible to make this connection?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-20T16:13:13.037Z",
                "Answer_score":0,
                "Answer_body":"according to documentation not all Azure data storage services can be used with Azure Machine Learning: Supported data storage service types. Azure table storage is not listed there.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-25T06:54:20.147Z",
                "Answer_score":0,
                "Answer_body":"Hello @KausthubNp\n\nTo add sadomovalex's answer, Azure Machine Learning supports accessing data from Azure Blob storage, Azure Files, Azure Data Lake Storage Gen1, Azure Data Lake Storage Gen2, Azure SQL Database, and Azure Database for PostgreSQL. If you're using unsupported storage, we recommend that you move your data to supported Azure storage solutions by using Azure Data Factory and these steps. Moving data to supported storage can help you save data egress costs during machine learning experiments.\n\nAzure Data Factory provides efficient and resilient data transfer with more than 80 prebuilt connectors at no additional cost. These connectors include Azure data services, on-premises data sources, Amazon S3 and Redshift, and Google BigQuery.\n\nI hope our answers are helpful, please let us know if you have any concern.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Formato di serializzazione eventi",
        "Question_creation_time":1649832685723,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/810747\/formato-di-serializzazione-eventi.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Buongiorno, nel output di un processo di analisi di flusso non posso cambiare formato da JSON a CVS come spiegato dal tutorial Microsoft \"Previsioni meteo usando i dati del sensore dall'hub IoT in Machine Learning Studio (versione classica)\".\nQualcuno ha qualche idea di come risolvere?\nGrazie.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-13T12:09:55.54Z",
                "Answer_score":0,
                "Answer_body":"Hello, in the output of a stream analysis process I cannot change format from JSON to CVS as explained by the Microsoft tutorial \"Weather forecast using sensor data from IoT hub in Machine Learning Studio (classic version)\".\nAnyone have any idea how to fix?\nThanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML connectivity with hive metastore",
        "Question_creation_time":1649938200287,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/812660\/azure-ml-connectivity-with-hive-metastore.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Dear MS team,\nwe're exploring the AML implementation in our org and i found AML can connect to ADLS2 through datastore; but I'm not sure if it can read the hive metastore and read the tables directly?\n\n( i choose some random tag below as it's not allowing to submit the question, pls ignore the tagging for this question)",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-02T23:04:22.353Z",
                "Answer_score":0,
                "Answer_body":"Any update? Seems Azure only support Azure storage now, any roadmap?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azue machine Learning",
        "Question_creation_time":1649945649033,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/812800\/azue-machine-learning.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hello all,\n\nAny tips to run an Azure ML exercise to help to create a pattern in names of professional occupations in a field ?\n\nI have thousands of ways the people have written their professional occupation and would like to run an ML to help to make some pattern to this names of occupations.\n\nAny idea \/ tips \/ examples will be appreciated\n\nBest regards\nPaulo",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-18T14:47:24.687Z",
                "Answer_score":0,
                "Answer_body":"Hello Yutong, Thanks for your reply !\n\nExactly Yutong this is the goal !\nI have around 22.000 records with the more diverse way people could \"invented\" :) how to write their occupation .\n\nI would like to create an experience in Azure Machine Learning to help me normalize this people occupation, I will have a sort of occupation define to start this normalization and hope with the scenario running could help to get the majority normalized.\n\nHope this help to clarify\n\nKR\nPaulo",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to implement customized AbstractADLSDatastore in Azure ML SDK",
        "Question_creation_time":1650999035973,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/827239\/how-to-implement-customized-abstractadlsdatastore.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi AzureML team,\n\nI'm from Linkedin. We are exploring the option of enabling AzureML to training models on our production data. Also we are using ADLS gen2, we have our customized authentication logic to access the data. We probability need to implement customized ADLSDatastore so that training applications can have access to the data. I'm is there a way to do such customization and contribute the AzureML Data SDK?\n\nThanks a lot!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-02T14:49:38.853Z",
                "Answer_score":0,
                "Answer_body":"I don\u2019t think this can be accomplished with info from the doc. A feature request is needed.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-02T14:51:49.857Z",
                "Answer_score":0,
                "Answer_body":"And the forum is pretty slow, post several times but failed",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-02T14:52:28.32Z",
                "Answer_score":0,
                "Answer_body":"And the forum is pretty slow, post several times but failed with error\nUnable to execute your request\nWe are sorry, but we are unable to execute your request at this time. You may be seeing this page because you attempted to submit a thread before its form was fully loaded. Please refresh this page and then try again. If this error persits, please enter a Site feedback and provide details of the action you were trying to take.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-02T17:05:43.76Z",
                "Answer_score":0,
                "Answer_body":"Thanks Azadeh, how can I initiate this request?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is there any way to create automatic datasets in Azure Machine Learning using Azure Data Factory",
        "Question_creation_time":1651474101517,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/833237\/is-there-any-way-to-create-automatic-datasets-in-a.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"I have Storage ADLS account, Azure Data Factory and Azure Machine Learning services. In Azure ML , we create datasets manually and use for training Models. But is there any way where Azure Data Factory takes data from ADLS account and updates as Datasets in Azure ML.\n\nOnly option I see is using Azure ML Notebooks which involves writing Notebooks(which I do not want). From ADF I want this process to be done. I do not have Azure Machine Learning Studio also.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-04T23:50:13.47Z",
                "Answer_score":0,
                "Answer_body":"Hello @KrishnamohanNadimpalli-6337,\n\nThanks for the question and using MS Q&A platform.\n\nUnfortunately, it is not possible from ADF as there isn't any out of f box feature.\n\nBut if you have a way to create those datasets using any SDK then you may try writing your own code then execute it in ADF using Custom Activity or Azure function Activity.\n\nAnd if you have any ADF product improvement suggestions or feature requests, please log your idea here - https:\/\/feedback.azure.com\/d365community\/forum\/1219ec2d-6c26-ec11-b6e6-000d3a4f032c. All the feedback shared in this forum are actively monitored and reviewed by respective product owners.\n\nPlease do share he feedback link once it is posted so that we can share it with internal teams for review.\n\nHope this will help. Please let us know if any further queries.\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"what is the difference between Dataset.Tabular.register_pandas_dataframe and dataset.register",
        "Question_creation_time":1651658160987,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/836059\/what-is-the-difference-between-datasettabularregis.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"what is the difference between Dataset.Tabular.register_pandas_dataframe and dataset.register option , which one should I use to register my dataset in Machine learning",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-04T21:03:33.35Z",
                "Answer_score":1,
                "Answer_body":"Hi, thanks for reaching out. After creating your dataset, use the register() method to register datasets with your workspace. The Dataset.Tabular.register_pandas_dataframe() method is used to create a TabularDataset from an in memory pandas dataframe and registers the TabularDataset to the workspace. Please review the following document for more details. Let us know if you have any further questions. Thanks.\n\n\n\n\n\n--please don't forget to Accept Answer if the reply is helpful. Thanks.--",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unknow error of AzureMLCompute",
        "Question_creation_time":1650387670807,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/818094\/unknow-error-of-azuremlcompute.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"when I add 2 rows sentence there, (whatever e.g. a= 1), then it shows this error , if I didn't add these 2 rows, it shows normal.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-20T09:41:52.723Z",
                "Answer_score":0,
                "Answer_body":"@SeiyaZelinShen-9380 This is a character limit on the script that can be used with the execute python script module.\nCould you please check if you can reduce the number of characters, probably by renaming some variables to a shorter name?\nAlso, have you copy pasted from any previous script in the module configuration? Please try to key in the script if reducing the characters is still reporting the issue. Thanks!!",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Connect to compute instance via ssh",
        "Question_creation_time":1626870444287,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/484265\/connect-to-compute-instance-via-ssh.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":1,
        "Question_body":"Hello,\n\nI have create a compute instance through the Azure ML Studio. Using the \"Applications\" list, I can access Jupyter, RStudio, a Terminal and connect via VS Code. But how can I just connect via SSH? I have added my SSH key to the instance while creating it, but cannot connect via the public IP address listed in the node details. I tried this as ssh azureuser@<compute-ip>\n\nIn the output of the azure ml compute show command in the cloud shell I noticed the values \"enable_public_ip\": false and \"ssh_public_access\": \"False\", but couldn't find anything regarding how to change these settings. Or is there any way to connect to them without a public ip?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-03T06:51:17.26Z",
                "Answer_score":0,
                "Answer_body":"Hey Yutong,\nI was just asking about compute instances created though the Azure ML Studio in general. Like the ones you create when you use the ML Studio, then select Compute in the sidebar and under Compute Instances create a new compute node. During creation, I selected the \"Enable SSH access\" option.\n\nI did figure out a solution to my problem of connecting to such an instance a bit later, and will leave it here for others with the same problem. As long as you select \"Enable SSH access\", the SSH access does work even though the azure ml compute show says \"ssh_public_access\": \"False\". My problem just was that I did not know the user name I had to log in as and also did not know which port I had to connect to. It turns out that the user name is always set to azureuser and the port seems to be either 50000 or 50001. You should therefore be able to connect via ssh azureuser@<PUBLIC_IP> -p 50000 or with -p 50001. You can find the public IP on the details page of the compute instance. If you want to know for sure which port it is, you can query the azure CLI with\n\naz resource show --ids \/subscriptions\/{subscriptionId}\/resourceGroups\/{resourceGroupName}\/providers\/Microsoft.MachineLearningServices\/workspaces\/{workspaceName}\/computes\/{computeName}\n\n\n\n\nand in the JSON response look under properties.sshSettings for adminUserName and sshPort.\n\nI just wished that this was documented somewhere in the Azure ML docs. I had to read through the source code of how the Azure ML VSCode extension connects to a compute instance to find this out.\n\nIs there any easier way to accomplish this? I needed the SSH access to forward specific ports from the compute instance to local and also to set up a Python SSH remote interpreter in IntelliJ",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Multi label classification on Azure ML Designer",
        "Question_creation_time":1651216958343,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/831308\/multi-label-classification-on-azure-ml-designer.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi, I would like to build an end-to-end ML pipeline for training a multi-label text classifier. When trying to achieve this, I see that the \"Train Model\" component does not allow the target label column to be a list of classes (Object type) which would be the case in Multi-label classification problems. Please correct me if I am wrong. Does the Train Model and Score Model components support multi-label classification?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-30T09:56:36.75Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. Yes, Train Model supports multi-classification but only a single column is supported. The selected column should contain the outcomes (classes). An example is provided in Designer > Show More Samples > Text Classification - Wikipedia SP 500 Dataset.\n\n\n\n\n\n--please don't forget to Accept Answer if the reply is helpful. Thanks.--",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Principal Component Analysis is Missing?",
        "Question_creation_time":1651249877603,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/832052\/principal-component-analysis-is-missing.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Classic ML Studio has PCA. The new one does not have PCA. What to do?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-30T10:38:18.71Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. Currently, only PCA-Based Anomaly Detection is supported in AML designer. A workaround would be to apply PCA using the Execute Python Script component or the SDK. You can also share feedback on ideas portal so you and others can upvote to enable the product team prioritize this feature.\n\n\n\n\n--please don't forget to Accept Answer if the reply is helpful. Thanks.--",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Store Raw JSON file from azureml.core.Run",
        "Question_creation_time":1651092990657,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/829188\/store-raw-json-file-from-azuremlcorerun.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi,\n\nin the details tab of a pipeline step (in an experiment) one of the last entries is \"See all properties\". Below that the Raw JSON file is linked and can be opened. Is there a way to save or access these Raw JSON file within the Python SDK?\n\nI want to store these file beside the model to guarantee traceability, if we deploy the registered model outside of Azure.\n\nThanks for your help",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-02T23:02:13.493Z",
                "Answer_score":0,
                "Answer_body":"Any update? Based on the doc from Microsoft, this is not available yet.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Cannot create compute instance",
        "Question_creation_time":1649411704767,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/805743\/cannot-create-compute-instance.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":5,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I'm busy going through the material to prepare for the DP100 Data Science Associate certification. I'm working through the section on Microsoft Azure Machine Learning, and I'm instructed to create a compute instance, but can't create a free one because I don't have enough quota (my available quota appears to be 0) for the required VM (or any VMs for that matter). I haven't created any compute resources yet, so I don't understand why I would have reached any kind of limit already - plus I still have $200 free credit to use. I've also upgraded to pay-as-you-go in hopes that would change something, which it hasn't.\n\nI've also requested a quota increase since that it what has been suggested for some similar posts, but it seems very strange to me that the default would be 0 quota, and that people would be required to request it? Has anyone else had this issue and solved it?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-08T20:01:33.637Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. A quota is a credit limit that is shared across all the services in your subscriptions. Limits vary by offer category type, such as free trial, pay-as-you-go, and virtual machine (VM) series (such as Dv2, F, and G). Here's how to manage the Azure Machine Learning compute quota for your subscription :\n\nGo to your Azure Machine Learning workspace in the Azure portal.\n\n\nOn the left pane, in the Support + troubleshooting section, select Usage + quotas to view your current quota limits and usage.\n\n\nSelect a subscription to view the quota limits. Filter to the region you're interested in.\n\n\nYou can switch between a subscription-level view and a workspace-level view.\n\nRaising a support request would be the best way to resolve issues regarding your subscription or service limits. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-20T21:22:25.257Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nI am experiencing the same issue, did you solve it ?\n\nThanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-21T06:17:46.413Z",
                "Answer_score":1,
                "Answer_body":"Hi, it's been solved as of 5 minutes ago. Unfortunately you have to request an increase in Quota through Microsoft. I did this on 07\/04\/22 and it took 8 days before someone got back to me, and then 6 more before it's been solved - so I would do that ASAP if I were you.\n\nIn the meantime, I've cloned the notebooks from the course locally (instead of to Azure ML) and for the most part been able to continue with the material. Good luck!!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-29T16:31:10.09Z",
                "Answer_score":0,
                "Answer_body":"30 days to use credits but need 15 days to get a compute instance. Makes sense.\n\nI'm bugged and discouraged. Its been 3 days, three FULL days, I'm trying to resolve this, just even get a minimal compute instance to just maybe! learn to use Azure ML. I'm so disapointed. All the videos and documentation make it look so easy, until it's not. I have posted my Quota increase, altho it says 0\/12 used. Should I assume I Could use 12 already? However, it's so confusing and demoralizing to learn here this will take up to two weeks just to get such a basic need solved.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-05-02T18:02:56.877Z",
                "Answer_score":0,
                "Answer_body":"I feel your pain, but thankfully you can continue with the content by cloning the notebooks and working locally instead of using ML notebooks on the compute instance. There were a couple notebooks I couldn't work through due to weird package conflicts, but for the most part it was fine. Once I got the quota increase sorted I could go back and run the other notebooks. I hope you haven't been too discouraged to continue, best of luck with the certification!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Cancel all child runs in Azure ML",
        "Question_creation_time":1649253299717,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/802549\/cancel-all-child-runs-in-azure-ml.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"How to I properly cancel all child runs in an Azure ML experiment? When I use the code below as expected from documentation, I get an error. \"RunConfigurationException:\nMessage: Error in deserialization. dict fields don't have list element type information. field=output_data, list_element_type=<class 'azureml.core.runconfig.OutputData'>...} with exception init() missing 2 required positional arguments: 'datastore_name' and 'relative_path'\"\n\nrun = Run.get(ws, 'run-id-123456789')\n\nfor child in run.get_children():\nprint(child.get_details())\ntry:\nchild.cancel()\nexcept Exception as e:\nprint(e)\ncontinue\n\nThe datasets and runs were configured properly because they run just fine.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-02T15:52:35.547Z",
                "Answer_score":0,
                "Answer_body":"You should cancel all the children run by canceling the parent.\n\nAny benefit to cancel child once a time? Just curious",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Generic framework for Azure machine Learning AutoML - Hyper parameter, featurization techniques",
        "Question_creation_time":1650817253897,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/824115\/generic-framework-for-azure-machine-learning-autom.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Currently we have implemented multiple Insurance use cases(Claims, Policy) using AutoML in Azure Machine Learning and created real-time endpoints.\nWe have a standard re-usable python scripts available where with few configuration changes, we are reusing this script for multiple use cases and quickly develop endpoints,\n\nCurrently, we need to apply our Insurance domain knowledge and enrich the training data set.\nTo do this, We understand there are features like Hyper parameter tuning, featurization, encoding techniques, etc. We understand that there are python libraries for that, but is there a generic framework\/coding available so that we can make use of this and implement across multiple use cases to increase the model accuracy. This is mainly to reduce the dependency on data scientist and reduce the azure ml implementation time",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-25T16:06:21.223Z",
                "Answer_score":0,
                "Answer_body":"@Rajavarman-1032 Thanks for the question. Previously, it was a black-box preprocessing, with user\u2019s preprocess=True\/False setting.\nNew change includes deprecation of preprocess and introduction of new field featurization, where featurization = \u2018auto\u2019 (for automatic featurization, comparable to preprocess=True) \/ \u2018off\u2019 (to turn off featurization, comparable to preprocess=False) \/ FeaturizationConfig (object to pass in customized configuration on featurization setting).\nFor more information on custom featurization as well as how to construct FeaturizationConfig is in this documentation: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train#customize-feature-engineering\nWe also have a notebook available with example in our git repo: https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/regression-hardware-performance-explanation-and-featurization\/auto-ml-regression-hardware-performance-explanation-and-featurization.ipynb",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"What is the easiest way to get pipeline failure alerts to email in Azure ML?",
        "Question_creation_time":1649202478243,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/801663\/what-is-the-easiest-way-to-get-pipeline-failure-al.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hello Everyone,\n\nWhat is the easiest way to get pipeline failure alerts to email in Azure ML?\nI tired to use Azure Logic Apps to react on the ML events, but fun fact that failed or cancelled ML operations don't trigger any event.\n\nHow do you monitor pipeline failures, guys?\n\nThank you in advance!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-06T14:03:20.75Z",
                "Answer_score":0,
                "Answer_body":"@BorisKorotkov-2570 Thanks, Can you share the code you are executing when you are getting the failure?.\nHere is the document to troubleshoot pipeline run failures.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure-ml defaults breaking pip",
        "Question_creation_time":1651090798580,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/829098\/azure-ml-core-breaking-pip.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hello,\n\nI've seen that the azureml-defaults package has been updated to version 1.41.0 updated in the past 2 days. https:\/\/pypi.org\/project\/azureml-defaults\/\n\nSince that update, I've been unable to update my web service as when the pip was installing the requirements for this dependency - it was left at the below stage in the screenshot.\n\nIt tries to run for 90 mins then times out. Was working perfectly before this update. Have tried decreasing the version as well and doesn't seem to work.\n\nThanks,\n\nCam",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-02T14:40:01.723Z",
                "Answer_score":0,
                "Answer_body":"Hi I have the same error. Is there any compatibilities issue?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Machine learning studio stuck",
        "Question_creation_time":1651358386807,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/832643\/machine-learning-studio-stuck.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"My project stuck again this week. It has been three hours for waiting.\n\nAny help?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-01T07:04:06.413Z",
                "Answer_score":0,
                "Answer_body":"Hello @Azadeh-9323\n\nI am sorry for your experience, but I just double check on backlog, we don't see any ongoing issue currently. Could you please share your region?\n\nPlease let us know if you still see this issue after refreshing and we are willing to help you anytime.\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"New Azure Machine Learning & Excel",
        "Question_creation_time":1651222482640,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/831512\/new-azure-machine-learning-amp-excel.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi All\n\nI have been working with Azure Machine Learning Studio (Classic) and have always found its integration with Excel super mega useful.\n\nAll I had to do was to get the URI and the API_Key of my web service and paste them on the Azure Machine Learning Add-In, that I had downloaded. Easy and useful.\n\nHowever, with the new Azure Machine Learning studio that does not seem possible any more.\n\nUnder the new Azure Machine Learning studio when I deploy a model I get a REST endpoint and that's it? !? I cannot find anywhere the API_key for my web service. I cannot even find a web service section as such.\n\nHow do I get the API_Key for the web service I need?\n\nIf I get the API_Key could I use it on the Excel Azure Machine Learning add-in. It looks as if this is no longer an option and we need to start using Power BI instead.\n\nI have read this interesting post where someone mentions a work around that consist of creating an Excel macro. Is this the best option? https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/236781\/consume-scoreing-api-in-excel.html\n\n\n\n\nThank you",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-30T11:48:21.697Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. The new AzureML integration with Excel isn't supported at this time. More details are provided on this thread. The alternative approach would be to use a Client or PowerBI to consume the model. For future reference, you can find your webservice endpoint and keys under Studio > Endpoints > Endpoint > Consume.\n\n\n\n\n\n--please don't forget to Accept Answer if the reply is helpful. Thanks.--",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Consume scoreing api in excel",
        "Question_creation_time":1611073754767,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/236781\/consume-scoreing-api-in-excel.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":1,
        "Question_body":"I created a new azure automl experiment and deployed it to an endpoint and can access the scoring URI via postman but how do I consume it in excel? Classic ml studio had the excel addin you can use but I don't see the same for URIs created and deployed from an automl experiment.\n\n\n\n\nThis Microsoft Developer video has a demo of exactly what I'm looking to do around the 32 min mark.\nhttps:\/\/youtu.be\/9FGuf55_Xtk?t=1915",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-20T12:52:45.4Z",
                "Answer_score":1,
                "Answer_body":"@steves-4330 Thanks for the question, Have a look here:\nhttps:\/\/github.com\/retkowsky\/AzureML_Excel\n\nThere is an Excel macro in the Excel file that call an Azure ML service deployed model.\nThere is a quick description of the process in the Word document available in this repo.\nYou can find here as well the Python notebook for creating & deploying the model. No autoML in it but not a big deal to adapt.\n\nPlease try the Consume web services portion Azure ML documentation? That could help you get started.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-04-29T16:09:45.88Z",
                "Answer_score":0,
                "Answer_body":"@steves-4330 @ramr-msft\n\nHi Steve did it work for you? I love this \"new\" Azure ML studio but its integration with Excel is not good. Microsoft seems to nudge us into Power BI.\n\nAlso it would be good to see some examples of web services that work with an Azure Machine Learning model rest endpoint. I would like to see practical examples.\n\nThank you",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning cost",
        "Question_creation_time":1607408839580,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/190053\/azure-machine-learning-cost.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":5,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"Hello,\n\nI am new to Azure Machine Learning, I have some questions related to cost\n\n1) What will be the cost breakup? (Workspace charges, Network charges, Disk Charges etc.)\n\n2) I saw that there were some charges for Bandwidth and Load balancer. Why is it getting charged and I am not able to see the details in Azure ML?\n\n3) I have a SQL Sever which is inside a Vnet (VPN Gateway) and I want to integrate it with Azure Machine Learning and use the data for my analysis. What all will be the charges for it?\n\n4) Is there a way to stop the computes automatically when i am not using it, as i dont want to be charged when i am not using the Azure Machine learning?\n\n5) Will there be any charges even though i am not using the Azure Machine learning? (Static Charges)",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-08T08:02:34.743Z",
                "Answer_score":2,
                "Answer_body":"@SrinivasanG-1471 Here are the charges that you could incur for the above setup:\n\n1) What will be the cost breakup? (Workspace charges, Network charges, Disk Charges etc.)\n\n\n\n\nFor Azure Machine learning the charges of ML services are nil for enterprise edition workspaces. Currently all the workspaces are using enterprise edition and if there are any basic edition workspaces they can be migrated with no down time. All other charges while using Azure ML workspace depends on the compute used and the setup of the compute. If they are enabled in a vnet then you could incur data charges according to vnet's pricing.\n\n\n\n\n2) I saw that there were some charges for Bandwidth and Load balancer. Why is it getting charged and I am not able to see the details in Azure ML?\n\nThe charges incurred for LB and bandwidth could be based on your setup and how the compute was setup to run the experiments. If you have also setup your designer to use virtual network then there could be charges on how the compute was setup with respect to the region. More details of the setup of workspace with private networks are detailed here. For the breakup of charges mentioned above you can raise a support request through the azure portal for billing which does not require any support plan to raise a ticket from the Help+Support tab on Azure portal.\n\n3) I have a SQL Sever which is inside a Vnet (VPN Gateway) and I want to integrate it with Azure Machine Learning and use the data for my analysis. What all will be the charges for it?\n\nOnce you are able to confirm if your vnet connection is successful you can get the data from Azure SQL database using the import data module from Azure ML designer. If you are planning to setup your own SQL server then this functionality is not supported with the available options, you might need to use the option URL via HTTP to get the required data in your experiments.\n\nIf you are attaching storage from different region than workspace region, it can result in higher latency and additional network usage costs.\n\n4) Is there a way to stop the computes automatically when i am not using it, as i dont want to be charged when i am not using the Azure Machine learning?\n\nThe option to shutdown compute instance automatically that is not in use is not available currently. You can stop the compute instances that are not required, for compute clusters you can set the minimum no. of nodes to 0 to ensure no compute is running when not in use.\n\n5) Will there be any charges even though i am not using the Azure Machine learning? (Static Charges)\n\nAzure ML learning enterprise edition workspaces do not have a surcharge i.e charges for using Azure ML. If there are any associated compute or storage or virtual networks there could be charges if used.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-10-25T10:18:13.413Z",
                "Answer_score":0,
                "Answer_body":"I had the same issue recently.\nI was being charged money for \"load balancer\" while obviously there is no place in Azure ML to start or stop a load balancer. I have checked my ML Studio under 'Compute' section make sure there is no running compute instances or clusters in ML.\n\nHow I solved the issue:\nI realised that I have created a real-time inference endpoint and I suspect that can be costing me money. I deleted that endpoint and in the next few days I can see the 'load balancer' cost has disappeared. Problem solved.\n\nConclusion:\na real-time inference endpoint requires some computing resources (I believe it's an AKS cluster in this case) so there should be a cost.\nHowever, this computing resource is not shown under the 'compute' section. Not under any of the 4 tabs there (compute instances, computer clusters, inference clusters, attached computes). I believe it should show under the \"inference cluster\" tab in the compute section, but it didn't.\nIn 'cost analysis', this cost has been incorrectly categorised to \"load balancer\". This categorisation is not only very confusing but also incorrect.\n\n\n\n\n@romungi-MSFT Could you please advise if my finding is correct or not?",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-25T09:56:17.43Z",
                "Answer_score":0,
                "Answer_body":"@taowang-5804\nI too saw a lot of Load Balancer charged in my invoice, as a matter of fact I got charged everyday for Load Balancer for 2 months. I am sure that the total amount of time I would have kept a Real Time Endpoint live would not exceed 3-4 hours during the course of 2 months. I have contacted helpdesk, looking forward to their response.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-28T10:14:03.033Z",
                "Answer_score":0,
                "Answer_body":"Hi,\nI also noticed some load balancer costs today and found a way to stop the LB costs.\nBased on this Microsoft Docs: https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/main\/articles\/machine-learning\/concept-plan-manage-cost.md#costs-might-accrue-before-resource-deletion\n\nEach VM is billed per hour it is running. Cost depends on VM specifications. VMs that are running but not actively working on a dataset will still be charged via the load balancer. For each compute instance, one load balancer will be billed per day. Every 50 nodes of a compute cluster will have one standard load balancer billed. Each load balancer is billed around $0.33\/day. To avoid load balancer costs on stopped compute instances and compute clusters, delete the compute resource. One virtual network will be billed per subscription and per region. Virtual networks cannot span regions or subscriptions. Setting up private endpoints in vNet setups may also incur charges. Bandwidth is charged by usage; the more data transferred, the more you are charged.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-29T05:38:58.373Z",
                "Answer_score":0,
                "Answer_body":"@moba-7946\n\nI had created my VMs on Jan 2021. My billings were close to Rs 800 per month($12 per month). Not only that, it remained consistent and only changed in a minor way whenever I used them for any ML training work.\n\nBut now all of a sudden since Feb 2022 I am being charged for a LB! and my costs have gone up >3x. I've been in touch with some people in the billing team but they are taking their own sweet time to respond.\n\nI am willing to accept that this is a fair charge as long as they can answer the following:\n\n\nLocate the LB linked to my account\nIs the LB charge a new addition ? if not then why was I never billed before for instances I've owned since Jan 2021 ?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Snapshot Creation Issue - Azure ML Pipeline",
        "Question_creation_time":1651144125440,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/830075\/snapshot-creation-issue-azure-ml-pipeline.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I have created new compute cluster, deleted the older versions, deleted blobs in data store, deleted unused files from the notebook instance, tried increasing the SNAPSHOT_MAX_SIZE_BYTES = 2000000000 but none of them are working.\n\nIt was showing the snapshot size issue (300 mb and 200 files allowed) previously so we included\nazureml._restclient.snapshots_client.SNAPSHOT_MAX_SIZE_BYTES = 4000000000 ,which resolved the issue then, but we are unable to find solution for this one.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure Machine Learning service was configured with a Load Balancer & Premium SSD Managed Disks (Cost Issue)",
        "Question_creation_time":1651101671863,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/829249\/azure-machine-learning-service-was-configured-with.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I create an Azure Machine Learning service and it was configured with a Load Balancer & Premium SSD Managed Disks. Is this configuration correct?\n\nI chose a Public Endpoint for the ML service. Is this the reason for the Load Balancer?\n\nIs there a way for me to change the \"Premium SSD Managed Disks\" to a lower-cost storage?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-28T10:42:07.783Z",
                "Answer_score":0,
                "Answer_body":"@TerrenceRideau-6599 The load balancer is a sub resource that is created when you create the compute instance or cluster. These resources are charged unless the compute instance or cluster is completely deleted. If the compute is in stopped state the resources might still accrue costs. Please check this section of the documentation for details. The endpoints should not be the reason for billing under load balancer. If you have any questions regarding billing you can always raise a azure support case from azure portal to seek clarification.\n\nThe storage that is created with the compute instances chosen from Azure ML portal ml.azure.com cannot be changed. If you would like to use a custom compute type with lower cost storage then you need to use attached compute which is actually created from Azure portal and then added to Azure ML compute(attached) to be used for your experiments. I hope this helps!!\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How could I upload notebooks to my AzureML workspace programatically",
        "Question_creation_time":1651101620807,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/829311\/how-could-i-upload-notebooks-to-my-azureml-workspa.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Would like to upload Jupyter notebooks from different sources like GitHub into my workspace either directly or through my local machine (download locally first and then upload) but I would like to do it programmatically. Either with the AzureML SDK or azure cli",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-28T00:07:22.393Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. You can use compute instance terminal in AML notebooks to clone the GitHub repo. There's currently no option to upload notebooks to your workspace programmatically using sdk or cli.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"AutoMLException: Message: Could not find a model with valid score for metric 'accuracy'. Please ensure that at least one run was successfully completed with a valid score for the given metric.",
        "Question_creation_time":1651063933880,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/828516\/automlexception-message-could-not-find-a-model-wit.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi, I am trying to make a classification using automl service , I've chosen KNN as model to train and for the primary metric i used accuracy . Based on the automl documentation the metric accuracy can be used with this type of classification task, but I get the error : AutoMLException: Message: Could not find a model with valid score for metric 'accuracy'. Please ensure that at least one run was successfully completed with a valid score for the given metric. when I checked azure ml studio I find this error of the run is that means that the dataset that i am using can be trained on KNN model ? ![197051-image.png][1] [1]: \/answers\/storage\/attachments\/197051-image.png",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-27T22:33:35.073Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. I can confirm that 'accuracy' is a valid primary metric for classification tasks. It's possible that your dataset isn't compatible due to high dimensionality, missing or sparse data. If you click on the error message details, there might be some more information that can help understand what caused the error. Review Data guardrails to identify the issues with your dataset. Also, try to allow additional models to see if it helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is it possible to run Azure cluster (Azure ML) on spot instances?",
        "Question_creation_time":1650979096333,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/826904\/is-it-possible-to-run-azure-cluster-azure-ml-on-sp.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hello, I wonder if it's possible to use spot instances to run experiments in Azure ML as it's implemented for VM https:\/\/azure.microsoft.com\/en-us\/services\/virtual-machines\/spot\/?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-27T14:59:37.54Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. There's no way to enable a vm as spot instance when creating a compute instance in AML. The workaround would be to attach vm as compute. Please note that AML only supports virtual machines that run Ubuntu and requires the virtual machine to have a public IP address.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Real-time endpoint doesn't work (error 502)",
        "Question_creation_time":1609249050140,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/213249\/real-time-endpoint-doesn39t-work-error-502.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":2,
        "Question_body":"Hello. I created a training pipeline using the ML designer, and also created a real-time inferencing pipeline after that. The training pipeline ran completely without any error. I also published the real-time inferencing pipeline successfully. In the end, I deployed the real-time inferencing pipeline to AKS and it resulted in a real-time endpoint with a Healthy state.\n\nHowever, when I want to test the endpoint from the \"Endpoints\" page, it returns nothing! Just a red empty box.\n\n\nI tried to run the example consumption codes in the \"Consume\" tab in the Notebooks section of the ML Studio.\n\n\n\n\n\nBut again, it didn't give any results and returned the following error description:\n\n\n\n\n\n\nI don't know what causes this issue. I appreciate if you could help me with this. Thanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-30T12:05:07.557Z",
                "Answer_score":1,
                "Answer_body":"@MehdiSamsami-7668 Thanks for the question. Can you please enable application insights as mentioned in the doc and share the logs to check. Also please share link to the sample that you are trying. Doc for creation of real-time inference endpoint authenticating to the inference cluster and doc to consume webservice Input and output module.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-03-01T03:18:00.003Z",
                "Answer_score":0,
                "Answer_body":"I am having same issue",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error when using azure trained model on yolov5",
        "Question_creation_time":1650115703107,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/814600\/error-when-using-trained-model-on-yolov5.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi, I trained a model with Azure Machine Learning studio for an objects detection tasks using yolov5 as the model. I created the experiment using the notebook and it ran successfully for a little less than 30 epochs. The experiment status tell me that it completed successfully and I have access to the file \"model.pt\" in the output folder of the child run.\n\nNow I would like to use that trained model and test it with the github version of yolov5 installed on my local computer, but when I use it, it simply doesn't work and display an error (it works with my own trained model from my local computer), the error is the following:\n\nTraceback (most recent call last):\nFile \"C:\\Users\\Username\\Desktop\\yolov5\\detect.py\", line 261, in <module>\nmain(opt)\nFile \"C:\\Users\\Username\\Desktop\\yolov5\\detect.py\", line 256, in main\nrun(**vars(opt))\nFile \"C:\\Users\\Username\\Desktop\\yolov5\\lib\\site-packages\\torch\\autograd\\grad_mode.py\", line 27, in decorate_context\nreturn func(args, *kwargs)\nFile \"C:\\Users\\Username\\Desktop\\yolov5\\detect.py\", line 92, in run\nmodel = DetectMultiBackend(weights, device=device, dnn=dnn, data=data)\nFile \"C:\\Users\\Username\\Desktop\\yolov5\\models\\common.py\", line 305, in init\nmodel = attempt_load(weights if isinstance(weights, list) else w, map_location=device)\nFile \"C:\\Users\\Username\\Desktop\\yolov5\\models\\experimental.py\", line 98, in attempt_load\nmodel.append(ckpt['ema' if ckpt.get('ema') else 'model'].float().fuse().eval()) # FP32 model\nKeyError: 'model'\n\nSo is there an explanation, or does the model simply doesn't work with classic yolov5 installations ? Either way I would appreciate the help. Thank you !",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-18T07:15:39.15Z",
                "Answer_score":0,
                "Answer_body":"@EricNeliz-1395 Are you able to deploy the model as a realtime endpoint directly on Azure? I couldn't really find any direct reference to using the model out of the box on local installations for yolo. One project does help to document steps to use yolov3 with keras locally and on azure. Is this an option to convert your model to a format like keras?\n\n\n\n\nRef: Micheleen Harris",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure machine learning cannot evaluate model",
        "Question_creation_time":1650117583373,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/814652\/azure-machine-learning-cannot-evaluate-model.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I create a trained model in Azure machine learning, when I use it to predict a new set of data, the evaluate model cannot show the result, it's all empty. How can I solve the problem?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Endpoints for getting metadata about published models?",
        "Question_creation_time":1649425228733,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/805976\/endpoints-for-getting-metadata-about-published-mod.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"My question centers around working with AML models that have been published as web services, as described here:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=azure-portal\n\nAre there any endpoints or ways of obtaining more detailed information about a published model? For example, the documentation states that inputs to the model are passed in via a \"data\" property, and obviously, this will vary my the model:\n\n{\n\"data\":\n[\n<model-specific-data-structure>\n]\n}\n\nIs there a way to programatically find out what the model expects as input?\n\nThe full 'wish-list' of metadata info we'd like is listed here:\n\nWhat models are available for serving\n\n\nWhat is the model prediction endpoint\n\n\nWhat are the required inputs and their data types\n\n\nWhat are the model outputs and data types\n\nAre there any endpoints or any way at getting to this information?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-10T22:33:36.347Z",
                "Answer_score":0,
                "Answer_body":"Hello @MKRP-6344\n\nThanks for reaching out to us, I will answer your question below, at the meantime, if you feel like I am not getting your point well, please point it out and correct me.\n\nI think you are mentioning how to monitor published model and collect data, there are several choice depends on the data you want to collect:\n\nCollect data from models in production - https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-data-collection\n\nThe following data can be collected:\n\nModel input data from web services deployed in an AKS cluster. Voice audio, images, and video are not collected.\nModel predictions using production input data.\n\nOnce collection is enabled, the data you collect helps you:\n\nMonitor data drifts on the production data you collect.\nAnalyze collected data using Power BI or Azure Databricks\nMake better decisions about when to retrain or optimize your model.\nRetrain your model with the collected data.\n\n2 . Monitor and collect data from ML web service endpoints - https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-app-insights\n\nYou can use Azure Application Insights to collect the following data from an endpoint:\n\nOutput data\nResponses\nRequest rates, response times, and failure rates\nDependency rates, response times, and failure rates\nExceptions\n\n3 . More details from Data Drift - https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-monitor-datasets?tabs=python\n\nWith Azure Machine Learning dataset monitors (preview), you can:\n\nAnalyze drift in your data to understand how it changes over time.\nMonitor model data for differences between training and serving datasets. Start by collecting model data from deployed models.\nMonitor new data for differences between any baseline and target dataset.\nProfile features in data to track how statistical properties change over time.\nSet up alerts on data drift for early warnings to potential issues.\nCreate a new dataset version when you determine the data has drifted too much.\n\nHope above information helps, please let us know if you need further helps!\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks a lot.",
                "Answer_comment_count":6,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Run experiment fails when using a pre-build Docker image as environment",
        "Question_creation_time":1644997645313,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/737518\/run-experiment-fails-when-using-a-pre-build-docker.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"My co-workers are using pre-build docker images for our developing environment in Azure Machine Learning Service.\nIn a separate script, they have registered these environments with the command myenv.register(workspace=ws). In another script, I should use their environment for testing our model.\n\nIn order to get one of their environments, I use the command registered_env = Environment.get(ws, 'the-specific-environment-name')\n\nUnfortunately, this does not work when I use registered_env for the experiment. I get the error \"Authentication failed for container registry name_of_their_container_registry.azurecr.io\". The experiment run works perfectly when I copy their environment definition code into my script instead of using the command registered_env = Environment.get(ws, 'the-specific-environment-name').\n\nHowever, I cannot copy everytime their environment definition code into my script.\nHow can I get the environment into my script which has been defined in another script?\n\nThis StackOverFlow post is quite related to my problem:\nhttps:\/\/stackoverflow.com\/questions\/71131403\/registering-and-getting-an-environment-in-azure-machine-learning-studio-that-der\n\n\n\n\n\nTo illustrate what my problem is, here are some code samples.\n\nThis code sample is working:\n\n registry = ContainerRegistry()\n registry.address = <DockerRegistryAddress>\n registry.username = <UserName>\n registry.password = <Password>\n exemplarily_env_docker_image = Environment.from_docker_image('exemplarily-env_Docker-image-AzureRegistry', <DockerImageAddress>, container_registry=registry, conda_specification=None, pip_requirements=None)\n    \n exemplarily_env_docker_image.python.user_managed_dependencies = True\n    \n # Registering and getting of an environment that derives from a Docker Image is not working because the credentials are not saved\n exemplarily_env_docker_image.register(workspace=ws)\n model = Model(ws, 'exemplarily_model')\n    \n inference_config = InferenceConfig(environment=exemplarily_env_docker_image, \n                                    source_directory='.\/source_dir', \n                                    entry_script='.\/score.py') \n deployment_config = LocalWebservice.deploy_configuration(port=6789)\n    \n service = Model.deploy(\n     ws,\n     \"myservice\",\n     [model],\n     inference_config,\n     deployment_config,\n     overwrite=True,\n )\n    \n service.wait_for_deployment(show_output=True)\n print(service.get_logs())\n\n\n\n\nNow, I do a small change and the code sample is not working anymore:\n\n registry = ContainerRegistry()\n registry.address = <DockerRegistryAddress>\n registry.username = <UserName>\n registry.password = <Password>\n exemplarily_env_docker_image = Environment.from_docker_image('exemplarily-env_Docker-image-AzureRegistry', <DockerImageAddress>, container_registry=registry, conda_specification=None, pip_requirements=None)\n    \n exemplarily_env_docker_image.python.user_managed_dependencies = True\n # Registering and getting of an environment that derives from a Docker Image is not working because the credentials are not saved\n exemplarily_env_docker_image.register(workspace=ws)\n model = Model(ws, 'exemplarily_model')\n    \n reg_env = Environment.get(ws, \"exemplarily-env_Docker-image-AzureRegistry\")\n inference_config = InferenceConfig(environment=reg_env, \n                                    source_directory='.\/source_dir', \n                                    entry_script='.\/score.py') \n    \n deployment_config = LocalWebservice.deploy_configuration(port=6789)\n    \n service = Model.deploy(\n     ws,\n     \"myservice\",\n     [model],\n     inference_config,\n     deployment_config,\n     overwrite=True,\n )\n    \n service.wait_for_deployment(show_output=True)\n print(service.get_logs())\n\n\n\n\nWhat is working:\n\n registry = ContainerRegistry()\n registry.address = <DockerRegistryAddress>\n registry.username = <UserName>\n registry.password = <Password>\n exemplarily_env_docker_image = Environment.from_docker_image('exemplarily-env_Docker-image-AzureRegistry', <DockerImageAddress>, container_registry=registry, conda_specification=None, pip_requirements=None)\n    \n exemplarily_env_docker_image.python.user_managed_dependencies = True\n # Registering and getting of an environment that derives from a Docker Image is not working because the credentials are not saved\n exemplarily_env_docker_image.save_to_directory(path=\".\/env\", overwrite=True)\n model = Model(ws, 'exemplarily_model')\n    \n reg_env = Environment.load_from_directory(path=\".\/env\")\n inference_config = InferenceConfig(environment=reg_env, \n                                    source_directory='.\/source_dir', \n                                    entry_script='.\/score.py') \n    \n deployment_config = LocalWebservice.deploy_configuration(port=6789)\n    \n service = Model.deploy(\n     ws,\n     \"myservice\",\n     [model],\n     inference_config,\n     deployment_config,\n     overwrite=True,\n )\n    \n service.wait_for_deployment(show_output=True)\n print(service.get_logs())\n\n\n\n\nWhy is the middle code sample not working? Is this a bug?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-18T05:15:10.98Z",
                "Answer_score":0,
                "Answer_body":"@AlexanderPakakis-0994 Thanks, register() returns a registered instance of environment. If environment was previously registered the corresponding version will be returned, otherwise AzureML service will create a new version and return back to the client. Now, when you do Environment.get() with no version specified, it returns you latest registered, that might be different that you would expect playing a lot with your environment. So, can you please just see repr of the environment returned by register() and by get(). or simply check env.register(ws).version and Environment.get(ws, name).version. I believe that will shed the light on the mystery. Please do not rely on the latest version, but specify the exact version or label, latter is more flexible and preferred.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure SQL Managed Instance PREDICT with an ONNX model",
        "Question_creation_time":1650460466510,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/819485\/azure-sql-managed-instance-predict-with-an-onnx-mo.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":1,
        "Question_body":"I repeat the example from https:\/\/docs.microsoft.com\/en-us\/azure\/azure-sql-edge\/deploy-onnx \"Deploy and make predictions with an ONNX model and SQL machine learning\" In this quickstart, you'll learn how to train a model, convert it to ONNX, deploy it to Azure SQL Edge, and then run native PREDICT on data using the uploaded ONNX model.\n\nSuccessfully create a model using Python, convert to onnx format, I test the model using Python, save the model to the database, load the necessary data and try to execute the SQL query\nUSE onnx\nDECLARE @model VARBINARY(max) = (\nSELECT DATA\nFROM dbo.models\nWHERE id = 1\n);\nWITH predict_input\nAS (\nSELECT TOP (1000) [id]\n, CRIM\n, ZN\n, INDUS\n, CHAS\n, NOX\n, RM\n, AGE\n, DIS\n, RAD\n, TAX\n, PTRATIO\n, B\n, LSTAT\nFROM [dbo].[features]\n)\nSELECT predict_input.id\n, p.variable1 AS MEDV\nFROM PREDICT(MODEL = @model, DATA = predict_input, RUNTIME=ONNX) WITH (variable1 FLOAT) AS p;\n\nAs a result I get an error Msg 102, Level 16, State 5, Line 27 Incorrect syntax near 'RUNTIME'.\n\nI can't figure out what's wrong. The documentation clearly says \"The RUNTIME = ONNX argument is only available in Azure SQL Edge, Azure Synapse Analytics, and is in Preview in Azure SQL Managed Instance.\"",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-20T13:29:53.25Z",
                "Answer_score":0,
                "Answer_body":"I think there is a misunderstanding here. The quickstart article named \"Deploy and make predictions with an ONNX model and SQL machine learning\" can be successfully implemented only with Azure SQL Edge and cannot be implemented with Azure SQL Managed Instance.\n\nYou cannot have an ONNX model and make predictions with it on Azure SQL Managed Instance. Please deploy Azure SQL Edge on an IoT device using this documentation.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-04-21T08:13:34.65Z",
                "Answer_score":0,
                "Answer_body":"Thanks for the answer.\nIn the document \"Native scoring using the PREDICT T-SQL function with SQL machine learning\"\nhttps:\/\/docs.microsoft.com\/en-us\/sql\/machine-learning\/predictions\/native-scoring-predict-transact-sql?view=sql-server-ver15\nit says that Azure SQL Managed Instance supports the onnx format\n\nIn the document \"PREDICT (Transact-SQL)\"\nhttps:\/\/docs.microsoft.com\/en-us\/sql\/t-sql\/queries\/predict-transact-sql?view=sql-server-ver15\nthe following is written \"Important. Support for PREDICT is in Preview in Azure SQL Managed Instance\"\n\nAs far as I understand, PREDICT with support for the onnx format is under development?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Loading pickle object in entry script in Azure ML",
        "Question_creation_time":1633278181287,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/575512\/loading-pickle-object-in-entry-script-in-azure-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":2,
        "Question_body":"I have an entry script that loads a pickled tokenizer object from Tensorflow and the model itself. When I try to deploy, locally or otherwise, I get an error saying something broke in the init function in the score.py script. Commenting out the tokenizer and the deployment works so I'm sure it's because of it. This is how I define the function:\n\n def init():\n     global tokenizer, model\n     tokenizer_path = os.path.join('.\/objs', 'tokenizer.pkl') # tried absolute path as well, didn't work\n     tokenizer = pickle.load(tokenizer_path)\n     # tokenizer = pickle.load(open(tokenizer_path, 'rb')) # also tried this, didn't work\n     model = tf.keras.models.load_model(os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.h5'))\n\n\n\nIs that the correct way to load a pickle object in the entry script? Any tips would be appreciated.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-04T13:34:19.55Z",
                "Answer_score":0,
                "Answer_body":"@2JK I think this should help.\n\nfrom sklearn.externals import joblib\n\n tokenizer_path = os.path.join('.\/objs', 'tokenizer.pkl') # tried absolute path as well, didn't work\n tokenizer = joblib.load(tokenizer_path)\n\n\n\n\nDid you also try the absolute path in your tokenizer_path?",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-20T17:22:23.093Z",
                "Answer_score":0,
                "Answer_body":"I have the same problem . did you get a solution ?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Deleting workspace resources after account automatically logged out by microsoft.",
        "Question_creation_time":1649349071340,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/804671\/deleting-workspace-resources-after-account-automat.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Dear Team,\n\nMy workspace on ML studio was logged ou and when I tried logging in it asked security details that I provided. I got a repy stating that the microsoft account will be validated within 1 month(30 days). I would like to delete all my resources and other compute instances so that I will not be billed for a daily charge. But to do so I am unable to login due to the 30 day timeline. Any support on deleting this resource woul be much appreciated. Thanks, Aakash.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-18T11:38:55.09Z",
                "Answer_score":0,
                "Answer_body":"For student account as soon as the $100 credit expires the resources will be stopped. If you would like to check about your account status you can reach out to support using any of these options.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How can we use Azure Machine Learning solution during an educational session with 20 students ?",
        "Question_creation_time":1650359134483,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/817296\/how-can-we-use-azure-machine-learning-solution-dur.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"How can we use Azure Machine Learning solution during an educational session with 20 students ? Can we share compute and storage resources between students?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-20T09:08:08.3Z",
                "Answer_score":0,
                "Answer_body":"@anonymous user Thanks, Please follow the below for managing compute instances. https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-compute-instance#managing-a-compute-instance All data scientists or developers need is access to the AzureML Workspace and they will have access to a shared file share where everyone\u2019s notebooks can be accessed. All notebook require a Compute Instance(CI). CI is a managed VM that exists in AzureML.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Reading dataset after uploading to storage",
        "Question_creation_time":1650301669787,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/816330\/reading-dataset-after-uploading-to-storage.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"hi,\n\nI created various datasets but within my python notebook, how do i read it?\n\nSo currently if this is what I have:\n\nx_train_df = pd.read_csv('data_reviews\/x_train.csv')\n\nwhat should I replace it with?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-19T13:17:17.23Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. I assume you registered a datastore and uploaded datasets to storage. To access the data from storage depends on whether it's structured or unstructured. For unstructured data you can access using FileDataset and for structured data you can access using TabularDataset. The following code snippet shows how to create dataset from datastore. For FileDataset, review Mount vs Download and sample notebook.\n\n from azureml.core import Workspace, Datastore, Dataset\n    \n datastore_name = 'your datastore name'\n    \n # get existing workspace\n workspace = Workspace.from_config()\n        \n # retrieve an existing datastore in the workspace by name\n datastore = Datastore.get(workspace, datastore_name)\n    \n # create a TabularDataset from 3 file paths in datastore\n datastore_paths = [(datastore, 'weather\/2018\/11.csv'),\n                    (datastore, 'weather\/2018\/12.csv'),\n                    (datastore, 'weather\/2019\/*.csv')]\n    \n weather_ds = Dataset.Tabular.from_delimited_files(path=datastore_paths)\n\n\n\n\n\n--please don't forget to Accept Answer if the reply is helpful. Thanks.--",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Training a TensorFlow model in Azure ML",
        "Question_creation_time":1649367124903,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/804968\/training-a-tensorflow-model-in-azure-ml.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I am following the link below for training a TensorFlow model in Azure ML:\n\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/ml-frameworks\/tensorflow\/train-hyperparameter-tune-deploy-with-tensorflow\/train-hyperparameter-tune-deploy-with-tensorflow.ipynb\n\nHowever, as my training dataset is in a container named \"sample-datasets\" in ADLS Gen2, I changed the following code (in the above link) to refer to the paths in my data lake. So I replaced code A (in the link above) with code B (my code)\n\nCode A:\n\nurllib.request.urlretrieve('https:\/\/azureopendatastorage.blob.core.windows.net\/mnist\/train-images-idx3-ubyte.gz', filename=os.path.join(data_folder, 'train-images-idx3-ubyte.gz'))\nurllib.request.urlretrieve('https:\/\/azureopendatastorage.blob.core.windows.net\/mnist\/train-labels-idx1-ubyte.gz',\nfilename=os.path.join(data_folder, 'train-labels-idx1-ubyte.gz'))\nurllib.request.urlretrieve('https:\/\/azureopendatastorage.blob.core.windows.net\/mnist\/t10k-images-idx3-ubyte.gz', filename=os.path.join(data_folder, 't10k-images-idx3-ubyte.gz'))\nurllib.request.urlretrieve('https:\/\/azureopendatastorage.blob.core.windows.net\/mnist\/t10k-labels-idx1-ubyte.gz',\nfilename=os.path.join(data_folder, 't10k-labels-idx1-ubyte.gz'))\n\n\n\n\nCode B:\n\nfrom azureml.core.dataset import Dataset\nurllib.request.urlretrieve('https:\/\/lakehousestgenrichedzone.dfs.core.windows.net\/sample-datasets\/train-images-idx3-ubyte.gz', filename=os.path.join(data_folder, 'train-images-idx3-ubyte.gz'))\nurllib.request.urlretrieve('https:\/\/lakehousestgenrichedzone.dfs.core.windows.net\/sample-datasets\/train-labels-idx1-ubyte.gz', filename=os.path.join(data_folder, 'train-labels-idx1-ubyte.gz'))\nurllib.request.urlretrieve('https:\/\/lakehousestgenrichedzone.dfs.core.windows.net\/sample-datasets\/t10k-images-idx3-ubyte.gz', filename=os.path.join(data_folder, 't10k-images-idx3-ubyte.gz'))\nurllib.request.urlretrieve('https:\/\/lakehousestgenrichedzone.dfs.core.windows.net\/sample-datasets\/t10k-labels-idx1-ubyte.gz', filename=os.path.join(data_folder, 't10k-labels-idx1-ubyte.gz'))\n\nBut I receive the following error:\n\nHTTPError: HTTP Error 401: Server failed to authenticate the request. Please refer to the information in the www-authenticate header.\n\nCan you please let me know how I can train the model using my data which are stored in the data lake? More precisely, how my Python code can copy the training dataset from my data lake into data_folder?\n\nPS: Please note that I have already granted the Blob Storage data Contributor role on my data lake storage account to my Azure ML workspace as a managed identity.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-08T12:21:38.973Z",
                "Answer_score":0,
                "Answer_body":"anonymous user I have not worked on ADLS scenarios with Azure ML but I have added the ADLS tag to this thread for others to chip in and add their views.\n\nBased on the documentation for ADLS REST API it supports Azure Active Directory (Azure AD), Shared Key, and shared access signature (SAS) authorization with the APIs that are available to download the files from its storage. So, I think a direct download might not work in this case without authentication.\n\nI think the easiest way to get your files locally from ADLS is to use the python SDK to authenticate using account key or AD as listed here.\n\nIf you have many files that needs to be downloaded and referenced in your ML experiments then you may also consider to use the import data module of designer for designer experiments or register them as dataset from dataset tab of ml.azure.com which can also be referenced using the Azure ML SDK.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-04-19T15:42:44.427Z",
                "Answer_score":0,
                "Answer_body":"I solved the problem by assigning an user-assigned managed identity to the target compute to access my ASDLS Gen2",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Issue in my MLOPs CD pipeline.",
        "Question_creation_time":1649140550093,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/800334\/issue-in-my-mlops-cd-pipeline.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Deploying my model to ACI takes forever and fails without any error message. In the ML workspace, the status of the deployed endpoint is unhealthy. I checked common errors while deployment but could not solve the problem. Pleas help. The deployment is never successful and it keeps running.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-06T07:47:34.493Z",
                "Answer_score":0,
                "Answer_body":"anonymous user Thanks for the question. Could you clarify the architecture of your model deployment? In particular, are you using a custom docker container for it? Also, usually ACI would be used for testing, but I'd recommend investigating AKS for production model deployment.\n\nI would deploy the container into a local machine\/VM with Docker to see the exact detail error message which you don't see via ACI deployment.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unable to run conda package manager. AzureML uses conda to provision python",
        "Question_creation_time":1648968542177,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/798162\/unable-to-run-conda-package-manager-azureml-uses-c.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi I was trying to run the 14. 'Interpret Models' exercise from https:\/\/aka.ms\/mslearn-dp100 in Azure ML Jupyter notebook, and was met with following error:\n\n\n\n\n\ni have installed the relevant packages and was unsure how to resolve it",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-05T07:39:22.86Z",
                "Answer_score":0,
                "Answer_body":"@BoonChong-7038 Thanks for the question. Here is the document and the sample to add the conda dependencies.\n\nIf you do not need any python dependencies on top your base image you can set user_managed_dependencies to True and base image will be used as is and no additional dependencies will be installed.\n\nhttps:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.conda_dependencies.condadependencies?view=azure-ml-py",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Studio Versioning",
        "Question_creation_time":1649276461560,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/803089\/azure-ml-studio-versioning.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Is there a way to pass in a specific version number parameter to render the studio UI that will exclude new \/ preview features?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-07T07:33:03.19Z",
                "Answer_score":0,
                "Answer_body":"@CesarArocho-0461 Currently there is no parameter that can be used to load a different version of the ML studio ml.azure.com\nBased on the current design of the studio features of the designer are available based on subscription and accounts. Is there a specific functionality that you want to provide feedback on?\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Notebook",
        "Question_creation_time":1603705986700,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/139062\/azure-notebook.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":1,
        "Question_body":"I can&#39;t create a project in Azure Notebooks. It shows on the page to migrate my notebooks. So, which notebooks should I use from the alternatives for use Jupyter noteboks on cloud?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-27T06:24:41.31Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us.\n\nThe Azure Notebooks preview is ending and the site is retiring on January 15th, 2021. You can enjoy powerful, integrated Jupyter notebooks with the following products and services from Microsoft and GitHub.\n\nNotebooks in Visual Studio Code\nVS Code is a free code editor and development platform that you can use locally or connected to remote compute. Combined with the Python extension, it offers a full environment for Python development including a rich experience for working with Jupyter notebooks. If you want a best-in-class, free Jupyter experience with the ability to leverage your compute of choice, this is a great option.\nUsing VS Code, you can develop and run notebooks against remotes and containers. To make the transition easier from Azure Notebooks, we have made the container image available so it can use with VS Code too.\nInstructions on how to get started with notebooks in VS Code and migrate your Azure Notebooks projects (optionally using the container)\n\nGitHub Codespaces beta\nGitHub Codespaces beta provides cloud-hosted environments where you can edit your notebooks using Visual Studio Code or your web browser, and store them on GitHub. GitHub Codespaces beta offers the same great Jupyter experience as VS Code, but without needing to install anything on your device.\nIf you don\u2019t want to set up a local environment and prefer a cloud-backed solution, then creating a codespace is a great option.\nInstructions on how to get started with notebooks in GitHub Codespaces beta and migrate your Azure Notebooks projects\n\nAzure Machine Learning\nAzure Machine Learning provides an end-to-end machine learning platform to enable users to build and deploy models faster on Azure. Azure ML allows you to run notebooks on a VM or a shared cluster computing environment.\nIf you are in need of a cloud-based solution for your ML workload with experiment tracking, dataset management, and more, we recommend Azure Machine Learning.\nInstructions on how to get started with Azure Machine Learning and how to migrate your Azure Notebooks projects\nAzure Lab Services\nAzure Lab Services allows educators to easily setup and provide on-demand access to preconfigured VMs for an entire classroom.\nFor educators looking for a way to work with notebooks and cloud compute in a tailored classroom environment, Lab Services is a great option.\nInstructions on how to get started with Azure Lab Services and how to migrate your Azure Notebooks projects\n\nGitHub\nGitHub provides a free, source-control-backed way to store notebooks (and other files), share your notebooks with others, and work collaboratively.\nIf you\u2019re looking for a way to share your projects and collaborate with others, GitHub is a great option.\nInstructions on how to get started with GitHub and how to migrate your Azure Notebooks projects\n\nThanks a lot.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-13T01:26:37.527Z",
                "Answer_score":0,
                "Answer_body":"MICROSOFT HAS UTTERLY LOST ME WITH THIS (NON) EXPLANATION...\n\nEXPLAIN THIS TO ME:\n1. Azure Notebooks is a CLOUD-based JUPYTER NOTEBOOK DEVELOPMENT and EXECUTION environment.\nKEY CRITERIA:\n- must be CLOUD-hosted;\n- must provide for a \"NOTEBOOK\" development experience (UI);\n- must provide for EXECUTION of notebooks being developed.\n\nThe (Microsoft) employee authoring this article asserts that the following technologies (adequately) REPLACE Azure Notebooks:\nVisual Studio Code (Desktop):\n- NOT cloud-hosted :-(\n- DOES provide a \"notebook\" development experience :-)\n- DOES provide for execution - but execution that is ONLY as powerful as the laptop or VM on which Visual Studio Code is installed :-|\n----------------------------\nOVERALL MATCH: DISMAL\n\nGithub Codespaces (beta):\n- IS cloud-hosted, but utterly INCOMPREHENSIBLE so far :-|\n- FORCES you to edit your github-hosted notebook in VISUAL STUDIO CODE on (say) your LAPTOP; utterly MISSING THE POINT :-(\n- does (I guess?) provide for execution, but again INCOMPREHENSIBLE when one is coming from the Azure Notebooks (or Azure Databricks or AzureML) development experience :-(\n-------------------------\nOVERALL MATCH: DISMAL\n\nAzure ML (\"Studio\"):\n- IS cloud-hosted, but FORCES you to now create an AZURE SUBSCRIPTION, PROVISION (at leAST) single-node (expensive) \"Compute Instance\" in order to execute code :-|\n- DOES provide a (mostly cool, mostly powerful) NOTEBOOK development experience (note: I've been using this professional full-time for the PAST 2 YEARS) :-)\n- DOES provide for EXECUTION of notebooks developed in the editor, but the learning curve here is far far far more COMPLEX than with Azure Notebooks or Azure Databricks :-|\n---------------------------------\nOVERALL MATCH: \"LESS DISMAL\"\n\nWHAT IS THE RESULT OF MICROSOFT'S DESTRUCTION OF AZURE NOTEBOOKS FOLLOWED BY THINLY-VEILED ATTEMPTS TO FORCE USERS ONTO OTHER EXISTING AZURE TOOLS?\nSHORT ANSWER: users AREN'T moving onto AZURE tools - they're LEAVING !!!!!\n- they're mostly moving to GOOGLE and KAGGLE - NICE JOB MICROSOFT (you blew it here)\n- some people (like me) HAVE moved to Azure ML Studio, and have FALLEN IN LOVE WITH IT... but I will tell you whole-heartedly it's NOT \"AZURE NOTEBOOKS\"\n\nONE LAST THING:\nOver a YEAR ago Microsoft was promising that GITHUB.COM was going to suddenly \"sprout\" NOTEBOOK EDITING & EXECUTION capability, but all we got so far is CODESPACES - an utterly DISMAL \"replacement\"\n\nMICROSOFT NEEDS TO RESTORE AZURE NOTEBOOKS - the ONLY GENUINE COMPETITION for GOOGLE'S notebook labs and KAGGLE'S built-in notebooks.\n\nWAKE UP MICROSOFT - you single-handedly are DRIVING WOULD-BE ADOPTER AWAY FROM YOU and ONTO YOUR COMPETITORS' NOTEBOOK ENVIRONMENTS !!!\n\nFoolish\nFoolish\nFoolish\n\n-Mark Vogt, Senior Solution Architect\/Data Scientist, AVANADE (a 45,000 consultant global consulting firm 1\/3 OWNED by MICROSOFT)\n\nPS: FEEL FREE to chat me up via MS Teams at mark.vogt@avanade.com, and I'd be happy to SPEARHEAD a REAL effort to integrate AzureNotebook's functionality into GITHUB.COM, which would be an AMAZING combination ! I'll even tell\/show you HOW :-) ...",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"synapse analytics datastores from Azure ML",
        "Question_creation_time":1649596287577,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/807044\/synapse-analytics-datastores-from-azure-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":17,
        "Question_score":0,
        "Question_body":"I use Azure ML (designer) as data mining pourpose.\nAND use synapse for datapreparation.\n\nAfter I executed data preparation prosess, i want to use the prepared data from Azure ML environment,,, but I can not select Azure Synapse data sourse from Azure ML side as datastores.\n\nIs there any work around? Or you just do not support it?\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-10T23:46:35.247Z",
                "Answer_score":0,
                "Answer_body":"Azure ML support SQL server as datastore.\nAnd Azure SQL support external table with which I can use Azure Synapse (serverless) external table.\n\n\n\n\nI created external table in Azure SQL with this blog...\nhttps:\/\/devblogs.microsoft.com\/azure-sql\/read-azure-storage-files-using-synapse-sql-external-tables\/\n\n\n\n\nattached Azure SQL as data store.\n\nNow I can use synapse serverless data in Azure ML directly....\n\nIt would be much faster if Azure ML would support synapse data set as datastore, though....",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Use custom environment in Azure Machine Learning Designer",
        "Question_creation_time":1647597231527,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/777745\/use-custom-environment-in-azure-machine-learning-d.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello,\n\nI would like to know if there is the possibility to use a custom environment (created from the AML portal) for the execution of a Python Script Step in the Azure Machine Learning Designer (only using the designer, not using azureml sdk to publish the pipeline from the code).\n\nThanks,\nG",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-28T19:05:42.677Z",
                "Answer_score":1,
                "Answer_body":"Thanks for your feedback. Based on your comments above, it seems you want to configure a custom environment in AML designer and install unsupported python libraries. These are the supported Custom Environments. However, in AML designer, the execute python script component enables you to write custom python scripts and install python libraries. This particular document shows how to configure execute python script. You can install packages that aren't in the preinstalled list by using the following command:\n\n import os\n os.system(f\"pip install scikit-misc\")\n\n\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure AutoML Model Accuracy Metrics",
        "Question_creation_time":1649318824207,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/803749\/azure-automl-model-accuracy-metrics.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hello Everyone , I have deployed a ML Model over a REST Endpoint successfully and the model is trained using Azure AutoML . I am successfully able to send data to the model via the endpoint and get back the predicted output . Sending of data is done in JSON format through a python script and the received data is print as output by the python script .I am able to view trained model metrics like accuracy , error rates , root mean squared errors etc .. through the Azure ML Studio User Interface but is there any way of accessing these error or accuracy metrics through the endpoint using a python script ? I know that there is ML flow but in that case the whole training should be done using a python script and that is not suitable for my case and the other one is logging APIs which don't give me error or accuracy metrics but give others which are not needed for my usage. In a nutshell I want to access model accuracy metrics of the already trained and deployed model via an API or endpoint . Also is there any place in azure storage where these accuracy metrics are stored and if they can be accessed via an Endpoint ? Please help me on this issue . Thank you all :)",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"ML Studio and Private Endpoint issue",
        "Question_creation_time":1646161833773,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/755259\/ml-studio-and-private-endpoint-issue.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"We are trying to setup a Machine Learning Workspace and only have it accessible via Private Endpoint Connection. When we have it this setup and try to connect from our company workstations it loads the page but we get an \"Error Loading recent runs\"\n\n\n\n\n\nIf we run this from a VM inside Azure it is fine.\n\nWe do have a VPN Gateway set up to access our on-prem which works for other Vnets we have in Azure. We peered the VNET that ML sits in with VNET where Gateway network is setup. unfortunately we had a 3rd party set up the original connection and did not fully document. We have tried to match all settings we have in the working VNET with the ML Vnet but can't seem to see what we are missing. I also can't seem to find what logs to check to see where connections are being blocked.\nHoping I explained our issue will enough.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-30T14:17:17.327Z",
                "Answer_score":1,
                "Answer_body":"So we have resolved the issue. We found that we had to add a rule to allow that traffic to the private endpoint. Once we did that and add adding a Forward Zone lookup in our DNS for the Private IPs resolved our issues.\nAppreciate all that help on this",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How do I extend the waiting time of Azure speech-to-text API in Python?",
        "Question_creation_time":1649087644937,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/799565\/how-do-i-extend-the-waiting-time-of-azure-speech-t.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"When using speech-to-text to transfer audio file to text, I found that the function would stop working if human voices haven't occurred for about 5 seconds. In my case, what I want to transfer is audios of interviews, which would often contain some advertisements or music in the middle of it, and when this happens, the speech-to-text would only transfer the first half of the whole audio, and report an error that \"No speech could be recognized\".\nIn this case, how can I extend the waiting time of that in order to transfer the whole file in Python codes?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-06T00:32:24.237Z",
                "Answer_score":0,
                "Answer_body":"Hello @MuyaoHu-4139\n\nI think there are two solutions you can have a try in Python SDK:\n\nThere is a 'set_property' method on the config to allow you to set parameters to your request, which can change the default silence time:: https:\/\/docs.microsoft.com\/en-us\/python\/api\/azure-cognitiveservices-speech\/azure.cognitiveservices.speech.propertycollection?view=azure-python#azure-cognitiveservices-speech-propertycollection-set-property\n\nThis way you can set the EndSilenceTimeout (PropertyIDs in Pyhton: https:\/\/docs.microsoft.com\/en-us\/python\/api\/azure-cognitiveservices-speech\/azure.cognitiveservices.speech.propertyid?view=azure-python#fields)\n\n\n\n\nPlease notice, the time is as \"ms\". Hope above helps!\n\n\n\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks!",
                "Answer_comment_count":4,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"how publish the pipeline endpoint and test it ?",
        "Question_creation_time":1649315875193,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/803725\/how-publish-the-pipeline-endpoint-and-test-it.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"we have build a pipeline and would like to publish as service, may I know how to test the it works or not ?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"list of folder names as input for ParallelRunStep-class",
        "Question_creation_time":1647256395817,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/771015\/list-of-folder-names-as-input-for-parallelrunstep.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"In this example, all data files for the parallel run step are stored in one folder.\n\nI also want to create a parallel run step. The task for each of the several folders, in which the multiple data files are stored, is exactly identical.\n\nThe folders:\n\n\n\n\n\nThe content of each folder:\n\n\n\n\n\nHow should I define the ParallelRunStep-class so that the identical task for each folder (here 'a', 'b', 'c', 'd' and 'e') is executed in parallel?\nTwo folders should run simultaneously in parallel.\n\nMoreover, I would like to ask how to get only the stored folder names or folder paths from a given directory path of a blob storage container.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-21T10:25:43.237Z",
                "Answer_score":1,
                "Answer_body":"@@AlexanderPakakis-0994 Thanks, An Azure ML dataset is just metadata pointing to a path or collection of paths in an Azure storage account. You should first \"merge\" those datasets into a collection of adjacent folders (e.g. root\/dataset1\/, root\/dataset2\/, ...) and then run PRS against root\/**.",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure SDK previous step output to multiple steps as input",
        "Question_creation_time":1649214311427,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/801687\/azure-sdk-previous-step-output-to-multiple-steps-a.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"I have a output from previous step and want to use it as input to multiple steps.\nBut, when I run the experiment, the pipeline looks like this\n\n\n\n\nHere is my code\n\n source_directory=\".\/test\"\n designer1_config = ScriptRunConfig(source_directory=source_directory,\n                                  command=[\"python\", \"designer1.py\", \n                                           \"--output_test1\", output_test1], # \n                                  compute_target=aml_compute,\n                                  environment=env_py)\n    \n designer1_step = CommandStep(name=\"designer_step\", \n                            inputs=[input_dept_fun_d],\n                            outputs=[output_test1], #\n                            runconfig=designer1_config,\n                            allow_reuse=True)\n source_directory=\".\/test\"\n designer2_config = ScriptRunConfig(source_directory=source_directory,\n                                  command=[\"python\", \"designer2.py\"], # \n                                  compute_target=aml_compute,\n                                  environment=env_py)\n    \n designer2_step = CommandStep(name=\"designer2_step\", \n                            inputs=[input_dept_fun_d, output_test1],\n                            outputs=[], #\n                            runconfig=designer2_config,\n                            allow_reuse=True)\n\n\n\nUse 2 steps, it shows picture 1\n\n step_sequence = [designer1_step, designer2_step]\n\n\n\nUse 1 step, it shows picture 2\n\n step_sequence = [designer2_step]\n\n\n\nSubmit the experiement\n\n pipeline = Pipeline(workspace=ws, steps=step_sequence)\n pipeline_run = Experiment(workspace=ws, name='pipeline').submit(config=pipeline, regenerate_outputs=True)\n\n\n\n\n\n\n\nHere's what I want",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-07T06:19:24.293Z",
                "Answer_score":1,
                "Answer_body":"@MiaZhangWHQWistron-2092 Based on the setup for designer2_step the inputs are the original input of step1 and the output of step1. The second screen shot seems appropriate and the designer has just replicated the original input dataset for step2. The connection that you are referring to is irrelevant because the same dataset is used, and designer only displays it for simplicity.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Reload skipped images in Data Labelling project?",
        "Question_creation_time":1642700153863,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/703399\/reload-skipped-images-in-data-labelling-project.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":17,
        "Question_score":0,
        "Question_body":"Hi\nI ran a data labeling project on Azure ml which had 20k images. We annotated about 4k images while the rest images were skipped. Is there a way to go back through skipped images again and reload them back into the system?\nI'd greatly appreciate your help in resolving this issue.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-21T15:48:48.09Z",
                "Answer_score":0,
                "Answer_body":"@TarunL-3644 Are you referring to the Azure ml data labeling project on ml.azure.com?\nIf Yes, then if you have skipped some images during labeling then I think you can re-label them by pausing the project and adding a new label which provides the following options.\n\nA detailed step by step process is listed in the documentation here for reference. I hope this helps!!\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML data labeling change polygon color",
        "Question_creation_time":1647528569083,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/776555\/azure-ml-data-labeling-change-polygon-color.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hello,\n\nWe are currently annotating images in a data labeling instance segmentation (polygon) project. Our images are rather blueish, which makes it difficult to use the polygon \"draw polygon region\" tool, which draws the polygon in blue.\n\nIs it possible to change the color to, for example, black?\n\nThanks and BR,\nMaite",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-18T09:37:47.23Z",
                "Answer_score":0,
                "Answer_body":"@Maite-3025\n\nThanks for reaching out to us, I am sorry we are using only blue for the polygon color. I will forward your feedback to product team for future release.\n\nOne workaround may help with your scenario is, you can change the brightness to \"-100\" when you draw and revert the brightness back when you done as below screenshot. This will help to make things clear.\n\nHope this helps and thanks for the feedback again.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Enabling Model Data Collector for ACI through az ml deploy",
        "Question_creation_time":1648735779630,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/795453\/enabling-model-data-collector-for-aci-through-az-m.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"Hello,\n\nI want to create a release pipeline in DevOps that deploys a model to ACI, I have a PowerShell script that deploys using the az ml package. However even though I set the model data collector flag in the deploy command, the endpoint does not collect the inputs. I have tried deploying the same model, using the exact same score.py, but deployed programmatically through azureml.core.webservice and it worked just fine with collection data, so the problem is elsewhere.\n\nI have deployed my model using the following command in a PowerShell script (paraphrasing some of the arguments):\n\naz ml model deploy -n $name --model $model -g $resource-group -w $workspace --es $entry_script_path --cf $conda_file_path --dc $deployment_config_path --md True --overwrite -v\n\nNotice that I have set the --md argument to True, which is the model data collector flag.\n\nAnd in my score.py, I have imported the ModelDataCollector, initialized it and I call collect. I have something like this:\n\nfrom azureml.monitoring import ModelDataCollector\n\n\ndef init():\nglobal model, scaler, input_name, label_name, inputs_dc, prediction_dc\n\n\n  # variables to monitor model input and output data\n  inputs_dc = ModelDataCollector(\"model\", designation=\"inputs\")\n\ninput_sample = pd.DataFrame(sample})\n@input_schema('data',PandasParameterType(input_sample))\n@output_schema(NumpyParameterType(np.array([0])))\ndef run(data):\ntry:\ninputs_dc.collect(data)\n# model inference\nresult = model.predict(data)\nreturn {\"result\": result.tolist()}\nexcept Exception as e:\nresult = e\nreturn {\"result\": result}\n\nHowever I deploy my model using the PowerShell script, and everything goes fine. The endpoint is callable, healthy and outputs correct results. But the data does not get saved in the storage account or in application insights (which I have enabled, and can see is enabled on the endpoint as well.\n\nIn my deployment config I see the following:\n\nData collection is not enabled. Set environment variable ML_MODEL_DC_STORAGE_ENABLED to 'true' to enable.\n\nHow do I go about that? I have enabled Data collection in my deployment command, why does it not work, and how can I set the environmental variable?\nI tried adding it to my conda_env.yml which is part of the deployment command \"--cf $conda_file_path\" like so:\n\nname: my_env\ndependencies:\n- python=3.6.2\n- pip:\n- numpy\n- onnxruntime\n- joblib\n- azureml-core~=1.10.0\n- azureml-defaults~=1.10.0\n- scikit-learn==0.22.2.post1\n- inference-schema\n- inference-schema[numpy-support]\n- azureml-monitoring\nchannels:\n- anaconda\n- conda-forge\nvariables:\nML_MODEL_DC_STORAGE_ENABLED = true\n\nBut that just produces another error. How do I solve this problem?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"AzureML webservice deployment with custom Environment - \/var\/runit does not exist",
        "Question_creation_time":1648579663380,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/792417\/azureml-webservice-deployment-with-custom-environm.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":21,
        "Question_score":0,
        "Question_body":"Hi everyone.\n\nI'm struggling to deploy a model with a custom environment through the azureml SDK.\n\nI have built a docker image locally and pushed it to azure container registry to use it for environment instantiating. This is how my dockerfile looks like:\n\n FROM mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04\n FROM python:3.9.12\n    \n # Keeps Python from generating .pyc files in the container\n ENV PYTHONDONTWRITEBYTECODE=1\n    \n # Turns off buffering for easier container logging\n ENV PYTHONUNBUFFERED=1\n    \n # Install requirement for deploying the service\n RUN apt-get update\n RUN apt-get install -y runit\n    \n # Install pip requirements\n RUN pip install --upgrade pip\n COPY requirements.txt .\n RUN pip install azureml-defaults\n RUN pip install -r requirements.txt\n\n\n\nI want to deploy the webservice locally for testing, so I am following the steps according to official documentation:\n\n ws = Workspace(subscription_id='***', resource_group='***', workspace_name='***')\n    \n model = Model.register(ws, model_name='***', model_path='.\/Azure_Deployment\/Algorithm')\n    \n container = ContainerRegistry()\n container.address = '***'\n myenv = Environment.from_docker_image('***', '***\/***-img:v1', container)\n    \n inference_config = InferenceConfig(environment=myenv, source_directory='.\/Azure_Deployment', entry_script='echo_score.py',)\n    \n deployment_config = LocalWebservice.deploy_configuration(port=6789)\n    \n service = Model.deploy(ws, \"myservice\", [model], inference_config, deployment_config, overwrite=True,)\n service.wait_for_deployment(show_output=True)\n\n\n\n\nThis is what I get from the logs:\n\n\n\n\n\n\n\n\nChecking into the resulting container for the service I can see indeed there is no \/runit folder inside \/var. There is also no other folders created for the service besides the azureml-app containing my model's files.\n\nI would really appreciate any insights to what's going on here as I have no clue at this point.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How is scoring done in azure ml?",
        "Question_creation_time":1649152330267,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/800586\/how-is-scoring-done-in-azure-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Suppose I have 50 features in my dataset, but after feature engineering(one hot encoding or tf-idf) I get 200 feature colums. The model is trained on these 200 features and is deployed and now we have a rest endpoint for the model. Now the customer will hit the endpoint with 50 features but the model is expecting 200 columns. Where will the conversion of 50 to 200 features takes place?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-05T20:26:45.297Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. It seems you're wondering how to consume the model after feature engineering. The simple answer is that you'll need to apply the same transformations on your testing dataset. The schema of the input dataset should match the schema of the data used to train the model.\n\n\n\n\n--please don't forget to Accept Answer if the reply is helpful. Thanks.--",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azureml: Metadata mismatch for dask dataframe after using filter()",
        "Question_creation_time":1647425925947,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/774453\/azureml-metadata-mismatch-for-dask-dataframe-after.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I noticed weird behaviour when filtering an azureml TabularDataset instance using filter() and converting it to a dask dataframe afterwards. Here is my code to recreate the issue:\n\nImports:\n\n from azureml.core import Dataset\n from azureml.data import TabularDataset\n import dask.dataframe as ddf\n import pandas as pd\n\n\n\nRegister a dask dataframe to the datastore and load it as a TabularDataset:\n\n test_df = pd.DataFrame({\"id\": [3,4,5], \"price\": [199, 98, 50]})\n test_dask = ddf.from_pandas(test_df, chunksize=1)\n    \n Dataset.Tabular.register_dask_dataframe(test_dask, datastore, name='bug_test')\n dataset = TabularDataset.get_by_name(workspace, name='bug_test')\n\n\n\nNow printing the loaded dataset after converting it to dask dataframe works (almost) well (almost, since there is weird indexing as the 0 appears two times):\n\n loaded_dask = dataset.to_dask_dataframe()\n print(loaded_dask.compute())\n >> \n           id  price  __null_dask_index__\n        0   3    199                   0\n        0   4     98                    1\n        1   5     50                    2\n\n\n\nWe now want to filter for rows where id equals to 5, which works perfectly when it is filtered after converting it to dask dataframe with loaded_dask[loaded_dask.id == 5].compute()\n\nNow computing the dask dataframe after filtering with the filter() method throws following exception, either no data or no datatype is found (for full error message see below):\n\n filtered_ds = dataset.filter(dataset[\"id\"] == 5)\n filtered_ds.to_dask_dataframe().compute()\n >> \n     ValueError: Metadata mismatch found in `from_delayed`.\n     Partition type: `pandas.core.frame.DataFrame`\n     +-----------------------+-------+----------+\n     | Column                | Found | Expected |\n     +-----------------------+-------+----------+\n     | '__null_dask_index__' | -     | int32    |\n     | 'id'                  | -     | int32    |\n     | 'price'               | -     | int32    |\n     +-----------------------+-------+----------+\n\n\n\nNote: When filtering for invalid values, e.g. for dataset[\"id\"] == 6 it correctly returns me an empty dataframe\n\nAlso a weird behaviour happens when playing around with the dtypes parameter in to_dask_dataframe(). When specifying types for only one column, datatypes can suddenly be found:\n\n filtered_ds.to_dask_dataframe(dtypes={\"id\": \"object\"}).compute()\n >>\n     ValueError: Metadata mismatch found in `from_delayed`.\n    \n     Partition type: `pandas.core.frame.DataFrame`\n     +-----------------------+-------+----------+\n     | Column                | Found | Expected |\n     +-----------------------+-------+----------+\n     | '__null_dask_index__' | int64 | -        |\n     | 'id'                  | int64 | object   |\n     | 'price'               | int64 | -        |\n     +-----------------------+-------+----------+\n\n\n\nbut setting dtypes={\"id\": \"int64\", \"price\": \"int64\", \"__null_dask_index__\": \"int64\"} leads again to the same ValueError as before that either no data or no datatype is found (full error ouput):\n\n filtered_ds.to_dask_dataframe(dtypes={\"id\": \"int64\", \"price\": \"int64\", \"__null_dask_index__\": \"int64\"}).compute()\n >>\n     Traceback (most recent call last):\n       File \"\\bug_analysis.py\", line 117, in <module>\n         filtered_ds.to_dask_dataframe(dtypes={\"id\": \"int64\", \"price\": \"int64\", \"__null_dask_index__\": \"int64\"}).compute()\n       File \"\\venv\\lib\\site-packages\\dask\\base.py\", line 290, in compute\n         (result,) = compute(self, traverse=False, **kwargs)\n       File \"\\envs\\venv\\lib\\site-packages\\dask\\base.py\", line 573, in compute\n         results = schedule(dsk, keys, **kwargs)\n       File \"\\venv\\lib\\site-packages\\dask\\threaded.py\", line 81, in get\n         results = get_async(\n       File \"\\venv\\lib\\site-packages\\dask\\local.py\", line 506, in get_async\n         raise_exception(exc, tb)\n       File \"\\venv\\lib\\site-packages\\dask\\local.py\", line 314, in reraise\n         raise exc\n       File \"\\venv\\lib\\site-packages\\dask\\local.py\", line 219, in execute_task\n         result = _execute_task(task, data)\n       File \"\\venv\\lib\\site-packages\\dask\\core.py\", line 119, in _execute_task\n         return func(*(_execute_task(a, cache) for a in args))\n       File \"\\venv\\lib\\site-packages\\dask\\dataframe\\utils.py\", line 407, in check_meta\n         raise ValueError(\n     ValueError: Metadata mismatch found in `from_delayed`.\n     Partition type: `pandas.core.frame.DataFrame`\n     +-----------------------+-------+----------+\n     | Column                | Found | Expected |\n     +-----------------------+-------+----------+\n     | '__null_dask_index__' | -     | int64    |\n     | 'id'                  | -     | int64    |\n     | 'price'               | -     | int64    |\n     +-----------------------+-------+----------+\n\n\n\n\nThe exceptions are raised when the dask dataframes are computed with compute().\n\nI am aware that I used two experimental methods ( TabularDataset.to_dask_dataframe() and TabularDataset.filter() ), so is this a bug or am I using the methods incorrectly at some point?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-05T04:59:25.48Z",
                "Answer_score":0,
                "Answer_body":"I have the same problem, any solution?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Deploying an ML Model to ACI with a secured workspace in a VNet",
        "Question_creation_time":1649065504527,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/799037\/deploying-and-ml-model-to-aci-with-a-secured-works.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"I am trying to deploy an ML model to an ACI in a VNet. I have followed the guide to setup a secure workspace, and also noted that if deploying to ACI, the container registry must not be in the same vnet.\nI have deployed the container registry:\n\noutside of the vnet in the same resource group\n\n\nAllowed admin user in the CR\n\n\nDisabled public access\n\n\nAllowed trusted microsoft services\n\n\nCreated a private endpoint for private access for the worskpace to access (needed this for image builds on my training runs)\n\n\nAllowed subnet delegation on the Scoring subnet for the containerGroups service as shown here\n\n\n\n\nNow when I am trying to deploy the model to a container instance, I get this failure\n```\nError:\n{\n\"code\": \"InaccessibleImage\",\n\"statusCode\": 400,\n\"message\": \"ACI Service request failed. Reason: The image '<containerRegName>.azurecr.io\/azureml\/azureml_<imageHash>' in container group '<serviceName>-qcloi6KnEkOQ6CTdniybhQ' is not accessible. Please check the image and registry credential.. Refer to https:\/\/docs.microsoft.com\/azure\/container-registry\/container-registry-authentication#admin-account and make sure Admin user is enabled for your container registry.\"\n}\n```\nAfter speaking to the docs team where the guides address this deployment strategy (here), the only response is to use AKS. AKS won't be feasible right now for this project and the documentation seems to suggest that this is possible.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"machine learning submit real-time inference error",
        "Question_creation_time":1648476067633,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/790255\/machine-learning-submit-real-time-inference-error.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"When I submit successfully at design, but submit the 'real time inference' is error, I just copy the action of the sample ,that is ok, but when I re-create a new one, it shows the error message, who can help me ? Thank you very much !",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-04T15:10:26.053Z",
                "Answer_score":0,
                "Answer_body":"Hi, following up on my previous comment. Inference Pipelines can only be created if there's a model in the pipeline. It's possible that the model wasn't trained successfully. You can verify by going to Experiments tab > Experiment > and confirm the status shows completed. You can also try to re-train the model by clicking the submit button again (as shown in the image above) and follow the steps shown on your screen. If you have any further questions or if issue persists, feel free to comment below so we can assist. Thanks.\n\n\n\n\n--please don't forget to Accept Answer if the reply is helpful. Thanks.--",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Export Data Row Number",
        "Question_creation_time":1646064764830,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/753636\/export-data-row-number.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"In the Export Data module within AML Designer, it is currently limiting the number of rows per batch to 50. It looks like this used to be a parameter that was adjustable within the interface on the old Studio but now it is not. When we try to update the environment variable it says that the variable is already set and errors out. Are there any other ways to adjust the number of rows per batch and\/or is this parameter going to come back in a future version of the Export Data module?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-04T09:59:09.1Z",
                "Answer_score":0,
                "Answer_body":"If there any answer to share?\n\nAML designer seems more advanced than old version, but it hasn\u2019t covered all the features as old version.\n\nThe complicated UI makes things terrible. The doc is not enough at all.\n\nI hope the easy use UI can be a part of Designer.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error while creating pipeline between first and second page - first step runs get error when second steps start",
        "Question_creation_time":1647462322017,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/775279\/error-while-creating-pipeline-between-first-and-se.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"first step of pipeline\n\ndata_prep_step = PythonScriptStep(\nscript_name='data_prep.py',\nsource_directory='.\/src',\narguments=[\"--data_path\", dataset.as_mount(), \"--out_folder\", output_data],\ncompute_target='cpu-cluster',\nrunconfig=aml_run_config,\nallow_reuse=True\n)\n\nsecond step of pipeline\n\ntrain_step = PythonScriptStep(\nscript_name='train.py',\nsource_directory='.\/src',\narguments=[\"--output_folder\", output_data.as_input()],\ncompute_target='cpu-cluster',\nrunconfig=aml_run_config,\nallow_reuse=True\n)\n\nrun\n\ntrain_pipeline = Pipeline(workspace = ws, steps = [data_prep_step, train_step])\nexperiment = Experiment(workspace = ws, name = 'training-pipeline' )\npipeline_run = experiment.submit(train_pipeline)\n\ncode first step completes, I get error when second step starts\n\n\ncode for first step below\n\ndef split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\nfiles = []\nfor filename in os.listdir(SOURCE):\nfile = os.path.join(SOURCE, filename)\nif os.path.getsize(file) > 0:\nfiles.append(filename)\nelse:\nprint(filename + \" is zero length, so ignoring.\")\n\n training_length = int(len(files) * SPLIT_SIZE)\n testing_length = int(len(files) - training_length)\n shuffled_set = random.sample(files, len(files))\n training_set = shuffled_set[0:training_length]\n testing_set = shuffled_set[training_length:]\n for filename in training_set:\n     this_file = os.path.join(SOURCE, filename)\n     destination = os.path.join(TRAINING, filename)\n     copy(this_file, TRAINING)\n for filename in testing_set:\n     this_file = os.path.join(SOURCE, filename)\n     destination = os.path.join(TESTING, filename)\n     copy(this_file, TESTING)\n\n\n\nrun = Run.get_context()\nif name == \"main\":\n\n parser = argparse.ArgumentParser()\n parser.add_argument('--data_path',\n                     type=str,\n                     help='Path to uploaded data')\n parser.add_argument('--out_folder', \n                    type=str\n                        \n                    )\n #parser.add_argument('--data_path_test', \n #                    type=str,\n #                   help='Path to test dataflow')\n #args = parser.parse_args()\n args = parser.parse_args()\n output_folder = args.out_folder\n inputs = args.data_path\n    \n try:\n     os.makedirs(os.path.join(output_folder, '\/train\/defect'), exist_ok=True) #'args.data_path_folder\/train\/defect\/')\n     os.makedirs(os.path.join(output_folder, '\/train\/no-defect'), exist_ok=True) #'args.data_path_folder\/train\/no-defect\/')\n     os.makedirs(os.path.join(output_folder, '\/test\/defect'), exist_ok=True) #'args.data_path_folder\/test\/defect\/')\n     os.makedirs(os.path.join(output_folder, '\/test\/no-defect'), exist_ok=True) #'args.data_path_folder\/test\/no-defect\/')\n     #os.mkdir('\/tmp\/cats-v-dogs\/training\/dogs')\n     #os.mkdir('\/tmp\/cats-v-dogs\/testing\/cats')\n     #os.mkdir('\/tmp\/cats-v-dogs\/testing\/dogs')\n except OSError:\n     pass\n    \n train_datagen = ImageDataGenerator(\n rescale = 1.\/255)\n val_datagen = ImageDataGenerator(\n rescale = 1.\/255)\n test_datagen = ImageDataGenerator(\n rescale = 1.\/255)\n    \n class_mode = 'binary'\n batch_size = 5\n    \n    \n NO_DEFECT_SOURCE_DIR =  os.path.join(inputs, \"Good\")\n TRAINING_NO_DEFECT_DIR = os.path.join(output_folder, '\/train\/no-defect') #'output_folder\/train\/no-defect\/'   #os.path.join(args.data_path_train, \"no-defect\/\")\n TESTING_NO_DEFECT_DIR =  os.path.join(output_folder, '\/test\/no-defect') #'output_folder\/test\/no-defect\/'    #os.path.join(args.data_path_test, \"no-defect\/\")\n DEFECT_SOURCE_DIR = os.path.join(inputs, \"Defective\")\n TRAINING_DEFECT_DIR = os.path.join(output_folder, '\/train\/defect') #'output_folder\/train\/defect\/' #os.path.join(args.data_path_train, \"defect\/\")\n TESTING_DEFECT_DIR = os.path.join(output_folder, '\/test\/defect') #'output_folder\/test\/defect\/' #os.path.join(args.data_path_test, \"defect\/\")\n    \n split_size = .8\n split_data(NO_DEFECT_SOURCE_DIR, TRAINING_NO_DEFECT_DIR, TESTING_NO_DEFECT_DIR, split_size)\n split_data(DEFECT_SOURCE_DIR, TRAINING_DEFECT_DIR, TESTING_DEFECT_DIR, split_size)\n\n\n\nerror received below\n\n\n\n{'code': data-capability.DatasetMountSession:input_915071c1.ExecutionError, 'message':\nError Code: ScriptExecution.StreamAccess.NotFound\n, 'target': , 'category': UserError, 'error_details': [{'key': NonCompliantReason, 'value': Error Code: ScriptExecution.StreamAccess.NotFound Failed Step: 92a8bfed-63f0-497a-bbcf-b0bfa1be2d9a Error Message: ScriptExecutionException was caused by StreamAccessException. StreamAccessException was caused by NotFoundException. Found no resources for the input provided: 'https:\/\/mich7068071609.blob.core.windows.net\/azureml-blobstore-e23f8d3d-4bfa-4d73-8330-db867b66a523\/dataset\/3c085033-67b7-4c25-8e29-1e58a993e90a\/prepped\/' | session_id=067cfe37-82a4-46e1-900c-8184e503ebfb}, {'key': StackTrace, 'value': File \"\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/data_capability\/capability_session.py\", line 47, in start (data_path, sub_data_path) = session.start() File \"\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/data_capability\/data_sessions.py\", line 171, in start if self._is_single_file: File \"\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/data_capability\/data_sessions.py\", line 119, in _is_single_file path = dataflow._to_pyrecords()[0][temp_column]\n\nFile \"\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/api\/dataflow.py\", line 756, in _to_pyrecords\nintermediate_files = _write_preppy_with_fallback('Dataflow.to_pyrecords', self, span_context=to_dprep_span_context(span.get_context()))\n\nFile \"\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/api\/_dataframereader.py\", line 190, in _write_preppy_with_fallback\n_execute_with_fallback(activity, dataflow_to_execute, force_clex=force_clex, span_context=span_context)\n\nFile \"\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/api\/_dataframereader.py\", line 238, in _execute_with_fallback\nclex_execute()\n\nFile \"\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/api\/_dataframereader.py\", line 219, in clex_execute\nspan_context=span_context\n\nFile \"\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/api\/_aml_helper.py\", line 38, in wrapper\nreturn send_message_func(op_code, message, cancellation_token)\n\nFile \"\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py\", line 154, in execute_anonymous_activity\nresponse = self._message_channel.send_message('Engine.ExecuteActivity', message_args, cancellation_token)\n\nFile \"\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/api\/engineapi\/engine.py\", line 291, in send_message\nraise_engine_error(response['error'])\n\nFile \"\/opt\/miniconda\/envs\/data-capability\/lib\/python3.7\/site-packages\/azureml\/dataprep\/api\/errorhandlers.py\", line 10, in raise_engine_error\nraise ExecutionError(error_response)\n}, ], 'inner_e",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-04T09:52:01.617Z",
                "Answer_score":0,
                "Answer_body":"Same error and I can confirm --data_path\", dataset.as_download() worked.\n\nToo difficult to get solution for pipeline debugging, any troubleshooting guidance here?\n\nShould I just post error I got to debug? No efficiency to do so.\n\nThank you anyway.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Feeding PipelineData to HyperDriveStep results in: TypeError: __new__() missing 2 required positional arguments: 'workspace' and 'name'",
        "Question_creation_time":1647906103627,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/781351\/feeding-pipelinedata-to-hyperdrivestep-results-in.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"When I try to feed PipelineData into HyperDriveStep like here:\n\n         data_datastore = Datastore(ws, datastore_name)\n         dataset = Dataset.File.from_files([data_datastore.path(\"\")]).as_named_input('data')\n        \n         steps = []\n        \n         datastore = ws.get_default_datastore()\n        \n         transformed_data = PipelineData(datastore=datastore, name=\"transformed_data\")\n         transformation_step = PythonScriptStep(script_name=\"demo_transform_data.py\",\n                                         arguments=[\"--input\", dataset, \"--output\", transformed_data],\n                                         inputs=[dataset],\n                                         outputs=[transformed_data],\n                                         compute_target=cpu_compute,\n                                         runconfig=cpu_run_config)\n         steps.append(transformation_step)\n        \n         hp_search_step = HyperDriveStep(\n             name='hp_search_step',\n             hyperdrive_config=HyperDriveConfig(\n                 run_config=ScriptRunConfig(\n                     source_directory='.', \n                     script='demo_train.py',\n                     arguments=['--input', transformed_data],\n                     compute_target=cpu_compute,\n                     environment=environment\n                 ),\n                 hyperparameter_sampling=RandomParameterSampling({\n                     '--learning_rate': choice(1e-1, 1e-2, 1e-3),\n                     '--hidden_size': choice(32, 64),\n                 }),\n                 primary_metric_name='loss',\n                 primary_metric_goal=PrimaryMetricGoal.MINIMIZE,\n                 max_total_runs=4,\n                 max_concurrent_runs=2\n             ),\n             inputs=[transformed_data],\n             outputs=[]\n         )\n         steps.append(hp_search_step)\n            \n         exp = Experiment(workspace=ws, name=f'hyperdrive-search')\n         pipeline_run = exp.submit(Pipeline(ws, steps))   **# Line 110 in the exception below**\n\n\n\n...then I getting the following exception:\n\n\n\n     Traceback (most recent call last):\n       File \"bug_repro.py\", line 110, in <module>\n         pipeline_run = exp.submit(Pipeline(ws, steps))\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/core\/_experiment_method.py\", line 104, in wrapper\n         return init_func(self, *args, **kwargs)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/pipeline.py\", line 180, in __init__\n         self._graph = self._graph_builder.build(self._name, steps, finalize=False)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py\", line 1497, in build\n         graph = self.construct(name, steps)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py\", line 1519, in construct\n         self.process_collection(steps)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py\", line 1555, in process_collection\n         builder.process_collection(collection)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py\", line 1846, in process_collection\n         self._base_builder.process_collection(item)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py\", line 1549, in process_collection\n         return self.process_step(collection)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py\", line 1593, in process_step\n         node = step.create_node(self._graph, self._default_datastore, self._context)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/pipeline\/steps\/hyper_drive_step.py\", line 271, in create_node\n         context._experiment_name)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/pipeline\/steps\/hyper_drive_step.py\", line 347, in _get_hyperdrive_config\n         experiment_name, telemetry_values)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/train\/hyperdrive\/_search.py\", line 38, in _create_experiment_dto\n         platform_config = hyperdrive_config._get_platform_config(workspace, experiment_name, **kwargs)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/train\/hyperdrive\/runconfig.py\", line 664, in _get_platform_config\n         platform_config.update(self._get_platform_config_data_from_run_config(workspace))\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/train\/hyperdrive\/runconfig.py\", line 678, in _get_platform_config_data_from_run_config\n         run_config = get_run_config_from_script_run(self.run_config)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/site-packages\/azureml\/core\/script_run_config.py\", line 85, in get_run_config_from_script_run\n         run_config.arguments = deepcopy(script_run_config.arguments)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py\", line 150, in deepcopy\n         y = copier(x, memo)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py\", line 215, in _deepcopy_list\n         append(deepcopy(a, memo))\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py\", line 180, in deepcopy\n         y = _reconstruct(x, memo, *rv)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py\", line 280, in _reconstruct\n         state = deepcopy(state, memo)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py\", line 150, in deepcopy\n         y = copier(x, memo)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py\", line 240, in _deepcopy_dict\n         y[deepcopy(key, memo)] = deepcopy(value, memo)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py\", line 180, in deepcopy\n         y = _reconstruct(x, memo, *rv)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py\", line 280, in _reconstruct\n         state = deepcopy(state, memo)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py\", line 150, in deepcopy\n         y = copier(x, memo)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py\", line 240, in _deepcopy_dict\n         y[deepcopy(key, memo)] = deepcopy(value, memo)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py\", line 180, in deepcopy\n         y = _reconstruct(x, memo, *rv)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copy.py\", line 274, in _reconstruct\n         y = func(*args)\n       File \"\/home\/sebastko\/miniconda3\/envs\/paml\/lib\/python3.6\/copyreg.py\", line 88, in __newobj__\n         return cls.__new__(cls, *args)\n     TypeError: __new__() missing 2 required positional arguments: 'workspace' and 'name'\n\n\n\nWhen I replace \"PipelineData\" with:\n\n OutputFileDatasetConfig().register_on_complete(name=\"xxx\")\n\n\n\n...then it works, but:\n\nI don't like that I need to register the dataset externally even though it's used only within the pipeline.\n\n\nIt seems to mess up step reusing - i.e., even though some steps in the pipeline may have \"allow_reuse=True\", if they are dependent on the data via OutputFileDatasetConfig().register_on_complete, they will need to be re-computed on every run of the pipeline.\n\nMy questions:\n1. Is there a way to feed PipelineData into HyperDriveStep correctly?\n2. Are there any other ways recommended to feed intermediate data to HyperDriveStep, but also allow reuse for any steps dependent on that intermediate data?\n3. If it's by design that PipelineData is not allowed in HyperDriveStep, could the AzureML team please make the error message less cryptic?\n\nI'd appreciate your help!\nThanks,\nSebastian",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-04T09:46:57.157Z",
                "Answer_score":0,
                "Answer_body":"I don\u2019t think you provided any answer for question 1&2 @ramr-msft Can you help 1&2?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Testing Data Problem",
        "Question_creation_time":1647528251100,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/776565\/testing-data-problem.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Any ideas what this could be? Trying to upload a test data to test the model.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-04T09:23:03.263Z",
                "Answer_score":0,
                "Answer_body":"Update about this case:\n\nDuring the support session, support team confirmed that PG has identified a bug where the target column in test data, which ideally should be optional, is currently required. PG will roll out the fix in the next python SDK release.\n\nSorry for the experience.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Submitting a job to Azure ML from Synapse workspace",
        "Question_creation_time":1648588740927,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/792681\/submitting-a-job-to-azure-ml-from-synapse-workspac.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":17,
        "Question_score":0,
        "Question_body":"Assume a data scientist who is coding inside a Synapse notebook, aims to submit his AutoML job to Azure ML. Also assume that we already created the Azure ML workspace, and linked it to Synapse, and also gave Synapse workspace the contributor access to Azure ML workspace. Also the data scientist has the Azure reader role at the synapse workspace level. Data scientist run the following code according to this link (https:\/\/docs.microsoft.com\/en-us\/azure\/synapse-analytics\/spark\/apache-spark-azure-machine-learning-tutorial)\n\nfrom azureml.core import Workspace\n\nsubscription_id = \"xxxxxx\" #you should be owner or contributor\nresource_group = \"xxxxx\" #you should be owner or contributor\nworkspace_name = \"xxxxx\" #your workspace name\nworkspace_region = \"xxxxx\" #your region\n\nws = Workspace(workspace_name = workspace_name,\nsubscription_id = subscription_id,\nresource_group = resource_group)\n\nHowever, he receives an error that says he does not have the required contributor\/owner roles at the subscription and resource group level. But we (as the synapse administrators) we don't want to give him the contributor\/owner role at the subscription and resource group name\n\nQuestion: How the data scientist can submit his job without letting him to have the required contributor\/owner role. Can he use the managed identity of the Synapse workspace to connect to the Azure ML workspace?\n\nThank you",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-30T06:04:50.573Z",
                "Answer_score":1,
                "Answer_body":"Hello anonymous user,\n\nThanks for the question and using MS Q&A platform.\n\nMake sure your Service principal or Managed Service Identity (MSI) must have \"Contributor\" access to the AML workspace.\n\nIf the model is registered in Azure Machine Learning, then you can choose either of the following two supported ways of authentication.\n\nThrough service principal: You can use service principal client ID and secret directly to authenticate to AML workspace. Service principal must have \"Contributor\" access to the AML workspace.\n\n\nThrough linked service: You can use linked service to authenticate to AML workspace. Linked service can use \"service principal\" or Synapse workspace's \"Managed Service Identity (MSI)\" for authentication. \"Service principal\" or \"Managed Service Identity (MSI)\" must have \"Contributor\" access to the AML workspace.\n\nHere is the complete walkthrough of authenticating AML workspace with Azure Synapse Analytics:\n\nFor more details, refer to Tutorial: Score machine learning models with PREDICT in serverless Apache Spark pools.\n\nHope this will help. Please let us know if any further queries.\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Authorization: Bearer [token] Error",
        "Question_creation_time":1648478793750,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/790341\/authorization-bearer-token-error.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"My Azure ML studio web service used to run fine but is unavailable for me to use now. Anybody know a fix?\n\nError Message: Could not authorize the request. Make sure the request has an Authorization header with a bearer token, of the form \"Authorization: Bearer [token]\". See online help to find which tokens are valid for this request.\nSite Path: \/workspaces\/fde0912ad97d4a94b9b2baaafd54c3e1\/webservices\/378f095e8260497697790a6d65fe9ff8\/endpoints\/default\nActivity ID: 82e53138-b3b9-4a94-8695-0b8152c505ac\nRequest ID: e3e8fbe7-6161-411b-9c2c-e2a609436353\nWorkspace ID: fde0912ad97d4a94b9b2baaafd54c3e1\nWorkspace Type: Free\nUser Role: Owner\nTenant ID: f8cdef31-a31e-4b4a-93e4-5f571e91255a",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-04T04:52:21.24Z",
                "Answer_score":1,
                "Answer_body":"Hello @dasa8-1391\n\nUpdate: The bug has been confirmed and the ETA is 2-3 weeks for the bug fixing. I am sorry for all the inconveniences.\n\nThe workaround for now is to use studio classic portal to manage the classic web service as below screenshot:\n\n\nThanks for the understanding and sorry for the experience again.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks a lot!",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Synapse Analytics Auto ML Predict No module named 'azureml.automl'",
        "Question_creation_time":1648542317563,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/791601\/synapse-analytics-auto-ml-no-module-named-39azurem.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"ref: https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/788637\/azure-synapse-ml-predict-errno-20-not-a-directory.html\n\n\n\n\nI get the following error with Apache Spark version 3.1 : ModuleNotFoundError: No module named 'azureml.automl'\n\nwith version 2.4",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-29T09:19:20.4Z",
                "Answer_score":0,
                "Answer_body":"Hello @ThiloBarth-2620,\n\nThanks for the question and using MS Q&A platform.\n\nIf you are using import azureml.automl in Apache spark 3.1 runtime, you will experience the error message stating No module named 'azureml.automl'.\n\nAs mentioned in the official document could you please try using from notebookutils.mssparkutils import azureML and it will work as excepted.\n\nHere is the sample notebook for Score machine learning models with PREDICT in serverless Apache Spark pools\n\n #!\/usr\/bin\/env python\n # coding: utf-8\n    \n # ## Azure_Synapse_ML_predict\n    \n    \n # In[Cell-1]:\n    \n    \n from notebookutils.mssparkutils import azureML\n    \n    \n # In[Cell-2]:  \n    \n ws = azureML.getWorkspace(\"AzureMLService\")\n        \n # In[Cell-3]:    \n    \n from azureml.core import Workspace, Model\n    \n model = Model(ws, id=\"linear_regression:1\")\n    \n model.download('.\/')\n        \n # In[Cell-4]:    \n    \n from pyspark.sql.functions import col, pandas_udf,udf,lit\n    \n from notebookutils.mssparkutils import azureML\n    \n from azureml.core import Workspace, Model\n    \n from azureml.core.authentication import ServicePrincipalAuthentication\n    \n import azure.synapse.ml.predict as pcontext\n    \n import azure.synapse.ml.predict.utils._logger as synapse_predict_logger\n    \n spark.conf.set(\"spark.synapse.ml.predict.enabled\",\"true\")\n    \n # In[Cell-5]:    \n    \n AML_MODEL_URI_SKLEARN= \"aml:\/\/linear_regression:1\"\n    \n # In[Cell-6]:    \n    \n model = pcontext.bind_model(\n    \n return_types=\"Array<float>\",\n    \n runtime=\"mlflow\",\n    \n model_alias=\"linear_regression:1\",\n    \n model_uri=AML_MODEL_URI_SKLEARN,\n    \n aml_workspace=ws\n    \n ).register()    \n    \n # In[Cell-7]:    \n    \n DATA_FILE = \"abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/AML\/LengthOfStay_cooked_small.csv\"\n df = spark.read     .format(\"csv\")     .option(\"header\", \"true\")     .csv(DATA_FILE,\n         inferSchema=True)\n df.createOrReplaceTempView('data')\n df.show(10)    \n    \n # In[Cell-8]:    \n    \n #Call PREDICT using Spark SQL API\n    \n predictions = spark.sql(\n               \"\"\"\n             SELECT PREDICT('linear_regression:1',\n             hematocrit,neutrophils,sodium,glucose,bloodureanitro,creatinine,bmi,pulse,respiration)\n             AS predict FROM data\n              \"\"\"\n         ).show()\n\nHope this will help. Please let us know if any further queries.\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":5,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-01T17:02:19.717Z",
                "Answer_score":1,
                "Answer_body":"I solved it. In my case it works best like this:",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine learning AutoML Fail",
        "Question_creation_time":1648706020587,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/794697\/azure-machine-learning-automl-fail.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi ,\n\nI use the fakenews data to try azure machine learning automl , but always train model fail and I tried reducing the feature field , but still fail\n\nError message :\n\n\n\n\n\nRun timed out. No model completed training in the specified time. Possible solutions:\n1) Please check if there are enough compute resources to run the experiment.\n2) Increase experiment timeout when creating a run.\n3) Subsample your dataset to decrease featurization\/training time out\n\n\n\n\n\ncompute machine : STANDARD_DS12_V2\n\ndata source : https:\/\/www.kaggle.com\/c\/fake-news\/data\n\n\n\n\n\nIs any good idea or suggestions ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-01T12:14:45.083Z",
                "Answer_score":0,
                "Answer_body":"@ianchen Thanks for the question. Please share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Comment s\u00e9lectionner Standard_DS11_v2",
        "Question_creation_time":1638368598000,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/647767\/comment-selectionner-standard-ds11-v2.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Bonjour\nJe suis le cours en ligne concernant l'impl\u00e9mentation d'algorithmes de machine learning\nA l'\u00e9tape Create compute resources\nhttps:\/\/docs.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/create-compute\n\nOn me demande Search for and select Standard_DS11_v2\n\nHors, l'interface me dit que je n'ai pas les quotas disponibles.\nJ'utilise l'offre d'essai \u00e0 200 USD.\nComment faire pour que cela fonctionne ?\nCordialement\nThibaut",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-02T08:09:58.51Z",
                "Answer_score":0,
                "Answer_body":"@ThibautJacquin-3972 For a free account only 200$ credit is available and not all compute can be created or selected because of this limitation. You can choose a lower priced VM and proceed with the creation of compute or upgrade to a pay-as-you-go account for your subscription and select the required compute type. I hope this helps.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-12-02T10:05:54.843Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nI am not a French speaker, below is my translation from machine:\n\nHello\nI am taking the online course on the implementation of machine learning algorithms\nAt the Create compute resources step\nhttps:\/\/docs.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/create-compute\n\n\nI am asked Search for and select Standard_DS11_v2\n\n\nHowever, the interface tells me that I do not have the quotas available.\nI am using the $ 200 trial offer.\nHow do I make it work?\nRegards\nThibaut\n\nAs the note: \"Compute instances and clusters are based on standard Azure virtual machine images. For this module, the Standard_DS11_v2 image is recommended to achieve the optimal balance of cost and performance. If your subscription has a quota that does not include this image, choose an alternative image; but bear in mind that a larger image may incur higher cost and a smaller image may not be sufficient to complete the tasks. Alternatively, ask your Azure administrator to extend your quota.\"\n\nYou do not need to select Standard_DS11_v2 for this, could you please try other similar image to see if that works( there is no effect for your lab)? There maybe some limitations from your administration.\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-12-02T14:18:35.637Z",
                "Answer_score":0,
                "Answer_body":"Thanks for you replies !\nIndeed, I can't select another image !\nFrom my understanding I have to ask to expand my quota !",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error running Experiment script (Azure Notebook - Python SDK)",
        "Question_creation_time":1648360151510,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/788720\/error-running-experiment-script-azure-notebook-pyt.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello,\n\nI am running the Azure ML Python example from here, https:\/\/docs.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/?view=azure-ml-py#run\n\nSpecifically this section of the example;\n\n from azureml.core.experiment import Experiment\n from azureml.core import ScriptRunConfig\n    \n script_run_config = ScriptRunConfig(source_directory=os.getcwd(), script=\"train.ipynb\", run_config=compute_config)\n experiment = Experiment(workspace=ws, name=\"compute_target_test\")\n run = experiment.submit(config=script_run_config)\n run.wait_for_completion(show_output=True)\n\n\n\nWhen I execute the above code I receive the error;\nmessage': \"User program failed with NameError: name 'true' is not defined\"\n\nThe log file gives the following details;\n\nFile \"train.ipynb\", line 67, in <module>\n\"notebookHasBeenCompleted\": true\nNameError: name 'true' is not defined\n\nThe problem is the train.ipynb file does not contain 67 lines.\n\nCould anyone provide some assistance as to how to resolve this.\n\nThanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-28T14:31:37.3Z",
                "Answer_score":0,
                "Answer_body":"@GrahamBenson-6517 Thanks for the question. We are able to run successfully with out an error as shown below.\n\n\nHere is link to the sample for using the environments.\n\n\n\n\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/tree\/master\/how-to-use-azureml\/training\/using-environments",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-03-30T09:21:36.737Z",
                "Answer_score":1,
                "Answer_body":"With the help of this post, https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/674712\/nameerror-when-trying-to-run-an-scriptrunconfig-in.html\nI have been able to resolve the problem.\n\nThe issue is the script parameter in the ScriptRunConfig class must be a .py file and not a .ipynb file. After changing the extension to *.py and downloading the Notebook the following JSON object will be visible;\n\n \"microsoft\": {\n           \"host\": {\n             \"AzureML\": {\n               \"notebookHasBeenCompleted\": true\n             }\n           }\n         },\n\n\n\nAfter changing the \"true\" value to \"True\" the script will execute successfully.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-04-02T07:27:31.687Z",
                "Answer_score":0,
                "Answer_body":"@ramr-msft\n\nHaving solved the above issue, I am now receiving the warning;\n\n\"Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies....\"\n\nI am using the curated environment, AzureML-sklearn-0.24-ubuntu18.04-py37-cpu which contains the packages;\n\nscikit-learn==0.24.1\n\n\nnumpy>=1.16.0\n\n\npandas~=1.1.x\n\nFollowing is the Notebook code;\n\n     from azureml.core import Workspace, Environment    \n     from azureml.core import ScriptRunConfig, Experiment\n     ws = Workspace.from_config()\n     myenv = Environment.get(workspace=ws, name=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\")   \n       \n        \n     exp = Experiment(name=\"myexp\", workspace = ws)\n     # Instantiate environment\n     myenv = Environment(name=\"myenv\")\n        \n     # Add training script to run config\n     runconfig = ScriptRunConfig(source_directory=\".\", script=\"train.py\")\n        \n     # Attach compute target to run config\n     runconfig.run_config.target = \"local\"\n        \n     # Attach environment to run config\n     runconfig.run_config.environment = myenv\n        \n     # Submit run \n     run = exp.submit(runconfig)\n\n\n\nThe train.py script is taken from the example, here https:\/\/docs.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/?view=azure-ml-py#run\n\n ------------------------------ train.py script ----------------------------------\n # train.py\n    \n from sklearn import svm\n import numpy as np\n import joblib\n import os\n    \n # customer ages\n X_train = np.array([50, 17, 35, 23, 28, 40, 31, 29, 19, 62])\n X_train = X_train.reshape(-1, 1)\n # churn y\/n\n y_train = [\"yes\", \"no\", \"no\", \"no\", \"yes\", \"yes\", \"yes\", \"no\", \"no\", \"yes\"]\n    \n clf = svm.SVC(gamma=0.001, C=100.)\n clf.fit(X_train, y_train)\n    \n os.makedirs(\"outputs\", exist_ok=True)\n joblib.dump(value=clf, filename=\"outputs\/churn-model.pkl\")\n    \n ------------------------------ train.py script ----------------------------------\n\nCan you please assist with the above. Why would I receive the error message when the environment being used is a Microsoft curated environment?\n\nThank you",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to solve \"max file size reached..\" issue on Azure ML notebook?",
        "Question_creation_time":1646248822733,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/756887\/how-to-solve-34max-file-size-reached34-issue-on-az.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":19,
        "Question_score":0,
        "Question_body":"Azure machine learning studio slows down. I get message like \"Max file size reached\" on the notebook quite often.\nCan anyone please tell me how to get rid of this issue?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-10T07:55:22.593Z",
                "Answer_score":0,
                "Answer_body":"@AbhijitZarekar-3908 Thanks for the details. Please share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"feature in new generation of classic studio",
        "Question_creation_time":1648513803980,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/791041\/feature-in-new-generation-of-classic-studio.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"hi:\n\nI have a question regarding to the new generation as I have already known that the classic old version of machine learning studio is retiring in August 2024.\n\nI wonder if all the features will be continouslty supported in the new generation of new version of studio in the future?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-29T03:44:35.91Z",
                "Answer_score":0,
                "Answer_body":"Hello @dontbelazy-2604\n\nThanks for reaching out to us here, I just answered your question under your previous thread. Not every feature in Studio (classic) will be back as the same, but most of the previous features\/ functions will be covered in the Azure Machine Learning Studio (V2).\n\nPlease go ahead to do the migration first, if you face any issue or you feel like some of the features missing, please let us know, we can help.\n\nGenerally, the new studio will provide a better experience.\n\nHope this helps.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How to lable Table with no column in Azure Form Recognizer",
        "Question_creation_time":1647507167407,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/775939\/how-to-lable-table-with-no-column-in-azure-form-re.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I have a PDF file which will contains some data like below structure.\n\nI want to use Azure Form Recognizer to get the data.\n\nHow can I set the label with Table.\n\nWhile tagging with Table, it need to specify the Column and Row.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-18T02:03:58.987Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. With Form Recognizer Studio (preview), you can create columns\/rows and label the data to the structure you want. You may not be able to label using above format (there's no option to create columns within a column), but you can adjust to a structure that is supported. This document shows demo of how to label forms using studio. Hope this helps.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Data Labeling images removed from dataset still being display when \"data label\"",
        "Question_creation_time":1648547078293,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/791637\/azure-ml-data-labeling-images-removed-from-dataset.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello,\n\nI created a labeling project by creating a new dataset that imports files from local. Afterwards, some images previously uploaded need to be replaced by a new images (we decided to change some details of the display).\n\nHowever, when creating a new version of the dataset with the updated images (this works well) and refreshing the project, the images display when \"label data\" remain unchanged (also the on-demand incremental refresh date doesnt change, I assume because the images have the same name so project doesnt recognize something has changed.)\n\nI tried deleting images from the dataset thinking about reloading them, but the project also doesnt stop showing deleted images.\n\nIs there a way I can get my new image versions correctly displayed without having to create a new project?\n\nThanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-29T15:48:21.383Z",
                "Answer_score":0,
                "Answer_body":"@Maite-3025 Thanks for the question. Please details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AzureMLCompute job failed",
        "Question_creation_time":1647081369547,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/769672\/azuremlcompute-job-failed-1.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I have created a simple pipeline in Azure ML studio.\nThe pipeline contains only one module \"Import Data\" which is set up as follows:\n\n][2]\n\nThis is a very small dataset that can be found here: https:\/\/archive.ics.uci.edu\/ml\/datasets\/adult\n\nThe validation passed and I can see the sample data.\n\nI have tried to run this pipeline twice and both runs:\n1. Took very long time - over 30 minutes\n2. Failed with the message \"AzureMLCompute job failed. InternalError: Server encountered an internal error. Please try again after some time\"\n\n\n\n\nWhen I look at the error logs of the module I see the following:\n\nJob failed, job RunId is cff2da53-1726-4092-9887-c7cb3c57dd81. Error: {\"Error\":{\"Code\":\"ServiceError\",\"Severity\":null,\"Message\":\"AzureMLCompute job failed.\\nInternalError: Server encountered an internal error. Please try again after some time\",\"MessageFormat\":null,\"MessageParameters\":null,\"ReferenceCode\":null,\"DetailsUri\":null,\"Target\":null,\"Details\":[],\"InnerError\":null,\"DebugInfo\":null,\"AdditionalInfo\":null},\"Correlation\":{\"operation\":\"be4e18a418e8ad6b924b509d8a353404\",\"request\":\"124bf413bb074f22\"},\"Environment\":\"eastus\",\"Location\":\"eastus\",\"Time\":\"2022-03-12T10:25:01.2364098+00:00\",\"ComponentName\":\"globaljobdispatcher\"}\n\nI am using the following compute:\n\nEven though this is marked as an internal server error, since I tried more than once - I think something is wrong with one of my settings.\n\nWould appreciate help with this.\n\nThanks.\n\n[2]: \/answers\/storage\/attachments\/182456-image.png",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-14T06:03:52.29Z",
                "Answer_score":0,
                "Answer_body":"@BelgiAmir-3027 I tried import data module and it seems to work fine while using the URI. I think in your case the link is incorrect, The URI download link is enabled on https.\n\nhttps:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/adult\/adult.data\n\nWith the above link, the module ran successfully and the data is available to view.\n\n@AngelicaGarrido-1922 @RahulKhanna-2541 Are you using the same dataset in your jobs? You can also report internal errors through Azure ml portal ml.azure.com using the smiley icon on the top right corner. This reports the issue directly to the product group to lookup the error based on the run details.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Synapse ML predict [Errno 20] Not a directory",
        "Question_creation_time":1648335577807,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/788637\/azure-synapse-ml-predict-errno-20-not-a-directory.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":16,
        "Question_score":0,
        "Question_body":"I follow the official tutotial from microsoft: https:\/\/docs.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool\n\nBut when I execute:\n\n #Bind model within Spark session\n model = pcontext.bind_model(\n     return_types=RETURN_TYPES, \n     runtime=RUNTIME, \n     model_alias=\"Sales\", #This alias will be used in PREDICT call to refer  this   model\n     model_uri=AML_MODEL_URI, #In case of AML, it will be AML_MODEL_URI\n     aml_workspace=ws #This is only for AML. In case of ADLS, this parameter can be removed\n ).register()\n\n\n\nI\u00b4ve got:\n\n\n\n\nNotADirectoryError: [Errno 20] Not a directory: '\/mnt\/var\/hadoop\/tmp\/nm-local-dir\/usercache\/trusted-service-user\/appcache\/application_1648328086462_0002\/spark-3d802a7e-15b7-4eb6-88c5-f0e01f8cdb35\/userFiles-fbe23a43-67d3-4e65-a879-4a497e804b40\/68603955220f5f8646700d809b71be9949011a2476a34965a3d5c0f3d14de79b.pkl\/MLmodel'\nTraceback (most recent call last):\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_context.py\", line 47, in bind_model\nudf = _create_udf(\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_udf.py\", line 104, in _create_udf\nmodel_runtime = runtime_gen._create_runtime()\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_runtime.py\", line 103, in _create_runtime\nif self._check_model_runtime_compatibility(model_runtime):\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_runtime.py\", line 166, in _check_model_runtime_compatibility\nmodel_wrapper = self._load()\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_runtime.py\", line 78, in _load\nreturn SynapsePredictModelCache._get_or_load(\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/core\/_cache.py\", line 172, in _get_or_load\nmodel = load_model(runtime, model_uri, functions)\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/utils\/_model_loader.py\", line 257, in load_model\nmodel = loader.load(model_uri, functions)\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/utils\/_model_loader.py\", line 122, in load\nmodel = self._load(model_uri)\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/utils\/_model_loader.py\", line 215, in _load\nreturn self._load_mlflow(model_uri)\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/azure\/synapse\/ml\/predict\/utils\/_model_loader.py\", line 59, in _load_mlflow\nmodel = mlflow.pyfunc.load_model(model_uri)\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/mlflow\/pyfunc\/`init`.py\", line 640, in load_model\nmodel_meta = Model.load(os.path.join(local_path, MLMODEL_FILE_NAME))\n\nFile \"\/home\/trusted-service-user\/cluster-env\/env\/lib\/python3.8\/site-packages\/mlflow\/models\/model.py\", line 124, in load\nwith open(path) as f:\n\nNotADirectoryError: [Errno 20] Not a directory: '\/mnt\/var\/hadoop\/tmp\/nm-local-dir\/usercache\/trusted-service-user\/appcache\/application_1648328086462_0002\/spark-3d802a7e-15b7-4eb6-88c5-f0e01f8cdb35\/userFiles-fbe23a43-67d3-4e65-a879-4a497e804b40\/68603955220f5f8646700d809b71be9949011a2476a34965a3d5c0f3d14de79b.pkl\/MLmodel'\n\nHow can I fix that error ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-28T11:26:12.193Z",
                "Answer_score":1,
                "Answer_body":"Hello @ThiloBarth-2620,\n\nThanks for the question and using MS Q&A platform.\n\n(UPDATE:29\/3\/2022): You will experiencing this error message if you model does not contains all the required files in the ML model.\n\nAs per the repro, I had created two ML models named:\n\nsklearn_regression_model: Which contains only sklearn_regression_model.pkl file.\n\nWhen I predict for MLFLOW packaged model named sklearn_regression_model, getting same error as shown above:\n\nlinear_regression: Which contains the below files:\n\nWhen I predict for MLFLOW packaged model named linear_regression, it works as excepted.\n\n--------------------------------------------------\n\nIt should be AML_MODEL_URI = \"<aml model uri>\" #In URI \":x\" => Rossman_Sales:2\n\nBefore running this script, update it with the URI for ADLS Gen2 data file along with model output return data type and ADLS\/AML URI for the model file.\n\n #Set model URI\n        #Set AML URI, if trained model is registered in AML\n           AML_MODEL_URI = \"<aml model uri>\" #In URI \":x\" signifies model version in AML. You can   choose which model version you want to run. If \":x\" is not provided then by default   latest version will be picked.\n    \n        #Set ADLS URI, if trained model is uploaded in ADLS\n           ADLS_MODEL_URI = \"abfss:\/\/<filesystemname>@<account name>.dfs.core.windows.net\/<model   mlflow folder path>\"\n\nModel URI from AML Workspace:\n\n DATA_FILE = \"abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/AML\/LengthOfStay_cooked_small.csv\"\n AML_MODEL_URI_SKLEARN = \"aml:\/\/mlflow_sklearn:1\" #Here \":1\" signifies model version in AML. We can choose which version we want to run. If \":1\" is not provided then by default latest version will be picked\n RETURN_TYPES = \"INT\"\n RUNTIME = \"mlflow\"\n\nModel URI uploaded to ADLS Gen2:\n\n DATA_FILE = \"abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/AML\/LengthOfStay_cooked_small.csv\"\n AML_MODEL_URI_SKLEARN = \"abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/linear_regression\/linear_regression\" #Here \":1\" signifies model version in AML. We can choose which version we want to run. If \":1\" is not provided then by default latest version will be picked\n RETURN_TYPES = \"INT\"\n RUNTIME = \"mlflow\"\n\n\n\nHope this will help. Please let us know if any further queries.\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":7,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Key for ML Endpoint",
        "Question_creation_time":1648186512237,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/787004\/key-for-ml-endpoint.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hi,\n\nI am new to Azure.\nI have created ML endpoint and when I try to access, I see a message \"Unauthorized, no token matched\".\nI know its Key based Auth.\nwhere can I find this key? can someone help me?\n\nregards,\n\nRohan",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-28T07:40:44.61Z",
                "Answer_score":0,
                "Answer_body":"@ROHANC-4945 I believe you are using the Azure ML Designer portal to deploy your endpoints.\nIn this case you will get the token for your endpoint from the consume tab as seen below:\n\nThe tab also lists snippets to call the endpoint programatically for reference.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"machine learning Studio",
        "Question_creation_time":1648415916797,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/789066\/machine-learning-studio.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi:\n\nI wonder when will the classic Machine Learning Studio retire?\n\nAlso in order to save my data and file, any preparation or migration should be done to avoid any loss?\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-27T23:20:57.9Z",
                "Answer_score":0,
                "Answer_body":"Hello @dontbelazy-2604\n\nThanks for reaching out to us, I think you are mentioning Azure Machine Learning Studio(classic). Machine Learning Studio (classic) will retire on 31 August 2024.\n\nFrom now through 31 August 2024, you can continue to use the existing Machine Learning Studio (classic). Beginning 1 December 2021, you will not be able to create new Machine Learning Studio (classic) resources.\n\nRequired action to avoid loss:\n\nFollow these steps to transition using Azure Machine Learning before 31 August 2024. Pricing may be subject to change, please view pricing here.\n\nHope this helps!\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks!",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"500 Internal Server Error Azure ml studio (classic)",
        "Question_creation_time":1648325290653,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/788677\/500-internal-server-error-azure-ml-studio-classic.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I've some problem i try to run my application on my apache2 web server everything good but when my app send api to azure ml studio it's show status code : \"500 Internal Server Error \".\nSo i open my local(dev) app and send api again result is good\n\n\nthen I want to know what is happening now or I do something wrong?\n\nthis is my proxypass",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"A\/B testing using Azure Container Instance.",
        "Question_creation_time":1648100125823,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/785262\/ab-testing-using-azure-container-instance.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":19,
        "Question_score":0,
        "Question_body":"I have two ML models A and B registered in my workspace and I want to deploy them to Azure Container Instance and perform A\/B testing or continuous rollout or Canary deployment. Can it be done without using AKS and only on ACI.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-25T01:18:56.617Z",
                "Answer_score":0,
                "Answer_body":"Hello @HARISHKUMAR-4152\n\nThanks for reaching out to us. I can understand you want to deploy your ML models to ACI to do the A\/B test. For question can models to be deployed only ACI, the answer is yes, but please be aware that ACI has some limitation compared to AKS, please check if ACI is a good choice for your model:\n\nAbout models:\nACI is suitable only for small models that are under 1 GB in size.\nWe recommend using single-node AKS to dev-test larger models.\nThe number of models to be deployed is limited to 1,000 models per deployment (per container).\n\nAbout Vnet:\nWhen using Azure Container Instances in a virtual network, the virtual network must be in the same resource group as your Azure Machine Learning workspace.\nWhen using Azure Container Instances inside the virtual network, the Azure Container Registry (ACR) for your workspace cannot also be in the virtual network.\n\nOther points:\nprefer not to manage your own Kubernetes cluster\nAre OK with having only a single replica of your service, which may impact uptime\nYou are advised to debug locally before deploying to the web service,\n\nAKS Advantages for your reference as well:\nFast response time\nAutoscaling of the deployed service\nLogging\nModel data collection\nAuthentication\nTLS termination\nHardware acceleration options such as GPU and field-programmable gate arrays (FPGA)\n\nIf you feel like ACI fulfill your need, then you can follow below guidance to do the deployment:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-container-instance#deploy-to-aci\n\nHope this helps, please let me know if you have more questions.\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Use the value of a PipelineParameter (passed from DataFactory) in a blob path for an OutputFileDatasetConfig object (in an ML pipeline)",
        "Question_creation_time":1648036709603,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/784006\/use-the-value-of-a-pipelineparameter-passed-from-d.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"Hello,\n\nIs it possible to use a PipelineParameter (defined in a DataFactory 'Machine Learning Execute Pipeline' activity) during the creation of a OutputFileDatasetConfig object in said Machine Learning pipeline?\n\nMy DataFactory pipeline runs on a schedule (via a trigger) and executes an Azure ML pipeline which does data preparation and model training.\nThe trigger start date is passed as a parameter 'date_time' to the ML pipeline.\n\nIn my ML pipeline, I want to save the model artifacts (trained in a PythonScriptStep) to a blob path (default_datastore + 'output_model\/{date_time}') which contains the value of the 'date_time' parameter. But I can't figure out a way to use the value of 'date_time' during the creation of the OutputFileDatasetConfig object (maybe there is a simple way to save model artifacts than to use a OutputFileDatasetConfig object?).\n\nAs a temporary hack, I am using a variable 'today_date' in my ML pipeline definition which contains today's date, and I use this variable to build the destination path of OutputFileDatasetConfig.\nBut the ideal solution would be to get the actual date directly from the DataFactory trigger parameter.\nThis is how I do now in my ML pipeline (not ideal):\n\n import datetime\n today_date = datetime.date.today().strftime('%Y%m%d')\n model_output_path = (def_data_store, f\"output_model\/{today_date}\")\n output_config = OutputFileDatasetConfig(destination = model_output_path)\n\n\n\nThis is what I tried in order to get the value of PipelineParameter, but it didn't work:\n\n pipeline_parameter = PipelineParameter(name=\"date_time\", default_value=today_date)\n model_output_path = (def_data_store, f\"output_model\/{pipeline_parameter}\")\n output_config = OutputFileDatasetConfig(destination = model_output_path)\n\n\n\nIt seems the only way to get the value of the PipelineParameter is through an argument inside a PythonScriptStep.\nI don't think I can create the OutputFileDatasetConfig object INSIDE the PythonScriptStep.\nIs there any other way to easily save model artifacts to a specific blob path which contains the value of a PipelineParameter?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-28T07:56:39.81Z",
                "Answer_score":0,
                "Answer_body":"@ShaikMaheer-MSFT\n\nHello and thanks for your answer.\n\nI solved my problem and I will explain how.\n\nWhat I was trying to do was to get the value of a PipelineParameter (containing the date at which the pipeline was triggered by Data Factory) in my Azure ML pipeline definition script in order to use it in the destination name of my OutputFileDatasetConfig object. Basically I wanted the destination name to be something like 'output_model\/20220328' where '20220328' is the value of the PipelineParameter.\n\nBut it seems impossible to read the value of a PipelineParameter outside of a PythonScriptStep.\n\nWhat I did to solve this is to create my OutputFileDatasetConfig first without specifying the full destination path.\nI specify only 'output_model' in the path. Then I get a reference to the PipelineParameter (at this point I still don't know its value).\n\n model_output_config = OutputFileDatasetConfig(destination = (def_data_store, 'output_model'))\n output_model_date = PipelineParameter(name=\"date_time\", default_value=\"20220328\")\n\n\n\nThen I pass both references as arguments to my PythonScriptStep.\n\n train = PythonScriptStep(\n     name=\"Train model\",\n     script_name=\"train.py\",\n     source_directory=\".\/\",\n     arguments=[\n         \"--output-model-dir\", model_output_config ,\n         \"--output-model-date\", output_model_date\n     ],\n     compute_target=compute_target,\n     runconfig=aml_run_config\n )\n\n\n\nAnd finally in my training script I get the actual value of the PipelineParameter and I just concatenate both parameters to create the full path:\n\n parser.add_argument(\"--output-model-dir\", type=str, dest=\"output_model_dir\", default=\"output_model\", help=\"Directory to store trained output models and artifacts\")\n parser.add_argument(\"--output-model-date\", type=str, dest=\"output_model_date\", default=\"20220328\", help=\"Date to use in the name of the output model folder\")\n output_model_dir = args.output_model_dir\n output_model_date = args.output_model_date\n full_output_model_dir = os.path.join(output_model_dir, output_model_date)\n\n\n\nAnd now I can save directly my model artifacts to 'full_output_model_dir'.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"how to pass test data to my deployed model in azure ml through function app",
        "Question_creation_time":1646371928903,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/759087\/how-to-pass-test-data-to-my-deployed-model-in-azur.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":19,
        "Question_score":0,
        "Question_body":"i am trying to make predictions for the model which is deployed in azure ml through function app\n\n1) my data is in azure blob storage\n2) i want to pass that data to model ( which is deployed ) for predictions\n3) once predictions is over i want to save that file again into blob storage\n\n\n\n\n\nall above has to be done through function app \n\ni dont have any idea on how to do it , any suggestions",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-04T12:47:51.377Z",
                "Answer_score":0,
                "Answer_body":"@ranjithkumar-3800 Thanks for the question. The deployment of a ML model to Azure Functions is in preview. Azure ML Managed Endpoints for enabling customers deploy models at cloud scale without needing to create & manage their own clusters. Here is link to the document that could help to Deploy and score a machine learning model by using an online endpoint (preview).\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-managed-online-endpoints",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Result with coordinator convertion",
        "Question_creation_time":1648416629250,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/789141\/result-with-coordinator-convertion.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I wonder how could I convert the result of boundingbox of form recognizer into image coordinate to visualize the overlay image and recognized data.\n\nI could not have that accomplished because it is not similar to normal coordinates.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-27T22:02:17.72Z",
                "Answer_score":0,
                "Answer_body":"Hello @masterhunter-9726\n\nThank you for reaching out to us, I think you have questions about the value of boundingBoxes, below I will give an example to explain it so that you can convert it to the coordinate you want to use:\n\nExample:\n\n\n\n\n    'boundingBox': [\n                 57.1,\n                 683.3,\n                 100.2,\n                 683.3,\n                 100.2,\n                 673.3,\n                 57.1,\n                 673.3\n               ]\n\n\n\nThose values represent the vertices of the bounding box as below:\n\n   (57.1,683.3) X1,Y1---->x2,y2(100.2,683.3)\n                   |                |\n                   |                |\n   (57.1,673.3) X4,Y4<----x3,y3(100.2,673.3)\n\n\n\nThe (0,0) is on the bottom left as you can see.\n\n \/\/ Azure Bounding box is like this                     \n \/\/                                                     0---->1\n \/\/                                                    |     |\n \/\/                                         Y          |     |\n \/\/                                         \u2191         3<----2\n \/\/                                  Origin . \u2192 X\n\n\n\nIf you want to measure the boundingBoxes, you can use above vertices to do the calculation.\n\nHope this helps!\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks!",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Get the list of input data in real time azure ml webservice",
        "Question_creation_time":1647338919760,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/772716\/get-the-list-of-input-data-in-real-time-azure-ml-w.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi, I am new to azure ml and I have a question about Real-time inference .\nafter deploying the service on ACI how can I get the list of input data that I should enter to make a prediction using python code from the parameters of the webservice ( endpoint , api key , webservice name , workspace,..)\n\nthank you",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-27T11:38:48.373Z",
                "Answer_score":0,
                "Answer_body":"Hi, I'm sorry for the delay of my answer,\n\nI am following this guidance :\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=python\n\nand as I said I want to Identify the input data. Let's say I had a friend who deployed a model as real-time inference and I am in the other hand want to make my predictions and I just have the REST Endpoint and API key, how can I identify what should be the input data from these information.\nthe guide I am following didn't specify how to identify the input data structure. I know it should be in Json format like the following Json :\n{\n\"data\":\n[\n<model-specific-data-structure>\n]\n}\nWhat I want to know is how to get the <model-specific-data-structure> with only the deployment output like REST API, swagger_uri.\n\nI hope you understand my problem.\n\nThanks again.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure function in Python 3.8 invoking Azure ML",
        "Question_creation_time":1648172045810,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/786745\/azure-function-in-python-38-invoking-azure-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":18,
        "Question_score":0,
        "Question_body":"I am working on an Azure Function which is written in Python 3.8. Azure function in Azure in Python is deployed in Linux. The Azure function is invoking Azure ML pipeline. When invoking the pipeline I am seeing the following exception:\n\nException: NotImplementedError: Linux distribution debian 11. does not have automatic support. .NET Core 2.1 can still be used via dotnetcore2 if the required dependencies are installed. Visit https:\/\/aka.ms\/dotnet-install-linux for Linux distro specific .NET Core install instructions. Follow your distro specific instructions to install dotnet-runtime- and replace with 2.1\n\nI have tried installing dotnetcore2 runtime via requirements.txt file but still getting the error. Any help is appreciated.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure ML Studio is bugged out and can not create a Microsoft ticket under MSDN. Need a few suggestions",
        "Question_creation_time":1647349970220,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/772790\/azure-ml-studio-is-bugged-out-and-can-not-create-a.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"ML studio is, by default picking up Python 3.6 kernel, even when I'm specifying use Python 3.8 AzureML kernel. In UI, it's changed but not actually.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-16T17:18:38.727Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. It looks like the command you ran isn't supported. A better command to test kernel changes is shown below:\n\n from platform import python_version\n print(python_version())\n\nHope this helps!",
                "Answer_comment_count":6,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azureml dataset consumption does not work when whitespaces are in the file name",
        "Question_creation_time":1645111306257,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/740186\/azureml-dataset-consumption-does-not-work-when-whi.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hello,\nwhen i previously exported the data from a data labeling project to Azure ML dataset, i could consume them with the azureml.contrib.dataset\n\nThis seems to be not supported anymore, therefor i tried to download them with the azureml.core Dataset package.\nIt seems to works only for data which have no white space in their name.\nThe dataset is a Tabular dataset, i download them with:\n\n from azureml.core import Workspace, Dataset\n workspace = Workspace(subscription_id, resource_group, workspace_name)\n dataset = Dataset.get_by_name(workspace, name='my_dataset_name')\n dataset.download('image_url', target_path='.\/', overwrite=True)\n\nError:\n\n\n\n\nAzureMLException:\nMessage: Some files have failed to download:('workspaceblobstore\/data\/quay_data_cra\/IMG_0082%20copy%207.jpg', 'Microsoft.DPrep.ErrorValues.DownloadFailed')\n('workspaceblobstore\/data\/quay_data_cra\/IMG_0543%20copy%205.jpg', 'Microsoft.DPrep.ErrorValues.DownloadFailed')\n\nHow can i download the dataset?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-01T10:57:25.963Z",
                "Answer_score":0,
                "Answer_body":"Hello @JanRubenSchmid-7483\n\nWe are sorry not to hear you back. Just want to update here, I have forwarded this issue to product team to investigate.\n\nFor workaround, please try \"file_handling_option\" to see if that works for you. Please let us know if you are still blocked. Thanks a lot.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-03-08T11:26:04.7Z",
                "Answer_score":0,
                "Answer_body":"Hello @YutongTie-MSFT ,\ni have just installed the latest version of azure ml core (1.39.0) and it seems the issue is still not fixed, is there any progress on your side?\n\nRegards,\nJan-Ruben",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-03-25T16:39:32.207Z",
                "Answer_score":0,
                "Answer_body":"Hi @YutongTie-MSFT\n\nI have exactly the same problem despite my files not having blanks.\n\nMy azure dataset name is:\n\npreprocess_config.json\n\nPath in blob is:\n\n\n\n\npreprocess_configs\/preprocess_config_day2022-03-24_16:28.json.\n\nWhen trying to download:\n\n parser = argparse.ArgumentParser()\n # DEFAULT ARGUMENTS\n parser.add_argument('--dataset', type=str,\n                     help='Data to score')\n parser.add_argument(\"--model_name\", type=str,\n                     help=\"Model to be used for scoring\",\n                     default=\"model_12\")\n parser.add_argument(\"--register_config_name\", type=str,\n                     help=\"Model to be used for scoring\",\n                     default=\"preprocess_config.json\")\n args, _ = parser.parse_known_args()\n preprocessing_config_dataset = Dataset.get_by_name(ws, name=args.register_config_name, version='latest')\n test = preprocessing_config_dataset.download(target_path='.', overwrite=True)\n > Traceback (most recent call last):\n >   File \"<stdin>\", line 1, in <module>\n >   File \"\/anaconda\/envs\/xgboost_gpu\/lib\/python3.8\/site-packages\/azureml\/data\/_loggerfactory.py\", line 132, in wrapper\n >     return func(*args, **kwargs)\n >   File \"\/anaconda\/envs\/xgboost_gpu\/lib\/python3.8\/site-packages\/azureml\/data\/file_dataset.py\", line 177, in download\n >     download_list = _get_and_validate_download_list(download_records,\n >   File \"\/anaconda\/envs\/xgboost_gpu\/lib\/python3.8\/site-packages\/azureml\/data\/file_dataset.py\", line 687, in _get_and_validate_download_list\n >     _download_error_handler(error_list)\n >   File \"\/anaconda\/envs\/xgboost_gpu\/lib\/python3.8\/site-packages\/azureml\/data\/dataset_error_handling.py\", line 188, in _download_error_handler\n >     raise UserErrorException(message) if all_user_errors else AzureMLException(message)\n > azureml.exceptions._azureml_exception.UserErrorException: UserErrorException:\n >         Message: Some files have failed to download:('Path', 'Microsoft.DPrep.ErrorValues.InvalidArgument')\n >         InnerException None\n >         ErrorResponse \n > {\n >     \"error\": {\n >         \"code\": \"UserError\",\n >         \"message\": \"Some files have failed to download:('Path', 'Microsoft.DPrep.ErrorValues.InvalidArgument')\"\n >     }\n > }",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"FileNotFoundError: [Errno 2] - Score machine learning models with PREDICT in serverless Apache Spark pools (Synapse & Azure Machine learning AML)",
        "Question_creation_time":1639738776307,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/667458\/filenotfounderror-errno-2-score-machine-learning-m.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_comment_count":1,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"Hi all,\n\nI am following the steps on this tutorial:\nTutorial: Score machine learning models with PREDICT in serverless Apache Spark pools tutorial-score-model-predict-spark-pool\nand what-is-aml-model-uri-predict-in-serverless-apache-1.html\nI tried to used a model created with AutoML and another from designer and I am getting this error: FileNotFoundError: [Errno 2] No such file or directory: '\/tmp\/tmp5xd2_hyr\/MLmodel'\n\nI added the DATA_FILE:\n\nI am getting this error (I am using Synapse):\n\n\nKind regards,\nAnaid",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-20T08:41:11.013Z",
                "Answer_score":0,
                "Answer_body":"Hello @Anaid-6816,\n\nThanks for the question and using MS Q&A platform.\n\nMake sure you have upload the mlflow folder to AML, not the parent folder to AML.\n\nNote: As per the repro, I got the same error message when I uploaded the parent folder to the AML workspace.\n\nAble to resolve the issue by uploading the mlflow folder to AML workspace.\n\n DATA_FILE = \"abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/AML\/LengthOfStay_cooked_small.csv\"\n AML_MODEL_URI_SKLEARN = \"aml:\/\/chepra:1\" #Here \":1\" signifies model version in AML. We can choose which version we want to run. If \":1\" is not provided then by default latest version will be picked\n RETURN_TYPES = \"INT\"\n RUNTIME = \"mlflow\"\n\n\n\nHope this will help. Please let us know if any further queries.\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-01-13T08:00:37.883Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nCan you explain a bit more on uploading the MLFlow to AML.\n\nWe currently have BoosteDecisionTitanic:1 in models on AML. How do we upload the MLFlow to AML.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-01-14T15:02:26.86Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nCan you explain a bit more on uploading the MLFlow to AML. Where are those files and how can we upload them?\n\nWe currently have BoosteDecisionTitanic:1 in models on AML. How do we upload the MLFlow to AML.\n\n\n\n\n\n\nKind regards,\nAnaid",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-03-24T18:34:32.82Z",
                "Answer_score":0,
                "Answer_body":"any solution yet?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"PermissionDeniedError when trying to save a Tensorflow model checkpoint",
        "Question_creation_time":1643818966130,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/720040\/permissiondeniederror-when-trying-to-save-a-tensor.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":12,
        "Question_follower_count":18,
        "Question_score":0,
        "Question_body":"Hi,\n\nWe are using the Azure Machine Learning Studio to run pipelines in which computer vision models are trained using Tensorflow (v2.4.0).\nOur input data (images & annotations) are stored on our Azure Blob Storage account.\nThe saved models are also saved to the same Azure Blob Storage account\n\nWe have several different pipelines (for different projects) that all worked perfectly fine for the last months... up until last week.\nEvery pipeline (that worked before) results in the exact same error now.\nEverything (image loading, preprocessing, augmentations, ...) works fine.\nThe training step starts and the first epoch is trained.\nHowever after the first epoch is done training, the error occurs.\n\ntensorflow\/core\/framework\/op_kernel.cc:1763] OP_REQUIRES failed at save_restore_v2_ops.cc:157 : Permission denied: \/mnt\/azureml\/cr\/j\/0ddbaa5dfd4243c4bd18feabd6037209\/cap\/data-capability\/wd\/output_84f84eab_univision_ai\/pc_ds_2021_v3\/refinement-reg\/v2\/results\/128_c1720fb5-81ed-45aa-a823-a1fa5ef1a8d1\/export\/saved_model\/variables\/variables_temp\/part-00000-of-00001.data-00000-of-00001.tempstate5255274353572806690; Read-only file system\n...\nEpoch 00001: val_loss improved from inf to 0.10273, saving model to \/mnt\/azureml\/cr\/j\/0ddbaa5dfd4243c4bd18feabd6037209\/cap\/data-capability\/wd\/output_84f84eab_univision_ai\/pc_ds_2021_v3\/refinement-reg\/v2\/results\/128_c1720fb5-81ed-45aa-a823-a1fa5ef1a8d1\/export\/saved_model Cleaning up all outstanding Run operations, waiting 300.0 seconds 2 items cleaning up... Cleanup took 0.19626808166503906 seconds\n...\ntensorflow.python.framework.errors_impl.PermissionDeniedError: \/mnt\/azureml\/cr\/j\/0ddbaa5dfd4243c4bd18feabd6037209\/cap\/data-capability\/wd\/output_84f84eab_univision_ai\/pc_ds_2021_v3\/refinement-reg\/v2\/results\/128_c1720fb5-81ed-45aa-a823-a1fa5ef1a8d1\/export\/saved_model\/variables\/variables_temp\/part-00000-of-00001.data-00000-of-00001.tempstate5255274353572806690; Read-only file system [Op:SaveV2]\n\nWe get a PermissionDeniedError while trying to save a temporary file, apparently because it's a read-only file system.\nIf we take a look at this temporary file in the Azure storage account there is nothing that points out it would be read-only.\nThere's also no difference in settings between this file and other files that we were able to read\/write.\n\nI have already been able to find what direction to search in.\nIn the training pipeline step we have always been using Model Checkpoint (if the validation is better than the current saved checkpoint, the model checkpoint is saved).\nBy deleting the Model Checkpoint callback, the error does not occur.\nThis is not a solution of course, as we do need these model checkpoints.\nIt does show however that it has something to do with these model checkpoints.\n\nI am not sure what else I can try to solve this issue.\n\nKind regards",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-08T13:36:39.523Z",
                "Answer_score":1,
                "Answer_body":"I just had a call with a Support Engineer of Microsoft and they solved the issue.\nApparently they are implementing a new version of AzureML Compute Runtime.\nMy problem was solved by reversing to an older version of this.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-03-25T01:39:46.117Z",
                "Answer_score":2,
                "Answer_body":"Hi @MichielVANACKER-8830, thank you for the report.\nThis issue is indeed caused by the new mounting solution in the new runtime. While being way faster and more performant it turned out there is a missing support for a rename operation on the mounted drive. Tensorflow saves model checkpoint to a temp file and then attempts to rename it and fails. Error message is very misleading and was in part a reason why it took us so long to root cause it.\n\nWe are disabling new mounting solution on our side and will reenable it once we validate support. Thank you for your patience and do not hesitate to reach out if you see any future data access issues.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"In multi step pipeline execution, how to maintain the data type of the columns when pass the dataset to next step",
        "Question_creation_time":1645805304397,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/751127\/in-multi-step-pipeline-execution-how-to-maintain-t.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"i am building a pipeline with multiple steps.\n\nStep 1 - Read the data from tabular dataset(with proper data types) , apply transformation and create an output dataset which will be passed as input to the step 2. However when i opened this dataset from the pipeline run log, the datatype all become string instead of maintaining the original data types of the input tabular data set\n\n\nStep 2 - use the output dataset of step 1 as input and apply some more transformations. However i have some logic based on data types which doesn't work because intermediate data set does not maintain the same data structure\n\nis there anyway we can maintain the original data types\/schema structure in the intermediate datasets?\n\nHere is some snippets on my code :\n\nfeature_work = (\nOutputFileDatasetConfig(\nname=\"data_enhanced_add_global_variables\",\ndestination=(def_blob_store, \"data\/processed\/output\/1\"),\n)\n.read_delimited_files()\n.as_upload(overwrite=True)\n\n\n\n\nfeature_engineering_step_1 = PythonScriptStep(name = \"1_feature_engineering\",\n#source_directory = experiment_folder,\nscript_name = \"1_feature_engineering.py\",\narguments = ['--input-data', data_aggregate_DS.as_named_input('raw_data'),\n'--prepped-data', feature_work],\n#outputs=[prepped_data_folder],\noutputs=[feature_work],\ncompute_target = compute_name,\nrunconfig = pipeline_run_config,\nallow_reuse = True)\n# Step 2\nfeature_engineering_step_2 = PythonScriptStep(name = \"2_feature_engineering\",\n#source_directory = experiment_folder,\nscript_name = \"2_feature_engineering.py\",\narguments = ['--input-data', feature_work.as_input(name='raw_data'),\n'--prepped-data', feature_work1],\noutputs=[feature_work1],\ncompute_target = compute_name,\nrunconfig = pipeline_run_config,\nallow_reuse = True)",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-28T12:43:31.087Z",
                "Answer_score":0,
                "Answer_body":"@VinothKumarK-8698 Thanks for the question. Can you please share the sample notebook that you are trying.\nHere is the notebook and doc that can help.\nOutputFileDatasetConfig as Tutorial: ML pipelines for batch scoring - Azure Machine Learning | Microsoft Docs as a means to pass data between pipeline steps.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML - Customizing a curated environment after cloning it doesn't seem to work",
        "Question_creation_time":1647484027330,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/775490\/azure-ml-customizing-a-curated-environment-after-c.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hello,\n\nI am building an ML pipeline which runs data preparation and training scripts relying both on Scikit-learn and Tensorflow libraries.\n\nSince Azure ML curated environments only include one library or the other, I followed instructions regarding how to customize a curated environment (https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-environments) to add additional libraries.\n\nI am adding the 'tensorflow' package to an existing curated environment as follows:\n\n USE_CURATED_ENV = True\n # Use and customize a curated environment provided by Azure\n if USE_CURATED_ENV :\n     curated_environment = Environment.get(workspace=ws, name=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\")\n        \n     # Clone the curated environment in order to add customized libraries\n     curated_clone = curated_environment.clone(\"customize_curated\")\n        \n     # Add necessary libraries to the existing curated environment\n     conda_dep = CondaDependencies()\n     conda_dep.add_conda_package(\"tensorflow\")\n     curated_clone.python.conda_dependencies=conda_dep\n    \n     # Associate the environment with the run configuration\n     aml_run_config.environment = curated_clone\n # Use a customized environment with specified packages only\n else:\n     aml_run_config.environment.python.user_managed_dependencies = False\n        \n     # Add some packages relied on by data preparation step\n     aml_run_config.environment.python.conda_dependencies = CondaDependencies.create(\n         conda_packages=['pandas','scikit-learn','tensorflow'], \n         pip_packages=['azureml-sdk', 'azureml-dataset-runtime[fuse,pandas]'], \n         pin_sdk_version=False)\n\n\n\nHowever, when I run the pipeline, it fails on \"import tensorflow\", saying that such package doesn't exist.\nI tried replacing conda_dep.add_conda_package(\"tensorflow\") by conda_dep.add_pip_package(\"tensorflow\"), but same error.\n\nThe alternative (when USE_CURATED_ENV = False) seems to work.\nI don't understand why it doesn't work when cloning an existing curated environment.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-17T11:10:34.533Z",
                "Answer_score":0,
                "Answer_body":"@ThierryL-3166 I think you should be using the following for conda tensorflow package:\n\nadd_tensorflow_conda_package(core_type='cpu', version=None)\n\nSimilarly, for pip tensorflow package:\n\nadd_tensorflow_pip_package(core_type='cpu', version=None)\n\nOnce you add these, you can list the packages and check if it is part of the conda dependencies.\n\n\n\n if curated_clone.python.conda_dependencies is not None:\n     print(\"packages\", curated_clone.python.conda_dependencies.serialize_to_string())\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-03-18T06:35:02.53Z",
                "Answer_score":0,
                "Answer_body":"Actually this didn't solve the problem.\nI can see 'tensorflow' is added to the conda dependencies, but it doesn't seem to be linked to my cloned environment.\nI registered the cloned environment to my workspace in order to see the resulting Dockerfile. It does't include tensorflow.\n\n curated_environment = Environment.get(workspace=ws, name=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\")\n curated_clone = curated_environment.clone(\"customize_curated\")\n conda_dep = CondaDependencies()\n conda_dep.add_tensorflow_conda_package(core_type='cpu', version='2.7')\n curated_clone.python.conda_dependencies=conda_dep\n curated_clone.register(workspace=ws)\n    \n if curated_clone.python.conda_dependencies is not None:\n     print(\"packages\", curated_clone.python.conda_dependencies.serialize_to_string())\n\n\n\nThe output of the 'print' is as follows:\n\n Running\n packages # Conda environment specification. The dependencies defined in this file will\n # be automatically provisioned for runs with userManagedDependencies=False.\n    \n # Details about the Conda environment file format:\n # https:\/\/conda.io\/docs\/user-guide\/tasks\/manage-environments.html#create-env-file-manually\n    \n name: project_environment\n dependencies:\n   # The python interpreter version.\n   # Currently Azure ML only supports 3.5.2 and later.\n - python=3.6.2\n    \n - pip:\n     # Required packages for AzureML execution, history, and data preparation.\n   - azureml-defaults\n    \n - tensorflow=2.7\n channels:\n - anaconda\n - conda-forge\n\n\n\nAnd the Dockerfile is:\n\n FROM mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04:20220314.v1\n    \n ENV AZUREML_CONDA_ENVIRONMENT_PATH \/azureml-envs\/sklearn-0.24.1\n    \n # Create conda environment\n RUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\\n     python=3.7 pip=20.2.4\n    \n # Prepend path to AzureML conda environment\n ENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/bin:$PATH\n    \n # Install pip dependencies\n RUN pip install 'matplotlib>=3.3,<3.4' \\\n                 'psutil>=5.8,<5.9' \\\n                 'tqdm>=4.59,<4.60' \\\n                 'pandas>=1.1,<1.2' \\\n                 'scipy>=1.5,<1.6' \\\n                 'numpy>=1.10,<1.20' \\\n                 'ipykernel~=6.0' \\\n                 'azureml-core==1.39.0' \\\n                 'azureml-defaults==1.39.0' \\\n                 'azureml-mlflow==1.39.0.post1' \\\n                 'azureml-telemetry==1.39.0' \\\n                 'scikit-learn==0.24.1'\n    \n # This is needed for mpi to locate libpython\n ENV LD_LIBRARY_PATH $AZUREML_CONDA_ENVIRONMENT_PATH\/lib:$LD_LIBRARY_PATH",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unable to connect SQL server to Azure ML pipeline?",
        "Question_creation_time":1647500219340,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/775844\/unable-to-connect-sql-server-to-azure-ml-pipeline.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_follower_count":18,
        "Question_score":0,
        "Question_body":"Hi,\nI am trying to connect sql server using pyodbc and to extract some procedure for Azure ML pipeline. Since I am not able to install pyodbc library in Azure ML, pipeline connection is not happening. Kindly let me know is there any alternative method to connect sql server and execute the procedure. Code is as bellow\n\nconn = pyodbc.connect(<Driver name and server credentials>)\ncursor = conn.cursor()\ncursor.execute(\"EXEC <The procedure name>\")",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-21T07:28:13.357Z",
                "Answer_score":0,
                "Answer_body":"@MOHAMMEDABDULLAT-7231 Thanks for the details. That's not the suggested way, please follow the Import Data doc to bring the Azure Sql database into pipeline.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/component-reference\/import-data\n\nAre you using the on-premise SQL server?. If yes we have forwarded to the product team to support in the near future. For unsupported storage solutions, and to save data egress cost during ML experiments, move your data to a supported Azure storage solution.\nHere is the document for supported storage types.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unable to sign into Azure Machine Learning Studio (classic), page constantly refreshes.",
        "Question_creation_time":1647878967167,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/780770\/unable-to-sign-into-azure-machine-learning-studio.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi,\n\nI am trying to sign into my Free Workspace within the Microsoft Azure Machine Learning Studio (classic).\n\nI am trying to access the RICT2 Prediction and Classification Experiment: https:\/\/gallery.azure.ai\/Experiment\/RICT-Prediction-and-Classification-GB-Single-Year-v4-0\n\nThe page refreshes inexplicably on a loop several times, before displaying a sign-in error.\n\nWould anyone be able to assist?\n\nThank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-22T09:34:53.447Z",
                "Answer_score":0,
                "Answer_body":"Hi Yutong,\n\nI've tried several times, including in an incognito window and it just loops on a refresh. I see the 'Microsoft Azure is going to retire in August' message for a split second, before the page refreshes.\n\nI'm working from Europe, however as per the RICT guidance working in the North American workspace.\n\nThank you.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-03-22T10:00:47.04Z",
                "Answer_score":0,
                "Answer_body":"Hi Yutong,\n\nI've managed to fix it (rather my in-house Frontstack did!). Something to do with the recent chrome update.\n\nThanks for your help.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure job requires interactive authentication every time",
        "Question_creation_time":1647457870313,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/775236\/azure-job-requires-interactive-authentication-ever.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I'm running a neural network on azure and it's working except it requires me to sign in with a device code for every job that runs. This is an issue for when I want to run long studies with multiple jobs and can't authenticate every job.\n\nI've tried to use the azure CLI authentication with the following code:\n\n cli_auth = AzureCliAuthentication()\n ws = Workspace(subscription_id=\"id\",\n                resource_group=\"rsgp\",\n                workspace_name=\"ws\", auth=cli_auth)\n\n\n\nWhen I do that, I recieve the error: \"Could not retrieve user token. Please run 'az login'\"\nThis happens when I login using az login before a run as well.\n\nI've also tried using the default credential before calling the workspace instead of using CLI, using this code:\n\n credential = DefaultAzureCredential()\n    \n    \n client = ResourceManagementClient(\n     credential=credential,\n     subscription_id=\"id\"\n )\n\n\n\nThis is functional, but I still need to log in manually for every job.\n\nAny help would be appreciated! Thanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-17T07:29:42.533Z",
                "Answer_score":0,
                "Answer_body":"@SydneyD-4380 I think you should be using service principal authentication for automated processes. Detailed steps to create a service principal are documented in this notebook along with other available options.\n\nTo summarize, you set a service principal with the required access role and then use the same while defining your workspace.\n\n import os\n from azureml.core.authentication import ServicePrincipalAuthentication\n    \n svc_pr_password = os.environ.get(\"AZUREML_PASSWORD\")\n    \n svc_pr = ServicePrincipalAuthentication(\n     tenant_id=\"my-tenant-id\",\n     service_principal_id=\"my-application-id\",\n     service_principal_password=svc_pr_password)\n    \n    \n ws = Workspace(\n     subscription_id=\"my-subscription-id\",\n     resource_group=\"my-ml-rg\",\n     workspace_name=\"my-ml-workspace\",\n     auth=svc_pr\n     )\n    \n print(\"Found workspace {} at location {}\".format(ws.name, ws.location))\n\n\n\nService principal password can be set as environment variable if it is for local testing or can be retried using Azure keyvault or a secret variable in Azure DevOps.\nHope this helps!!\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Project in Data Labeling not working, getting only \"Loading project details\"",
        "Question_creation_time":1647676305203,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/778679\/project-in-data-labeling-not-working-getting-only.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Project in Azure Machine Learning Studio in Data Labeling was working, we did label it every day. One day we just could not open it, it showed only Loading project details.. for hours.\nSAS token is working, it also work for our admin account, but not for Labellers.\nDo you have any idea?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-21T16:36:47.9Z",
                "Answer_score":0,
                "Answer_body":"@ika-8686 Thanks for the question. Please share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"machine learning algorithms questions",
        "Question_creation_time":1647856847267,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/780362\/machine-learning-algorithms-questions.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":1,
        "Question_body":"Hi :\n\nI am planing to use k-means to form algorithm to do project. However, I am aware that there are certain shortcomings to find the optimal groups using k-means.\n\nCould you please tell the limitation and provide me with a detailed example?\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-21T21:40:47.903Z",
                "Answer_score":0,
                "Answer_body":"Hello @hideonbush again,\n\nGenerally to think about k-means, please refer to below cons and pros. If you can provide more details and how you want to develop your project, I can share more:\n\nPros:\n\nK-means is very simple, highly flexible, and efficient.\n\n\nEasy to adjust and interpret the clustering results. Easy to explain the results in contrast to Neural Networks.\n\n\nThe efficiency of k-means implies that the algorithm is good at segmenting a dataset.\n\n\nAn instance can change cluster (move to another cluster) when the centroids are recomputed\n\nCons\n\nIt does not allow to develop the most optimal set of clusters and the number of clusters must be decided before the analysis. How many clusters to include is left at the discretion of the researcher. This involves a combination of common sense, domain knowledge, and statistical tools. Too many clusters tell you nothing because of the groups becoming very small and there are too many of them.\n\n\nWhen doing the analysis, the k-means algorithm will randomly select several different places from which to develop clusters. This can be good or bad depending on where the algorithm chooses to begin at. From there, the center of the clusters is recalculated until an adequate \"center'' is found for the number of clusters requested.\n\n\nThe order of the data input has an impact on the final results.\n\nHope this helps!\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure TabularDataset wrongly loads Parquet?",
        "Question_creation_time":1647121761043,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/769866\/azure-dataflow-wrongly-loads-parquet.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":2,
        "Question_body":"Below I give a concrete example where azureml Python api fails to correctly read Parquet files.\nMore precisely, the data gets displaced. It may clarify this issue where data could not be publicly shared posted by @KengoWada-6837.\n\nSetup: Python 3.8 + azureml-core=1.36.0 + azureml-dataprep=2.26.0 + pyarrow=7.0.0\n\nThe data is attached182488-error.log\n\nThe code demonstrating the issue is given below.\nIt uses an input data to create a table of strings along with some None values, stores in Parquet format, and reads either directly or through TabularDataset.\n\n from azureml.core import Workspace, Dataset\n import tempfile\n import pandas as pd\n import hashlib\n    \n # prepare data: list of hashs with some None values\n df = pd.read_csv(\"error.log\")\n mask = df.isna().any(1)\n df.id = df.id.map(lambda s:hashlib.sha512(str(s).encode()).hexdigest() if s else None)\n df.loc[mask,'id'] = None\n # configure Azure storage\n ws = Workspace.from_config()\n dstore = ws.datastores.get('my_datastore')\n dstore_path = 'my_path'\n target = (dstore,dstore_path)\n # write to Azure storage\n with tempfile.TemporaryDirectory() as tmpdir:\n     df.to_parquet(f'{tmpdir}\/df.parquet')\n     ds=Dataset.File.upload_directory(tmpdir,target,overwrite=True)\n    \n # read by two ways: download and open in pandas or use the Azure connector\n with tempfile.TemporaryDirectory() as tmpdir:\n     ds=Dataset.File.from_files(target)\n     ds.download(tmpdir)\n     df1 = pd.read_parquet(tmpdir)\n     ds = Dataset.Tabular.from_parquet_files(target)\n     df2 = ds.to_pandas_dataframe()\n    \n # comparison fails, the data seems displaced :-(\n pd.testing.assert_frame_equal(df1,df2)\n\n\n\n\n\n\n\nFWD: @ramr-msft",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-14T10:59:31.277Z",
                "Answer_score":0,
                "Answer_body":"@MaciejSkorski-9112 Thanks for the question. Please raise an issue in the following link to check by product team.\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Local compute not found error when running a hyperparameter search",
        "Question_creation_time":1647273614647,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/771547\/local-compute-not-found-error-when-running-a-hyper.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I am new to Azure and am trying to run a hyperparameter search on my neural network. I can run my code fine when I'm submitting a single job to examine a parameter, but when I run a hyperparameter search with the same configurations I get the following error:\n\n\"ComputeTargetNotFound: Compute Target with name local not found in provided workspace\"\n\nAny help would be appreciated!\n\n  from azureml.core import Workspace\n     from azureml.core import Experiment \n     from azureml.core import Environment\n     from azureml.core import ScriptRunConfig\n     from azureml.core.environment import CondaDependencies\n     from azureml.train.hyperdrive import HyperDriveConfig\n     from azureml.train.hyperdrive import choice\n     from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, uniform, PrimaryMetricGoal\n     from azureml.core.compute import ComputeTarget\n        \n        \n     ws = Workspace.from_config()\n     env = Environment.get(workspace=ws, name=\"AzureML-tensorflow-2.5-ubuntu20.04-py38-cuda11-gpu\")\n     curated_clone1 = env.clone(\"customize_curated\")\n     conda_dep = CondaDependencies().add_conda_package(\"scikit-learn\")\n     curated_clone1.python.conda_dependencies=conda_dep\n        \n        \n     curated_clone1.register(ws)\n        \n     param_sampling = RandomParameterSampling( {\n             'learning_rate': choice(0.001, 0.0001, 0.00001),\n                \n         }\n     )\n        \n     early_termination_policy = BanditPolicy(slack_factor=0.15, evaluation_interval=1, delay_evaluation=10)\n        \n     src = ScriptRunConfig(source_directory='.\/', script='loadv1.py',  environment=curated_clone1)\n        \n     hd_config = HyperDriveConfig(run_config=src,\n                                  hyperparameter_sampling=param_sampling,\n                                  policy=early_termination_policy,\n                                  primary_metric_name=\"loss\",\n                                  primary_metric_goal=PrimaryMetricGoal.MINIMIZE,\n                                  max_total_runs=100,\n                                  max_concurrent_runs=4)\n        \n        \n     experiment = Experiment(workspace=ws, name='day3-experiment-data')\n     #run = experiment.submit(src)\n     hyperdrive_run = experiment.submit(hd_config)",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-15T07:29:21.147Z",
                "Answer_score":0,
                "Answer_body":"@SydneyD-4380 The experiment setup mentioned seems similar to one of the threads I recently commented on.\nThe error in that case was with the module sklearn, not sure if the suggested steps worked for the user to fix the error with the module.\n\nIn this case and the other thread the compute target is still not defined. The compute target needs to be defined in your ScriptRunConfig() for example,\n\n\n\n from azureml.core.compute import ComputeTarget, AmlCompute\n from azureml.core.compute_target import ComputeTargetException\n    \n # choose a name for your cluster\n cluster_name = \"hd-cluster\"\n    \n try:\n     compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n     print('Found existing compute target.')\n except ComputeTargetException:\n     print('Creating a new compute target...')\n     compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', \n                                                            max_nodes=4)\n    \n     # create the cluster\n     compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n    \n     compute_target.wait_for_completion(show_output=True)\n    \n # use get_status() to get a detailed status for the current cluster. \n    print(compute_target.get_status().serialize())\n    \n    src = ScriptRunConfig(source_directory='.\/', script='loadv1.py',compute_target=compute_target, environment=curated_clone1)\n\n\n\n\nThe default compute target is local on the ScriptRunConfig() and since it is not created in your workspace this error is seen since you are submiting this experiment to the workspace.\n\nThe compute target where training will happen. This can either be a ComputeTarget object, the name of an existing ComputeTarget, or the string \"local\". If no compute target is specified, your local machine will be used.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Replacement for Azure ML Classic Excel Add In",
        "Question_creation_time":1647680517643,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/778717\/replacement-for-azure-ml-classic-excel-add-in.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"As far as I can tell there is no way to use the Excel add in for Azure ML using the new Azure ML service, it only works for the Classic. Is there any plan to provide a replacement add in that brings this functionality to the new Azure ML before Classic stops being supported in 2024?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-21T10:14:07.663Z",
                "Answer_score":0,
                "Answer_body":"@TimCahill-0615 Thanks for the question. Currently it's on roadmap to support in the near future. Excel add in feature similar to studio classic, it will be built on top on v2 online endpoints.\nCurrently, managed endpoints are not integrated with Designer, we need to first provide capability to do a no code designer deployment on v2 online endpoints and integrating excel add in for v2 endpoints.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"ParallelRunStep doesn\u00b4t support multiple input datasets",
        "Question_creation_time":1647759270327,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/779233\/parallelrunstep-doesnt-support-multiple-input-data.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"Currently we are using the parallelrunstep in AML, Is there any workaround\/other approach to support distribute datasets in the parallel run step.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-21T05:31:00.423Z",
                "Answer_score":0,
                "Answer_body":"@AI-6562 Thanks for the question. An Azure ML dataset is just metadata pointing to a path or collection of paths in an Azure storage account. You should first \"merge\" those datasets into a collection of adjacent folders (e.g. root\/dataset1\/, root\/dataset2\/, ...) and then run PRS against root\/**.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Quertion about the Azure Designer save model",
        "Question_creation_time":1647239817743,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/770634\/quertion-about-the-azure-designer-save-model.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello guys. I have a question about how to save the model as a file after I trained model(like model.pkl)??Thanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-15T02:45:26.013Z",
                "Answer_score":0,
                "Answer_body":"@AngelaZhang-1098 Thanks for the question. The \u201cscore.py\u201d exposed in trained_model_outputs is for customized deployment, only have model init and scoring logic, user can add their own pre-process and post-process code on top of that.\nThe scoring logic that having pre-process logic is available through Designer deployed web service, which can be on both AKS and ACI. You can follow this doc: Tutorial: Deploy ML models with the designer - Azure Machine Learning | Microsoft Docs.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-model-designer#download-the-entry-script-file-and-conda-dependencies-file",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to make use of Labelled Images in AzureML Designer?",
        "Question_creation_time":1628873927937,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/513343\/how-to-make-use-of-labelled-images-in-azureml-desi.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hello! I have been labeling images in AzureML Data Labeling. I wish to use this labelled set in Designer, to prototype some model ideas. However, I cannot get this to work. Any output (Dataset, COCO or csv) seems not to be compatible with \"Convert to Image Directory\".\n\nMy question is quite similar to one asked over a year ago - https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/32203\/how-to-use-labeled-image-datasets-to-perform-an-im.html - the answer suggests a result was imminent. Has there been any update?\n\nIf there is not one individual module capable of parsing this information, is there a way to use multiple modules to import the data?\n\nThanks!\n\n\n\n\nEDIT: The problem is also discussed here:\nhttps:\/\/docs.microsoft.com\/en-us\/answers\/questions\/194940\/how-to-use-azuremldataset.html\nIs there a cleaner solution yet? Or is downloading it, converting to pandas, then reuploading the best thing to do?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-02T15:30:10.037Z",
                "Answer_score":1,
                "Answer_body":"Hello @andrewblance-4822\n\nSorry I didn't hear anything from product team, what I can do now is I will continue following up with them to see any new ways for this and also I can help you enable a support ticket to escalate this issue for more awareness. Please let me know if you do not have a support plan, I can help you to enable a one time free ticket regarding to this issue. Thanks.\n\nRegards,\nYutong",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML workspace blob structure \/ Can I safely delete these blobs?",
        "Question_creation_time":1647500925610,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/775834\/azure-ml-workspace-blob-structure-can-i-safely-del.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello,\n\nI am trying to figure out the folder structure of Azure ML workspace in my storage account.\nI want to be able to delete old pipeline runs and experiments that have piled up in my workspace directly from Azure Storage Explorer without breaking the system.\nMy datastores and folder structure are as follows:\n\nDatastore: workspaceartifactstore\nBlob container: azureml\nFolder structure:\n\u251c\u2500 ComputeRecord\n\u251c\u2500 Dataset\n\u251c\u2500 ExperimentRun\n\u251c\u2500 LocalUpload\n\nDatastore: workspaceblobstore (Default)\nBlob container: azureml-blobstore-(a series of numbers)\nFolder structure:\n\u251c\u2500 azureml\n\u2502 \u251c\u2500\u2500 (a series of numbers)-setup\n\u2502 \u2502 \u251c\u2500\u2500 _tracer.py\n\u2502 \u2502 \u251c\u2500\u2500 azureml_globals.py\n\u2502 \u2502 \u251c\u2500\u2500 context_managers.py\n\u2502 \u2502 \u251c\u2500\u2500 job_prep.py\n\u2502 \u2502 \u251c\u2500\u2500 log_history_status.py\n\u2502 \u2502 \u251c\u2500\u2500 request_utilities.py\n\u2502 \u2502 \u251c\u2500\u2500 run_token_provider.py\n\u2502 \u2502 \u251c\u2500\u2500 utility_context_managers.py\n\u2502 \u251c\u2500\u2500 (another series of numbers)-setup\n\u2502 \u2502 \u251c\u2500\u2500 sames files as above\n\nIt would help if I understood what does each of these containers actually store.\nI already tried to delete all blobs stored in 'workspaceblobstore', but it didn't remove any pipeline or experiment from ML Studio.\nI have a few datasets registered in my workspace, and I don't want to delete them (nor unregister them).\n\nCan I set a data retention policy on both containers in order to delete old blobs?\nCan I safely delete the blobs (folders) stored in 'workspaceartifactstore' too? Will they be recreated automatically when I run a new experiment?\nWhy are there two separate 'azureml' and 'azureml-blobstore-(a series of numbers)' containers? Is it possible to merge them?\n\nThanks.\n\nThank you.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-17T14:52:56.467Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. I've worked on a similar inquiry and the advise is to not delete data stored in default datastore to avoid weird errors. The option to easily delete experiment runs is on the roadmap. Here's a similar thread. Feel free to raise and track feature request on ideas portal.\n\nAccording to documentation, when you create a workspace, an Azure blob container and an Azure file share are automatically registered as datastores to the workspace. They're named workspaceblobstore and workspacefilestore, respectively. The workspaceblobstore is used to store workspace artifacts and your machine learning experiment logs. It's also set as the default datastore and can't be deleted from the workspace. The workspacefilestore is used to store notebooks and R scripts authorized via compute instance.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Form recognizer to report on missing information in (near) real-time",
        "Question_creation_time":1647481005860,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/775440\/form-recognizer-to-report-on-missing-information-i.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi community,\nI'm interested in what Azure Form Recogniser or another tool can do for us in terms of screening the correctness of uploaded applications. Think of applications for funding grants. I haven't built any models yet, just wondering how feasible the below is. A solution doesn't have to involve AI at all, but must be able to 'read' the uploaded documents.\n\n\n\n\nA client uploads a set of standard documents (usually scanned PDF's) using a file upload in our .net application.\nCan we:\n1) Use form recogniser to extract key value pairs, after training a custom model.\n2) Run a loop over these pairs to find missing information e.g. they forgot to add their date of birth, or didn't enter their income.\n3) Report back to the user the missing information so they can correct the document and reupload them?\nPreferably in real time? So they hit submit on the webpage, it extracts, analyses and provides a result in a few seconds?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-17T10:30:11.953Z",
                "Answer_score":0,
                "Answer_body":"@AndrewRobertson-7835 Yes, you can use Azure form recognizer to analyze a document that is passed to the API and use the result of the analyze operation to report any missing fields in the form back to the user. This is the most widely used use case by most of the customers.\n\nForm recognizer comes with a set of prebuilt APIs where it can extract common information from invoices, business cards, receipts etc. If you have a form that does not conform to the prebuilt API standards you need to create a custom model to extract the text in the form of a tags and their key:value pairs. The custom models require some basic training with some test forms and if all the forms that need extraction follow the same layout or guidelines the extraction results will be good.\n\nIn the case of custom forms the results are provided in almost real time where the form is submitted or POST request is sent to the API and an operation id is returned to retrieve the results using GET. Depending on your pricing tier of your resource if you intend to perform these actions synchronously you might have to limit the rate of requests sent to the API to avoid any TPS errors. If you are using async operations with a slight delay to fetch the results then you can design an application that can take large number of documents and provide results to the users within a short span of time.\n\nI hope the above information is helpful.\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Getting error on Local Machine Learning Execution",
        "Question_creation_time":1647417258117,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/774178\/getting-error-on-local-machine-learning-execution.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"On Local machine learning,\nDevelopment platform is not bad.\nBut prediction environment got error.\n\nI show a log.\n\nTraceback (most recent call last):\nFile \"\/home\/user\/.pyenv\/versions\/anaconda3-2021.11\/envs\/HH32_P2_AzureAutoML\/lib\/python3.6\/site-packages\/luigi\/worker.py\", line 191, in run\nnew_deps = self._run_get_new_deps()\nFile \"\/home\/user\/.pyenv\/versions\/anaconda3-2021.11\/envs\/HH32_P2_AzureAutoML\/lib\/python3.6\/site-packages\/luigi\/worker.py\", line 133, in _run_get_new_deps\ntask_gen = self.task.run()\nFile \"tasks\/run_load.py\", line 1115, in run\nlocal_run = experiment.submit(automl_config, show_output=True)\nFile \"\/home\/user\/.pyenv\/versions\/anaconda3-2021.11\/envs\/HH32_P2_AzureAutoML\/lib\/python3.6\/site-packages\/azureml\/core\/experiment.py\", line 220, in submit\nrun = submit_func(config, self.workspace, self.name, **kwargs)\nFile \"\/home\/user\/.pyenv\/versions\/anaconda3-2021.11\/envs\/HH32_P2_AzureAutoML\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py\", line 103, in _automl_static_submit\nshow_output)\nFile \"\/home\/user\/.pyenv\/versions\/anaconda3-2021.11\/envs\/HH32_P2_AzureAutoML\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py\", line 213, in _start_execution\nignored_dependencies=package_utilities._PACKAGES_TO_IGNORE_VERSIONS\nFile \"\/home\/user\/.pyenv\/versions\/anaconda3-2021.11\/envs\/HH32_P2_AzureAutoML\/lib\/python3.6\/site-packages\/azureml\/automl\/core\/package_utilities.py\", line 446, in _get_package_incompatibilities\nconda_list_packages = all_dependencies_conda_list()\nFile \"\/home\/user\/.pyenv\/versions\/anaconda3-2021.11\/envs\/HH32_P2_AzureAutoML\/lib\/python3.6\/site-packages\/azureml\/automl\/core\/package_utilities.py\", line 338, in all_dependencies_conda_list\nstdout=subprocess.PIPE, stderr=subprocess.PIPE)\nFile \"\/home\/user\/.pyenv\/versions\/anaconda3-2021.11\/envs\/HH32_P2_AzureAutoML\/lib\/python3.6\/subprocess.py\", line 403, in run\nwith Popen(popenargs, *kwargs) as process:\nFile \"\/home\/user\/.pyenv\/versions\/anaconda3-2021.11\/envs\/HH32_P2_AzureAutoML\/lib\/python3.6\/subprocess.py\", line 707, in init\nrestore_signals, start_new_session)\nFile \"\/home\/user\/.pyenv\/versions\/anaconda3-2021.11\/envs\/HH32_P2_AzureAutoML\/lib\/python3.6\/subprocess.py\", line 1333, in _execute_child\nraise child_exception_type(errno_num, err_msg)\nPermissionError: [Errno 13] Permission denied\n\nBut log contains very few information.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Scheduling Jupyter notebook run in AzureML",
        "Question_creation_time":1647243630153,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/770720\/scheduling-jupyter-notebook-run-in-azureml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\nI am trying to run my jupyter notebook in azure ml by scheduling. I noticed some methods to schedule by ml pipeline. But I need to run my jupyter notebook file (.pynb) by scheduling every midnight. Please help me regarding this.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-14T18:22:22.967Z",
                "Answer_score":0,
                "Answer_body":"Hi, as far as I know, there's no way to trigger your notebook to run based on a schedule. However, you can schedule your published pipeline to run at a particular frequency and time of day. Detailed information is provided in this document. Hope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-03-15T09:00:24.127Z",
                "Answer_score":0,
                "Answer_body":"Dear @GiftA-MSFT\nI tried to publish my notebook as pipeline. But I am unable to import some libraries (prophet library). Please find my python executable code made for pipeline bellow.\n\n\n\n\n\n.jpg\n\n\n\n\n\nError: 'ModuleNotFoundError: No module named 'prophet''",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Time series forecasting AutoML Automatic featurization groupby specific column values",
        "Question_creation_time":1647278425307,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/771703\/time-series-forecasting-automl-automatic-featuriza.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\nI'm training time-series forecasting models with Azure AutoML.\n\nAs far as I\u2019m concerned, featurization techniques such as Normalization and Scaling or Impute missing values, are applied by columns.\n\nGiven that I\u2019m dealing with time-series data, is there a way to apply these kinds of featurization using a group by some column values? Otherwise, I feel the transformations applied make no sense at all.\n\nFor instance, If I want to predict product demand from different stores, would be possible to impute missing values from one article given the median of that article (not the one of the column) modifying AutoML Automatic featurization? Or standardize the target values for each article separately?\n\nThanks in Advance.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-16T07:17:18.337Z",
                "Answer_score":0,
                "Answer_body":"@Marcrb-4306 Thanks for the question. \"featurization\": 'FeaturizationConfig' Indicates customized featurization step should be used. Learn how to customize featurization.\nHere is link to Currently Supported customization.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Designer- Language Detection",
        "Question_creation_time":1647103939673,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/769728\/azure-ml-designer-language-detection.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hello,\n\nWe have a clustering model in AzureML designer and we are using the \"Preprocess Text\" component to clean the messages.\nBut, the messages can be in different languages and in the dropdown of the Language in the \"Preprocess Text\" component there is only English and no other language. Is there a way to detect the language of a text in azureml designer?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-14T06:26:50.423Z",
                "Answer_score":0,
                "Answer_body":"@ValerieHAYECK-2072 Pre-process text component only supports English language. Currently, there is no ready to use module in azure ml designer to detect text from a dataset.\nAzure cognitive services does offer some services that can auto detect language and translate text to a different language. Are you looking to translate data of a particular dataset?\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Deep learning",
        "Question_creation_time":1647180028657,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/770128\/deep-learning.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Which algorithm is most suitable for face reorganization attendance system?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-14T08:08:38.477Z",
                "Answer_score":0,
                "Answer_body":"@ARCHANAMACHHOYA-1358 A great way to start learning about the various algorithms available with Azure ML is to lookup the cheat sheet document which summarizes which algorithm will help you.\n\nFor this use case I would recommend looking at Image classification ResNet & DenseNet modules in the designer studio. Thanks.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"The file limit in Azure ML studio",
        "Question_creation_time":1647197880180,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/770207\/the-file-limit-in-azure-ml-studio.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi, when I submitted my work in Azure ML studio, it showed an error like this.\n\n\n\n\n\nMy folder contains around 50000 files, and even if I uploaded my files onto the datasets, I still need to download them to my current workplace. Is there a way to directly use the file from datasets or increase the snapshot size? I really appreciate any help you can provide.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Multiple new errors when deploying to ACI webservice",
        "Question_creation_time":1647268740933,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/771372\/multiple-new-errors-when-deploying-to-aci-webservi.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":10,
        "Question_score":1,
        "Question_body":"I've deployed an ACI webservice a few months ago on Azure ML. The scoring script references an object in a container in Azure blob, and everything worked fine. I now want to increate the size of the deployment config, and tried redeploying. It failed, and I don't know what changed. I didn't touch the code or notebooks. It's instantly failing, 5 seconds into running Model.deploy..\n\nI first get a\n\n WebserviceException:\n Message: Service deployment polling reached non-successful terminal state, current service state: Unhealthy\n\n\n\nThen clicking on more info, I get: The specified blob does not exist. RequestId:f2302ade-901e-0014-667b-37d663000000 Time:2022-03-14T08:14:42.7864874Z\n\nThere's also this error in the logs: Reason: Container registry 0309abcc70a24ee8921ea4b9f73c3e96.azurecr.io not found. Should it not create a new container registry and a new Docker image if one does not exist? It did the many times I deployed a service before. Why is it still referencing an old container? It should have created a new one...\n\nThe blob definitely exists and it worked before. The error doesn't make any sense. It's not a code issue. I even tried removing every registered model, endpoint, and even regenerated access keys and recreated the containers and blobs; same error. I also removed the old container registry. Also nothing.\n\nIt doesn't even work on a LocalWebService. Again, nothing's changed in the scoring script or deployment notebook I had...\n\nEntire error:\n\n Tips: You can try get_logs(): https:\/\/aka.ms\/debugimage#dockerlog or local deployment: https:\/\/aka.ms\/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n FailedService deployment polling reached non-successful terminal state, current service state: Unhealthy\n Operation ID: 61feee21-ae87-4ab3-a973-eeaa8124011c\n More information can be found here: https:\/\/wstextanalytic6896936843.blob.core.windows.net\/azureml\/ImageLogs\/61feee21-ae87-4ab3-a973-eeaa8124011c\/build.log?sv=2019-07-07&sr=b&sig=405cun7a1PV5afij4KfU0fYvCxp18IHIzB%2BvA1c1wpI%3D&st=2022-03-14T09%3A49%3A48Z&se=2022-03-14T17%3A54%3A48Z&sp=r\n Error:\n {\n   \"code\": \"AciDeploymentFailed\",\n   \"statusCode\": 404,\n   \"message\": \"No definition exists for Environment with Name: textanalytics Version: Autosave_2022-03-14T09:29:27Z_5e5728c1 Reason: Container registry 0309abcc70a24ee8921ea4b9f73c3e96.azurecr.io not found. If private link is enabled in workspace, please verify ACR is part of private link and retry..\",\n   \"details\": []\n }\n    \n ---------------------------------------------------------------------------\n WebserviceException                       Traceback (most recent call last)\n \/tmp\/ipykernel_32412\/349779865.py in <module>\n       8 )\n       9 \n ---> 10 service.wait_for_deployment(show_output=True)\n      11 print(service.state)\n    \n \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages\/azureml\/core\/webservice\/webservice.py in wait_for_deployment(self, show_output, timeout_sec)\n     917                     logs_response = 'Current sub-operation type not known, more logs unavailable.'\n     918 \n --> 919                 raise WebserviceException('Service deployment polling reached non-successful terminal state, current '\n     920                                           'service state: {}\\n'\n     921                                           'Operation ID: {}\\n'\n    \n WebserviceException: WebserviceException:\n  Message: Service deployment polling reached non-successful terminal state, current service state: Unhealthy\n Operation ID: 61feee21-ae87-4ab3-a973-eeaa8124011c\n More information can be found here: https:\/\/wstextanalytic6896936843.blob.core.windows.net\/azureml\/ImageLogs\/61feee21-ae87-4ab3-a973-eeaa8124011c\/build.log?sv=2019-07-07&sr=b&sig=405cun7a1PV5afij4KfU0fYvCxp18IHIzB%2BvA1c1wpI%3D&st=2022-03-14T09%3A49%3A48Z&se=2022-03-14T17%3A54%3A48Z&sp=r\n Error:\n {\n   \"code\": \"AciDeploymentFailed\",\n   \"statusCode\": 404,\n   \"message\": \"No definition exists for Environment with Name: textanalytics Version: Autosave_2022-03-14T09:29:27Z_5e5728c1 Reason: Container registry 0309abcc70a24ee8921ea4b9f73c3e96.azurecr.io not found. If private link is enabled in workspace, please verify ACR is part of private link and retry..\",\n   \"details\": []\n }\n  InnerException None\n  ErrorResponse \n {\n     \"error\": {\n         \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Unhealthy\\nOperation ID: 61feee21-ae87-4ab3-a973-eeaa8124011c\\nMore information can be found here: https:\/\/wstextanalytic6896936843.blob.core.windows.net\/azureml\/ImageLogs\/61feee21-ae87-4ab3-a973-eeaa8124011c\/build.log?sv=2019-07-07&sr=b&sig=405cun7a1PV5afij4KfU0fYvCxp18IHIzB%2BvA1c1wpI%3D&st=2022-03-14T09%3A49%3A48Z&se=2022-03-14T17%3A54%3A48Z&sp=r\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 404,\\n  \\\"message\\\": \\\"No definition exists for Environment with Name: textanalytics Version: Autosave_2022-03-14T09:29:27Z_5e5728c1 Reason: Container registry 0309abcc70a24ee8921ea4b9f73c3e96.azurecr.io not found. If private link is enabled in workspace, please verify ACR is part of private link and retry..\\\",\\n  \\\"details\\\": []\\n}\"\n     }\n }\n\n\n\nEDIT: I removed everything. Recreated EVERYTHING. And now, somehow the entry script is wrong when I didn't touch it. Someone please help here so that I move on from this service already.\n\n\n\n {\n   \"code\": \"AciDeploymentFailed\",\n   \"statusCode\": 400,\n   \"message\": \"Aci Deployment failed with exception: Error in entry script, ImportError: cannot import name 'ParamSpec', please run print(service.get_logs()) to get details.\",\n   \"details\": [\n     {\n       \"code\": \"CrashLoopBackOff\",\n       \"message\": \"Error in entry script, ImportError: cannot import name 'ParamSpec', please run print(service.get_logs()) to get details.\"\n     }\n   ]\n }\n  InnerException None\n  ErrorResponse \n {\n     \"error\": {\n         \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Unhealthy\\nOperation ID: ffaab603-0358-4b87-b1c9-8e5ee3390bf7\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Error in entry script, ImportError: cannot import name 'ParamSpec', please run print(service.get_logs()) to get details.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Error in entry script, ImportError: cannot import name 'ParamSpec', please run print(service.get_logs()) to get details.\\\"\\n    }\\n  ]\\n}\"\n     }\n }\n\n\n\n\nEntire error log when testing on a LocalWebService:\n\n Container Logs:\n 2022-03-14T14:13:04,088795292+00:00 - rsyslog\/run \n 2022-03-14T14:13:04,096166698+00:00 - iot-server\/run \n 2022-03-14T14:13:04,096661705+00:00 - gunicorn\/run \n Dynamic Python package installation is disabled.\n Starting HTTP server\n 2022-03-14T14:13:04,096254199+00:00 - nginx\/run \n EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n 2022-03-14T14:13:04,184522169+00:00 - iot-server\/finish 1 0\n 2022-03-14T14:13:04,186354496+00:00 - Exit code 1 is normal. Not restarting iot-server.\n Starting gunicorn 20.1.0\n Listening at: http:\/\/127.0.0.1:31311 (14)\n Using worker: sync\n worker timeout is set to 300\n Booting worker with pid: 42\n 2022-03-14 14:13:04.894347: W tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: \/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib:\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib:\n 2022-03-14 14:13:04.894395: I tensorflow\/stream_executor\/cuda\/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n SPARK_HOME not set. Skipping PySpark Initialization.\n Exception in worker process\n Traceback (most recent call last):\n   File \"\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/gunicorn\/arbiter.py\", line 589, in spawn_worker\n     worker.init_process()\n   File \"\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py\", line 134, in init_process\n     self.load_wsgi()\n   File \"\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py\", line 146, in load_wsgi\n     self.wsgi = self.app.wsgi()\n   File \"\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/gunicorn\/app\/base.py\", line 67, in wsgi\n     self.callable = self.load()\n   File \"\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 58, in load\n     return self.load_wsgiapp()\n   File \"\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 48, in load_wsgiapp\n     return util.import_app(self.app_uri)\n   File \"\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/gunicorn\/util.py\", line 359, in import_app\n     mod = importlib.import_module(module)\n   File \"\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/importlib\/__init__.py\", line 126, in import_module\n     return _bootstrap._gcd_import(name[level:], package, level)\n   File \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\n   File \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\n   File \"<frozen importlib._bootstrap>\", line 950, in _find_and_load_unlocked\n   File \"<frozen importlib._bootstrap>\", line 655, in _load_unlocked\n   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n   File \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\n   File \"\/var\/azureml-server\/entry.py\", line 1, in <module>\n     import create_app\n   File \"\/var\/azureml-server\/create_app.py\", line 4, in <module>\n     from routes_common import main\n   File \"\/var\/azureml-server\/routes_common.py\", line 32, in <module>\n     from aml_blueprint import AMLBlueprint\n   File \"\/var\/azureml-server\/aml_blueprint.py\", line 28, in <module>\n     main_module_spec.loader.exec_module(main)\n   File \"\/var\/azureml-app\/arabic_sentiment\/score.py\", line 7, in <module>\n     from azureml.core.model import Model\n   File \"\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/azureml\/core\/__init__.py\", line 13, in <module>\n     from .workspace import Workspace\n   File \"\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/azureml\/core\/workspace.py\", line 22, in <module>\n     from azureml._project import _commands\n   File \"\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/azureml\/_project\/_commands.py\", line 29, in <module>\n     from azure.mgmt.resource import ResourceManagementClient\n   File \"\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/azure\/mgmt\/resource\/__init__.py\", line 9, in <module>\n     from .managedapplications import ApplicationClient\n   File \"\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/azure\/mgmt\/resource\/managedapplications\/__init__.py\", line 9, in <module>\n     from ._application_client import ApplicationClient\n   File \"\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/azure\/mgmt\/resource\/managedapplications\/_application_client.py\", line 18, in <module>\n     from .operations import ApplicationClientOperationsMixin, ApplicationDefinitionsOperations, ApplicationsOperations\n   File \"\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/azure\/mgmt\/resource\/managedapplications\/operations\/__init__.py\", line 9, in <module>\n     from ._application_client_operations import ApplicationClientOperationsMixin\n   File \"\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/azure\/mgmt\/resource\/managedapplications\/operations\/_application_client_operations.py\", line 17, in <module>\n     from azure.core.tracing.decorator import distributed_trace\n   File \"\/azureml-envs\/azureml_ae7237d9cfbf5d852bb84bf47fdf5c24\/lib\/python3.6\/site-packages\/azure\/core\/tracing\/decorator.py\", line 31, in <module>\n     from typing_extensions import ParamSpec\n ImportError: cannot import name 'ParamSpec'\n Worker exiting (pid: 42)\n Shutting down: Master\n Reason: Worker failed to boot.\n 2022-03-14T14:13:06,839815591+00:00 - gunicorn\/finish 3 0\n 2022-03-14T14:13:06,841371413+00:00 - Exit code 3 is not normal. Killing image.\n    \n Error: Container has crashed. Did your init method fail?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-15T06:24:24.273Z",
                "Answer_score":0,
                "Answer_body":"More error logs (can't add in comments):\n\n Error:\n {\n   \"code\": \"AciDeploymentFailed\",\n   \"statusCode\": 400,\n   \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n     1. Please check the logs for your container instance: aciservicesentimentar. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n     2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n     3. You can also try to run image f75691feb45c4b3c9a0d73442a23d99e.azurecr.io\/azureml\/azureml_5df2da553c194ecec033f24d7523db5f locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\",\n   \"details\": [\n     {\n       \"code\": \"CrashLoopBackOff\",\n       \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n     1. Please check the logs for your container instance: aciservicesentimentar. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n     2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n     3. You can also try to run image f75691feb45c4b3c9a0d73442a23d99e.azurecr.io\/azureml\/azureml_5df2da553c194ecec033f24d7523db5f locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\"\n     },\n     {\n       \"code\": \"AciDeploymentFailed\",\n       \"message\": \"Your container application crashed. Please follow the steps to debug:\n     1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.\n     2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.\n     3. You can also interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n     4. View the diagnostic events to check status of container, it may help you to debug the issue.\n \"RestartCount\": 3\n \"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n \"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2022-03-14T19:38:03.337Z\",\"exitCode\":111,\"finishTime\":\"2022-03-14T19:38:11.513Z\",\"detailStatus\":\"Error\"}\n \"Events\": null\n \"\n     }\n   ]\n }",
                "Answer_comment_count":7,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Why am I recieving \"ModuleNotFoundError: No module named 'Quandl'\" in the Microsoft Azure Machine Learning Studio?",
        "Question_creation_time":1647121274650,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/769829\/why-am-i-recieving-34modulenotfounderror-no-module.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"In the Microsoft Azure Machine Learning Studio I am trying to import quandl, but I keep running into this error: \"ModuleNotFoundError: No module named 'Quandl'\". For context, I am using an .ipynb file.\n\nI have tried:\n!pip install quandl\nimport quandl\n\nas well as:\n!pip3 install quandl\nimport quandl\n\nI have also tried spelling quandl with an uppercase q to no avail.\n\nThe pip installation command works just fine, outputting that the requirement is already satisfied.\n\nI have no trouble doing this in jupyter notebooks or google colab, so what is the issue?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-14T07:18:15.433Z",
                "Answer_score":1,
                "Answer_body":"@ExchangeGuru-9680 I believe you are using the notebooks to run the install and import. Which kernel are you using? I have Python 3.6 - AzureML kernel and it seems to work fine.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How is Azure ML custom Environment Autosave version generated",
        "Question_creation_time":1634123620240,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/588969\/how-is-azure-ml-custom-environment-autosave-versio.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_comment_count":2,
        "Question_follower_count":10,
        "Question_score":4,
        "Question_body":"Hi,\nThe training notebook points to the specified environment version but once the run is submitted, the run picks up the env with version=autosave... instead of the version I had specified which leads to failure of the run submitted.\nCould you help me understand how this autosave environment version gets created once the run is submitted.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-14T12:25:08.78Z",
                "Answer_score":0,
                "Answer_body":"@RajeshKumarS-7965 Thanks for the question. Can you please add more details about the code that you are trying.\nHere is the link to setup runconfig environment configuration we have to do is for configuring the Python runtime environment which is defined by a separate yaml file (conda_dependencies.yml).\nhttps:\/\/github.com\/microsoft\/MLOps\/blob\/master\/examples\/cli-train-deploy\/generate-runconfig.py",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-02-10T23:31:28.127Z",
                "Answer_score":0,
                "Answer_body":"Hi, I am having the same question. Those are from web UI ->Environments-> SELECT A SAVED ENVIRONMENT -> Version dropdown. See the screenshot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-03-01T19:41:39.92Z",
                "Answer_score":0,
                "Answer_body":"I am facing the same issue. @ramr-msft do you have any comments on this? @RajeshKumarS-7965 Did you figure out a solution?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-03-14T17:20:54.73Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nI have done some tests\nFor 3 different pip requirements files (A.txt, B.txt and C.txt) with different pip dependencies, I have constructed associated envA, envB, envC with the Environment class from AzureML.\n\nI have register and build envA from SDK then submitted a job\nI have register EnvB from SDK then submitted a job\nI have submitted a job with EnvC not registered and not built.\n\nKey Results :\nAutosave is created when you submit a run without having registered your environment\n\nFurthermore, on others Experiment from my work, I have noticed that having autosaved version while calling a specific one might be due to the fact that they are pointing to the same built image",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Dataset access- azure cloud, notebook, blobstore",
        "Question_creation_time":1647268826120,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/771337\/dataset-access-azure-cloud-notebook-blobstore.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"From my online azure Notebook, how can I access a Dataset that I uploaded to blobstore. I have uploaded 5000 images for training a CNN deep learning model and there seem to be no easy access from the notebook.\n\nI have my python script with a tensorflow datagenerator that draws images from a folder.\n\n\nI have uploaded all images to my datasets under blobstorage.\n\n\nI now want to specify the path to that dataset.\n\nSeems so simple, yet all online tutorials is about accessing cloud data from your local notebook.\nThis should not be that difficult!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-14T15:35:22.563Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. It seems you want to connect to Azure Blob Storage from your notebook. Here are some steps to guide you in the right direction:\n\nThis document gives an overview of how to connect to data in Azure ML. Essentially, you need to create a datastore, create datasets, then use datasets by mounting to compute target or consume directly in your pipeline. See also Identity-Based Data Access.\n\n\nThis document shows how to create, register, and access datastores. After creating datastores, create dataset to interact with your data.\n\n\nThis document shows how to train with datasets. Here's information on how to mount\/download datasets as well as how to get datasets in ml scripts.\n\n\nHere's an example notebook on how to train with datasets.\n\nHope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Module Not Found Error when launching parameter study",
        "Question_creation_time":1647126154127,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/769904\/module-not-found-error-when-launching-parameter-st.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hello,\n\nI am a new user to Azure ML, and I would like to use the service to perform a parameter study for a ML model. I was able to launch a single job to test one parameter (e.g. learning rate = 0.01), but I am having trouble launching multiple jobs to cover several parameters (e.g. learning rates = 0.1, 0.01, or 0.001).\n\nI generally followed the hyperparameter tuning guide (https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-tune-hyperparameters), but when I run the code below, the jobs fail with the error \"User program failed with ModuleNotFoundError: No module named 'sklearn'\". Can someone help me identify what I am doing incorrectly? I tried to add the conda dependency (as shown) to fix this error, but it still did not work.\n\nThank you!\n\n\n\n from azureml.core import Workspace\n from azureml.core import Experiment \n from azureml.core import Environment\n from azureml.core import ScriptRunConfig\n from azureml.core.environment import CondaDependencies\n from azureml.train.hyperdrive import HyperDriveConfig\n from azureml.train.hyperdrive import choice\n from azureml.train.hyperdrive import RandomParameterSampling, BanditPolicy, uniform, PrimaryMetricGoal\n from azureml.core.compute import ComputeTarget\n    \n    \n ws = Workspace.from_config()\n env = Environment.get(workspace=ws, name=\"AzureML-tensorflow-2.5-ubuntu20.04-py38-cuda11-gpu\")\n curated_clone1 = env.clone(\"customize_curated\")\n conda_dep = CondaDependencies().add_conda_package(\"scikit-learn\")\n curated_clone1.python.conda_dependencies=conda_dep\n    \n    \n curated_clone1.register(ws)\n myvm = ComputeTarget(workspace=ws, name='cpu3')\n param_sampling = RandomParameterSampling( {\n         'learning_rate': choice(0.001, 0.0001, 0.00001),\n            \n     }\n )\n    \n early_termination_policy = BanditPolicy(slack_factor=0.15, evaluation_interval=1, delay_evaluation=10)\n    \n src = ScriptRunConfig(source_directory='.\/', script='loadv1.py', compute_target = myvm, environment=curated_clone1)\n src.run_config.target = myvm\n hd_config = HyperDriveConfig(run_config=src,\n                              hyperparameter_sampling=param_sampling,\n                              policy=early_termination_policy,\n                              primary_metric_name=\"loss\",\n                              primary_metric_goal=PrimaryMetricGoal.MINIMIZE,\n                              max_total_runs=100,\n                              max_concurrent_runs=4)\n    \n    \n experiment = Experiment(workspace=ws, name='day2-experiment-data')\n #run = experiment.submit(src)\n hyperdrive_run = experiment.submit(hd_config)",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Load the most recent data from Date partitioned folder",
        "Question_creation_time":1646726960863,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/763313\/load-the-most-recent-data-from-date-partitioned-fo.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":16,
        "Question_score":0,
        "Question_body":"Hello,\n\nI have set up a pipeline with Azure Data Factory in order to move data from my on-premises Oracle DB to parquet files in an Azure blob container every 10 days.\nThe folder structure of my blob container is as follows:\n\nonpremises\/2022\/02\/18\/file1.parquet\nonpremises\/2022\/02\/18\/file2.parquet\nonpremises\/2022\/02\/18\/file3.parquet\n\n\nonpremises\/2022\/02\/28\/file1.parquet\nonpremises\/2022\/02\/28\/file2.parquet\nonpremises\/2022\/02\/28\/file3.parquet\n\n\nonpremises\/2022\/03\/08\/file1.parquet\nonpremises\/2022\/03\/08\/file2.parquet\nonpremises\/2022\/03\/08\/file3.parquet\n\n\n...\n\nNow I'm trying to set up a pipeline in Azure ML which will run every time new data is coming into this container.\nIn my script below, I start by getting a reference to my container before calling the function 'from_parquet_files' to read from Parquet files.\nProblem: the script reads all files from every folder and adds a data column to the dataset (I believe it is because of the parameter 'partition_format').\n\n from azureml.core import Workspace, Datastore\n    \n # Get a reference to the workspace\n ws = Workspace.from_config()\n    \n # Reference to the datastore 'onpremises' from which we will contruct our dataset\n data_store = Datastore(ws, \"onpremises\")\n    \n from azureml.core import Dataset\n # Create a dataset from the data stored in datastore 'onpremises' at the specified path\n specs_dataset = Dataset.Tabular.from_parquet_files(path=(data_store, ''), partition_format='\/{PartitionDate:yyyy\/MM\/dd}\/')\n    \n # Register the dataset to the workspace. Increments the version if dataset already exists.\n specs_dataset.register(workspace=ws, name=\"specs\", description=\"Specs data from on-premises\", create_new_version=True)\n\n\n\nWhat I would like to do is to read only the most recent set of files (in my case, files listed under 'onpremises\/2022\/03\/08\/').\nAs the pipeline will run automatically, it should detect what is the most recent data among the folder structure.\nIs there a simple way to achieve this programmatically?\n\nThanks in advance.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-09T08:13:14.767Z",
                "Answer_score":1,
                "Answer_body":"@ThierryL-3166 You could only pass the required files by getting the year, month and day from the timestamp or date output. If your pipeline runs on schedule, you could list all the paths for all the days since the last run and load the files. I think something like below should work.\n\n # create tabular dataset from multiple paths\n from datetime import date\n from datetime import timedelta\n    \n today = date.today()\n    \n yesterday = today - timedelta(1)\n        \n d1 = today.strftime(\"%Y\/%m\/%d\")\n d2=yesterday.strftime(\"%Y\/%m\/%d\") \n    \n    \n path1 = 'onpremises\/'+ d1 + '\/*.parquet'\n path2 = 'onpremises\/'+ d2 + '\/*.parquet'\n    \n data_paths = [(datastore, path1),(datastore, path2)]\n tabular_dataset = Dataset.Tabular.from_parquet_files(path=data_paths)\n\n\n\n\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"dataset.to_pandas_dataframe() throws a DatabaseConnectionException",
        "Question_creation_time":1646912554290,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/767054\/datasetto-pandas-dataframe-throws-a-databaseconnec.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hello,\n\nI try to access a Azure ML Dataset in python and get the following error message:\n\n Execution failed in operation 'to_pandas_dataframe' for Dataset(id='[data.id]', name='[data.name]', version=1, error_code=ScriptExecution.DatabaseConnection.Unexpected,error_message=ScriptExecutionException was caused by DatabaseConnectionException.\\n  DatabaseConnectionException was caused by UnexpectedException.\\n    'MSSQL' encountered unexpected exception of type 'AggregateException' with HResult 'x80131500' while opening connection to server ([REDACTED]), database ([REDACTED]).\\n      Failed due to inner exception of type: AggregateException\\n| session_id=[session-id]) ErrorCode: ScriptExecution.DatabaseConnection.Unexpected\n\n\n\nIt is a Tabular Dataset created from a Azure SQL database datasource.\nFor the access from the studio to the database a service principal is used.\nI can access all the resources mentioned above in the standard ui.\n\nThe \"sample usage\" in the \"consume\" tab of the dataset was used for accessing the dataset in python.\nRegarding environments i tried python 3.6 and 3.8 locally and in a compute instance of the ML studio.\nHowever the same error keeps coming.\n\nI also tried to use sync-keys as described in this question:\nhttps:\/\/docs.microsoft.com\/en-us\/answers\/questions\/644562\/datasetto-pandas-dataframe-throws-a-scriptexecutio.html\n\n\n\n\nBest Regards,\nGerhard",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-11T09:21:44.827Z",
                "Answer_score":1,
                "Answer_body":"A DevOps-Colleague could find the cause of the problem. The service principal didn't have the correct rights for my use case.\n\n@romungi-MSFT : I'll try your suggestion since I can create a snapshot of the table.\n\nThanks for your time and support!\n\nCheers,\nGerhard",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Register Trained Model in Azure Machine Learning",
        "Question_creation_time":1646841384953,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/765721\/register-trained-model-in-azure-machine-learning.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I'm training a Azure Machine learning model using script via python SDK. I'm able to see the environment creation and the model getting trained in std_log in output&logs folder. After the Model training I try to dump the model, but I don't see the model in any folder.\n\nIf possible I want to register the model directly into the Model section in Azure ML rather than dumping it in the pickle file.\n\nI'm following this documentation a reference for model training https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-sdk-train\n\nBelow is the output log snapshot for the model training run.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-10T19:40:33.727Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. It seems you'd like to register your trained model to your workspace. You can use run.register_model to register the model to your workspace. The above mentioned document also shows how to register model from a training run. Here's another example. Hope this helps!\n\n model = run.register_model(model_name='bidaf_onnx',\n                            tags={'area': 'qna'},\n                            model_path='outputs\/model.onnx')\n print(model.name, model.id, model.version, sep='\\t')",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Not able to run CD Pipeline to Deploy ML Model - Pipeline was successful months ago",
        "Question_creation_time":1646739646433,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/763631\/not-able-to-run-ci-pipeline-to-train-ml-model-pipe.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hey ya all. :)\n\nI have created a CI-Pipeline for Model Training and a Release Pipeline for deployment. I am using the Azure ML CLI Extension and a service principal User to get access to all Azure Ressources that are needed do run such a pipeline.\n\nThe CI Pipeline is running perfectly, no errors or any suspicious things to see...\nSince a few weeks the CD-Pipeline doesn't run successfully due to an error in the step \"Deploy to ML Service on ACI\".\n\nI thought this is caused by invalid permissions for my service principals but the SP has all rights on all resources in my Resource Group.\n\nSo i tried to do the Deployment by using the Python SDK. And there i am able to successfully deploy my model. ( I used the same artifact to deploy as for the CD Pipeline)\n\nWell, i have no idea what happened, because nothing changed since the Pipeline ran successfully in July 2021.\n\nDoes anyone of have an idea what could be the cause?\n\nThis is the log of the failed Task. That debug log happens every 2 seconds until the pipeline fails:\n\nThis is my Pipeline:",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"ERROR: The provided hyperparameter space cannot be interpreted",
        "Question_creation_time":1646489041427,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/760594\/error-the-provided-hyperparameter-space-cannot-be.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":4,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I'm training a KNN classifier from sklearn, and I want to use BayersianParameterSampling for hypertununing parameters. I have this code:\n\n run_config = ScriptRunConfig(\n     source_directory='.', script='train.py', arguments=['--input-data', input_ds.as_named_input('data')], \n     environment=_env, compute_target=cluster\n )\n    \n hyper_params = BayesianParameterSampling(parameter_space={\n     '--n_neighbors': choice(range(5, 11)),\n     '--weights': choice('uniform', 'distance'),\n     '--leaf_size': choice(range(30, 101)),\n     '--p': choice(1, 2)\n })\n    \n hd_config = HyperDriveConfig(\n     run_config=run_config, hyperparameter_sampling=hyper_params, policy=None, \n     primary_metric_name='AUC', primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n     max_total_runs=80, max_concurrent_runs=2)\n    \n experiment = Experiment(ws, 'churn-hyperdrive')\n hyperdrive_run = experiment.submit(hd_config)\n    \n hyperdrive_run.wait_for_completion(show_output=True)\n\n\n\nWhen I submit the experiment, I get an error saying there's something wrong with the parameter space I have. I'm passing the parameters as arguments to a simple script, train.py, which only parses the args, sets the values in the KNN classifier, logs a few metrics, and saves the model.\n\nWhat am I doing wrong here? I've went over everything multiple times, and I don't think there's a mistake. The error I'm getting:\n\n\n\n \"<START>[2022-03-05T13:56:17.215074][API][INFO]Experiment created<END>\\n\"\"<START>[2022-03-05T13:56:18.343781][GENERATOR][ERROR]Exception in creating bayesian optimization: ArgumentException:\\n\\tMessage: Got an invalid parameter space for [Random sampling]: [The provided hyperparameter space cannot be interpreted.]\\n\\tInnerException None\\n\\tErrorResponse \\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"Got an invalid parameter space for [Random sampling]: [The provided hyperparameter space cannot be interpreted.]\\\",\\n        \\\"inner_error\\\": {\\n            \\\"code\\\": \\\"BadArgument\\\",\\n            \\\"inner_error\\\": {\\n                \\\"code\\\": \\\"ArgumentInvalid\\\"\\n            }\\n        }\\n    }\\n}.<END>\\n\"\"<START>[2022-03-05T13:56:18.343632][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space<END>\\n\"",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-07T12:55:32.057Z",
                "Answer_score":1,
                "Answer_body":"Removing the weights parameter solves it. I'm not sure why, as the model I used does take a weights param.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-03-10T17:11:51.467Z",
                "Answer_score":0,
                "Answer_body":"@jjk1993 After checking with the product group they have suggested an odd workaround that might work for you. Could you please switch \"uniform\" and \"distance\" in the weights parameter and check if it works?\n\nEx:\n\n hyper_params = BayesianParameterSampling(parameter_space={\n      '--n_neighbors': choice(range(5, 11)),\n      '--weights': choice('distance', 'uniform'),\n      '--leaf_size': choice(range(30, 101)),\n      '--p': choice(1, 2)\n  })\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Response 502 error in Azure Machine Learning Studio Notebook",
        "Question_creation_time":1643768437050,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/718999\/response-502-error-in-azure-machine-learning-studi.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I copied over code from my training course into the Notebook in Azure Machine Learning Studio. After I run the code, I get the error - <Response [502]>. Please help",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-04T16:26:08.893Z",
                "Answer_score":1,
                "Answer_body":"@VATSALDANI-4609 Another customer with similar issue posted this solution on a different thread. You could try this and check if it works for you.\n\nThe problem come from lack of GlobalParameters in the next sentence.\ninput_json = json.dumps({\"Inputs\":{\"data\": x}, \"GlobalParameters\": 1.0})\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-03-10T08:37:26.92Z",
                "Answer_score":1,
                "Answer_body":"Hi,\nSolution #input_json = json.dumps({\"Inputs\":{\"data\": x}, \"GlobalParameters\": 1.0})\" worked for me!\n\/\/Harald",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to use custom environment defined in the custom environments tab in Azure Machine Learning Studio.",
        "Question_creation_time":1646779156963,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/764339\/how-to-use-custom-environment-defined-in-the-custo.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"In Azure Machine Learning Studio, in the Environments section's \"Custom environments\" tab, I defined a custom environment. I have done this once with a Conda yaml file, and once with a requirements.txt file, eg filling out this form as described here: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-environments-in-studio\n\nI can see that the environments have been created but I have no idea how to use them.\n\nI have tried using this code within an Azure ML Studio notebook, where the new environment I defined is called \"my_new_env\":\n\n from azureml.core import Workspace, Environment\n ws = Workspace.from_config()\n env = Environment.get(workspace=ws, name=\"my_new_env\")\n\n\n\nI also tried this within an Azure ML Studio notebook to see if I could define an environment without doing it in the environments menu.\n\n from azureml.core.environment import Environment\n my_new_env = Environment.from_conda_specification(name = \"myenv\", file_path = environment.yml)\n\n\n\nBoth execute without any warnings or errors, but I'm not sure they are running, or indeed what I have done.\n\nHaving run either of these two blocks of code, when I try to select a new environment in the Azure ML Studio notebook's drop down menu:\n\nThere is no evidence of my new environments.\n\nI'm new to Azure ML Studio. What I want to do is create a new Python virtual environment. Am I getting confused between virtual Python environments and some other more general type of environments? If I wanted to create my own stable Python virtual environment within Azure ML to use in notebooks that was not tied to a specific compute instance, how would I do it?\n\nThanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-09T10:54:29.947Z",
                "Answer_score":1,
                "Answer_body":"@ml-3263 In the first two cases the environments created from portal or the yaml file are used to train your model or score your model when it is deployed as a endpoint.\nThese are re-usable environments that can even be created on local machine or compute to develop your training script and can be used used on Azure compute for large scale training or deployment.\n\nThe different types of environments are curated, user-managed and system-managed. The first two environments you created fall under the user and system managed categories, whereas curated environments are offered by azure and are available by default in every workspace.\n\nThese environments are not tied to any of the compute instance and you can use them with any type of compute for training or inference.\n\nThe last type of environment that you have listed with the screen shot is actually a virtual environment that you have to setup on your compute instance to use it as your kernel on your notebook. This however is tied to your compute instance and if you need to use the same setup on a different compute then you need to set it up again on a different instance. I have explained the setup on one of the previous threads, which can be helpful if you need one.\n\nTo summarize, if you are looking to create environments to train your models and infer then you will have to use the curated, user\/system-managed environments in your experiments.\nIf you are looking to just use the notebooks then you can setup a custom kernel or virtual environment to run an experiment locally.\n\nA great way to start learning about Azure ML through notebooks is to clone this repo on your ml.azure.com notebooks and follow the steps or tutorials to create and run experiments.\n\nOnce the repo is cloned from sample tab it will be available under files tab to be run on available compute and kernel.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"What are valid Azure ML Workspace connection argument options?",
        "Question_creation_time":1646219078177,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/756279\/azure-ml-workspace-connection.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I want to build an Azure ML environment with two python packages I have in Azure Devops.\nFor this I need a workspace connection to Azure Devops. One package is published to an artifact feed and I can access it using the python SDK:\nws.set_connection(name=\"ConnectionName\", category = \"PythonFeed\", target = \"https:\/\/pkgs.dev.azure.com\/\", authType = \"PAT\", value = PAT_TOKEN)\n\nHowever, for the other I need to get the package from git. The documentation of the Python SDK and the underlying REST API don't give the options for the arguments, only that they need to be strings (see links).\n\nMy question: what are the options for the following arguments:\n\nauthType\n\n\ncategory\n\n\nvalueFormat\n\nAnd what do I need to set for target link, so that I can connect to the Azure DevOps repository with potentially different authentication?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-03T09:30:41.653Z",
                "Answer_score":0,
                "Answer_body":"@KyllianBroers-1395 Thanks for the question. Here's an example for DevOps feed: Use private Python packages - Azure Machine Learning | Microsoft Docs. An admin sets up the connection once when configuring workspace.",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Pipeline pyarrow dependency for installing transformers",
        "Question_creation_time":1646062523127,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/753625\/azure-ml-pipeline-pyarrow-dependency-for-installin-1.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I was trying to import transformers in AzureML designer pipeline, it says for importing transformers and datasets the version of pyarrow needs to >=3.0.0, but then after upgrading pyarrow's version to 3.0.0 and importing transformers pyarrow version is reset to original version of 0.16.0. attaching few error samples. please have a look.\n\nGot exception when invoking script: 'RuntimeError: Failed to import transformers.trainer because of the following error (look up to see its traceback):To use datasets, the module pyarrow>=3.0.0 is required, and the current version of pyarrow doesn't match this condition.If you are running this in a Google Colab, you should probably just restart the runtime to use the right version of pyarrow.' azureml-designer-core 0.0.68 requires pyarrow==0.16.0, but you'll have pyarrow 3.0.0 which is incompatible.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-01T01:14:11.423Z",
                "Answer_score":0,
                "Answer_body":"Hello @PoojithaG\n\nThanks for reaching out to us for this issue, I will forward this issue to product team for investigation. If you could provide related guidance to me so that we can address this quicker it would be nice.\n\nI see your issue related to this thread in GitHub as well: https:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1698\n\nI will let you know if any update.\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"After deploying an Azure ML model to a container instance, call to the model fails when using the code provided in the \"Consume\" section of the endpoint (Python and C#).",
        "Question_creation_time":1646656866430,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/762071\/after-deploying-an-azure-ml-model-to-a-container-i.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I have trained a model in Azure Auto-ML and deployed the model to a container instance.\n\nNow when I am trying to use the Python code provided in the Endpoint's \"Consume\" section I get the following error:\n\nThe request failed with status code: 502\nContent-Length: 55\nContent-Type: text\/html; charset=utf-8\nDate: Mon, 07 Mar 2022 12:32:07 GMT\nServer: nginx\/1.14.0 (Ubuntu)\nX-Ms-Request-Id: 768c2eb5-10f3-4e8a-9412-3fcfc0f6d648\nX-Ms-Run-Function-Failed: True\nConnection: close\n\n\n---------------------------------------------------------------------------\nJSONDecodeError Traceback (most recent call last)\n<ipython-input-1-6eeff158e915> in <module>\n48 # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n49 print(error.info())\n---> 50 print(json.loads(error.read().decode(\"utf8\", 'ignore')))\n\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/json\/init.py in loads(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\n352 parse_int is None and parse_float is None and\n353 parse_constant is None and object_pairs_hook is None and not kw):\n--> 354 return _default_decoder.decode(s)\n355 if cls is None:\n356 cls = JSONDecoder\n\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/json\/decoder.py in decode(self, s, _w)\n337\n338 \"\"\"\n--> 339 obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n340 end = _w(s, end).end()\n341 if end != len(s):\n\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/json\/decoder.py in raw_decode(self, s, idx)\n355 obj, end = self.scan_once(s, idx)\n356 except StopIteration as err:\n--> 357 raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n358 return obj, end\n\n\nJSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\n\n\n\nIf I use C# code provided in the Endpoint's \"Consume\" section I get the following error:\n\n\n\n\nThe request failed with status code: BadGateway\nConnection: keep-alive\nX-Ms-Request-Id: 5c3543cf-29ac-46a3-a9fb-dcb6a0041b08\nX-Ms-Run-Function-Failed: True\nDate: Mon, 07 Mar 2022 12:38:32 GMT\nServer: nginx\/1.14.0 (Ubuntu)\n\n\n'<=' not supported between instances of 'str' and 'int'\n\n\n\n\nCould you please help me with this issue? I am not sure what do to if Microsoft's provided code is erroring out, don't know what else to do.\n\n\n\n\nThe Python code I am using is:\n\n import urllib.request\n import json\n import os\n import ssl\n    \n def allowSelfSignedHttps(allowed):\n     # bypass the server certificate verification on client side\n     if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n         ssl._create_default_https_context = ssl._create_unverified_context\n    \n allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n    \n data = {\n     \"Inputs\": {\n         \"data\":\n         [\n             {\n                 \"SaleDate\": \"2022-02-08T00:00:00.000Z\",\n                 \"OfferingGroupId\": \"0\",\n                 \"week_of_year\": \"7\",\n                 \"month_of_year\": \"2\",\n                 \"day_of_week\": \"1\"\n             },\n         ]\n     },\n     \"GlobalParameters\": {\n         \"quantiles\": \"0.025,0.975\"\n     }\n }\n    \n body = str.encode(json.dumps(data))\n    \n url = 'http:\/\/4a0427c2-30d4-477e-85f5-dfdfdfdfdsfdff623f.uksouth.azurecontainer.io\/score'\n api_key = '' # Replace this with the API key for the web service\n headers = {'Content-Type':'application\/json', 'Authorization':('Bearer '+ api_key)}\n    \n req = urllib.request.Request(url, body, headers)\n    \n try:\n     response = urllib.request.urlopen(req)\n    \n     result = response.read()\n     print(result)\n except urllib.error.HTTPError as error:\n     print(\"The request failed with status code: \" + str(error.code))\n    \n     # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n     print(error.info())\n     print(json.loads(error.read().decode(\"utf8\", 'ignore')))\n\n\n\n\nThe C# code I am using is:\n\n using System;\n using System.Collections.Generic;\n using System.IO;\n using System.Net.Http;\n using System.Net.Http.Headers;\n using System.Text;\n using System.Threading.Tasks;\n using Newtonsoft.Json;\n    \n namespace MLModelAPICall\n {\n     class Program\n     {\n         static void Main(string[] args)\n         {\n             InvokeRequestResponseService().Wait();\n         }\n    \n         static async Task InvokeRequestResponseService()\n         {\n             var handler = new HttpClientHandler()\n             {\n                 ClientCertificateOptions = ClientCertificateOption.Manual,\n                 ServerCertificateCustomValidationCallback =\n                         (httpRequestMessage, cert, cetChain, policyErrors) => { return true; }\n             };\n             using (var client = new HttpClient(handler))\n             {\n                 \/\/ Request data goes here\n                 var scoreRequest = new\n                 {\n                     Inputs = new Dictionary<string, List<Dictionary<string, string>>>()\n                     {\n                         {\n                             \"data\",\n                             new List<Dictionary<string, string>>()\n                             {\n                                 new Dictionary<string, string>()\n                                 {\n                                     {\n                                         \"SaleDate\", \"2022-02-08T00:00:00.000Z\"\n                                     },\n                                     {\n                                         \"OfferingGroupId\", \"0\"\n                                     },\n                                     {\n                                         \"week_of_year\", \"7\"\n                                     },\n                                     {\n                                         \"month_of_year\", \"2\"\n                                     },\n                                     {\n                                         \"day_of_week\", \"1\"\n                                     }\n                                 }\n                             }\n                         }\n                     },\n                     GlobalParameters = new Dictionary<string, string>()\n                     {\n                         {\n                             \"quantiles\", \"0.025,0.975\"\n                         }\n                     }\n                 };\n    \n    \n                 const string apiKey = \"\"; \/\/ Replace this with the API key for the web service\n                 client.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(\"Bearer\", apiKey);\n                 client.BaseAddress = new Uri(\"http:\/\/4a0427c2-30d4-477e-85f5-xxxxxxxxxxxxx.uksouth.azurecontainer.io\/score\");\n    \n                 \/\/ WARNING: The 'await' statement below can result in a deadlock\n                 \/\/ if you are calling this code from the UI thread of an ASP.Net application.\n                 \/\/ One way to address this would be to call ConfigureAwait(false)\n                 \/\/ so that the execution does not attempt to resume on the original context.\n                 \/\/ For instance, replace code such as:\n                 \/\/      result = await DoSomeTask()\n                 \/\/ with the following:\n                 \/\/      result = await DoSomeTask().ConfigureAwait(false)\n    \n                 var requestString = JsonConvert.SerializeObject(scoreRequest);\n                 var content = new StringContent(requestString);\n    \n                 content.Headers.ContentType = new MediaTypeHeaderValue(\"application\/json\");\n    \n                 HttpResponseMessage response = await client.PostAsync(\"\", content);\n    \n                 if (response.IsSuccessStatusCode)\n                 {\n                     string result = await response.Content.ReadAsStringAsync();\n                     Console.WriteLine(\"Result: {0}\", result);\n                 }\n                 else\n                 {\n                     Console.WriteLine(string.Format(\"The request failed with status code: {0}\", response.StatusCode));\n    \n                     \/\/ Print the headers - they include the requert ID and the timestamp,\n                     \/\/ which are useful for debugging the failure\n                     Console.WriteLine(response.Headers.ToString());\n    \n                     string responseContent = await response.Content.ReadAsStringAsync();\n                     Console.WriteLine(responseContent);\n                     Console.ReadLine();\n                 }\n             }\n         }\n     }\n }",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-09T09:32:51.647Z",
                "Answer_score":1,
                "Answer_body":"After much more digging I found out that the \"Consume\" scripts provided with the endpoint are wrong (Python and C#) .\n\nWhen making a call to the endpoint the GlobalParameters expects an integer value, but the provided scripts have wrapped the values in double quotes hence making it a string:\n\n  },\n  \"GlobalParameters\": {\n      \"quantiles\": \"0.025,0.975\"\n  }\n\n\n\nIf you are using Python to consume the model, when making call to the endpoint your GlobalParameters should be define as this:\n\n  },\n  \"GlobalParameters\": {\n      \"quantiles\": [0.025,0.975]\n  }\n\n\n\nwrapped in square brackets\n\n[0.025,0.975]\n\nand not in double quotes \"\n\nhave also opened a ticket with microsoft so hopefully they will fix the code provided in the \"consume\" section of every endpoint*",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Reference trigger metadata in pipeline runs azureml",
        "Question_creation_time":1645183760857,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/741645\/reference-trigger-metadata-in-pipeline-runs-azurem.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I have defined a pipeline using the azure ml sdk and defined a Pipeline parameter to be parsed as a timestamp.\nNow, I want to create a schedule that takes the timestamp of the trigger and pass it as the aforementioned pipeline parameter.\nSo far, I do not see how to get this\n\nCode:\n\nfrom azureml.pipeline.core import Pipeline, PipelineParameter, Workspace\nfrom azureml.pipeline.steps import PythonScriptStep\n\ncutoff_time = PipelineParameter(name=\"cutoff_time\", default_value='2022-1-1')\n\nmy_step = PythonScriptStep(\nname=\"My Step\",\nsource_directory=\"dir\",\nscript_name=\"my_script.py\",\narguments=['--cutoff_time', cutoff_time],\nrunconfig=aml_run_config,\nallow_reuse=True\n)\n\nws = Workspace.from_config()\npipeline = Pipeline(workspace=ws, steps=[my_step])\npublished_pipeline = pipeline.publish('my_pipeline_name')\n\nSchedule\n\nrecurrence = ScheduleRecurrence(frequency='Day', interval=1, hours=[0])\nrecurring_schedule = Schedule.create_for_pipeline_endpoint(ws,\nname='My schedule',\ndescription='Description',\npipeline_id=pipeline_published.id,\nexperiment_name='My experiment',\nrecurrence=recurrence)\n\nHow do I tell AzureML to take the timestamp trigger as my Pipeline Param? In other words, how can I get the metadata of the trigger as a variable available to my pipeline run?\n\nThanks",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Microsoft Azure Machine Learning Studio - Error durind Deploy <Response [502]> Automated ML",
        "Question_creation_time":1646161278517,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/755239\/microsoft-azure-machine-learning-studio-error-duri.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-02T07:00:37.88Z",
                "Answer_score":0,
                "Answer_body":"@FernandoJosRibeiroJnior-4000 I think the following changes are required in the above code to get it working with the endpoint.\n\nChange the line where the input JSON is created.\n\nFrom:\n\n input_json = json.dumps({\"Inputs\":{\"data\": x}})\n\nTo:\n\n input_json = json.dumps({\"data\": x})\n\n\n\nAlso change, the following to ensure result is loaded correctly and formatted in the print statement.\n\nFrom:\n\n y = response.json()\n\n\n\nTo:\n\n y = json.loads(response.json())\n\n\n\n\n\nThis should print the result correctly, as seen below:\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Access file in a storage account residing in different tenant to ML Service in another tenant via IP based SAS restricted access",
        "Question_creation_time":1645593594070,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/747081\/access-file-in-a-storage-account-residing-in-diffe.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":16,
        "Question_score":0,
        "Question_body":"Hi,\n\nI have a storage account residing in tenant-A and machine learning service in tenant-B. When I try to read file from storage account in tenant-A via SAS (with IP restriction) in the jupyter notebook running on compute in ML service in tenant-B, it is not accessible and failing with 403 (Forbidden).\n\nBut when I try to access the file without IP restriction, I am able to read it in the notebook.\nCan you please help in understanding why it is happening and possible fix for the problem?\n\nPlease note, the public IP of ML compute is being used for whitelisting in SAS.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-23T13:50:27.507Z",
                "Answer_score":0,
                "Answer_body":"@HimanshuBajpai-3138 I think you need to whitelist the IP ranges that fall under BatchNodeManagement.<region> and AzureMachineLearning.<region> from the list of Azure IPs for your region under the respective categories. The list of azure IPs can be downloaded from here.\n\nDepending on your region try whitelisting these IPs instead of the public IP of your compute and check if it works. For more details about setting up inbound and outbound network configuration for Azure ML, please refer this page.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":7,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Synapse - 'No Azure Cognitive Service Linked Service are available'",
        "Question_creation_time":1644147139677,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/724155\/synapse-39no-azure-cognitive-service-linked-servic.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":19,
        "Question_score":0,
        "Question_body":"I am following this guide\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-cognitive-services-sentiment\n\nBut when I get to selecting 'Machine Learning - Predict with a Model', then I choose 'Sentiment Analysis'\n\nBut the first dropdown is greyed out for me and reads:\nAzure Cognitive Services linked service: No Azure Cognitive Service Linked Service are available\n\nI had one created, then created another. AKV and link service tested with specific key.\n\nAnyone know how I can get it to recognize the Cognitive Service Linked Server?\n\nThanks\n\n][2]\n\n\n\n\n\n\n\n[2]: \/answers\/storage\/attachments\/171659-image.png",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-06T20:12:21.55Z",
                "Answer_score":0,
                "Answer_body":"The problem was I needed to create a Language specific Cognitive Service and not the general Cognitive Service resource.\n\nThere is no distinction for this from Synapse, when creating the Cognitive Service Linked Service, but the Predict a Model cares.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Studio AutoML Hyperparameter Optimization & Algorithm Selection",
        "Question_creation_time":1646043411497,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/753198\/azure-ml-studio-automl-hyperparameter-optimization.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Which method (Grid Search, Bayesian Search, Random Search, ...) is used in Azure ML Studio AutoML per default to optimize model hyperparameters in order to increase model accuracy? In the SDK you can choose which method you want to use (according to https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-tune-hyperparameters), but I could not find any information about the Studio execept another asked question, but the provided answer was not clear to me (https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/462352\/hyperparamter-optimization-in-azure-automl.html).\n\nAnd how exactly does Azure ML Studio AutoML search for possible algorithms\/ how does the tool choose, which algorithm to use next?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-01T05:13:03.31Z",
                "Answer_score":1,
                "Answer_body":"Hi, according to this document, Azure AutoML uses Bayesian optimization to optimize hyperparameters. How Azure AutoML works - During training, Azure Machine Learning creates a number of pipelines in parallel that try different algorithms and parameters for you. The service iterates through ML algorithms paired with feature selections, where each iteration produces a model with a training score. The higher the score, the better the model is considered to \"fit\" your data. It will stop once it hits the exit criteria defined in the experiment. Hope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How does autoML actually calculate feature importance?",
        "Question_creation_time":1645707636143,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/749298\/how-does-automl-actually-calculate-feature-importa.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Do they use a sklearn feature selection method? I want to learn how they actually decide what features are more important than others (the ones shown in explain model). Going through the generated code doesn't reveal much to me.\nI see ExtraTreesRegressor, LGBMRegressor, PreFittedSoftVotingRegressor but I don't know if they're used for feature importance or something else.\n\nAny advice really appreciated.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-25T06:51:17.607Z",
                "Answer_score":1,
                "Answer_body":"Hi, thanks for reaching out. The following document provides details on how to use data featurization in Azure Automl. However, the underlying methods used for featurization seems to be proprietary and not shared publicly at this time. I'll try to make some inquiries and let you know if additional information is available.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AML Pipeline as an Artifacts in Azure Devops CI\/CD",
        "Question_creation_time":1645623751260,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/747636\/aml-pipeline-as-an-artifacts-in-azure-devops-cicd.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I have a script that has multiple steps to preprocess, train, register model, and publish an AML pipeline.\n\nHere is the code for AML pipeline:\n\n\n\n step_sequence = StepSequence(steps=[step1, step2,step3])\n     pipeline = Pipeline(workspace=ws, steps=step_sequence)\n    \n     pipeline.validate()\n    \n     # Submit a pipeline\n     pipeline.submit(experiment_name=e.experiment_name_train)\n     print(\"Pipeline submitted for execution.\")\n    \n     # Publish a pipeline\n     published_pipeline = pipeline.publish(\n         name='SomeName',\n         description=\"some Desc\",\n         version=e.build_id\n     )\n     #Publish the pipeline to its versioned endpoint URI\n     publish_pipeline_to_endpoint(ws, published_pipeline)\n\n\n\nIn CI pipeline, we want publish the AML pipeline as an artifact so that it can be used in CD pipeline and deploy the same AML pipeline in test and prod.\n\nNot just a model, we want to deploy whole AML pipeline.\n\nIs there a way to do this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-24T15:50:51.947Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. Please review the following resources:\n\nAzure Pipelines for CI\/CD\n\n\nSamples (MLOps and MLOpsPython)",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How long does it take to use a resource after you creat it?",
        "Question_creation_time":1645195183417,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/741883\/how-long-does-it-take-to-use-a-resource-after-you.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I cannot see my machine learning resource I created.\nAfter you create a resource under the resource group, how long does it take to actually see it and start using it?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-18T23:03:49.903Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. The creation process normally takes a few mins to complete. Are you sure that you're looking at the correct resource group? You can also check the notification icon at the top of Azure portal to confirm deployment status.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-02-19T05:14:51.103Z",
                "Answer_score":0,
                "Answer_body":"Please open the RG to see the resource you created is available under it.\n\nAlso try to check the Deployments tab to see if the deployment of that resource was successful\n\n\n\n\n\nPlease don't forget to Accept Answer and Up-vote if the response helped -- Vaibhav",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Kernel not connected",
        "Question_creation_time":1645626985700,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/747823\/kernel-not-connected.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I have an azureml studio with a notebook and suddenly since today, I cant run notebooks cells anymore. It says kernel not connected.\nI cant either open the terminal it never loads.\n\nI restarted the compute instance several time, but that didnt fix the problem",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-01T10:45:52.13Z",
                "Answer_score":0,
                "Answer_body":"Hello @levalencia\n\nThere was an issue causing the \"kernal not connected\" issue, but it has been fixed. Please let us know if you are still blocked by this issue. Thanks a lot!\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"azure machine learning - environment - add conda dependancies by sdk for training on a compute instance",
        "Question_creation_time":1645625095433,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/747638\/azure-machine-learning-environment-add-conda-depen.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":9,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"hello guys, i m a bit confused\n\ni need to add joblib package to a tensorflow 2.7 environment so as to load the needed datas during the train on the compute instance\n\n1) i start by making an environnment clone:\n\n env = Environment.get(workspace=ws, name=\"AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu\")\n curated_clone = env.clone(\"customize_curated\")\n\n\n\n2) i add conda dependancies at the python key (like the MS example)\n\n conda_dep = CondaDependencies()\n conda_dep.add_pip_package(\"joblib==1.0.1\")\n curated_clone.python.conda_dependencies=conda_dep\n\n\n\n3) registration\n\n curated_clone.register(workspace=ws)\n\n\n\ni meet an error when i train the model by using the registred environment caus joblib is missing\n\nbut if i modify the dockerfile of the environmment by adding joblib directly on studio, everything is ok\ncould you please explain me what i m doing wrong with the sdk",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Where to look for Source Code while implementing Azure Machine learning?",
        "Question_creation_time":1645806024193,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/751130\/where-to-look-for-source-code-while-implementing-a.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I am implementing a training pipeline using Azure Machine learning Pipeline architecture. I am interested in looking at the Source code, for example Hyper-drive step class or python-script step class. Where should I look for Source code?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-25T19:34:48.637Z",
                "Answer_score":0,
                "Answer_body":"Hi, it seems you're looking for source code for AzureML Pipelines. You can find it here. Also, here's an example notebook that demonstrates the use of HyperDriveStep.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure machine learning studio for designer function connected with excel?",
        "Question_creation_time":1645970050413,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/752248\/azure-machine-learning-studio-for-designer-functio.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hello, I am using Azure machine learning studio, which has been changed since last year.\n\nPreviously, the Azure Machine Learning designer function of the Classic version could be applied to Excel by importing the App function to Excel and downloading it. Like the picture below!\n\nHas the function that can be linked to Excel be lost in this Azure Machine Learning Studio? it's very difficult....\n\nIf there is a function, can you tell me how to do it?\n\nAnd I wonder if there are any lectures that explain the new azure machine learning designer features.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-28T10:37:23.35Z",
                "Answer_score":0,
                "Answer_body":"@RobinJang-2932 The designer studio does not have an add-in for excel. This is only available with the classic version of Azure Machine Learning.\nIf you are new to Azure machine learning designer I would recommend to start with the tutorials from Microsoft Learn available here.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-02-28T08:06:31.203Z",
                "Answer_score":0,
                "Answer_body":"Hi @RobinJang-2932,\nWhat version of Office did you use?\nI tested in Excel 365, I can add the add-in and run it:\n\n\nThe add-in is only supported:\nExcel 2013 or later on Windows\nExcel 2013 SP1 or later on Windows\nExcel on Windows (Microsoft 365)\nExcel on the web\n\nHere is the link about Azue Machine Learning documents:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/\n\nJust checking in to see if the information was helpful. Please let us know if you would like further assistance.\n\nIf the response is helpful, please click \"Accept Answer\" and upvote it.\nNote: Please follow the steps in our documentation to enable e-mail notifications if you want to receive the related email notification for this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Trigger Azure ML Pipeline from Azure Data Factory",
        "Question_creation_time":1645081864137,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/739240\/trigger-azure-ml-pipeline-from-azure-data-factory.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":10,
        "Question_follower_count":30,
        "Question_score":5,
        "Question_body":"I have created and published a Azure ML pipeline. I want to trigger the ML pipeline from Azure Data Factory.\n\nIn ADF, i have chosen Machine learning execute pipeline and created the linked service to azure machine learning and able to choose the published pipeline endpoint. However while running, i am getting the below error. I couldn't find much information how to resolve the error.\n\n\"Convert Failed. The value type 'System.String', in key 'azureCloudType' is not expected type 'Microsoft.DataTransfer.Common.Models.AzureCloudType\"",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-17T15:32:33.53Z",
                "Answer_score":3,
                "Answer_body":"Hi @VinothKumarK-8698 ,\nWelcome to Microsoft Q&A platform and thankyou for posting your query.\nAs per the details you have shared in the query, it looks like a product bug. I have raised this issue with the internal Product team. Once I hear back from them, I will keep everyone posted on this. Thanks for your patience!",
                "Answer_comment_count":14,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-02-28T10:12:25.843Z",
                "Answer_score":0,
                "Answer_body":"Hi Ahmed,\n\nWorking now :)\nMany thanks.\n\nRegards,\nJos\u00e9.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"RuntimeError: Java gateway process exited before sending its port number when deploying Pyspark model to Azure Container Instance (Issue #23158)",
        "Question_creation_time":1645557644517,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/746493\/runtimeerror-java-gateway-process-exited-before-se.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"Hi, I raised my issue in a GitHub repo for azure-sdk-for-python too:\n\nhttps:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/23158",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Export metadata file of componenets and its parameters of trained and submitted model in AzureML designer",
        "Question_creation_time":1645272036680,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/742573\/export-metadata-file-of-componenets-and-its-parame.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello , I'm new to azureML and I have a question about Azure ML designer , after creating a workflow (drag and drop components , let's say problem of linear regression ) can I export, download a file of the metadata of the workflow that contains the names of components used and its parameters.\nif it's possible can automate the process of creating a workflow in azureML designer by using already exsiting metadata file (json, xml , yaml ... ) similar to the one mentioned previously.\n\nif there any other services in azure that's capable of solving this issue please feel free to mention it\n\nthank youu.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-21T11:00:27.963Z",
                "Answer_score":0,
                "Answer_body":"@AchrafDRIDI-0098 Yes, you can export your designer experiment as a pipeline. The option to export is available from the designer from the top right hand corner. This is basically a cli command that helps you export the experiment in two ways.\n\nShallow\n\n\nDeep\n\nUPDATE\nThe feature mentioned above is in private preview and not available to all users. Exact ETA not available at this point of time.\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Replace SKLearn with supported code",
        "Question_creation_time":1645627689823,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/747835\/replace-sklearn-with-supported-code.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello,\nAny ideas on how to rewrite this code to supported Python code?\nThis code in a demo does not run well:\n\n\n\n\nWARNING:azureml.train.sklearn:'SKLearn' estimator is deprecated\n\n\n\n\nfrom azureml.train.sklearn import SKLearn\n\nestimator = SKLearn(source_directory='.\/Scripts',\ncompute_target=compute_target,\nentry_script='train.py',\ninputs=[tabular.as_named_input('training')],\npip_packages=['azureml-dataprep[fuse,pandas]','joblib==0.14.1','azureml-interpret','azureml-contrib-interpret','matplotlib','scikit-learn==0.22.1','seaborn'])\n\nrun = experiment.submit(estimator)\nrun",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-24T01:08:42.71Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us,\"SKLearn\" estimator classes has been deprecated in favor of using \"ScriptRunConfig\" to configure experiment runs.\n\nHere I would recommend you to follow the document to see how to run your scikit-learn training scripts with Azure Machine Learning.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-scikit-learn?view=azure-ml-py\n\nThis is a good guidance for customer to migrate from SKLearn Estimator to ScriptRunConfig.\n\nHope this helps!\n\nRegards,\nYutong\n\n-Please kindly accept the answer if you feel helpful, thanks.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AzureML Datetime Issue",
        "Question_creation_time":1623315431723,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/430158\/azureml-datetime-issue.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_follower_count":13,
        "Question_score":5,
        "Question_body":"Hi,\n\nI am coming across an issue to do with retaining the datetime values in the datasets that I have uploaded to AzureML.\nThis issue can be replicated in the following ways:\n\nCreate a pandas dataframe with a column of datetime strings and parse them accordingly\n\nd = {\"Date\": [\"2020-03-06\", \"2021-01-05\", \"2016-01-30\", \"2019-12-14\"]}\ndf = pd.DataFrame(data=d)\ndf[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\")\n\nSave this dataframe as a .parquet\n\n\nUpload to Azure Blob\n\n\nCreate a Tabular Dataset object with the uploaded file\n\ndatastore = workspace.get_default_datastore()\ndatastore_path = [(datastore, \"filename.parquet\")]\nazureml_df = Dataset.Tabular.from_parquet_files(path=datastore_path)\n\nPrinting the dataframe results in the following:\n\nThe datetime values are now different.\nTo investigate further, we can cast the datetime to int:\n\nwhich gives us a 15 digit number.\n\nWe also cast the original df to int:\n\nwhich instead gives us an 18 digit number.\n\nThis 18 digit number represents the number of nanoseconds since UNIX epoch. Three trailing zeroes are stripped from the number when creating the Tabular Dataset object through azureml-sdk, resulting in an incorrect datetime being read. Keep in mind that if you were to download the parquet from Azure Blob, the values are still intact, meaning the issue is with AzureML and potentially the Dataset method, from_parquet_files. A simple workaround would be to multiply this column by 1000 then convert it back to datetime again but I would like to know if there's something I'm missing in between reading the parquet from AzureML or if the problem is on Azure's side.\n\nRegards,\nMuhammad",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-10T10:50:22.953Z",
                "Answer_score":1,
                "Answer_body":"@MuhammadZainal-1174 Thanks for the detailed explanation of the issue. I have tried to replicate this issue with the exact steps but the date in does not change to a different value as seen in your case. Here are the steps:\n\nWith the exact same steps too the date is consistent.\n\nMaybe there is an issue with one of the SDK version. Which version of the SDK are you using?",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-26T22:40:14.59Z",
                "Answer_score":0,
                "Answer_body":"I'm seeing the same issue running PythonScriptStep in AzureML Pipelines.\n\nI suspect it has something to do with the PyArrow representation of datetimes.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-01-19T08:22:28.737Z",
                "Answer_score":1,
                "Answer_body":"I'm facing the same problem. I'm using PythonScriptStep to create pipeline and PipelineData to get the output of the pipeline. The output has the right datetime, but once I registered that output data as a dataset in AzureML, the datetime is incorrect when I read it.\n\n\n\n\nAs for the environment, I specified as below:\n\npyarrow 3.0.0\npandas 0.25.3\nazureml-core 1.34.0\npython 3.6.9",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-02-25T15:42:47.697Z",
                "Answer_score":1,
                "Answer_body":"I have the same issue when running the following code on the ML notebook.\n\n\n\n\n\n\nIt was fine until yesterday and suddenly started happening today.\nWe can see the expected timestamp by converting it to datetime64 and then multiplying by 1000, but we would like know why it happens and don't want to have unexpected thing like this in the future or internally in the pipeline.\nPlease investigate if something has changed within the aml dataset and casting the datatype, etc.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning: I cannot find experiment's user logs located in logs\/user folder",
        "Question_creation_time":1645621539517,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/747549\/azure-machine-learning-i-cannot-find-experiment39s.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"I am running experiments in Azure Machine Learning using ParallelRunStep, and I cannot get the user folder with logs as defined in readme.txt file with the log folder structure.\nI cannot find log\/user folder with \"Logs generated when loading and running user's scripts.\"\n\nreadme.txt file states:\nParallelRunStep has two major parts:\n1. Scheduling, progress tracking and file concatenation for append_row.\n2. Processing mini batch by calling the entry script.\nThe agent manager on each node start agents.\nAn agent gets mini batch and calls the entry script against the mini batch.\n\n The \"logs\" folder has user, sys and perf sub folders.\n The user folder includes messages from the entry script in processing mini batches.\n The sys folder includes messages from #1 and non-entry script log from #2.\n The perf folder includes periodical checking result of resource usage.\n\n\n\nIn majority case, users can find the processing messages from the user folder.\nUsers need to check sys folder for messages beyond processing mini batches.\nlogs\/\nazureml\/: Logs from azureml dependencies. e.g. azureml.dataprep\nuser\/ : Logs generated when loading and running user's scripts.\nerror\/ : Logs of errors encountered while loading and running entry script.\nstderr\/ : stderr output of user's scripts.\nstdout\/ : stdout output of user's scripts.\nentry_script_log\/ : Logs generated by loggers of EntryScript()\n<node seq> :\nprocessNNN.log.txt : Logs generated by loggers of EntryScript() from each process.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-24T02:37:03.417Z",
                "Answer_score":0,
                "Answer_body":"@CalabriaMonteroSalvadorSGRESEDFPDC-5704 Thanks for the question. Please follow the doc to view and log files for a run. Interactive logging sessions are typically used in notebook environments. The method Experiment.start_logging() starts an interactive logging session. Any metrics logged during the session are added to the run record in the experiment. The method run.complete() ends the sessions and marks the run as completed.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-log-view-metrics#view-and-download-log-files-for-a-run",
                "Answer_comment_count":4,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How to use batch endpoints (preview) in Azure Machine Learning studio tutorial",
        "Question_creation_time":1645721296993,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/749684\/how-to-use-batch-endpoints-preview-in-azure-machin.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello,\n\nI have been following this tutorial on how to use batch endpoints.\n\nWhen I attempt to select environment I am not greeted with the same as on the tutorial, please see below screenshot. \n\n\n\n\n\nWhat are the steps in continuing this tutorial in terms of selecting an environment?\n\nKind Regards,\n\nAdam N",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-25T08:49:48.953Z",
                "Answer_score":0,
                "Answer_body":"@AdamNevin-8126 Currently, the scoring and dependencies files are generated only for mlflow models that are registered with Azure ML workspace.\nFor example after running this notebook locally I registered the model and the folder with Azure ML workspace from the models tab.\nThis registered model can be selected while creating the batch endpoint and the dependencies are automatically created without the need of selecting a custom environment.\n\nIf you are using a different framework model then the dependencies or scoring files need to be provided along with selection of custom environment. The custom environments though first need to be created from the Environments tab by providing a YAML file. After adding a custom environment you can proceed to select the environment on this screen and deploy the endpoint.\n\nHope this helps!!\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure ML - Notebook - Jupyter Kernel Error - No Kernel connection",
        "Question_creation_time":1612145607873,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/252893\/azure-ml-notebook-jupyter-kernel-error-no-kernel-c-1.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":8,
        "Question_comment_count":3,
        "Question_follower_count":15,
        "Question_score":6,
        "Question_body":"In ML Studio, when I create a notebook the top of my screen says \"Jupyter kernel error\" in red. I have a compute instance running (it's green), but it also says \"No Kernel connected\".\n\nTo correct this matter, can you please provide explicit, step by step instructions on how to review. Screen shots help too.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-11T19:39:03.553Z",
                "Answer_score":0,
                "Answer_body":"i am having exactly same issue with \"No kernel connected\", have you guys resolved this yet? how?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-08-06T16:01:38.527Z",
                "Answer_score":0,
                "Answer_body":"Has anyone resolved this issue? Can someone please post the solution.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-15T20:18:50.39Z",
                "Answer_score":0,
                "Answer_body":"Part of our team had this issue this week, the root cause for us was some language-packs for pt-br not loading correctly, once the affected team members changed the page\/browser language to en-us the problem was solved.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-27T14:04:50.417Z",
                "Answer_score":0,
                "Answer_body":"I had this same issue and resolved it by stopping and restarting the compute. This may be overly simplistic as I am a learner too.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-12-29T19:04:08.963Z",
                "Answer_score":0,
                "Answer_body":"Hi! I got this problem right now. I don't know what happened, but I've been working with Azure ML for 6 months already and it's the first time I get this kind of error.\nDid you found the solution already? @danielgo-9074 I've got page\/browser language set to en-us ;\/",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-01-18T06:11:45.067Z",
                "Answer_score":0,
                "Answer_body":"Hi I also have the same problem. My compute is running but I cannot connect to any of the kernel. It keeps saying that the kernel not found or was deleted.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-01-26T12:38:07.16Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nI have the same issue (eastus location):",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-02-24T19:52:41.67Z",
                "Answer_score":1,
                "Answer_body":"i have been facing the same issue my compute was running still there was no kernel, i resolved it after a long search. It seemed my firewall was preventing me from doing that.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Problems with the creation of a compute instance using azure cli",
        "Question_creation_time":1645190462707,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/741739\/problems-with-the-creation-of-a-compute-instance-u.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hello, I am introducing the concept of MLOps and right now I have a problem when I create a compute instance from devops. In order to create the compute instance from a devops pipeline, I use the azure cli to do this with the following code:\n\naz ml computetarget create computeinstance -g $(RESOURCE_GROUP) -w $(WORKSPACE_NAME) -n $(amlcompute.instanceName) -s $(amlcompute.instancevmSize) -v\n\nthe command creates the compute instance, but I can't use the ML notebooks as the compute doesn't appear to be available. I have searched the web and everywhere they use the same cli code to create the compute instance.\n\n\n\n\nI would appreciate knowing why it doesn't work this way",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"MemoryError: Unable to allocate 3.35 GiB for an array with shape (3000000, 300) and data type float32",
        "Question_creation_time":1645539137690,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/745993\/memoryerror-unable-to-allocate-335-gib-for-an-arra.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I'm trying to deploy a model using Azure Machine Learning. In the init() method of the score.py (the entry script), I try to load in a Google Word2Vec model (https:\/\/mccormickml.com\/2016\/04\/12\/googles-pretrained-word2vec-model-in-python\/). When trying to create an endpoint, the following exception is thrown:\n\nMemoryError: Unable to allocate 3.35 GiB for an array with shape (3000000, 300) and data type float32\n\nI'm using a Standard_DS12_v2 compute instance, from which I would expect that the specified ram and storage should be sufficient to handle the 3.35 GiB.\n\nAny suggested solutions? Thanks a lot",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure ML and Power BI integration",
        "Question_creation_time":1645173232983,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/741401\/azure-ml-and-power-bi-integration.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I am following this tutorial to integrate Azure ML and Power BI:\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-power-bi-designer-model\n\nThe model Deployment stage is failing with the following error:\n\nDeploy: Failed on Waiting real-time endpoint creation.\nDetails: AzureML service API error.\nWARNING:main:Looking for secret AML_MODEL_DC_STORAGE WARNING:main:no config found, using configfile INFO:azure.storage.common.storageclient:\n\n...",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Deploying from Azure ML studio Designer is giving error in deploying real time inference endpoint",
        "Question_creation_time":1645328557520,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/742817\/deploying-from-azure-ml-studio-designer-is-giving.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"2022\/02\/20 03:25:31 Downloading source code...\n2022\/02\/20 03:25:32 Finished downloading source code\n2022\/02\/20 03:25:32 Creating Docker network: acb_default_network, driver: 'bridge'\n2022\/02\/20 03:25:32 Successfully set up Docker network: acb_default_network\n2022\/02\/20 03:25:32 Setting up Docker configuration...\n2022\/02\/20 03:25:33 Successfully set up Docker configuration\n2022\/02\/20 03:25:33 Logging in to registry: c89d3aeb8176436a9d4c29a07e6381fb.azurecr.io\n2022\/02\/20 03:25:33 Successfully logged into c89d3aeb8176436a9d4c29a07e6381fb.azurecr.io\n2022\/02\/20 03:25:33 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2022\/02\/20 03:25:33 Scanning for dependencies...\n2022\/02\/20 03:25:34 Successfully scanned dependencies\n2022\/02\/20 03:25:34 Launching container with name: acb_step_0\nSending build context to Docker daemon 66.56kB\n\nStep 1\/21 : FROM mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04@sha256:922be75bb02cf219cb86ac4734bcbda41d956314a4b3b7a4febc807d0a803f6e\nmcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04@sha256:922be75bb02cf219cb86ac4734bcbda41d956314a4b3b7a4febc807d0a803f6e: Pulling from azureml\/openmpi3.1.2-ubuntu18.04\n68e7bb398b9f: Already exists\n893c92dab848: Pulling fs layer\na0757eae439e: Pulling fs layer\nee2957a13303: Pulling fs layer\nf49a3daea774: Pulling fs layer\ncab73971ce79: Pulling fs layer\nc3d7fbfdaca2: Pulling fs layer\n0976efdf0829: Pulling fs layer\nd02e6f607e12: Pulling fs layer\nf49a3daea774: Waiting\ncab73971ce79: Waiting\nc3d7fbfdaca2: Waiting\n0976efdf0829: Waiting\nd02e6f607e12: Waiting\nee2957a13303: Verifying Checksum\nee2957a13303: Download complete\nf49a3daea774: Verifying Checksum\nf49a3daea774: Download complete\ncab73971ce79: Verifying Checksum\ncab73971ce79: Download complete\nc3d7fbfdaca2: Verifying Checksum\nc3d7fbfdaca2: Download complete\n0976efdf0829: Verifying Checksum\n0976efdf0829: Download complete\n893c92dab848: Verifying Checksum\n893c92dab848: Download complete\nd02e6f607e12: Verifying Checksum\nd02e6f607e12: Download complete\na0757eae439e: Verifying Checksum\na0757eae439e: Download complete\n893c92dab848: Pull complete\na0757eae439e: Pull complete\nee2957a13303: Pull complete\nf49a3daea774: Pull complete\ncab73971ce79: Pull complete\nc3d7fbfdaca2: Pull complete\n0976efdf0829: Pull complete\nd02e6f607e12: Pull complete\nDigest: sha256:922be75bb02cf219cb86ac4734bcbda41d956314a4b3b7a4febc807d0a803f6e\nStatus: Downloaded newer image for mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04@sha256:922be75bb02cf219cb86ac4734bcbda41d956314a4b3b7a4febc807d0a803f6e\n---> 8926027fde41\nStep 2\/21 : USER root\n---> Running in 0b57828c9289\nRemoving intermediate container 0b57828c9289\n---> 370ef8ee2d0f\nStep 3\/21 : RUN mkdir -p $HOME\/.cache\n---> Running in 3eee95c47f9f\nRemoving intermediate container 3eee95c47f9f\n---> 415459035e6d\nStep 4\/21 : WORKDIR \/\n---> Running in 08c6f83df4b1\nRemoving intermediate container 08c6f83df4b1\n---> 4216bc82e697\nStep 5\/21 : COPY azureml-environment-setup\/99brokenproxy \/etc\/apt\/apt.conf.d\/\n---> 03b433a4a6b8\nStep 6\/21 : RUN if dpkg --compare-versions conda --version | grep -oE '[^ ]+$' lt 4.4.11; then conda install conda==4.4.11; fi\n---> Running in a59290010c77\nRemoving intermediate container a59290010c77\n---> 5bc601b6dd21\nStep 7\/21 : COPY azureml-environment-setup\/mutated_conda_dependencies.yml azureml-environment-setup\/mutated_conda_dependencies.yml\n---> d43a193f0f3e\nStep 8\/21 : RUN ldconfig \/usr\/local\/cuda\/lib64\/stubs && conda env create -p \/azureml-envs\/azureml_9a27d0b682f7325ef536eaeb801b2a62 -f azureml-environment-setup\/mutated_conda_dependencies.yml && rm -rf \"$HOME\/.cache\/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR\/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name pycache -exec rm -rf {} + && ldconfig\n---> Running in 6f1452f548f8\nCollecting package metadata (repodata.json): ...working...\ndone\nSolving environment: ...working... done\n\nDownloading and Extracting Packages\n\nlibblas-3.9.0 | 12 KB | | 0%\nlibblas-3.9.0 | 12 KB | ########## | 100%\n\nreadline-7.0 | 391 KB | | 0%\nreadline-7.0 | 391 KB | ########## | 100%\n\ntk-8.6.12 | 3.3 MB | | 0%\ntk-8.6.12 | 3.3 MB | #####1 | 51%\ntk-8.6.12 | 3.3 MB | ########## | 100%\ntk-8.6.12 | 3.3 MB | ########## | 100%\n\nsix-1.16.0 | 14 KB | | 0%\nsix-1.16.0 | 14 KB | ########## | 100%\n\nsqlite-3.28.0 | 1.9 MB | | 0%\nsqlite-3.28.0 | 1.9 MB | ########## | 100%\nsqlite-3.28.0 | 1.9 MB | ########## | 100%\n\nncurses-6.3 | 1012 KB | | 0%\nncurses-6.3 | 1012 KB | ########## | 100%\nncurses-6.3 | 1012 KB | ########## | 100%\n\nlibgfortran-ng-11.2. | 19 KB | | 0%\nlibgfortran-ng-11.2. | 19 KB | ########## | 100%\n\nopenssl-1.1.1l | 2.1 MB | | 0%\nopenssl-1.1.1l | 2.1 MB | ########## | 100%\nopenssl-1.1.1l | 2.1 MB | ########## | 100%\n\nzlib-1.2.11 | 86 KB | | 0%\nzlib-1.2.11 | 86 KB | ########## | 100%\n\nlibcblas-3.9.0 | 12 KB | | 0%\nlibcblas-3.9.0 | 12 KB | ########## | 100%\n\nlibgomp-11.2.0 | 426 KB | | 0%\nlibgomp-11.2.0 | 426 KB | ########## | 100%\n\n_libgcc_mutex-0.1 | 3 KB | | 0%\n_libgcc_mutex-0.1 | 3 KB | ########## | 100%\n\nlibzlib-1.2.11 | 59 KB | | 0%\nlibzlib-1.2.11 | 59 KB | ########## | 100%\n\nlibffi-3.2.1 | 47 KB | | 0%\nlibffi-3.2.1 | 47 KB | ########## | 100%\n\npip-20.2.4 | 1.1 MB | | 0%\npip-20.2.4 | 1.1 MB | ########## | 100%\npip-20.2.4 | 1.1 MB | ########## | 100%\n\nsetuptools-58.0.4 | 966 KB | | 0%\nsetuptools-58.0.4 | 966 KB | ########## | 100%\nsetuptools-58.0.4 | 966 KB | ########## | 100%\n\nxz-5.2.5 | 343 KB | | 0%\nxz-5.2.5 | 343 KB | ########## | 100%\nxz-5.2.5 | 343 KB | ########## | 100%\n\npython_abi-3.6 | 4 KB | | 0%\npython_abi-3.6 | 4 KB | ########## | 100%\n\nnumpy-1.19.5 | 5.3 MB | | 0%\nnumpy-1.19.5 | 5.3 MB | ######9 | 70%\nnumpy-1.19.5 | 5.3 MB | ########## | 100%\nnumpy-1.19.5 | 5.3 MB | ########## | 100%\n\njoblib-1.1.0 | 210 KB | | 0%\njoblib-1.1.0 | 210 KB | ########## | 100%\n\nlibgfortran5-11.2.0 | 1.7 MB | | 0%\nlibgfortran5-11.2.0 | 1.7 MB | ########## | 100%\nlibgfortran5-11.2.0 | 1.7 MB | ########## | 100%\n\nca-certificates-2021 | 139 KB | | 0%\nca-certificates-2021 | 139 KB | ########## | 100%\n\nwheel-0.37.1 | 31 KB | | 0%\nwheel-0.37.1 | 31 KB | ########## | 100%\n\n_openmp_mutex-4.5 | 22 KB | | 0%\n_openmp_mutex-4.5 | 22 KB | ########## | 100%\n\nscikit-surprise-1.0. | 636 KB | | 0%\nscikit-surprise-1.0. | 636 KB | ########## | 100%\nscikit-surprise-1.0. | 636 KB | ########## | 100%\n\nlibopenblas-0.3.18 | 9.6 MB | | 0%\nlibopenblas-0.3.18 | 9.6 MB | ######2 | 63%\nlibopenblas-0.3.18 | 9.6 MB | #########8 | 99%\nlibopenblas-0.3.18 | 9.6 MB | ########## | 100%\n\nlibgcc-ng-11.2.0 | 904 KB | | 0%\nlibgcc-ng-11.2.0 | 904 KB | ########## | 100%\nlibgcc-ng-11.2.0 | 904 KB | ########## | 100%\n\nlibstdcxx-ng-11.2.0 | 4.2 MB | | 0%\nlibstdcxx-ng-11.2.0 | 4.2 MB | ########## | 100%\nlibstdcxx-ng-11.2.0 | 4.2 MB | ########## | 100%\n\npython-3.6.8 | 30.1 MB | | 0%\npython-3.6.8 | 30.1 MB | #6 | 17%\npython-3.6.8 | 30.1 MB | ######2 | 63%\npython-3.6.8 | 30.1 MB | ########## | 100%\npython-3.6.8 | 30.1 MB | ########## | 100%\n\nliblapack-3.9.0 | 12 KB | | 0%\nliblapack-3.9.0 | 12 KB | ########## | 100%\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\nInstalling pip dependencies: ...working...\nRan pip subprocess with arguments:\n['\/azureml-envs\/azureml_9a27d0b682f7325ef536eaeb801b2a62\/bin\/python', '-m', 'pip', 'install', '-U', '-r', '\/azureml-environment-setup\/condaenv.s4sfl041.requirements.txt']\nPip subprocess output:\nCollecting azureml-designer-classic-modules==0.0.161\nDownloading azureml_designer_classic_modules-0.0.161-py3-none-any.whl (403 kB)\nCollecting en_core_web_sm\nDownloading https:\/\/github.com\/explosion\/spacy-models\/releases\/download\/en_core_web_sm-2.1.0\/en_core_web_sm-2.1.0.tar.gz (11.1 MB)\nCollecting spacy==2.1.7\nDownloading spacy-2.1.7-cp36-cp36m-manylinux1_x86_64.whl (30.8 MB)\nCollecting azureml-model-management-sdk\nDownloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\nCollecting azure-storage-blob==1.5.0\nDownloading azure_storage_blob-1.5.0-py2.py3-none-any.whl (75 kB)\nCollecting azureml-designer-internal==0.0.56\nDownloading azureml_designer_internal-0.0.56-py3-none-any.whl (28 kB)\nCollecting seaborn==0.10.0\nDownloading seaborn-0.10.0-py3-none-any.whl (215 kB)\nCollecting gensim==3.8.3\nDownloading gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2 MB)\nCollecting lightgbm==3.2.1\nDownloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\nCollecting chardet==3.0.4\nDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\nCollecting joblib==0.14.0\nDownloading joblib-0.14.0-py2.py3-none-any.whl (294 kB)\nCollecting scipy==1.4.1\nDownloading scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1 MB)\nCollecting nimbusml==1.6.1\nDownloading nimbusml-1.6.1-cp36-none-manylinux1_x86_64.whl (105.2 MB)\nCollecting matplotlib==3.1.3\nDownloading matplotlib-3.1.3-cp36-cp36m-manylinux1_x86_64.whl (13.1 MB)\nCollecting pandas==1.0.4\nDownloading pandas-1.0.4-cp36-cp36m-manylinux1_x86_64.whl (10.1 MB)\nCollecting scikit-learn==0.22.2\nDownloading scikit_learn-0.22.2-cp36-cp36m-manylinux1_x86_64.whl (7.1 MB)\nCollecting imbalanced-learn==0.4.3\nDownloading imbalanced_learn-0.4.3-py3-none-any.whl (166 kB)\nCollecting Pillow==8.3.2\nDownloading Pillow-8.3.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\nCollecting azureml-interpret==1.36.0\nDownloading azureml_interpret-1.36.0-py3-none-any.whl (52 kB)\nCollecting blis<0.3.0,>=0.2.2\nDownloading blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (3.2 MB)\nCollecting plac<1.0.0,>=0.9.6\nDownloading plac-0.9.6-py2.py3-none-any.whl (20 kB)\nRequirement already satisfied, skipping upgrade: numpy>=1.15.0 in \/azureml-envs\/azureml_9a27d0b682f7325ef536eaeb801b2a62\/lib\/python3.6\/site-packages (from spacy==2.1.7->-r \/azureml-environment-setup\/condaenv.s4sfl041.requirements.txt (line 3)) (1.19.5)\nCollecting murmurhash<1.1.0,>=0.28.0\nDownloading murmurhash-1.0.6-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\nCollecting cymem<2.1.0,>=2.0.2\nDownloading cymem-2.0.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\nCollecting srsly<1.1.0,>=0.0.6\nDownloading srsly-1.0.5-cp36-cp36m-manylinux2014_x86_64.whl (184 kB)\nCollecting requests<3.0.0,>=2.13.0\nDownloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\nCollecting thinc<7.1.0,>=7.0.8\nDownloading thinc-7.0.8-cp36-cp36m-manylinux1_x86_64.whl (2.1 MB)\nCollecting preshed<2.1.0,>=2.0.1\nDownloading preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (83 kB)\nCollecting wasabi<1.1.0,>=0.2.0\nDownloading wasabi-0.9.0-py3-none-any.whl (25 kB)\nRequirement already satisfied, skipping upgrade: six>=1.10 in \/azureml-envs\/azureml_9a27d0b682f7325ef536eaeb801b2a62\/lib\/python3.6\/site-packages (from azureml-model-management-sdk->-r \/azureml-environment-setup\/condaenv.s4sfl041.requirements.txt (line 4)) (1.16.0)\nCollecting adal>=0.4.5\nDownloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\nCollecting dill>=0.2.7.1\nDownloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\nCollecting python-dateutil>=2.5.3\nDownloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\nCollecting liac-arff>=2.1.1\nDownloading liac-arff-2.5.0.tar.gz (13 kB)\nCollecting pytz>=2017.2\nDownloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\nCollecting azure-storage-common~=1.4\nDownloading azure_storage_common-1.4.2-py2.py3-none-any.whl (47 kB)\nCollecting azure-common>=1.1.5\nDownloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\nCollecting azureml-pipeline-core==1.36.0\nDownloading azureml_pipeline_core-1.36.0-py3-none-any.whl (313 kB)\nCollecting azureml-defaults==1.36.0\nDownloading azureml_defaults-1.36.0-py3-none-any.whl (3.0 kB)\nCollecting azureml-telemetry==1.36.0.\nDownloading azureml_telemetry-1.36.0-py3-none-any.whl (30 kB)\nCollecting cffi==1.12.3\nDownloading cffi-1.12.3-cp36-cp36m-manylinux1_x86_64.whl (430 kB)\nCollecting azureml-designer-core==0.0.68\nDownloading azureml_designer_core-0.0.68-py3-none-any.whl (101 kB)\nCollecting smart-open>=1.8.1\nDownloading smart_open-5.2.1-py3-none-any.whl (58 kB)\nRequirement already satisfied, skipping upgrade: wheel in \/azureml-envs\/azureml_9a27d0b682f7325ef536eaeb801b2a62\/lib\/python3.6\/site-packages (from lightgbm==3.2.1->azureml-designer-classic-modules==0.0.161->-r \/azureml-environment-setup\/condaenv.s4sfl041.requirements.txt (line 1)) (0.37.1)\nCollecting dotnetcore2>=2.1.2\nDownloading dotnetcore2-2.1.23-py3-none-manylinux1_x86_64.whl (29.3 MB)\nCollecting kiwisolver>=1.0.1\nDownloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\nCollecting cycler>=0.10\nDownloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\nCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1\nDownloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\nCollecting interpret-community==0.21.\nDownloading interpret_community-0.21.0-py3-none-any.whl (136 kB)\nCollecting azureml-core~=1.36.0\nDownloading azureml_core-1.36.0.post2-py3-none-any.whl (2.4 MB)\nCollecting certifi>=2017.4.17\nDownloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\nCollecting idna<4,>=2.5; python_version >= \"3\"\nDownloading idna-3.3-py3-none-any.whl (61 kB)\nCollecting charset-normalizer~=2.0.0; python_version >= \"3\"\nDownloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\nCollecting urllib3<1.27,>=1.21.1\nDownloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\nCollecting tqdm<5.0.0,>=4.10.0\nDownloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\nCollecting PyJWT<3,>=1.0.0\nDownloading PyJWT-2.3.0-py3-none-any.whl (16 kB)\nCollecting cryptography>=1.1.0\nDownloading cryptography-36.0.1-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\nCollecting configparser==3.7.4\nDownloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\nCollecting json-logging-py==0.2\nDownloading json-logging-py-0.2.tar.gz (3.6 kB)\nCollecting azureml-inference-server-http~=0.4.1\nDownloading azureml_inference_server_http-0.4.9-py3-none-any.whl (52 kB)\nCollecting azureml-dataset-runtime[fuse]~=1.36.0\nDownloading azureml_dataset_runtime-1.36.0-py3-none-any.whl (3.5 kB)\nCollecting applicationinsights\nDownloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\nCollecting pycparser\nDownloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\nCollecting pycryptodomex==3.7.3\nDownloading pycryptodomex-3.7.3-cp36-cp36m-manylinux1_x86_64.whl (7.5 MB)\nCollecting pyarrow==0.16.0\nDownloading pyarrow-0.16.0-cp36-cp36m-manylinux2014_x86_64.whl (63.1 MB)\nCollecting distro==1.4.0\nDownloading distro-1.4.0-py2.py3-none-any.whl (17 kB)\nCollecting ruamel.yaml==0.16.10\nDownloading ruamel.yaml-0.16.10-py2.py3-none-any.whl (111 kB)\nCollecting more-itertools==6.0.0\nDownloading more_itertools-6.0.0-py3-none-any.whl (52 kB)\nCollecting jsonschema==3.0.1\nDownloading jsonschema-3.0.1-py2.py3-none-any.whl (54 kB)\nCollecting interpret-core[required]<=0.2.6,>=0.1.20\nDownloading interpret_core-0.2.6-py3-none-any.whl (6.5 MB)\nCollecting packaging\nDownloading packaging-21.3-py3-none-any.whl (40 kB)\nCollecting shap<=0.39.0,>=0.20.0\nDownloading shap-0.39.0.tar.gz (356 kB)\nCollecting numba<0.54.0\nDownloading numba-0.53.1-cp36-cp36m-manylinux2014_x86_64.whl (3.4 MB)\nCollecting ndg-httpsclient<=0.5.1\nDownloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\nCollecting jmespath<1.0.0\nDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\nCollecting azure-graphrbac<1.0.0,>=0.40.0\nDownloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\nCollecting backports.tempfile\nDownloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\nCollecting msrest<1.0.0,>=0.5.1\nDownloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\nCollecting azure-mgmt-containerregistry>=2.0.0\nDownloading azure_mgmt_containerregistry-9.0.0-py3-none-any.whl (937 kB)\nCollecting jsonpickle<3.0.0\nDownloading jsonpickle-2.1.0-py2.py3-none-any.whl (38 kB)\nCollecting SecretStorage<4.0.0\nDownloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\nCollecting azure-mgmt-keyvault<10.0.0,>=0.40.0\nDownloading azure_mgmt_keyvault-9.3.0-py2.py3-none-any.whl (412 kB)\nCollecting pathspec<1.0.0\nDownloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\nCollecting azure-mgmt-storage<16.0.0,>=1.5.0\nDownloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\nCollecting contextlib2<22.0.0\nDownloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\nCollecting msrestazure<=0.6.4,>=0.4.33\nDownloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\nCollecting azure-mgmt-resource<15.0.0,>=1.2.1\nDownloading azure_mgmt_resource-13.0.0-py2.py3-none-any.whl (1.3 MB)\nCollecting pyopenssl<21.0.0\nDownloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)\nCollecting docker<6.0.0\nDownloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\nCollecting azure-mgmt-authorization<1.0.0,>=0.40.0\nDownloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\nCollecting sanic-cors~=1.0.1\nDownloading Sanic_Cors-1.0.1-py2.py3-none-any.whl (17 kB)\nCollecting inference-schema~=1.3.1\nDownloading inference_schema-1.3.1-py3-none-any.whl (20 kB)\nCollecting protobuf~=3.17.3\nDownloading protobuf-3.17.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\nCollecting grpcio-tools~=1.38.1\nDownloading grpcio_tools-1.38.1-cp36-cp36m-manylinux2014_x86_64.whl (2.5 MB)\nCollecting aiohttp~=3.7.4.post0\nDownloading aiohttp-3.7.4.post0-cp36-cp36m-manylinux2014_x86_64.whl (1.3 MB)\nCollecting aiotask-context~=0.6.1\nDownloading aiotask_context-0.6.1-py3-none-any.whl (3.5 kB)\nCollecting opencensus-ext-azure~=1.1.0\nDownloading opencensus_ext_azure-1.1.1-py2.py3-none-any.whl (42 kB)\nCollecting gunicorn==20.1.0; platform_system != \"Windows\"\nDownloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\nCollecting tritonclient[all]~=2.11.0\nDownloading tritonclient-2.11.0-py3-none-manylinux1_x86_64.whl (7.7 MB)\n\nfailed\n[91m\n\n==> WARNING: A newer version of conda exists. <==\ncurrent version: 4.9.2\nlatest version: 4.11.0\n\nPlease update conda by running\n\n $ conda update -n base -c defaults conda\n\n\n\n\nPip subprocess error:\nERROR: Could not find a version that satisfies the requirement sanic~=21.6.0 (from azureml-inference-server-http~=0.4.1->azureml-defaults==1.36.0->azureml-designer-internal==0.0.56->azureml-designer-classic-modules==0.0.161->-r \/azureml-environment-setup\/condaenv.s4sfl041.requirements.txt (line 1)) (from versions: 0.1.0, 0.1.1, 0.1.3, 0.1.4, 0.1.5, 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.3.0, 0.3.1, 0.4.0, 0.4.1, 0.5.0, 0.5.1, 0.5.2, 0.5.4, 0.6.0, 0.7.0, 0.8.0, 0.8.1, 0.8.2, 0.8.3, 18.12.0, 19.3.1, 19.6.0, 19.6.2, 19.6.3, 19.9.0, 19.12.0, 19.12.2, 19.12.3, 19.12.4, 19.12.5, 20.3.0, 20.6.0, 20.6.1, 20.6.2, 20.6.3, 20.9.0, 20.9.1, 20.12.0, 20.12.1, 20.12.2, 20.12.3, 20.12.4, 20.12.5, 20.12.6)\nERROR: No matching distribution found for sanic~=21.6.0 (from azureml-inference-server-http~=0.4.1->azureml-defaults==1.36.0->azureml-designer-internal==0.0.56->azureml-designer-classic-modules==0.0.161->-r \/azureml-environment-setup\/condaenv.s4sfl041.requirements.txt (line 1))\n\n\n\n\nCondaEnvException: Pip failed\n\n[0mThe command '\/bin\/sh -c ldconfig \/usr\/local\/cuda\/lib64\/stubs && conda env create -p \/azureml-envs\/azureml_9a27d0b682f7325ef536eaeb801b2a62 -f azureml-environment-setup\/mutated_conda_dependencies.yml && rm -rf \"$HOME\/.cache\/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR\/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name pycache -exec rm -rf {} + && ldconfig' returned a non-zero code: 1\n2022\/02\/20 03:27:17 Container failed during run: acb_step_0. No retries remaining.\nfailed to run step ID: acb_step_0: exit status 1\n\nRun ID: cf6 failed after 1m47s. Error: failed during run, err: exit status 1",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-21T14:51:28.87Z",
                "Answer_score":0,
                "Answer_body":"@ shrutinehra-0489 Thanks for the question. Please share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning app for Excel incorrect positive and negative sentiment - feedback?",
        "Question_creation_time":1645107466670,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/740005\/azure-machine-learning-app-for-excel-incorrect-pos.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"We have just trialled the Azure ML excel add in and used the sentiment analyser. The majority of results are coming back with false positive and negative results. Where would we feedback our results to support development and is there support out there for new users? Ended up here and the support ticket system was unclear as to which ticket area to allocate.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-18T05:30:53.757Z",
                "Answer_score":0,
                "Answer_body":"@AlastairWhiteley-3627 Thanks for the feedback. You can raise a user voice request here so the community can vote and provide their feedback, the product team then checks this feedback and implements the same in future releases.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Private endpoint in hub-and-spoke architecture (Try to access a storage account in my different vnets)",
        "Question_creation_time":1644509273567,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/730824\/private-endpoint-in-hub-and-spoke-architecture-try.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":22,
        "Question_score":0,
        "Question_body":"Hello,\n\nI'm trying to register a dataset in my different Azure Machine Learning workspaces (of each vnet spoke) but for that I need to connect from my ML workspaces to my storage account (dev or prod) located in the vnet 'spoke-pdata'. (screenshot)\n\nThe datastore (refer to storage account) is already register with Access key.\nI have already checked:\n- peering between my hub and my different spoke\n- private dns zone (privatelink.blob.core.windows.net) in my hub vnet with record set for storage\n- all virtual network links between hub and each spoke (privatelink blob)\n- private dns zone (privatelink.api.azureml.ms) in my hub vnet with record set for each azure machine learning\n- all virtual network links between hub and each spoke (privatelink azureml)\n- storage account roles for each azure ML\n- contributor role for each azure ml in storage account (to be sure it's not role issue)\n- NSG off for storage account\n\n\n\n\nWhen I set ''All network'' in network of my storage account, Azure ML is connected to my storage account and I can register my dataset... So it's a network issue.\nI tried nslookup in AML and I can get the private ip of my storage account:\n\n\nWhat did I forget? Maybe I misunderstood the concept of private endpoint... From my point of view, I just need a private endpoint connected to a private dns. And in case there are two different vnet, I need to connect them with a private link and a vnet peering.\nI read the documentation but did not find a similar case... I am still confused.\n\nError:\n\n\nScriptExecutionException was caused by StreamAccessException.\nStreamAccessException was caused by AuthenticationException.\nAuthentication failed for 'AzureBlob GetReference' operation at '[REDACTED]' with '403: AuthorizationFailure'. Please make sure the SAS token or the account key is correct.\nFailed due to inner exception of type: StorageException",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-11T03:19:40.743Z",
                "Answer_score":1,
                "Answer_body":"Hello @mhajji\n\nThanks for reaching out to us, one of the possible reason for this issue may be firewall is not enabled.\n\nCould you please validate if your storage account is firewall enabled ?\n\nPlease follow this steps to do so:\nAzure Portal -> Storage Account -> Networking -> Check Allow Access From (All Networks \/ Selected Networks)\nIf it is \"Selected Networks\" - It means the storage account is firewall enabled.\n\nIf the storage account is firewall enabled , check your CORS is setting correctly as below:\n\nFor me, I am using Allowed origins as below:\nhttps:\/\/mlworkspace.azure.ai,https:\/\/ml.azure.com,https:\/\/*.ml.azure.com,https:\/\/mlworkspacecanary.azure.ai,https:\/\/mlworkspace.azureml-test.net\n\nLet us know if the above steps helps out in resolving the issue , please don't forget to Upvote and Accept the Answer\n\nRegards,\nYutong",
                "Answer_comment_count":5,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Clean Up instructions at the end of the module to stop compute resources.",
        "Question_creation_time":1643823950947,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/720158\/clean-up-instructions-at-the-end-of-the-module-to.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hello,\n\nI am currently doing cloudskillschallenge for getting certified in Azure Data Scientist course and I came across a point in Module 6 : \"Use automated machine learning in Azure Machine Learning\" that says \"After completing each module, be sure to follow the Clean Up instructions at the end of the module to stop your compute resources. Stopping your compute ensures your subscription won't be charged for compute resources.\"\n\nI have opted for the free trial in Azure portal and would like to know how to do the said process of removing the instructions.\n\n\n\n\nRegards,\nTuhin",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-02T23:03:54.763Z",
                "Answer_score":0,
                "Answer_body":"@TuhinDas-5095\n\nHello,\n\nThank for reaching out to us. Please see below guidance about how to do the Clean Up for resource.\n\nStop Compute Instance:\nIf you're not going to use it now, stop the compute instance:\n\nIn the studio, on the left, select Compute.\n\n\nIn the top tabs, select Compute instances\n\n\nSelect the compute instance in the list.\n\n\nOn the top toolbar, select Stop.\n\nDelete all resources\nIf you don't plan to use any of the resources that you created, delete them so you don't incur any charges:\n\nIn the Azure portal, select Resource groups on the far left.\n\n\nFrom the list, select the resource group that you created.\n\n\nSelect Delete resource group.\n\n\n\nEnter the resource group name. Then select Delete.\n\nMore information please see below document:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/quickstart-create-resources#clean-up\n\nHope it helps. Please let us know if you have more questions.\n\nPlease kindly accept the answer if you feel it's helpful.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Batch Endpoint: How to correctly submit dataset to batch endpoint",
        "Question_creation_time":1644854452957,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/734672\/azure-ml-batch-endpoint-how-to-correctly-submit-da.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I built a model using auto ML and deployed it as a batch endpoint.\nWhen I re-use the same dataset I used to train the data I get an error:\n\nValueError: Length mismatch: Expected axis has 1 elements, new values have 7 elements\n\nI assume, I have to convert the whole thing into some kind of batch first?\nI didn't find documentation on how to convert a structured table dataset to a batch. Does anyone know how to do this?\n\nThank you for the help, best, Max",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-16T04:11:03.81Z",
                "Answer_score":0,
                "Answer_body":"@MaxCH-1766 Thanks for the question. Here is the document for Azure ML Batch endpoint for Batch scoring and Troubleshooting batch endpoints.\n\nHere is a sample that does AutoML Batch Scoring that can help.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-02-17T18:50:58.75Z",
                "Answer_score":0,
                "Answer_body":"Hi Max, I don't how you shaped the data, but I tried to do the below:\n\n\n\n\n\nIs your data somewhere expecting to be reshaped into minibatch_size=(350,1) in the second axis?...because the error says \"ValueError: Length mismatch: Expected axis has 1 elements, new values have 7 elements\"",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Python Azure SDK Having Trouble Importing tsv data; pandas error",
        "Question_creation_time":1644536309460,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/731321\/python-azure-sdk-having-trouble-importing-tsv-data.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I'm trying to get some cosmos data into an azure ml compute instance. I've done this a bunch of times but for some reason this particular set of data is giving me trouble, and I'm not sure why. I've removed all punctuation and special characters from the source data and the data is small enough for pandas to handle. I tried to download an entire stream but that failed so I downloaded a partial stream. The only glitch was a partial row of data on the final row but that is an artifact of a partial stream download, not the underlying data. Here's a link to one of the source files on cosmos that has caused issue:\n\nhttps:\/\/aad.cosmos15.osdinfra.net\/cosmos\/xbox.quality.prod\/shares\/IEBKS.PartnerProd\/cooked\/xcloud\/xCloudBi\/AdrianAntico\/Retention-\nEngagement\/LatencyServerFrameV2Raw_2022_01-12_14.tsv?property=info\n\nHere's the code I'm running in a compute instance to transfer data from blob storage to the compute instance directory:\n\nimport os\nimport azureml\nfrom azureml.core import Workspace, Dataset\nimport pandas as pd\n# Root Path\nRootPath = os.getcwd()\n# MetaData # I hid the values below but they work\nsubscription_id = '' \nresource_group = ''\nworkspace_name = ''\n# Create workspace \nworkspace = Workspace(subscription_id, resource_group, workspace_name)\ninlist = [\n  'LatencyServerFrameV2Raw_2022_01-12_14',\n  'LatencyServerFrameV2Raw_2022_01-15_18',\n  'LatencyServerFrameV2Raw_2022_01-19_22',\n  'LatencyServerFrameV2Raw_2022_01-23_26',\n  'LatencyServerFrameV2Raw_2022_01-27_30',\n  'LatencyServerFrameV2Raw_2022_01-31_03',\n  'LatencyServerFrameV2Raw_2022_02-04_07']\n# Import all data\nfor dd in inlist:  \n  dataset = Dataset.get_by_name(workspace, name=f\"{dd}.tsv\")\n  Path1 = RootPath + f\"\/Latency\/NanoLatencyRawData\/{dd}.csv\"\n  df = dataset.to_pandas_dataframe()                                                  # the error occurs on this step !!!!!\n  del dataset\n  df.to_csv(Path1)\n  del df\n\n\n\n\n\n\nUserErrorException: UserErrorException:\nMessage: Execution failed in operation 'to_pandas_dataframe' for Dataset(id='7cea1b1e-30df-4536-a859-d0931e52962a', name='LatencyServerFrameV2Raw_2022_02-04_07.tsv', version=3, error_code=ScriptExecution.StreamAccess.Validation,error_message=ScriptExecutionException was caused by StreamAccessException.\nStreamAccessException was caused by ValidationException.\nUnable to read file using Unicode (UTF-8). Attempted read range 230686720:251658240. Lines read in the range 5597. Decoding error: [REDACTED]\nFailed due to inner exception of type: DecoderFallbackException\n| session_id=c27e97a1-bdc7-4216-ba31-c804c5570ae7) ErrorCode: ScriptExecution.StreamAccess.Validation\nInnerException\nError Code: ScriptExecution.StreamAccess.Validation\n\n\n\n\ndataset\n\n\n{\n\"source\": [\n\"('retention_engagement_dimention', '\/local\/data\/cooked\/xcloud\/xCloudBi\/AdrianAntico\/Retention-Engagement\/LatencyServerFrameV2Raw_2022_02-04_07.tsv')\"\n],\n\"definition\": [\n\"GetDatastoreFiles\",\n\"ParseDelimited\",\n\"DropColumns\",\n\"SetColumnTypes\"\n],\n\"registration\": {\n\"id\": \"7cea1b1e-30df-4536-a859-d0931e52962a\",\n\"name\": \"LatencyServerFrameV2Raw_2022_02-04_07.tsv\",\n\"version\": 3,\n\"workspace\": \"Workspace.create(name='xCloudML', subscription_id='09b5fdb3-165d-4e2b-8ca0-34f998d176d5', resource_group='xCloudData')\"\n}\n}\n\n\nValidation Error Code: InvalidEncoding\nValidation Target: TextFile\nFailed Step: 10a002a3-6c2b-4173-9b00-43cb4d8d0011\nError Message: ScriptExecutionException was caused by StreamAccessException.\nStreamAccessException was caused by ValidationException.\nUnable to read file using Unicode (UTF-8). Attempted read range 230686720:251658240. Lines read in the range 5597. Decoding error: Unable to translate bytes [EF] at index 382 from specified code page to Unicode.\nUnable to translate bytes [EF] at index 382 from specified code page to Unicode.\n| session_id=c27e97a1-bdc7-4216-ba31-c804c5570ae7\nErrorResponse\n{\n\"error\": {\n\"code\": \"UserError\",\n\"message\": \"Execution failed in operation 'to_pandas_dataframe' for Dataset(id='7cea1b1e-30df-4536-a859-d0931e52962a', name='LatencyServerFrameV2Raw_2022_02-04_07.tsv', version=3, error_code=ScriptExecution.StreamAccess.Validation,error_message=ScriptExecutionException was caused by StreamAccessException.\\n StreamAccessException was caused by ValidationException.\\n Unable to read file using Unicode (UTF-8). Attempted read range 230686720:251658240. Lines read in the range 5597. Decoding error: [REDACTED]\\n Failed due to inner exception of type: DecoderFallbackException\\n| session_id=c27e97a1-bdc7-4216-ba31-c804c5570ae7) ErrorCode: ScriptExecution.StreamAccess.Validation\"\n}\n}",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-14T04:48:26.917Z",
                "Answer_score":0,
                "Answer_body":"@AdrianAnticoTEKsystemsInc-1526 Thanks for the question. Can you please add more details about the Azure SDK version that you are trying. Could you check what version of azureml-dataprep is installed in your python environment?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"FileNotFoundError: [Errno 2] No such file or directory: '\/tmp\/tmpqie8i33i\/MLmodel' - Tutorial: Score machine learning models with PREDICT in serverless Apache Spark pool",
        "Question_creation_time":1643645716927,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/716755\/filenotfounderror-errno-2-no-such-file-or-director.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":16,
        "Question_score":0,
        "Question_body":"Hello,\n\nI am following the tutorial score machine learning models using PREDICT.\n\nI receive the following error: FileNotFoundError: [Errno 2] No such file or directory: '\/tmp\/tmpqie8i33i\/MLmodel'\n\nIn a previous post it was advised to ensure to upload the mlflow folder to AML, not the parent folder to AML.\n\nCould I get a bit more clarity on these steps as I was unable to solve my issue.\n\nThanks in advance,\n\nAdam\n][3]",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-01T11:42:25.703Z",
                "Answer_score":0,
                "Answer_body":"@AdamNevin-8126 After checking the referenced thread I believe @PRADEEPCHEEKATLA-MSFT is referring to uploading your model folder to Azure ML workspace and register it as a model.\n\nIf you are using AML Model as seen in the model_uri parameter above I think you need to navigate to ml.azure.com and register the model from the models tab. Then use the model name and appropriate version for the AML_MODEL_URI env variable.\n\nEx:\n\n AML_MODEL_URI = \"aml:\/\/test1:1\"\n\n\n\n\nIf all the steps to register and authenticate the AML workspace mentioned in the earlier part of the document are run successfully then I think this should work.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Request GPU Quota increase",
        "Question_creation_time":1615999382250,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/319120\/request-gpu-quota-increase.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"For my Machine Learning Experiments I need a dedicated VM with GPU. They are not available in my region (only low priority VMs). The system tells me to request a quota increase but if I go to the quota increase support page I can only select additional CPU's not a GPU for a dedicated VM. How do I request a GPU quota increase?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-18T00:57:11.537Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nSorry for the confuse description. Could you please try as below with \"Machine Learning Service\" and describe your need with the support engineer? I am also checking internally to see if there any direct way to increase the quota.\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Real-time inferencing with azure ml model and send output to databricks",
        "Question_creation_time":1644441202260,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/729370\/real-time-inferencing-with-azure-ml-model-and-send.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi,\nI've built and registered a basic ml model in azure ml studio and I will get an aks cluster for the purpose of doing real-time inferencing with the model. So our pipipline would be we get the real time data from eventhub in databricks and store it into datalake(datastore) near real-time then azure ml model will get the input data from datalake, inference the data and generate output and send the output back to the databricks. and finally we want to visualize the output in powerbi.\nBut I'm just wondering if it's possible to do it as I'm new to azure ml. I was thinking to use stream analytics but seems like I can't get an approval from my company for using stream analytics for this pipeline.\n\nAnyone who could help me on this would be every much appreciated. and I'd appreicate it if you could tell me how to connct azure ml model and databricks using API as well.\n\nThank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-10T08:45:17.373Z",
                "Answer_score":0,
                "Answer_body":"@jingyeongyu-5737 Thanks, In Azure Machine Learning, you can write output data directly to Azure Blob Storage, Azure Data Lake Storage Gen 1, Azure Data Lake Storage Gen 2, Azure FileShare without going through extra DataTransferStep. Learn how to use OutputFileDatasetConfig to achieve that with sample notebooks here.**",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to import Microsoft.RelInfra.Common.Exception so that it could be properly handled?",
        "Question_creation_time":1643997368443,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/723386\/how-to-import-microsoftrelinfracommonexception-so.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I am working on creating a Pipeline Endpoint and want to handle the exception if incorrect Pipeline endpoint name is passed to the constructor:\n\nPipelineEndpoint.get(workspace, name='xyz')\n\nIn this case, I am seeing a \"Microsoft.RelInfra.Common.Exceptions.ErrorResponseException:PipelineEndpoint name xyz not found in workspace\".\n\nFrom where to import this exception class??\n\nPlease advise.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-05T04:24:34.057Z",
                "Answer_score":2,
                "Answer_body":"@ShivapriyaKatta-8600\n\nI think the first thing is make sure your endpoint_pipeline is set up correctly.\n\nYou can try to return all active pipeline to see if the pipeline you want to call is in the list:\n\n endpoint_list = PipelineEndpoint.list(workspace=ws, active_only=True)\n endpoint_list\n\n\n\nI also attach the guidance of how to deploy a pipeline here for your reference:\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-setup-versioned-pipeline-endpoints.ipynb\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Hyperdrive warm start error",
        "Question_creation_time":1644098638560,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/723990\/azure-ml-hyperdrive-warm-start-error.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I've attempted to do a warm start on an Azure ML Hyperdrive run, following this tutorial how-to-tune-hyperparameters\n\nI am given the following error after 15 minutes: Hyperdrive is unable to further process the experiment due to some internal error. Experiment has been marked as failed. Reason: MaxDeliveryCountExceeded, ErrorDescription: Message could not be consumed after 5 delivery attempts.\n\nThis is the only feedback in the hyperdrive.txt log, and it is the only log with anything in it. Does anyone have any insight into what this error could mean and how to resolve it?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Model state unhealthy : AzureML",
        "Question_creation_time":1643298335143,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/712704\/model-state-unhealthy-azureml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"I have trained a model using Azure AutoML and when I am trying to deploy it I am getting unhealthy model state. Not sure what the problem might be. could you help out?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"After deploying getting error 502 while generating forecast in Azure Ml through Code",
        "Question_creation_time":1644405738470,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/728627\/after-deploying-getting-error-502-while-generating.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"Hi,\nAfter doing the deployment task, i am not able to generate the forecast through code pipeline of Azure Ml.\nthis is my run.py file:\n\ndef run(df, url, api_key):\nallowSelfSignedHttps(True)\nif api_key == 'uu':\napi_key = ''\ndata = []\nfor index, row in list(df.iterrows()):\ndata.append(dict(row))\n\n data = {\n     \"data\": data\n }\n body = str.encode(json.dumps(data))\n headers = {'Content-Type': 'application\/json',\n            'Authorization': ('Bearer ' + api_key)}\n req = urllib.request.Request(url, body, headers)\n print(url, api_key)\n try:\n     response = urllib.request.urlopen(req)\n     result = response.read()\n     print(result)\n except urllib.error.HTTPError as error:\n     print(\"The request failed with status code: \" + str(error.code))\n     # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n     print(error.info())\n     # print(json.loads(error.read().decode(\"utf8\", 'ignore')))\n data = json.loads(json.load(response))\n df= pd.json_normalize(data[result])\n data = data.get('forecast', None)\n return data\n\n\n\n\nError: 502",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Execute R Script - characters not displaying on saved image",
        "Question_creation_time":1643900146447,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/721637\/execute-r-script-characters-not-displaying-on-save.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Updated this question with new information:\n\nUsing Azure ML Studio & Execute R Script to run some existing models. I need to generate outputs with saved plots which I am doing with the openxlsx package and saving the outputs to some azure cloud storage. This part all works well. The problem is that the plots do not have characters displayed correctly, instead they are \"squares\"\n\nI have recreated the problem with some repeatable code using the data in ggplot2. This is the relevant code snippet that I am running in an \"azureml_main\" function. This example I actually copied from another azure help page to keep things simple and compatible as possible : https:\/\/gallery.azure.ai\/Experiment\/Tutorial-Base-R-Graphics-in-AzureML-2\n\n   imageName <- \"testplot.png\"\n   png(imageName)\n   plot(price ~ carat, data = diamonds, main = \"Price vs Carat\")\n   dev.off()\n   wb <- createWorkbook()\n   addWorksheet(wb, \"testplotsheet\", gridLines = TRUE)\n   insertImage(wb, \"testplotsheet\", imageName)\n   saveWorkbook(wb, file = xlName, overwrite = TRUE)\n\n\n\nOn retrieving the saved excel workbook, this is what the image looks like\n\nThe problem is to get characters to display correctly. The same problem occurs in tiff, jpg svg formats. But pdf displays fonts! On further investigation I am wondering if there are actually any system fonts installed on this compute cluster machine because the folders \/usr\/lib\/share\/fonts & \/usr\/share\/fonts do not exist\n\nCan anyone at microsoft check & confirm this (seems a bit of an oversight?) or advise where the fonts are installed for this \"Execute R script\" machine\n\nHere are some data from the azureml instance sessionInfo\n\nR version 3.5.1 (2018-07-02)\nPlatform: x86_64-conda_cos6-linux-gnu (64-bit)\nRunning under: Ubuntu 18.04.6 LTS\n\nMatrix products: default\nBLAS: \/azureml-envs\/azureml_6ff64eff0a652bbe0bb1d84fc0884554\/lib\/R\/lib\/libRblas.so\nLAPACK: \/azureml-envs\/azureml_6ff64eff0a652bbe0bb1d84fc0884554\/lib\/R\/lib\/libRlapack.so\n\nlocale:\n[1] LC_CTYPE=C.UTF-8 LC_NUMERIC=C LC_TIME=C.UTF-8\n[4] LC_COLLATE=C.UTF-8 LC_MONETARY=C.UTF-8 LC_MESSAGES=C.UTF-8\n[7] LC_PAPER=C.UTF-8 LC_NAME=C LC_ADDRESS=C\n[10] LC_TELEPHONE=C LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C\n\nattached base packages:\n[1] stats graphics grDevices utils datasets methods base\n\nother attached packages:\n[1] httr_1.4.1 RODBC_1.3-16 tibble_3.0.1 tidyr_1.0.2\n[5] stringr_1.4.0 data.table_1.12.8 azuremlsdk_1.10.0 openxlsx_4.2.5\n[9] dplyr_0.8.5 jsonlite_1.6.1 reticulate_1.12\n\nloaded via a namespace (and not attached):\n[1] Rcpp_1.0.8 magrittr_1.5 tidyselect_1.0.0 lattice_0.20-41\n[5] R6_2.4.1 rlang_1.0.1 tools_3.5.1 grid_3.5.1\n[9] ellipsis_0.3.0 assertthat_0.2.1 lifecycle_0.2.0 crayon_1.3.4\n[13] Matrix_1.2-18 zip_2.2.0 purrr_0.3.4 vctrs_0.2.4\n[17] glue_1.4.0 stringi_1.4.3 compiler_3.5.1 pillar_1.4.3\n[21] pkgconfig_2.0.3",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-07T08:12:30.023Z",
                "Answer_score":0,
                "Answer_body":"@YutongTie-MSFT apologies for the tag, but no other responders yet. Any further suggestions or insight into why this problem is occurring? I have done extensive research into this and it must be something to do with the available encoding\/fonts on the Ubuntu setup on ML Studio & what the code is attempting to use in the png encoding. Your suggestion made a lot of sense, but didn't seem to change the environment at all? Any idea why? It's also incredibly difficult to troubleshoot because in this black-box Azure ML studio I do not have access to a console to run code segments",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-02-08T10:56:36.127Z",
                "Answer_score":0,
                "Answer_body":"update : there are no fonts installed in R or seemingly on the container\/image which is launched by \"Execute R script\". The system contains no fonts folder or \/etc\/fonts\/fonts.conf file, which is what it should be for ubuntu. R installation does not have \"sysfonts\" library and it can't be installed due to a missing file \"zlib\". if sysfonts could be installed I could use showtext, or possibly resolve the issue\n\nI've spent a week on this trying to get execute r task to save an image with characters, but it doesn't seem possible\n\nUpdate : this image\/compile needs to be updated, the R version is from 2018, and missing fonts. FYI, this refers to the \"cluster\" version\"",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Subscription Cost",
        "Question_creation_time":1644315390737,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/726898\/azure-subscription-cost.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":19,
        "Question_score":1,
        "Question_body":"my azure subscription cost is decreasing everyday. Knowing that i have deleted everything from my workspace and in my azureml workspace don't have any cluster, I don't know why it is still decreasing.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-08T10:41:29.22Z",
                "Answer_score":1,
                "Answer_body":"If you want to review your costs and what resources are being charged, then the Cost Analysis blade will allow you to drill down work this out. Please let us know if this helps",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Executing pipeline in AML from Logic Apps stopped working",
        "Question_creation_time":1639583614587,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/664994\/executing-pipeline-in-aml-from-logic-apps-stopped.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":31,
        "Question_score":1,
        "Question_body":"Hello! I have a few logic apps for my company that trigger ML pipelines at specific time intervals. I followed the documentation on how to set up a logic app and trigger pipeline to the letter and for the past 2 months everything was working fine and my logic apps were able to trigger the ML pipelines with no issues. However, on 12\/08\/2021 at exactly in between 1:30PM - 2:30PM CST, every single pipeline starting failing and they continue to do so up until now. I noticed that we are now receiving this error on every execution:\n\n\"UserError: Response status code does not indicate success: 400 (User starting the run is not an owner or assigned user to the Compute Instance). User starting the run is not an owner or assigned user to the Compute Instance\"\n\nMy Logic apps are setup with \"Managed Identities\" of Owners (like the documentation explains). My last successful run for all the logic apps was on 12\/08 before 1:30PM CST. Did something change on both Azure Logic Apps and Azure ML that is now causing this issue? Any help is greatly appreciated as this is impacting my company's business.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-16T21:36:31.763Z",
                "Answer_score":0,
                "Answer_body":"I ran into this same issue in a slightly different context. I didn't manage to figure out the root cause but managed to resolve it in practice by standing up a Compute Cluster instead of a Compute Instance (see https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-attach-compute-cluster?tabs=python)",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learing - Batch Scoring with ParallelRunConfig output_action='summary_only'",
        "Question_creation_time":1643895433557,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/721542\/azure-machine-learing-batch-scoring-with-parallelr.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello,\n\nI have deployed a batch inferencing service and I want to save minibatch results in a json format. My understanding after reading the ParallelRunConfig documentation is that for output_action=\"append_row\" you can return only list or pandas dataframe objects in the run() function.\nI have tried to change output_action='summary_only' but nothing is saved into the datastore anymore.\nI could not find any examples on how to use output_action='summary_only' except the below explanation, which does not give details on how to store the output:\n\n'append_row' \u2013 All values output by run() method invocations will be aggregated into one unique file named parallel_run_step.txt that is created in the output location.\n'summary_only' \u2013 User script is expected to store the output by itself. An output row is still expected for each successful input item processed. The system uses this output only for error threshold calculation (ignoring the actual value of the row).\n\nDo you know how can I save the results of each minibatch of the run() function as a json into the datastore?\n\nThank you,\nDaniel",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"change location of Azure ML workspace?",
        "Question_creation_time":1643794457387,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/719406\/change-location-of-azure-ml-workspace.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi , i would like to know if it is possible to change the location of AzureML workspace after creating it ?\nRight now i do not find any option to change it manually on the UI. We want to move the server location to a different country.\nAny leads would be helpful. Thanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-02T10:00:22.067Z",
                "Answer_score":1,
                "Answer_body":"Based on the below document, ML workspace can't be moved across region. Probably, you will have to create a new resource in target region and move artifacts \/ pipelines \/ child resources to it (not so familiar with ML)\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/azure-resource-manager\/management\/move-support-resources#microsoftmachinelearning\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-move-workspace#limitations\n\nPlease don't forget to Accept Answer and Up-vote if the response helped -- Vaibhav",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How to get Model ID of the Latest Version registered in Azure Machine Learning Service Model Registry using az ml cli?",
        "Question_creation_time":1643903626503,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/721792\/how-to-get-model-id-of-the-latest-version-register.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello MS team,\n\nI have registered an ML model in the AML workspace using an Azure Machine learning pipeline and triggered the main control script of the pipeline by linking the repo present in Azure DevOps to the AML workspace(using Service principal).\n\nHow do I download the latest version of the model from the AML workspace to the \"Artifacts\" folder in Azure DevOPs?\n\nAny help is appreciated please.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-04T00:19:45.587Z",
                "Answer_score":0,
                "Answer_body":"@ShivapriyaKatta-8600\n\nI think you are mentioning how to get the latest version of model and download the model in az ml.\n\nThere are 2 steps, one is list the model to get the model ID you want, two is download the model.\n\naz ml model list\nList models in the workspace.\n\n az ml model list [--dataset-id]\n                  [--latest]\n                  [--model-name]\n                  [--path]\n                  [--property]\n                  [--resource-group]\n                  [--run-id]\n                  [--subscription-id]\n                  [--tag]\n                  [--workspace-name]\n                  [-v]\n\n\n\nOptional Parameters\n--dataset-id\nIf provided, will only show models with the specified dataset ID.\n\n--latest -l\nIf provided, will only return models with the latest version.\n\n--model-name -n\nAn optional model name to filter the list by.\n\n--path\nPath to a project folder. Default: current directory.\n\n--property\nKey\/value property to add (e.g. key=value ). Multiple properties can be specified with multiple --property options.\n\n--resource-group -g\nResource group corresponding to the provided workspace.\n\n--run-id\nIf provided, will only show models with the specified Run ID.\n\n--subscription-id\nSpecifies the subscription Id.\n\n--tag\nKey\/value tag to add (e.g. key=value ). Multiple tags can be specified with multiple --tag options.\n\n--workspace-name -w\nName of the workspace containing models to list.\n\n-v\nVerbosity flag.\n\naz ml model download\nDownload a model from the workspace.\n\n az ml model download --model-id\n                      --target-dir\n                      [--overwrite]\n                      [--path]\n                      [--resource-group]\n                      [--subscription-id]\n                      [--workspace-name]\n                      [-v]\n\n\n\n\nRequired Parameters\n--model-id -i\nID of model.\n\n--target-dir -t\nTarget directory to download the model file to.\n\nOptional Parameters\n--overwrite\nOverwrite if the same name file exists in target directory.\n\n--path\nPath to a project folder. Default: current directory.\n\n--resource-group -g\nResource group corresponding to the provided workspace.\n\n--subscription-id\nSpecifies the subscription Id.\n\n--workspace-name -w\nName of the workspace containing model to show.\n\n-v\nVerbosity flag.\n\nHope this helps!\n\nPlease kindly accept the answer if you feel helpful, thank you!\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-02-04T03:33:57.637Z",
                "Answer_score":0,
                "Answer_body":"Thanks a lot for the response....but I am trying to get the parameter \"--model-id\" as a variable and pass it into the download command, trying to do something like:\n\naz ml model download --model-id $(az ml model list --query \"[].{ID:id}[0].ID\" -o tsv --name saved_model --resource-group $(rg_name) --workspace-name $(ws_name)) --target-dir .\/models --resource-group $(rg_name) --workspace-name $(ws_name)\n\nNot working though...any idea?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"RunHistory finalization failed: ServiceException: Code: 400",
        "Question_creation_time":1643880887487,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/721282\/runhistory-finalization-failed-serviceexception-co.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I am trying to log my model metrics and hyperparam space in the run metrics.\nI tried to also reduce the variable lengths throughout but still get consistently the following error:\ni find in the documentation that we can only have 15 columns for every row in the run metric.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/resource-limits-quotas-capacity . But is there a way to increase this capacity? Thanks\n\nIs there a way to increase this capacity?\n\n RunHistory finalization failed: ServiceException:\n  Code: 400\n  Message: (UserError) A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.\n  Details:\n  A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.\n  A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.\n  A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.\n  A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.\n  A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.\n  A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.\n  A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.\n  A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.\n  A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.\n  A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.\n  A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.\n  A field of the entity is over the size limit. FieldName=MetricV2Dto.Columns\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.\n  A field of the entity is over the size limit. FieldName=MetricV2Value.Data\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.\n  A field of the entity is over the size limit. FieldName=MetricV2Value.Data\/Count, Limit=15, Size=16. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.\n  A field of the entity is over the size limit. FieldName=MetricV2Value.Data\/Count, Limit=15, Size=16. See",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-03T15:44:22.357Z",
                "Answer_score":0,
                "Answer_body":"@AntaraDas-4298 Some of the limits are soft limits which can be increased for a subscription or a workspace. Usually these limits can be increased by using a support case with appropriate usage scenario mentioned in the details of the case. Once the case is submitted it is reviewed by the service team and the limits are increased if it is possible to do so.\n\nPlease create a support case from Azure portal and use the following settings from the drop downs and mention the summary detail as \"Increase limit of columns per metric row\"\n\nIf you do not have a valid support subscription we could help you with a one time free support case that could help you to create one for this scenario.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"'message': 'User errors were found in at least one of the child runs.'",
        "Question_creation_time":1643808927707,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/719823\/39message39-39user-errors-were-found-in-at-least-o.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"image_config_yolov5 = AutoMLImageConfig(task=ImageTask.IMAGE_OBJECT_DETECTION,\ncompute_target=compute_target,\ntraining_data=training_dataset,\nvalidation_data=validation_dataset,\nhyperparameter_sampling=GridParameterSampling({'model_name': choice('yolov5')}),\niterations=1)\nautoml_image_run = experiment.submit(image_config_yolov5)\nautoml_image_run.wait_for_completion(wait_post_processing=True)\n\n\n\n\nwhile running this code am getting this error. Am not getting what this error means.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Cannot find created compute instance",
        "Question_creation_time":1642537079270,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/700065\/cannot-find-created-compute-instance.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I have created a compute instance and it is not available at the compute instances list. Instead it shows a \"create new\" button.\nI can see the instance at usage+quotas but when I click on it , it says the compute instance cannot be found.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-19T06:21:07.94Z",
                "Answer_score":0,
                "Answer_body":"@ManolisDagdilelis-4594 Clicking on the compute name from the usage+quotas blade should redirect you to ml.azure.com compute page to use the compute instance\/clusters. In your case it seems that the instance is used in quota but is actually not available to use. It may be an orphaned instance that needs to be reported.\n\nYou can click on New Support request and report this issue from Azure portal or use the smiley icon on the top right corner of ml.azure.com and report the case with the screen shots. This will help the service team to check the issue from backend. Meanwhile, do you see the same issue for a new compute instance that you create from ml.azure.com?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"The azure cli command \"az ml attach folder\" is directly adding .azureml directory to .amlignore , so where to put config.json when using Azure devops pipeline to submit script to aml workspace?",
        "Question_creation_time":1643414978747,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/714713\/the-azure-cli-command-34az-ml-attach-folder34-is-d.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hello MS team,\n\nI am using Azure devOps pipeline to submit a control script to the Azure-ML workspace. This control script in turn kicks off the Azure-ML pipeline containing pythonscriptsteps and hyperdrive step.\n\nMy directory structure:\n\n.\n\u251c\u2500\u2500\u2500.vscode\n\u251c\u2500\u2500\u2500Automation\n\u251c\u2500\u2500\u2500Build\n\u2514\u2500\u2500\u2500Source\n\u251c\u2500\u2500\u2500.azureml\n\u251c\u2500\u2500\u2500.vscode\n\u251c\u2500\u2500\u2500amlcode\n\u2502 \u251c\u2500\u2500\u2500projectcode\n\u2502 \u2514\u2500\u2500\u2500pycache\n\u251c\u2500\u2500\u2500config\n\u251c\u2500\u2500\u2500Data\n\u251c\u2500\u2500\u2500setup\n\u251c\u2500\u2500\u2500tests\n\u2502 \u251c\u2500\u2500\u2500.pytest_cache\n\u2502 \u2502 \u2514\u2500\u2500\u2500v\n\u2502 \u2502 \u2514\u2500\u2500\u2500cache\n\u2502 \u2514\u2500\u2500\u2500pycache\n\u2514\u2500\u2500\u2500pycache\n\n\n\n\nSo here one of the azure cli task in Azure DevOps pipeline uses:\n\naz ml folder attach -w $(azureml.workspaceName) -g $(azureml.resourceGroup)\n\nThis command attaches my whole directory to the AML workspace and automatically creates \".amlignore\" and \".azureml\" is automatically added to that.\n\nSo it is throwing an authentication error as the config.json() is not found because it is generally put in the path \/.azureml.\n\nWhere to put the config.json() then? What is the best practice?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-31T07:16:57.497Z",
                "Answer_score":1,
                "Answer_body":"@ShivapriyaKatta-8600 The command az ml folder attach will create the directories and add the config file to .azureml to ensure the workspace resources are easily accessible. You can lookup the note section of the command for reference.\n\nThis command creates a .azureml subdirectory that contains example runconfig and conda environment files. It also contains a config.json file that is used to communicate with your Azure Machine Learning workspace.\n\n\n\n\nThe authentication error in your case could be because az login command might have been missed which allows the cli to authenticate interactively or service principal or MI and then run rest of the commands. You can try to run this and check if the attach works successfully.\n\nAlso, with the devops pipeline I am not sure if az devops login is required to be run but if the above command fails even after az login authentication you can try az devops login.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-02-01T05:55:55.68Z",
                "Answer_score":0,
                "Answer_body":"Thank you...Got the issue resolved! The command \"az ml folder attach\" won't override the \".amlignore\" if the user creates it beforehand. So I just created \".amlignore\" how I want it to be and removed \".azureml\" from it.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-02-01T06:49:04.323Z",
                "Answer_score":0,
                "Answer_body":"Thanks a lot!... I understood what \"az ml folder attach\" is doing (have been reading Azure docs), what I wanted is when I do the following:\n\nSubmit a script using Service principal from Azure git repo (where my code lies), what is the point of using \"az ml folder attach\"?\n\nbecause anyway when I am submitting script from my local PC or from Azure DevOps (without \"az ml folder attach\"), the script runs.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Random Forest",
        "Question_creation_time":1642600143767,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/701327\/random-forest.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I am currently working on Career Guidance prediction using Machine Learning.\n\nThe dataset has 38 features. For feature selection I tried using mutual_info_classif for getting the mutual information of my features and got the list of important features.\n\nThe Second approach I followed is using SelectKBest with mutual_info_classif as my score_func. On this approach I got some other list of features.\n\nIs it normal to get different results ?\nCan anyone please help me out?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-20T04:02:53.047Z",
                "Answer_score":0,
                "Answer_body":"Hello @PriyeshDave-5166\n\nThanks for reaching out to us here. Based on my understanding, if you keep X, Y the same, and you are using sklearn.feature_selection.SelectKBest(score_func= mutual_info_classif , *, k= n) the result should be the same.\n\nAre you manually rank the feature with mutual_info_classif score? The SelectKBest function is basically return the K highest feature based on the X and Y.\n\nIf this is not your case, I would highly recommend you to check with Scikit-learn team by email : https:\/\/mail.python.org\/mailman\/listinfo\/scikit-learn\n\nOr forum: https:\/\/stackoverflow.com\/questions\/tagged\/scikit-learn\n\n\n\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Best Practise\/How to deploy one algorihtm many models",
        "Question_creation_time":1642980954963,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/706471\/best-practisehow-to-deploy-one-algorihtm-many-mode.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Greetings,\nI plan to use LightGBM for forecasting. However, I could have upwards of 3000 nodes I plan to forecast. This would mean tuning them all initially and then training them as and when they require a forecast. I wanted to use Azure ML and call it as a service but not seeing from the documentation or searches for the best way to deploy a single algorithm, use it to tune and then later call it for training. Is this something Azure supports or am I better just creating my own web app and API to that than using Azure ML Studio?\n\nAny help would be greatly appreciated.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-24T01:43:30.927Z",
                "Answer_score":0,
                "Answer_body":"@RayAdams-4768\n\nHello,\n\nThanks for reaching out to us. I think you are mentioning how to deploy model you created in Azure Machine Learning Studio as a web service so that you can call the endpoint for your forecast.\n\nPlease see this guidance for how to do it in Azure Machin Learning studio: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning - error during the creation Create a control script",
        "Question_creation_time":1643753509637,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/718873\/azure-machine-learning-error-during-the-creation-c.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello, I am reproducing this tutorial https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-hello-world \/ Create a control script. The next observations appear in the console.\n\nI will thank you if some ideas are shared with me to face this issue.\n\nRegards",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-02-02T08:04:16.33Z",
                "Answer_score":0,
                "Answer_body":"@Anth0nyCamp0s I believe the error is because in the config command you are using the script parameter hello.py which is in .\/src directory but because you are already in .\/src directory on the terminal and the source_directory parameter also mentions to use .\/src as the path to the file the following error is indicated in the message.\n\n\n\n\nIf you navigate back to get-started directory in your terminal and run the script run-hello.py your experiment should be created successfully.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning - Deployment of real-time endpoint works in westeurope but fails in eastus.",
        "Question_creation_time":1643123451253,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/709396\/azure-machine-learning-deployment-of-real-time-end.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I encountered the following situation when I run a Python real-time deployment Notebook script in 2 different Resource Groups, one is based in eastus and the other in westeurope:\nIt works for the westeurope Resource Group: \nWhen I run it in eastus Resource Group I get the following error: \n\nNotebook configuration: Standard_DS12_v2 (4 cores, 28 GB RAM, 56 GB disk) and azureml.core.VERSION==1.34.0 for both Resource Groups.\n\nHas anyone encountered this problem before?\n\nLet me know if any other details are needed.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-26T08:40:24.997Z",
                "Answer_score":0,
                "Answer_body":"Hi, based on a similar post, can you confirm that you've registered the model?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-01-26T08:58:00.213Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nYes, the model is registered.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"ModuleNotFoundError: No module named 'azureml' in ML Studio",
        "Question_creation_time":1643140351313,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/709861\/modulenotfounderror-no-module-named-39azureml39-in.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I am learning Azure ML from Microsoft tutorials, here. The third tutorial is giving me the following error.\n\n [stderr]Traceback (most recent call last):\n [stderr]  File \"train.py\", line 8, in <module>\n [stderr]    from azureml.core import Run\n [stderr]ModuleNotFoundError: No module named 'azureml'\n [stderr]\n\n\n\nWorking with Azure ML Studio and submitting the code to the environment, I am unable to find how to resolve this error.\n\nI have checked that the package is installed (running on Azure ML studio so this is a basic assumption, but I have tested as well). Following is the code 'run-pytorch.py' which calls the script 'train.py'\n\n # run-pytorch.py\n from azureml.core import Workspace\n from azureml.core import Experiment\n from azureml.core import Environment\n from azureml.core import ScriptRunConfig\n    \n if __name__ == \"__main__\":\n     ws = Workspace.from_config()\n     experiment = Experiment(workspace=ws, name='day1-experiment-train')\n     config = ScriptRunConfig(source_directory='.\/src',\n                              script='train.py',\n                              compute_target='cpu-cluster')\n    \n     # set up pytorch environment\n     env = Environment.from_conda_specification(\n         name='pytorch-env',\n         file_path='pytorch-env.yml'\n     )\n     config.run_config.environment = env\n    \n     run = experiment.submit(config)\n    \n     aml_url = run.get_portal_url()\n     print(aml_url)\n     print('Success...!!!')\n\n\n\nThe code snippet for train.py is as follows\n\n # train.py\n import os\n import argparse\n import torch\n import torch.optim as optim\n import torchvision\n import torchvision.transforms as transforms\n from model import Net\n from azureml.core import Run\n ...\n ...",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-26T01:08:44.91Z",
                "Answer_score":1,
                "Answer_body":"@ShanJaffry-1153\n\nSorry for your experience and thanks for reaching out to us, I am able to reproduce your issue with my new create compute-cpu, the resolution is easy to install the azureml in your compute at the terminal under your root user.\n\n pip install azureml\n\n\n\n\nJust in case, I encounter pyarrow error after that, the resolution is uninstall the pyarrow 4.0 and install pyarrow 3.0.0 instead as below:\n\n pip uninstall pyarrow\n        \n pip install pyarrow==3.0.0\n\n\n\nI have forwarded this bug to product group and hope to make this process smoother.\n\nPlease kindly accept the answer if you feel this is helpful. Thank you.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-01-26T06:17:11.51Z",
                "Answer_score":0,
                "Answer_body":"Thanks for your answer.\n\nI tried what you mentioned, but it does not work, unfortunately. Same error.\nFirst of all, it says that the 'Requirement already satisfied'.\n\nSecondly, I can see that azureml is already installed. Furthermore, as I mentioned earlier, that it is running in other cases. Not running for this particular case ! I appreciate your help.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"azure ML how should my score script look like to deploy my ml model",
        "Question_creation_time":1643317719657,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/713048\/azure-ml-how-should-my-score-script-look-like-to-d.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\nI've created made an basic ml model just for the demo purpose and\nhere is the sample output from the model that I want to send to the eventhub from azure ml,\n\nI know I need score.py script when deploying the model and I wonder how the score script should be like to get the desired output that I want.\n\nany help would be very appreciated.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-28T06:31:01.693Z",
                "Answer_score":1,
                "Answer_body":"@YuHazelAPEXSYSTEMSLLC-5897 If you have already able to test your model then your scoring script is essentially should try to load the model and define a input and output schema based on the input\/output value types. This will validate your input data and generate a swagger document when you deploy your model. For example, I think your scoring script can be defined as below:\n\n import joblib\n import numpy as np\n import os\n    \n from inference_schema.schema_decorators import input_schema, output_schema\n from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n    \n    \n # The init() method is called once, when the web service starts up.\n #\n # Typically you would deserialize the model file, as shown here using joblib,\n # and store it in a global variable so your run() method can access it later.\n def init():\n     global model\n    \n     # The AZUREML_MODEL_DIR environment variable indicates\n     # a directory containing the model file you registered.\n     model_filename = 'your_model.pkl'\n     model_path = os.path.join(os.environ['AZUREML_MODEL_DIR'], model_filename)\n    \n     model = joblib.load(model_path)\n    \n    \n # The run() method is called each time a request is made to the scoring API.\n #\n # Shown here are the optional input_schema and output_schema decorators\n # from the inference-schema pip package. Using these decorators on your\n # run() method parses and validates the incoming payload against\n # the example input you provide here. This will also generate a Swagger\n # API document for your web service.\n @input_schema('data', NumpyParameterType(np.array([[0.1, 1.2, 2.3, 3.4, 4.5, 5.6, 6.7, 7.8, 8.9, 9.0]])))\n @output_schema(NumpyParameterType(np.array([4429.929236457418])))\n def run(data):\n     # Use the model object loaded by init().\n     result = model.predict(data)\n    \n     # You can return any JSON-serializable object.\n     return result.tolist()\n\n\n\nRef: Scoring script from Azure ML Notebooks github repo.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"how do I deploy a ml model with cpu cluster?",
        "Question_creation_time":1643474757900,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/715101\/how-do-i-deploy-a-ml-model-with-cpu-cluster.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi..I'm new to Azure ML and I've been trying to deploy a ml model I've created and registered.\nSince I can't deploy a model to aci or aks and don't have those clusters,I need to deploy the model using my cpu cluster.\nI'm looking up docs but couldn't find any tutorial for deploying a model with cpu cluster.\nSo I wonder if any of azure ml experts here could help me with doing this..\n\nI would appreciate your help",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-31T11:08:25.56Z",
                "Answer_score":0,
                "Answer_body":"@YuHazelAPEXSYSTEMSLLC-5897 Thanks for the question. Here is document to create compute cluster.\n\nHere is the notebook sample to Register model and deploy locally.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is it possible to parameterize the sharable url of an azure ml notebook?",
        "Question_creation_time":1643398754623,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/714542\/is-it-possible-to-parameterize-the-sharable-url-of.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I would like to share the link to a Jupyter notebook (stored in azure ml studio) with the parameters of the notebook already updated. I see I can automatically get a sharable link for the notebook. Is it possible to parameterize this link? If not, is there an equivalent alternative?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-31T14:50:27.643Z",
                "Answer_score":0,
                "Answer_body":"Hi, are you looking for something similar to Run with Parameters feature in Azure Data Studio?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"I got an error that the kernel could not be found in Azure ml.",
        "Question_creation_time":1643096138537,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/708659\/i-got-an-error-that-the-kernel-could-not-be-found.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"When I was using a compute instance with azure ml, I got the following message:\n\nThe kernel for python 3.8 azure ml was not available.\nPlease tell me the cause and solution.\nThe instance I was using is:\nVirtual machine size\nStandard_DS11_v2 (2 cores, 14 GB RAM, 28 GB disk)",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-25T12:23:23.78Z",
                "Answer_score":0,
                "Answer_body":"@kk-7094 Yes, by default the python 3.8 version of kernel is not available on Azure ML notebooks. You can however create your custom kernel and use it from the dropdown for any your notebooks by following some simple steps:\n\nUse the terminal of your compute by clicking the open terminal option.\n\nRun the following commands on the terminal using conda to create a python 3.8 environment and creating a kernel which can be used with your notebook.\n\nconda create -n py38 python=3.8\nconda activate py38\n\nconda install pip\nconda install ipykernel\npython -m ipykernel install --user --name python38 --display-name \"Python 38\"\n\nStop and start your compute instance and load the drop down to see the new kernel. Stopping and starting the kernel is available from the notebook screen as seen in the first screen shot\n\nPrint the version in a cell to confirm if the desired kernel or python version is picked up.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is it possible to migrate a completed Azure data labelling project to Custom Vision ?",
        "Question_creation_time":1643343651050,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/713444\/is-it-possible-to-migrate-a-completed-azure-data-l.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I've recently labelled approx. 3500 images for a multi-class classification project and wondered if I could use the Custom Vision service to train the data (for a prototype demo) ?\n\nIf not, is there a way to access the model created using the Auto Labelling feature and use it as an end point (In Javascript) ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-28T14:56:47.107Z",
                "Answer_score":0,
                "Answer_body":"@HamentPandya-0884 Thanks for the details. This feature is in Preview. AML and Custom Vision (Cog. services) worked on the integration , which would allow the customers to have their data labeled in AML and take it into Cog. service and vice versa.\n\nHere is link to the document for labeling project and Check out the Automate Custom Vision model creation with AutoML for Images: https:\/\/www.youtube.com\/watch?v=FPDCRSuAym0\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n- Want a reminder to come back and check responses? Here is how to subscribe to a notification\n- If you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Models not being registered when pipeline is triggered using REST endpoint",
        "Question_creation_time":1641571746503,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/687290\/models-not-being-registered-when-pipeline-is-trigg.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":8,
        "Question_score":2,
        "Question_body":"I have a pipeline with two python script steps. The first script performs some data cleaning, and the second one trains a model, saves it in the 'outputs' folder, and finally calls the Model.register() function to register the updated model file. Just to be clear, the registration is being done in the script that trains the model (which runs on the cloud), not the script that starts the experiment (which runs on my laptop).\n\nIt works as it should when I run the experiment using the Experiment.submit() function call, but when I run the published pipeline using the REST endpoint, the model doesn't get registered. I can see the REST call recorded as a new experiment, and the 'outputs' folder of the second step has a model file too. But the new model doesn't get registered for some reason.\n\nDoes anyone know what's going wrong here?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-27T08:01:04.413Z",
                "Answer_score":0,
                "Answer_body":"@DaveJ-4580 Thanks for the details and apologies for the late response. I think the problem is that you rely on AML background process to automatically upload content under .\/outputs to AML workspace.\nBut when the upload is not complete and we immediately call run.register_model which takes the content from AML workspace then the error will happen.\nTo avoid that situation, you can do it like this:\n- Persist model (joblib.dump) to a custom folder other than outputs\n- Manually run upload_file to upload the model AML workspace. Name the destination same name with your model file.\n- Then run run.register_model.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"machine learning conda env package(pyenchant)",
        "Question_creation_time":1643330999837,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/713217\/machine-learning-conda-env-packagepyenchant.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":13,
        "Question_score":1,
        "Question_body":"I have pip install pyenchant, but It doesn't seem to be working.\n\n\n\n\n\n\n\n\n\nIs there any other way?\nhttps:\/\/stackoverflow.com\/questions\/21083059\/enchant-c-library-not-found-while-installing-pyenchant-using-pip-on-osx\nI looked it up but do not know where to put it\nThanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-28T08:12:23.967Z",
                "Answer_score":0,
                "Answer_body":"@YongchaoLiuNeusoftAmericaInc-6769 Based on the error it looks like you also need to ensure the enchant C library is available to use for the package. Based on the pip install page of pyenchant, the package will not work directly out of the box using pip.\n\nIn general, PyEnchant will not work out of the box after having been installed with pip. See the Installation section for more details.\n\nSince you are using Linux, this is the guidance on the installation page.\n\nThe quickest way is to install libenchant using the package manager of your current distribution. PyEnchant tries to be compatible with a large number of libenchant versions. If you find an incompatibility with your libenchant installation, feel free to open a bug report.\n\n\nTo detect the libenchant binaries, PyEnchant uses ctypes.util.find_library(), which requires ldconfig, gcc, objdump or ld to be installed. This is the case on most major distributions, however statically linked distributions (like Alpine Linux) might not bring along binutils by default.\n\n\n\n\nI believe you are using the ubuntu flavor of the azureml base image, In this case I think adding libenchant-2-dev as dependency in your YAML should work.\n\n -libenchant-2-dev=2.2.8\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Error 1000 on Microsoft Machine Learning",
        "Question_creation_time":1643361646673,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/713788\/error-1000-on-microsoft-machine-learning.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi everyone,\nI'm using Azure Studio (Microsoft Machine Learning Studio (classic)) to run R script.\n\nI'm trying to run a loop to find auc on 1,000 times.\n\nThe loop and the code run perfectly when the iterator is up to 100, and fail on 1,000.\n\nThe error is:\n\n\n\n\n\n\nThanks for your help!\n\nThe full script is:\ninstall.packages (\"AUC\", repos= \"https:\/\/cran.microsoft.com\/snapshot\/2022-01-13\/\")\n\n # Map 1-based optional input ports to variables\n universal_bank.df <- maml.mapInputPort(1) # class: data.frame\n    \n ComputeUAC <- function( seed ){\n   #split data\n   set.seed( seed )\n   train.index <- sample(1:dim( universal_bank.df )[1], dim( universal_bank.df )*0.6)\n   train.df <- universal_bank.df[train.index , ]\n   valid.df <- universal_bank.df[-train.index , ]\n      \n   library(party)\n   tr <- ctree( Personal.Loan ~. , data = train.df  )\n   plot(tr, type = \"simple\")\n    \n   pred <- predict( tr, newdata = valid.df )\n      \n    \n   library(AUC)\n   r <- roc( pred, as.factor(valid.df$Personal.Loan) )\n   #plot(r)\n   UAC <- auc(r)\n      \n   return ( UAC )\n    \n }\n    \n UAC_arr <- c()\n for( seed in c(1:10000)){\n   UAC_arr <- c( UAC_arr , ComputeUAC( seed ) )\n }\n    \n boxplot(UAC_arr);\n    \n UAC_arr.df <- as.data.frame( UAC_arr )\n    \n # Select data.frame to be sent to the output Dataset port\n maml.mapOutputPort(\"UAC_arr.df\");",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azuer ml How can I use model version 1 if I delete model version 1",
        "Question_creation_time":1642560823080,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/700512\/azuer-ml-how-can-i-use-model-version-1-if-i-delete.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I don't know where to find version 1\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-19T12:48:09.783Z",
                "Answer_score":0,
                "Answer_body":"@YongchaoLiuNeusoftAmericaInc-6769 Usually if you click on the model the previous versions are available to view and use. If you have deleted the previous versions then I think it is no longer available.\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Unable to load .ipynb file in Azure Machine Learning Workspace",
        "Question_creation_time":1642489248987,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/699144\/unable-to-load-ipynb-file-in-azure-machine-learnin.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hey all,\n\nI experienced the issue below. To summarize, I cannot open .ipynb file in my azure machine learning workspace.\n\nI have tried and ensure that the notebooks are under ~\/cloudfiles\/code\/Users\/ folder so it is visible to Jupyter environment.\n\nCan anyone give suggestions\/guidance on how to resolve the issue?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-19T01:50:07.83Z",
                "Answer_score":0,
                "Answer_body":"Hi, if you're still experiencing this issue, have you tried a different browser (private browsing) to see if it helps? Are you able to connect to a kernel? When you create a new file, are you still getting same error?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Notebook, Kernel Not Connected or Was Deleted",
        "Question_creation_time":1642481695177,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/698918\/azure-ml-notebook-kernel-not-connected-or-was-dele.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I was installing OpenCV in Azure ML - Tensorflow Kernel, when it suddenly fails. After that, I tried to connect to various kernels but failed to launch any of them. It keeps saying that the kernel was not connected or was deleted. May I know how to fix the problem? Many thanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-18T16:48:14.313Z",
                "Answer_score":0,
                "Answer_body":"Hi, are you still experiencing this issue? It's most likely an intermittent issue, but let us know if it still persists. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Car damage detection using azure machine learning or azure artificial intelligence",
        "Question_creation_time":1643020905263,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/707265\/car-damage-detection-using-azure-machine-learning.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":2,
        "Question_body":"Hi. Can someone please guide me how to detect damages in the car from car images using Azure Machine Learning or Azure AI?\n\nI'm planning to use image classification computer vision solution as a first step to classify if car is damaged or not, then as a second step use object detection to identify which parts of the car are damaged.\n\nI'm a beginner in AI and ML. Am I going with the correct approach or is there any other way to solve my problem?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-25T03:33:41.933Z",
                "Answer_score":1,
                "Answer_body":"Hi, I think you're heading in the right direction. Since this is a classification problem, you'd want to use Azure ML (computer vision) to classify the images. To identify which parts have been damaged, Custom Vision's object detector seems to be a viable solution. Please refer to the documentation links provided.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Can't test real-time endpoint",
        "Question_creation_time":1642850859443,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/705771\/can39t-test-real-time-endpoint.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello,\n\nThe text box where I am meant to enter the input to test my endpoint doesn't let me enter anything. The deployment state is currently healthy.\n\n\nI can test the webservice directly without any issues. I also have the same issue with multiple browsers!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-27T09:52:19.137Z",
                "Answer_score":1,
                "Answer_body":"@romungi-MSFT thanks for the advice! I didn't actually have a chance to report the issue, but the endpoint seems to be working fine now. I will report if it starts happening again",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Pipeline stops at train model stage",
        "Question_creation_time":1642031139267,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/693063\/pipeline-stops-at-train-model-stage.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello there,\n\nWhen I am running the following steps of the pipeline, I'm getting this error at the \"train model\" stage.\n\nCan anyone explain why I'm getting this error?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-13T23:43:46.163Z",
                "Answer_score":0,
                "Answer_body":"After your thoughtful suggestion this is what I got in std_log.txt after clicking failed module ( train model ) :\n\nDo I need to fix the error for all the following steps ?\n\nFile \"\/azureml-envs\/azureml_27f4babfbdfccc3e0926823cfdde349d\/lib\/python3.6\/site-packages\/azureml\/studio\/modules\/datatransform\/common\/named_encoder.py\", line 105, in validate_series\ncolumn_name=series.name)\n\nFile \"\/azureml-envs\/azureml_27f4babfbdfccc3e0926823cfdde349d\/lib\/python3.6\/site-packages\/azureml\/studio\/modules\/datatransform\/common\/named_encoder.py\", line 157, in _check_too_many_unique_values\ntroubleshoot_hint=\"Find the explanation and resolution in https:\/\/docs.microsoft.com\/en-us\/\"\n\nFile \"\/azureml-envs\/azureml_27f4babfbdfccc3e0926823cfdde349d\/lib\/python3.6\/site-packages\/azureml\/studio\/common\/error.py\", line 835, in throw\nraise err\n> err = ColumnUniqueValuesExceededError('Number of unique values in column: \"TotalCharges\" is greater than allowed. Find the explanation and resolution in https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/designer-error-codes#error-0014',)",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-01-14T03:38:27.7Z",
                "Answer_score":1,
                "Answer_body":"@Dexter-9539 Yes, The error needs to be resolved. It looks like a data error and if you follow the link mentioned in the error the steps indicate possible ways to remove the unique values that are not required to be passed for training. I would recommend to follow this suggestion based on the error.\n\nFor ID columns which is not meaningful features during training a model, you can use Edit Metadata to mark that column as Clear feature and it will not be used during training a model.\n\nYou can mark TotalCharges as clear feature in this case on the edit metadata module and check if it works. Thanks!!\n\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"One tenant ID ( Root inheriter ) and another subsction ID creating problem for Azure ML-SDK",
        "Question_creation_time":1642202294597,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/696233\/one-tenant-id-root-inheriter-and-another-subsction.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello everyone,\n\nMy laptop is borrowed from University Tech Department since I am a GTA there. Though I opened my own account taking Microsoft Azure subscription ( one month free ) when I'm trying to create a workspace and other related stuff using AzureML-SDK it sends me the following error message:\n\n\"\"\nMessage: You are currently logged-in to 762ebf40-80b2-40ba tenant. You don't have access to <74595002-4d5f-4c26-871c-> subscription, please check if it is in this tenant.\nAll the subscriptions that you have access to in this tenant are =\n[SubscriptionInfo(subscription_name='Azure subscription 1', subscription_id='74595002-4d5f-4c****')].\nPlease refer to aka.ms\/aml-notebook-auth for different authentication mechanisms in azure ml-SDK.\n\"\"\n\n\n\n\nSince it was owned by the tech department I believe it has access to the administration's azure subscription - which I can't find a way to get around to have access of my subscription to use AzureML-SDK.\n\nThe last user ( in the photo ) is from the tech department - who is the administrative user of this laptop. Could the knowledgeable admins\/members kindly suggest what can I do to keep using azure using my own subscription? Any kind suggestion is much appreciated.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure Get API",
        "Question_creation_time":1642420332357,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/697928\/azure-get-api.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":6,
        "Question_score":1,
        "Question_body":"Hi,\n\nWe are trying to develop a python code which will return a json of all VMs for given Azure region along with its vCPU, Ram, pricing as per OS etc.\n\nHowever after one hour it is getting expired. Here is the reference link for the API we are using.\nhttps:\/\/docs.microsoft.com\/en-us\/rest\/api\/azureml\/virtual-machine-sizes\/list#code-try-0\n\nHow can we extend this one hour expiry to 1-3months?\n\nRegards,\nShreeshail",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-18T06:24:11.84Z",
                "Answer_score":0,
                "Answer_body":"@ShreeshailGupte-8888 With the REST API call you will not be able to extend the expiry time for such a long period or time and it is not advisable to have the authentication open for longer periods with any of the methods to call the API.\n\nHowever, you can use the SDK with service principal authentication along with environment variables to have your authentication setup for longer periods and call the API using the SDK. Here is a sample notebook with all the authentication methods listed that you can try.\n\nOnce this is setup you can call the supported_vmsizes method to get all the supported VMs for your workspace and region.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Delete failed and cancelled runs automatically regularly in AzureML experiments",
        "Question_creation_time":1641907647207,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/690810\/delete-failed-and-cancelled-runs-automatically-reg.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"Hi all, AzureML experiments excellently helps us sort our runs.\nThere are atleast daily 100 runs or more in our workspace. Some of these runs fail. I was wondering if there is a way in AzureML to automatically delete the failed runs, because now we have to manually delete them which is not feasible everytime.\nI am aware of Azure LCM, but was wondering if something similar exists to manage our failed runs or any runs that does not have a 'completed' status.\nAny lead would be helpful.\n\nThanks :)",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-11T19:34:34.177Z",
                "Answer_score":1,
                "Answer_body":"Hi, thanks for your feedback. Currently, the deletion process is still manual, but I have forwarded your feedback to the product team and it's in review.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Quantify conformity or compliance between different datasets",
        "Question_creation_time":1641225921097,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/681917\/quantify-conformity-or-compliance-between-differen.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":16,
        "Question_score":0,
        "Question_body":"Hello,\nI have generated regression model using Azure design for a specific dataset of which I know the value to be predicted so I can evaluate the model performance and tune hyper-parameters. But now I would like to apply this trained model to a new and different dataset of which I do not know the values to be predicted during the regression so I cannot quantify the performance of the model for this testing dataset. However, for doing so I would like to see if the testing dataset is representative or similar to the trained dataset to evaluate if the prediction will be accurate. Is there a way in Azure to measure the conformity or compliance of a testing dataset to be similar or comparable to the training dataset?\nThank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-03T21:26:01.087Z",
                "Answer_score":1,
                "Answer_body":"Hi, with dataset monitor, you can detect data drift on datasets. Please review the documentation and let us know if it helps your scenario.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Issues with SQL Alchemy whilst deploying real time endpoint on ACI",
        "Question_creation_time":1642105094927,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/694586\/issues-with-sql-alchemy-whilst-deploying-real-time.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"Hello,\n\nI'm trying to deploy an image to an ACI using Azure Machine Learning. One of the requirements\/installations is sqlalchemy.\n\nWhen building the image, sqlalchemy seems to install correctly. However, when I try to import the sqlalchemy modules within the code, the deployment to the ACI fails and I can't work out why.\n\nAnyone had any similar issues - let me know if I need to provide any more info.\n\nThanks,\n\nCam",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-14T09:23:13.24Z",
                "Answer_score":0,
                "Answer_body":"Hey,\n\nThanks for the reply. Below is currently what I'm doing - I'm using a yaml file rather than a docker file but I think what I'm currently doing should allow dependencies?\n\nThis is part of my yaml file that i'm supplying to the image\n\n\n\n\n\nAnd then this is the code for the image i'm deploying.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Dark Cluster",
        "Question_creation_time":1642592185800,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/701109\/dark-cluster.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I would like to know how to integrate dark cluster with Azure Compute Target (Cluster).\n\nAs a suggestion, I think there should be an option to create a dark cluster in Azure ML Studio.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-20T07:42:13.937Z",
                "Answer_score":1,
                "Answer_body":"Hi, here's the list of compute targets currently supported in AML Studio. If the compute target you're referring to is not in the list, kindly share more details regarding the \"dark cluster\" service you're referring to and I'll be glad to forward your feedback to the product team.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2022-01-20T20:45:10.607Z",
                "Answer_score":0,
                "Answer_body":"Sorry, it's Dask Cluster, located in https:\/\/docs.dask.org\/en\/stable\/\nMany Machine Learning solutions make use of this cluster, not AML Compute Cluster.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Experiment stuck in Queued",
        "Question_creation_time":1642636050810,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/702171\/azure-ml-experiment-stuck-in-queued.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I have only one experiment running, but it is stuck in queued. I see this happens to people a lot, but on one ever says how to fix it.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Problem: AML Designer - Batch Inference Pipeline",
        "Question_creation_time":1639744934170,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/667479\/problem-aml-designer-batch-inference-pipeline.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi Team,\n\nWhen I Submit the Batch Inference Pipeline. It is working.\n\n\n\nAfter submitting, I can see the file:\n\n\nThen when I Publish, the file is not in the Datastore. The file is not generated again. I didn't get an error.\n\nKind regards,\nAnaid",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-19T09:16:36.71Z",
                "Answer_score":0,
                "Answer_body":"@Anaid-6816\n\nHi,\n\nI\u2019ve enabled one-time Free Technical Support for you. To create the support request, please do the following:\n\n\n\n\n\u2022 Go to the Health Advisory section within the Azure Portal: https:\/\/aka.ms\/healthadvisories\n\u2022 Select the Issue Name \"You have been enabled for one-time Free Technical Support\"\n\u2022 Details will populate below in the Summary Tab within the reading pane and you can click on the link \"Create a Support Request\" to the right of the message\n\nLet me know what your support request number is so that I can keep track of your case. If you run into any issues, feel free to let me know.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Import ML Model from ADLS to Azure ML using Databricks",
        "Question_creation_time":1642414997297,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/697789\/import-ml-model-from-adls-to-azure-ml-using-databr.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"Hi,\nI have stored some ml model in my ADLS and I want to register the model to Azure ML using databricks.\nTried to use the following codes to register my ml model but keep encountering an error that the path cannot be found.\n\nimport urllib.request\nfrom azureml.core.model import Model\n\nRegister a model\n\n\n\nmodel = Model.register(model_path = 'dbfs:\/mnt\/machinelearning\/classifier.joblib',\nmodel_name = \"pretrained-classifier\",\ndescription = \"Pretrained Classifier\",\nworkspace=ws)",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-17T16:51:50.977Z",
                "Answer_score":1,
                "Answer_body":"@Yuzu-9670 Using the databricks file path for registering a model is not supported. When using the model.register() you need to download the model locally and then use the path of the model or the folder in which the model is present to register the same.\n\n\n\n\nmodel_path\n\n\nThe path on the local file system where the model assets are located. This can be a direct pointer to a single file or folder. If pointing to a folder, the child_paths parameter can be used to specify individual files to bundle together as the Model object, as opposed to using the entire contents of the folder.\n\nThis sample notebook should help you with using the method.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-01-18T06:21:46.863Z",
                "Answer_score":0,
                "Answer_body":"Hi @romungi-MSFT,\nThank you for your comment!\nI have shifted my ml model to a repo folder and it works now.\nThank you!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"WebserviceException when deploying image",
        "Question_creation_time":1642151764693,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/695283\/webserviceexception-when-deploying-image.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hi,\nI created a model and an image in AML using mlflow.azaureml.build_image. I am able to create the image successfully.\nI tried to deploy the image but i encountered an error.\n\nwebservice_name = \"model-image2\"\nwebservice_deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\naci_webservice = Webservice.deploy_from_image(name=webservice_name, image=model_image, deployment_config=webservice_deployment_config,workspace=ws)\naci_webservice.wait_for_deployment(show_output=True)\n\nIt gave an error which is \"WebserviceException\"",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Executing pipeline in AML from ADF suddenly stopped working",
        "Question_creation_time":1639398869747,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/661588\/how-to-run-a-pipeline-in-aml-from-adf.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":16,
        "Question_score":1,
        "Question_body":"I have a pipeline defined in Azure Machine Learning. It was launched every day with Azure Data Factory with Machine Learning Execute Pipeline activity. This solution worked without any issues for a few weeks, but since 12\/09\/2021 all pipeline runs have failed with error: User starting the run is not an owner or assigned user to the Compute Instance.\nI did not change anything in ADF or AML.\n\nShould I assign compute to ADF? How to do this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-16T21:35:37.337Z",
                "Answer_score":0,
                "Answer_body":"I ran into this same issue in a slightly different context. I didn't manage to figure out the root cause but managed to resolve it in practice by standing up a Compute Cluster instead of a Compute Instance (see https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-attach-compute-cluster?tabs=python)",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2022-01-14T07:24:35.053Z",
                "Answer_score":0,
                "Answer_body":"Using compute cluster as compute target fix the issue.\nRoot cause is compute instance is assigned to certain user or team, and service principle or managed identity is not in the assigned user group in compute instance. Compute cluster can be used by multi-users, and other services.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"python 3.8 kernel \/ change conda environment in azureml",
        "Question_creation_time":1641900858460,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/690792\/python-38-kernel-change-conda-environment-in-azure.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Kernel - I dont know how to activate the Greyed out kernel python 3.8, R and Python 3.6 are ok, should be no trick right?\n\nActivate conda environment - i want to activate say anaconda 3.8 (azureml_py38) inside the terminal, but after that, how to run a notebook? normally u go to web browser, but there is no such one in cloud, and the existing notebook wont get changed..? right?\n\n][1]",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-11T19:25:37.373Z",
                "Answer_score":0,
                "Answer_body":"Hi, you can activate the conda environment by running conda activate newenv as you've done correctly. Then select your notebook or go to your notebook tab (make sure you've selected the appropriate kernel from the drop down menu). There seems to be no option to open the notebook in browser. Simply edit in run your notebooks from your workspace.\n\n\n\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"SqlDataReference usage fails from yaml based AzureML pipeline",
        "Question_creation_time":1641464197140,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/685525\/sqldatareference-usage-fails-from-yaml-based-azure.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_follower_count":15,
        "Question_score":1,
        "Question_body":"I am trying to deploy a DataTransferStep with azureml pipeline\n\nsource -> SQL database\nsink -> Azure Blob\n\nusing yaml pipelines\n\nadditonal comments:\n\n\nThis is built similar to pipeline class as in\nhttps:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-pipeline-core\/azureml.pipeline.core.pipeline.pipeline?view=azure-ml-py\nNote: I have deployed successfully yaml other pipelines that uses PythonScriptStep successfully previously\n\n\n\n\nmy pipeline fails as below\n\n\n\n\n\n\nThe above one is built using following yaml snippet\n\nit fails mentioning \"The SQL Source payload is invalid: Cannot specify 'sqlReaderQuery', 'storedProcedureParameters' at the same time\". whereas only sqlReaderQuery is only provided by me in yaml. storedProcedureParameters takes a default value of None as per https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.sql_data_reference.sqldatareference?view=azure-ml-py . I have debugged inside azureml code and verified storedProcedureParameters is None too.\n\nin executionlogs.txt its also found that an additional stored procedure parameters: 0 () is printed.\nCopy source: SQL server database: xxxxxxxx, servername: xxxxxxxxxxxxx, serverUri: xxxxxxx-dev.database.windows.netAuthentication: AuthencationType=SqlAuthentication, table: dummy, query: SELECT TOP (100) * FROM dml.annotations, stored procedure parameters: 0 ()\n\n\n\n\n\n\n\nI tried numerous combinations to avoid this default value of 0 () coming for stored procedure parameters since it is the summary of the issue as per logs and nothing worked.\n\nadditional analysis:\n\n\nI tried to implement same as direct code in azureml notebook ( here yaml is not present ) i see that the data transfer from sql to blob works perfectly fine in notebook.\n\n\n\n\nso question is when written via yaml why is it not working and creating a error by adding a default value to stored procedure parameters of SqlDataReference, how to fix it ???*\n\nAlso tried in various software versions:\nazureml-core 1.26 and 1.36",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Using the Custom Module in AzureML Designer Created from Notebook",
        "Question_creation_time":1638334248197,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/646978\/using-the-custom-module-in-azureml-designer-create.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"Following the steps in the notebook I am able to create a Module and I also can see the module in the AzureML designer (Under Custom module).\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-how-to-use-modulestep.ipynb\n\nCreating pipeline with ModuleStep and running a pipeline from notebook is also possible. But while trying to use the module in the designer, and trying to run a pipeline in an experiment, getting following error,\n**Error\nCan't build command text for [ModelExplainer], moduleId [ed91c7cf-028f-4867-a228-b32f74cb8ff2] executionId [e4436bd8]: Assignment for parameter Target is not specified\n\nWhere ModelExplainer is the experiment name.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-01T12:52:53.937Z",
                "Answer_score":0,
                "Answer_body":"@AzureMLUser-5271 Thanks for the question. Please share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.\n\nCustom module is designed for reusable tasks in machine learning workflow, like data process, training, scoring etc. So specific transformation. Generally it's recommended to pass asset (dataset or model) as input for a custom module, and the module can use the input to perform certain task.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to tain a ML model with CSV filles and not dataframes?",
        "Question_creation_time":1641828520987,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/689654\/how-to-tain-a-ml-model-with-csv-filles-and-not-dat.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":16,
        "Question_score":0,
        "Question_body":"Hello,\n\nI have a dataset composed of different csv files (a lot of them) with the same metadata that I have added to the Azure blob storage and now I would like to run a regression ML model with this data in Azure ML, however I want to train the model based on the csv files and not on each line of the files (not on each dataframe). How can I do this? Is it possible in Azure ML design?\n\nThank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-10T22:42:30.247Z",
                "Answer_score":0,
                "Answer_body":"Hi, you can create dataset from a datastore. Please refer to the following document for more details on training a regression model in designer. Let us know if you have additional questions. Thanks.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"I got error in inference pipeline in Azure machine Learning notebook",
        "Question_creation_time":1622619661983,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/418869\/i-got-error-in-inference-pipeline-in-azure-machine.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"\u0131 am learning machine learning on microsoft learn and \u0131 have problem with inference pipeline\ninference-pipeline",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-02T12:49:25.843Z",
                "Answer_score":1,
                "Answer_body":"@TunahanDENZ-6224 Thanks for the question. Can you please add more details steps that you performed. If you have changed the schema of the incoming data to exclude the price field, you must remove any explicit use of this field in other modules.\n\nPlease follow the document to create a real-time inference pipeline.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy#create-a-real-time-inference-pipeline-1\n\nWe are able to create inference pipeline without any errors as shown below.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-21T01:43:01.617Z",
                "Answer_score":0,
                "Answer_body":"you can try keeping \"price\" column in the dataset in the first Box,\nEnter Data manually: price,column2,col3,....col10\nSelect Columns in Dataset: price,column2,col3,....col9 (choose which columns to import, omit col10 for example) Though the learning path says to remove price column, try keeping it in.\nAnd you may be interested in Edit Metadata asset box. It allows your model to import the columns and associate the features with the predicted price. So instead of just seeing a predicted price, you can output, what you fed the model. Overall, did you get it to work by starting over? That learning Path worked for me when I followed all steps. maybe these extra ideas will help.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Why does PowerBI not see my custom Azure AI model?",
        "Question_creation_time":1641415247077,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/684845\/why-does-powerbi-not-see-my-custom-azure-ai-model.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello,\nI created custom Azure AI model what I would like to use in PowerBI.\nWhen I open a dataset in PowerBI and after select the \"Azure Machine learning\" after the pop-up window is empty but I suppose it should contain my custom model(s).\nI followed the below articles:\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy\nhttps:\/\/docs.microsoft.com\/en-us\/power-bi\/connect-data\/service-aml-integrate\n\nKind regards\nTom",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-05T21:53:10.033Z",
                "Answer_score":0,
                "Answer_body":"The product group for Power Bi actively monitors questions over at\nhttps:\/\/community.powerbi.com\/\n\n--please don't forget to upvote and  if the reply is helpful--",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"I am not able to configure run in automated ML run?",
        "Question_creation_time":1641292863803,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/682916\/i-am-not-able-configure-run-in-automated-ml-run-wh.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"I am currently learning getting started with Machine learning on azure I had to set up my ML studio and import the dataset and later on to create an automate ML run and to configure a run. After I fill out the name of the experiment, target column and when I click on next I am not able to configure the run and move to the next step. Can someone please guide me what should I do next?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-05T04:09:14.603Z",
                "Answer_score":0,
                "Answer_body":"@PrathikshaKini-3105 Thanks for the question. Can you please add more details about the error that you are getting.\nHere is the document to trian a classification model with no-code AutoML in the Azure Machine Learning studio.\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Compute instance not setting MLFlow's URIs correctly for R",
        "Question_creation_time":1640647322290,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/676727\/compute-instance-not-setting-mlflow39s-uris-correc.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi!\n\nI am trying to set up my ML pipeline on Azure Machine Learning's compute instances. My model is in R, but I found that the azureml sdk for R is deprecated in favour of Azure's CLI (v2), so I am following the documentation on how to set up my pipelines and as all of it is written with Python in mind, not everything translates directly to R and I have found the workaround for some things, but not all of them.\n\nMy main issue is with MLFlow as I want to use Azure's Experiments to track my experiments and after following the documentation to do it with CLI (v2):\n\nCompute Instances set the MLFlow's tracking URI via the environment variable MLFLOW_TRACKING_URI to match my resource's URI. The problem is that the URI is in the shape azureml:\/\/<path> which works correctly on Python when installing azureml-mlflow python package, but it doesn't work on R as that is not a supported format. After several hours of googling, I found a github repo which states that the URI must be changed to https:\/\/ and that allows to log metrics.\n\n\nStill, the problem persists when I want to log artifacts via mlflow_log_artifact as changing the MLFLOW_TRACKING_URI doesn't change the URI to which artifacts are logged, so MLFlow is trying to upload the file to the previous URI schemes (the one starting with azureml:\/\/) which fails with the following error:\n\nMlflowException: Could not find a registered artifact repository for: azureml:\/\/experiments\/<name>\/runs\/<run ID>\/artifacts. Currently registered schemes are: ['', 'file', 's3', 'gs', 'wasbs', 'ftp', 'sftp', 'dbfs', 'hdfs', 'viewfs', 'runs', 'models', 'http', 'https', 'mlflow-artifacts']\n\nI don't know where to submit my issue as:\n\nIt could be related to azureml-mlflow not working correctly when trying to use MLFlow's R wrapper\n\n\nIt could be related to the need of having an azureml-mlflow's package for R\n\n\nIt could be related to the Compute Instance not setting the artifact URI correctly when creating the experiments\n\nMy workaround for now is to store my artifacts as raw outputs of the experiments, but is there a way I can set this up correctly for R?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Unicertainity quantification in Azure ML model",
        "Question_creation_time":1640957755590,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/680275\/unicertainity-quantification-in-azure-ml-model.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hello,\n\nI have run different models in Azure ML under different algorithms (mainly Decision Forest Regression and linear Regression) and I can evaluate the performance of each model by compering the predicted value with the actual input value I have added in the label column. However, I would like to now quantify the uncertainty of the models or the confidence of the prediction by the models. I am looking and have yet to find a way on how to infer uncertainty from the models trained in Azure?\nSo please any help or advice on this subject would be greatly appreciated.\nThank you very much!\n\nMaria Castano.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-03T10:04:48.927Z",
                "Answer_score":0,
                "Answer_body":"@CASTANOSANCHEZMariaJoseA-3582 Thanks, Here is link to the document for model interpretability in Azure Machine Learning.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-machine-learning-interpretability\n\nSDK: For regression we provide an API to compute quantiles which can be used to get confidence intervals. For classification, it is not available yet.\nFor example house price prediction is regression example, here is the API:\nhttps:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-automl-runtime\/azureml.automl.runtime.shared.model_wrappers.regressionpipeline?view=azure-ml-py#predict-quantiles-x--typing-any----predict-params--typing-any-----pandas-core-frame-dataframe\n\nand example code snippet to use:\n\nThe API calls to get the 95% interval look like this:\n\nBest_run, fitted_model = run.get_output()\nfitted_model.quantiles = [0.025, 0.975]\npred_df = fitted_model.predict_quantiles(X_test)\n\nThen pred_df is a dataframe where the columns contain the predictions on the test set for the requested quantiles.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-manage-ml-pitfalls",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Cannot Create Batch Inference ParallelRunStep Pipeline",
        "Question_creation_time":1639579721297,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/664931\/cannot-create-batch-inference-parallelrunstep-pipe.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Firstly, here is my entry script,\ndeploy model code,\n\n\n\n\n\n\n\nMy run keeps failing with the same errors\n\n\n\n\n\nI'm not sure if the entry script is failing to read the model or whether I have some authorisation issues.\nI have made so many attempts by adding datasets used in config file with SAS tokens from the respective containers, I even have\nowner authority access from containers and blob data reader etc, but nothing seems to work. Even when I register the model,\nI don't seem to have an AZURE_MODEL_DIR enviroment variable. Any advice would be much welcome",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-01-03T18:21:01.383Z",
                "Answer_score":0,
                "Answer_body":"@ShayneWilliams-5714\n\nHello,\n\nHope your issue has been resolved and sorry we have not hear back from you. I will link some guidance below for reference and please let us know if you are still blocked by this.\n\nIf you received auth issue but you think you have input the correct SAS, please check if you have the correct CORS setting.\n\nBatch Inference repo: https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/parallel-run\/README.md\n\nTroubleshooting guidance: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-debug-parallel-run-step\n\nHope this helps.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Use LightGBM algorithms in Azure Machine Learning Designer",
        "Question_creation_time":1639119129643,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/658828\/use-lightgbm-algorithms-in-azure-machine-learning.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"Wonder anyone can help on this. My customer wonder if Azure Machine Learning Designer (GUI) can support using Python open library e.g. LightGBM algorithms to develop machine learning model. It seems that it is supported but could not find a supporting document.\nThe customer is currently using Python programming with LightGBM algorithms etc to develop machine learning model with other ML tool. Thanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-10T14:14:43.29Z",
                "Answer_score":0,
                "Answer_body":"@LeeChongYew-9493 Thanks for the question. Custom module is designed for reusable tasks in machine learning workflow, like data process, training, scoring etc.\nstudio designer can manage model deployment as described here: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unable to use \"join data\" to combine multiple datasets into one using Azure Machine Learning Studio Designer",
        "Question_creation_time":1639646320353,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/666021\/unable-to-use-34join-data34-to-combine-multiple-da.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"How can I combine mutiple datasets into one using Azure Machine Learning Studio?\n\n(The following graph doesn't work)\n\nSame Question:\nhttps:\/\/stackoverflow.com\/questions\/70376362\/unable-to-use-join-data-to-combine-multiple-datasets-into-one-using-azure-mach",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-23T04:55:00.347Z",
                "Answer_score":0,
                "Answer_body":"@PoonCheukHinChristophe-1304 Thanks for the details. As you said The second \"Join Data\" is unable to combine the first \"Join Data\" dataset with another dataset named \"Aruoba-Diebold-Scotti Business Conditions Index\". Are you seeing any error details?. If yes please share the same.\n\nHere is the document to Join Data in the Designer.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/component-reference\/join-data\n\nTo check further on this issue, Please share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Connect Azure ML notebook to azure VM",
        "Question_creation_time":1639928946803,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/668659\/connect-azure-ml-notebook-to-azure-vm.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hey All,\n\nI want to connect to my VM in order to get access to files on the VM from my notebook. Is it possible?\n\ncan someone help me with it?\n\nthanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-20T07:40:11.063Z",
                "Answer_score":0,
                "Answer_body":"@IdanConley-4574 If you are using the same compute instance for your notebook then you should be able to access the files from your notebook. For example,\n\nOpen the terminal of your notebook, create a file\n\n\nHit refresh and the file should be listed in the directory which can be accessed from your notebook cell by using relative path.\n\n\n\n\n\n\n\nIf you are looking to use the files from a different VM that is not a compute instance then the option available is to use the Azure storage or file dataset that you can mount using the data actions -> Mount from the notebook UI.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"On Azure ML, how to import another jupyter notebook from a notebook?",
        "Question_creation_time":1640321644830,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/674563\/on-azure-ml-how-to-import-another-jupyter-notebook.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"I'm working on Azure ML and want to import another jupyter notebook from a notebook.\n\nThank you.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-24T11:11:07.313Z",
                "Answer_score":0,
                "Answer_body":"@MyongRaeChang-0941 I don't see a direct way to import another notebook in a cell of a azure ML notebook. But, you can export the notebook that you want to run as a python script and then run it in a cell in the required notebook.\n\nExport option:\n\nThe generated .py script can be copied in a cell of your notebook which run everything in one execution. I hope this works!!\n\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"NameError when trying to run an ScriptRunConfig in Azure Machine Learning",
        "Question_creation_time":1640331391010,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/674712\/nameerror-when-trying-to-run-an-scriptrunconfig-in.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I'm trying to deploy a locally trained RandomForest model into Azure Machine Learning Studio.\n\ntraining code (whentrain.ipynb) :\n\n #import libs and packages\n import numpy as np\n import pandas as pd\n    \n from sklearn.preprocessing import MinMaxScaler\n from sklearn.model_selection import train_test_split\n    \n from sklearn import metrics\n from sklearn.metrics import r2_score\n from math import sqrt\n    \n from sklearn.ensemble import RandomForestRegressor\n    \n from sklearn.preprocessing import LabelEncoder\n from imblearn.over_sampling import SMOTE\n    \n import xgboost as xgb\n from sklearn.metrics import accuracy_score\n from azureml.core import Workspace, Dataset\n    \n # get existing workspace\n workspace = Workspace.from_config(path=\"config.json\")\n    \n # get the datastore to upload prepared data\n datastore = workspace.get_default_datastore()\n    \n # load the dataset which is placed in the data folder\n dataset = Dataset.Tabular.from_delimited_files(datastore.path('UI\/12-23-2021_023530_UTC\/prepped_data101121.csv'))\n dataset = dataset.to_pandas_dataframe()\n    \n # Create the outputs directories to save the model and images\n os.makedirs('outputs\/model', exist_ok=True)\n os.makedirs('outputs\/output', exist_ok=True)\n dataset['Date'] = pd.to_datetime(dataset['Date'])\n dataset = dataset.set_index('Date')\n ###\n scaler = MinMaxScaler()\n    \n #inputs\n X = dataset.iloc[:, 1:]\n #output\n y = dataset.iloc[:, :1]\n    \n X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 42, shuffle=True)\n    \n X_train = scaler.fit_transform(X_train)\n X_test = scaler.fit_transform(X_test)\n    \n ###\n    \n model1 = RandomForestRegressor(n_estimators = 6,\n                                    max_depth = 10,\n                                    min_samples_leaf= 1,\n                                    oob_score = 'True',\n                                    random_state=42)\n model1.fit(X_train, y_train.values.ravel())\n    \n y_pred2 = model1.predict(X_test)\n\n\n\n\nAnd here is the code on the estimator part (estimator.ipynb):\n\n from azureml.core import Experiment\n from azureml.core import Workspace\n from azureml.core.compute import ComputeTarget, AmlCompute\n from azureml.core.compute_target import ComputeTargetException\n from azureml.train.dnn import TensorFlow\n from azureml.widgets import RunDetails\n    \n import os\n    \n workspace = Workspace.from_config(path=\"config.json\")\n exp = Experiment(workspace=workspace, name='azure-exp')\n cluster_name = \"gpucluster\"\n    \n try:\n     compute_target = ComputeTarget(workspace=workspace, name=cluster_name)\n     print('Found existing compute target')\n except ComputeTargetException:\n     print('Creating a new compute target...')\n     compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS3_v2',\n                                                            max_nodes=1)\n    \n     compute_target = ComputeTarget.create(workspace, cluster_name, compute_config)\n    \n     compute_target.wait_for_completion(show_output=True)  # , min_node_count=None, timeout_in_minutes=20)\n     # For a more detailed view of current AmlCompute status, use get_status()\n     print(compute_target.get_status().serialize())\n from azureml.core import ScriptRunConfig\n source_directory = os.getcwd()\n    \n from azureml.core import Environment\n    \n myenv = Environment(\"user-managed-env\")\n myenv.python.user_managed_dependencies =True\n from azureml.core import Dataset\n test_data_ds = Dataset.get_by_name(workspace, name='prepped_data101121')\n    \n src = ScriptRunConfig(source_directory=source_directory,\n                       script='whentrain.ipynb',\n                          \n                       arguments=['--input-data', test_data_ds.as_named_input('prepped_data101121')],\n                       compute_target=compute_target,\n                       environment=myenv)\n run = exp.submit(src)\n RunDetails(run).show()\n run.wait_for_completion(show_output=True)\n\n\n\n\nThe error that happens in run.wait_for_completion states :\n\n [stderr]Traceback (most recent call last):\n [stderr]  File \"whentrain.ipynb\", line 107, in <module>\n [stderr]    \"notebookHasBeenCompleted\": true\n [stderr]NameError: name 'true' is not defined\n [stderr]\n\n\n\nAs you can see in my whentrain.ipynb, it does not even reach line 107, and I could not find where this error come from. So how do I fix it?\n\nI'm running the Notebook on Python 3.\n\n\n\n\n\nUPDATE:\n\nOkay, after a little adjustment that should not affect the whole code (I just removed some extra columns, added model save code in whentrain.ipynb making use of import os) it's now giving me somewhat the same error.\n\n [stderr]Traceback (most recent call last):\n [stderr]  File \"whentrain.ipynb\", line 115, in <module>\n [stderr]    \"source_hidden\": false,\n [stderr]NameError: name 'false' is not defined\n [stderr]",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-27T18:03:50.64Z",
                "Answer_score":0,
                "Answer_body":"@Ash-8361 Ok, I think the issue is here.\n\n src = ScriptRunConfig(source_directory=source_directory,\n                        script='whentrain.ipynb',\n                              \n                        arguments=['--input-data', test_data_ds.as_named_input('prepped_data101121')],\n                        compute_target=compute_target,\n                        environment=myenv)\n\n\n\nThe script parameter is set to the notebook \"whentrain.ipynb\", This should be a python script *.py which can train your model. Since you are using the notebook filename the entire source of jupyter notebook is loaded and it fails with these errors. You can lookup samples on azure ml notebook github repo for reference. I think if you can convert your whentrain.ipynb file to a python script whentrain.py and save it the current folder structure you should be able to use it in this step.",
                "Answer_comment_count":4,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How can I use a working pipeline",
        "Question_creation_time":1640685619343,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/677175\/how-can-i-use-a-working-pipeline.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi,\n\nI created a working pipeline in azure machine learning studio but I am stuck how i can use it with a live dataset. Could anybody help to me in this issue? I dont have such option to deploy it.\n\nthank you in advance",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-28T21:24:18.68Z",
                "Answer_score":0,
                "Answer_body":"Hi, please review Test the real-time endpoint for more details on how to test your model. You can consume your model using a Client or PowerBI.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Is there a cross-sectional, unified security check list for Azure?",
        "Question_creation_time":1638435378937,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/648921\/is-there-a-cross-sectional-unified-security-check.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":21,
        "Question_score":0,
        "Question_body":"I have been used Azure for the first time, and I am overwelmed by the huge quantity of information about Azure.\n\nI think that the information about security on Azure is not unified.\n\nFor example, in Identity Management and access control security best practices page, sometimes there are multiple best practices per one section header.\nHowever, in Security recommendations for Blob storage page,security recommendations are documented in the form of table, one issue per one row.\n\nI wish there was a cross-sectional, unified security check list for Azure as follows.\n\nWe could select Azure services we use.\n\n\nWhen we select the services, the security check list are displayed or could be downloaded as text file.\n\n\nThe security check list are documented so that we can easily understand what we should do. (where on the Azure portal UI, which item, or how to do set the item which is related to security, etc)\n\nI have used Azure services as follows.\n\nAzure Data Factory\n\n\nAzure Data Lake Storage Gen2\n\n\nAzure Functions (App Service)\n\n\nAzure Database for MySQL\n\n\nAzure Machine Learning\n\n\nAzure Monitor (for Application Insights)\n\nEven if I take one service (for example, Azure Data Lake Storage Gen2), I think that I have to check at least two pages (here and here ).\nHowever, I'm not sure if it's covered. Do you have any good ideas?\n\nRegards.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-03T17:52:59.01Z",
                "Answer_score":0,
                "Answer_body":"Hi @makotooda-1289,\n\nThanks for using Microsoft Q&A!!\n\nI do not think that we have a single document which can provide you a consolidated view of security across all Azure services. You may need to go through the documentation available for individual services to get the required information. However, you can try checking - Azure security documentation and Security considerations for Azure Architecture center if this helps you getting anything specific you are looking in Azure at higher level.\n\nHope this helps.\n\nThanks\nSaurabh",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-12-24T07:47:55.087Z",
                "Answer_score":0,
                "Answer_body":"Recently, I found the Microsoft Security Benchmarks Repository from the Azure security baseline for Azure Data Factory article.\n\nI think that this repository's contents are comprehensive, and this is that which I've been searching. Is it right?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Token authentication failed: 'utf-8' codec can't decode byte 0xe4 in position 0: invalid continuation byte",
        "Question_creation_time":1640198898043,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/672951\/token-authentication-failed-39utf-839-codec-can39t.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":16,
        "Question_score":0,
        "Question_body":"I'm trying to send the json data from azure ml to eventhub using codes below\n\nimport json\nd = result.to_dict(orient='records')\ndata = json.dumps(d,ensure_ascii=False)\n\nimport asyncio\nfrom azure.eventhub.aio import EventHubProducerClient\nfrom azure.eventhub import EventData\nimport time\nconn_sting = \"Endpoint=***\"\nasync def run():\nproducer = EventHubProducerClient.from_connection_string(conn_str=conn_string)\nasync with producer:\n\n event_data_batch = await producer.create_batch(partition_id='0')\n event_data_batch.add(EventData(data))\n   \n await producer.send_batch(event_data_batch)\n\nnest_asyncio.apply()\nloop = asyncio.get_event_loop()\nloop.run_until_complete(run())\nprint(\"sent to eventhub\")\n\nand getting follwing error..\n\nToken authentication failed: 'utf-8' codec can't decode byte 0xe4 in\nposition 0: invalid continuation byte\nToken authentication failed: 'utf-8' codec can't decode byte 0xe4 in\nposition 0: invalid continuation byte\n\nanyone could help debug the error? thanks",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Referencing Python Dependency files in scoring file",
        "Question_creation_time":1638888910963,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/654894\/referencing-python-dependency-files-in-scoring-fil.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello,\n\nI'm intending to add some python files in the dependencies in the screenshot below. How do I reference them in my scoring.py file?\n\ni.e. if the dependency file is called main.py, i'd like to import a python function from main.py - along the lines of the below:\n\"import main\"\n\nin my scoring.py file. Is this possible?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-08T11:57:51.577Z",
                "Answer_score":0,
                "Answer_body":"@CameronGrimshawJones-8148 Thanks for the question. Did you use the designer or Azure machine leaning SDK for training the model, Also can you please share the requirement of main.py file that you are trying?.\n\nThe \u201cscore.py\u201d exposed in trained_model_outputs is for customized deployment, only have model init and scoring logic, user can add their own pre-process and post-process code on top of that.\nThe scoring logic that having pre-process logic is available through Designer deployed web service, which can be on both AKS and ACI. You can follow this doc: Tutorial: Deploy ML models with the designer - Azure Machine Learning | Microsoft Docs.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Storage for Azure ML Workspace",
        "Question_creation_time":1626270141667,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/475803\/storage-for-azure-ml-workspace.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":5,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello:\n\nWhen I create Azure ML Workspace, why I cannot use existing storage, why I have to create new one?\n\nAny clarification will help me to educate.\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-15T03:38:52.29Z",
                "Answer_score":0,
                "Answer_body":"Hello Manu:\n\nThanks for your reply, when i try to create new Azure ML Service, It didn't allowed me to select existing storage account - ADLS Gen2.\n\nSo i endup creating new at the time of creating (AML01).\n\nI try to create another one (AML02) and it did allowed me to select storage account for the AML01 workspace but not the ADLS Gen2.\n\nThanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-15T04:05:35.553Z",
                "Answer_score":0,
                "Answer_body":"Hello Manu:\n\nI came across MS Link and it make sense.\n\nhttps:\/\/docs.microsoft.com\/en-us\/cli\/azure\/ml\/datastore?view=azure-cli-latest\n\nWhen you create a workspace, an Azure Storage account is automatically created as an associated resource. A blob container is created in this account, and its connection information is stored as a datastore named 'workspaceblobstore'. This serves as the workspace's default datastore, and the blob container is used to store your workspace artifacts and machine learning job logs and outputs.\n\nSo this is what I experienced as mention above.\n\nThanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-15T04:15:19.32Z",
                "Answer_score":0,
                "Answer_body":"Looks like an IAM assignment needed for the storage account.\n\n\n\nCheck it after granting the service principal with Storage Blob Data Reader access.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-15T04:29:08.85Z",
                "Answer_score":0,
                "Answer_body":"Thanks for your reply, I will check & let you know.\n\nThank you again.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-20T02:05:13.463Z",
                "Answer_score":0,
                "Answer_body":"I was out and will test tomorrow.\n\nThank you for follow-up.\n\nThanks",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Cannot open a terminal in compute instances",
        "Question_creation_time":1615232316253,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/304418\/cannot-open-a-terminal-in-compute-instances.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":4,
        "Question_follower_count":12,
        "Question_score":1,
        "Question_body":"I am trying to complete the learning exercises in the Microsoft Learning module \"Explore and analyze data with Python\" with a trial subscription to Azure. In any compute instances that I start, I cannot connect to the terminal and get the error \"Invalid terminal: Unable connect to terminal, please close the tab and restart your current compute and retry Trace ID : 5b4a5ee5-c5cf-4f66-b054-71a81417bdbc \". I have tried restarting the instance, in addition to deleting the VM and starting a new instance but still encounter the same error which happens in both Edge and Chrome browsers. Is there something that I am missing in connecting to the terminal in these notebooks?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-09T10:39:16.61Z",
                "Answer_score":0,
                "Answer_body":"@GeoffreyMoxley-0007 Thanks for the question. Can you please add more details about the VM(type, size) that you are trying. We are able to create the terminal without any error.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-16T18:12:31.17Z",
                "Answer_score":0,
                "Answer_body":"I'm having the same issue",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-30T18:36:06.157Z",
                "Answer_score":0,
                "Answer_body":"I'm having the same issue. I've started & stopped my compute instance several times as well as created a new compute instance from scratch.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Why can't I see web app bot in the market place?",
        "Question_creation_time":1640039500510,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/670277\/why-can39t-i-see-web-app-bot-in-the-market-place.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":16,
        "Question_score":0,
        "Question_body":"I've tried to look everywhere in the marketplace, however, I can't seem to find a web app bot.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-20T23:24:34.567Z",
                "Answer_score":1,
                "Answer_body":"Sorry, Web App Bot and Bot Channels Registration are deprecated but existing resources will continue to work. You should use Azure Bot, instead.\n\nQuick start for Azure Bot: https:\/\/docs.microsoft.com\/en-us\/azure\/bot-service\/abs-quickstart?view=azure-bot-service-4.0&tabs=userassigned\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure endpoint in decimal notation",
        "Question_creation_time":1639603918890,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/665285\/azure-endpoint-in-decimal-notation.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello, I've set up an Azure endpoint and I'm trying to communicate with it using some old software that can only read decimal notation. The scientific notation the endpoint occasionally delivers is breaking it. Is there a way to configure the endpoint to return only decimal notation? Ideally just with the correct header like \"application\/jsonlegacy\" or something?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-16T06:58:54.83Z",
                "Answer_score":1,
                "Answer_body":"@JonathanHorton-4850 Returning a decimal value from an endpoint should be possible. I think this depends on the training of the experiment if the ML studio is used. I have an experiment which returns decimals. You can use a similar setup with Apply transformation module or Apply Math operation if using the newer version of the studio.\n\n\n\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Failure when submitting pipe line",
        "Question_creation_time":1598970144413,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/83451\/failure-when-submitting-pipe-line.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"Doing exam training using my free subscription (Exam DP-100: Designing and Implementing a Data Science Solution on Azure).\nGot in to problem in the following mudule, https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/explore-data.\nGets following error in my pipe line in Microsoft Azure Machine Learning:\nUnable to get image details : Unable to fetch workspace resources: Not Found response body: {\"error\":{\"code\":\"ResourceNotFound\",\"m",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-03T11:21:56.257Z",
                "Answer_score":0,
                "Answer_body":"Hello @JohanLv-5811 - Did you post the complete error details above? If possible, check that you are referencing the right ML workspace resource.\nJust in case you haven't seen this already, also recommend checking out these troubleshooting tips on creating and managing workspaces..",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-12-16T21:37:57.267Z",
                "Answer_score":0,
                "Answer_body":"I have finally solved the problem. Container registry of Workspace was failed. Solved once I renew.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"RuntimeError: Load model failed - Score machine learning models with PREDICT in serverless Apache Spark pools (Synapse & Azure Machine learning AML)",
        "Question_creation_time":1638981543063,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/656548\/what-is-aml-model-uri-predict-in-serverless-apache-1.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"Hi all,\n\nI am following the steps on this tutorial:\nTutorial: Score machine learning models with PREDICT in serverless Apache Spark pools tutorial-score-model-predict-spark-pool\nI tried to used a model created with AutoML and another from designer and I am getting this error: RuntimeError: Load model failed\n\n\n\n\nI am using the model according to this: https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/631200\/what-is-aml-model-uri-predict-in-serverless-apache.html?childToView=637754#comment-637754\n\nThank you for your help.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-14T05:36:00.303Z",
                "Answer_score":0,
                "Answer_body":"Hello @Anaid-6816,\n\nBefore running this script, update it with the URI for ADLS Gen2 data file along with model output return data type and ADLS\/AML URI for the model file.\n\n #Set model URI\n        #Set AML URI, if trained model is registered in AML\n           AML_MODEL_URI = \"<aml model uri>\" #In URI \":x\" signifies model version in AML. You can   choose which model version you want to run. If \":x\" is not provided then by default   latest version will be picked.\n    \n        #Set ADLS URI, if trained model is uploaded in ADLS\n           ADLS_MODEL_URI = \"abfss:\/\/<filesystemname>@<account name>.dfs.core.windows.net\/<model   mlflow folder path>\"\n\nModel URI from AML Workspace:\n\n DATA_FILE = \"abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/AML\/LengthOfStay_cooked_small.csv\"\n AML_MODEL_URI_SKLEARN = \"aml:\/\/mlflow_sklearn:1\" #Here \":1\" signifies model version in AML. We can choose which version we want to run. If \":1\" is not provided then by default latest version will be picked\n RETURN_TYPES = \"INT\"\n RUNTIME = \"mlflow\"\n\nModel URI uploaded to ADLS Gen2:\n\n DATA_FILE = \"abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/AML\/LengthOfStay_cooked_small.csv\"\n AML_MODEL_URI_SKLEARN = \"abfss:\/\/data@cheprasynapse.dfs.core.windows.net\/linear_regression\/linear_regression\" #Here \":1\" signifies model version in AML. We can choose which version we want to run. If \":1\" is not provided then by default latest version will be picked\n RETURN_TYPES = \"INT\"\n RUNTIME = \"mlflow\"\n\n\n\nHope this will help. Please let us know if any further queries.\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"ClusterIdentityNotFound when submitting experiment.",
        "Question_creation_time":1633943984543,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/585373\/clusteridentitynotfound-when-submitting-experiment.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"When I'm submitting my experiment fom notebook, experiment is queing for a long time then I get as error:\n\nAzureMLCompute job failed.\nClusterIdentityNotFound: Identity of the specified\nmanaged compute <hidden cluster location> is not found\n\n\n\n\nI've updated all azure ml packages and restarted cluster, deleted, recreating, ... Nothing seems to be working.\n\nWhat Should I do?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-11T21:32:50.467Z",
                "Answer_score":1,
                "Answer_body":"Hi, are you by any chance using a low priority VM? If so, can you try selecting 'dedicated' as priority to verify? Also, ensure that you are following the steps outlined in this document for creating a compute cluster. In the advanced settings, ensure to assign a managed identity and specify a system-assigned identity or user-assigned identity.\n\n\n\n\n--- Kindly Accept Answer if the information provided helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-10-13T07:35:27.65Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThank you for you answer.\nIt fixed my issue.\n\nHave a great day. :)\n\n\n\n\nBest regards.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-12-16T10:25:02.78Z",
                "Answer_score":0,
                "Answer_body":"Thanks for the answer @GiftA-MSFT . May i ask if this problem is happening for both compute clusters and compute instances? We are experiencing the same problem when trying to create an automated regression machine learning experiment by using a compute instance: Virtual machine size\nStandard_DS3_v2 (4 cores, 14 GB RAM, 28 GB disk)\nProcessing unit\nCPU - General purpose\nAny help much appreciated\nKind regards",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Auto ML JobConfigurationMaxSizeExceeded error when using a cluster",
        "Question_creation_time":1638916697927,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/655421\/azure-auto-ml-jobconfigurationmaxsizeexceeded-erro.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello,\n\nI am running into the following error when I try to run Automated ML through the studio on a GPU compute cluster:\n\nThe attempted run is on a registered tabulated dataset in filestore and is a simple regression case. Strangely, it works just fine with the CPU compute instance I use for my other pipelines. I have been able to run it a few times using that and wanted to uprade to a cluster only to be hit by this error. I found online that it could be a case of having the following setting: AZUREML_COMPUTE_USE_COMMON_RUNTIME:false; but I am not sure where to put this in when just running from the web studio.\n\nThank you for your help!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-15T16:17:17.217Z",
                "Answer_score":0,
                "Answer_body":"Looks like the issue was fixed! Works normally now.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML - Workspace contributor cannot access Compute Instance",
        "Question_creation_time":1639128960857,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/659117\/azure-ml-workspace-contributor-cannot-access-compu.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi,\n\n\n\n\nUntil 2021\/12\/7, every user whose role is Contributor can use the same Compute Instance to run an Experiment.\nOn 2021\/12\/8, only the owner of Compute Instance can access.\nHow can I still use shared Compute Instance?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure ML: Upload File to Step Run's Output - Authentication Error",
        "Question_creation_time":1630074811383,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/530817\/azure-ml-upload-file-to-step-run39s-output-authent.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":15,
        "Question_score":1,
        "Question_body":"During a PythonScriptStep in an Azure ML Pipeline, I'm saving a model as joblib pickle dump to a directory in a Blob Container in the Azure Blob Storage which I've created during the setup of the Azure ML Workspace. Afterwards I'm trying to upload this model file to the step run's output directory using\n\nRun.upload_file (name, path_or_stream)\n\n\n\n(for the function's documentation, see https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.run(class)?view=azure-ml-py#upload-file-name--path-or-stream--datastore-name-none-)\n\nSome time ago when I created the script using the azureml-sdk version 1.18.0, everything worked fine. Now, I've updated the script's functionalities and upgraded the azureml-sdk to version 1.33.0 during the process and the upload function now runs into the following error:\n\nTraceback (most recent call last):\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_file_utils\/upload.py\", line 64, in upload_blob_from_stream\n    validate_content=True)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py\", line 93, in execute_func_with_reset\n    return ClientBase._execute_func_internal(backoff, retries, module_logger, func, reset_func, *args, **kwargs)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py\", line 367, in _execute_func_internal\n    left_retry = cls._handle_retry(back_off, left_retry, total_retry, error, logger, func)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py\", line 399, in _handle_retry\n    raise error\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py\", line 358, in _execute_func_internal\n    response = func(*args, **kwargs)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/blockblobservice.py\", line 614, in create_blob_from_stream\n    initialization_vector=iv\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_chunking.py\", line 98, in _upload_blob_chunks\n    range_ids = [f.result() for f in futures]\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_chunking.py\", line 98, in <listcomp>\n    range_ids = [f.result() for f in futures]\n  File \"\/opt\/miniconda\/lib\/python3.7\/concurrent\/futures\/_base.py\", line 435, in result\n    return self.__get_result()\n  File \"\/opt\/miniconda\/lib\/python3.7\/concurrent\/futures\/_base.py\", line 384, in __get_result\n    raise self._exception\n  File \"\/opt\/miniconda\/lib\/python3.7\/concurrent\/futures\/thread.py\", line 57, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_chunking.py\", line 210, in process_chunk\n    return self._upload_chunk_with_progress(chunk_offset, chunk_bytes)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_chunking.py\", line 224, in _upload_chunk_with_progress\n    range_id = self._upload_chunk(chunk_offset, chunk_data)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/_upload_chunking.py\", line 269, in _upload_chunk\n    timeout=self.timeout,\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/blob\/blockblobservice.py\", line 1013, in _put_block\n    self._perform_request(request)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/common\/storageclient.py\", line 432, in _perform_request\n    raise ex\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/common\/storageclient.py\", line 357, in _perform_request\n    raise ex\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/common\/storageclient.py\", line 343, in _perform_request\n    HTTPError(response.status, response.message, response.headers, response.body))\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_vendor\/azure_storage\/common\/_error.py\", line 115, in _http_error_handler\n    raise ex\nazure.common.AzureHttpError: Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature. ErrorCode: AuthenticationFailed\n<?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>AuthenticationFailed<\/Code><Message>Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.\nRequestId:5d4e1b7e-c01e-0070-0d47-9bf8a0000000\nTime:2021-08-27T13:30:02.2685991Z<\/Message><AuthenticationErrorDetail>Signature did not match. String to sign used was rcw\n2021-08-27T13:19:56Z\n2021-08-28T13:29:56Z\n\/blob\/mystorage\/azureml\/ExperimentRun\/dcid.98d11a7b-2aac-4bc0-bd64-bb4d72e0e0be\/outputs\/models\/Model.pkl\n2019-07-07\nb\n<\/AuthenticationErrorDetail><\/Error>\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/...\/azureml-setup\/context_manager_injector.py\", line 243, in execute_with_context\n    runpy.run_path(sys.argv[0], globals(), run_name=\"__main__\")\n  File \"\/opt\/miniconda\/lib\/python3.7\/runpy.py\", line 263, in run_path\n    pkg_name=pkg_name, script_name=fname)\n  File \"\/opt\/miniconda\/lib\/python3.7\/runpy.py\", line 96, in _run_module_code\n    mod_name, mod_spec, pkg_name, script_name)\n  File \"\/opt\/miniconda\/lib\/python3.7\/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"401_AML_Pipeline_Time_Series_Model_Training_Azure_ML_CPU.py\", line 318, in <module>\n    main()\n  File \"401_AML_Pipeline_Time_Series_Model_Training_Azure_ML_CPU.py\", line 286, in main\n    path_or_stream=model_path)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/core\/run.py\", line 53, in wrapped\n    return func(self, *args, **kwargs)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/core\/run.py\", line 1989, in upload_file\n    datastore_name=datastore_name)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py\", line 114, in upload_artifact\n    return self.upload_artifact_from_path(artifact, *args, **kwargs)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py\", line 107, in upload_artifact_from_path\n    return self.upload_artifact_from_stream(stream, *args, **kwargs)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py\", line 99, in upload_artifact_from_stream\n    content_type=content_type, session=session)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py\", line 88, in upload_stream_to_existing_artifact\n    timeout=TIMEOUT, backoff=BACKOFF_START, retries=RETRY_LIMIT)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_file_utils\/upload.py\", line 71, in upload_blob_from_stream\n    raise AzureMLException._with_error(azureml_error, inner_exception=e)\nazureml._common.exceptions.AzureMLException: AzureMLException:\n    Message: Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\n    StorageAccount: mystorage\n    ContainerName: azureml\n    StatusCode: 403\n    InnerException Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature. ErrorCode: AuthenticationFailed\n<?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>AuthenticationFailed<\/Code><Message>Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.\nRequestId:5d4e1b7e-c01e-0070-0d47-9bf8a0000000\nTime:2021-08-27T13:30:02.2685991Z<\/Message><AuthenticationErrorDetail>Signature did not match. String to sign used was rcw\n2021-08-27T13:19:56Z\n2021-08-28T13:29:56Z\n\/blob\/mystorage\/azureml\/ExperimentRun\/dcid.98d11a7b-2aac-4bc0-bd64-bb4d72e0e0be\/outputs\/models\/Model.pkl\n2019-07-07\nb\n<\/AuthenticationErrorDetail><\/Error>\n    ErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\\n\\tStorageAccount: mystorage\\n\\tContainerName: azureml\\n\\tStatusCode: 403\",\n        \"inner_error\": {\n            \"code\": \"Auth\",\n            \"inner_error\": {\n                \"code\": \"Authorization\"\n            }\n        }\n    }\n}\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"401_AML_Pipeline_Time_Series_Model_Training_Azure_ML_CPU.py\", line 318, in <module>\n    main()\n  File \"401_AML_Pipeline_Time_Series_Model_Training_Azure_ML_CPU.py\", line 286, in main\n    path_or_stream=model_path)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/core\/run.py\", line 53, in wrapped\n    return func(self, *args, **kwargs)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/core\/run.py\", line 1989, in upload_file\n    datastore_name=datastore_name)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py\", line 114, in upload_artifact\n    return self.upload_artifact_from_path(artifact, *args, **kwargs)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py\", line 107, in upload_artifact_from_path\n    return self.upload_artifact_from_stream(stream, *args, **kwargs)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py\", line 99, in upload_artifact_from_stream\n    content_type=content_type, session=session)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_restclient\/artifacts_client.py\", line 88, in upload_stream_to_existing_artifact\n    timeout=TIMEOUT, backoff=BACKOFF_START, retries=RETRY_LIMIT)\n  File \"\/opt\/miniconda\/lib\/python3.7\/site-packages\/azureml\/_file_utils\/upload.py\", line 71, in upload_blob_from_stream\n    raise AzureMLException._with_error(azureml_error, inner_exception=e)\nUserScriptException: UserScriptException:\n    Message: Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\n    StorageAccount: mystorage\n    ContainerName: azureml\n    StatusCode: 403\n    InnerException AzureMLException:\n    Message: Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\n    StorageAccount: mystorage\n    ContainerName: azureml\n    StatusCode: 403\n    InnerException Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature. ErrorCode: AuthenticationFailed\n<?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>AuthenticationFailed<\/Code><Message>Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature.\nRequestId:5d4e1b7e-c01e-0070-0d47-9bf8a0000000\nTime:2021-08-27T13:30:02.2685991Z<\/Message><AuthenticationErrorDetail>Signature did not match. String to sign used was rcw\n2021-08-27T13:19:56Z\n2021-08-28T13:29:56Z\n\/blob\/mystorage\/azureml\/ExperimentRun\/dcid.98d11a7b-2aac-4bc0-bd64-bb4d72e0e0be\/outputs\/models\/Model.pkl\n2019-07-07\nb\n<\/AuthenticationErrorDetail><\/Error>\n    ErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\\n\\tStorageAccount: verovisionstorage\\n\\tContainerName: azureml\\n\\tStatusCode: 403\",\n        \"inner_error\": {\n            \"code\": \"Auth\",\n            \"inner_error\": {\n                \"code\": \"Authorization\"\n            }\n        }\n    }\n}\n    ErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Encountered authorization error while uploading to blob storage. Please check the storage account attached to your workspace. Make sure that the current user is authorized to access the storage account and that the request is not blocked by a firewall, virtual network, or other security setting.\\n\\tStorageAccount: mystorage\\n\\tContainerName: azureml\\n\\tStatusCode: 403\"\n    }\n}\n\n\n\n\nAs far as I can tell from the code of the azureml.core.Run class and the subsequent function calls, the Run object tries to upload the file to the step run's output directory using SAS-Token-Authentication (which fails). This documentation article is linked in the code (but I don't know if this relates to the issue): https:\/\/docs.microsoft.com\/en-us\/rest\/api\/storageservices\/create-service-sas#service-sas-example\n\nDid anybody encounter this error as well and knows what causes it or how it can be resolved?\n\nBest,\nJonas",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-31T16:24:16.313Z",
                "Answer_score":0,
                "Answer_body":"@Jonas-4379 Thanks for the details. This is a bug with the azureml-sdk-version V1.33 and will update once this is fixed.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is there a way to delete datasets on AzureML?",
        "Question_creation_time":1632745762197,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/567611\/is-there-a-way-to-delete-datasets-on-azureml.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"We have a list of datasets in our AzureML. Is there a way to delete the datasets that we no longer require?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-27T21:28:04.783Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us. I think you are mentioning how to unregister dataset you do not need at this moment in Machine Learning Studio.\n\nYou can do it by go to your Azure Machine Learning Studio and check the Datasets. Then select the dataset you not longer need and click unregister.\n\nHope this helps.\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How to connect Azure ML to Eventhub",
        "Question_creation_time":1639361629193,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/660845\/how-to-connect-azure-ml-to-eventhub.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hi I'm new to Azure ML so I have little knowledge of it..\nI've created a basic regression ML model using auto ml package inJjupyeter notebook\nand now I have to deploy the model and send the output to the eventhub..\n\nI'm wondering if anyone could help me with deploying the model and connecting it to the eventhub",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-14T06:19:03.517Z",
                "Answer_score":0,
                "Answer_body":"@jjyuu-6497 Thanks for the details. We usually recommend to use Stream Analytics to Integrate Azure Stream Analytics with Azure Machine Learning (Preview). In addition to send data to SQL for the heatmap, Azure Stream Analytics can work with PBI streaming datasets. ASA is also a good choice for low latency (second or less) and complex queries.\n\nSample Repo: https:\/\/github.com\/JackXueIndiana\/Azure-Stream-Analysis-AML-WS-Call",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"getting an error when trying to deploy azure ml model",
        "Question_creation_time":1639419111370,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/662007\/getting-an-error-when-trying-to-deploy-azure-ml-mo.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I'm new to Azure ML so I have very little knowledge of this service..\nI've built a dummy regression model using automl package and now I'm trying to deploy it.\nI looked up some docs and followed a tutorial I found to deploy the model and I'm getting some errors..\n <- this is the error I'm currently getting\nI think there is a problem with my score.py so I'm attaching the photo here as well.\n\n\nand this is the output i need to print out through the model..\n\n\nI'd appreciate it much if somebody could give me some help\n\nthank you",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-14T05:30:21.473Z",
                "Answer_score":1,
                "Answer_body":"Hello,\n\nThanks for reaching out to us. From the above error it looks like the package did not install successfully. A more detailed procedure to install the SDK is available directly in the documentation: https:\/\/docs.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/install?view=azure-ml-py\n\nHow to set up the environment: https:\/\/github.com\/Azure\/azureml-examples\/tree\/main\/python-sdk\/tutorials\/automl-with-azureml#3-setup-a-new-conda-environment\n\nYou can test if you have set the env correct by below code:\n\n import azureml.core\n    \n print(\"This notebook was created using version 1.35.0 of the Azure ML SDK.\")\n print(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK.\")\n assert (\n     azureml.core.VERSION >= \"1.35\"\n ), \"Please upgrade the Azure ML SDK by running '!pip install --upgrade azureml-sdk' then restart the kernel.\"\n\n\n\nThere are some prerequisites to deploy models:\n\nAn Azure Machine Learning workspace. For more information, see Create an Azure Machine Learning workspace. https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace\n\n\nA model. The examples in this article use a pre-trained model.\n\n\nThe Azure Machine Learning software development kit (SDK) for Python. https:\/\/docs.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/intro\n\n\nA machine that can run Docker, such as a compute instance. https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-manage-compute-instance\n\nMore information please refer to https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python#prerequisites\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Custom Dockerfile on Azure Environment with python poetry",
        "Question_creation_time":1638821054557,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/653688\/custom-dockerfile-on-azure-environment-with-python.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"I am new to docker and environments. This could be basics but i have been trying to install packages in my pyproject.toml file in Dockerfile without success.\n\nI have tried using poetry to export requirements.txt file and using it with the\nEnvironment.from_pip_requirements('requirements.txt') function and a Dockerfile.\n\nBut could there be any elegant solution to use toml file directly for creating a custom environment ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-08T16:31:16.963Z",
                "Answer_score":1,
                "Answer_body":"Thanks for the response, @Ram-msft\nUsing the Dockerfile :\n\n FROM python:3.8-slim-buster\n ENV PYTHONUNBUFFERED=1 \\\n     PYTHONDONTWRITEBYTECODE=1 \\\n     PIP_NO_CACHE_DIR=1 \\\n     PIP_DISABLE_PIP_VERSION_CHECK=1 \\\n     POETRY_VERSION=1.1.7 \\\n     PYLINT_VERSION=2.9.4\n    \n RUN pip install pylint==$PYLINT_VERSION \\\n     && pip install \"poetry==$POETRY_VERSION\" \n    \n COPY pyproject.toml .\/\n RUN poetry config virtualenvs.create false",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-12-07T15:37:01.407Z",
                "Answer_score":0,
                "Answer_body":"@AntaraDas-4298 Thanks for the question. Can you please share the sample\/document that you are trying. I would recommend to use yml file that is relatively easy to get from pip requirements file\n\nfrom azureml.core import Environment\nfrom azureml.core.conda_dependencies import CondaDependencies\n\nenv = Environment(\u201cmyenv\u201d)\nenv.python.conda_dependencies = CondaDependencies(\u201cmy_yaml_file\u201d)\n\n\n\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-with-custom-image",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How Do I Create a ModelDirectory Type FileDataset",
        "Question_creation_time":1621299075643,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/398468\/how-do-i-create-a-modeldirectory-type-filedataset.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I am trying to build a solution that automates part of the model deployment within the Azure ML designer. I am able to build a model with the designer, and then execute a python script block to extract the trained_model_outputs folder from the model training block. I have precisely matched the folder structure that Azure ML designer assigns to the model's FileDataset\n\nWhen I register the trained_model_outputs as a FileDataset, it assigns it the type AnyDirectory. This is a problem, as when I try to build it into the inference pipeline, the designer rejects it, saying it must be a ModelDirectory, even though there shouldn't be any functional difference between the two.\n\nI have seen that I can expose the ModelDirectory class as below, however I cannot find the API documentation online about this class anywhere, and I can't review it's source code as it isn't in the standard SDK:\n\nfrom azureml.studio.core.io.model_directory import ModelDirectory\n\nCan you provide a code snippet or similar that I can use to leverage this class when creating the FileDataset so that the model dataset gains the ModelDirectory type attribute?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-18T13:56:26.373Z",
                "Answer_score":0,
                "Answer_body":"@LeeHarper-5286 Thanks for the question. Can you please add more details about the use case.\n\nOutFileDatasetConfig is a control plane concept to pass data between pipeline steps. PipelineData was intended to represent \"transient\" data from one step to the next one, while OutputDatasetConfig was intended for capturing the final state of a dataset. PipelineData always outputs data in a folder structure like {run_id}{output_name}. OutputDatasetConfig allows to decouple the data from the run and hence it allows you to control where to land the data (although by default it will produce similar folder structure). The OutputDatasetConfig allows even to register the output as a Dataset, where getting rid of such folder structure makes sense. From the docs itself: \"Represent how to copy the output of a run and be promoted as a FileDataset. The OutputFileDatasetConfig allows you to specify how you want a particular local path on the compute target to be uploaded to the specified destination\".\n\nPlease follow the below link to use the upload API.\nhttps:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.dataset_factory.filedatasetfactory?view=azure-ml-py#upload-directory-src-dir--target--pattern-none--overwrite-false--show-progress-true-",
                "Answer_comment_count":10,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Compute (instance or cluster) times out mounting blob storage with BFSMountError",
        "Question_creation_time":1637782411833,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/639949\/azure-ml-compute-instance-or-cluster-times-out-mou.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"We've recently spun up an Azure ML environment to do some initial testing of its capabilities. A little background, we have quite a few different other services deployed, all encapsulated in our VNET which has no ingress or egress to the internet, just a VPN GW to our offices. We are leveraging private endpoints and private link capabilities across the board.\n\nWe explicitly followed the instructions of setting up a secure ML workspace (https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-create-secure-workspace). We are using private endpoints for the workspace, storage, ACR, KV, and everything ML-related is in its own subnet within our VNET. Compute instances and\/or clusters are also deployed to the same subnet.\n\nWhen we try and run one of the sample designer packages, Automobile Price Prediction, we get the following error whether using a compute instance or a compute cluster:\n\nAzureMLCompute job failed.\nBFSMountError: Unable to mount blob fuse file system\nInfo: Mounting of azureml-blobstore-XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX container from ${storageaccountname} account timed out\nInfo: Failed to setup runtime for job execution: Job environment preparation failed on ${Compute IP Address} with err exit status 1.\n\nAny ideas or things to look at?\n\nThanks in advance",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-08T16:41:58.993Z",
                "Answer_score":0,
                "Answer_body":"Hi folks- it turns out that the DNS entry for our private endpoint for blob storage in our ML storage account was misconfigured. Makes sense that the compute was trying to mount the blob storage to the wrong FQDN\/IP and timing out. I found this by enabling SSH access to the test compute node, logging in while it was trying to mount, and trying to resolve FQDN\/IP, which came back incorrect for some reason. After correcting the private DNS entry for access to our ML blob storage account, everything executed as expected. @romungi-MSFT, I'm not sure this is the bug you mentioned above or not, but thanks again for your help.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to create deploy a Deep learning model as Function app",
        "Question_creation_time":1638553622740,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/651132\/how-to-create-deploy-a-deep-learning-model-as-func.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I have a DL model which sizes around 3.5 gigs and I'm creating a HTTP trigger to hit the model, all works fine when I test it in my local machine. When I start deploying the model as Function App into Azure, deployment breaks midway.\n\nAlso how can I link a gpu compute to the function app for the model to run.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-07T00:47:52.4Z",
                "Answer_score":0,
                "Answer_body":"Hi, here's documentation on how to Deploy ML model to Azure Functions. Currently, GPU is not supported, however, you can deploy to a Kubernetes cluster using GPU. Perhaps you can share the error message?\n\nAdditional Resources:\n\nAzure Functions hosting options\n\n\nAzure Functions on Kubernetes with KEDA\n\n\nSample 1, Sample 2, Sample 3",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Something went wrong with AZUREML_COMPUTE_USE COMMON_RUNTIME",
        "Question_creation_time":1635026593690,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/601551\/something-went-wrong-with-azureml-compute-use-comm.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Suddenly, we had some problems with python module import.\n\nHere the same error on stackoverflow\nhttps:\/\/stackoverflow.com\/questions\/69554336\/azure-ml-release-bug-azureml-compute-use-common-runtime\n\nRun ID - 3c50cae1-b463-4ec1-afd5-c92393b2167c",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-06T20:05:20.2Z",
                "Answer_score":0,
                "Answer_body":"The error should've been resolved by now, please remove the AZUREML_COMPUTE_USE_COMMON_RUNTIME environment variable and try again.\n\nFor more details, please see the reply to the stack overflow question above on more details.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Python 3.8 - AzureML kernel not starting",
        "Question_creation_time":1638550291587,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/650960\/python-38-azureml-kernel-not-starting.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\n\ntl;dr: Azureml - 3.8 Python kernel will not connect to jupyter notebook using Standard_NC6 GPU compute\n\nI'm using Azure for a class with a Standard_NC6 GPU as the compute (this is required for the assignment). While I was working yesterday, the compute got stuck on cell in jupyter for around 30 minutes when it only should have taken 10. I tried to interrupt the kernel, but it wasn't responding. I tried stopping the compute, but it wouldn't stop. Then I tried deleting the compute, which stopped the compute, but didn't actually delete it. I couldn't restart the compute, so I tried to delete it again, which did work. Then I created a new compute in the same resource group with the same requirements as before, only once it finally launched the correct kernel, Azureml-3.8 Python wouldn't start up in Jupyter. It would say launching when I tried to start it, run for maybe 5-10 minutes, and then say it couldn't connect.\n\nI then created a new resource group with a brand new compute, and still ran into the same error. I could even start the notebook up with any of the other kernels, but unfortunately I have to use azureml-3.8 Python for the assignement. What am I doing wrong? Please let me know if I should post more information\n\nThanks",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"ML Notebooks PATH set for python3.6 not matter what kernel you use",
        "Question_creation_time":1638785774433,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/652960\/ml-notebooks-path-set-for-python36-not-matter-what.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi all,\n\nI've trying to run this notebook in AzureML which requires python 3.7 or higher. I'm trying with the built-in Python 3.8 kernel but the PATH contains reference to the 3.6 kernel and therefore pip and python versions are 3.6, not 3.8:\n\nI've created a new environment and can check that it works through the terminal, but I can't change the path of the notebook server, despite a correct kernel spec.\n\nHelp!\n\nAmadeus",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-06T10:32:20.553Z",
                "Answer_score":0,
                "Answer_body":"Current workaround is to find the path of the pip for your env and prepend this manually:\n\n !\/anaconda\/envs\/py39\/bin\/pip install Pillow",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"is there a way to delete azureml runs using the python sdk?",
        "Question_creation_time":1638386026283,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/648089\/is-there-a-way-to-delete-azureml-runs-using-the-py.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"I was wondering if it was possible to delete particular runs using the Python SDK.\nthis would be rather useful to delete old failed runs.\nit already has functions such as cancel(), fail(), submit().",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-03T01:16:37.37Z",
                "Answer_score":0,
                "Answer_body":"@AntaraDas-4298 Thanks, Run history documents, which may contain personal user information, are stored in the storage account in blob storage, in subfolders of \/azureml. You can download and delete the data from the portal.\n\nHere is the document to delete workspace data.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-export-delete-data\n\nThere is a Private Preview for deleting an experiment, however such functionality does not delete the intermediate data generated for the run or any child run.\n\u2022 Not deleted:\no Files in azureml-blobstore-GUID\/azureml\/{run_id}\no Code snapshot (zip files)\no Pipeline intermediate data and child runs\no Metric data\n\n\u2022 Deleted\no The output folder content\no Log files",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure AutoML Model - Test Interface",
        "Question_creation_time":1638313645353,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/646763\/azure-automl-model-test-interface.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi Guys. New in the Azure AutoML space.\nI followed through the steps and successfully deployed a model on web:\n\n\n\n\n\n\n\nWhen I go into \"Test\" tab, the interface with dialog boxes is missing, and it's displaying raw code:\n\n\n\n\n\nJust wanted to check if anyone knew how I could get the dialog boxes or UI ?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Many Azure ML subresources do not support tags and tags in cost report",
        "Question_creation_time":1638463996317,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/649517\/many-azure-ml-subresources-do-not-support-tags-and.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":16,
        "Question_score":0,
        "Question_body":"Tags are supported on Azure Machine learning, but the most cost generating part in Azure ML usage is related to sub-resources that do not support tags in cost report as shown here.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/azure-resource-manager\/management\/tag-support#microsoftmachinelearningservices\n\nIt seems that Azure ML also leverages other services and hence flagged with the resource name of the emitting service (Azure ML workspace) with no tags propagated, and unfortunately these are the most expensive and are not covered by tagging mechanism.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-03T03:04:07.75Z",
                "Answer_score":0,
                "Answer_body":"@MOHAMMEDAMINETOURARI-9591\n\nThanks a lot for your feedback and sorry for your experience. I have forwarded your feedback to product team for review.\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"automate failed runs delete using life cycle management ?",
        "Question_creation_time":1638290477030,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/646383\/automate-failed-runs-delete-using-life-cycle-manag.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"i would be interested in knowing if there is an elegant method of deleting the Failed , cancelled runs on AzureML using the life cycle management ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-01T18:34:27.807Z",
                "Answer_score":0,
                "Answer_body":"@AntaraDas-4298\n\nSorry, this is not supported currently, but I have forwarded your feedback to pm. Thanks.\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"What is AML_MODEL_URI - PREDICT in serverless Apache Spark pools (Synapse & Azure Machine learning AML)",
        "Question_creation_time":1637180271803,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/631200\/what-is-aml-model-uri-predict-in-serverless-apache.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"Hi all,\n\nI am following the steps on this tutorial:\nTutorial: Score machine learning models with PREDICT in serverless Apache Spark pools https:\/\/docs.microsoft.com\/en-us\/azure\/synapse-analytics\/machine-learning\/tutorial-score-model-predict-spark-pool\n\nI don't know what is the AML_MODEL_URI. I thought it was the REST endpoint or the Swagger URI from the endpoint.\n\n\nBut it is not working. I am getting this error on Synapse: \"RuntimeError: Load model failed\nTraceback (most recent call last):\"\n\n\nI appreciate you help.\n\nKind regards,\nAnaid",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-23T11:39:05.273Z",
                "Answer_score":1,
                "Answer_body":"Hello @Anaid-6816,\n\nThanks for the question and using MS Q&A platform.\n\nAML_MODEL_URL is the same name of the model in the ML workspace with (follow the format of aml:\/\/ + Name of the Model).\n\nExample: aml:\/\/sklearn_regression_model:1 (follow the format of aml:\/\/ + Name of the Model).\n\nHope this will help. Please let us know if any further queries.\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure AutoML maximum columns supported",
        "Question_creation_time":1638323249770,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/646730\/azure-automl-maximum-columns-supported.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi,\n\nIs there any documentation on the maximum columns supported by the AML both on the Portal and SDK?\n\nI tried to input a training sets with more than 60k columns and the process failed on the portal but still running on my notebooks.\n\nWonder is there any limits on the number of columns that we can put it?\n\nThanks!",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Moving contents from one container to other in storage blob",
        "Question_creation_time":1638289735473,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/646381\/moving-contents-from-one-container-to-other-in-sto.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"Is there a way to move container contents from one Container to another without using SAS tokens or keys using Python SDK in AzureML?\nThere are lot of resources which site the possibilities of moving containers.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-01T08:35:45.04Z",
                "Answer_score":1,
                "Answer_body":"@AntaraDas-4298\n\nHello,\n\nThanks for reaching out to us, there are several way to move the data to and from storage blob. The following articles describe how to move data to and from Azure Blob storage using different technologies:\n\nAzure Storage-Explorer\nAzCopy\nPython\nSSIS\nWhich method is best for you depends on your scenario.\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How do I get the experimentID inside a running pipeline script?",
        "Question_creation_time":1638292741140,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/646416\/how-do-i-get-the-experimentid-inside-a-running-pip.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello, I'm writing a ML pipeline.\n\nAt the end of a script I have to write the output to a SQL database, and I would need the ExperimentID as a field of the output dataframe.\n\nIs there a way for me to find within the running script in which experiment it's being run?\nOr is there a way for me to input the ExperimentID as a parameter to the pipeline at launch? From what I understand parameters are defined before the experiment is created so that's a bit confusing.\n\nIn case this is too complicated, is there a way I can somehow chain the pipeline output inside a script to the experiment it's being run?\n\nThank you very much,",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-01T04:39:29.95Z",
                "Answer_score":0,
                "Answer_body":"Hi, you can use the get_context method of the Run Class to get the run id. Here's an example:\n\n run = Run.get_context()\n run_id = run.id",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error - AttributeError: 'function' object has no attribute 'service_context'",
        "Question_creation_time":1638262419597,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/645756\/error-attributeerror-39function39-object-has-no-at.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi all,\n\nI am trying out some code on Azure machine learning notebook however I keep getting this error as stated above.\nCan anyone please help\nI tried to re-login\n\n\n\n\n\nRegards\nLyon",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-12-01T04:35:09.483Z",
                "Answer_score":0,
                "Answer_body":"Hi @romungi-MSFT,\n'\nI solved the problem already, it was because I did not include the parenthesis for the function Workspace.from_config()\n\n\n\n\n\nThanks again",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Can I use compressed data on TabularDataset?",
        "Question_creation_time":1638234150553,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/645118\/can-i-use-compressed-data-on-tabulardataset.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"I have a question about the source of TabularDataset on Azure Machine Learnigng.\n\nCan I use compressed data saved Azure Data Lake Storage Gen2 like below on TablarDataset without expansion?\n\ncsv with bzip2(.bz2)\n\n\nparquet with gzip(gz)\n\n\nparquet with snappy",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-30T02:15:20.327Z",
                "Answer_score":0,
                "Answer_body":"Hi, tabular dataset does not support compressed files. You'll need to extract the data as shown here for example before creating a tabular dataset. However, file dataset supports any format.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Internal server error while deploying scoring endpoint",
        "Question_creation_time":1638274714127,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/646024\/internal-server-error-while-deploying-scoring-endp.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Dear Azure community,\n\nUnfortunately, I am currently failing to deploy a scoring endpoint via ml studio or via the azure cli. I always get an internal server error (500). It's not because of the qutoas (I already requested additional ones).\n\nThe specific configurations and models would be those from the Azure Samples on GitHub (azureml-examples\\cli\\endpoints\\online\\model-1\\onlinescoring\\score.py and azureml-examples\\cli\\endpoints\\online\\managed\\sample\\endpoint.yml and blue-deployment.yml\n\nMy own configurations are based on this 1:1. Both configurations are not a problem locally and run smoothly. The server error only comes when deploying online.\n\nUnfortunately I don't have any further error information from the 500.\n\nRegion: West Europe\nSubscription: Visual Studio Enterprise - MPN\n\nHas anyone ever had this problem? Could someone please help me here?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-30T16:33:17.527Z",
                "Answer_score":0,
                "Answer_body":"@ChristophGattermayr-6000 Thanks for the details, Please share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Cannot access the storage account with the given account key. Please verify that the account key is valid.",
        "Question_creation_time":1629992057303,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/529375\/cannot-access-the-storage-account-with-the-given-a.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"Hi Azure ML Users, my model fails on the 2nd module with the error:\nAzureMLCompute job failed.\nBFSMountError: Unable to mount blob fuse file system\nInfo: Could not mount Azure Blob Container azureml-blobstore-547333bb-90a5-4a1c-b9a2-958870d93883 at workspaceblobstore: Unauthorized. Cannot access the storage account with the given account key. Please verify that the account key is valid.\nInfo: Failed to setup runtime for job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.\n\nThe only 2 things I did outside the Azure defaults was in creating the Azure ML workspace resource:\n1. I created my own new Storage Account.\n2. created my own Container Registry\n\nI did this so that I could select the lowest priced type in setting up all my resources. Previously, my models ran from Designer, no issues. thank you.\n\nAnd how do I run this a command?\n\"az ml workspace sync-keys -w myworkspace -g myresourcegroup\" to sync up the key again\n\nscreen shot of storage account, showing ML worksspace has access.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-02T08:49:40.02Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nHope you have solved this issue. Please make sure you are using the account access key as account key in the setting page in portal.\n\nYou can find account key, SAS token, and service principal information on your Azure portal.\n\nIf you plan to use an account key or SAS token for authentication, select Storage Accounts on the left pane, and choose the storage account that you want to register.\n\nThe Overview page provides information such as the account name, container, and file share name.\nFor account keys, go to Access keys on the Settings pane.\nFor SAS tokens, go to Shared access signatures on the Settings pane.\nIf you plan to use a service principal for authentication, go to your App registrations and select which app you want to use.\n\nIts corresponding Overview page will contain required information like tenant ID and client ID.\n\nPlease let us know if you still need help.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-11-30T16:47:05.923Z",
                "Answer_score":0,
                "Answer_body":"@MikeRichardson-3493\n\ni had the same problem .\nBy running az ml workspace sync-keys -w myworkspace -g myresourcegroup on your Azure cli works.\nI had installed azure cli and used with microsoft Powershell.\n\nSources :\ninstall azure cli : https:\/\/docs.microsoft.com\/en-us\/cli\/azure\/install-azure-cli\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-change-storage-access-key",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"dataset.to_pandas_dataframe() throws a ScriptExecution.StreamAccess.Authentication error",
        "Question_creation_time":1638194224630,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/644562\/datasetto-pandas-dataframe-throws-a-scriptexecutio.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":13,
        "Question_score":1,
        "Question_body":"Azure fails to connect with the Dataset citing 403 inspite of SAS token\nThis appears when we try to load the data as a pandas dataframe . dataset = Dataset.get_by_name() works\n\nError message:\n\n\n\n\n{\n\"error\": {\n\"code\": \"UserError\",\n\"message\": \"Execution failed in operation 'to_pandas_dataframe' for Dataset(id='data id', name='dataset name', error_code=ScriptExecution.StreamAccess.Authentication,error_message=ScriptExecutionException was caused by StreamAccessException.\\r\\n StreamAccessException was caused by AuthenticationException.\\r\\n Authentication failed for 'AzureBlob GetReference' operation at '[REDACTED]' with '403: AuthenticationFailed'. Please make sure the SAS token or the account key is correct.\\r\\n Failed due to inner exception of type: StorageException\\r\\n| session_id=session_id) ErrorCode: ScriptExecution.StreamAccess.Authentication\"\n}\n}",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-30T13:29:23.5Z",
                "Answer_score":1,
                "Answer_body":"The problem was solved by updating the account keys in the workspace.\naz ml workspace sync-keys -w mlw-kundenscore -g rg-datascience",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-11-30T01:44:50.843Z",
                "Answer_score":1,
                "Answer_body":"Hi, some suggestions include:\n\nCheck your Network and Firewall settings\n\n\nEnsure that you are providing the correct SAS token and in the correct format\n\n\nWhen generating a new SAS token, try to adjust your start time to be at least 15mins in the past (review Be careful with SAS start time)\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AML Hyper Drive - Stuck",
        "Question_creation_time":1635931220580,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/613972\/aml-hyper-drive-stuck.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"I am using a HyperDriveStep in a Pipeline and often get stuck in HyperDriveStep.\nI am using our company subscription and we have sufficient cores allocated for our ML development.\n\nWe have plan to use this on production very soon. Is it production ready (HyperDriveStep in AML)....!!!??\n\n\n\n\nHere is the HyperDrive Execution log: I have canceled the child run after 16 hours of waiting......!!!!!\n\n[2021-11-02 16:01:15Z] Submitting 1 runs, first five are: 5523baba:941f5822-2f1f-4075-a475-5980aa8c6d45\n[2021-11-02 16:03:18Z] Completing processing run id 941f5822-2f1f-4075-a475-5980aa8c6d45.\n[2021-11-02 16:03:18Z] Submitting 1 runs, first five are: 059c259e:7b1e6c57-6469-43cf-8ca7-f05837f0a8fc\n[2021-11-03 08:11:23Z] Execution of experiment canceled, update experiment status and cancel submitted nodes\n\n\n\n\nMy Run ID is : 7e90bbd9-c843-46e0-a611-7810d15a8c92\n\nIs there anyone can help us on this....!!!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-03T12:11:29.953Z",
                "Answer_score":1,
                "Answer_body":"@MohammadZahirulIslam-7110 Thanks for the question. Please share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.\nFor an example of using HyperDriveStep, see the notebook https:\/\/aka.ms\/pl-hyperdrive and Azure Machine Learning Pipeline with HyperDriveStep.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"clean up resources",
        "Question_creation_time":1636923021220,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/626538\/clean-up-resources.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\n\nI am trying to learn about machine learning and using the free resources. I read here about cleaning up resources:\n\nhttps:\/\/docs.microsoft.com\/en-gb\/azure\/machine-learning\/samples-designer#clean-up-resources\n\n\n\n\nI was wondering how this works.\n\nSuppose I am trying to build a recommender app:\n\nhttps:\/\/docs.microsoft.com\/en-gb\/azure\/machine-learning\/samples-designer#recommender\n\n\n\n\n\nThis will easily take a few hours. If I delete the resource I would have to start over again. Surely Microsoft cannot have meant it like that, right? How do I go about using my free resources without busing my limits.\n\nThanks,\n\nNaveen",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-15T15:52:58.303Z",
                "Answer_score":0,
                "Answer_body":"Thanks for the question. Here is link to Azure Machine Learning pricing, also please check the FAQ at the end.\n\nThis is in fact by design that \u201cunregister\u201d doesn\u2019t actually delete your underlying storage; since an Azure ML Dataset is a reference point to your data in storage, this means we don\u2019t copy your data to your workspace so no extra storage cost is incurred. This also helps safeguard against accidentally deleting files in storage when cleaning up assets in an Azure ML workspace\n\nThere is a Private Preview for deleting an experiment, however such functionality does not delete the intermediate data generated for the run or any child run.\n\u2022 Not deleted:\no Files in azureml-blobstore-GUID\/azureml\/{run_id}\no Code snapshot (zip files)\no Pipeline intermediate data and child runs\no Metric data\n\n\u2022 Deleted\no The output folder content\no Log files\n\n\n\n\nthere are no additional Azure Machine Learning charges. The compute target that you created here automatically autoscales to zero nodes when it's not being used. This action is taken to minimize charges.\n\nThe resources that you created can be used as prerequisites to other Azure Machine Learning tutorials and how-to articles.\n\nLink to cleanup resources: https:\/\/docs.microsoft.com\/en-gb\/azure\/machine-learning\/quickstart-create-resources#clean-up",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure AutoML Featurisation Error",
        "Question_creation_time":1638154550033,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/643670\/azure-automl-featurisation-error.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"According the following doc, I should be able to to turn on FeaturizationConfig in the settings:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train\n\nHowever I'm getting the following error when I try to change the switch to 'FeaturizationConfig' when setting up the AutoML experiment:\n\nConfigException: ConfigException: Message: Invalid argument(s) 'featurizationconfig' specified. Supported value(s): 'off, auto'\n\nThe following is my settings:\n\nimport logging\n\n\nautoml_settings = {\n\"iteration_timeout_minutes\": 15,\n\"experiment_timeout_hours\": 0.3,\n\"enable_early_stopping\": True,\n\"primary_metric\": 'spearman_correlation',\n\"featurization\": 'FeaturizationConfig',\n\"verbosity\": logging.INFO,\n\"n_cross_validations\": 5\n}",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-29T12:46:23.847Z",
                "Answer_score":0,
                "Answer_body":"@SoonJooGenting-3682 Thanks, Previously, it was a black-box preprocessing, with user\u2019s preprocess=True\/False setting.\nNew change includes deprecation of preprocess and introduction of new field featurization, where featurization = \u2018auto\u2019 (for automatic featurization, comparable to preprocess=True) \/ \u2018off\u2019 (to turn off featurization, comparable to preprocess=False) \/ FeaturizationConfig (object to pass in customized configuration on featurization setting).\n\nFor more information on custom featurization as well as how to construct FeaturizationConfig is in this documentation.\nWe also have a notebook available with example in our git repo.\nUsage example:\n\n from azureml.automl.core.featurization import FeaturizationConfig\n    \n featurization_config = FeaturizationConfig()\n featurization_config.add_column_purpose('Column2', 'Categorical')\n featurization_config.add_column_purpose('Column5', 'Categorical')\n    \n automl_config = AutoMLConfig(task = 'classification', compute_target=compute_target, featurization=featurization_config, **automl_settings )\n remote_run = experiment.submit(automl_config, show_output = False)\n\n\n\n\nFor classification & regression you do have the option to turn off automatic featurization.\n\nfeaturization\nstr or FeaturizationConfig\n'auto' \/ 'off' \/ FeaturizationConfig Indicator for whether featurization step should be done automatically or not, or whether customized featurization should be used.\n\u2026\nNote: Timeseries features are handled separately when the task type is set to forecasting independent of this parameter.\n\n\n\n\n\u2022 AutoMLConfig Class",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How to move all the ai models (service endpoints) from one compute cluster to another cluster in azure without any effects",
        "Question_creation_time":1636704232043,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/624851\/how-to-move-all-the-ai-models-service-endpoints-fr.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":16,
        "Question_score":0,
        "Question_body":"I have machine learning models which is deployed in Azure aks in 'x' Cluster , Now i want to move this models and its endpoint in another cluster which is 'y' within same workspace and subscription ,So how to do this without any changes to its rest endpoint as this endpoints are in production use already.\n\nalso if this is not possible then can i upgrade my x cluster with newer version without affecting my endpoints",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-12T11:50:38.363Z",
                "Answer_score":1,
                "Answer_body":"@VishalSuryavanshi-3563 Thanks for the question. Here is link to the blog for New managed online endpoints features in Azure ML: Autoscaling, Debugging, MLflow and more.",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"open a csv file",
        "Question_creation_time":1636324623930,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/618167\/open-a-csv-file.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"Hello,\n\nI have a very basic question. I have a CSV file saved in a blob. I need to open that file in ML Studio. whenever I reference the file I just get an error that the file doesn't exist. Please help",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-08T10:12:28.853Z",
                "Answer_score":0,
                "Answer_body":"@KamilaThompson-6591 Thanks for the question. AML datasets enables customers to benefit from our storage, compute and framework agnostic data access solution. Additionally with the launch of identity based access, customers can just pass the url directly to create a dataset (without the need for create a datastore). This avoids storing credentials in AML or managing data access yourself.\n\nHere is the document to Connect to data with the Azure Machine Learning studio.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Failed to install python 3.5",
        "Question_creation_time":1636717036753,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/625123\/failed-to-install-python-35.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I need a conda environment with python 3.5.\n\nWhile I was creating one, it showed in the specification that python 3.5 would be installed. But after the environment was created, python version was 3.8 instead of python 3.5 (pls. see the screenshot below)\nI tried to create a new env with python 3.5 twice, but always python 3.8 in the end.\n\nI found someone had similar issue here, but I didn't find solution to this issue.\n\nCan someone explain why it happens? Thanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-19T11:53:13.773Z",
                "Answer_score":1,
                "Answer_body":"Hi @YutongTie-MSFT , I just want to do a short update. Though I don't know, if someone maybe has fixed this problem on the last days (if yes, thanks!), the python version in the environment that I showed above is magically python 3.5 instead of python 3.8.5...\nIn order to test, I just created another env with python=3.5 and it succeeded this time.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is it possible to use pre-defined designer modules when building pipelines using python-sdk?",
        "Question_creation_time":1636017242333,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/615328\/is-it-possible-to-use-pre-defined-designer-modules.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":1,
        "Question_body":"Hey, I am trying to build ML pipelines using the python-sdk. I am wondering if I can use those pre-defined modules from Designer when building pipelines using the python-sdk?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-05T02:26:50.01Z",
                "Answer_score":1,
                "Answer_body":"Hello @Chris-2395\n\nThanks for reaching out to us. But this currently is under development and we have no exact ETA for it.\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-11-26T02:52:46.95Z",
                "Answer_score":1,
                "Answer_body":"Hi @Chris-2395, would you share more detail use case of your scenario for built-in component. We are planning to support built-in component in CLI and SDK. For your use case, do you need to use built-in component only with built-in component or you also expect to use them with your customized component?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Where are registered models saved in storage containers?",
        "Question_creation_time":1637664392747,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/637656\/where-are-registered-models-saved-in-storage-conta.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"Have a small doubt. i could run a pipeline successfully and also register the model. I can locate the model on the AzureML UI .\nModel.get_model_path() shows that it is located in azureml-models\/model-name\/..\n\nBut was wondering where exactly they are stored in storage account? Becasue i dont find and container azureml-model listed.\n\nAny lead on this will be helpful",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-26T00:22:51.657Z",
                "Answer_score":0,
                "Answer_body":"@AntaraDas-4298 Thanks for the details. there is not an azureml-models container, run.register_model() copies the model files to the azureml container.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure ML kernel",
        "Question_creation_time":1637143159873,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/630550\/azure-ml-kernel.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi,\n\nI installed custom env and added it to jupyter on my compute instance.\nYet, when I run the code error says that it occurs under base env (azureml_py38)\n\nsee the pic. Can you help me?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How to update the labelled tags in the azure machine learning ?",
        "Question_creation_time":1637728063797,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/638862\/how-to-update-the-labelled-tags-in-the-azure-machi.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":1,
        "Question_body":"![151940-test-img.png][1]\n[1]: \/answers\/storage\/attachments\/151940-test-img.png\n\nHow can I edit the existing tags and it will update to the tags in labelled images.\nFor example :\nEdit the tags['test1'] to new tag['Breeze'] and the tags['test1] in the image will replace with the new tag ['Breeze']\nHow can I do it in the azure UI or by using python",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-24T08:50:07.057Z",
                "Answer_score":0,
                "Answer_body":"@ZiXiangYan-6877 You can edit the tags using the Details tab -> Label Classes screen of your project from the portal. If the project is in paused state you can add new labels and choose the required option to continue or start over by keeping existing labels or removing all labels and relabel.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Got error \"TimeseriesDfUniqueTargetValueGrain\" with AutoML",
        "Question_creation_time":1637800802320,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/640215\/got-error-34timeseriesdfuniquetargetvaluegrain34-w.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"\"message\": \"The input data contains time series with only unique target values. One such series that displays this behavior is the time series 5962. Please only provide series with non-unique target values.\"\n\nGot this error when trying to use AutoML training time series models. I am not sure what this error means and where to find this time series 5962. Could someone please explain what is going wrong with this data and where do I find time series 5962?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure ML private notebooks (multiple user\/project)",
        "Question_creation_time":1637769772467,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/639765\/azure-ml-private-notebooks-multiple-userproject.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hello all,\n\nUse case:\nActually, I would like to prevent some users (guest user for example) from viewing some notebooks with sensitive data. I started by creating several Azure ML workspaces but given the limit of storage accounts (250 per subscription), I shared the same storage account for several workspaces... And I was surprised that the same notebooks were shared in all workspaces for all users.\n\nSo, I try to understand how to work on Azure Machine Learning while managing notebook access.\n1) Multiple workspace with multiple storage account = Limited in the long term as we have a lot of projects (max 250 storage acc)...\n2) Multiple workspace with same storage account = all notebooks shared...Impossible to work with guest users...\n\n\n\n\nBecause these two issues, I was wondering:\n- What is the way to limit access to some Azure Machine Learning Notebooks?\n- Is there any good practice about multiple project with AML workspaces ? (One workspace per project or one workspace per environment)\n\n\n\n\nKind regards,",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-24T16:30:28.203Z",
                "Answer_score":0,
                "Answer_body":"Hi, your notebooks are stored in your workspace's storage account, and can be shared with others, depending on their access level to your workspace. By default, your notebooks are in a folder with your username, and others can access them there. With Azure RBAC, you can manage access to your AML workspace. These are the default roles, however for your scenario, I recommend creating custom role.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning - Data Labeling - Refresh",
        "Question_creation_time":1636385510357,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/619198\/azure-machine-learning-data-labeling-refresh.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello,\n\nI've started a new Data labeling project in Azure Machine Learning and I configured the incremental refresh.\n\nHow often is the data refreshed? Is it possible to force a refresh manually? Is it possible to execute this command via SDK (Python or PowerShell)?\n\nThanks.\n\nG",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-09T02:24:49.197Z",
                "Answer_score":0,
                "Answer_body":"Hi, data is refreshed within 24hrs. Currently, incremental refresh is only enabled using the portal and there's no option to trigger refresh manually.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How to run python 2.7 scripts on a computer cluster",
        "Question_creation_time":1637171846430,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/631040\/importerror-cannot-import-name-outputfiledatasetco.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I am aware that azureml will drop support for python 2.7, but I have got some old codes and have to finish training the models. Since I will not use the codes afterwards anyway, so I do not want to spend much time to port to python 3.\n\nAs I tried to run the codes in python 2.7 on a compute cluster, I got the error ImportError: cannot import name OutputFileDatasetConfig coming from this line:\nfrom azureml.data import OutputFileDatasetConfig\nThe environment, that I have created for python 2.7, has azureml-core v1.1.5. I cannot find any documentation for this version, so I do not know, if it supports OutputFileDatasetConfig.\n\nCan someone tell me, how I can run my codes in python 2.7 on compute clusters? Thanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-18T03:49:39.763Z",
                "Answer_score":0,
                "Answer_body":"Hello @Lu-3578\n\nThanks for reaching out to us. I have not found any official document either.\n\nIn this scenario, I think the quickest way to solve the problem is to raise a support ticket.\n\nLet me know if you have no support plan, please share the ticket id since I will forward this issue to product team to see what we can do more.\n\n\n\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Loosen azureml-dataprep requirements to cloudpickle<=2.0.0",
        "Question_creation_time":1637242355487,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/632441\/loosen-azureml-dataprep-requirements-to-cloudpickl.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi,\n\nI couldn\u2019t find a specific github repo for azureml-dataprep so I decided to also write you here. Can you forward it to the devs?\n\n\n\n\nazureml-dataprep (which is a depedency for azureml-dataset-runtime) has requirement cloudpickle<2.0.0 and >=1.1.0. However there is to my knowledage no breaking features going from cloudpickle==1.6.0 to cloudpickle==2.0.0. cloudpickle==2.0.0 introduces some very effective tools for serializing helper scripts which is very helful when working with azureml. So azureml-dataprep should allow cloudpickle<=2.0.0\n\nIntro to new cloudpickle:\nhttps:\/\/github.com\/cloudpipe\/cloudpickle#overriding-pickles-serialization-mechanism-for-importable-constructs\nPR:\nhttps:\/\/github.com\/cloudpipe\/cloudpickle\/pull\/417\nGithub issue:\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/1637",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-19T02:48:45.06Z",
                "Answer_score":0,
                "Answer_body":"@ThomasH-1455\n\nThank you so much for the contribute, I have sent an email to the author for the PR review and merge.\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Local Deployment Azure ML failed with error",
        "Question_creation_time":1631297380170,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/547716\/local-deployment-azure-ml-failed-with-error.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"I am a beginner in the Azure. I am using this tutorial https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python of setting a dummy script for a local web service but many errors are coming up. It is strange because I am using an h5 file (model involving Keras and tensor flow) in place of onxx file. I used the code\n\n from azureml.core import Environment\n from azureml.core.model import InferenceConfig\n    \n env = Environment(name=\"myenv\")\n conda_dep = CondaDependencies()\n conda_dep.add_conda_package(\"tensorflow\")\n conda_dep.add_conda_package(\"pip\")\n conda_dep.add_pip_package(\"azureml-core\")\n conda_dep.add_pip_package(\"azureml-contrib-services\")\n conda_dep.add_pip_package(\"azureml.api\")\n env.python.conda_dependencies=conda_dep\n inference_config = InferenceConfig(\n     environment=env,\n     source_directory=\".\/source_dir\",\n     entry_script=\".\/echo_score.py\",\n\n)\n\nI am trying to deploy the model local using Webservice. But always getting some error. I have tried many times but does not work. I am always getting some error. It is bizarre.\n\n\n\n\n$ conda update -n base -c defaults conda\n\n\n\n\nPip subprocess error:\nERROR: Could not find a version that satisfies the requirement azureml.api (from -r \/azureml-environment-setup\/condaenv.811vr6y8.requirements.txt (line 4)) (from versions: none)\nERROR: No matching distribution found for azureml.api (from -r \/azureml-environment-setup\/condaenv.811vr6y8.requirements.txt (line 4))\n\n\n\n\nCondaEnvException: Pip failed",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-13T07:04:56.04Z",
                "Answer_score":1,
                "Answer_body":"@santra-4408 The error indicates that the environment setup is not done or the start of the environment setup is failing. I think you need to add the following line since you are using conda package installation along with pip packages.\n\n  from azureml.core.environment import CondaDependencies\n\nYou can also use this sample notebook for localwebservice deployment using Azure notebooks feature for ml.azure.com\nThis notebook or repo can be cloned directly from the portal and can be run to deploy the webservice.",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-11-23T14:06:07.737Z",
                "Answer_score":0,
                "Answer_body":"Hi I am trying to deploy Prophet Model.\nModel is logged as mlflow.prophet flavour.\nHere the code for deployment:\n\n import azureml\n import mlflow.azureml\n from azureml.core import Workspace\n from azureml.core.authentication import ServicePrincipalAuthentication\n from azureml.core.webservice import AciWebservice, Webservice\n    \n    \n    \n principal_auth = ServicePrincipalAuthentication(tenant_id, principal_id, app_secret)\n workspace = Workspace.get(name=workspace_name, subscription_id=subscription_id, auth=principal_auth, resource_group=workspace_rg)\n model_image, azureml_model = mlflow.azureml.build_image(model_uri='runs:\/016fc3f2d5c34c8eadbeb20ad16d3\/082358timeseriesforecasting', workspace=workspace)\n model_image.wait_for_creation(show_output=True)\n\n\n\nWhen I am creating image from Model Artifact this error came :\n\nWebserviceException: WebserviceException:\nMessage: Image creation polling reached non-successful terminal state, current state: Failed\nError response from server:\nStatusCode: 400\nMessage: Docker image build failed.\nInnerException None\nErrorResponse\n{\n\"error\": {\n\"message\": \"Image creation polling reached non-successful terminal state, current state: Failed\\nError response from server:\\nStatusCode: 400\\nMessage: Docker image build failed.\"\n}\n}\n\n\n\n\nIn Container logs error is shown below:\n\n[0mThe command '\/bin\/sh -c CONDA_ROOT_DIR=$(conda info --root) && if [ -n \"$AZUREML_CONDA_ENVIRONMENT_PATH\" ]; then conda env update -p \"$AZUREML_CONDA_ENVIRONMENT_PATH\" -f '\/var\/azureml-app\/conda.yaml'; else conda env update -n base -f '\/var\/azureml-app\/conda.yaml'; fi && conda clean -aqy && rm -rf \/root\/.cache\/pip && rm -rf \"$CONDA_ROOT_DIR\/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name pycache -exec rm -rf {} +' returned a non-zero code: 137\n2021\/11\/23 12:21:39 Container failed during run: acb_step_0. No retries remaining.\nfailed to run step ID: acb_step_0: exit status 137\n\nRun ID: cj58 failed after 6m19s. Error: failed during run, err: exit status 1\n\n\n\n\n\n\n\nI have tried different yaml dependencies even defaults but of no use.\nDo anyone have a clue what is wrong here? Any solution?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Scaling and load balancing with deployed machine learning containers - ACI + Application Gateway vs AKS?",
        "Question_creation_time":1637592050953,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/636334\/scaling-and-load-balancing-with-deployed-machine-l.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":18,
        "Question_score":0,
        "Question_body":"I have been working on a deployment solution for machine learning models. Our objective is to minimize the internal development effort while maintaining high availability and full control over the API. Our first solution is a deployment as azure webservice to ACI using the azureml.core.model.Model.deploy method with a deployment config azureml.core.webservice.AciWebservice.\nWe quickly noticed that our initial deployment configuration was not powerful enough and wanted to upgrade the hardware. Here is the first issue: it seems that the ACI webservice does not support any GPU instances. So my first question is: which service is recommended to deploy models that require GPU for inference?\nHowever, we first wanted to deploy the same image onto a more powerful CPU. When doing this, we got the error\n\"Invalid overwrite request - cannot update container resource requirements, dns name label, or deployment type. Please delete and redeploy this service.\". After deleting and redeploying, the scoring URI changes, which is a problem for us. As we cannot predict the load and resource requirements at this point, we need a way of (auto-) scaling the containers and also to update single container resource requirements, without changing the endpoint. As this seems to be impossible using the scoring URI provided by azureml endpoint, I had the feeling that we need to hide the azureml endpoint behind a load balancer. Is this the intended way of doing it? If so, should I use application gateway or traffic manager? If I use application gateway, how do I configure the VPC such that the containers managed by azureml are available to application gateway? Or should I completely abandon ACI and go with AKS? It would be great to get some expert feedback on this as I feel like every single of these questions leads me down a rabbit hole and I cannot continue the actual project if I first have to learn about >10 azure services and all cross combinations of those.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Terminal is blank, while compute instance is running",
        "Question_creation_time":1637237700637,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/632304\/terminal-is-blank-while-compute-instance-is-runnin.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"For about 2 or 3 days, the terminal hasn't been showing properly.\nIf I open a new terminal, it shows properly. After I switch to another terminal\/script\/notebook tab, and then switch back to the previous terminal tab, it is then blank (see screenshot below). I tried on 2 different compute instances as well as in 2 different browsers incl. edge, the same problem remains.\nDoes anyone have the same problem and the solution?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-18T20:29:43.52Z",
                "Answer_score":0,
                "Answer_body":"Hi, I wasn't able to reproduce this issue. I'm able to switch back and forth between notebooks\/terminals. Please share the region of your resource so I can verify. It could be a problem with your computer or network. You can also try using private browsing.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"IoT Edge custom machine learning module reported error status",
        "Question_creation_time":1637069073437,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/629089\/iot-edge-custom-machine-learning-module-reported-e.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"Hi,\n\nI have developed a ML solution based on this tutorial.\nI adapted the Python notebook to run into an existing ML workspace.\nUnfortunately, when I tried to create Docker image, it failed with error 500. I found out that the Image class is deprecated (suppose this was the reason of the error), so I relied on the Environment class (in particular this documentation) and everything worked fine.\nAlso, testing the model as Web Service ACI endpoint works correctly, providing the result:\n['{\"machine\": {\"temperature\": 31.16469009, \"pressure\": 2.158002669}, \"ambient\": {\"temperature\": 21.17794693, \"humidity\": 25}, \"timeCreated\": \"2017-10-27T18:14:02.4911177Z\", \"anomaly\": false}']\n\n\n\n\nThe issue I need support is the following: after deploying the ML model as container to the Edge device (in this case a Ubuntu VM created using this template), the ML module reported an error:\n\nNo logs are displayed, neither through VM SSH access, nor through the Portal.\n\nThe only information that I found out is this one:\n\n\nI checked multiple times the correctness of the image URI for the ML module, and I'm pretty confident that it is, since the ACI is based on it and the Web Service test was succeded.\n\nWhat could be the problem here?\n\nThanks",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"AML lab : Error in deparse1(call): could not find function \"deparse1\" when executing R Script",
        "Question_creation_time":1637247331003,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/632506\/aml-lab-error-in-deparse1call-could-not-find-funct.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi there\n\nMy Azure ML lab model was running fine until today when I get this error when running an R script:\n\nError in deparse1(call): could not find function \"deparse1\"\n\nI tried the suggestion to set the env var \"AZUREML_COMPUTE_USE_COMMON_RUNTIME\" : \"false\" but still failing\n\nFull error:\n\nAmlExceptionMessage:User program failed with FailedToEvaluateScriptError: The following error occurred during script evaluation, please view the output log for more information:\n---------- Start of error message from R interpreter ----------\nGot exception when invoking script: 'Script failed with error message:\nError in deparse1(call): could not find function \"deparse1\"\n\n\nazureml_main(input_dataframe_1, input_dataframe_2), mine_rules_general(), mine_rules(.GlobalEnv$df, base_str, conf, NULL, aggregate_categories, multilevel, params), apriori(.GlobalEnv$dataset, parameter = params), .handleSimpleError(function (e)\n{\nerror_msg <<- paste(toString(e), toString(sys.calls()[-c(1:3)]), sep = \"\\n\")\nstop(e)\n}, \"could not find function \\\"deparse1\\\"\", quote(deparse1(call))), h(simpleError(msg, call))\n'.\n---------- End of error message from R interpreter ----------\n\n\nModuleExceptionMessage:FailedToEvaluateScript: The following error occurred during script evaluation, please view the output log for more information:\n---------- Start of error message from R interpreter ----------\nGot exception when invoking script: 'Script failed with error message:\nError in deparse1(call): could not find function \"deparse1\"\n\n\nazureml_main(input_dataframe_1, input_dataframe_2), mine_rules_general(), mine_rules(.GlobalEnv$df, base_str, conf, NULL, aggregate_categories, multilevel, params), apriori(.GlobalEnv$dataset, parameter = params), .handleSimpleError(function (e)\n{\nerror_msg <<- paste(toString(e), toString(sys.calls()[-c(1:3)]), sep = \"\\n\")\nstop(e)\n}, \"could not find function \\\"deparse1\\\"\", quote(deparse1(call))), h(simpleError(msg, call))\n'.\n---------- End of error message from R interpreter ----------\n\n\n\n\nWould much appreciate any help on this",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-19T03:16:40.423Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us. I have seen the same error one time due to the R version is too old on my side.\n\nI will high recommend you check your R version and other package's version to make sure everything is compatible.\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Best Approach to Clientside Machine Learning for Text Classification",
        "Question_creation_time":1637112667940,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/629917\/best-approach-to-clientside-machine-learning-for-t.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I have approximately 100k rows of text data (initially PDF documents that have been OCR). Most are rows of less than 5000 characters. Each of the source documents are addressed to some department. These are typically in the form of the below examples where the target department would 'Urology' (there are several departments).\n\nUrologly Department\n\n\nUrologly Clinic\n\n\nUrology Out Patients\n\n\nUrology\n\n\nDear urology team\n\nI have read a bit on ML Text Analysis and it seems I should be able to make a pretty good model by reviewing several hundred documents for each department (I have built an App to help me do this) and manually Classifying those documents. Some documents may mention urology but are actually addressed to another department. Typically the addressed department text is at the top third (first 3-7 lines) of the text body.\n\nI cannot use any online tools, i.e. I can't upload any of the Document text to servers to process I need a client side library. I have read and completed several tutorials using the ML.net but these are pretty basic (sentiment, entity detection without any initial training), and read an excellent blog at MonkeyLearn: which seems to acknowledge that can do what I imagine I should be able to do.\n\nSo can anybody point me in the right direction, can I use some offline Microsoft client library to complete my task? Is there some other Open Source client library i should look at. Will I have to learn Go, or python to complete the task (currently a C# dev).\n\nNote: I could get fairly good matches simply using SQL Text search and a bit of C# with plenty of hard coded rules, but I thought I'd try ML -- however its a nest of complications at the moment and i am going around in circles.\n\nMany Thanks\nMike.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-17T10:19:58.317Z",
                "Answer_score":0,
                "Answer_body":"@MikeShapleski-3383 I see two possible solutions for your scenario.\n\nExtracting text from your documents using the computer vision API and passing the required text as input to Azure Text Analytics for Health API\n\n\nUsing Azure cognitive search to upload the documents and creating a search service and enabling specific skills on the service to extract PII data or entities\n\nThe first solution can help you achieve this and ensure everything is offline or using docker containers without uploading any of your data to any storage externally. For billing purposes the containers need to connect to a metering endpoint on Azure to bill your usage of both these services(Computer Vision API & Azure text analytics containers). Also, you can use C# client library to call the local endpoint of these containers. The setup could take time to configure docker containers and passing the PDF documents to the computer vision read API to extract text. The extracted text can then be directly used or stored, to call the text analytics for health API.\n\nThe second solution can be used to index all the documents by using the search service by having your data in the cloud or behind a firewall to index the documents and make them searchable. There are some skills that can be enabled on the search service to extract entities and other PII information but this may not extract the same data as text analytics for health. This solution can be faster to setup because you can directly query your data after uploading the documents.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"build an AZURE ML enviroment from docker image in dockerhub",
        "Question_creation_time":1635963924763,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/614519\/build-an-azure-ml-enviroment-from-docker-image-in.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I want to use https:\/\/hub.docker.com\/layers\/shi2yu3\/mainz\/v7_nccl2804\/images\/sha256-298ca59f25e56ff8d0f3faeb7493618ff7d69149e6a92283ed3176a215b8da8d?context=explore in Azure ML as an environment for model training and testing. Any idea how to do this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-05T10:56:13.927Z",
                "Answer_score":0,
                "Answer_body":"@MiaHu-2196 I think your scenario needs to use a custom docker image for training. In that case, you can refer to the steps in this documentation to use this image in your build.\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AzureML workspace: IP addresses of compute instances and clusters",
        "Question_creation_time":1636666325000,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/624341\/azureml-workspace-ip-addresses-of-compute-instance.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"For the compute instances\/clusters in our AzureML studio workspace to communicate with our Snowflake server, we need to provide their IP addresses to Snowflake admin for whitelisting.\n1) When a compute instance is created, it comes with a static IP address, which is random. Is it possible to limit the IP addresses to a pre-defined range so that our snowflake admin can whitelist the range, instead of individual IP address of each compute instance?\n2) When a cluster is created, the IP address changes each time it is scaled up from 0 nodes. This makes it impossible to whitelist. Is it possible to limit the IP address to a pre-defined range as well?\nOur AzureML workspace is currently not behind any virtual network yet. Any suggestions about the direction to secure our workspace and facilitate its outbound communication (especially with snowflake servers) are highly appreciated. Thanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-12T07:26:26.767Z",
                "Answer_score":0,
                "Answer_body":"@ZhenlongLi-6900 You can whitelist the range of IPs based on the list published by Azure. The list can be downloaded from here.\nThe compute instance and the Azure ML workspace IP range list will differ from region to region so I would advise to lookup your existing IPs that are whitelisted in this list first and confirm if the IP matches within the range that is published. The range usually does not change so frequently so frequent whitelisting will not be required but having a mechanism or automation around validating the list regularly would help your team to pro-actively whitelist the required IPs to not break your existing applications. I hope this helps.\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Where can and should I save a trained model?",
        "Question_creation_time":1636989187060,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/627680\/where-can-and-should-i-save-a-trained-model.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\n\nI am new to Azure and am currently having a problem with saving a CNN model that is created by my training script. I am currently trying to save it in my project folder under the 'outputs' directory yet the model refuses to be saved. The size is over 300 MB so that may be a further problem. I have looked around for a solution but have not seen much that could help me. I am using PyTorch and am trying to save my model using the torch.save(...) function into a .tar file. Now, my question is how and where should one save the models generated by a training script and how would one ultimately load that same model to then use it for inference? Any help is greatly appreciated :)",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-15T19:05:25.077Z",
                "Answer_score":0,
                "Answer_body":"Hi, here's an example training script showing how to save trained pytorch model. You can then register, deploy, and consume the model. For more details on training pytorch models, please visit this document. Also, feel free to review where to save and write files for experiments. If you're still unable to save the trained model, please share the error message or steps to reproduce the issue. Hope this helps!\n\n def main():\n     print(\"Torch version:\", torch.__version__)\n    \n     # get command-line arguments\n     parser = argparse.ArgumentParser()\n     parser.add_argument('--num_epochs', type=int, default=25,\n                         help='number of epochs to train')\n     parser.add_argument('--output_dir', type=str, help='output directory')\n     parser.add_argument('--learning_rate', type=float,\n                         default=0.001, help='learning rate')\n     parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n     args = parser.parse_args()\n    \n     data_dir = download_data()\n     print(\"data directory is: \" + data_dir)\n     model = fine_tune_model(args.num_epochs, data_dir,\n                             args.learning_rate, args.momentum)\n     os.makedirs(args.output_dir, exist_ok=True)\n     torch.save(model, os.path.join(args.output_dir, 'model.pt'))\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning - Specify disk storage type",
        "Question_creation_time":1636713894743,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/625035\/azure-machine-learning-specify-disk-storage-type.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hi,\n\nIs there a way to specify the disk storage type for Compute instances?\nBoth the Azure portal and ARM templates do not have an option to define the disk storage type, which defaults to the P10 disks (Premium SSD).\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-15T05:00:01.093Z",
                "Answer_score":0,
                "Answer_body":"@simonmagrin Thanks, Currently There's no way to change the disk storage type for CIs or compute clusters. We have added this to our product backlog item to support in the near future.\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"AzureML Endpoint Record Limit",
        "Question_creation_time":1636729296570,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/625373\/azureml-endpoint-record-limit.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"I have a customer who is receiving a 424 error when they try to pass 13k records to an endpoint for inference but succeeding when passing 6k records. My questions are:\nWhat are the record limits for managed endpoints and does this vary by compute?\nIs there a way to reconfigure this limitation or is the best solution to have them loop over the records if they're over the limit?\n74900502>",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-13T12:56:43.057Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nPlease refer to this document for any limitation about Azure Machine Learning Service.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-quotas#azure-machine-learning-assets\n\nTo raise the limit or quota above the default limit, open an online customer support request at no charge.\n\nYou can't raise limits above the maximum values shown in the preceding tables. If there's no maximum limit, you can't adjust the limit for the resource.\n\nWhen you're requesting a quota increase, select the service that you have in mind. For example, select Azure Machine Learning, Container Instances, or Storage. For Azure Machine Learning compute, you can select the Request Quota button while viewing the quota in the preceding steps.\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML realtime endpoint provisioning fail",
        "Question_creation_time":1632622407193,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/566381\/azure-ml-realtime-endpoint-provisioning-fail.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":2,
        "Question_body":"When creating the azure ml real-time endpoint, at the end of the journey the provisioning is falling. The reason for the failure is not included. Have anyone have an idea why that is happening and how to solve that?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-27T16:22:57.577Z",
                "Answer_score":0,
                "Answer_body":"@YasiruRandika-5760 Thanks, The service has failed to deploy due to an error or crash, So Please share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-11-05T02:05:07.057Z",
                "Answer_score":0,
                "Answer_body":"No log is there and even I am getting the error",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-11-13T12:48:17.66Z",
                "Answer_score":0,
                "Answer_body":"Hi, I'm experiencing the same issue.\nDid someone figure out the cause?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Check Azure ML Instance Type",
        "Question_creation_time":1636608553670,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/623173\/check-azure-ml-instance-type.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":24,
        "Question_score":1,
        "Question_body":"How do i check current instance of AzureML type ? Where menu can i acces to see the type ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-12T05:39:05.823Z",
                "Answer_score":1,
                "Answer_body":"You can view the machine type in the compute section.\n\nGo to the Microsoft Azure Machine Learning Studio and In Manage section, click on Compute, It will show all your available compute instances.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Best compute cluster for training large image datasets !",
        "Question_creation_time":1633703536287,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/583349\/best-compute-cluster-for-training-large-image-data.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Good morning,\nI have a a dataset that consist of 99000 (256 x 256 pixels) images. I am trying to use this dataset to training a generative advesarial network (GAN) for at least a 1,000 epoch.\nCurrently, I am using a standard_NC24r (24 cores, 224 GB RAM, 1440 GB disk) GPU (4 x NVIDIA Tesla K80) cluster but the training is slow. It takes about 3000 seconds to train 1 epoch. This implies it would take at least a month to complete training.\nIs a cluster that I can used to speed up training?\n\nThanks for your help in advance\n\nMany thanks\n\nRoland",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-11T05:01:12.66Z",
                "Answer_score":0,
                "Answer_body":"@OkwenRolandT-6377 Thanks, Instead of bigger machines with more memory, there are techniques to be used with Aml Compute for larger datasets. The Parallel Run Step is an AzureML Pipeline Step which enables parallel processing or data partitions across multiple workers on multiple nodes. PRS (ParallelRunStep) is designed for embarrassingly parallel workload, e.g. train many models, batch inference, etc.\n\nAlso look into using some of the curated images provided for compute clusters.\nSpecifically look into the DASK image.\n\nCurated environments - Azure Machine Learning | Microsoft Docs",
                "Answer_comment_count":4,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Trouble Accessig the Machine Learning resource on my Azure for Students account",
        "Question_creation_time":1636577704690,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/622698\/trouble-accessig-the-machine-learning-resource-on.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I am trying to create a machine learning resource with my Azure for Students account, but every time I hit create it tells me that I need to upgrade my account to access it. I have confirmed that I do have an azure for students account, I don't know why I can't create the resource. Any guidance would be helpful. Thanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-11T07:08:07.2Z",
                "Answer_score":0,
                "Answer_body":"@JacobReynolds-1964 This message to upgrade appears when the 100$ credit in your account is used already. You can upgrade to pay-as-you-go and create a workspace resource, and you will be billed for any compute used as part of the experiments created in the workspace. Please check the FAQ on this page confirming the same.\n\n\n\n\nPersonally, if you like to try out the workspace without upgrading your student account you can create a normal Azure free account with your personal email id and try using the same with the 200$ credit after which you also need to upgrade this account to pay-as-you-go.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to use model created in Azure AutoML",
        "Question_creation_time":1636445777447,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/620181\/how-to-use-model-created-in-azure-automl.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Absolute Azure beginner here.\n\nI created a forecast model, and I can forecast next month when I deploy and test the model on Azure.\n\nHowever, I would like to read the pickle file, turn it and predict more than only the next month, let's say one year.\n\nThen I would like to do something like this:\n\n y_pred = model.predict(x_test)\n\n\n\n\nHow can I achieve this? I tried reading the pickle file but it only returns an object which I am unsure of what to do with.\n\nKind regards and thank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-09T23:12:15.417Z",
                "Answer_score":0,
                "Answer_body":"Hi, with forecast horizon parameter, you can select how many periods forward you would like to forecast. Currently, you can consume your automl model using a Client or PowerBI. To download and run your model locally, please review this document.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Attached AKS not available in Azure ML Create Model Deployment UI",
        "Question_creation_time":1636497254520,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/621129\/attached-aks-not-available-in-azure-ml-create-mode.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"I have AKS cluster attached with Azure ML for inference cluster,\nBut when i try to create End point using UI, kubernetes cluster is not available in the drop down menu\nwhy the AKS cluster that attached in Azure ML is not available in the drop down menu?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-10T04:27:51.993Z",
                "Answer_score":0,
                "Answer_body":"Hi @Edhotp-9431\n\nA machine learning model registered in your workspace.\n\nAzure Machine Learning can deploy trained machine learning models to Azure Kubernetes Service.\nYou must first either create an Azure Kubernetes Service (AKS) cluster from your Azure ML workspace, or attach an existing AKS cluster.\n\nCheck with the limitations\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-attach-kubernetes?tabs=python#limitations\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-kubernetes-service?tabs=python\n\n\n\n\n\nIf the Answer is helpful, please click Accept Answer and up-vote, so that it can help others in the community looking for help on similar topics.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-11-10T18:27:38.86Z",
                "Answer_score":0,
                "Answer_body":"Hi @Edhotp-9431\n\nThe + Create option on Endpoints UI page, is based off our v2 APIs : https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-cli\n\nYou Kubernetes will show up, if you have attached them using the following docs : https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-attach-arc-kubernetes?tabs=studio\nThe cluster will show up if you are attaching it the following way:\n\nIf you don't see your cluster after following the above documentation, please let us know!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error 404: AciDeploymentFailed",
        "Question_creation_time":1635187234100,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/603277\/error-404-acideploymentfailed.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"Hello,\n\nI am trying to deploy a machine learning model through an ACI (Azure Container Instances) service. I am working in Python and I followed the following code (from the official documentation : https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=azcli) :\n\nfrom azureml.core import Workspace\n\n from azureml.core import Workspace\n    \n # Connect to workspace\n ws = Workspace(subscription_id=\"my-subscription-id\",\n                resource_group=\"my-ressource-group-name\",\n                workspace_name=\"my-workspace-name\")\n    \n from azureml.core.model import Model\n    \n model = Model.register(workspace = ws,\n                        model_path= 'model.pkl',\n                        model_name = 'my-model',\n                        description = 'my-description')\n    \n    \n    \n %%writefile score.py\n    \n import os\n import dill\n import joblib\n    \n def init():\n     global model\n     # Get the path where the deployed model can be found\n     model_path = os.getenv('AZUREML_MODEL_DIR')\n    \n     # Load existing model\n     model = joblib.load('model.pkl')\n    \n # Handle request to the service\n def run(data):\n     try:\n         # Pick out the text property of the JSON request\n         # Expected JSON details {\"text\": \"some text to evaluate\"}\n         data = json.loads(data)\n         prediction = model.predict(data['text'])\n         return prediction\n     except Exception as e:\n         error = str(e)\n         return error\n    \n    \n from azureml.core.environment import Environment\n    \n # Name environment and call requirements file\n # requirements: numpy, tensorflow\n myenv = Environment.from_pip_requirements(name = 'myenv', file_path = 'requirements.txt')\n    \n from azureml.core.model import InferenceConfig\n    \n # Create inference configuration\n inference_config = InferenceConfig(environment=myenv, entry_script='score.py')\n    \n from azureml.core.webservice import AciWebservice #AksWebservice\n    \n # Set the virtual machine capabilities\n deployment_config = AciWebservice.deploy_configuration(cpu_cores = 0.5, memory_gb = 3)\n    \n    \n from azureml.core.model import Model\n    \n # Deploy ML model (Azure Container Instances)\n service = Model.deploy(workspace=ws,\n                        name='my-service-name',\n                        models=[model],\n                        inference_config=inference_config,\n                        deployment_config=deployment_config)\n    \n service.wait_for_deployment(show_output = True)\n\n\n\n\n\nI succeded once with the previous code. I noticed that the Model.deploy created a container registry with a specific name 6e07ce2cc4ac4838b42d35cda8d38616.\nThe API was working well and I wanted to deploy an other model from scratch. I deleted the service and model from Azure ML Studio and the container registry from Azure ressources.\n\nUnfortunately I am not able to deploy again anything.\n\nFor the last step (the Model.deploy step), I have the following error message :\n\nService deployment polling reached non-successful terminal state, current service state: Unhealthy\nOperation ID: 46243f9b-3833-4650-8d47-3ac54a39dc5e\nMore information can be found here: https:\/\/machinelearnin2812599115.blob.core.windows.net\/azureml\/ImageLogs\/46245f8b-3833-4659-8d47-3ac54a39dc5e\/build.log?sv=2019-07-07&sr=b&sig=45kgNS4sbSZrQH%2Fp29Rhxzb7qC5Nf1hJ%2BLbRDpXJolk%3D&st=2021-10-25T17%3A20%3A49Z&se=2021-10-27T01%3A24%3A49Z&sp=r\nError:\n{\n\"code\": \"AciDeploymentFailed\",\n\"statusCode\": 404,\n\"message\": \"No definition exists for Environment with Name: myenv Version: Autosave_2021-10-25T17:24:43Z_b1d066bf Reason: Container > registry 6e07ce2cc4ac4838b42d35cda8d38616.azurecr.io not found. If private link is enabled in workspace, please verify ACR is part of private > link and retry..\",\n\"details\": []\n}\n\nI do not understand why the first time a new container registry was well created, but now it seems that it is sought (the message is saying that container registry identified by name 6e07ce2cc4ac4838b42d35cda8d38616 is missing). I never found where I can force the creation of a new container registry ressource in Python, neither specify a name for it in AciWebservice.deploy_configuration or Model.deploy.\n\nI tried to create the container registry by hand, but this time, this is the container that cannot be created. The output is the folloiwing :\n\nTips: You can try get_logs(): https:\/\/aka.ms\/debugimage#dockerlog or local deployment: https:\/\/aka.ms\/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2021-10-25 19:25:10+02:00 Creating Container Registry if not exists.\n2021-10-25 19:25:10+02:00 Registering the environment.\n2021-10-25 19:25:13+02:00 Building image..\n2021-10-25 19:30:45+02:00 Generating deployment configuration.\n2021-10-25 19:30:46+02:00 Submitting deployment to compute.\nFailed\n\nService deployment polling reached non-successful terminal state, current service state: Unhealthy\nOperation ID: 93780de6-7662-40d8-ab9e-4e1556ef880f\nCurrent sub-operation type not known, more logs unavailable.\nError:\n{\n\"code\": \"InaccessibleImage\",\n\"statusCode\": 400,\n\"message\": \"ACI Service request failed. Reason: The image '6e07ce2cc4ac4838b42d35cda8d38616.azurecr.io\/azureml\/azureml_684133370d8916c87f6230d213976ca5' in container group 'my-service-name-LM4HbqzEBEi0LTXNqNOGFQ' is not accessible. Please check the image and registry credential.. Refer to https:\/\/docs.microsoft.com\/azure\/container-registry\/container-registry-authentication#admin-account and make sure Admin user is enabled for your container registry.\"\n}\n\nI tried to follow the recommandation of the last message saying to set Admin user enabled for the container registry. Unfortunately the same error message appears again and I am stuck here...\n\nDoes anyone could help me omving on with this? The best solution would be I think to delete totally this 6e07ce2cc4ac4838b42d35cda8d38616 container registry but I can't find where the reference is set so Model.deploy always fall to find it.\n\nAn other solution would be to force Model.deploy to generate a new container registry, but I could find how to make that.\n\nI need your help !",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-26T09:08:27.543Z",
                "Answer_score":0,
                "Answer_body":"@FlorianSurmont-4431 The azure container registry is actually created while creating your workspace. Deleting the container registry or any of its dependent resources like storage account, Keyvault and app insights will actually cause the workspace to behave inconsistently.\n\nSince you have already deleted the registry and tried to attach a new one, it looks like the keys of this dependent resource are not synced with the workspace. Ideally during create of a workspace you can use an existing registry with the following command.\n\n az ml workspace create -w <workspace-name>\n                        -g <resource-group-name>\n                        --container-registry \"\/subscriptions\/<service-GUID>\/resourceGroups\/<resource-group-name>\/providers\/Microsoft.ContainerRegistry\/registries\/<acr-name>\"\n\n\n\nSince the workspace is already available you can use the az ml workspace update command instead to set the registry and then sync the keys.\n\n  az ml workspace sync-keys -w <workspace-name> -g <resource-group-name>\n\n\n\nI have worked with another user with a similar issue before but they did not enable admin access on registry. Since you have already done so, I think the above steps should help to sync the registry with your workspace and you can try to create or update a model from your experiment.\n\nI hope this can help.\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-26T10:29:45.23Z",
                "Answer_score":0,
                "Answer_body":"Thank you very much for your answer. I do understand when I made my mistake, and what happens, thank you.\n\nUnfortunately I am not able to run the command you suggest:\n\n  az ml workspace sync-keys -w machinelearning -g oc-ingenieur-ia\n\nIndeed, I am not able to find <workspace-name> from the CLI. The error message is the following:\n\nProjectSystemException:\nMessage: Workspace not found.\nInnerException None\nErrorResponse\n{\n\"error\": {\n\"message\": \"Workspace not found.\"\n}\n}\n\n\n\n\nWhen I run\n\n az ml workspace list\n\nThe result is empty : [].\n\nThat is quite weird, because I do have it created in the portal web interface.\n\nWhen I try to find the resource group name with command:\n\n az group list --subscription <my-subscription-id>\n\nI do have the result:\n\n[\n{\n\"id\": \"\/subscriptions\/<my-subscription-id>\/resourceGroups\/OC-ingenieur-IA\",\n\"location\": \"francecentral\",\n\"managedBy\": null,\n\"name\": \"OC-ingenieur-IA\",\n\"properties\": {\n\"provisioningState\": \"Succeeded\"\n},\n\"tags\": {},\n\"type\": \"Microsoft.Resources\/resourceGroups\"\n}\n]\n\nBut when I run either:\n\n az ml workspace list --resource-group OC-ingenieur-IA\n\nor\n\n az ml workspace list --resource-group oc-ingenieur-ia\n\nI have the following error:\n\nProjectSystemException:\nMessage: Workspaces not found.\nInnerException None\nErrorResponse\n{\n\"error\": {\n\"message\": \"Workspaces not found.\"\n}\n}\n\n\n\n\nMoreover if I try to import the workspace from Python:\n\n ws = Workspace(subscription_id=\"my-subscription-id\",\n                resource_group=\"oc-ingenieur-ia\",\n                workspace_name=\"machinelearning\")\n\nThe Python object iswell created and its name attribute is \"machinelearning\" as expected. I can interact with it to create a model with Model.register that shows up in Azure portal.\n\nAny idea of what is going on?",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Importing\/Exporting Data from SQL Server in Live Endpoint",
        "Question_creation_time":1635886704310,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/613262\/importingexporting-data-from-sql-server-in-live-en.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello,\n\nI'm currently migrating an experiment & webservice over from AzureML Classic to the new AzureML.\n\nOne of the actions the classic webservice did was export data into SQL Server during the run. In the new Azure ML, I have created a new pipeline with an export data module (essentially replicating how it was in classic), however, after reading the docs I'm told this would be removed in a live endpoint? https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/export-data\n\nI need to store the data that is output from the pipeline somewhere. What are the best practice solutions to do this?\n\nGive me a shout if you need any more info \/ I've not explained the problem well enough!\n\nThanks,",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Discontinuation of Azure ML Studio (Classic)",
        "Question_creation_time":1635919954397,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/613623\/discontinuation-of-azure-ml-studio-classic.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi Everyone\n\nI am currently using Machine Learning Studio (classic).\n\n'From now through 31 August 2024, you can continue to use the existing Machine Learning Studio (classic) experiments and web services. Beginning 1 December 2021, new creation of Machine Learning Studio (classic) resources will not be available.'\n\nAs mentioned above, what do resources mean? Can you please be specific about which services won't be available? Web services? Experiments? Projects?\n\nWill I be able to create new BLANK EXPERIMENTS after December 2021?\n\nThanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-03T12:31:28.82Z",
                "Answer_score":0,
                "Answer_body":"@NitinVarshney-0181 Resources refer to the classic workspace that cannot be created from Azure portal after 1st Dec 2021. If you have already created a classic workspace you can create an experiment, webservice with that resource. Please ensure the workspace is not deleted from Azure portal. It is recommended to use the Azure ML workspace or migrate to the new workspace for newer features of Azure ML. Please lookup a similar conversation about the same on this thread. Thanks!!\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"LSTM Algorithm regarding accuracy",
        "Question_creation_time":1636431320857,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/619877\/lstm-algorithm-regarding-accuracy.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi all,\n\n   I have implemented LSTM algorithm for my project ,It is giving accuracy o.13 which is very low , Is there any way to increase my accuracy\n\n\n\nkindly respond ,waiting for guidance please help\n\nLet me know if any additional information required\n\nThanks in advance",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How to Build an User Specific Machine Learning Model?",
        "Question_creation_time":1636444026477,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/620019\/how-to-build-an-user-specific-machine-learning-mod.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\n\nAs a company, we are planning to build an easy, user-specific navigation recommender. This tool will make recommendations based on the user's navigation search history. We are familiar with Azure ML Studio, yet wondering how we can train user-specific machine learning models and give users recommendations through them. So, instead of building one big machine learning model for all users, we are looking for training and inferencing user-specific machine learning models.\n\nWe really appreciate any help you can provide.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"MLnet Choosing an Algorithm for ranking categories matching a sentence",
        "Question_creation_time":1636351700077,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/618483\/mlnet-choosing-an-algorithm-for-ranking-categories.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I am looking to train a model to suggest tags\/categories for a given text string.\n\neg: \"the fox is weak and limping\" = [1-animal],[34-weak],[2667-injury],[16-foot] (a list of tags each with probabilities generated by past associations)\n\nThis data would be trained from a data set of many instances of text each with a corresponding string representing the list of tags that match the text.\n\nIs there a way to featurize the text AND the result tags? And apply an algorithm to cross reference them?\nThe closest I have come is the idea of duplicating each of the training data rows so that each row has only one tag at a time.\n\nI have been researching this question for a week and am thinking the problem is how I am asking it! Everything I have read does not hint at an existing algorithm to match this use case so should I look towards manipulating the data to a different structure.\n\nAny help greatly appreciated.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-09T11:34:41.42Z",
                "Answer_score":0,
                "Answer_body":"@Ide-2761 Thanks, Here is the sample to finetune using BERT to identify the tags.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning - Naming the NSG, PIP and NLB resources",
        "Question_creation_time":1635766129500,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/611217\/azure-machine-learning-naming-the-nsg-pip-and-nlb.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi, is there a way to predefine the Load balancer, Network security group and Public IP resource names for the Compute instances (as posted here), rather than Azure randomly generate names for those three specific resources? Happy to use az cli, PowerShell or ARM to predefine these resources. Thanks",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"azure cosmos db as a datastore in ml",
        "Question_creation_time":1597331768270,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/66297\/azure-cosmos-db-as-a-datastore-in-ml.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"Hi, I'm wondering if I can register azure cosmos db as a datastore in azure machine learning?\nFrom your documentation, it seems not https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.core.datastore%28class%29?view=azure-ml-py\n\nDo you have a plan to implement the feature in near future?\n\n\nAny recommended alternative solutions for now?\n\nThanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-14T22:43:18.18Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. Currently, Cosmos DB isn't a supported datasource when using Azure ML datastores. However, the product team are aware of this request and will provide updates accordingly. An alternative for now will be to use Azure ML Studio (Classic) which supports Cosmos DB as data source. You can also try a heuristic approach via Execute Python Script module in Designer to import data using python. Hope this helps.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-10-14T06:27:11.747Z",
                "Answer_score":2,
                "Answer_body":"Hi, Is there an update on this as a year has passed? For us, Cosmos DB is an important datasource (with no workable workarounds ), and not being able to use it as a datastore in Azure ML is forcing us to make a choice to continue with Azure ML or not.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-20T13:32:02.98Z",
                "Answer_score":0,
                "Answer_body":"I'm also interested in an update. We're in the process of migrating to azure and have lots of metadata associated with our training set stored in json files. It would be very nice to store it as a Table under our storage account and connect to it from AzureML via a datastore.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"About the end of Machine Learning Studio (classic)#2",
        "Question_creation_time":1636119906810,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/616952\/about-the-end-of-machine-learning-studio-classic2.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"hello.\n\nI am currently using Machine Learning Studio (classic).\n\n'From now through 31 August 2024, you can continue to use the existing Machine Learning Studio (classic) experiments and web services. Beginning 1 December 2021, new creation of Machine Learning Studio (classic) resources will not be available.\n\nIs the following interpretation correct?\n\nThings you can't do from 1 December 2021\n-Creating a workspace for Machine Learning Studio (classic)\n-Creating a web service plan for Machine Learning Studio (classic)\n\nWhat you can do until 1 December 2021\n-Creating new Machine Learning Studio (classic) experiments\n-Creating new Machine Learning Studio (classic) trained models\n-Creating a new Machine Learning Studio (classic) web service",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-06T14:35:42.13Z",
                "Answer_score":0,
                "Answer_body":"Hi, customers will not be able to create new ML Studio(classic) workspaces after Dec 1, 2021. However, customers can create or update experiments\/web services in existing workspaces until Aug 31, 2024.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"my script stops running without any message explaining the reason",
        "Question_creation_time":1634306015143,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/592153\/my-script-stops-running-without-any-message-explai.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Please see the screenshots below. Once it said terminated but without reason:\n\nThe other time there was nothing just stopped:",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-02T02:05:01.493Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nHope you have solved this issue and we are sorry not seeing your response. Since this issue happened without any error details, support ticket would be the best way to debug that. Please let me know if you still need that. Thanks.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure AutoML deployment to PowerBI",
        "Question_creation_time":1635966824653,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/614605\/azure-automl-deployment-to-powerbi.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I have deployed an Azure AutoML model and the test seems to look fine (shows all input variables and actually runs the test properly). But, when I try to use the model in PowerBI, PBI only shows ONE input variable.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-04T19:29:52.12Z",
                "Answer_score":0,
                "Answer_body":"Hi, according to the documentation, to generate a web service that's supported for consumption in Power BI, the schema must support the format that's required by Power BI. Learn how to create a Power BI-supported schema. Once the web service is deployed, follow these steps to consume the model in PowerBI. Also review Azure Machine Learning integration in Power BI.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to use a working pipeline on live dataset?",
        "Question_creation_time":1635766961413,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/611229\/how-to-use-a-working-pipeline-on-live-dataset.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hello,\nI would like to ask a bit help in my custom pipeline because I am stuck at that point where my custom pipeline is working and published but I cannot test it with \"live\" dataset.\nI tried to follow this article but I have not found my algorithm's name also the endpoint and model menus are empty:\nhttps:\/\/docs.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/deploy-model\nCould anyone help how to use my custom pipeline at live dataset?\nThank you",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-02T01:30:39.207Z",
                "Answer_score":0,
                "Answer_body":"Hi, from your post, I'd assume you've deployed your model. So, click on Endpoints > Pipeline Endpoints > Select a specific pipeline to run, consume, or review results of previous runs of the pipeline endpoint. You can use a Client Application or PowerBI to consume the webservice. Feel free to review train and deploy regression model example.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-11-02T19:32:29Z",
                "Answer_score":0,
                "Answer_body":"Hello GiftA,\nFirst of all, thank you for your reply.\nUnfortunately, this where i am stuck the \"model\" menu is empty at my side (screenshot), i suppose i have not deployed my pipeline yet.\n\n\n\n\nFurther on, I do not have this \"Pipeline Endpoints\" menu what you mentioned before: \"\"Endpoints > Pipeline Endpoints > Select a specific pipeline to run\"\"",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Why is Designer so slow to execute?",
        "Question_creation_time":1601819361423,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/116085\/why-is-designer-so-slow-to-execute.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":5,
        "Question_comment_count":1,
        "Question_follower_count":15,
        "Question_score":2,
        "Question_body":"I'm running the simple tutorials, preparing for DP 100. I was wondering why the execution of Designer Pipelines is so slow, even when running very simple operations and minuscule DataFrames such as Automobile price data (Raw). I also may start working for a company that has been using Azure for Machine Learning and the interviewer commented something along the lines of being it very very slow.\n\nIf a very simple model training pipeline on a 200 records DataFrame took almost 20 minutes, I keep wondering how long it would take to compute a real world data pipeline.\n\nAny insights? Thank you.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-05T10:10:32.187Z",
                "Answer_score":0,
                "Answer_body":"@ivangvi can you please check if your compute has spinned up or is a cold compute in this case? If you are running on a cold compute, it may take several minutes to spin up. Also Azure Machine Learning is running on the backend of Azure Machine Learning pipeline, so if your input data hasn't changed, next time pipeline is automatically using the cached result of that module so it should be fast compared with first time running time.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-13T21:28:42.713Z",
                "Answer_score":0,
                "Answer_body":"Designer is pretty interesting, but I agree: IT IS TOO SLOW. Unusably slow, unfortunately.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-06-12T19:30:38.833Z",
                "Answer_score":0,
                "Answer_body":"I can't believe it has been over 7 months since the first post in this thread and this fundamental issue still persists! As @ivangvi indicating, simply following Microsoft's own ML tutorial (here: https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/explore-data), takes 20 min just to apply a few simple transformation to a 205 row x 36 column dataset. Just removing one column took 5 min! The whole thing would take milliseconds in a local Jupiter notebook. Why would anyone ever use this? I'm baffled.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-17T12:16:01.32Z",
                "Answer_score":0,
                "Answer_body":"Same for me, I am experimenting with some Udacity courses that were created by MS, and the pipelines are so slow to the point of unbearabe. For on example the course says that the pipeline should take around 10 mins and the actual time was 50 mins. There was another case were my lab free time of 1hr elapsed and the pipeline didnt complete the execution....",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-11-03T17:40:02.17Z",
                "Answer_score":0,
                "Answer_body":"I used to teach Azure Classic and it was great. Now, I need to switch to Azure Designer but it is too slow.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"About the end of Machine Learning Studio (classic)",
        "Question_creation_time":1635690920907,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/610432\/about-the-end-of-machine-learning-studio-classic.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"hello.\n\nI am currently using Machine Learning Studio (classic).\n\n'From now through 31 August 2024, you can continue to use the existing Machine Learning Studio (classic) experiments and web services. Beginning 1 December 2021, new creation of Machine Learning Studio (classic) resources will not be available.'\n\nAs mentioned above, what do resources mean?\nIs it possible to continue creating experiments and web sales, and using APIs from outside until 2024?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-01T02:29:26.197Z",
                "Answer_score":0,
                "Answer_body":"Hello @gatsby53-6558 ,\n\nThanks for reaching out to us here. There are several important dates.\n\nBeginning 1 December 2021, you will not be able to create new Machine Learning Studio (classic) resources. You can still work on your existing resource from 1 December 2021 to 31 August 2024.\n\nSupport for Machine Learning Studio (classic) will end on 31 August 2024. We recommend you transition to Azure Machine Learning by that date.\n\nPlease refer to this guidance for how to migrate your project for better experience.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Experiments stuck as queued",
        "Question_creation_time":1635394156133,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/606918\/experiments-stuck-as-queued.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I have been trying to run experiments through Azure Machine Learning and today they have all been stuck as Queued and nothing is progressing. I have tried cancelling them but whenever I try to run an experiment is just shows as 'Queued'.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure ML notebook kernel changes but not really",
        "Question_creation_time":1633792808087,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/584151\/azure-ml-notebook-kernel-changes-but-not-really.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi, I'm starting to use the ML notebooks in Azure and I'm facing the following issue:\nI create a new conda env and enable it via ipykernel, following the documentation[1], and install the Pyserini library.\nOn a notebook, I am able to import the library no problem with import pyserini, but when I try !python -m pyserini.index, it throws me the following error:\n\n Exception: No matching jar file found in \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/pyserini\/resources\/jars\n\n\n\nEven though I'm not using the AzureML3.6 env\n\n\nMy workaround so far has been installing the same library on AzureML3.6, but in the end, it has some incompatibilities with Python 3.6",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Getting below error while creating dataset",
        "Question_creation_time":1633749762887,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/583883\/getting-below-error-while-creating-dataset.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"{\n\"error\": {\n\"code\": \"UserError\",\n\"message\": \"Cannot load any data from the specified path. Make sure the path is accessible and contains data.\\nScriptExecutionException was caused by StreamAccessException.\\r\\n StreamAccessException was caused by NotFoundException.\\r\\n Found no resources for the input provided: '[REDACTED]'\\r\\n| session_id=9d60cf18-54e5-457a-910d-5dcd223fa0a0\"\n}\n}\n\nCode I am using is\n\n-----------------------------------------------------\nImport required azureml classes\n\n\n-----------------------------------------------------\n\nfrom azureml.core import Workspace, Datastore, Dataset\n\n\n\n-----------------------------------------------------\nAccess the workspace from the config.json\n\n\n-----------------------------------------------------\n\nws = Workspace.from_config(path=\".\/config\")\n\n\n\n-----------------------------------------------------\nAccess datastore by its name\n-----------------------------------------------------\n\naz_store = Datastore.get(ws, \"workspaceblobstore\")\n\n\n\n-----------------------------------------------------\nCreate and register the dataset\n-----------------------------------------------------\n\n\nCreate the path of the csv file\n\ncsv_path = [(az_store, \"azureml\/EmployeeAC1.csv\")]\n\nCreate the dataset\nCreate the dataset\n\nloan_dataset = Dataset.Tabular.from_delimited_files(path=csv_path)\n\nloan_dataset = loan_dataset.register(workspace=ws,\nname=\"Employee Using SDK\",\ncreate_new_version=True)",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Long Running Experiment",
        "Question_creation_time":1635794626850,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/611813\/long-running-experiment.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I am running a Machine Learning experiment in Azure Machine Learning Studio (not classic version). The total time of each step in the experiment is 7.5 min, however the overall execution time of the run was 20.5 min. Could someone please explain why there is such a large discrepancy between the total time the experiment took to run compared to the total of each step and what can be done to improve performance.\n\nThanks for your help.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Unable to activate conda enviornment in AzureML when deploying pipeline with custom docker container",
        "Question_creation_time":1635611670527,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/610084\/unable-to-activate-conda-enviornment-in-azureml-wh.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I have trouble using the environment I've created in a custom docker container while deploying an AzureML pipeline.\n\nHere is what I am doing:\n\nI create a container which builds a conda enviornment along with other requirements.\n\n\nThe above container is create on Azure Pipelines and stored on a private azure container repository.\n\n\nI pull this container in my pipeline using the below:\n\naml_run_config.environment.docker.base_image = \"xxxx\"\n    aml_run_config.environment.docker.base_image_registry.address = (\n        \"xxxx.azurecr.io\"\n    )\n    aml_run_config.environment.docker.base_image_registry.username = (\n        \"xxxx\"\n    )\n    aml_run_config.environment.docker.base_image_registry.password = (\n        xxxx\n    )\n\n\n\n\nAfter that I tried two things:\n\nUse a PythonScriptStep() to call my forecast.py\n\n\nUse a CommandStep() with command = \"conda run -n build_env python src\/forecast.py\"\n\nbuild_env is the name of my conda env\n\nIn both cases I get a ModuleNotFoundError for pandas (the first library I use).\n\nIf I pull my docker container locally and try exactly the same command, it works fine.\n\nWhat am I missing?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-01T11:12:16.757Z",
                "Answer_score":0,
                "Answer_body":"@DavidClarance-7033 Thanks for the question. pre-built Azure ML environments: https:\/\/github.com\/Azure\/AzureML-Containers#base-image-dependencies\n\nIt is possible to use our own docker image (which is pushed into private container registry!)\n\nDeploy models with custom Docker image - Azure Machine Learning | Microsoft Docs\n\nTo use an image from a private container registry that is not in your workspace, you must use docker.base_image_registry to specify the address of the repository and a user name and password:\n\n\n\n\n   # Set the container registry information\n     myenv.docker.base_image_registry.address = \"myregistry.azurecr.io\"\n     myenv.docker.base_image_registry.username = \"username\"\n     myenv.docker.base_image_registry.password = \"password\"\n        \n     myenv.inferencing_stack_version = \"latest\"  # This will install the inference specific apt packages.\n        \n     # Define the packages needed by the model and scripts\n     from azureml.core.conda_dependencies import CondaDependencies\n     conda_dep = CondaDependencies()\n     # you must list azureml-defaults as a pip dependency\n     conda_dep.add_pip_package(\"azureml-defaults\")\n     myenv.python.conda_dependencies=conda_dep",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to Connect Azure MySQL server in Azure Machine Learning Studio",
        "Question_creation_time":1635536784630,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/609742\/how-to-connect-azure-mysql-server-in-azure-machine.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"In Azure machine learning studio I am trying to connect an azure mysql server as a datastore. The azure mysql server was created by a colleague and I have the credentials to connect properly. However, after entering the credentials and creating a datastore, I cannot select the datastore from the dropdown in order to create a dataset. Does machine learning studio have the ability to connect to an azure mysql server?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-11-01T13:15:25.337Z",
                "Answer_score":0,
                "Answer_body":"@MalcolmCavin-6279 Thanks, Currently AML studio doesn't support Azure Database for MySQL as shown below.\n\n\n\n\nUsing Azure machine learning python SDK here is the doc link Register and create a datastore to easily connect to your storage account, and access the data in your underlying storage service.\n\nSupported cloud-based storage services in Azure that can be registered as datastores:\n\nAzure Blob Container\nAzure File Share\nAzure Data Lake\nAzure Data Lake Gen2\nAzure SQL Database\nAzure Database for PostgreSQL\nDatabricks File System\nAzure Database for MySQL\n\nAlso MySQL is only supported for pipeline DataTransferStep and For unsupported data source, we are recommended to use Azure Data Factory to copy the data over to one of our supported Azure data source.\n\nAlso Python + Azure Database for MySQL: https:\/\/techcommunity.microsoft.com\/t5\/azure-database-for-mysql\/python-azure-database-for-mysql\/ba-p\/841926",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AzureML endpoint - gunicorn worker timeout",
        "Question_creation_time":1630071044527,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/530811\/azureml-endpoint-gunicorn-worker-timeout.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":2,
        "Question_body":"Hello everyone,\nI am trying to deploy a large model using AzureML endpoint.\nThe model is made up of many sub-models which get loaded by the init() method as described in the documentation here.\nThe model is trained and then registered in AzureML.\n\nWhen I deploy the model I can see in the logs that the gunicorn worker resets themselves after 300 seconds, so the whole ensemble of sub-models never have time to completely be loaded.\n\nIs there a way to manually set the timeout of the gunicorn workers?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-31T08:14:45.617Z",
                "Answer_score":2,
                "Answer_body":"Hi @ramr-msft thanks for the time.\nSo I have a notebook that I use for deploying. The steps are the following:\nFirst I connect to the Workspace and select a registered model and a registered env.\n\n ws = Workspace.from_config(path=\".\/config.json\")\n model = Model(ws, 'Model_Name')\n env = Environment.get(workspace=ws, name=\"condaenv\")\n\n\n\nThen I create a inference config and deploy config with this cell:\n\n inference_config = InferenceConfig(\n     environment=env,\n     source_directory=\"..\/lib\",\n     entry_script=\"azureml\/score.py\",\n )\n deploy_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=4)\n\n\n\nMy score.py has the required two methods init() and run() plus a couple of methods to postprocess the inferred data:\n\n def init():\n global model\n model = MyModel.load(os.getenv('AZUREML_MODEL_DIR'))\n    \n def run(request):\n predictions = model.predict(request)\n return postprocess(predictons)\n\n\n\n\nThe actual deployment is then done by running the next cell:\n\n service = Model.deploy(\n     ws,\n     \"model-service\",\n     [model],\n     inference_config,\n     deploy_config, \n     overwrite=True,\n     show_output=True,\n )\n    \n service.wait_for_deployment(show_output=True)\n\n\n\n\n\nSo then AzureML work his magic stuff until then it runs the init method in score.py.\nProblem starts here, since the loading of all the sub-models takes more than 300s and the workers timeout and are killed, then a new one is spawned but then the cycle starts again.\n\nIn other project (which did not involve using AzureML endpoints) I had a more direct access to gunicorn configuration and I could change the timeout or set the loading of the module to complete before workers were spawn.\n\nIs something similar possible with AzureML endpoints?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-31T20:35:13.437Z",
                "Answer_score":0,
                "Answer_body":"@Matteo-0936 @ramr-msft Was there ever a solution found to this problem?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning Studio Notebook failing to run simple print statement",
        "Question_creation_time":1633027832257,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/573362\/azure-machine-learning-studio-notebook-failing-to.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I'm attempting to run a simple print statement in an Azure Machine Learning Studio Notebook and the cell shows status 'Queued' for several minutes, then fails with the message:\n\n\"Web socket error: Your request for data wasn\u2019t sent, your network is possibly blocking websocket. Please configure your workspace to allowing websocket requests. Learn More troubleshoot link.\nTrace ID : 90e47983-d9d0-491f-8834-ac50d4e62156\"\n\nAs far as I can see, there are no options on the Workspace (SAW-ML-TEST) having to do with websockets, etc. I've attempted to log off and back on several times. I've attempted to start and stop my compute instance several times.\n\nSee screenshot for more details:",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-01T06:13:00.937Z",
                "Answer_score":0,
                "Answer_body":"@DustinReagan-3231 Thanks for the question. Please share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.\n\nWe are able to execute successfully without any issue as shown below in the snapshot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-30T00:19:46.09Z",
                "Answer_score":0,
                "Answer_body":"Hi,\nWant to follow up is the issue still existing?\nThe previous error is websocket error which might be related to home\/office network, firewall, or browser extension\nIt is hard to invetigate but we would like to help if we know more details.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Tuning help for Time Series Forecasting model in Azure (AMLS \/ AutoML)",
        "Question_creation_time":1635468147490,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/608424\/tuning-help-for-time-series-forecasting-model-in-a.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Casting a wide here for some urgent assistance with ML Tuning. Looking for a specialist with time series forecasting model experience in azure... someone who knows the inner workings and can help tune things... needs to know how to alter the Alpha hyper-param in AMLS\/AutoML. The documentation is short in describing the tuning needed.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-29T12:11:47.177Z",
                "Answer_score":0,
                "Answer_body":"@LarryYE-0750 Thanks for the question. Currently No control over hyperparameter tuning in Model Training.\n\u2022 DNN learners supported for forecasting\nPlease follow the below resources for understanding of Automated ML capabilities as well as forecasting using Automated ML.\n\nResources:\nAutomated ML Forecasting Blog\nAutomated ML Forecasting How-to\nAutomated ML Charts & Metrics\nGitHub Sample Notebooks\n\nHave questions or feedback? Let us know by reaching out to, AskAutomatedML@microsoft.com",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Difference in processing time between Azure Machine Learning Studio and Azure Machine Learning Studio (classic)",
        "Question_creation_time":1635432791567,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/607943\/difference-in-processing-time-between-azure-machin.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I used to use Azure Machine Learning Studio (classic).\nCreating the same workout in Azure Machine Learning Studio takes about 20 times longer than classic.\nVirtual machine size is Standard_DS3_v2 (4 core\u300114 GB RAM\u300128 GB disk).\nSteps that have been executed once will be processed quickly from the next time onward, but steps that have been changed even slightly will take 20 times longer than classic.\n\nHow can I process at the same speed as classic?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-28T22:04:25.073Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for your feedback. AML classic studio appears to be faster in some cases because it uses a Fixed Compute (and always available). However, AML Classic lacks flexibility and scalability that the new platform offers. With designer, you have greater flexibility but depending on the task (e.g. smaller tasks), the processing time may seem longer than classic due to overhead for preparing each step. For smaller tasks, majority of execution time is spent on overhead. Furthermore, when input data changes, it may take longer. If no changes are made, the pipeline would automatically use the cached result of that module, so it should be faster compared to the first run. The product team are aware of this limitation and working to improve the experience. For compute heavy tasks, we recommend you pick a larger VM to improve processing speeds. Please review this document for ways to Optimize Data Processing. Feel free to submit feedback directly to the product team by using the 'smiley' feedback icon in Azure ML Studio. Other Similar Posts: (1), (2).\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"About creating a computing cluster with Azure Machine Learning",
        "Question_creation_time":1635431417297,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/607903\/about-creating-a-computing-cluster-with-azure-mach.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello.\nYou can only select up to one maximum node when Create an Azure Machine Learning compute cluster. How do I select multiple nodes?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-28T21:24:17.703Z",
                "Answer_score":0,
                "Answer_body":"Hi, you can only select min and max number of nodes that you want to provision. The compute will autoscale to a maximum of this node count when a job is submitted. For more details, review Create an AML Compute Cluster.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"ML for each client in SaaS",
        "Question_creation_time":1606883207173,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/182640\/ml-for-each-client-in-saas.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I work for a SaaS and am wanting to release a Machine learning model in a standard structure but with specific learning for each client. That is the training is defined in our software by the client (azure SQL) and then we want to apply that to a trained model for the client to then use in our software.\n\nWhat is the best way to do this.\n\na. A separate ML model for each client \/ continuous training via web endpoint to import the data and consume\nb. A single ML that has an extra category for ClientID and we pass that into the model?\n\nAre there any tips, tricks or hacks for Azure ML \/ Studio?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-03T00:50:35.007Z",
                "Answer_score":0,
                "Answer_body":"Thanks for reaching out. I'd need to understand your scenario a little better to provide guidance. However, I encourage you check Azure AI Gallery for various ML examples and our documentation. Hope this helps.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-28T05:07:11.3Z",
                "Answer_score":0,
                "Answer_body":"Hi Patrick, not sure if you've solved this already. Given it's been some time since you raised this question, there is tremendous progress in MSFT ML Ops. If you go to https:\/\/github.com\/microsoft\/MLOps, you will find the example of MSFT end-to-end ML models lifecycle management, which should have included what you've asked.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unable to deploy a ML Model",
        "Question_creation_time":1633960741913,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/585717\/unable-to-deploy-a-ml-model.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I tried to deploy my machine learning model from python (using PyCharm 2018, python 3.9).\nHowever I encountered the following error but when I run \"az login\" all my subscription information is displayed.\nCan anyone advise?\n\nYou have logged in. Now let us find all the subscriptions to which you have access...\nInteractive authentication successfully completed.\nTraceback (most recent call last):\nFile \"C:\\InstalledApps\\Python39\\lib\\site-packages\\azureml\\core\\authentication.py\", line 1653, in _get_arm_token_with_refresh\nif (_get_exp_time(access_token) - time.time()) < _TOKEN_REFRESH_THRESHOLD_SEC:\nFile \"C:\\InstalledApps\\Python39\\lib\\site-packages\\azureml\\core\\authentication.py\", line 1720, in _get_exp_time\ndecode_json = jwt.decode(access_token, verify=False)\nTypeError: decode() got an unexpected keyword argument 'verify'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\nFile \"C:\\InstalledApps\\Python39\\lib\\site-packages\\azureml\\core\\authentication.py\", line 276, in wrapper\nreturn test_function(self, args, *kwargs)\nFile \"C:\\InstalledApps\\Python39\\lib\\site-packages\\azureml\\core\\authentication.py\", line 427, in _get_arm_token\nreturn self._get_arm_token_using_interactive_auth()\nFile \"C:\\InstalledApps\\Python39\\lib\\site-packages\\azureml\\core\\authentication.py\", line 521, in _get_arm_token_using_interactive_auth\narm_token = _get_arm_token_with_refresh(profile_object, cloud_type, ACCOUNT, CONFIG, SESSION,\nFile \"C:\\InstalledApps\\Python39\\lib\\site-packages\\azureml\\core\\authentication.py\", line 1660, in _get_arm_token_with_refresh\nraise AuthenticationException(\"Could not retrieve user token. Please run 'az login'\",\nazureml.exceptions._azureml_exception.AuthenticationException: AuthenticationException:\nMessage: Could not retrieve user token. Please run 'az login'\nInnerException decode() got an unexpected keyword argument 'verify'\nErrorResponse\n{\n\"error\": {\n\"code\": \"UserError\",\n\"inner_error\": {\n\"code\": \"Authentication\"\n},\n\"message\": \"Could not retrieve user token. Please run 'az login'\"\n}\n}",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-12T03:40:26.29Z",
                "Answer_score":0,
                "Answer_body":"@GohSokBoon-9189\n\nPython SDK seems not works well with Python 3.9.\n\nOne workaround I have seen is to create a condo environment with Python 3.8. This works well for me. Could you please have a try?\n\nFor Python 3.9 compatibility with Python SDK issue, we will work on that and let you know any update.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-13T22:02:19.43Z",
                "Answer_score":0,
                "Answer_body":"@GohSokBoon-9189\n\nProduct team just deployed a fix for this issue. Python 3.9 should work now. Please check and let us know if there is still a problem for you.\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-19T16:56:21.337Z",
                "Answer_score":0,
                "Answer_body":"@GohSokBoon-9189\n\nThis is the workaround works for me.\n\n from azureml.core.authentication import InteractiveLoginAuthentication\n from azureml.core.compute import ComputeTarget, AmlCompute\n from azureml.core.compute_target import ComputeTargetException\n import urllib\n    \n forced_interactive_auth = InteractiveLoginAuthentication(tenant_id=\"YOUR TENANT ID\", force=True)\n #interactive_auth = InteractiveLoginAuthentication(tenant_id=\"YOUR TENANT ID\")\n ws = Workspace(\n     workspace_name='YOUT WS NAME',\n     subscription_id='YOUR S ID',\n     resource_group='YOUR RESOURCE',auth=forced_interactive_auth\n )\n\n\n\n\nThis issue with workspace(in(login) authentication...Here are the details.\nIf we are creating a workspace in our local computer without giving tenant_id or wrong tenant_id we will get this issue.\nPlease refer the links below:\nHow to find your tenant ID - Azure Active Directory | Microsoft Docs\nazure - Workspace Authentication: More than one token matches the criteria - Stack Overflow\n\nInteractive login authentication is suitable for local experimentation on your own computer and is the default authentication model when using Azure Machine Learning SDK.\nYou work for company A which is on Azure.\nYou get access to company B's subscription.\nProblem is: You are associated to A's AAD in ML-Studio.\nYou need to specify the tenant ID in the How to find your tenant ID - Azure Active Directory | Microsoft Docs\nInteractiveLoginAuthentication like\nazureml.core.authentication.InteractiveLoginAuthentication class - Azure Machine Learning Python | Microsoft Docs\ninteractive_auth = InteractiveLoginAuthentication(tenant_id=tenant_id)\n\nworkspace = Workspace.get(name=workspace_name,\nsubscription_id=subscription_id,\nresource_group=resource_group,\nauth=interactive_auth)\nNow the important part: You need to use company B's tenant_id (I used company A's .\nOf course, this is obvious while you read it...as it is to me now :)\n\n\n\n\n\nPlease let me know if this works or not.\n\nRegards,\nYutong",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to deploy R script web service via Azure CLI",
        "Question_creation_time":1635213453407,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/603664\/how-to-deploy-r-script-web-service-via-azure-cli.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello everyone,\n\nI am tring to deploy R script as a web service using Azure Machine Learning. I created pipeline as below.\n\nI can deploy the model and endpoint from [Deploy] button but I cannot control some properties: i.e. resource name, dns name.\n\nIt seems that the az ml model deploy command can be used to deploy the endpoint.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-container-instance#using-the-azure-cli\n\nI have no information for inferenceconfig.json. How to write score.py to execute R script? Is it any example?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-26T21:18:18.257Z",
                "Answer_score":0,
                "Answer_body":"Hi, the following document describes how to define an inference configuration.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Machine Learning \/ Data Science",
        "Question_creation_time":1589856030190,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/27823\/machine-learning-data-science.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"Qual curso e indicado para iniciantes em Machine Learning e Data Science?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-05-19T07:13:52.087Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nQ&A currently supports the products listed over here https:\/\/docs.microsoft.com\/en-us\/answers\/products (more to be added later on).\n\nYou can reach the experts in the dedicated Microsoft Certification forum for courses over here:\nhttps:\/\/trainingsupport.microsoft.com\/en-us\/mcp\/forum\/mcp_courses\n\n(Please don't forget to mark helpful replies as answer)\n\nBest regards,\nLeon",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-05-19T07:51:06.393Z",
                "Answer_score":2,
                "Answer_body":"The good start is a Microsoft AI School which is available here: https:\/\/aischool.microsoft.com\/en-us",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-26T08:45:40.47Z",
                "Answer_score":0,
                "Answer_body":"Hi @ DiegoLuczk-7370,\n\nI would recommend to get prepared with the help of any of modern introductory books on Data Science like this one or this. Also, apart from the Microsoft AI School mentioned above, take a look at Udemy and Coursera beginner courses.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error when running ML Algorithms",
        "Question_creation_time":1635152541867,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/602539\/error-when-running-ml-algorithms.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":16,
        "Question_score":0,
        "Question_body":"Hello\n\nI am trying to run some ML algorithms but I get the folliwing mistake and I do not know how to proceed. Please let me know what I can do to fix this.\n\n\n\n\n\nThank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-26T04:47:11.62Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us.\n\nRegarding to the error message you shared, it seems like there is an error about your storage setting.\n\nCould you please check:\n1. You have the right datastore setting as the document: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data#create-and-register-datastores\n2. For Azure blob container and Azure Data Lake Gen 2 storage, make sure your authentication credentials have Storage Blob Data Reader access. Learn more about Storage Blob Data Reader. An account SAS token defaults to no permissions.\nFor data read access, your authentication credentials must have a minimum of list and read permissions for containers and objects.\nFor data write access, write and add permissions also are required.\n\nHope this helps.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How do you see ALL predictors by influence not just the top predictors of AutoML training reports?",
        "Question_creation_time":1635159990897,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/602784\/how-do-you-see-all-predictors-by-influence-not-jus.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"The \"top predictors by influence\" in the training reports of AutoML regression models is very useful (see reference image), but I'm looking for a way to display all of the predictors, not just the top 10. Any way I can visualise this either in the training report or using the data tables themselves would be very useful.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-26T02:26:26.563Z",
                "Answer_score":0,
                "Answer_body":"Hi, PowerBi is not currently supported here on Q&A. Please post your question on the PowerBI community forum for faster response. Thanks.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Cannot start and delete compute",
        "Question_creation_time":1634651667563,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/595819\/cannot-start-and-delete-compute.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_comment_count":1,
        "Question_follower_count":15,
        "Question_score":1,
        "Question_body":"Hi\nI worked ML Azure practice at office and home. But in the morning, the compute cannot start when I work at home.\nThe alter as follows:\n\"Failed to start compute\nTrace ID : f1b5cabf-123a-470d-8a44-11631264118eClient request ID : 5967255a-9901-4717-a78e-2c350d3f6498Service request ID : 0fbd2dd4-2aea-4d00-b5ce-958ed7846f2e \"\nAnd I find the ID number changed in alter every time when I start the compute\n\n\"Failed to start compute\nTrace ID : 515db030-c027-422c-9ddf-67a17f8e1e89Client request ID : ee8db673-63e9-4bc0-adec-b5d2db4e606aService request ID : e9a8a652-5c35-48c5-a381-58d1d1fa1e89\"\n\nNow, I try to delete compute and it is running more than 50min for deleting, cannot finish. I don\u2019t know how to figure it now.\nCan I build a new compute for my course practice, even this one still keep deleting?\nYan",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-20T00:21:24.92Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. Sorry about any inconvenience you may have faced. Please share the tutorial you're referencing so we can better understand your scenario. Furthermore, you may need to raise a support request for further investigation if it's still stuck in deleting state and if you're unable to create a new compute instance.\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-22T06:09:05.207Z",
                "Answer_score":0,
                "Answer_body":"I am facing this right now. I faced it 2 days before as well. I suspect these are related to some outages. Because, things start working after few hours.\n\nUpdate on 25th Oct' 2021\nFaced the same issue today as well.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-22T17:18:03.337Z",
                "Answer_score":0,
                "Answer_body":"Hello I'm facing the same problem. This happened to me twice, I've created a new workspace then, for the first 1-2 days worked nicely, then when we tried to start the instance it gave me that error. This could be a region related problem? I've created mine at eastus.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-25T22:19:27.067Z",
                "Answer_score":0,
                "Answer_body":"Hi I am still facing the same issue. I have to create new compute when I got the refuse alert and cannot open the old compute.\nBut when I turn on the new compute, the old one fixed by itself and turned on with the new one.\nAnd my new problem is I cannot turn off the old or new compute. I have to open two compute.\nIt makes my frustrated if I cannot control it on or off.\n\nNew issue, I notice I turn off the compute and there is no endpoint in my MLAzure account. I was charge more than 1 dollar everyday.\nDo I have to remove everything in the Azure? But I have to practice or review my history for the Exam.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Machine Learning Workspace Load Balancer",
        "Question_creation_time":1620773916823,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/391564\/machine-learning-workspace-load-balancer.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi there,\n\nIs it possible to delete the Load Balancer that's installed as part of the Machine Learning workspace? Or to adjust the configuration so that it doesn't cost so much?\n\nI'm just using this ML workspace to study\/practice concepts for the DP-100 exam so I don't think I need a load balancer, but at no point did I see an option to turn it off, it doesn't even appear as a resource item.\n\nWhat role\/purpose is the load balancer playing as part of the Workspace deployment?\n\nThanks kindly for any insight.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-11T23:16:17.933Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nI am sorry for your experience. The charges incurred for LB and bandwidth could be based on your setup and how the compute was setup to run the experiments. If you have also setup your designer to use virtual network then there could be charges on how the compute was setup with respect to the region. More details of the setup of workspace with private networks are detailed here. For the breakup of charges mentioned above you can raise a support request through the azure portal for billing which does not require any support plan to raise a ticket from the Help+Support tab on Azure portal.\n\nAs the same time, for student studying, there are some student benefit: https:\/\/azure.microsoft.com\/en-us\/free\/students\/\n\n\n\n\nHope this helps.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-11T23:20:05.527Z",
                "Answer_score":0,
                "Answer_body":"Thanks, I just did a basic installation of the Machine Learning Workspace. I didn't do any private networks or anything.\n\nI've seen the answer you posted, it seems like a canned answer. How do I configure Machine Learning Workspace to not need\/use the Load Balancer?\n\nThat's why I posted here. I'd like to terminate that feature.\n\nThanks kindly,",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-15T21:49:40.997Z",
                "Answer_score":0,
                "Answer_body":"THanks for replying. I have two compute instances, both are off. I only turn them on to run notebooks. I had a compute cluster that was up for an hour or so but have since deleted it. Deleting the compute clusters did NOT remove the Load Balancer. I have no Inference clusters.\n\nThanks kindly,",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-25T10:30:10.747Z",
                "Answer_score":0,
                "Answer_body":"Hi @EmilioGagliardi-5163\n\nThe 'load balancer' cost could actually be due to the endpoints in ML Studio.\n\nThe computing resources behind the inferencing endpoints can be costing you money while they are now shown in the 'Compute' section, not under any of the 4 tabs there, not anywhere in ML Studio.\n\nGo to the 'endpoints' section to see if you have any endpoints. Remove the endpoints and check if the cost have reduced.\n\nLet me know how this works.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"[Azure][ML][Python SDK][Environment][Docker] Docker copy missing context",
        "Question_creation_time":1634739305317,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/597612\/azuremlpython-sdkenvironmentdocker-docker-copy-mis.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello,\n\nI am trying to create an Azure ML Environment using a Dockerfile but it contains the 'COPY' instruction.\n\nFrom the documentation of Environment.from_dockerfile ( https:\/\/docs.microsoft.com\/fr-fr\/python\/api\/azureml-core\/azureml.core.environment(class)?view=azure-ml-py#from-dockerfile-name--dockerfile--conda-specification-none--pip-requirements-none- ), I can not find a way to give it some files along with the Dockerfile itself.\n\nSo, how to pass context to enable using COPY in the Dockerfile ?\n\nThank you for your time !",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-21T00:05:42.763Z",
                "Answer_score":1,
                "Answer_body":"Docker context is not supported with AzureML Python SDK at the moment. Context support will added later this year",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Equation from linear regression model",
        "Question_creation_time":1634735454220,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/597388\/equation-from-linear-regression-model.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hello,\n\nI have run a linear regression model considering several variables applying tune model hyperparameters in design. I am now interested in obtaining the equation of this regression model that considers the coefficients of the inputs of the model, but I cannot find how to get this result.\nPlease let me know how I might accomplish this.\n\nThank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-21T10:09:05.433Z",
                "Answer_score":0,
                "Answer_body":"@CASTANOSANCHEZMariaJoseA-3582 Thanks for the question. Can you please add more details about the sample that you are trying. Currently do not have coefficients for regression\/forecasting models, but we will raise this with our data science team as we have seen this ask before. We are working on an interface to surface models that compose ensembles, model weights and more. some of this information is available today within the model details tags.\n\nLink to find the best model: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-tune-hyperparameters#find-the-best-model",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Upload Custom Algorithms to Azure ML Designer (Studio)",
        "Question_creation_time":1625060259073,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/458133\/upload-custom-algorithms-to-azure-ml-designer-stud.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Is it possible in some way to extend or customize Azure ML Designer (Studio) to upload and allow selection of custom developed algorithms for training models. The context is to be able to provide power or citizen data scientists with home grown algorithms in a drag and drop manner as enabled by Azure ML Designer Studio whilst still protecting internal IP.\nAlternately is there a possibility of exposing dockerized\/containerized algorithms for training via the Designer interface.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-30T17:07:13.973Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. Currently, you cannot create custom modules in Designer. However, Execute R\/Python script module allows you to write custom code. This document shows how to use the execute python script module, you can also find more examples on Azure AI Gallery although it uses the ML Studio Classic interface. Hope this helps.",
                "Answer_comment_count":5,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Model predictions",
        "Question_creation_time":1634657889403,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/596074\/model-predictions.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\nI build a Bagged GLM model on azure studio with tons of data split 50\/50 as training and testing input. Mow I am trying to deploy it as web service, it wont let me to input from the start point.\n\n1) Where should I input a simple data to the model? Before the loop for bagging when I got a single request? Would the result same for fast requests\/input?\nbeggin<-function(trainx,testx,length_divisor=4,iterations=100)\nprediction<-foreach(m=1:iterations, .combine=rbind) %dopar% {\npredict(glm,newdata=testx, na.action=na.omit)\n}\ndata.set<-rowMeans(prediction)\n2) Another model built using use r-script modules. Each time it predicts almost the same value using our algorithm not from the studio, the variation of the result was trivial to the .0xx\n\nThanks\nN.A.W.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-20T10:38:50.637Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nAfter you creating your web service, you need to call it as below.\n\nI am giving Python as an example: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=python#call-the-service-python\n\n import requests\n import json\n    \n # URL for the web service\n scoring_uri = '<your web service URI>'\n # If the service is authenticated, set the key or token\n key = '<your key or token>'\n    \n # Two sets of data to score, so we get two results back\n data = {\"data\":\n         [\n             [\n                 0.0199132141783263,\n                 0.0506801187398187,\n                 0.104808689473925,\n                 0.0700725447072635,\n                 -0.0359677812752396,\n                 -0.0266789028311707,\n                 -0.0249926566315915,\n                 -0.00259226199818282,\n                 0.00371173823343597,\n                 0.0403433716478807\n             ],\n             [\n                 -0.0127796318808497,\n                 -0.044641636506989,\n                 0.0606183944448076,\n                 0.0528581912385822,\n                 0.0479653430750293,\n                 0.0293746718291555,\n                 -0.0176293810234174,\n                 0.0343088588777263,\n                 0.0702112981933102,\n                 0.00720651632920303]\n         ]\n         }\n # Convert to JSON string\n input_data = json.dumps(data)\n    \n # Set the content type\n headers = {'Content-Type': 'application\/json'}\n # If authentication is enabled, set the authorization header\n headers['Authorization'] = f'Bearer {key}'\n    \n # Make the request and display the response\n resp = requests.post(scoring_uri, input_data, headers=headers)\n print(resp.text)\n\n\n\nMore information please refer to the documentation. Please let me know if you need more details.\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Path to already registered model file for docker image construction",
        "Question_creation_time":1634580956150,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/594682\/path-to-already-registered-model-file-for-docker-i.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":7,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I'm attempting to create a docker image containing my already registered model; working with my currently working python code. My question is - what is the Model directory?\n\nIn this guide:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-extend-prebuilt-docker-image-inference\nit states:\n\nIf the model and code need to be built into the image, the following environment variables need to be set in the Dockerfile:\n\n\nAZUREML_ENTRY_SCRIPT: The entry script of your code. This file contains the init() and run() methods.\nAZUREML_MODEL_DIR: The directory that contains the model file(s). The entry script should use this directory as the root directory of the model.\n\nIt then goes on to give an example with this line:\nCOPY <model_directory> \/var\/azureml-app\/azureml-models\nBasically, I'm trying to figure out what <model_directory> should be.\n\nMy dockerfile is currently:\n\n FROM python:3\n    \n COPY *.py \/opt\/azureml-app \\\n     requirements.txt \/opt\/azureml-app \\\n     .\/model.pkl \/opt\/azureml-app\/azureml-models\n    \n RUN pip install -r requirements.txt \n    \n ENV AZUREML_ENTRY_SCRIPT=trivialEntryScript.py \\\n     AZUREML_MODEL_DIR=\/opt\/azureml-app\/azureml-models\n    \n ENTRYPOINT python \/opt\/azureml-app\/trivialEntryScript.py \n\n\n\nThe only files in the directory I'm building from are model.pkl, trivialEntryScript.py, requirements.txt and my Dockerfile. The folder structure is notebooks: myName\/dockerTesting. I do have other directories, eg myName\/mainCode which is where I ran my actual model training and registering. However, I manually added the model.pkl file into the dockerTesting folder (which I probably shouldn't need to do anyways?).\n\nI've tried the following:\ndockerfile as shown - error file does not exist\ndockerfile COPY model.pkl \/opt\/azureml-app\/azureml-models (eg no .\/ in front of model.pkl) - error file does not exist\n\nMy confusion is a bit more general - I have no idea where the actual registered models are stored in terms of actual filepaths; eg when I registered model.pkl in the first place, its not in myName\/mainCode where I trained it, though it does show up in the registered models tab. If I run a script that is only:\n\n print( Model.get_model_path(model_name) )\n\n\n\nIt will tell me my model isn't found in Cache or my current working directory - regardless of if I run in mainCode or dockerTesting. However, if I run the exact same command in the init method of a entryScript after deploying my model with an inference config and whatnot, it will load the model (deploying the model seems to download it to cache - but from Where? How do I put the original location into my docker file???).\n\ntrivialEntryScript is literally just the basic entry script from: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=azcli",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How to handle growing\/changing datasets?",
        "Question_creation_time":1634718031020,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/596990\/how-to-handle-growingchanging-datasets.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"We are in the situation whereby we have datasets that are updated frequently so we have to retrain regularly on that new data. However it seems there is no way to expand a dataset and use the dataset versioning. This is what I'm currently testing, but there are some problems with it:\n\nCreate dataset from datastore and add new images to the datastore. This expands the dataset as we want and also updates the labeling job such that the new data can be labeled. This is handy since we don't have different labeling jobs for the same project. However if we want to export that dataset to use for training (Export > Export as Azure ML Dataset) it creates a new dataset, is it possible to export into a new version of a dataset? That way we can reuse the training code and the correct version is automatically stored.\n\nKind regards",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-20T13:51:00.55Z",
                "Answer_score":0,
                "Answer_body":"@GillesBallegeer-1456 Thanks for the question. Here is the link to Data drift as described here:\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-monitor-datasets?tabs=python\n\nAn Azure ML dataset does not version the underlying data (snapshot), but rather it points to the underlying source.\n\nIn this context, up versioning would be that you change the schema (add a column, etc) rather than underlying data.\n\nVersion and track Azure Machine Learning datasets: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-version-track-datasets",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Getting OSError: [Errno 30] Read-only file system",
        "Question_creation_time":1624894187850,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/454901\/getting-oserror-errno-30-read-only-file-system.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I am new to AzureML, I am trying to run the pipeline using parallelRunSteps and pipeline is getting submitted successfully but while running the pipeline it is throwing an above error not sure what would be the root cause of it.\n\nThe step I am following is\n\nCreating the workspace if does not exists\n\n\nFetching the datastore by specifying the storage account and other details\n\n\nUsing the from file dataset\n\n\nRegistering the dataset\n\n\nAfter registering fetching the dataset\n\n\nFetching\/Initialising Experiment\n\n\nFetching\/Initialising Environment\n\n\nAdding Private wheel file to pip package\n\n\nRegistering the packages to conda dependencies\n\n\nRegistering the Environment\n\n\nFetching\/Initialising the Compute Target\n\n\nInitialising the ParallelRunConfig\n\n\nInitialising the PipelineData as output data\n\n\nInitialising the ParallelRunStep\n\n\nFetching\/Initialising the Pipeline\n\n\nSubmitting the Pipeline\n\nThe above same technique I tried with different PythonScriptSteps instead of ParallelRunStep method.\n\nCreating the workspace if does not exists\n\n\nFetching the datastore by specifying the storage account and other details\n\n\nTabular Dataset\n\n\nsetting dataset name input\n\n\nFetching the Experiment\n\n\nFetching\/Initialising the Experiment\n\n\nFetching\/Initialising the Environment\n\n\nAdding Private wheel file to pip package\n\n\nRegistering the packages to conda dependencies\n\n\nRegistering the Environment\n\n\nFetching the ComputeTarget\n\n\nInitialising the PythonStepScript\n\n\nInitialising the Pipeline\n\n\nSubmitting the Pipeline\n\nWith PythonStepScripts it is working fine. Not able to understand what mistake I am doing while running ParallelRunStep method.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-06T08:12:22.683Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nHope your issue has been solved. We haven\u2019t heard from you on the last response and was just checking back to see if you have a resolution yet.\n\nThe workaround I have seen for the similar issue is to add \"tmp\" to the file path like filepath = '\/tmp\/' + key\n\nIn case if you have any resolution please do share that same with the community as it can be helpful to others . Please do let us know if you still have issue for it.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-13T06:48:36.4Z",
                "Answer_score":0,
                "Answer_body":"Hi Yutong,\n\nSorry for the late reply was on leave.\n\nSharing the error message below\n\nTraceback (most recent call last):\nFile \"driver\/amlbi_main.py\", line 48, in <module>\nmain()\nFile \"driver\/amlbi_main.py\", line 44, in main\nJobStarter().start_job()\nFile \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/gmail\/azureml\/68b3ef53-65a6-4d2f-a3ba-07af48d1081e\/wd\/azureml\/68b3ef53-65a6-4d2f-a3ba-07af48d1081e\/driver\/job_starter.py\", line 50, in start_job\nself.setup(is_master=True)\nFile \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/gmail\/azureml\/68b3ef53-65a6-4d2f-a3ba-07af48d1081e\/wd\/azureml\/68b3ef53-65a6-4d2f-a3ba-07af48d1081e\/driver\/job_starter.py\", line 44, in setup\nLogConfig().config(args.logging_level, is_master=is_master)\nFile \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/gmail\/azureml\/68b3ef53-65a6-4d2f-a3ba-07af48d1081e\/wd\/azureml\/68b3ef53-65a6-4d2f-a3ba-07af48d1081e\/driver\/singleton_meta.py\", line 18, in call\ncls.instances[cls] = super(SingletonMeta, cls).call(args, *kwargs)\nFile \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/gmail\/azureml\/68b3ef53-65a6-4d2f-a3ba-07af48d1081e\/wd\/azureml\/68b3ef53-65a6-4d2f-a3ba-07af48d1081e\/driver\/log_config.py\", line 39, in init_\nself.log_dir = self.get_log_dir()\nFile \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/gmail\/azureml\/68b3ef53-65a6-4d2f-a3ba-07af48d1081e\/wd\/azureml\/68b3ef53-65a6-4d2f-a3ba-07af48d1081e\/driver\/log_config.py\", line 48, in get_log_dir\nworking_dir = RunContextFactory.get_context().working_dir\nFile \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/gmail\/azureml\/68b3ef53-65a6-4d2f-a3ba-07af48d1081e\/wd\/azureml\/68b3ef53-65a6-4d2f-a3ba-07af48d1081e\/driver\/run_context.py\", line 64, in working_dir\npth.mkdir(parents=True, exist_ok=True)\nFile \"\/azureml-envs\/azureml_91e342c44c0de9bc46808411bb1fed8e\/lib\/python3.6\/pathlib.py\", line 1226, in mkdir\nself._accessor.mkdir(self, mode)\nFile \"\/azureml-envs\/azureml_91e342c44c0de9bc46808411bb1fed8e\/lib\/python3.6\/pathlib.py\", line 387, in wrapped\nreturn strfunc(str(pathobj), *args)\nOSError: [Errno 30] Read-only file system: '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/gmail\/azureml\/68b3ef53-65a6-4d2f-a3ba-07af48d1081e\/mounts\/workspaceblobstore\/azureml\/68b3ef53-65a6-4d2f-a3ba-07af48d1081e'\n\nSorry not getting where to add file path like filepath = '\/tmp\/' + key can you some reference or example",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-19T21:21:49.037Z",
                "Answer_score":0,
                "Answer_body":"I am having the same issue\n\nI am creating a compute cluster and then mounting a Jupyter Lab mounted at the Workspace default datastore at this location:\n\n\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/{workspace_name}\/azureml\/{run_id.lower()}\/mounts\/\n\nI also uploaded Jupyter Notebooks to\n\n\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/{workspace_name}\/azureml\/{run_id.lower()}\/mounts\/workspaceblobstore\/\n\nI used to be able to run the Jupyter Notebooks and save the results on the mount, or being able to upload content using the Jupyter Lab, or duplicating or saving changes to the notebooks\n\nBut not anymore I am getting this error:\n\nUnexpected error while saving file: workspaceblobstore\/tao\/bpnet\/bpnet-Copy1.ipynb [Errno 30] Read-only file system: '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/ngc_aml_toolkit_ws_test2\/azureml\/tao-mrg-exp34_1634671669_282ea162\/mounts\/workspaceblobstore\/tao\/bpnet\/bpnet-Copy1.ipynb\n\nWhile trying to duplicate notebook bpnet.ipynb",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Cannot upload local files to AzureML datastore (python SDK)",
        "Question_creation_time":1594197439043,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/43980\/cannot-upload-local-files-to-azureml-datastore-pyt.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":36,
        "Question_score":0,
        "Question_body":"Hi everybody,\n\nI just started learning how to use MS Azure and I got stuck with an apparently trivial issue.\n\nI have my own pet ML project, a python script that runs a classification analysis with Tensorflow and Keras.\nIt runs smoothly locally and I am happy with it.\n\nNow I am trying to run this script on Azure ML, hoping to take advantage from the available computing power and in general gaining some experience with the Azure services. I am a bit old style and I like the idea of running my code on my local IDE, rahter than running it in a notebook. Because of this, I focused on the python SDK libraries.\n\nI created a free trial account on Azure and create a workspace. In order to adapt my original code to the\nnew task, I followed the example in https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/tutorial-train-models-with-aml?WT.mc_id=aisummit-github-amynic\n\nThe problem arises when I try to upload my locally-stored training data to the datastore of the workspace. The data is savedlocally in a parquet file, about 70Mb in size. The transfer fails after some time with a ProtocolError. After that it keeps retrying and failing with a NewConnectionError.\n\nThe snippet that reproduces the error is:\n\n import numpy as np\n import pandas as pd\n from os.path import join as osjoin\n    \n import azureml.core\n from azureml.core import Workspace,Experiment,Dataset,Datastore\n from azureml.core.compute import AmlCompute,ComputeTarget\n    \n workdir = \".\"\n # Set up Azure Workspace\n # load workspace configuration from the config.json file in the current folder.\n try:\n     ws = Workspace.from_config()\n except:\n     print(\"Could not load AML workspace\")\n    \n    \n datadir= osjoin(workdir,\"data\")\n local_files = [ osjoin(datadir,f) for f in listdir(datadir) if \".parquet\" in f ]\n    \n # get the datastore to upload prepared data\n datastore = ws.get_default_datastore()\n datastore.upload_files(files=local_files, target_path=None, show_progress=True)\n\n\n\nEverything runs smoothly until the last line. What happens is that the program starts to upload the file,\nI can see that there is outbound traffic from my VPN monitor. From the upload speed and the size of the file, I would say that it uploads it completely or close to that, then I get this message * :\n\n WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', OSError(\"(10054, 'WSAECONNRESET')\"))': \/azureml-blobstore-xxx\/creditcard.parquet?comp=block&blockid=TURBd01...TURB...RA%3D%3D\n WARNING - Retrying (Retry(total=1, connect=2, read=2, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002210A8BAF48>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': \/azureml-blobstore-xxx\/creditcard.parquet?comp=block&blockid=TURBd01...TURB...RA%3D%3D\n WARNING - Retrying (Retry(total=0, connect=1, read=2, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002210B446748>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': \/azureml-blobstore-xxx\/creditcard.parquet?comp=block&blockid=TURBd01...TURB...RA%3D%3D\n WARNING - Retrying (Retry(total=2, connect=2, read=3, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002210A8B5148>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': \/azureml-blobstore-xxx\/creditcard.parquet?comp=block&blockid=TURBd01...TURB...RA%3D%3D\n WARNING - Retrying (Retry(total=1, connect=1, read=3, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x000002210A891288>, 'Connection to creditfraudws2493375317.blob.core.windows.net timed out. (connect timeout=20)')': \/azureml-blobstore-xxx\/creditcard.parquet?comp=block&blockid=TURBd01...TURB...RA%3D%3D\n WARNING - Retrying (Retry(total=0, connect=0, read=3, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002210A8BD3C8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': \/azureml-blobstore-xxx\/creditcard.parquet?comp=block&blockid=TURBd01...TURB...RA%3D%3D\n\nFrom the initial ProtocolError, I understand that the Azure cloud server bounces me back, but it is\nunclear to me why. Checking the workspace from the Azure portal, I would guess that the container of the workspace is still empty, but I am not 100% sure if I checked that correctly.\n\nMaybe I misunderstood the different components of the storage services in AzureML and I not using\nthe API correctly. Am I doing something wrong? Is there a way for me to extract more information about\nthe reasons for this error?\n\nThanks a lot in advance for any help you can provide\n\n\n\n\n\n[*] (I manually edited portions of the error message obfuscating the blobstore name)",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-21T22:53:06.057Z",
                "Answer_score":0,
                "Answer_body":"@romungi-MSFT\n\nI am having the same issue. With the tutorial here: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-bring-data\n\nWARNING - Retrying (Retry(total=0, connect=3, read=0, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection abo\nrted.', timeout('The write operation timed out'))': \/azureml-blobstore-6cf75ce5-9da9-4149-bcfd-c844582dc038\/datasets\/cifar10\/cifar-10-batche\ns-py\/test_batch\nUploading .\/data\/cifar-10-batches-py\/data_batch_2\n--- Logging error ---\nTraceback (most recent call last):\n  File \"\/home\/user01\/ws\/azure-ml-tutorial\/venv\/lib\/python3.7\/site-packages\/urllib3\/connectionpool.py\", line 677, in urlopen\n    chunked=chunked,\n  File \"\/home\/user01\/ws\/azure-ml-tutorial\/venv\/lib\/python3.7\/site-packages\/urllib3\/connectionpool.py\", line 392, in _make_request\n    conn.request(method, url, **httplib_request_kw)\n  File \"\/home\/user01\/anaconda3\/lib\/python3.7\/http\/client.py\", line 1252, in request\n    self._send_request(method, url, body, headers, encode_chunked)\n  File \"\/home\/user01\/anaconda3\/lib\/python3.7\/http\/client.py\", line 1298, in _send_request\n    self.endheaders(body, encode_chunked=encode_chunked)\n  File \"\/home\/user01\/anaconda3\/lib\/python3.7\/http\/client.py\", line 1247, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n  File \"\/home\/user01\/anaconda3\/lib\/python3.7\/http\/client.py\", line 1065, in _send_output\n    self.send(chunk)\n  File \"\/home\/user01\/anaconda3\/lib\/python3.7\/http\/client.py\", line 987, in send\n    self.sock.sendall(data)\n  File \"\/home\/user01\/anaconda3\/lib\/python3.7\/ssl.py\", line 1034, in sendall\n    v = self.send(byte_view[count:])\n  File \"\/home\/user01\/anaconda3\/lib\/python3.7\/ssl.py\", line 1003, in send\n    return self._sslobj.write(data)\nsocket.timeout: The write operation timed out\nDuring handling of the above exception, another exception occurred:\n\n\n\n\nThree small files are successfully loaded, but it failed at the other actual data files.\n\nI'm using Ubuntu18.04, Python 3.7.6. I'm using a home-wifi which I don't think have a firewall for this.\n\nAny idea?",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-18T12:05:25.383Z",
                "Answer_score":0,
                "Answer_body":"Each Azure ML workspace comes with a default datastore:\n\n from azureml.core import Workspace\n ws = Workspace.from_config()\n datastore = ws.get_default_datastore()\n\n\n\nWhen declaring BlobService pass in protocol='http' to force the service to communicate over HTTP. Note that you must have your container configured to allow requests over HTTP (which it does by default).\n\n client = BlobService(STORAGE_ACCOUNT, STORAGE_KEY, protocol=\"http\")\n\n\n\nYou can also read more about os path expanduser method. Some example code can be found here: https:\/\/gist.github.com\/drdarshan\/92fff2a12ad9946892df",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Access company's fileshare from Azure ML Compute",
        "Question_creation_time":1633621586400,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/581725\/access-company39s-fileshare-from-azure-ml-compute.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I have been doing some searching around and can't seem to find anything particularly related to this question. Is it possible to connect to a local fileshare system from an Azure ML instance? Basically, I have a large amount of data in the form of images stored on a local drive and would like to use ml.azure to train and make predictions on this data.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-08T03:43:32.46Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nI am not pretty sure what's \"company fileshare\" you are mentioning. But Azure Machine Learning Studio does support upload data from local\/ datastore\/ Web URL\/ public dataset. You can create your dataset for training.\n\nReference:https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-connect-data-ui#create-datasets\n\nBesides Studio, you can also connect to datastore and storage.\n\nThere are two dataset types, based on how users consume them in training; FileDatasets and TabularDatasets. Both types can be used in Azure Machine Learning training workflows involving, estimators, AutoML, hyperDrive and pipelines.\n\nA FileDataset references single or multiple files in your datastores or public URLs. If your data is already cleansed, and ready to use in training experiments, you can download or mount the files to your compute as a FileDataset object.\n\nA TabularDataset represents data in a tabular format by parsing the provided file or list of files. This provides you with the ability to materialize the data into a pandas or Spark DataFrame so you can work with familiar data preparation and training libraries without having to leave your notebook. You can create a TabularDataset object from .csv, .tsv, .parquet, .jsonl files, and from SQL query results.\n\nReference: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-register-datasets#dataset-types\n\nHope this will help. Please let us know if any further queries.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Cannot Run Notebook",
        "Question_creation_time":1613062788243,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/269426\/cannot-run-notebook.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"When I go to Run a script in my Notebook on the Azure Learning Studio, there is no icon or option to run it. Even if the Compute is running, I still do not have the \u25b7 button needed to Run it. I am an owner, but perhaps there could be some issue with my subscription or might be platform issue with the portal UI itself? Please help.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-12T00:34:09.283Z",
                "Answer_score":0,
                "Answer_body":"Hi, can you please share a screenshot of the notebook itself? Can you run the notebook using shift + enter command? Also, did you try opening in Jupyter Notebook and try running from there? Can you also try a different browser?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-10-16T08:27:13.143Z",
                "Answer_score":0,
                "Answer_body":"I tried both. Does not work. Still having this issue",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure compute not provisioning nodes",
        "Question_creation_time":1634279482907,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/591559\/azure-compute-not-provisioning-nodes.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Azure ML is not creating nodes despite having quota. Cluster just shows Resizing 0 ->2 nodes and continues to circle for hours. Using training instance standard_DS11_V2 in central India",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Cost of running a compute, other tasks",
        "Question_creation_time":1634318912257,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/592299\/cost-of-running-a-compute-other-tasks.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"Hi;\n\nFirst off, where can I find the costs for all the different things I can run in Azure ML? Not just a compute, but editing a notebook, connecting to a datastore, splitting a datastore, etc. Basically where is the price list?\n\nSecond, where can I find what I will be charged for things I ran in the last hour? I want to see what I'm spending before a month is up and the charge is then 100x what I expected (and can afford).\n\nthanks - dave",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-16T01:32:38.867Z",
                "Answer_score":2,
                "Answer_body":"Hi, you can use Azure Cost Management to manage Azure costs, please review the quickstart document. Also, the following document provides detailed information on how to plan and manage cost for AML.\n\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Test data for time sequential data",
        "Question_creation_time":1633802017540,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/584120\/test-data-for-time-sequential-data.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi all;\n\nIf I am trying to predict: the weather, the stock market, coffee sales per city, etc. there is no good way I can see to break out the data for training vs test data. For the weather case, training with Honolulu weather isn't going to do well testing with Denver weather.\n\nIs it a good approach to train with the data for 5 years ago to 1 year ago. The test with the most recent year of data?\n\nOr is there a better approach?\n\nthanks - dave",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Datastore workspaceblobstore access failed, ErrorCode: ResourceNotFound using AutoML.",
        "Question_creation_time":1634120760290,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/588934\/datastore-workspaceblobstore-access-failed-errorco.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Why remote run is getting \"Datastore workspaceblobstore access failed, ErrorCode: ResourceNotFound\" when using automl?\n\nI've attached datastore to workspace and I'm able to create Tabular dataset using blob URL.\n\nBut it crashes when submittting experiment with auto ml.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Deploying model from Azure ML to AKS inference cluster failing with 504 error",
        "Question_creation_time":1634117582693,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/588825\/deploying-model-from-azure-ml-to-aks-inference-clu.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"We are trying to deploy model from ML onto Inference cluster in AKS. While training is successful, during deployment it fails with 504 error. Not sure if this is due to an issue on ML end or on AKS\n\nWebserviceException:\nMessage: Received bad response from Model Management Service:\nResponse Code: 504\nHeaders: {'Server': 'nginx\/1.21.1', 'Date': 'Wed, 13 Oct 2021 08:13:26 GMT', 'Content-Type': 'text\/html', 'Content-Length': '160', 'Connection': 'keep-alive', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'X-Content-Type-Options': 'nosniff', 'x-request-time': '180.024'}\nContent: b'<html>\\r\\n<head><title>504 Gateway Time-out<\/title><\/head>\\r\\n<body>\\r\\n<center><h1>504 Gateway Time-out<\/h1><\/center>\\r\\n<hr><center>nginx<\/center>\\r\\n<\/body>\\r\\n<\/html>\\r\\n'\nInnerException None\nErrorResponse\n{\n\"error\": {\n\"message\": \"Received bad response from Model Management Service:\\nResponse Code: 504\\nHeaders: {'Server': 'nginx\/1.21.1', 'Date': 'Wed, 13 Oct 2021 08:13:26 GMT', 'Content-Type': 'text\/html', 'Content-Length': '160', 'Connection': 'keep-alive', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'X-Content-Type-Options': 'nosniff', 'x-request-time': '180.024'}\\nContent: b'<html>\\\\r\\\\n<head><title>504 Gateway Time-out<\/title><\/head>\\\\r\\\\n<body>\\\\r\\\\n<center><h1>504 Gateway Time-out<\/h1><\/center>\\\\r\\\\n<hr><center>nginx<\/center>\\\\r\\\\n<\/body>\\\\r\\\\n<\/html>\\\\r\\\\n'\"\n}\n}",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-14T12:39:09.067Z",
                "Answer_score":0,
                "Answer_body":"@SureshBettadapur-4155 Thanks for the question. A 504 status code indicates that the request has timed out. The default timeout is 1 minute.\n\nYou can increase the timeout or try to speed up the service by modifying the score.py to remove unnecessary calls. If these actions do not correct the problem, use the information in the below article to debug the score.py file. The code may be in a non-responsive state or an infinite loop.\n\nHere is the link to troubleshot and Enable AppInsights flag will start flowing the logs (for Application monitoring).\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment?tabs=azcli#http-status-code-504",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"What's the correct tooling to use cognitive services to identity SPECIFIC items?",
        "Question_creation_time":1634146030337,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/589463\/what39s-the-correct-tooling-to-use-cognitive-servi.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Scenario: I have three children and need to sort their garments as they are cleaned. I would like to be able to hold a garment up to a camera, and for the application to recognise the actual garment, so that it can tell me who it (currently) belongs to.\n\nWhat approach should I use to teach an application to find a specific item? Obviously just noticing that it is a \"t-shirt\" or \"trousers\" isn't enough in this case; I need to identify individual items.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-14T06:48:23.693Z",
                "Answer_score":0,
                "Answer_body":"@NeilBarnwell-3329 I would advise to use the Azure custom vision service for this scenario. Identifying an object in an image is possible by Azure computer vision and it does a good job to provide description of the image, tag all objects, locate the object, brands in an image with co-ordinates but it wouldn't be able to track the item with different predictions as the model is not customized for a closed set of objects.\n\nCustom vision provides the ability to train a model with a closed set of objects and you would be able to predict an object in an image with high confidence and track the object with the help of tags. Tags are metadata that you would attach to an image while training so the trained model returns these tags with a confidence score. For example, I have trained a model with images of aircrafts to distinguish an image from a thumbnail. If the image contains a play button then it identifies the same in the tag or else the no_play tag is displayed.\n\nIf no play button is on the image.\n\n\nIf play button is on the image.\n\n\nIn your case, you would have to create a classification project with multilabel classification type for retail domain with appropriate tags set on your images to identify a particular garment or its owner. I hope this helps to get you started and try this scenario.\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Why can't I access the Dataset class using azureml.core?",
        "Question_creation_time":1634060274827,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/587772\/why-can39t-i-access-the-dataset-class-using-azurem.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi, I am unable to use Dataset class in azureml.core with new version of azureml.core==1.35.0\n\nImportError: cannot import name 'Dataset' from 'azureml.core'\n\nAlso, I am unable to downgrade or reinstall azureml.core to a lower version (1.32.0). Please find the snapshot below of pip install azureml.core==1.32.0\n\nCan someone please guide me to a possible alternative. I need to use the Dataset methods -\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-13T00:43:10.873Z",
                "Answer_score":0,
                "Answer_body":"Hi, I'm not able to reproduce this issue. I was able to import Dataset using version 1.35.0 as shown below. Perhaps try uninstalling and reinstalling the package?\n\n\n\n\n\n\n\n--- Kindly Accept Answer if the information helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Can I set a cost limit?",
        "Question_creation_time":1633801837460,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/584194\/can-i-set-a-cost-limit.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi all;\n\nWhen I run a compute to train a model, is there a way to set a maximum charge for that run? And if it hits that number, it stops?\n\nI have this nightmare that I set a training model to run and when done, it's a $12,000.00 charge.\n\nthanks - dave",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Trouble downloading and loading files in python script module",
        "Question_creation_time":1633726401097,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/583739\/trouble-downloading-and-loading-files-in-python-sc.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I'm currently trying to create an endpoint in Azure ML studio designer, I'm trying to download a ML model pickle file from a blob container and use it in the pipeline to make predictions in new data. But when I try to download the file and load into the script I always get an error. Here follows the code snippet I'm trying to run and the error returned.\n\n\n\n\nCode Snippet\n\norigin = dataframe1['Key'].unique()[0].lower()\nrun = Run.get_context(allow_offline = True)\nws = run.experiment.workspace\ndatastore = Datastore(ws, 'models_datastore')\ndatastore.download('Downloads\/\/', prefix = 'Model_{origin}\/\/vectorizer.pkl')\nmodel = pickle.load(open('Downloads\/\/vectorizer.pkl', 'rb'))\n\n\n\n\nError returned\n\nGot exception when invoking script at line 23 in function azureml_main: 'FileNotFoundError: [Errno 2] No such file or directory: 'Downloads\/\/vectorizer.pkl''.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-11T10:03:11.52Z",
                "Answer_score":0,
                "Answer_body":"@GuilhermeTakata-1435 Thanks for the question. Here are the instructions to Use the studio to deploy models trained in the designer - Azure Machine Learning | Microsoft Docs and document that explains how we can get access to score.py and conda_env.yaml files under Output + logs tab for Train module.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Pipeline does not run new data",
        "Question_creation_time":1633192729123,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/575144\/pipeline-does-not-run-new-data.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":16,
        "Question_score":0,
        "Question_body":"Hi -\nI created and published a pipeline that pulls data from an Azure SQL table, processes, models and then appends the output to an Azure SQL table. The Azure SQL table is updated with new data every day or two. In my script, I want to model on data that has been added two days before today with the following script:\n\nfrom datetime import date, timedelta\nyesterday = date.today() - timedelta(days=2)\nyesterday.strftime(\"%Y-%m-%d\")\nprint(yesterday)\n\nkeep data that is 2 days ago only\n\ndata_prior = data[data['MatterOpenDate'] == str(yesterday)]\nprint(data_prior.head())\n\nwhile True:\nanswer = data_prior.empty\nif answer == False:\nprint('Continue Process')\nbreak\nelif answer == True:\nprint('Empty dataset')\nrun.complete()\nexit()\n\nWhen I first ran my pipeline it worked great. I published this experiment, etc. and created a reoccurring schedule to run once a day every day.\n\nBUT the schedule continues to run the exact same data as the original run even when there is new data being uploaded. Why and what do I need to do for the script to run 'naturally' as written?\n\nThank you",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-09T14:54:22.36Z",
                "Answer_score":0,
                "Answer_body":"I solved it, thank you.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Deploying model in Azure ML confusion",
        "Question_creation_time":1632945969247,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/571518\/deploying-model-in-azure-ml-confusion.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"I'm following a tutorial (https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=python) on how to deploy a model to Azure, and I had a few questions that have had confused a bit. I had a ready model that I trained using a notebook in Azure ML and have saved the model in a folder (as .h5) in my compute directory (Users\/username\/projectname\/models).\n\n1- Can I deploy from the Azure ML Notebook section? So I create a .py file (or can I do it in a .ipynb notebook?), connect to my workspace, and register the model through there? I have my model stored in the models folder, so can I just reference that from an azureml.core.Run object?\n\n2- When I create my entry scripts and inference and deployment configurations, do they have to be in separate files or does that not matter? Same for the code to deploy the model.\n\n3- What model extensions are supported? Is .h5 fine?\n\n4- When I deploy successfully, do I get an endpoint or uri I can connect to from anywhere?\n\nI know this is a bit all over the place, but any clarifications would be appreciated.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-30T18:42:24.787Z",
                "Answer_score":1,
                "Answer_body":"Hi, thanks for reaching out. Here's the workflow for deploying a model:\n\nRegister the model\n\n\nPrepare an entry script\n\n\nPrepare an inference configuration\n\n\nDeploy the model locally to ensure everything works\n\n\nChoose a compute target\n\n\nRe-deploy the model to the cloud\n\n\nTest the resulting web service\n\nYou can perform the above steps through AML notebooks. However, you entry script and deployment configuration need to be in separate files. After deployment, you obtain an endpoint for calling the webservice. Model with extension .h5 is supported.\n\nYou can create new or reference an existing environment in your config, here's information on how to create\/use software environments. Also, here's another example (Deploy the model in ACI section) of how to create a scoring script. Please review the following document for details on how to save and load Keras models.\n\n %%writefile score.py\n import json\n import numpy as np\n import os\n import tensorflow as tf\n    \n from azureml.core.model import Model\n    \n def init():\n     global tf_model\n     model_root = os.getenv('AZUREML_MODEL_DIR')\n     # the name of the folder in which to look for tensorflow model files\n     tf_model_folder = 'model'\n        \n     tf_model = tf.saved_model.load(os.path.join(model_root, tf_model_folder))\n    \n def run(raw_data):\n     data = np.array(json.loads(raw_data)['data'], dtype=np.float32)\n        \n     # make prediction\n     out = tf_model(data)\n     y_hat = np.argmax(out, axis=1)\n    \n     return y_hat.tolist()",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-10-01T21:01:34.717Z",
                "Answer_score":0,
                "Answer_body":"Hate to bump threads, but if someone can help with my comments to @GiftA-MSFT, that would be appreciated. I'm a bit stuck in some areas.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"InternalServerError when I try to open jupyter lab in a compute instance in Machine Learning Studio",
        "Question_creation_time":1632656732000,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/566360\/internalservererror-when-i-try-to-open-jupyter-lab.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I am trying to launch Jupyter lab on a compute instance inside Machine Learning Studio.\nIt keeps giving me this Error.\n{\n\"error\": {\n\"code\": \"ServiceError\",\n\"severity\": null,\n\"message\": \"InternalServerError\",\n\"messageFormat\": null,\n\"messageParameters\": null,\n\"referenceCode\": null,\n\"detailsUri\": null,\n\"target\": null,\n\"details\": [],\n\"innerError\": null,\n\"debugInfo\": null,\n\"additionalInfo\": null\n},\n\"correlation\": {\n\"operation\": \"87079acea847584aae25f2f02e96a4cb\",\n\"request\": \"2718ebcb2e21004c\"\n},\n\"environment\": \"eastus\",\n\"location\": \"eastus\",\n\"time\": \"2021-09-26T11:42:36.0001935+00:00\",\n\"componentName\": \"notebook-instance-proxy\"\n}\n\nInstance Details are:\nStandard_DS11_v2 (2 cores, 14 GB RAM, 28 GB disk)",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-04T21:36:21.09Z",
                "Answer_score":0,
                "Answer_body":"Hello @Akash-2979\n\nA hotfix has been deployed on Friday, please have another try to see if this works on your end. Thanks.\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Read JSON in ML Pipeline",
        "Question_creation_time":1631259308947,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/547031\/read-json-in-ml-pipeline.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"We created a ML pipline that downloads data from an external CRM system, predicts certain things based on the new data and uploads the results to the external CRM. For the upload a json file, that contains information on the metadata is mandatory. The json file sits in our datastore. We need to open the json file and update its content based on the new predictions. Unfortunately we are not able to load and read the json file in our Python script.\nFirst we create a datastore path --> datastore_paths = [(ds, 'Metadata\/XXX_metadata.json')]\nThen we create a FileDataset --> json_file = Dataset.File.from_files(path=datastore_paths)\nThen we try to open the Json file -->\nf=open(json_file)\ndata_json=json.load(f)\nWe get the following error message --> expected str, bytes or os.PathLike object, not FileDataset\nSo far we were not able to find any solution for our problem, Any help or input is highly appreciated. Many thanks in advance !!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-13T04:08:12.16Z",
                "Answer_score":0,
                "Answer_body":"@MichaelKollegger-8271 Thanks, Can you please share the code that you are trying. Please follow the to use FileDataset. Creating a FileDataset pointing to your json file in azure storage, then mount\/download the filedataset to your compute target for reading and parsing. Mount will work even if the file size exceeds the storage of your compute instance.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Run a pipeline using cvs files from a folder in the datastore",
        "Question_creation_time":1630494672977,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/535935\/run-a-pipeline-using-cvs-files-from-a-folder-in-th.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":18,
        "Question_score":0,
        "Question_body":"I want to run a model using as input CVS files in a folder (UI\/date) in the default datastore. I want the model to train based on the CVS files and to pick a random between them as each file represents an object to be randomly selected.\n\nI already have in design the pipeline I want to use; is just that I want to run it with the files of the datastore and not from a tabular dataset. I have tried to call these folder by a python script using os.listdir and then read_cvs, however the path for this folder doesn\u2019t seem valid. I have done this activity in python using the path of folder in my computer and it works. But I don\u2019t know how to proceed in python.\n\nThank you for your help.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-03T02:18:56.367Z",
                "Answer_score":0,
                "Answer_body":"@MEZIANEYani-9720 Thanks for the question. Can you please share the code that you are trying. Create a filedataset referencing to the root folder. Mount the filedataset on CI, and use pandas to read each file from the mounted path. If you're trying to read data into a Pandas dataframe, you can do so directly with Pandas from Azure storage including Blob, ADLSv1, and ADLSv2. Every pandas.read_* takes in storage_options, for instance see: pandas.read_table \u2014 pandas 1.2.1 documentation (pydata.org).\nTypically you can retrieve these storage options from your Azure ML Datastore, i.e. for the default datastore:\n\n\n\npython\nfrom azurmel.core import Workspace \n \nws = Workspace.from_config()\nds = ws.get_default_datastore() # ws.datastores[\"my-datastore-name\"]\n \nstorage_options = {\"account_name\": ds.account_name, \"account_key\": ds.account_key}\n \ndata_path = f\"az:\/\/mycontainer\/path\/to\/data.csv\"\n \ndf = pd.read_csv(data_path, storage_options=storage_options)\n\n\n\nIf you want to list each file in the storage account and read sequentially into Pandas, you could easily do that as well. You'll need to adjust the code for ADLSv1 (the storage options and protocol to \"adl\").",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-15T12:34:47.89Z",
                "Answer_score":1,
                "Answer_body":"Hello,\n\nI have managed to pre-process the data on the files with the following code:\n\n\n\n\n              run = Run.get_context()\n         ws = run.experiment.workspace\n         datastore = Datastore.get(ws, 'workspaceblobstore')\n         data_paths = [(datastore, 'UI\/08-26-2021_014718_UTC\/**\/*.csv')]\n         tabular = Dataset.Tabular.from_delimited_files(path=data_paths)\n         dataframe1 = tabular.to_pandas_dataframe()\n\n\n\nAnd like this I can modify and clean the data as necessary, however this is the same as creating a tabular dataset that will take random rows for the training of the model (random selection per frame) while I need to train according to the csv files (random selection per well\/file), which again is very simple with python but have yet to manage with azure specially since my already designed workflow is in design (where data is pre-processed, trained with tunning hyper-parameters and evaluated).\n\nThe code from python I want to recreate:\n\n                      for file in listOfFile:\n                    new_well=pd.read_csv(os.path.join(path,file))\n\n\n\n\nSo, I can train with new well that represents the csv files.\n\nI am attaching an example of the csv files I have to processed (in total I have over 2000 documents).",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AzureMLCompute job failed. UserProcessKilledBySystemSignal: Job failed since the user script received system termination signal usually due to out-of-memory, segfault or disk full, please check driver log for more info.",
        "Question_creation_time":1630327734917,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/532922\/azuremlcompute-job-failed-userprocesskilledbysyste.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"Can anybody help me on below mentioned below error, same thing i ran previously using same AML compute cluster but didn't get issue. But now its giving like this.\nI don't understand where out of memory issue coming.\n\nAzureMLCompute job failed.\nUserProcessKilledBySystemSignal: Job failed since the user script received system termination signal usually due to out-of-memory, segfault or disk full, please check driver log for more info.\n\n\n\n\n Reason: Job failed since the user script received system termination signal usually due to out-of-memory, segfault or disk full, please check driver log for more info.\n Cause: killed\n TaskIndex: \n NodeIp: 10.0.0.11\n NodeId: tvmps_bf6163b7d0d8755f028c834b88478cac2e05488f7c3d5fe3b2c518b98ef2a186_d\n Reason: Job failed with non-zero exit Code\n Reason: Out of memory error\n BatchNodeId: tvmps_bf6163b7d0d8755f028c834b88478cac2e05488f7c3d5fe3b2c518b98ef2a186_d\n RoleInstanceName: 9e7b1aec-9e01-41a0-94bb-5ac4407e4d2d-AzureBatch-Deployment_7\n VmId: c90d75ad-37a5-4c8b-a40d-f411ad459be1\n ErrorCode: OutOfMemoryError",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-31T11:40:14.95Z",
                "Answer_score":0,
                "Answer_body":"@RashmiSoniIN68524-6993 Thanks for the question, We would recommend to provide a feedback item along with screen shot of this error to the service team from Azure ML portal to help you on this. Navigate to the page of your run, click the smiley icon on top right corner and provide details of the issue and select \"include screenshot\" option along with option to contact you for feedback. This should enable the team to complete your request and reach out to you for more information.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-13T12:45:41.827Z",
                "Answer_score":1,
                "Answer_body":"I changed the Compute cluster size then it is working( i changed from 2 core cluster to 4 core).",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"unable to set holiday country parameter in Forecastingparameters when running Auto-ml from Python Notebook in azure ml studio",
        "Question_creation_time":1630327508670,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/532921\/unable-to-set-holiday-country-parameter-in-forecas.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"As the question suggests, I am trying to setup an Azure Auto-ML experiment from Jupyter Notebook from Azure ML Workspace, and trying to configure the holiday country for the forecasting parameters.\n\nMSDN for ForecastingParameters Class suggests all the Holiday Country related parameters have been deprecated.\n\nI have also tried using the parameter for Holiday Country in the AutoMLConfig but in MSDN the country parameter has also been deprecated. AutoMLConfig AutoMLConfig\n\nDoes anyone know how can I use Country Region settings in either ForecastingParameters or AutoMLConfig?\n\nMy Attempt with Forecasting Parameters:\n\n  forecastingParam_dict = {   'time_column_name':'DateColumn',\n                             'forecast_horizon':365,\n                             'time_series_id_column_names': 'GroupColumn',\n                             'target_lags':None,\n                             'feature_lags':None,\n                             'target_rolling_window_size':None,\n                             'holiday_country':'GB',                             # <-- Tried both values with no luck\n                             'country_or_region_for_holidays':'GB',              # <-- Tried both values with no luck\n                             'use_stl':'season_trend',\n                             'short_series_handling':True,\n                             'short_series_handling_configuration': 'auto',\n                             'freq':'D',\n                             'target_aggregation_function':None,\n                             'validate_parameters':True,\n                 } \n    \n    \n fcpm = ForecastingParameters.from_parameters_dict(forecastingParam_dict,\n                                                   validate_params=True ,\n                                                   show_deprecate_warnings=True)\n\n\n\n\nMy Attempt with AutoMLConfig:\n\n\n\n automl_settings = {\n                     'enable_early_stopping':True,\n                     'enable_ensembling':True,\n                     'enable_stack_ensembling':False,\n                     'ensemble_iterations':15,\n                     'enable_onnx_compatible_models':False,\n                     'max_cores_per_iteration':-1,\n                     'send_telemetry':True,\n                     'blacklist_algos':['TensorFlowDNN','TensorFlowLinearRegressor'],\n                     'enable_dnn':False,\n                     'enable_code_generation':False,\n                     'experiment_exit_score':None,\n                     'experiment_timeout_minutes':360,\n                     'featurization':'auto',\n                     'is_timeseries':True,\n                     'iteration_timeout_minutes':360,\n                     'country_or_region':'GB',                 # <-- Tried both values with no luck\n                     'country_or_region_for_holidays':'GB',    # <-- Tried both values with no luck\n                     'max_concurrent_iterations':1,\n                     'metric_operation':'minimize',\n                     'model_explainability':True,\n                     'n_cross_validations':5,\n                     'primary_metric':'normalized_root_mean_squared_error',\n                     'task_type':'regression',\n                     'validation_size':None,\n                     'test_size':None,\n                     'label_column_name':'Sales',\n                     'target_lags':None,\n                     'enable_batch_run':True,\n                     'enable_run_restructure':True\n                     }",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-31T16:01:28.277Z",
                "Answer_score":0,
                "Answer_body":"@MuhammadAli-6945 Thanks for the question. Can you please add more details about the error that you are getting. Please check the following BikeShare Demand Forecasting sample using Automated Machine Learning. If you are still facing an issue we would recommend raising an issue in the following Machine leaning notebooks link.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Which azure service should I use.",
        "Question_creation_time":1633510606170,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/579427\/which-azure-service-should-i-use.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"So I have a pretty big on-premise ssms database and I want to use some data from it in azure Machine Learning.\nI need to use just a small amount of data from my db, from certain tables.\nAlso this data updates from time to time.\nI want you to help me with the choice of correct azure service for my purpose.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-06T10:17:26.467Z",
                "Answer_score":0,
                "Answer_body":"@CherkasovDmitriy-9587 Welcome to Microsoft Q&A forums.\n\nFrom the description of your use case, I understand that the database won't be used round the clock but in short bursts of time, when you want to your ML workloads or while updating the tables from your on-premises database.\n\nYou might want to consider Azure SQL Serverless database.\nYou will be billed only for the time the database is in use and it automatically pauses itself during inactive periods.\n\nPlease let us know if you have any further questions.\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Cannot install azureml-sdk without dependency conflicts",
        "Question_creation_time":1631182445263,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/545669\/cannot-install-azureml-sdk-without-dependency-conf.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"I'm trying to install the latest azureml-sdk (1.34.0) inside a new conda env (with python 3.7) but the installation ends with the following error:\n\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nknack 0.7.2 requires argcomplete, which is not installed.\nknack 0.7.2 requires colorama, which is not installed.\nknack 0.7.2 requires pygments, which is not installed.\nazure-functions-devops-build 0.0.22 requires jinja2, which is not installed.\nazure-cli-core 2.10.0 requires argcomplete~=1.8, which is not installed.\nazure-cli-core 2.10.0 requires colorama~=0.4.1, which is not installed.\nazure-cli 2.10.0 requires azure-mgmt-keyvault~=2.2.0, but you have azure-mgmt-keyvault 9.1.0 which is incompatible.\nazure-cli 2.10.0 requires cryptography<3.0.0,>=2.3.1, but you have cryptography 3.4.8 which is incompatible.\nazure-cli-core 2.10.0 requires azure-mgmt-core==1.0.0, but you have azure-mgmt-core 1.3.0 which is incompatible.\nazure-cli-core 2.10.0 requires msal~=1.0.0, but you have msal 1.14.0 which is incompatible.\nazure-cli-core 2.10.0 requires msal-extensions~=0.1.3, but you have msal-extensions 0.2.2 which is incompatible.\n\nHow can I solve it?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-09T14:14:06.617Z",
                "Answer_score":1,
                "Answer_body":"@ramr-msft Thanks for your answer.\nI've just run the following comands:\n\nconda create -n myenv python=3.7\n\n\nconda activate myenv\n\n\npip install azureml-sdk --no-cache-dir",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-09T14:24:58.08Z",
                "Answer_score":0,
                "Answer_body":"@Elia-1010 Thanks for the details, We recommend that you always keep azureml-core updated to the latest version.\n\nUpgrade a previous version:\n\n pip install --upgrade azureml-core\n\n\n\nWe are able to install the latest azureml-sdk (1.34.0) successfully without the above mentioned error in conda environment. Please find the below snapshot for the same.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Getting 500 errors after model deployment",
        "Question_creation_time":1632915546127,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/570879\/getting-500-errors-after-model-deployment.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hello,\n\nI am trying to deploy a model using InferenceConfig . It deploys successfully, both locally and to an ACI, but whenever I make a request to it I get a <Response [500]> error. My code is based on what is found in this example here. I believe the init and run parts of my entry script are correct, as when I call the run function without it being involved in a deployment the data does go through it correctly. Investigating the endpoint on the Azure portal makes it look ok to, it has a \"healthy\" status.\n\nIs there any advice about how to fix this? Or how I can modify what I have to get around it? I have attached code below\n\nThese are my deployment logs:\n\n 2021-09-30T08:55:33,882785000+00:00 - iot-server\/run \n 2021-09-30T08:55:33,893848100+00:00 - gunicorn\/run \n Dynamic Python package installation is disabled.\n Starting HTTP server\n 2021-09-30T08:55:33,903826800+00:00 - rsyslog\/run \n 2021-09-30T08:55:33,932288900+00:00 - nginx\/run \n EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n 2021-09-30T08:55:34,629656500+00:00 - iot-server\/finish 1 0\n 2021-09-30T08:55:34,631347500+00:00 - Exit code 1 is normal. Not restarting iot-server.\n Starting gunicorn 20.1.0\n Listening at: http:\/\/127.0.0.1:31311 (63)\n Using worker: sync\n worker timeout is set to 300\n Booting worker with pid: 87\n SPARK_HOME not set. Skipping PySpark Initialization.\n Initializing logger\n 2021-09-30 08:55:36,257 | root | INFO | Starting up app insights client\n logging socket was found. logging is available.\n logging socket was found. logging is available.\n 2021-09-30 08:55:36,258 | root | INFO | Starting up request id generator\n 2021-09-30 08:55:36,260 | root | INFO | Starting up app insight hooks\n 2021-09-30 08:55:36,260 | root | INFO | Invoking user's init function\n 2021-09-30 08:55:36,423 | root | INFO | Users's init has completed successfully\n 2021-09-30 08:55:36,430 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n 2021-09-30 08:55:36,430 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n 2021-09-30 08:55:36,432 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n 2021-09-30 08:56:19,493 | root | INFO | Swagger file not present\n 2021-09-30 08:56:19,493 | root | INFO | 404\n 127.0.0.1 - - [30\/Sep\/2021:08:56:19 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"Go-http-client\/1.1\"\n 2021-09-30 08:56:19,594 | root | INFO | Swagger file not present\n 2021-09-30 08:56:19,595 | root | INFO | 404\n 127.0.0.1 - - [30\/Sep\/2021:08:56:19 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"Go-http-client\/1.1\"\n 2021-09-30 08:56:23,093 | root | INFO | Swagger file not present\n 2021-09-30 08:56:23,093 | root | INFO | 404\n 127.0.0.1 - - [30\/Sep\/2021:08:56:23 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"Go-http-client\/1.1\"\n 2021-09-30 08:56:24,193 | root | INFO | Swagger file not present\n 2021-09-30 08:56:24,194 | root | INFO | 404\n 127.0.0.1 - - [30\/Sep\/2021:08:56:24 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"Go-http-client\/1.1\"\n 2021-09-30 08:56:47,726 | root | INFO | Scoring Timer is set to 60.0 seconds\n 2021-09-30 08:56:47,727 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n   File \"\/var\/azureml-server\/synchronous\/routes.py\", line 65, in run_scoring\n     response, time_taken_ms = invoke_user_with_timer(service_input, request_headers)\n   File \"\/var\/azureml-server\/synchronous\/routes.py\", line 110, in invoke_user_with_timer\n     result, time_taken_ms = capture_time_taken(user_main.run)(**params)\n   File \"\/var\/azureml-server\/synchronous\/routes.py\", line 92, in timer\n     result = func(*args, **kwargs)\n TypeError: run() got an unexpected keyword argument 'input'\n    \n During handling of the above exception, another exception occurred:\n    \n Traceback (most recent call last):\n   File \"\/azureml-envs\/azureml_be9a4db270db0ae2ca6059a059402ecf\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1832, in full_dispatch_request\n     rv = self.dispatch_request()\n   File \"\/azureml-envs\/azureml_be9a4db270db0ae2ca6059a059402ecf\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1818, in dispatch_request\n     return self.view_functions[rule.endpoint](**req.view_args)\n   File \"\/var\/azureml-server\/synchronous\/routes.py\", line 44, in score_realtime\n     return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n   File \"\/var\/azureml-server\/synchronous\/routes.py\", line 74, in run_scoring\n     raise RunFunctionException(str(exc))\n run_function_exception.RunFunctionException\n    \n 2021-09-30 08:56:47,728 | root | INFO | 500\n 127.0.0.1 - - [30\/Sep\/2021:08:56:47 +0000] \"POST \/score HTTP\/1.0\" 500 48 \"-\" \"python-requests\/2.25.1\"\n 2021-09-30 08:57:25,014 | root | INFO | Swagger file not present\n 2021-09-30 08:57:25,014 | root | INFO | 404\n 127.0.0.1 - - [30\/Sep\/2021:08:57:25 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"Go-http-client\/1.1\"\n Exception in worker process\n Traceback (most recent call last):\n   File \"\/azureml-envs\/azureml_be9a4db270db0ae2ca6059a059402ecf\/lib\/python3.6\/site-packages\/gunicorn\/arbiter.py\", line 589, in spawn_worker\n     worker.init_process()\n   File \"\/azureml-envs\/azureml_be9a4db270db0ae2ca6059a059402ecf\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py\", line 142, in init_process\n     self.run()\n   File \"\/azureml-envs\/azureml_be9a4db270db0ae2ca6059a059402ecf\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py\", line 125, in run\n     self.run_for_one(timeout)\n   File \"\/azureml-envs\/azureml_be9a4db270db0ae2ca6059a059402ecf\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py\", line 84, in run_for_one\n     self.wait(timeout)\n   File \"\/azureml-envs\/azureml_be9a4db270db0ae2ca6059a059402ecf\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py\", line 36, in wait\n     ret = select.select(self.wait_fds, [], [], timeout)\n   File \"\/var\/azureml-server\/routes_common.py\", line 153, in alarm_handler\n     raise TimeoutException(error_message)\n timeout_exception.TimeoutException\n Worker exiting (pid: 87)\n worker timeout is set to 300\n Booting worker with pid: 145\n SPARK_HOME not set. Skipping PySpark Initialization.\n Initializing logger\n 2021-09-30 08:57:48,727 | root | INFO | Starting up app insights client\n logging socket was found. logging is available.\n logging socket was found. logging is available.\n 2021-09-30 08:57:48,732 | root | INFO | Starting up request id generator\n 2021-09-30 08:57:48,732 | root | INFO | Starting up app insight hooks\n 2021-09-30 08:57:48,733 | root | INFO | Invoking user's init function\n 2021-09-30 08:57:48,827 | root | INFO | Users's init has completed successfully\n 2021-09-30 08:57:48,833 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n 2021-09-30 08:57:48,834 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n 2021-09-30 08:57:48,835 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n 2021-09-30 08:58:10,161 | root | INFO | Swagger file not present\n 2021-09-30 08:58:10,162 | root | INFO | 404\n 127.0.0.1 - - [30\/Sep\/2021:08:58:10 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"Go-http-client\/1.1\"\n\n\n\nIf I run the command azmlinfsrv --model_dir . --entry_script entry_script.py to see how the entry script works locally, I get the output:\n\n Azure ML Inferencing HTTP server v0.4.1\n    \n    \n Server Settings\n ---------------\n Entry Script Name: entry_script.py\n Model Directory: .\/\n Worker Count: 1\n Server Port: 5001\n Application Insights Enabled: false\n Application Insights Key: None\n    \n    \n Server Routes\n ---------------\n Liveness Probe: GET   127.0.0.1:5001\/\n Score:          POST  127.0.0.1:5001\/score\n    \n Starting gunicorn 20.1.0\n Connection in use: ('0.0.0.0', 5001)\n Retrying in 1 second.\n Connection in use: ('0.0.0.0', 5001)\n Retrying in 1 second.\n Connection in use: ('0.0.0.0', 5001)\n\n\n\nentry_script.py:\n\n import json\n import numpy as np\n import os\n import onnxruntime\n    \n # Called when the service is loaded\n def init():\n     # Get the path to the deployed model file and load it\n     global sess\n     sess = onnxruntime.InferenceSession(\n         os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), \"model.onnx\")\n     )\n    \n def run(raw_data, session = None):\n     if session != None: sess = session\n     try:\n         # Get the input data as a numpy array\n         data = np.array(json.loads(raw_data)['data'], dtype=np.float32)\n         # Get a prediction from the model\n    \n         first_input_name = sess.get_inputs()[0].name\n         first_output_name = sess.get_outputs()[0].name\n    \n         test = sess.run(\n             [first_output_name], {first_input_name: data}\n         )\n         result = test[0].tolist()\n    \n         # Return the predictions as JSON\n         return json.dumps({\"result\":result})\n     except Exception as e:\n         result = str(e)\n         return {\"error\": result}\n\n\n\nDeploy Code:\n\n service_env = Environment(name='service-env')\n python_packages = ['numpy', 'onnxruntime']\n for package in python_packages:\n     service_env.python.conda_dependencies.add_pip_package(package)\n inference_config = InferenceConfig(source_directory=\".\/source_dir\",\n                                    entry_script=\".\/entry_script.py\",\n                                    environment=service_env)\n    \n deployment_config = AciWebservice.deploy_configuration(\n     cpu_cores=0.5, memory_gb=1, auth_enabled=True\n )\n    \n service = Model.deploy(\n     ws,\n     \"myservice\",\n     [model],\n     inference_config,\n     deployment_config,\n     overwrite=True,\n )\n service.wait_for_deployment(show_output=True)",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-30T05:09:45.737Z",
                "Answer_score":0,
                "Answer_body":"@AndrewBlance-8766 Thanks for the question. Can you please add more about the error details that you are getting.\n\nHere is link to document for Troubleshooting remote model deployment.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Auto ML processor never utilized, utilization below 10%",
        "Question_creation_time":1633373617237,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/576887\/auto-ml-processor-never-utilized-utilization-below.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I'm trying to run an Automated ML run with a 5Gb .csv file as the dataset. I've selected the Standard_D8_v3 (8 cores, 32 GB RAM, 200 GB disk) for my compute cluster and it allows 2 nodes.\n\nWhen it starts out initially the CPU Utilization spikes to 80%, but then stays below 1% for as long as I'll let it run, which has been over a day. I see this utilization measure under the \"Monitoring (preview)\" tab of the run, and I've also setup configured Metrics at the Workspace level, which reflect the same thing. The CPUMemoryUtilization never raises.\n\nNo models have ever appeared in the \"models\" tab.\n\nThe first run continually indicates \"Setting up the run\", but the one child run indicates \"running\". I think I've got a managed ID issue.\n\nI suspect the training never starts. Is there an error I can look for in the logs? I'm not even sure which log would have it. I'll post them here if needed.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-05T03:34:15.603Z",
                "Answer_score":1,
                "Answer_body":"Hi, perhaps you cancel the run and try again? Here's information on how to view log information for a run (including description of log files).",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"InternalServerError when launching Jupyterlabs in Azure Machine Learning workspace",
        "Question_creation_time":1632877552993,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/569900\/internalservererror-when-launching-jupyterlabs-in.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"My workspace is in EastUS2.\nI have created compute instances from multiple sku's and I always receive the following error when creating instances:\n\n{\n\"error\": {\n\"code\": \"ServiceError\",\n\"severity\": null,\n\"message\": \"InternalServerError\",\n\"messageFormat\": null,\n\"messageParameters\": null,\n\"referenceCode\": null,\n\"detailsUri\": null,\n\"target\": null,\n\"details\": [],\n\"innerError\": null,\n\"debugInfo\": null,\n\"additionalInfo\": null\n},\n\"correlation\": {\n\"operation\": \"f0bc2b1a27a3534eb83eac4f3f71fedf\",\n\"request\": \"589656f8c89b684a\"\n},\n\"environment\": \"eastus2\",\n\"location\": \"eastus2\",\n\"time\": \"2021-09-29T01:01:09.3745269+00:00\",\n\"componentName\": \"notebook-instance-proxy\"\n}\n\nWhat can I do to resolve this issue? I have tried restarting, recreating, and testing other sku's.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-10-04T21:34:28.567Z",
                "Answer_score":0,
                "Answer_body":"@DwayneThomson-9529\n\nHello, a hotfix has been deployed on Friday, please have another try to see if this works on your end.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to use ML to detect key from set of value(s)",
        "Question_creation_time":1633257609393,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/575394\/how-to-use-ml-to-detect-key-from-set-of-values.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I have a CSV file with first row as header & after that each row has set of values for each column. Each row in the CSV correspond to some field in the DB. user has to manually map the header attributes to Business fields (or DB fields).\n\nI want to use ML to learn from existing values, when single or set of values are provided then it should detect the key. Overall I want to avoid manual mapping. One can think going forward there is no more header row in the CSV file.\n\nIs any services (preferably Azure) to machine learn from set of key-value pairs. When a value is provided then it should detect the keys? Please note this does not involve any OCR, my data is in CSV form.\n\nAtul",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Deployment from Designer fails in every possible way",
        "Question_creation_time":1632862175993,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/569925\/deployment-from-designer-fails-in-every-possible-w.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":10,
        "Question_score":1,
        "Question_body":"I trained a model with Designer, created a real-time inference pipeline which was succesfully submitted. When deploying to either ACI or AKS it fails and I get the error \"ModuleNotFoundError: No module named 'azureml.api'\". I've had no problems deploying this model many times in the past and haven't changed anything. Even if I use one of the sample pipelines (automobiles basic), I get the same error when deploying to real-time.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-30T02:27:30.12Z",
                "Answer_score":1,
                "Answer_body":"It's an known issue caused by unexpected module version upgrade. It's been resolved by applying hotfix to all regions. For users, please rerun training pipeline by check on \"Regenerate Output\", and run corresponding inference pipeline and try deployment again.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-10-02T22:50:30.443Z",
                "Answer_score":0,
                "Answer_body":"Hello everyone,\n\nThis issue has been confirmed fixed. Please let us know if you still seeing this issue.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Can I create a workspace in Azure that multiple people can use?",
        "Question_creation_time":1632780178700,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/568295\/can-i-create-a-workspace-in-azure-that-multiple-pe.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi! I'm wondering if it's possible to create a workspace in Azure for multiple to use? I have a group of students who will run a lab using ML Studio and I'd like for when the Machine Learning workspace question comes up, they can select an already created workspace. Is that possible?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-28T15:23:17.06Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. Yes, you can create a workspace in AML for multiple users. User Roles enable you to share your workspace with other users, teams, or projects.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error in Azure Machine Learning Notebook Using Managed Identity to Authenticate to other resources",
        "Question_creation_time":1633032949577,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/573433\/error-in-azure-machine-learning-notebook-using-man.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I'm trying to access Azure Digital Twins(ADT) resources in an AML notebook via Managed Identity. I've granted access to the workspace in ADT's IAM.\nI found out that whatever I put for client_id, it takes more than 2 mins to get back and error showing\nManagedIdentityCredential.get_token failed: Unexpected response 'None'\n\n\n\n\nIs there anything that I did wrong? Is AML supporting MSI to access other Azure resources now?\n(I've tried ways using secrets to authenticate to ADT and it worked. I'm looking for a way that there's no secret needed.)\n\nThank you!",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"I'm getting Error: Internal server error.",
        "Question_creation_time":1632823517743,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/569010\/i39m-getting-error-internal-server-error.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I get this Internal server error. I am able to work with datasets , but as I try to work with workspace.from_config I get \"DecodeError: Not enough segments\" this error",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Issue starting labeling project",
        "Question_creation_time":1631780569863,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/554539\/issue-starting-labeling-project.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"We have a 500.000 image labeling project in progress. The team was receiving some errors that indicated no work was queued even though the project was only 3% complete.\n\nWe paused the project and attempted to restart to see if that would clear out the issue but when trying to restart an error is being thrown \"Failed\" with no additional information.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-17T12:50:14.3Z",
                "Answer_score":0,
                "Answer_body":"@DaveHartman-9746 Thanks for the question. Please share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-20T07:42:01.74Z",
                "Answer_score":1,
                "Answer_body":"The issue has been resolved. There was some corruption in the database that was corrected by the product team.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-27T17:43:47.913Z",
                "Answer_score":0,
                "Answer_body":"My labeling project is also now frozen after an attempt to resume from paused... it has been trying to resume for >2 hours now....",
                "Answer_comment_count":5,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AzureML endpoint shows 502 bad gateway",
        "Question_creation_time":1632920919200,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/571062\/azureml-endpoint-shows-502-bad-gateway.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"I deployed my model from local machine, but I can't predict with the API.\n\nWhen I checked this endpoint with this command\n\ncurl -v http:\/\/6b3138f3-b4aa-44d3-873d-32255fb5ab50.eastus2.azurecontainer.io\/score\n\nit shows 502 bad gateway. (but without \"\/score\", it looks fine)",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-30T13:13:49.127Z",
                "Answer_score":0,
                "Answer_body":"@Sih-8305 Thanks for the question. A 502 status code indicates that the service has thrown an exception or crashed in the run() method of the score.py file.\n\nHere is link to the document to Troubleshooting remote model deployment.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Permission denied: '.\/outputs'",
        "Question_creation_time":1632664334123,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/566533\/permission-denied-39outputs39.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":11,
        "Question_score":4,
        "Question_body":"When I tried to run experiments in azure ml notebook using azure ml python SDK it giving an error message as permission denied.\nI am also facing the same issue when I am trying to save CSV files in the same folder as the notebook saved.\n\ncompute instance using : STANDARD_DS3_V2\ncode -\nexperi = Experiment(workspace=ws,name=\"newsampleexperiment12\")\nrun = experi.start_logging()\n\nerror message :\n\nPermissionError Traceback (most recent call last)\n<ipython-input-7-8946b6d7df18> in <module>\n----> 1 run = experi.start_logging()\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/experiment.py in start_logging(self, args, *kwargs)\n259 \"\"\"\n260 from azureml.core.run import Run\n--> 261 return Run._start_logging(self, args, _parent_logger=self._logger, *kwargs)\n262\n263 @_check_for_experiment_id\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/run.py in _start_logging(experiment, name, run_id, outputs, snapshot_directory, **kwargs)\n586 typev2 = RunTypeV2(orchestrator=\"External\", traits=['unspecified'])\n587 run = Run._create(experiment, name=name, run_id=run_id, outputs=outputs,\n--> 588 properties=properties, typev2=typev2, **kwargs)\n589 run._client.start()\n590 if snapshot_directory:\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/run.py in _create(experiment, name, run_id, outputs, properties, tags, typev2, display_name, **kwargs)\n706 properties=properties, tags=tags, typev2=typev2,\n707 display_name=display_name)\n--> 708 return Run._dto_to_run(experiment, run_dto, outputs=outputs, **kwargs)\n709\n710 @property\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/run.py in _dto_to_run(experiment, run_dto, outputs, **kwargs)\n198 :rtype: Run\n199 \"\"\"\n--> 200 return Run(experiment, run_dto.run_id, outputs=outputs, _run_dto=run_dto, **kwargs)\n201\n202 @classmethod\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/run.py in init(self, experiment, run_id, outputs, **kwargs)\n171\n172 \"\"\"\n--> 173 super(Run, self).init(experiment, run_id, outputs=outputs, **kwargs)\n174 self._parent_run = None\n175\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/run_impl\/run_base.py in init_(self, experiment, run_id, outputs, logs, _run_dto, _worker_pool, _user_agent, _ident, _batch_upload_metrics, py_wd, deny_list, flush_eager, redirect_output_stream, **kwargs)\n76 for output in outputs:\n77 try:\n---> 78 os.makedirs(output)\n79 except OSError as exception:\n80 if exception.errno != errno.EEXIST:\n\n\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/os.py in makedirs(name, mode, exist_ok)\n218 return\n219 try:\n--> 220 mkdir(name, mode)\n221 except OSError:\n222 # Cannot rely on checking for EEXIST, since the operating system\n\nPermissionError: [Errno 13] Permission denied: '.\/outputs'",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-28T04:13:24.643Z",
                "Answer_score":0,
                "Answer_body":"@shimshad-5222 Thanks for the question. Please follow the document\/sample for creating the workspace and experiment logging. We are able to successfully execute and see the outputs+ logs and snapshots.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-hello-world#create-and-run-a-python-script\n\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/track-and-monitor-experiments\/logging-api\/logging-api.ipynb",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-28T12:56:23.69Z",
                "Answer_score":1,
                "Answer_body":"Update: after switching from Chrome to Edge everything started working. I hope it helps you @shimshad-5222",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Studio vs Azure ML Classic - K-Means",
        "Question_creation_time":1632846849270,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/569616\/azure-ml-studio-vs-azure-ml-classic-k-means.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi,\nWe have been using ML Classic and are testing and deploying to Azure ML Studio. As per the documentation for migration (https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview ) we decided to test the output results using the same algorithm (K-Means) and using the same dataset and parameters. The output was then compared and the results differ. Can someone help me understand why or why not this is expected and any other topics to consider between the two enviornments?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Custom Argument pass to Docker Container Azure ML inference",
        "Question_creation_time":1632856020243,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/569816\/custom-argument-pass-to-docker-container-azure-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello Team,\n\nI'm trying to pass the arguments to Azure ML docker. I have created an environment like this.\n\n env = Environment.from_conda_specification(name='pytorch-1.6-gpu', file_path='curated_env\/conda_dependencies.yml' )\n\n\n\nAm I passing the arguments correct?\n\n DOCKER_ARGUMENTS = [\"--shm-size\",\"32G\"]  # increase shared memory\n env.docker.arguments = DOCKER_ARGUMENTS\n\n\n\n\nThe main goal of this project is to deploy a model on the AKS inference cluster. I have successfully deployed the model. When I try to get predictions from the model I got this error\n\nIt is possible that data loaders workers are out of shared memory. Please try to raise your shared memory limit\n\nHow can I do that if that's not the correct way to pass arguments?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-29T06:31:54.6Z",
                "Answer_score":0,
                "Answer_body":"@khubaibRaza-8970 To pass the argument for increasing the default \"shm_size\" you would have to use the DockerConfiguration object. Here is a sample to achieve this:\n\n from azureml.core import Environment\n from azureml.core import ScriptRunConfig\n from azureml.core.runconfig import DockerConfiguration\n    \n    \n # Specify VM and Python environment:\n my_env = Environment.from_conda_specification(name='my-test-env', file_path=PATH_TO_YAML_FILE)\n my_env.docker.base_image = 'mcr.microsoft.com\/azureml\/openmpi3.1.2-cuda10.2-cudnn7-ubuntu18.04'\n    \n docker_config = DockerConfiguration(use_docker=True,shm_size='32g')\n    \n # Finally, use the environment in the ScriptRunConfig:\n src = ScriptRunConfig(source_directory=DEPLOY_CONTAINER_FOLDER_PATH,\n                       script=SCRIPT_FILE_TO_EXECUTE,\n                       arguments=EXECUTE_ARGUMENTS,\n                       compute_target=compute_target,\n                       environment=my_env,\n                       docker_runtime_config=docker_config)\n\n\n\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Deploy GPU enbaled in a studio notebook locally",
        "Question_creation_time":1632702738960,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/566714\/deploy-gpu-enbaled-in-a-studio-notebook-locally.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hello there, team. I'm attempting to deploy a model locally in my ML studio notebook, which has GPU compute power. But when I try to run my model, I get an error.\n\nFound no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from azure ml\n\nI'm using this\n\n env = Environment.from_conda_specification(name='pytorch-1.6-gpu', file_path='curated_env\/new_cuda_dep.yml' ) #environment  using\n inference_config = InferenceConfig(entry_script=\"score.py\", environment=env , source_directory='.' ,)",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-29T04:12:36.79Z",
                "Answer_score":0,
                "Answer_body":"@NabeelRaza-8986 Thanks for the question. Since the AzureML SDK for local deployment uses the existing docker client we'll have to make sure that this client picks up the nvidia container runtime to make the GPUs available to it. Usually we would use the gpus --all flag when creating a new docker container.\n\nMake sure you install the nvidia container runtime.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure-cli-ml Version: '1.33.0', 'Error': WebserviceException. Can't deploy model into ACI",
        "Question_creation_time":1632679013550,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/566564\/azure-cli-ml-version-39133039-39error39-webservice.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi, I am trying to deploy with Azure DevOps my ktrain model, which is in a folder and has to loaded as a folder, to ACI, but I got this error:\n\n021-09-26T16:10:35.2295468Z ERROR: {'Azure-cli-ml Version': '1.33.0', 'Error': WebserviceException:\n2021-09-26T16:10:35.2296197Z Message: Received bad response from Resource Provider:\n2021-09-26T16:10:35.2296590Z Response Code: 404\n2021-09-26T16:10:35.2298648Z Headers: {'Date': 'Sun, 26 Sep 2021 16:10:35 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'x-ms-client-request-id': '656a1432-d67d-4ad7-859d-f1408af3192f', 'x-ms-client-session-id': '3df8af72-17d1-46a7-88ea-21c9adce345f', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'X-Content-Type-Options': 'nosniff', 'x-request-time': '0.037', 'Content-Encoding': 'gzip'}\n2021-09-26T16:10:35.2301435Z Content: b'{\"code\":\"NotFound\",\"statusCode\":404,\"message\":\"The specified resource was not found.\",\"details\":[{\"code\":\"OperationNotFound\",\"message\":\"There is no operation with id 7c10e5b9-2c13-48d4-82d0-10feba0ef679\"}],\"correlation\":{\"RequestId\":\"656a1432-d67d-4ad7-859d-f1408af3192f\"}}'\n2021-09-26T16:10:35.2302322Z InnerException None\n2021-09-26T16:10:35.2302601Z ErrorResponse\n2021-09-26T16:10:35.2302853Z {\n2021-09-26T16:10:35.2303108Z \"error\": {\n2021-09-26T16:10:35.2306300Z \"message\": \"Received bad response from Resource Provider:\\nResponse Code: 404\\nHeaders: {'Date': 'Sun, 26 Sep 2021 16:10:35 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'x-ms-client-request-id': '656a1432-d67d-4ad7-859d-f1408af3192f', 'x-ms-client-session-id': '3df8af72-17d1-46a7-88ea-21c9adce345f', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'X-Content-Type-Options': 'nosniff', 'x-request-time': '0.037', 'Content-Encoding': 'gzip'}\\nContent: b'{\"code\":\"NotFound\",\"statusCode\":404,\"message\":\"The specified resource was not found.\",\"details\":[{\"code\":\"OperationNotFound\",\"message\":\"There is no operation with id 7c10e5b9-2c13-48d4-82d0-10feba0ef679\"}],\"correlation\":{\"RequestId\":\"656a1432-d67d-4ad7-859d-f1408af3192f\"}}'\"\n2021-09-26T16:10:35.2308796Z }\n2021-09-26T16:10:35.2309029Z }}`\n\nMy scoring script is below for init(). I have tried using both get_model_path and AZUREML_MODEL_DIR, but they don't work. For the latter, the deployment will keep running, and sometimes for the former.\n\n def init():\n     global model\n     logging.basicConfig(level=logging.DEBUG)\n     #  load the model from file into a global object\n     model_path = Model.get_model_path('mgsa')#, _workspace=ws)\n     print(model_path)\n     #model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'outputs')\n     model = ktrain.load_predictor(model_path)`",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-28T10:15:32.973Z",
                "Answer_score":0,
                "Answer_body":"@TobyTan-0337 Thanks for the question. Can you confirm are you able to execute successfully in local environment. Please share the sample that you are trying.\nTroubleshooting with a local model deployment: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment-local",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"What are the main advantages of Azure AutoML compared to FLAML as a paid service?",
        "Question_creation_time":1632771141767,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/568026\/what-are-the-main-advantages-of-azure-automl-compa.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I've studying the Python SDK documentation for Azure Automated ML and also a little bit o FLAML documentation. Both of them seems very similar to me in terms of code, so the only advantages I've noticed for Azure AutoML are the explicability diagram and the easy deployment by user interface. Are there any other advantages\/differences?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-28T16:03:21.527Z",
                "Answer_score":0,
                "Answer_body":"Hi, Azure AutoML is cloud based and integrates with Azure ML ecosystem, enables automatic or custom featurization, option to use local or remote compute targets, option to use python SDK or UI. Hope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"deployment issue in Azure.",
        "Question_creation_time":1632128817590,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/558600\/deployment-issue-in-azure.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hello, I am a beginner in Azure ML. I am have successfully deployed my NLP model in Azure for sentiment analysis. Then I go to the workspace and Azure Machine Learning services. When I go to the endpoints, I get a 'Test' option. But when I put a sentence for example 'I love to play football' in the test section the only things come up in the Test result\nis {}. Can any one help.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-20T10:49:54.233Z",
                "Answer_score":0,
                "Answer_body":"@santra-4408 A null response in your endpoint result indicates that the scoring script used in your model deployment is not working as expected. Have you used any document to follow the steps and deploy the endpoint? Could you also lookup the logs of your endpoint to check more details?",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Document Translator Access Error",
        "Question_creation_time":1632627969450,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/566297\/document-translator-access-error.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I am using AML to run python to translate documents (document translator) given the current bug, i am using the region endpoint (endpoint = \"https:\/\/australiaeast.api.cognitive.microsoft.com\/translator\/text\/batch\/v1.0\")\n\nThe request sends (I get a 202) response.\n\nWhen I run python to get the job status, I receive 200 :\n\n\"200\n{\"id\":\"b2e26de0-55c0-44c4-83ca-5c4315ec5bcd\",\"createdDateTimeUtc\":\"2021-09-26T03:33:19.9387768Z\",\"lastActionDateTimeUtc\":\"2021-09-26T03:33:20.5718544Z\",\"status\":\"ValidationFailed\",\"error\":{\"code\":\"InvalidRequest\",\"message\":\"Cannot access source document location with the current permissions.\",\"target\":\"Operation\",\"innerError\":{\"code\":\"InvalidDocumentAccessLevel\",\"message\":\"Cannot access source document location with the current permissions.\"}},\"summary\":{\"total\":0,\"failed\":0,\"success\":0,\"inProgress\":0,\"notYetStarted\":0,\"cancelled\":0,\"totalCharacterCharged\":0}}\"\n\nI am using a SAS generated URL+ URI from Storage Explorer, and have also tried to use SAS tokens generated from Azure Portal. I am generating these tokens at the Container level, as I'm trying to translate 3 documents.\n\nAnyway I try to generate a SAS token, it always send fine, but I always get the above error. I even attempted to use a file specific SAS.\n\nI am not using the user delegate SAS token in the portal. I haven't set up anything else in my Azure portal.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-27T11:32:59.063Z",
                "Answer_score":1,
                "Answer_body":"@SimonTemby-2690 I have tried this scenario with couple of files in a container, 1 PDF and 1 .txt file. The body of the request I used for this scenario is:\n\n {\n     \"inputs\": [\n         {\n             \"source\": {\n                 \"sourceUrl\": \"https:\/\/<myblob>.blob.core.windows.net\/translator?sp=rl&st=2021-09-27T11:17:06Z&se=2021-09-27T19:17:06Z&spr=https&sv=2020-08-04&sr=c&sig=tiUsV%2Ba95O%2BzoeuvamgZHwqdyFsXCydn%2FP6uZIkon80%3D\"\n             },\n             \"targets\": [\n                 {\n                     \"targetUrl\": \"https:\/\/<myblob>.blob.core.windows.net\/target?sp=rwl&st=2021-09-27T11:19:15Z&se=2021-09-27T19:19:15Z&spr=https&sv=2020-08-04&sr=c&sig=BL0bfpBiMXCTbhrsSAn8FxYtbAkDXvVgysteiDNgLns%3D\",\n                     \"language\": \"de\"\n                 }\n             ]\n         }\n     ]\n }\n\n\n\nIn both cases the source and target access is delegated as SAS access at the container level.\nOnce the request was submitted the get status operation returned success for both the documents. I have created a new target container in this case as the error you mentioned seems to occur for some of my older containers.\n\nI would request to check the body of your request as above and create a new target container and use that SAS URL in the body to check if this works. Thanks.\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to dynamically score models in Azure ML?",
        "Question_creation_time":1632739965043,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/567358\/how-to-dynamically-score-models-in-azure-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello,\n\nI'm currently migrating from Machine Learning Studio to Azure Machine learning, and I am having some trouble replicating one of the experiments.\n\nSo, when using Studio, we had a blob storage where we stored all our trained models (ILearner files). Then, we had an experiment that imported one of these models and imported a dataset, and proceeded to score that model against the dataset.\n\nThis was made using the Load Trained Model module. However in Azure ML this module no longer exists and I'm having trouble finding a new way of replicating this experiment. Is there something I'm missing or is it no longer possible to do something like this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-28T08:47:57.14Z",
                "Answer_score":0,
                "Answer_body":"@SubtilFernandoM-9753\n\nSorry just got confirmation from product team, this is not supported at this moment. In designer we have implemented the most popular modules in Studio classic. designer don't have this module probably because Load Trained Model has little usage among all the customers.\n\nCould you share your email address to us so that the product group can reach out to you for more information? We will consider this.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning Workspace",
        "Question_creation_time":1632495617397,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/565561\/azure-machine-learning-workspace.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi, I'm facing several difficulties in starting Exercise Part 1: Create a Microsoft Azure Machine Learning Workspace.\n\n1-It is always sending me to a page that I have two options: start free or pay as you go; when I choose the 'start free\" option, I'm facing an additional problem is that the name on my CC is not correct :-(. I've tried several cards but it didn't work.\n\nWould you please support me.\n\nI'm reachable via the following email: samihamandi@yahoo.com\n\nBR,\nSami Hamandi",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How can I transfer a csv file on an Azure Machine Learning compute instance directory back to the Datastore?",
        "Question_creation_time":1632158641093,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/559227\/how-can-i-transfer-a-csv-file-on-an-azure-machine.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I posted a similar question last week and didn't get a response to that yet so I'm posting another one now.\n\nThe code below is what I use to pull data into the compute instance from the Datastore. I transfer data from a Datastore to the compute instance and then save the data to my directory as a csv. The data originates from a SCOPE script and is transferred from Cosmos to the Datastore via Azure Data Factory.\n\nOnce the data is in the directory as a csv, I then utilize R to pull in the data into an RStudio session and then I run various tasks that create new data sets. I also save these new data sets to the compute instance directory as csv's. These new data sets are the ones I'd like to push back to the Datastore so they can be transferred elsewhere via Azure Data Factory and later consumed by a PowerBI app we're looking to create.\n\nI tried using Designer and it ran for 4 days without completing before I cancelled the job and started looking for an alternative route. I don't know if it would have completed or if it ran into memory issues and simply didn't fail. When I pull data into the compute instance from the datastore it takes less than a few minutes to complete so I'm not sure why it would take Designer multiple days to attempt to do the reverse operation.\n\nI've looked through a bunch of documentation and I am not able to find anything that tells us how we can transfer data from the compute instance back to the Datastore aside from Designer which is too slow or unable to handle.\n\nThis task seems like one that should be obvious for use and a major selling point of Azure Machine Learning so I'm a bit dumbfounded to see that this is a challenge figuring out how to do and that the documentation doesn't clearly show users how to achieve this task, assuming it's even possible. If it's not possible then I need to figure out a whole new system to use to get my work done. If it's not possible, the Azure Machine Learning team should enable this functionality as soon as possible.\n\n# Azure management\nfrom azureml.core import Workspace, Dataset\n# MetaData\nsubscription_id = '09b5fdb3-165d-4e2b-8ca0-34f998d176d5'\nresource_group = 'xCloudData'\nworkspace_name = 'xCloudML'\n# Create workspace \nworkspace = Workspace(subscription_id, resource_group, workspace_name)\n# 1. Retention_Engagement_CombinedData\ndataset = Dataset.get_by_name(workspace, name='retention-engagement-combineddata')\n# Save data to file\ndf = dataset.to_pandas_dataframe()\ndf.to_csv('\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/v-aantico1\/code\/RetentionEngagement_CombinedData.csv')\n# 2. TitleNameJoin\ndataset = Dataset.get_by_name(workspace, name='TitleForJoiningInR')\n# Save data to file\ndf = dataset.to_pandas_dataframe()\ndf.to_csv('\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/v-aantico1\/code\/TitleNameJoin.csv')",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-21T08:00:14.827Z",
                "Answer_score":1,
                "Answer_body":"@AdrianAnticoTEKsystemsInc-1526 Have you tried the following to upload data to your datastore?\n\n from azureml.core import Workspace\n ws = Workspace.from_config()\n datastore = ws.get_default_datastore()\n    \n datastore.upload(src_dir='.\/data',\n                  target_path='datasets\/',\n                  overwrite=True)\n\n\n\nI think datastore.upload() should work for you to upload the required datafiles from your compute instance to datastore.",
                "Answer_comment_count":4,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"InternalServerError when starting a GPU pipeline step",
        "Question_creation_time":1632415728727,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/564212\/internalservererror-when-starting-a-gpu-pipeline-s.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello!\n\nI have been using Azure ML pipelines for some time now. Starting this week (at least - it may be a couple of weeks since I had previously used it) my pipeline runs are failing to start steps that run on GPU clusters.\n\nI have a simple pipeline defined and triggered using the Python SDK, with three PipelineScriptSteps, the first of which runs on a CPU while the second runs on a GPU. The first step starts and runs as expected (and has now cached the output), however, when it moves on to the second step, it fails to start the GPU instance. It sits for ~30 mins preparing, then fails with an InternalServerError.\n\nI also tried manually starting the relevant cluster in advance by setting a minimum size of 1. This successfully started the instance but the pipeline step still fails in the same way.\n\nAny suggestions as to how I can get this working again?\n\nDavid",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-24T20:23:31.063Z",
                "Answer_score":0,
                "Answer_body":"Thanks for your information and sorry for your experience. For this scenario I think we should raise a support ticket to solve this issue since we don't have enough information.\n\nPlease do create a support directly and let me know your ticket number.\n\nIf you have no support to do so, please let me know I can enable you a one-time-free-ticket.\n\nThanks.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning Python SDK Error \"RunIDConflict\"",
        "Question_creation_time":1612451511860,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/259049\/azure-machine-learning-python-sdk-error-34runidcon.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":7,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hello everybody,\n\nI am currently learning Azure Machine Learning using the learning paths and labs. The lab scripts give me the following error I could not find anywhere yet.\n\n\"Run IDs must be unique within a workspace and can only be used once. Ensure multiple runs with the same ID are not submitted simultaneously.\"\n\nI am running the scripts locally. I have tried both Jupyter Notebook and VS Code. The error occurs exactly after 65 seconds when running experiment scripts. Both lab 1 with script config and lab 2 with an estimator give me the error. Running experiments directly within the IPython script works and I can see the results in the Azure web GUI. My SDK version is 1.21. When I did this in May 2020 with SDK version 1.15 I did not receive this error.\n\nThe respective code blocks that throw the errors copied from the lab scripts:\n\nLab 1:\n\n import os\n import sys\n from azureml.core import Experiment, ScriptRunConfig\n from azureml.widgets import RunDetails\n    \n    \n # Create a script config\n script_config = ScriptRunConfig(source_directory=experiment_folder, \n                       script='diabetes_experiment.py') \n    \n # submit the experiment\n experiment = Experiment(workspace = ws, name = 'diabetes-experiment')\n run = experiment.submit(config=script_config)\n RunDetails(run).show()\n run.wait_for_completion()\n\n\n\nLab 2:\n\n from azureml.train.estimator import Estimator\n from azureml.core import Experiment\n    \n # Create an estimator\n estimator = Estimator(source_directory=training_folder,\n                       entry_script='diabetes_training.py',\n                       compute_target='local',\n                       conda_packages=['scikit-learn']\n                       )\n    \n # Create an experiment\n experiment_name = 'diabetes-training'\n experiment = Experiment(workspace = ws, name = experiment_name)\n    \n # Run the experiment based on the estimator\n run = experiment.submit(config=estimator)\n run.wait_for_completion(show_output=True)\n\n\n\nCan you tell me how to fix this error? Thanks in advance.\n\nRegards",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-16T20:59:54.947Z",
                "Answer_score":0,
                "Answer_body":"Please try to run the labs using Azure ML Studio (Notebooks), I was able to run it there without any errors. However, while running locally, I ran into a different error. Hence, the error may be related to your local environment. I also noticed the Labs have been archived, so please report the issue directly to Microsoft Learn team. If you're trying to explore Azure ML, please follow the tutorials in our official documentation. Hope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-24T08:52:48.263Z",
                "Answer_score":0,
                "Answer_body":"Anyone have find a solution to it? I meet the same issue.\n\n\n\n\n   1 src.run_config.environment = system_managed_env\n\n----> 2 run = exp.submit(src)\n\nC:\\Anaconda\\lib\\site-packages\\azureml\\core\\experiment.py in submit(self, config, tags, **kwargs)\n218 submit_func = get_experiment_submit(config)\n219 with self.log_context(\"submit config {}\".format(config.class.name_)):\n--> 220 run = submit_func(config, self.workspace, self.name, **kwargs)\n221 if tags is not None:\n222 run.set_tags(tags)\n\nC:\\Anaconda\\lib\\site-packages\\azureml\\core\\script_run_config.py in submit(script_run_config, workspace, experiment_name, run_id, _parent_run_id, credential_passthrough)\n62 run = _commands.start_run(project, run_config,\n63 telemetry_values=script_run_config._telemetry_values,\n---> 64 run_id=run_id, parent_run_id=_parent_run_id)\n65 run.add_properties(global_tracking_info_registry.gather_all(script_run_config.source_directory))\n66\n\nC:\\Anaconda\\lib\\site-packages\\azureml_execution_commands.py in start_run(project_object, run_config_object, run_id, injected_files, telemetry_values, parent_run_id, prepare_only, check)\n117 raise ExperimentExecutionException(\"Can not check preparation of local targets\")\n118 return _start_internal_local_cloud(project_object, run_config_object,\n--> 119 **shared_start_run_kwargs)\n120 else:\n121 return _start_internal(project_object, run_config_object, prepare_check=check,\n\nC:\\Anaconda\\lib\\site-packages\\azureml_execution_commands.py in _start_internal_local_cloud(project_object, run_config_object, prepare_only, custom_target_dict, run_id, injected_files, telemetry_values, parent_run_id)\n267\n268 response = ClientBase._execute_func(requests.post, uri, files=files, headers=headers)\n--> 269 _raise_request_error(response, \"starting run\")\n270\n271 invocation_zip_path = os.path.join(project_temp_dir, \"invocation.zip\")\n\nC:\\Anaconda\\lib\\site-packages\\azureml_execution_commands.py in _raise_request_error(response, action)\n569 # response.text is a JSON from execution service.\n570 response_message = get_http_exception_response_string(response)\n--> 571 raise ExperimentExecutionException(response_message)\n572\n573\n\nExperimentExecutionException: ExperimentExecutionException:\nMessage: {\n\"error_details\": {\n\"componentName\": \"execution\",\n\"correlation\": {\n\"operation\": \"a6adb9078e64c642a0828802f831f801\",\n\"request\": \"aea5e681ddf5e549\"\n},\n\"environment\": \"westeurope\",\n\"error\": {\n\"code\": \"UserError\",\n\"innerError\": {\n\"code\": \"Conflict\",\n\"innerError\": {\n\"code\": \"RunIDConflict\"\n}\n},\n\"message\": \"Run IDs must be unique within a workspace and can only be used once. Ensure multiple runs with the same ID are not submitted simultaneously.\",\n\"messageFormat\": \"Run IDs must be unique within a workspace and can only be used once. Ensure multiple runs with the same ID are not submitted simultaneously.\"\n},",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Test dataset contains invalid data. ( Error 0018 ) in Azure ML Studio Evaluate Recommender",
        "Question_creation_time":1631430278073,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/548501\/test-dataset-contains-invalid-data-error-0018-in-a.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I am doing a crop recommender system using the Matchbox recommender system in Azure ml studio.\nwhile splitting the dataset using Recommender split, it won't be split. but I split while using split rows, it works.\n\nbut when evaluating recommender it shows error like 'Test dataset contains invalid data'\nhow to overcome this issue?\n\n][2]\n\n\n\n\n[2]: \/answers\/storage\/attachments\/131249-rate.png",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-24T07:19:36.587Z",
                "Answer_score":0,
                "Answer_body":"@JEYAKEERTHANANK-1817 Thanks, Please publish your project to azure gallery and share the link to your project to check. Here is the link to the document to Split Data using Recommender Split. We recommend that you review the walkthrough provided with this sample experiment in the Azure AI Gallery: Movie Recommendation.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"sizing cloud resources for an AI credit risk analysis application",
        "Question_creation_time":1632292183837,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/561581\/sizing-cloud-resources-for-an-ai-credit-risk-analy.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":18,
        "Question_score":0,
        "Question_body":"AI SaaS\/CRM solution focused on enhancing b2b credit risk analysis. The customer is trying to size his solution in Azure cloud for investors\nbut isn\u2019t clear on how much compute, networking, etc he\u2019ll need and if any of that is included in the AI\/ML framework solutions Azure cloud offers.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-22T08:39:50.867Z",
                "Answer_score":0,
                "Answer_body":"@JP-8660 Is the customer looking to use their own models on the Azure Machine Learning framework or service?\nIf Yes, then the compute requirements of the customer are not limited by the machine learning workspace they are going to use. The compute required to run the training and inference are infact the same compute instances that Azure offers as Azure compute or virtual machines. This can be scalable based on the kind of experiment or compute type chosen i.e virtual machine compute cluster or AKS or ACI. The only charge for using the machine learning service is the compute or storage or networking that is used for your experiments.\n\nMost of the cognitive service related offerings are API based which are limited based on the pricing tier that is chosen. If a certain pricing tier falls short based on usage then the customer can always upgrade the tier and they are offered as pay as you go model. The compute that powers the APIs are highly available and scalable in the backend so higher TPS is supported as per the pricing tier chosen.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Remove a published python script from designer in \"Microsoft Auzre Machine Learning\" framework ?",
        "Question_creation_time":1631266291247,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/547166\/remove-a-published-python-script-from-designer-in.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello,\n\nI created a module that i have published using\n\n from azureml.pipeline.core.graph import InputPortDef, OutputPortDef\n from azureml.pipeline.core.module import Module\n    \n datastore = ws.get_default_datastore()\n    \n p_in = InputPortDef(\n     name=\"p_in\", \n     default_datastore_mode=\"mount\", \n     default_data_reference_name=datastore.name, \n     label=\"Donn\u00e9es de production\"\n     )\n    \n module = Module.create(ws, name=\"Well Clustering\", description=\"use well prod to create n class of producters\")\n entry_version = module.publish_python_script(\"main.py\", \"initial\", \n                                              inputs=[p_in], outputs=[], params = { \"n_classes\": 4},\n                                              version=\"1\", source_directory=\".\")\n\n\n\n\nIt works and i can see it in the Designer as a \"Custom Module\" with the right version, but how can i \"unregister it\"",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-23T04:05:06.773Z",
                "Answer_score":0,
                "Answer_body":"Hi, please go to Azure ML Studio > Assets > Components to view all your custom components. Select target component and click Archive on the top action bar to archive that component from your list. You can also turn on View archived button to view all your archived component and restore them back to the list if needed. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Question for Azure ML Studio Classic",
        "Question_creation_time":1632106981540,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/558101\/question-for-azure-ml-studio-classic.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hi, saw the post on https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/migrate-overview, would like to get some clarifications.\n\n\"Beginning 1 December 2021, you will not be able to create new Machine Learning Studio (classic) resources. Through 31 August 2024, you can continue to use the existing Machine Learning Studio (classic) resources.\"\nIf I am just interested in creating the experiments, creating the ML models using the click-and-drag, is it still supported? Ie, i want to create new experiment, new model, new dataset, from now till 2024. I am focused more on the creating of ML model and evaluation, not so much on the deployment. What does the resources mean?\n\nwhat are the options for students to migrate to Azure machine learning, if they do not have credit card to setup an azure account? What if the students are from private institutions, ie not from government affiliated organizations? Or is there a support granted to the students, if they have a .edu email account?\n\n\n\n\nthank you and apologies if the queries are out of place. Not sure where can i get for help. thanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-20T07:53:08.5Z",
                "Answer_score":0,
                "Answer_body":"@YewMeng-6232 I think some of your questions are answered on this thread.\nTo clarify, you can use the resource or workspace to create experiments provided that you have created the resource before 1st December 2021 and not deleted it after this date.\n\nFor students Azure runs a program which helps students use some of the services with free credit. All the criteria and services available are listed on the page.\n\nYou can also use the new Azure Machine Learning designer which does not have any dates for retirement. The classic studio is retiring so if you plan to use the services for a longer period it is advisable to use the designer services.\n\nIf an answer is helpful, please click on  or upvote  which might help other community members reading this thread.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How AI\/Machine learning works in translator",
        "Question_creation_time":1632270279733,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/561221\/how-aimachine-learning-works-in-translator.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I am an undergraduate community college student in Richmond, VA.\n\nI am wondering if you can help me understand how the translator works or if you can connect me with another expert who might be able to help me learn exactly how google translate works.\n\nQuestions:\n\nIf you enter the same phrase into the translator multiple times, does the program learn from it? If so, how?\n\nDoes the translator take what people enter into the translator, store it and use it to output a common translation?\n\nHere is a scenario. Let's say I wrote something in english and then translated it word for word into farsi. Then, I took my farsi work, inputed into google translate, and the output was a translation almost word for work with my english translation. IF I keep doing that, would the translator \"deep learn\" and correct itself so that it exactly matched my english translation? What about if I kept hitting the reverse arrow, and changing a word here or there, until both the farsi and english sentences inside the translator, match exactly what I originally wrote? Would the translator learn from that? In that way could I have \"taught\" the translator the most common way to interpret sentences in either language? Is there a way to prove that someone used a translator to write something? IF someone is trying to prove that someone else used a translator to create a literary work, instead of writing it themselves, can they fairly say that the translator's translation matching word for word is indisputable, undeniable proof of their accusation?\n\nVery Respectfully,",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-23T04:53:45.967Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. According to our confidentiality document, customer data submitted for translation to Azure Cognitive Services Translator (both standard and custom models), Speech service, the Microsoft Translator Speech API, and the text translation features in Microsoft Office products are not written to persistent storage. There will be no record of the submitted text or voice, or any portion thereof, in any Microsoft data center. The audio and text will not be used for training purposes either. The documents you upload using Custom Translator (portal or APIs) are stored encrypted in your workspace. Custom Translator uses your uploaded documents exclusively to provide your personalized translation system and does not use it for any other purpose. The documents you upload to Custom Translator will be stored in the Azure region you selected when you created your Translator key until you delete them or until your account expires. For more details on Microsoft Translator and how to use the service, please review our documentation.\n\nHope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML compute not able to access Azure MLS workspace blob( not in vnet) during automl experiment execution",
        "Question_creation_time":1631627630167,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/551634\/azure-ml-compute-not-able-to-access-azure-mls-work.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"Hi Team,\n\nI'm trying to run the automl code from the examples (https:\/\/github.com\/Azure\/MachineLearningNotebooks\/tree\/master\/how-to-use-azureml\/automated-machine-learning\/regression-explanation-featurization) in Azure MLS which is not in virtual network. While running the experiment, it is getting failed with the below error.\n\nAzureMLCompute job failed.\nBFSMountError: Unable to mount blob fuse file system\nInfo: Could not mount Azure Blob Container azureml-blobstore-xxxx at workspaceblobstore: Unauthorized. Cannot access the storage account with the given account key. Please verify that the account key is valid.\nInfo: Failed to setup runtime for job execution: Job environment preparation failed on 10.0.0.4 with err exit status 1.\n\nNot sure why the AzureML is not able to access its own blobstorage to place the model artifacts.\nThe AzureML and the workspace blob both are not in virtual network.\n\nWorkarounds tried:\n1) Tried to register the workspace blob container (azureml-blobstore-<ID>) as per the link here (https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data), but still getting the same error.\n\nNote: The workspace blob storage keys are synced and can able to access the notebooks and data in AzureML, Is this causing the issue?\n\nAs per the ticket :- https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/35043\/azure-machine-learning-resync-keys-not-working-no.html\n\nAre the storage keys cached in the storage connection strings at the backend ? however the error message is different, in the reference ticket it says not able to access the resource, but in my case it is not able mount to the azure-ml-<ID> container.\n\nCould you please help on it.\n\nThanks in advance.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-14T21:51:14.653Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nCould you please let me know where you try to do that? I tried in my Azure Machine Learning Notebook in the studio and everything works fine for me.\n\nPlease let me know more details and let's see if we can figure this out here. If we need more environment details, I will recommend raising a ticket for this.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-15T04:40:21.273Z",
                "Answer_score":0,
                "Answer_body":"Thanks for your response.\n\nI'm able to connect to workspace and create the compute cluster, I'm getting the error while submitting the experiment on the AML compute.\n\nIt is throwing unauthorized error while trying to place the Automl artifacts folder in the AML workspace default blobstore.\n\n\n\n\n\n\n\nI tired explicitly registering the AML workspace blob container (azureml-blobstore-<ID>) as per the link here (https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data), but still getting the same error.\n\nIs it because of resyncing azure blob keys with azure MLS?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Auto ML model endpoint deployment (Container Instance): Error No module named 'azureml.api'",
        "Question_creation_time":1628773443990,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/511349\/auto-model-deployment-in-container-instance-no-mod.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_follower_count":16,
        "Question_score":1,
        "Question_body":"Hi,\n\nI am trying to deploy a model trained using AutoML directly from the Portal but the deployment to Container Instance fails. From the logs I can read the errors reported below.\n\nI am not sure what's the problem, it only appeared recently and fun fact is that if I try to deploy a model that was trained about 10 days ago it works without problem.\nDid anything change in the meantime? What am I missing?\n\n\n\n\nException in worker process\nTraceback (most recent call last):\nFile \"\/var\/azureml-server\/routes_common.py\", line 37, in <module>\nfrom azureml.api.exceptions.ClientSideException import ClientSideException\nModuleNotFoundError: No module named 'azureml.api'\n\nand\n\nTraceback (most recent call last):\nFile \"\/azureml-envs\/azureml_058f846b7dd22d1daecb37981c0969bb\/lib\/python3.6\/site-packages\/gunicorn\/arbiter.py\", line 589, in spawn_worker\nworker.init_process()\nFile \"\/azureml-envs\/azureml_058f846b7dd22d1daecb37981c0969bb\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py\", line 134, in init_process\nself.load_wsgi()\nFile \"\/azureml-envs\/azureml_058f846b7dd22d1daecb37981c0969bb\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py\", line 146, in load_wsgi\nself.wsgi = self.app.wsgi()\nFile \"\/azureml-envs\/azureml_058f846b7dd22d1daecb37981c0969bb\/lib\/python3.6\/site-packages\/gunicorn\/app\/base.py\", line 67, in wsgi\nself.callable = self.load()\nFile \"\/azureml-envs\/azureml_058f846b7dd22d1daecb37981c0969bb\/lib\/python3.6\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 58, in load\nreturn self.load_wsgiapp()\nFile \"\/azureml-envs\/azureml_058f846b7dd22d1daecb37981c0969bb\/lib\/python3.6\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 48, in load_wsgiapp\nreturn util.import_app(self.app_uri)\nFile \"\/azureml-envs\/azureml_058f846b7dd22d1daecb37981c0969bb\/lib\/python3.6\/site-packages\/gunicorn\/util.py\", line 359, in import_app\nmod = importlib.import_module(module)\nFile \"\/azureml-envs\/azureml_058f846b7dd22d1daecb37981c0969bb\/lib\/python3.6\/importlib\/init.py\", line 126, in import_module\nreturn _bootstrap._gcd_import(name[level:], package, level)\nFile \"<frozen importlib._bootstrap>\", line 978, in _gcd_import\nFile \"<frozen importlib._bootstrap>\", line 961, in _find_and_load\nFile \"<frozen importlib._bootstrap>\", line 950, in _find_and_load_unlocked\nFile \"<frozen importlib._bootstrap>\", line 655, in _load_unlocked\nFile \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\nFile \"<frozen importlib._bootstrap>\", line 205, in _call_with_frames_removed\nFile \"\/var\/azureml-server\/entry.py\", line 1, in <module>\nimport create_app\nFile \"\/var\/azureml-server\/create_app.py\", line 4, in <module>\nfrom routes_common import main\nFile \"\/var\/azureml-server\/routes_common.py\", line 39, in <module>\nfrom azure.ml.api.exceptions.ClientSideException import ClientSideException\nModuleNotFoundError: No module named 'azure.ml'",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-13T06:24:07.123Z",
                "Answer_score":1,
                "Answer_body":"@LeoSabato-0219 I think this is because of a recent change in the SDK, release notes are mentioned here.\n\nThis change is causing an issue:\n\nazureml-defaults\nWe are removing the dependency azureml-model-management-sdk==1.0.1b6.post1 from azureml-defaults.\n\nAn issue is also reported on a different github repo.\n\nThe workaround for now is to update your conda environment yaml file to include the package azureml-model-management-sdk under pip after azureml-defaults\n\nI hope this helps.",
                "Answer_comment_count":8,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-22T17:26:53.52Z",
                "Answer_score":0,
                "Answer_body":"Hello\n\nI also got in to this issue 3 days back when I tried to deploy a pytorch based recommender model with a newer variation. I tried with both the recommended solution - explicitly installing either the library azure-ml-api-sdk. or azureml-model-management-sdk\n\nBoth landed on this new error\n\nmessage\": \"Error in entry script, AttributeError: Can't get attribute 'new_block' on <module 'pandas.core.internals.blocks' from '\/azureml-envs\/azureml_a9071edb452f2dedb0ab60b9e2450ad3\/lib\/python\n\n\n\n\nSomewhere I found that Pandas 1.3 is causing this error and 1.2 would solve it- I tried with Pandas 1.2 \/ 0.25 also but the \"Cant get Attribute \"new block\" stays --\n\nI had to reschedule a planned demo as I never thought I would get this problem for a very similar model that is running in production.\n\nAny help is much appreciated -\n\nThanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-22T20:04:06.627Z",
                "Answer_score":0,
                "Answer_body":"Update\n\nThe pandas 1.2 library is working for this issue- Originally I was using it as a reference in the YML file during deployment - But I tried changing it in my environment and ran all the scripts including train and validate scripts and now the deployment worked. Hope this saves sometime for people out there who struggled like me\n\nThank you",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"File Dataset not supported in Automated ML",
        "Question_creation_time":1632158977537,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/559228\/file-dataset-not-supported-in-automated-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi Team,\n\nI'm trying to select a File dataset (file from Power BI) in Automated ML for a Regressive Machine Learning Model. However, Machine learning studio is displaying the dataset name under unsupported dataset (Screenshot attached). I wanted to know why the Power BI file is not being supported in the Automated ML? Additionally, I wanted to know what is the way I can upload the Power BI file (.pbix extension) in Machine learning studio to train the Regressive machine learning model?\n\nPlease let me know if you need any details from me.\n\nRegards,\nAmbarish",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-22T03:55:38.717Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. Currently, AutoML only supports TabularDatasets, so the dataset type should default to Tabular. You can create TabularDatasets from .csv, .tsv, .parquet, .jsonl files, and from SQL query results. You may need to convert the Power BI file to a supported file format. Hope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AzureML Data Labeling remains at \"Initializing\" state",
        "Question_creation_time":1632142944040,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/558956\/azureml-data-labeling-remains-at-34initializing34.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I've created two Data Label projects, one with ML assistance and one without.\nBoth of these projects have been in the \"initializing\" state for days (4 days at the time of this post).\n\nIs there a place to check progress and what is the expected time it should take for a labeling project to be ready?\n\nAre there best practices perhaps that might speed this process up?\n\nThe dataset has about 2,000 JPG images in it, so I can't imagine anything taking that long to even just index them.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-21T15:05:56.88Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. According to this document, initialization should proceed at roughly 20 data points per second. Please try refreshing the page (due to lack of autorefresh). If issue persists, comment below and I'd be glad to forward your feedback to the product group for further investigation.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Clean Data Error",
        "Question_creation_time":1631932138293,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/557185\/import-data-error-2.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I'm getting an error trying to clean a data module in Azure Machine Learning Studio (classic).\n\nBelow is the full log. I've tried logging out and back into my Azure account to no avail. Is there something wrong with my credentials?\n\nRecord Starts at UTC 09\/18\/2021 02:19:08:\n\n\nRun the job:\"\/dll \"Microsoft.Analytics.Modules.CleanMissingData.Dll, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca;Microsoft.Analytics.Modules.CleanMissingData.Dll.CleanMissingData;Run\" \/Output0 \"....\\Cleaned dataset\\Cleaned dataset.dataset\" \/Output1 \"....\\Cleaning transformation\\Cleaning transformation.itransform\" \/inputData \"....\\Dataset\\Dataset.csv\" \/columnsToClean \"%7B%22isFilter%22%3Atrue%2C%22rules%22%3A%5B%7B%22ruleType%22%3A%22ColumnNames%22%2C%22columns%22%3A%5B%22symboling%22%5D%2C%22exclude%22%3Afalse%7D%5D%7D\" \/minRatio \"0\" \/maxRatio \"1\" \/cleaningMode \"Replace with mean\" \/colsWithAllMissing \"Remove\" \/indicatorColumns \"False\" \/ContextFile \"...._context\\ContextFile.txt\"\"\n[Start] Program::Main\n[Start] DataLabModuleDescriptionParser::ParseModuleDescriptionString\n[Stop] DataLabModuleDescriptionParser::ParseModuleDescriptionString. Duration = 00:00:00.0024833\n[Start] DllModuleMethod::DllModuleMethod\n[Stop] DllModuleMethod::DllModuleMethod. Duration = 00:00:00.0000264\n[Start] DllModuleMethod::Execute\n[Start] DataLabModuleBinder::BindModuleMethod\n[Verbose] moduleMethodDescription Microsoft.Analytics.Modules.CleanMissingData.Dll, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca;Microsoft.Analytics.Modules.CleanMissingData.Dll.CleanMissingData;Run\n[Verbose] assemblyFullName Microsoft.Analytics.Modules.CleanMissingData.Dll, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca\n[Start] DataLabModuleBinder::LoadModuleAssembly\n[Verbose] Loaded moduleAssembly Microsoft.Analytics.Modules.CleanMissingData.Dll, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca\n[Stop] DataLabModuleBinder::LoadModuleAssembly. Duration = 00:00:00.0090461\n[Verbose] moduleTypeName Microsoft.Analytics.Modules.CleanMissingData.Dll.CleanMissingData\n[Verbose] moduleMethodName Run\n[Information] Module FriendlyName : Clean Missing Data\n[Information] Module Release Status : Release\n[Stop] DataLabModuleBinder::BindModuleMethod. Duration = 00:00:00.0102317\n[Start] ParameterArgumentBinder::InitializeParameterValues\n[Verbose] parameterInfos count = 10\n[Verbose] parameterInfos[0] name = inputData , type = Microsoft.Numerics.Data.Local.DataTable\n[Start] DataTableCsvHandler::HandleArgumentString\n[Stop] DataTableCsvHandler::HandleArgumentString. Duration = 00:00:00.1604789\n[Verbose] parameterInfos[1] name = columnsToClean , type = Microsoft.Analytics.Modules.Common.Dll.ColumnSelection\n[Verbose] parameterInfos[2] name = minRatio , type = System.Double\n[Verbose] Converted string '0' to value of type System.Double\n[Verbose] parameterInfos[3] name = maxRatio , type = System.Double\n[Verbose] Converted string '1' to value of type System.Double\n[Verbose] parameterInfos[4] name = cleaningMode , type = Microsoft.Analytics.Modules.CleanMissingData.Dll.CleanMissingData+CleanMissingDataHandlingPolicy\n[Verbose] Converted string 'Replace with mean' to enum of type Microsoft.Analytics.Modules.CleanMissingData.Dll.CleanMissingData+CleanMissingDataHandlingPolicy\n[Verbose] parameterInfos[5] name = replacementValue , type = System.String\n[Verbose] Set optional parameter replacementValue value to NULL\n[Verbose] parameterInfos[6] name = colsWithAllMissing , type = Microsoft.Analytics.Modules.CleanMissingData.Dll.CleanMissingData+ColumnsWithAllValuesMissing\n[Verbose] Converted string 'Remove' to enum of type Microsoft.Analytics.Modules.CleanMissingData.Dll.CleanMissingData+ColumnsWithAllValuesMissing\n[Verbose] parameterInfos[7] name = indicatorColumns , type = System.Boolean\n[Verbose] Converted string 'False' to value of type System.Boolean\n[Verbose] parameterInfos[8] name = iterations , type = System.Int32\n[Verbose] Set optional parameter iterations value to NULL\n[Verbose] parameterInfos[9] name = iterationsPCA , type = System.Int32\n[Verbose] Set optional parameter iterationsPCA value to NULL\n[Stop] ParameterArgumentBinder::InitializeParameterValues. Duration = 00:00:00.4304001\n[Verbose] Begin invoking method Run ...\n[Verbose] End invoking method Run\n[Start] DataLabOutputManager::ManageModuleReturnValue\n[Verbose] moduleReturnType = System.Tuple`2[T1,T2]\n[Start] DataLabOutputManager::ConvertTupleOutputToFiles\n[Verbose] tupleType = System.Tuple`2[Microsoft.Numerics.Data.Local.DataTable,Microsoft.Analytics.MachineLearning.ITransform`2[Microsoft.Numerics.Data.Local.DataTable,Microsoft.Numerics.Data.Local.DataTable]]\n[Verbose] outputName Output0\n[Start] DataTableDatasetHandler::HandleOutput\n[Start] SidecarFiles::CreateVisualizationFiles\n[Information] Creating Cleaned dataset.visualization with key visualization...\n[Stop] SidecarFiles::CreateVisualizationFiles. Duration = 00:00:00.0704111\n[Start] SidecarFiles::CreateDatatableSchemaFile\n[Information] SidecarFiles::CreateDatatableSchemaFile creating \"....\\Cleaned dataset\\Cleaned dataset.schema\"\n[Stop] SidecarFiles::CreateDatatableSchemaFile. Duration = 00:00:00.0071185\n[Start] SidecarFiles::CreateMetadataFile\n[Information] SidecarFiles::CreateMetadataFile creating \"....\\Cleaned dataset\\Cleaned dataset.metadata\"\n[Stop] SidecarFiles::CreateMetadataFile. Duration = 00:00:00.0019639\n[Stop] DataTableDatasetHandler::HandleOutput. Duration = 00:00:00.1898522\n[Verbose] outputName Output1\n[Start] CustomSerializationHandler::HandleOutput\n[Start] DotNetSerializationHandler::HandleOutput\n[Start] SidecarFiles::CreateRuntimeInfoFile\n[Information] SidecarFiles::CreateRuntimeInfoFile creating \"....\\Cleaning transformation\\Cleaning transformation.runtimeinfo\"\n[Information] SidecarFileWritter::WriteRuntimeInfoToFile setting Language info for \"Microsoft.Analytics.Modules.CleanMissingData.Dll.CleaningMVTransform\"\n[ModuleOutput] SidecarFileWritter::WriteRuntimeInfoToFile setting Language info for \"Microsoft.Analytics.Modules.CleanMissingData.Dll.CleaningMVTransform\"\n[ModuleOutput] Setting Languge to DotNet.\n[Stop] SidecarFiles::CreateRuntimeInfoFile. Duration = 00:00:00.0016640\n[Start] SidecarFiles::CreateMetadataFile\n[Information] SidecarFiles::CreateMetadataFile creating \"....\\Cleaning transformation\\Cleaning transformation.metadata\"\n[Stop] SidecarFiles::CreateMetadataFile. Duration = 00:00:00.0003313\n[Stop] DotNetSerializationHandler::HandleOutput. Duration = 00:00:00.0045472\n[Stop] CustomSerializationHandler::HandleOutput. Duration = 00:00:00.0050090\n[Stop] DataLabOutputManager::ConvertTupleOutputToFiles. Duration = 00:00:00.2003385\n[Stop] DataLabOutputManager::ManageModuleReturnValue. Duration = 00:00:00.2017888\n[Verbose] {\"InputParameters\":{\"DataTable\":[{\"Rows\":205,\"Columns\":26,\"estimatedSize\":12574720,\"ColumnTypes\":{\"System.Int32\":5,\"System.Nullable`1[System.Int32]\":4,\"System.String\":10,\"System.Double\":5,\"System.Nullable`1[System.Double]\":2},\"IsComplete\":true,\"Statistics\":{\"0\":[0.8341463414634146,1.0,-2.0,3.0,1.2453068281055315,6.0,0.0],\"1\":[122.0,115.0,65.0,256.0,35.442167530553256,51.0,41.0],\"2\":[22,0],\"3\":[2,0],\"4\":[2,0],\"5\":[2,2],\"6\":[5,0],\"7\":[3,0],\"8\":[2,0],\"9\":[98.756585365853581,97.0,86.6,120.9,6.0217756850255721,53.0,0.0],\"10\":[174.04926829268285,173.2,141.1,208.1,12.337288526555183,75.0,0.0],\"11\":[65.907804878048722,65.5,60.3,72.3,2.1452038526871831,44.0,0.0],\"12\":[53.724878048780596,54.1,47.8,59.8,2.4435219699049036,49.0,0.0],\"13\":[2555.5658536585365,2414.0,1488.0,4066.0,520.68020350163874,171.0,0.0],\"14\":[7,0],\"15\":[7,0],\"16\":[126.90731707317073,120.0,61.0,326.0,41.642693438179847,44.0,0.0],\"17\":[8,0],\"18\":[3.3297512437810943,3.31,2.54,3.94,0.27353873182959904,38.0,4.0],\"19\":[3.2554228855721377,3.29,2.07,4.17,0.31671745337703111,36.0,4.0],\"20\":[10.142536585365862,9.0,7.0,23.0,3.9720403218632976,32.0,0.0],\"21\":[104.25615763546799,95.0,48.0,288.0,39.714368786793578,59.0,2.0],\"22\":[5125.3694581280788,5200.0,4150.0,6600.0,479.33455983341668,23.0,2.0],\"23\":[25.219512195121951,24.0,13.0,49.0,6.5421416530016216,29.0,0.0],\"24\":[30.751219512195121,30.0,16.0,54.0,6.886443130941827,30.0,0.0],\"25\":[13207.129353233831,10295.0,5118.0,45400.0,7947.066341939274,186.0,4.0]}}],\"Generic\":{\"columnsToClean\":\"{\\\"isFilter\\\":true,\\\"rules\\\":[{\\\"ruleType\\\":\\\"ColumnNames\\\",\\\"columns\\\":[\\\"symboling\\\"],\\\"exclude\\\":false}]}\",\"minRatio\":0.0,\"maxRatio\":1.0,\"cleaningMode\":\"ReplaceWithMean\",\"colsWithAllMissing\":\"Remove\",\"indicatorColumns\":false}},\"OutputParameters\":[\"Parameter with no known logging method, Microsoft.Analytics.Modules.CleanMissingData.Dll.CleaningMVTransform\",{\"Rows\":205,\"Columns\":26,\"estimatedSize\":0,\"ColumnTypes\":{\"System.Int32\":5,\"System.Nullable`1[System.Int32]\":4,\"System.String\":10,\"System.Double\":5,\"System.Nullable`1[System.Double]\":2},\"IsComplete\":true,\"Statistics\":{\"0\":[0.8341463414634146,1.0,-2.0,3.0,1.2453068281055315,6.0,0.0],\"1\":[122.0,115.0,65.0,256.0,35.442167530553256,51.0,41.0],\"2\":[22,0],\"3\":[2,0],\"4\":[2,0],\"5\":[2,2],\"6\":[5,0],\"7\":[3,0],\"8\":[2,0],\"9\":[98.756585365853581,97.0,86.6,120.9,6.0217756850255721,53.0,0.0],\"10\":[174.04926829268285,173.2,141.1,208.1,12.337288526555183,75.0,0.0],\"11\":[65.907804878048722,65.5,60.3,72.3,2.1452038526871831,44.0,0.0],\"12\":[53.724878048780596,54.1,47.8,59.8,2.4435219699049036,49.0,0.0],\"13\":[2555.5658536585365,2414.0,1488.0,4066.0,520.68020350163874,171.0,0.0],\"14\":[7,0],\"15\":[7,0],\"16\":[126.90731707317073,120.0,61.0,326.0,41.642693438179847,44.0,0.0],\"17\":[8,0],\"18\":[3.3297512437810943,3.31,2.54,3.94,0.27353873182959904,38.0,4.0],\"19\":[3.2554228855721377,3.29,2.07,4.17,0.31671745337703111,36.0,4.0],\"20\":[10.142536585365862,9.0,7.0,23.0,3.9720403218632976,32.0,0.0],\"21\":[104.25615763546799,95.0,48.0,288.0,39.714368786793578,59.0,2.0],\"22\":[5125.3694581280788,5200.0,4150.0,6600.0,479.33455983341668,23.0,2.0],\"23\":[25.219512195121951,24.0,13.0,49.0,6.5421416530016216,29.0,0.0],\"24\":[30.751219512195121,30.0,16.0,54.0,6.886443130941827,30.0,0.0],\"25\":[13207.129353233831,10295.0,5118.0,45400.0,7947.066341939274,186.0,4.0]}}],\"ModuleType\":\"Microsoft.Analytics.Modules.CleanMissingData.Dll\",\"ModuleVersion\":\" Version=6.0.0.0\",\"AdditionalModuleInfo\":\"Microsoft.Analytics.Modules.CleanMissingData.Dll, Version=6.0.0.0, Culture=neutral, PublicKeyToken=69c3241e6f0468ca;Microsoft.Analytics.Modules.CleanMissingData.Dll.CleanMissingData;Run\",\"Errors\":\"\",\"Warnings\":[],\"Duration\":\"00:00:00.7323002\"}\n[Stop] DllModuleMethod::Execute. Duration = 00:00:00.7557727\n[Stop] Program::Main. Duration = 00:00:00.8973350\nModule finished after a runtime of 00:00:00.9843864 with exit code 0\nExecution failed due to exception:taskStatusCode=400. Failed to upload W:\\jw\\e\\Cleaned dataset\\Cleaned dataset.dataset to Uri experimentoutput\/4a90c8cd-cc1d-4de0-97b2-aebb1285e140\/4a90c8cd-cc1d-4de0-97b2-aebb1285e140.dataset. This is an Azure storage request failure with status code 404. The request id is 5052585f-501e-000b-2933-acd43e000000 and the error message is The specified resource does not exist.. Possible reasons for such failure: (1) Invalid storage account or credential (2) Invalid SAS token (3) Concurrent jobs trying to upload files to the same blob at the same time. If those are not your case, please consider it as a transient error and retry.\n\n\nRecord Ends at UTC 09\/18\/2021 02:19:09.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-20T05:59:40.243Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for reaching to us about this issue. I have the same issue because of my bad setting for cleaning mode.\n\nFor replace with mean:\nCalculates the column mean and uses the mean as the replacement value for each missing value in the column.\n\nApplies only to columns that have Integer, Double, or Boolean data types. See the Technical Notes section for more information.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/clean-missing-data#bkmk_TechNotes\n\nYou may contain other types of data.\n\nMy solution is I used \"MICE\" instead. Could you please check on your data types or change your mode?\n\nHope this helps.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-20T16:28:19.043Z",
                "Answer_score":0,
                "Answer_body":"Thank you YutongTie-MSFT but unfortunately that does not appear to be the case. Several new experiment attempts have been failing me lately and given the 400 code errors I'm noticing in the logs, I suspect the issue is on Microsoft's side.\n\nTo verify further, here I run the experiment again with only one numerical column selected:\n\n======\n\n======\n\n======\n\n======\n\nMind you, I'm using the basic Automobile price data (Raw) that appears under Sample Datasets. In review of my log file, I suspect this to be potentially the most relevant piece (emphasis mine):\n\n\n\n\nExecution failed due to exception:taskStatusCode=400. Failed to upload [...].dataset to Uri [...].dataset. This is an Azure storage request failure with status code 404. The request id is [...] and the error message is The specified resource does not exist.. Possible reasons for such failure: (1) Invalid storage account or credential (2) Invalid SAS token (3) Concurrent jobs trying to upload files to the same blob at the same time. If those are not your case, please consider it as a transient error and retry.\n\n\n\n\nQuestions for Follow Up:\n\nCan you run my experiment and verify it for you?\n\n\nIf functional, how do I check \"possible reasons\" (1), (2), and (3)?\n\n\nIf not, how do we escalate the issue?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-20T18:31:05.827Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nI followed your settings but everything seems work well for me as below:\nReplace by mean:\n\n\nMICE:\n\n\nCould you please rebuild one to try? I am in South Central US.\n\n\nPlease let me know if you still have this issue.\n\nRegards,\nYutong",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Convert File Dataset into a Dataframe to use in a pipeline",
        "Question_creation_time":1630504637667,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/536168\/convert-file-dataset-into-a-dataframe-to-use-in-a.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_follower_count":16,
        "Question_score":0,
        "Question_body":"Hello,\n\nI would like to convert a file dataset into a dataframe using a python script to use the data in a pipeline. I need to use the file dataset as i want to train my model using the files and not the table.\n\nThank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-02T10:17:48.457Z",
                "Answer_score":0,
                "Answer_body":"@MEZIANEYani-9720 I think you could try this to use the filedataset as pandas dataframe, download and use it for your experiment's training.\n\n from azureml.core import Dataset\n from azureml.opendatasets import MNIST\n import pandas as pd\n import os\n data_folder = os.path.join(os.getcwd(), 'data')\n os.makedirs(data_folder, exist_ok=True)\n    \n #Download the dataset\n mnist_file_dataset = MNIST.get_file_dataset()\n mnist_file_dataset.download(data_folder, overwrite=True)\n #Use the files in dataframe\n df = pd.DataFrame(mnist_file_dataset.to_path())\n print(df)\n    \n #Register the dataset for training\n mnist_file_dataset = mnist_file_dataset.register(workspace=ws,\n                                                  name='mnist_opendataset',\n                                                  description='training and test dataset',\n                                                  create_new_version=True)",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-06T14:45:29.03Z",
                "Answer_score":0,
                "Answer_body":"My aim is to run a pipeline (pre-process data and tune model hyperparameters) that I already have with design using as input data not each row of a table as it does with a tabular dataset but rather for each CVS file that represents an object (its information with a lot of rows) as input since the random selection per frame is amplifying the performance of the model. I have the data as tabular and files in a dataset. I have managed to get the path of each cvs file; but cannot read them as part of a new dataframe. I have the data in a datastore and dataset, so I don\u2019t know if to accomplish this I should store the data elsewhere (I have not been working long with Azure so I am not acquainted with all the storage possibilities and the interactions between these and the ML studio.)\n\nI manage to do this in python with the following code:\nlistOfFile = os.listdir(path)\nfor file in listOfFile:\nnew_well=pd.read_csv(os.path.join(path,file))\n\n\n\n\nAnd in Azure this is as far as I have gotten without result:\n\n   ds = Dataset.get_by_name(ws, name='well files')\n  ds.download(data_folder, overwrite=True)\n  df = pd.DataFrame(ds.to_path())\n  df= dirr+df\n files = pd.DataFrame(df)\n well = map(pd.read_csv, files)\n\n\n\n\n\nbut I cannot use this output of well into the design pipeline due to being class map.\n\nThank you very much for your help. It is greatly appreciated as I really have no clue whatsoever on how to proceed or solve this.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-09T14:19:01.737Z",
                "Answer_score":0,
                "Answer_body":"@romungi-MSFT\n\nIs there a way to do this with multiples .cvs documents?\nI have a folder full of cvs files I need to read, is there a way to give the path of the folder and for the program to read all of the cvs files within that folder?\nThere are a lot so not really feasible to do them one by one.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-10T08:24:33.5Z",
                "Answer_score":0,
                "Answer_body":"Ok I managed with this very simple line:\n\n                      tabular_dataset_3 = Dataset.Tabular.from_delimited_files(path=(datastore,'weather\/**\/*.csv'))\n\n\n\nHowever, I\u2019m afraid this will not help me accomplish my objective as all the files are now in the same tabular dataset and now, I need the training of a model to be done considering the files and not all the rows, meaning that there will be random selection per frame and not per document as I desired. I need to pre-process the data and split the training and test dataset based on the csv documents, not on a table containing all the data points.\n\nThank you for your help!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Designer: Cannot create inference because there is no model on this pipeline",
        "Question_creation_time":1603790266017,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/140838\/azure-designer-cannot-create-inference-because-the.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I have created a pipeline in Azure Designer and trying to deploy this as a batch prediction.\n\nWhen I click \"Create Inference Pipeline\" and \"Batch Inference Pipeline\" I get this error message:\nCannot create inference because there is no model on this pipeline.\n\nHow can I deploy this as a batch prediction?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-27T09:37:17.777Z",
                "Answer_score":1,
                "Answer_body":"Is it possible to share the screenshot of your designer pipeline or submit a feedback by clicking the smiley face on the top right corner of the studio portal? This will help us better debug\/troubleshoot the issue.",
                "Answer_comment_count":5,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-04-12T13:20:09.29Z",
                "Answer_score":0,
                "Answer_body":"I am also having this issue. any solution for this. we have exising R code which is using xboost R models as a saved file. we used execute R code task, the experiments executing fine and returning the results as expected, this experiment does not have train model task in the experiment. how to publish this as a webserive?\n\nAppreciate any help in advance.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Not able to pull docker image from Container Registry",
        "Question_creation_time":1631798842910,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/555024\/not-able-to-pull-docker-image-from-container-regis.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hello community,\nI'm facing a problem, my ACR in my resource group was deleted and I couldn't create any instance. I created again and now I can create instances but i'm having problems to run the dataset profile. It's failing to pull the image docker.\n\nThis is the output\n\n AzureMLCompute job failed.\n FailedPullingImage: Unable to pull docker image\n     imageName: 19acd0cdf57549bcace363c924cf045b.azurecr.io\/azureml\/azureml_e7e3dfebc6129c75c60868383ebc992f\n     error: Run docker command to pull public image failed with error: Error response from daemon: Get https:\/\/19acd0cdf57549bcace363c924cf045b.azurecr.io\/v2\/azureml\/azureml_e7e3dfebc6129c75c60868383ebc992f\/manifests\/latest: unauthorized: authentication required, visit https:\/\/aka.ms\/acr\/authorization for more information.\n .\n     Reason: Error response from daemon: Get https:\/\/19acd0cdf57549bcace363c924cf045b.azurecr.io\/v2\/azureml\/azureml_e7e3dfebc6129c75c60868383ebc992f\/manifests\/latest: unauthorized: authentication required, visit https:\/\/aka.ms\/acr\/authorization for more information.\n    \n     Info: Failed to setup runtime for job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.\n\n\n\nThe ML Studio has the following permissions on the ACR permissions\n\n\n\n\nThe docker image appears in the repositories of the ACR\n\n\n\n\nAny hint how can i solve this problem?\n\nThanks in advance",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-16T14:37:51.767Z",
                "Answer_score":2,
                "Answer_body":"@MoresiMarco-2752 Does this container registry have the admin account enabled? A requirement while creating a workspace with an existing container registry is to have the admin account enabled.\n\nIf you have already enabled it then a re-sync of keys might be required for your workspace.\n\n az ml workspace sync-keys -w <workspace-name> -g <resource-group-name>\n\nDeleting the default container registry used by the workspace can also cause the workspace to break.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Support for Azure Machine Learning workspace with Azure Kubernetes Service 1.21.X",
        "Question_creation_time":1631726396763,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/553605\/support-for-azure-machine-learning-workspace-with.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"Hi Team,\n\nCurrently Azure Machine Learning Worksapce doesnt support Azure Kubernetes Service 1.21.X, when will this support be available ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-17T00:43:59.767Z",
                "Answer_score":0,
                "Answer_body":"@BharathReddy-6301\n\nHello,\n\nWe are working on this. We don't have an exact date, but the ETA for the support is the last week of September to the first week of October.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML: User errors were found in at least one of the child runs",
        "Question_creation_time":1630835455217,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/540302\/azure-ml-user-errors-were-found-in-at-least-one-of-1.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi, I am trying to perform hyperparameter tuning, but I keep getting the error in my Question Title. I am new to Azure, and I am not sure if it is some error in my script. Could someone advise please?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Machine Learning\u306b\u3064\u3044\u3066\u306e\u8cea\u554f",
        "Question_creation_time":1631251067517,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/546760\/machine-learning%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%E3%81%AE%E8%B3%AA%E5%95%8F.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"\u63b2\u984c\u306e\u4ef6\u306b\u3064\u304d\u307e\u3057\u3066\u3001\u73fe\u5728Machine Learning\u3092\u4f7f\u7528\u3057\u3066\u6a5f\u68b0\u5b66\u7fd2\u3092\u884c\u3063\u3066\u3044\u307e\u3059\u3002\n\u305d\u3053\u3067\u8cea\u554f\u306b\u306a\u308b\u306e\u3067\u3059\u304c\u3001\u30c7\u30b6\u30a4\u30ca\u30fc\u6a5f\u80fd\u3092\u4f7f\u7528\u3057\u3066\u5b66\u7fd2\u7d50\u679c\u3092CSV\u3067\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u3057\u3088\u3046\u3068\u3057\u3066\u3044\u308b\u306e\u3067\u3059\u304c\u3001\nExport Data\u30e2\u30c7\u30eb\u3067CSV\u5f62\u5f0f\u306b\u8a2d\u5b9a\u3057\u3066\u3044\u3066\u3082CSV\u3067\u306f\u306a\u3044\u5f62\u5f0f\u3067\u5171\u6709\u305b\u308c\u3066\u3057\u307e\u3046\u306e\u3067\u3059\u304c\u3001\u539f\u56e0\u304c\u308f\u304b\u3089\u306a\u3044\u72b6\u6cc1\u3067\u3059\u3002\n\u3054\u6559\u793a\u306e\u307b\u3069\u3088\u308d\u3057\u304f\u304a\u9858\u3044\u3044\u305f\u3057\u307e\u3059\u3002",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-10T10:15:10.237Z",
                "Answer_score":0,
                "Answer_body":"@63862379 Are you referring to the export data module of the designer from ml.azure.com?\nI think I understand the issue, Are you seeing that the .csv format of file is not listed on the blob storage?\n\nSince the input is a dataframe directory to export module the output format selected should still be the format you selected, in this case CSV. The file name extension only might be missing. You can still open the csv file in excel and it will recognize the delimiters and headers so you can convert it into excel files.\n\nYou can also avoid this by providing the .csv extension in the path itself in export settings and file will be exported as a csv file directly.\n\n\n\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning Web Service returning Internal Server Error",
        "Question_creation_time":1592326778243,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/36823\/azure-machine-learning-web-service-returning-inter.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Getting following error while submitting request to machine learning service. Where can I get more details of this error?\nError Message: An unknown error occurred.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure Percept DK: How to collect network inference performance on a pre-trained model?",
        "Question_creation_time":1631223450427,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/546407\/azure-percept-dk-how-to-collect-network-inference.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Looking for some metric, for example latency in milliseconds, that can represent the inference time of a pre-trained model using the Azure Percept DK.\n\n\n\n\nFor example, I have been training a network or creating a network in TensorFlow and would like to test it on the Azure Percept DK. I would like to see any performance improvements or latency metrics that represent the changes I am making to my network to track inference performance overtime.\n\n\n\n\nIs there any way to get this information from the Percept Devkit? I see telemetry information but this doesn't seem like the performance numbers I am seeking.\n\n\n\n\nIf easier to make an example, is this feature available for any of the pre-trained models supplied with the devkit I can test on to see the model inference performance?\n\n\n\n\nAre there any guides or precedence for collecting network performance on this device? Not looking for the precision\/recall\/mAP percents here, more network latency times.\n\n\n\n\nThanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-10T16:36:07.007Z",
                "Answer_score":0,
                "Answer_body":"Hello @jspdev-6011,\nMy suggestion is that you leverage IoT Edge Azure Monitor Integration -> Collect and transport metrics (Preview)\n\nYou will be able to Add custom metrics (Preview)\n\nGather custom metrics from your IoT Edge modules in addition to the built-in metrics that the system modules provide. The built-in metrics provide great baseline visibility into your deployment health. However, you may require additional information from custom modules to complete the picture. Custom modules can be integrated into your monitoring solution by using the appropriate Prometheus client library to emit metrics. This additional information can enable new views or alerts specialized to your requirements.\n\nLet me know if you have further questions or concerns on implementing this solution?\n\nThanks!\n\nRemember:\n- Please accept an answer if correct. Original posters help the community find answers faster by identifying the correct answer. Here is how.\n- Want a reminder to come back and check responses? Here is how to subscribe to a notification.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"failed to run cuBLAS routine: CUBLAS_STATUS_EXECUTION_FAILED",
        "Question_creation_time":1631128926847,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/544656\/failed-to-run-cublas-routine-cublas-status-executi.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi, I am trying to train a model on AZURE AML A100.\n\nI have trained the same model on my GPU server before with tensorflow_gpu-1.15.5, python 3.7, Gcc 7.5.0, cuDNN 7.6.5 , cuda 10.0\n\nI used a docker file to curated the same env, so I am sure it has tensorflow_gpu-1.15.5, python 3.7, cuDNN 7.6.5 , cuda 10.0. The only thing I am not sure is Gcc 7.5.0.\n\nHowever, I am keeping getting the error message\n\nstart training\n2021-09-08 18:18:21.911226: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n2021-09-08 18:58:09.545333: E tensorflow\/stream_executor\/cuda\/cuda_blas.cc:428] failed to run cuBLAS routine: CUBLAS_STATUS_EXECUTION_FAILED\n2021-09-08 18:58:09.545451: I tensorflow\/stream_executor\/stream.cc:1990] [stream=0x55ae14908d10,impl=0x55ae14907470] did not wait for [stream=0x55ae14908a90,impl=0x55ae149074a0]\n2021-09-08 18:58:09.545478: F tensorflow\/core\/common_runtime\/gpu\/gpu_util.cc:342] CPU->GPU Memcpy failed\n2021-09-08 18:58:09.545528: I tensorflow\/stream_executor\/stream.cc:4938] [stream=0x55ae14908d10,impl=0x55ae14907470] did not memcpy host-to-device; source: 0x7fe9f749b000\n2021-09-08 18:58:09.545529: I tensorflow\/stream_executor\/stream.cc:4938] [stream=0x55ae14908d10,impl=0x55ae14907470] did not memcpy host-to-device; source: 0x7fe9f74a1600\nbash: line 1: 96 Aborted (core dumped) python $AZ_BATCHAI_JOB_TEMP\/azureml\/hydranet_prod_base_tf_1_15_5_1631122651_ba72eb11\/azureml-setup\/context_manager_injector.py \"-i\" \"ProjectPythonPath:context_managers.ProjectPythonPath\" \"-i\" \"Dataset:context_managers.Datasets\" \"-i\" \"RunHistory:context_managers.RunHistory\" \"-i\" \"TrackUserError:context_managers.TrackUserError\" \"-i\" \"UserExceptions:context_managers.UserExceptions\" \"main_aml.py\" \"--note\" \"hydranet_prod_base_tf_1_15_5\" \"--mount_path\" \"DatasetConsumptionConfig:data_folder\" \"--conf\" \"conf\/aml.conf\" \"--job\" \"train\" \"--in_train_feat_path\" \"account_clean_sq_distribution.10.null.feat.jsonl|opportunity_clean_sq_distribution.10.null.feat.jsonl|contact_clean_sq_distribution.10.null.feat.jsonl|lead_clean_sq_distribution.10.null.feat.jsonl|customerprofile_clean_sq_distribution.10.null.feat.jsonl|train.prioritysetexact.account.noise-level-0.feat.jsonl|train.prioritysetexact.opportunity.noise-level-0.feat.jsonl|train.prioritysetexact.contact.noise-level-0.feat.jsonl|train.prioritysetexact.lead.noise-level-0.feat.jsonl\" \"--in_dev_feat_path\" \"measurement.contact.noise-level-0.20201202.feat.jsonl\" \"--in_wikisql_train_feat_path\" \"wikisql.train.noise-level-0.20201202.feat.jsonl\" \"--out_subset_feat_dir\" \"outputs\\\\subset_feat_dir\" \"--in_bert_root_path\" \"DatasetConsumptionConfig:base_model_folder\"\n2021\/09\/08 18:58:11 Skipping parsing control script error. Reason: Error json file doesn't exist. This most likely means that no errors were written to the file. File path: \/mnt\/batch\/tasks\/workitems\/6670d3e3-260e-46c2-bdb4-8fb42942abe0\/job-1\/hydranet_prod_base_t_82b9b21d-3ac5-4f55-a692-5b84119e9daa\/wd\/runTaskLetTask_error.json\n2021\/09\/08 18:58:11 Wrapper cmd failed with err: exit status 134\n2021\/09\/08 18:58:11 Attempt 1 of http call to http:\/\/10.0.0.19:16384\/sendlogstoartifacts\/status\n2021\/09\/08 18:58:11 Send process info logs to master server succeeded\n2021\/09\/08 18:58:11 mpirun version string: {\nmpirun (Open MPI) 3.1.2\nReport bugs to http:\/\/www.open-mpi.org\/community\/help\/\n}\n2021\/09\/08 18:58:11 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 2\nFilteredData: 0.\n2021\/09\/08 18:58:11 Process Exiting with Code: 134\n2021\/09\/08 18:58:11 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n\n\n\n\nI searched the message in the title, and the common solution of adding\n\nconfig = tf.compat.v1.ConfigProto()\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.9\nconfig.gpu_options.allow_growth = True\nconfig.gpu_options.polling_inactive_delay_msecs = 10\nsession = tf.compat.v1.Session(config=config)\n\n\n\n\n\n\n\ndid not work.\n\nOne final idea is that this set-up does not work on RTX 3xxx. However, I am not sure what kind of GPU Azure is using.\n\nCould anyone help? Thank you!!",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Custom computer vision for surface calculations on digital floor maps",
        "Question_creation_time":1631108624923,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/544199\/custom-computer-vision-for-surface-calculations-on.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I am working on a project to calculate surface area from digital floor maps. I am currently experimenting with azure cognitive services - Custom computer vision. However I don't know if this is the right track.\n\nIf possible I would like to use a existent tool instead of reinventing the wheel. Has anyone experience with this and can provide me with some guidance?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-09T19:50:55.323Z",
                "Answer_score":0,
                "Answer_body":"Sure, thanks for clarifying. I agree, an out of box approach would be to use computer vision or custom vision to detect objects and then use the metadata to calculate the surface area. I haven't seen an existing solution using Azure Cognitive services at the moment, so you'd most likely have to use a heuristic approach.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-09-09T02:31:11.82Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. We currently don't have a custom model that supports the above scenario.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-09T10:50:00.087Z",
                "Answer_score":0,
                "Answer_body":"Thanks for answering @GiftA-MSFT . I understand that there isn't a custom model that supports the above scenario. I was just hoping to get some idea's on how to make it work with custom Vision or any alternative.\n\nFor instance I've a gotten a few idea's on how to make it work with custom vision;\n- use object detection to recognize the rectangle\/square shapes of the floor maps.\n- calculate the distance based on the pixels -> leads to surface area ;\n\nThis is just a example .. if this is wrong of there is a better alternative I would love to hear about it.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Need to do a Face detection on rtsp stream using Azure services",
        "Question_creation_time":1631162999540,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/545213\/need-to-do-a-face-detection-on-rtsp-stream-using-a.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"I would like to use some of the Azure service for my project. Idea is to stream encoded video stream (h264), expecting Azure to decode and perform face detection on it in real time. What are the best services to use it.\nOne option I explore is to use computer vision\/face Api with media services, however computed vision API requires image in jpeg\/bif format which requires reencoding of decoding stream, or I need to do screen grab, which I dont want to do as it will increase latency.\nIf there is service which does ML operations on raw frame decoded by media services would help here.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-09T10:28:15.583Z",
                "Answer_score":0,
                "Answer_body":"@SaurabhSinghSengar-7709 The service that offers the capability to enable identification of faces in real time with streaming video is Azure Video Analyzer. It should support HLS and other popular formats, you can take a look at the limitations and quotas from the documentation.\n\nWith computer vision or face API you need to capture the frame or a screen shot and pass the same to the API to get the results.\n\nPlease don't forget to click on  or upvote  button whenever the information provided helps you. Original posters help the community find answers faster by identifying the correct answer. Here is how\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification\n\n\nIf you are interested in joining the VM program and help shape the future of Q&A: Here is how you can be part of Q&A Volunteer Moderators",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-09-09T15:05:35.147Z",
                "Answer_score":0,
                "Answer_body":"In particular, review https:\/\/docs.microsoft.com\/en-us\/azure\/azure-video-analyzer\/video-analyzer-docs\/use-intel-openvino-tutorial that shows you how you can run Intel's face detection model on an RTSP stream.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"reID machine learning inference",
        "Question_creation_time":1631163287910,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/545271\/reid-machine-learning-inference.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I want to do reID operation on a person's face, so that it give me different numerical value for different faces, which can be map to person's identity. I couldn't find any ready to use reID model with Azure, please let me know what is the work involved in it ?\nCan I use some open source reID trained model like caffe\/pytorch and use with some of the Azure service to inference using it.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-09T11:36:39.24Z",
                "Answer_score":0,
                "Answer_body":"@SaurabhSinghSengar-7709 I don't think there is a readymade model that is available from Azure Machine Learning to deploy and infer face ids.\nAzure Face API is the service that offers this scenario where you can pass an image to the API and a face id or a GUID is returned for a face or faces detected in the image.\nThis is a cognitive service offering from Azure which is available in general to public with the exception of using it for police or police departments in the US.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Why is the STANDARD_NC6_PROMO VM slow ?",
        "Question_creation_time":1619490632293,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/372837\/why-is-the-standard-nc6-promo-vm-slow.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Subscription ID : e30f2093-840c-43cf-8aa6-35923b617406\n\nI have created a Machine Learning resource and then uploaded a Jupyter Notebook that I have previously runned in Google Colab.\nIn the Google Colab free GPU my Deep Learning model for Object Localization (Yolov5) runs in a heavier model (Yolov5l.pt for 100 epochs) in 4.5 hours and in Azure my model in its slightest version (Yolov5s.pt) runs for 12 hours and it is only in the half of the process (41 epochs out of 100).\n\nWhy is it so slow ?\n\nWhat can I change to make it faster ?\n\nFYI: In the second image I show you that I have uploaded in this place my training dataset.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-01T09:18:56.213Z",
                "Answer_score":1,
                "Answer_body":"Same problem for me!\n\nThough I have in Jupiter:\nNum GPUs Available: 1\n\nMy tensorflow models are calculating slower than on my local Core i5 PC without any GPU.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-08T14:48:55.657Z",
                "Answer_score":0,
                "Answer_body":"Have you tried looking at the server IOPS? NC6 Promo only supports Standard disks which have an IOPS ceiling of 500.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Why would I need to register a machine learning model with azure endpoint?",
        "Question_creation_time":1630340796540,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/533161\/why-would-i-need-to-register-a-machine-learning-mo.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi,\nIt appears to me that the types of models that can be registered using the azure SDK should come from sklearn, Keras, etc and be converted into a pickle file and after registration, you can send the request to the endpoint.\n\nI can think of a very limited number of cases where you just want to create a backend system that only returns the model prediction. In most cases, the backend of a front end application would take care of all the calculations and sometimes also decide which models to run and maybe combine the results before sending the output to the frontend. For this reason, you might want to implement the complex logic in rest API such as Flask. In this case, why would I call another endpoint from the flask application to run the model, instead of simply loading the pickle file in the flask project?\n\nWhat are the cases where you are registering with Azure endpointst and actually using the endpoints to make a prediction in azure from you trained model? Are you limited to specific libraries to create the pickles? what if you need to process the input before making the predictions?\n\nthanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-31T04:00:08.69Z",
                "Answer_score":0,
                "Answer_body":"Hi, registering a model creates a logical container for the one or more files that make up your model. In addition to the content of the model file itself, a registered model also stores model metadata, including model description, tags, and framework information, that is useful when managing and deploying the model in your workspace. For example, with tags you can categorize your models and apply filters when listing models in your workspace. After registration, you can then download or deploy the registered model and receive all the files and metadata that were registered. The following sample shows how to register a model specifying tags and a description. The following sample shows how to register a model specifying framework, input and output datasets, and resource configuration.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-08-31T19:40:11.04Z",
                "Answer_score":0,
                "Answer_body":"Dear @GifA-MSFT,\nthank you for the answer, however is still not clear to me when would you use it as an alternative to a Rest API:\n\nexample: imagine the following logic: 3 inputs in the request: {isCEO : yes\/no, age: float, location: categorical} if isCEO is yes return null, if isCEO is no return the output of a regression model over the 2 other inputs.\n\n1) One can think of a Flask API that check the isCEO with an if statement and then run or not run a prediction with the pickle file of the regression model.\n2) If I have registered the model in azure what would be the options in this example?\n\n3) you mentioned that registering a model creates a logical container for the one or more file that make up your model? if in the above example the if statement was in a different file, how would you register all the component of the application (the if statement and the regression model)?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-08T08:28:25.54Z",
                "Answer_score":0,
                "Answer_body":"As an example of machine learning components that are needed for a deployed service, they are:\n\nModel files (for example, Pytorch files) that define the implementation of the model You wish to deploy\n\n\n\n\nExecution code runs within the service to analyze inputs and apply the model.\n\nYou can use Azure Machine Learnings to deploy the model and the code to be updated, but the code can remain the same. As we define \"registering the model,\u201d the process of uploading a model separate from code is referred to as that.\n\nYou register a model, and it is uploaded to the cloud (in the default account for your workspace) and then mounted to the same compute where your web service is running.\n\n\n\n\nEnsure that only models that you create or that you obtain from a trustworthy source are used. There have been security vulnerabilities discovered in a number of popular formats for serialized models. It is also possible for models to be intentionally built with the intention of generating inaccurate or biased results.\nIt is important to realize that the computing target you choose to host your model will influence the cost and availability of the endpoint. Choose an appropriate compute target from the table below.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning (AutoML) export data to SharePoint",
        "Question_creation_time":1631064917827,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/543361\/azure-machine-learning-automl-export-data-to-share.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"I am using Azure Machine Learning Studio to design pipelines to analyze data.\nIs there any possibility to export data to sharepoint?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-08T07:07:22.44Z",
                "Answer_score":2,
                "Answer_body":"Hi @MiaZhangWHQWistron-2092\nPer my research, there is no way to export data from Azure Machine Learning Studio to SharePoint directly.\n\nAs an alternative, you could export data to Azure SQL database first:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/export-to-azure-sql-database\n\nThen export data from Azure SQL database to SharePoint list:\nhttps:\/\/social.technet.microsoft.com\/wiki\/contents\/articles\/39170.azure-sql-db-with-sharepoint-online-as-external-list-using-business-connectivity-services.aspx\n\n\nIf an Answer is helpful, please click \"Accept Answer\" and upvote it.\n\nNote: Please follow the steps in our documentation to enable e-mail notifications if you want to receive the related email notification for this thread.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Hiding secrets in raw JSON [AML]",
        "Question_creation_time":1631001392253,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/542247\/hiding-secrets-in-raw-json-aml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"On AML in the RUN View you can see firstly the command which was run on AML and the \"Raw JSON\" which displays the whole runDefinition and more.\nWe want to do something as described here https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-github-actions-machine-learning?McasTsid=28375 but without waiting for the results. This means that the RUN has to have credentials to push the trained model to some location.\n\nThis is an issue as we currently can not restrict access or mask secrets in the \"Raw JSON\". The command section in the Run view contains the same issue as this section can contain secrets too.\n\nWe use https:\/\/docs.microsoft.com\/en-us\/cli\/azure\/ml\/job?view=azure-cli-latest to create a Run, but the issue would be the same if any other method would be used to trigger a Run.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure Machine Learning Exit Code 143",
        "Question_creation_time":1631037752020,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/543071\/azure-machine-learning-exit-code-143.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi There,\nI am running a very simple pipeline that contains a dataset and a SQL transformation task. When i run the two tasks i get an error : 2021\/09\/07 17:49:47 Wrapper cmd failed with err: exit status 143 which i can't seem to find anywhere. I am running a compute VM DS1.\nany direction?\nThanks,",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-07T18:40:59.28Z",
                "Answer_score":1,
                "Answer_body":"Incase anyone is wondering, you must increase the compute with more memory to avoid this...",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How to resolve error - Creating conda environment failed with exit code: 1?",
        "Question_creation_time":1629557858217,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/522968\/how-to-resolve-error-creating-conda-environment-fa.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":1,
        "Question_body":"I am getting this error when I run script job_submit.py. I do not know how to debug this issue, would appreciate help to solve this.\n\n\n\n\nPS: I have just started learning azure so I am not sure what I am missing.\n\n\n\n\nscript_to_run.py\nfrom azureml.core import Workspace, Dataset, Run\nws = Workspace.from_config()\naz_dataset = Dataset.get_by_name(workspace=ws, name='titanic-dataset')\n# Get the context of the experiment\nnew_run = Run.get_context()\ndf = az_dataset.to_pandas_dataframe()\n### count the observations\ntotal_obs = len(df)\n### get the gender count\ngender_count = df['Sex'].value_counts()\n# log the metrics to workspace\nnew_run.log(name = \"Total observations\", value = total_obs)\n### Log the gender data values\nfor val in df['Sex'].unique():\n    new_run.log(name = val, value = gender_count[val])\n# complete an experiment run\nnew_run.complete()\n\n\n\njob_submit.py\nfrom azureml.core import Workspace, Datastore, Dataset, Experiment, ScriptRunConfig, Environment\n# Access workspace\nws = Workspace.from_config()\n# create an experiment object\nexp = Experiment(workspace=ws, name = \"Titanic_exp\")\n# create custom env - myenv\nmyenv = Environment(name = 'MyEnvironment')\n# to install dependencies\nfrom azureml.core.environment import CondaDependencies\n# from CondaDependencies class we need to create an object which will have all the required dependencies\n# create the dependencies object\npackages = CondaDependencies.create(conda_packages=['pandas', 'scikit-learn']) # this will have list of all packages we will need\nmyenv.python.conda_dependencies = packages # this will tell to install the packages\n# register environment to workspace so that we have access to it\nmyenv.register(ws)\n# create a script configuration for custom env\nscript_config = ScriptRunConfig(source_directory = '.', script = \"script_to_run.py\", environment = myenv)\nnew_run = exp.submit(config = script_config)",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-24T01:12:50.137Z",
                "Answer_score":0,
                "Answer_body":"Hi @ramr-msft thanks for replying.\nI am following this link to learn azureml: 4-azure-ml-experiment\n\nI did the following steps:\n1. Created the workspace, downloaded the config.json file and uploaded it in the .azureml folder created by me.\n2. I was able to successfully run this script using experiment.start_logging() function as given in the module. \n3. The problem comes when i try to run the script as an experiment using Run.get_context()125769-60-control-log.txt\n\n4. I am attaching the 60_control_log.txt for reference.\n\nPlease let me know if this answers your question and helps you to figure out the issue.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-07T11:52:30.913Z",
                "Answer_score":0,
                "Answer_body":"Hey, I was having the same issue. resolved in two steps, however i think you can skip step 1\n\nstep 1 (not sure if this actually had any impact but did not retest with default setup)\nI have modified the environment.yml fiIe and specified a python version as 3.8.10\n\n\nstep 2 (I think this did the trick)\nCreated new compute instance and rerun\n\nHope same works for you",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Deployemnt Time out error in AKS and Endpoint stuck in \"Transitioning\" state.",
        "Question_creation_time":1630906705210,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/540740\/deployemnt-time-out-error-in-aks-and-endpoint-stuc.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":17,
        "Question_score":1,
        "Question_body":"Working on the deployment of 170 ML models using ML studio and azure Kubernetes service which is referred on the below doc link \"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/machine-learning\/how-to-deploy-azure-kubernetes-service.md\".\n\nWe are training the model using python script with the custom environment and we are registering the ml model on the Azure ML services. Once we register the mode we are deploying it on the AKS by using the container images.\n\nWhile deploying the ML model we are able to deploy up to 10 to 11 models per pod for each Node in AKS. When we try to deploy the model on the same node we are getting deployment timeout error and we are getting the below error message.\n\n\n\n\nFor deploying the model in Azure Kubernetes Service using python language with below sample code.\n\n\n\n  #  Create an environment and add conda dependencies to it and for this creating our environment and building the custom container image.\n         myenv = Environment(name = Deployment_name)\n         myenv.python.conda_dependencies = CondaDependencies.create(pip_packages)\n        \n            \n     #  Inference_Conifiguration\n         inf_config = InferenceConfig(environment= myenv, entry_script='.\/Script_file.py')\n        \n        \n     # Deployment_Conifiguration\n         deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1, cpu_cores_limit = 2, memory_gb_limit = 2, traffic_percentile = 10)\n        \n     #  AKS cluster compute target \n         aks_target = ComputeTarget(ws, 'pipeline')\n           \n        \n    #  Deploying the model in AKS server\n           service = Model.deploy(ws, Deployment_name, model_1, inf_config,\n                       deployment_config, aks_target, overwrite=True)\n        \n            service.wait_for_deployment(show_output=True)\n\n\n\nWe also checked on the azure documentation and we could able to find any configuration or deployment setup for aks nodes.\n\n\n\n\nCan you please provide us more clarification regarding \"The number of models to be deployed is limited to 1,000 models per deployment (per container)\" and Can you please give insight\/feedback on how to increase the number of ml models that can be deployed in each node in Azure Kubernetes Service? Thanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-06T18:02:32.08Z",
                "Answer_score":1,
                "Answer_body":"Hello @DanMarculescu-1199 ,\nCan you kindly take a look at the similar post which was answered with relevant documentation .\nhttps:\/\/docs.microsoft.com\/en-us\/answers\/questions\/540001\/how-many-models-can-be-deployed-in-single-node-in.html\n\nLet us know if that helps !\n\nRegards,\nShiva.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"What is the best way to deploy my machine learning model using GPUs, specifically as a web based API?",
        "Question_creation_time":1630916125883,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/541074\/what-is-a-the-best-way-to-deploy-my-machine-learni.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"I am trying to find the best way to run my machine learning models on GPUs for inference as an http request. Do Azure functions support GPUs? if not, what are other options I can look into?\n\nnote: I also want to use packaged models, not necessarily ones of my own creation (such as easyOCR for python)",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-06T09:42:39.623Z",
                "Answer_score":1,
                "Answer_body":"Hi,\n\nIf you need GPU support on ML inference the only supported option is the Azure Kubernetes Service as stated in this documentation\n\nFor guidance on deploying an ML model to AKS, please refer to this documenation on deploying to AKS",
                "Answer_comment_count":4,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Question on Azure Features and Limitations for Free and Paid Version",
        "Question_creation_time":1630749021297,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/539984\/question-on-azure-features-and-limitations-for-fre.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\n\nI am a student from University of Wollonggong Malaysia KDU Penang. I am planning to do a final year project that utilises machine learning to perform image and handwriting recognition using cloud computing. Therefore I would like to understand if there are related products that are provided on Azure. For the free tier and\/or Azure for student, what are the available product(s) that may satisfy my project requirements and what are its limitations. Similarly for the paid version, what additional features are provided and how are the pricings calculated?\n\nThank you",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-04T10:37:07.907Z",
                "Answer_score":0,
                "Answer_body":"Hello @TANFANGSHEENUOWMKDU-6628 !\n\n\n\n\nYou can refer to the below mentioned topics to know about the Limitations of Free , Pay as You Go and Student Package of Azure.\n\nStudents Offering :-\nhttps:\/\/azure.microsoft.com\/en-us\/free\/students\/\n\nAzure Pay as You Go :-\nhttps:\/\/azure.microsoft.com\/en-in\/pricing\/purchase-options\/pay-as-you-go\/\n\nAzure Free :-\nhttps:\/\/azure.microsoft.com\/en-in\/free\/\n\nAzure subscription and service limits, quotas, and constraints :-\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/azure-resource-manager\/management\/azure-subscription-service-limits\n\n\n\n\n\n\n\nIf the response is helpful, please click \"Accept Answer\" and upvote it.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Collaborate on Azure Machine Learning Project",
        "Question_creation_time":1596973683450,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/62694\/collaborate-on-azure-machine-learning-project.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":2,
        "Question_score":0,
        "Question_body":"I just recently became a Microsoft Certified Azure Data Scientist Associate. So I am looking for data scientist novices to join me practice on open datasets on kaggle to build machine learning models and do predictions using Azure ML. We will start with Titanic competition. If interested please visit my github link: https:\/\/github.com\/ivombi\/Titanic-Machine-Learning-from-Disaster or send a request on LinkedIn using my full name: Kubam Ivo Mbi.\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-10T07:33:44.81Z",
                "Answer_score":0,
                "Answer_body":"anonymous user Thanks, Here are the Azure machine learning notebook samples that you can participate and contribute on the same.\n\nOther links for ML competitions i.e., kaggle and driven data to work with the same. can you please add more details about the use-case that you are trying. Are you looking for data scientist resources, If yes below links will be helpful to work with the teams.\n\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\n\nhttps:\/\/www.drivendata.org\/competitions\/\nhttps:\/\/www.kaggle.com\/",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-09-05T01:03:19.383Z",
                "Answer_score":0,
                "Answer_body":"Hi, I am very interested in collaborating on this, could you reach out to me via email at piusanalyticsandbeyond@gmail.com?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"how many models can be deployed in single node in azure kubernetes service?",
        "Question_creation_time":1630746472547,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/540001\/how-many-models-can-be-deployed-in-single-node-in.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"Working on deployment of 170 ml models using ML studio and azure Kubernetes service which is referred on the below doc link \"https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/machine-learning\/how-to-deploy-azure-kubernetes-service.md\".\n\nWe are training the model using python script with the custom environment and we are registering the ml model on the Azure ML services. Once we register the mode we are deploying it on the AKS by using the container images.\n\nWhile deploying the ML model we are able to deploy up 10 to 11 models per pods for each Node in AKS. When we try to deploy the model on the same node we are getting deployment timeout error and we are getting the below error message.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-04T12:32:05.4Z",
                "Answer_score":0,
                "Answer_body":"Hi @suvedharan-5910\n\nThe number of models to be deployed is limited to 1,000 models per deployment (per container).\n\nAutoscaling for Azure ML model deployments is azureml-fe, which is a smart request router. Since all inference requests go through it, it has the necessary data to automatically scale the deployed model(s).\nmore details\n\n\n\n\n\nIf the Answer is helpful, please click Accept Answer and up-vote, so that it can help others in the community looking for help on similar topics.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Apply SQL Transformation Error : Failed when create table error 1000",
        "Question_creation_time":1629294395873,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/518856\/apply-sql-transformation-error-failed-when-create.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I connected 2 tables to \"Apply SQL Transformation\" box and when i ran the code the following error appears (screenshots attached). csv files downloaded from web for i have shared link below.\n\nLink 1 : https:\/\/docs.google.com\/spreadsheets\/d\/1aeZllwICUG7Q_rEgtNm4zj9pVV4iJaND6uUbou0qOp8\/pub?gid=873193374&single=true&output=csv\nLink 2 : https:\/\/docs.google.com\/spreadsheets\/d\/1xnMNKqB2tCdOecXt3WWjIUxbAk5rrvbYfbJLrfzFrjc\/pub?gid=1144892773&single=true&output=csv\n\nError details : requestId = cf031a39f0684e2786d1fb4768c898ce errorComponent=Module. taskStatusCode=400. {\"Exception\":{\"ErrorId\":\"LibraryException\",\"ErrorCode\":\"1000\",\"ExceptionType\":\"ModuleException\",\"Message\":\"Error 1000: SQLiteQueryRunner Library library exception: Failed when create table: \",\"Exception\":{\"Library\":\"SQLiteQueryRunner Library\",\"ErrorId\":\"SQLiteCreateTableFailed\",\"ErrorCode\":\"3\",\"ExceptionType\":\"LibraryException\",\"Message\":\"Failed when create table: \",\"Exception\":{\"ExceptionType\":\"Exception\",\"Message\":\"SQL logic error or missing database\\r\\nunrecognized token: \\\"\\\"PK\\u0003\\u0004\\u0014\\\"\"}}}}Error: Error 1000: SQLiteQueryRunner Library library exception: Failed when create table: Process exited with error code -2\n\n\n\n\nVery much appreciate it if someone could explain the way out since i am new to Azure ML.\n\nSQL query that i used is provided below\n\nselect title_year, movie_title, category, Won?\nfrom t1, t2\nwhere t1.movie_title = t2.Nominee\nand Won? = \"YES\"\norder by title_year desc",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-02T16:34:34.933Z",
                "Answer_score":0,
                "Answer_body":"Hello @JahnaviHCQSQ-9723\n\nSorry I can miss your message. The \"?\" is not working well in SQL, and you also need a \";\" by the end of your query.\n\nThis works for me well:\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Model Predicted results vary if data is fed from sql trasnformation block",
        "Question_creation_time":1629196292650,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/517122\/model-predicted-results-vary-if-data-is-fed-from-s.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi,\nI created a model to read training and testing data from 2 respective cosmos db tables and used an sql transformation block to rename the column names and used it for training and in score model as shown in snapshot (modela.jpg) . The Predicted parameter (scored label) is very much different and incorrect (refer onlysqltrans.jpg)\nWhen I use a \"convert to csv\" block connected to output of sql transformation block (refer modelb.jpg for model diagram ) and then use it in training , I get expected results ( refer withcsvblock.jpg) .\nThe Mean Absolute error in first case was 51.2 while in modelb was only 0.09\n\nI used a convert to dataset block after sql transform block and used that to connect to training model\nbut that too gave the same result as modela output\n\nIn case you want to see what sql transformation i used\n\n\n\n\n   select  \"['CombiTimeTable.y[1]']\" as av1 ,\"['CombiTimeTable.y[2]']\" as av2,\"['CombiTimeTable.y[3]']\" as av3,\"['CombiTimeTable.y[4]']\" as av4,\"['CombiTimeTable.y[5]']\" as av5,\"['CombiTimeTable.y[6]']\" as av6,\"['CombiTimeTable.y[7]']\" as av7,\"['CombiTimeTable.y[8]']\" as av8,\"['CombiTimeTable.y[9]']\"  as av9 from t1\n\n\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-02T15:40:14.457Z",
                "Answer_score":0,
                "Answer_body":"@HCLAZURECloudConnectedECOSystems-0579\n\nUpdate for this thread, this issue has been forwarded to product team, I will let you know any news I get from them back. Thanks for the feedback again.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"ValidationException: The data points should have at least 50 rows for a valid regression or classification task with cv 5.",
        "Question_creation_time":1629986755287,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/529189\/validationexception-the-data-points-should-have-at.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I am trying to run a autoML model as follows:\n\nautoml_settings = {\n\"n_cross_validations\": 5\n}\n\nautoml_config = AutoMLConfig(task = 'regression',\ncompute_target = compute_target,\ntraining_data = train_data.filter(train_data['location']==l),\nlabel_column_name = label,\n**automl_settings)\n\nremote_run = experiment.submit(automl_config, show_output=True)\n\nAnd I get: ValidationException: The data points should have at least 50 rows for a valid regression or classification task with cv 5.\n\nThe data has more than 250 rows. Moreover, when I changed the cv number, nothing changed. Does anybody have any idea what might be happening?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-02T08:54:47.363Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nHope you have solved this issue. If you are still blocked by this, please feel free to let us know. We can either investigate deeper if we can have more details, or we can help you to enable a support ticket if you do not have a support plan. Thanks.\n\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"why the ML data only result in 1 point?",
        "Question_creation_time":1629379772053,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/520581\/why-the-ml-data-only-result-in-1-point.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-02T08:43:51.05Z",
                "Answer_score":0,
                "Answer_body":"\u60a8\u597d\uff0c\n\n\u611f\u8c22\u60a8\u8054\u7cfb\u5fae\u8f6fAzure\u8bba\u575b\uff0c\u6211\u8bd5\u56fe\u91cd\u590d\u60a8\u6240\u8bf4\u7684bug\uff0c\u4f46\u662f\u5e76\u4e0d\u80fd\u5f97\u5230\u4efb\u4f55\u201c1 point\u201d\u7684\u7ed3\u679c\u3002\u5982\u679c\u60a8\u4ecd\u6709\u8fd9\u4e2a\u95ee\u9898\uff0c\u8bf7\u63d0\u4f9b\u66f4\u591a\u8be6\u60c5\uff0c\u6211\u4eec\u4f1a\u5c3d\u53ef\u80fd\u63d0\u4f9b\u6700\u5927\u5e2e\u52a9\u3002\n\n\u8c22\u8c22\u60a8\u3002\n\n\u5b87\u5f64",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"pipelines stuck on preparing stage forever.",
        "Question_creation_time":1630478522800,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/535410\/pipelines-stuck-on-preparing-stage-forever.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":21,
        "Question_score":0,
        "Question_body":"Unable to execute pipelines on the STANDARD_D16S_V3. It is stuck on the prepare stage forever. But the same pipeline executed without trouble 2 weeks ago.\nAlso now AutoML are stuck on 'Not Started' stage.\nThe compute instances and compute clusters were again recreated, just to ensure if there were some issues with our previous computes. We have faced the issue where suddenly the computes have slowed down but this time they just dont get ahead of the prepare stage.\nTo be noted, this occurs only in case of pipelines and automl.\nAt the same time we are getting billed for the compute resources.\nWhat can be possibly wrong here?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Using Azure ML Studio Designer with R script: package not found but I installed it on the compute instance",
        "Question_creation_time":1630452066907,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/535094\/using-azure-ml-studio-designer-with-r-script-packa.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I created a compute instance and then I installed all the necessary R packages to execute a few scripts. The scripts run without issue when I'm inside an RStudio instance on that compute instance. However, when I try to have those scripts run through the Designer service using the same compute instance, R no longer recognizes the packages as being installed. Is there a way for Designer to recognize the installed R packages without resorting to using a Docker image, or the zip file method from the stackoverflow question linked below?\n\nhttps:\/\/stackoverflow.com\/questions\/40632047\/azure-ml-studio-cannot-load-a-installed-package-in-r",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Drifting Sample in azure machine learning studio does not finish backfill",
        "Question_creation_time":1630488394320,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/535756\/drifting-sample-in-azure-machine-learning-studio-d.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I am trying to run the sample tutorial on data\/model drifting in azure machine learning samples. When I run the backfill command is waiting for the target cluster in the queue and it does not start, after waiting for a very long time.\n\nIs it a common issue? How to run the example? I thought was a question of simply run it .. but it does not finish the run..",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-01T20:33:51.383Z",
                "Answer_score":0,
                "Answer_body":"Hi, you need to first clone the Azure ML Samples, then you'll be able to run the notebook from Files tab:\n\n\n\n\n\n\n\nGo to Files tab and open the notebook:",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"The standard d16_v3 is extremely slow",
        "Question_creation_time":1629815195147,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/526081\/the-standard-d16-v3-is-extremely-slow.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"d16_v3 compute instance takes forever just for a simple preprocessing of a 4 GB chunk size of tabular data from the azure blob storage. This action is executed by a pipeline here and it is stuck on the preparing stage for a long time. ~2 weeks the pipeline was through within an hour.\n\nwhat could possibly go wrong here?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-09-01T15:33:24.437Z",
                "Answer_score":0,
                "Answer_body":"@AntaraDas-4298 Thanks for the feedback again. Product team has received this report, will do proper investigation and fixing.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"[Bug] azureml-train Python package deprecated but did receive an update which is not in line with azureml-train-core",
        "Question_creation_time":1629973035930,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/528959\/bug-azureml-train-python-package-deprecated-but-di.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"The Python package azureml-train is deprecated and seems basically a wrapper around azureml-train-core. When installing azureml-train, if I'm correct it tries to install the azureml-train-core package with the same version number. However, on the 24th of August 2021 the azureml-train package was updated to version 1.33.1 whereas azureml-train-core wasn't updated. This causes the installation of azureml-train to fail.\n\nI would suggest to remove version 1.33.1 of azureml-train such that it still can be installed.\nOtherwise, I'm curious why this situation is the case.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-26T12:35:40.733Z",
                "Answer_score":1,
                "Answer_body":"@SjoerdGn-2530 Yes, this is a bug in the release cycle that was pushed to pypi, This also caused other packages to get updated.\n\nhttps:\/\/pypi.org\/project\/azureml-train-automl-runtime\/1.33.1.post1\/\nhttps:\/\/pypi.org\/project\/azureml-train-automl\/1.33.1\/\n\nazureml-sdk 1.33.0.post1 is released now to ensure the correct versions are installed with the SDK. As you mentioned above azureml-train 1.33.1 is not required and can be removed.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Can't deploy a real time endpoint in azure Auto ML",
        "Question_creation_time":1628186151087,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/503097\/can39t-deploy-a-real-time-endpoint-in-azure-auto-m.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I've trained a model using Auto ML and I want to try to deploy it to a Kubernetes service, I've got a pretty simple inference cluster. But no matter how low I set the CPU and memory reserve capacity it always says there isn't enough resources to deploy. Do I need to upgrade my cluster or is this a known issue with a current solution? It seems to me to be quite random as other times I was able to deploy other models with no problems at all. And even if I try to deploy it as a container instance it gets stuck in transitioning state indefinetely . Hope someone might clarify this issue and propose some kind of workaround.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-10T16:10:32.567Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for the details, I just found a same issue for this abnormal computer resource issue. The solution of the customer isrewriting all the code in Python and using the AKSWebService.update_endpoint method to update the endpoint without having to delete it each time (which was happening using the Model.deploy method).\n\nhttps:\/\/docs.microsoft.com\/en-us\/answers\/questions\/249335\/azure-machine-learning-update-realtime-endpoint.html\n\nCould you please take a look and have a try?\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Problems with Azure ML Designer",
        "Question_creation_time":1630234227267,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/531796\/problems-with-azure-ml-designer.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I am trying to follow Learning Path Create a Classification Model with Azure Machine Learning Designer.\n\nThere are some problems that I faced. I use latest version of Chromium for this.\nWhen I hit submit, the process gets stuck to queued unless I refresh the page.\nAfter submit, the database I selected get replaced with an empty dataset.\n* Maximising and minimising window or changing screen size also had a bad effect on the save. Although I save the pipeline, its name gets back to default when I leave full screen or enter full screen.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-31T02:40:07.427Z",
                "Answer_score":0,
                "Answer_body":"@devkapilbansal Thanks for the question. Please share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/samples-designer",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is it possible to change the scoring URI in ML Service deployment",
        "Question_creation_time":1630356655677,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/533289\/is-it-possible-to-change-the-scoring-uri-in-ml-ser.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\n\nI'm trying to deploy a model as an endpoint in azure ML Studio. model.deploy call returns service which has a scoring_uri. I'm wondering if it is possible to change the scoring_uri from \/score to something else more appropriate. Or potentially register multiple of the uri's under the same FQDN like \/score, \/test, \/retrain under same principal guid service name.\n\ninference_config = InferenceConfig(entry_script=ENTRY_SCRIPT, environment=keras_env)\naci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n\nservice = Model.deploy(workspace=ws,\nname=SERVICE_NAME,\nmodels=[model],\ninference_config=inference_config,\ndeployment_config=aci_config,\noverwrite=True)\nservice.wait_for_deployment(show_output=True)\n\nuri = service.scoring_uri\n\nhttp:\/\/XXXXXXXX-XXXX-4000-XXXX-aa1a5e7XXXXX.westus2.azurecontainer.io\/score\n\nCan we change the last part from \/score to something else? like \/test or register multiple endpoints.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-31T04:25:11.45Z",
                "Answer_score":0,
                "Answer_body":"Hi, you cannot modify the web service uri.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error during Experiment run",
        "Question_creation_time":1628072461983,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/501299\/error-during-experiment-run.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I am getting the following error after trying to submit my experiment in the Azure ML workspace:\n\nazureml-logs\/60_control_log.txt\n\nWARNING conda.gateways.disk.delete:unlink_or_rename_to_trash(143): Could not remove or rename \/anaconda\/pkgs\/zlib-1.2.11-h7b6447c_3\/lib\/libz.so.1.2.11. Please remove this file manually (you may need to reboot to free file handles)\n\nWhat is the cause for this problem?\n\nDo I need to manually remove this files?\n\nThanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-04T14:11:37.913Z",
                "Answer_score":0,
                "Answer_body":"@SoonJooGenting-3682 Thanks for the question. Can you please share the steps that you performed and also share the sample. Please share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue from the back-end? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Pulling ML Models from MLFLow in a VM in Azure to the VM that Pipeline Runs",
        "Question_creation_time":1629093489833,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/514806\/pulling-ml-models-from-mlflow-in-a-vm-in-azure-to.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"We have a pipeline in a repo in Azure Devops for evaluating ML model performances after each commit. Currently models are manually put into repo. We also have a MLFlow server in a VM in Azure, so instead of putting models manually into the repo we want to pull models from MLFlow which also resides in a Azure VM into the VM that pipeline runs. Is there a way to accomplish this by using service connections or something?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-17T01:46:49.143Z",
                "Answer_score":1,
                "Answer_body":"@KarahanTolgaAVLTR-6434 Thanks for the question. Can you please add more details about the Model packaging and deploy steps that you performed. We have forwarded to the product team to check on this.\n\nYou can find the Azure ML + MLflow examples here: https:\/\/github.com\/Azure\/MachineLearningNotebooks\/tree\/master\/how-to-use-azureml\/track-and-monitor-experiments\/using-mlflow",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Designer python script to save Dataset data as csv to compute instance directories",
        "Question_creation_time":1630351702510,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/533352\/designer-python-script-to-save-dataset-data-as-csv.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I have a set of custom Python and R scripts to execute a machine learning pipeline for analysis purposes. The steps are as follows:\n\nWith Python, Convert Datastore data to csv that gets saved in the compute instance directory\n\n\nWith R, pull in the csv data and run some feature engineering, build a machine learning model, and save scoring data to directory as csv\n\n\nPush csv data back to Datastore\n\nThe first issue I'm encountering in Designer is the first step, saving Datastore data as csv to the compute instance directory. I created a function called azureml_main() that internally pulls in the Datastore data and saves it as csv to the directory. I have run the code that's inside the function a bunch of times but when I try to have it run in the Python script node in Designer it fails.\n\nError message:\n\nAmlExceptionMessage:User program failed with FailedToEvaluateScriptError: The following error occurred during script evaluation, please view the output log for more information:\n---------- Start of error message from Python interpreter ----------\nGot exception when invoking script at line 22 in function azureml_main: 'AuthenticationException: Unknown error occurred during authentication. Error detail: Unexpected polling state code_expired'.\n---------- End of error message from Python interpreter ----------\n\nModuleExceptionMessage:FailedToEvaluateScript: The following error occurred during script evaluation, please view the output log for more information:\n---------- Start of error message from Python interpreter ----------\nGot exception when invoking script at line 22 in function azureml_main: 'AuthenticationException: Unknown error occurred during authentication. Error detail: Unexpected polling state code_expired'.\n---------- End of error message from Python interpreter ----------\n\n\n\n\n\/\/ Python script inside Python node in Designer.\n\/\/ The script MUST contain a function named azureml_main\n\/\/ which is the entry point for this module.\n\nimport pandas as pd\n\n\/\/ The entry point function MUST have two input arguments.\n\/\/ If the input port is not connected, the corresponding\n\/\/ dataframe argument will be None.\n\/\/ Param<dataframe1>: a pandas.DataFrame\n\/\/ Param<dataframe2>: a pandas.DataFrame\n\ndef azureml_main(dataframe1 = None, dataframe2 = None):\n    # Azure management\n    from azureml.core import Workspace, Dataset\n    # MetaData\n    subscription_id = '09b5fdb3-165d-4e2b-8ca0-34f998d176d5'\n    resource_group = 'xCloudData'\n    workspace_name = 'xCloudML'\n    # Create workspace \n    workspace = Workspace(subscription_id, resource_group, workspace_name)\n    # 1. Retention_Engagement_CombinedData\n    dataset = Dataset.get_by_name(workspace, name='retention-engagement-combineddata')\n    # Save data to file\n    df = dataset.to_pandas_dataframe()\n    df.to_csv('\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/v-aantico1\/code\/RetentionEngagement_CombinedData.csv')\n    # 2. TitleNameJoin\n    dataset = Dataset.get_by_name(workspace, name='TitleForJoiningInR')\n    # Save data to file\n    df = dataset.to_pandas_dataframe()\n    df.to_csv('\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/v-aantico1\/code\/TitleNameJoin.csv')\nazureml_main()",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-30T22:02:22.097Z",
                "Answer_score":1,
                "Answer_body":"Hi, thanks for reaching out. There's no need to re-authenticate inside the Execute Python Script module, instead include the following:\n\n     from azureml.core import Run\n     run = Run.get_context(allow_offline=True)\n     #access to current workspace\n     ws = run.experiment.workspace\n\n\n\nHope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Deployment failed - InternalServerError",
        "Question_creation_time":1630015001840,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/529757\/deployment-failed-internalservererror.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":13,
        "Question_score":1,
        "Question_body":"Hello,\n\nI just created a free Azure account. I want to create an an Azure Machine Learning workspace (create a resource), but it seems that the the deployment fails. I receive the following error:\n\n\"code\": \"InternalServerError\",\n\"message\": \"Received 400 from a service request\"\n\nWhat should I do?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-27T08:22:12.05Z",
                "Answer_score":0,
                "Answer_body":"@ArminNajarpourForoushani-0656 Which region did you try to create this resource? Usually, such errors could occur due to some intermittent issues.\nIf this is a free account without any usage the creation of workspace should be successful. I would request to try the same with a different region maybe eastus and check if it is successful.",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ml model with power virtual agents.",
        "Question_creation_time":1630294796910,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/532187\/azure-ml-model-with-power-virtual-agents.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"can anyone help me how to integrate Azure ML model with power virtual agents and publish it in team's...\n\nThank's in advance\n\nwaiting for reply:)",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Not able to see azureml python virtual env in VSCode",
        "Question_creation_time":1627995036793,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/499892\/not-able-to-see-azureml-python-virtual-env-in-vsco.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"I created a python virtual environment in Azure ML compute instance and have linked my VSCode with the compute instance but I am not able to access that virtual environment.\nIs it something I am missing?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-04T11:41:58.457Z",
                "Answer_score":0,
                "Answer_body":"@JitenderKumarChandel-7567 Thanks for the question. Can you please add more details about the error that you are facing, also share the steps that you performed.\nPlease follow the document to setup dev environment.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning Pipeline Step started to fail with no apparent reason.",
        "Question_creation_time":1630021622550,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/529730\/azure-machine-learning-pipeline-step-started-to-fa.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"The PythonScript steps, which consume only PipelineData started to fail with no apparent reason. No changes were made to any of the step scripts or pipeline building scripts, but newly built pipelines fail with the same error in the same place. There is no such problem with resubmitting the same pipeline created a couple of days ago. Is it somehow connected to the recent AML update?\n\nthe 70_driver_log.txt contents are:\n\n [2021-08-26T22:36:12.024855] After variable expansion, calling script [preprocess\/EvaluateStage1Models.py] with arguments: **...**\n bash: line 1:   111 Illegal instruction     (core dumped) \/azureml-envs\/azureml_**...**\n\n\n\n\n\nRunIDs:\n1) 70a1ec8a-ab32-48da-8aa8-077a03839cb7 - newly made one (failed)\n2) 6649f74f-54be-4ede-8f01-23fe1de78eb9 - old resubmitted one (ok)",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Custom Vision for student",
        "Question_creation_time":1630134876857,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/531378\/custom-vision-for-student.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I registered Microsoft Azure with student account for senior project in my university and I wonder how long that I can use Custom Vision (1month or 1 year)?, I would like to know the algorithm inside the Custom Vision for object detection?, which domain is good for the big model for object detection, and can I export the project to share with my friend to label pictures in project?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-28T08:33:39.62Z",
                "Answer_score":0,
                "Answer_body":"Hi @THITITHITINUNSOMBOON-5939 ,\n\nthe details can be found here: https:\/\/azure.microsoft.com\/en-us\/free\/students\/\n\nTechnical details for Azure Custom Vision you can find here: https:\/\/docs.microsoft.com\/en-us\/azure\/cognitive-services\/custom-vision-service\/overview\n\n(If the reply was helpful please don't forget to upvote and\/or accept as answer, thank you)\n\nRegards\nAndreas Baumgarten",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"why is spanish not showing in preprocess text module in Azure ML designer?",
        "Question_creation_time":1630021974807,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/529798\/why-is-spanish-not-showing-in-preprocess-text-modu.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi everyone,\n\nI'm migrating a NPL model created in ML Studio (classic) to Azure ML designer. When I try to configure the language in the Preprocess Text module the list only displays English.\n\nIs Spanish available for this module? Or is there a way to enable more languages that include spanish.\n\nThanks in advance for a solution\/answer",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-27T09:14:28.337Z",
                "Answer_score":0,
                "Answer_body":"@BenjaminKutz-0870 This module only supports English. Please refer the documentation of the module here.\nWe will check with the team internally to confirm if there is a roadmap to extend this to other languages. Thanks!!",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-08-27T20:02:04.14Z",
                "Answer_score":1,
                "Answer_body":"Thanks, I wasn't sure with the specification un the module documentation. I hope the team is considering extending this module to spanish in orden for us to succesfully migrate our models from Machine Learning Studio (classic) which has the same module with spanish.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to apply activation functions in Azure Machine Learning studio",
        "Question_creation_time":1629883772423,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/527245\/how-to-apply-activation-functions-in-azure-machine.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":1,
        "Question_body":"I want to be able to apply activation functions in pipeline flow in Azure Mazhine Learning. According to every documentation and Q&A there should be the option of selecting Hidden layer specification: Define a custom architecture. but as you can see in the image below there is only one option in the drop down menu.\n\n\n\n\n\nWhat do I need to do to get more options, and if there are none why have a drop down menu?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-25T10:09:47.583Z",
                "Answer_score":1,
                "Answer_body":"@johan-1005 I believe this is a gap in new Azure ML designer studio. The documentation mentions the creation of custom architecture for neural network but the implementation is missing in the Azure ML studio ml.azure.com\n\nThis may be because the previous version of the studio https:\/\/studio.azureml.net has this option but it is not ported to the new designer studio. I will check internally if they intend to port this feature or if the documentation needs to be updated to remove this section. Thanks for spotting this.\n\nThe options in the previous version of studio.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"cant Connect API Managment request to R file",
        "Question_creation_time":1628743828770,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/510811\/cant-connect-api-managment-request-ro-r-file.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hi team,\n\nWe are having .net web api which is hosted to Azure iaas sever now we have have moved that to Azure pass with apim. Api pass the request to r server and get the details.\n\nHow we can move r files from iaas to pass and connect with APIM in Azure as we don't want to use any iaas server.\n\nWe have tried with Machine learning but not getting any solution.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Move R file from on Premise to Pass Services and connect APIM to R file",
        "Question_creation_time":1628744989137,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/510695\/move-r-file-from-on-premise-to-pass-services-and-c.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"Hi All,\n\nI am having .Net web API which is hosted to Azure IAAS sever now we have have moved API to Azure pass with API Management. API pass the request to r server and get the details. How we can migrate r server to pass service and connect with APIM in Azure as we don't want to use any IAAS server. We have tried with Machine learning studio but not getting any solution.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Access to NCasT4_v3-series and ND A100 v4-series VMs",
        "Question_creation_time":1629921673763,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/528034\/access-to-ncast4-v3-series-and-nd-a100-v4-series-v.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":22,
        "Question_score":1,
        "Question_body":"How could I request quota for the NCasT4_v3-series and ND A100 v4-series VMs for Machine Learning services and as regular VMs\n\nThey both do not appear as an option on the usual form to request quota increase in any of the 4 US regions I looked\n\nThanks\n\nManuel",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-25T20:15:51.63Z",
                "Answer_score":1,
                "Answer_body":"Hi @ManuelReyesGomez-1028 ,\n\nthe VM series NCasT4_v3 and ND A100 v4 are only available in 3 US regions (both series together)\n\nSource: https:\/\/azure.microsoft.com\/en-us\/global-infrastructure\/services\/?products=virtual-machines&regions=us-central,us-east,us-east-2,us-north-central,us-south-central,us-west-central,us-west,us-west-2,us-west-3\n\n(If the reply was helpful please don't forget to upvote and\/or accept as answer, thank you)\n\nRegards\nAndreas Baumgarten",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How to deploy a scikit learn regression model as a web service?",
        "Question_creation_time":1629821122530,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/526203\/how-to-deploy-a-scikit-learn-regression-model-as-a.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hello,\n\nI find the documentation related with ML model deployment overwhelming and I'm struggling with the most basic \"Hello world\" tutorial even after several days of research.\n\nAll I want is to deploy the most basic model as a web service that can be consumed via an API through Power BI or any other web app to serve as a POC. Then we can think about \"scale\", \"dockers\", \"containers\", etc...\n\nThis is my code in Python 3.6:\n\n\n\n import joblib\n    \n from sklearn.datasets import load_diabetes\n from sklearn.linear_model import Ridge    \n    \n dataset_x, dataset_y = load_diabetes(return_X_y=True)\n    \n model = Ridge().fit(dataset_x, dataset_y)\n    \n joblib.dump(model, 'sklearn_regression_model.pkl')\n\n\n\n\nThis model as features as an array like:\n\n array([[ 0.03807591,  0.05068012],[ ... , ...]])\n\n\n\n\nAs you can see, I've got the model serialized into a sklearn_regression_model.pkl file, I've also got the ML environment setup in Azure ML, a compute instance, I'm familiar with Python and the designer and prefer notebooks.\n\nHow can I deploy this model through an API like:\n\nhttps:\/\/api.xxx.com&parameters....\n\nThanks for any help!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-25T17:00:18.437Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us. Please refer to this guidance to deploy your model and service. https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where?tabs=azcli#deploy-again-and-call-your-service\n\nPlease refer to deploy from local file for your scenario. The workflow is similar no matter where you deploy your model:\n\nRegister the model - Please register from local file\nPrepare an entry script\nPrepare an inference configuration\nDeploy the model locally to ensure everything works\nChoose a compute target\nRe-deploy the model to the cloud\nTest the resulting web service\n\nHope this helps.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Designer: Could not find member 'intellectualPropertyPublisher'",
        "Question_creation_time":1629829259160,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/526276\/azure-ml-designer-could-not-find-member-39intellec.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"From today (Aug 24th, 2021) I'm receiving the following error message when submit any operation in Azure Machine Learning Designer with a dataset:\n\nCould not find member 'intellectualPropertyPublisher' on object of type 'JobProperties'\n\nComplete error message:\n\nUserError: Job submission to AzureML Compute encountered an Exception with status code , Could not find member 'intellectualPropertyPublisher' on object of type 'JobProperties'. Path 'properties.intellectualPropertyPublisher', line 309, position 36.\n\nI'm seeing there's new items in user interface, maybe could be an updating error? Someone is receiving something that? There's something I can do?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-25T16:37:28.447Z",
                "Answer_score":0,
                "Answer_body":"Thanks for reaching out to us. This seems an internal error.\n\nIs there any change in your project before this error happened? Could you please provide your log so that we can look into this issue?\n\nI would suggest you to raise a support ticket for this issue or send us your log to us.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Availibility of VM-Type NC6_Promo for region southeastasia not possible with terraform scripting",
        "Question_creation_time":1629529670457,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/522855\/availibility-of-vm-type-nc6-promo-for-region-south.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I got this error \"STANDARD_NC6_PROMO is not supported in region southeastasia. Please choose a different VM size\". Please advise?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-21T08:15:27.707Z",
                "Answer_score":1,
                "Answer_body":"Hi @TobyTan-0337 ,\n\nit looks like the VM SKU NC6 Promo isn't available in the Azure region Southeast Asia:\n\n\nSource: https:\/\/azure.microsoft.com\/en-us\/global-infrastructure\/services\/?products=virtual-machines&regions=germany-north,asia-pacific-southeast,us-east,us-west,asia-pacific-east\n\nI see two options: Use a different VM SKU or a different Azure region.\n\nDid you try to create a VM using the VM SKU NC6 Promo via Azure portal? This works?\n\n(If the reply was helpful please don't forget to upvote and\/or accept as answer, thank you)\n\nRegards\nAndreas Baumgarten",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"\u201cFailure Exception: OSError: [Errno 30] Read-only file system\u201d when using AzureML in Python Azure Function",
        "Question_creation_time":1597403151470,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/67126\/failure-exception-oserror-errno-30-read-only-file.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Issue\nI am trying prepare and then submit a new experiment to Azure Machine Learning from an Azure Function in Python. I therefore register a new dataset for my Azure ML workspace, which contains the training data for my ML model using dataset.register(.... However, when I try to create this dataset with the following line of code\n\n dataset = Dataset.Tabular.from_delimited_files(path = datastore_paths)\n\nthen I get a Failure Exception: OSError: [Errno 30] Read-only file system ....\n\nIdeas\n1. I know that I shouldn't write to the file system from within an Azure function if possible. But I actually don't want to write anything to the local file system. I only want to create the dataset as a reference to my blob storage under datastore_path and then register this to my Azure Machine Learning workspace. But it seems that the method from_delimited_files is trying to write to the file system anyway (maybe some caching?).\n2. I also know that there is a temp folder in which writing temporary files is permitted. However, I belive I cannot really control where this method is writing data. I already tried changing the current working directory to this temp folder just before the function call using os.chdir(tempfile.gettempdir()), but that didn't help.\n\nAny other ideas? I don't think I am doing something particularly unusually...\n\nDetails\nI am using python 3.7 and azureml-sdk 1.9.0 and I can run the python script locally without problems. I currently deploy from VSCode using the Azure Functions extension version 0.23.0 (and an Azure DevOps pipeline for CI\/CD).\n\nHere is my full stack trace:\n\n Microsoft.Azure.WebJobs.Host.FunctionInvocationException: Exception while executing function: Functions.HttpTrigger_Train\n  ---> Microsoft.Azure.WebJobs.Script.Workers.Rpc.RpcException: Result: Failure\n Exception: OSError: [Errno 30] Read-only file system: '\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/dotnetcore2\/bin\/deps.lock'\n Stack:   File \"\/azure-functions-host\/workers\/python\/3.7\/LINUX\/X64\/azure_functions_worker\/dispatcher.py\", line 345, in _handle__invocation_request\n     self.__run_sync_func, invocation_id, fi.func, args)\n   File \"\/usr\/local\/lib\/python3.7\/concurrent\/futures\/thread.py\", line 57, in run\n     result = self.fn(*self.args, **self.kwargs)\n   File \"\/azure-functions-host\/workers\/python\/3.7\/LINUX\/X64\/azure_functions_worker\/dispatcher.py\", line 480, in __run_sync_func\n     return func(**params)\n   File \"\/home\/site\/wwwroot\/HttpTrigger_Train\/__init__.py\", line 11, in main\n     train()\n   File \"\/home\/site\/wwwroot\/shared_code\/train.py\", line 70, in train\n     dataset = Dataset.Tabular.from_delimited_files(path = datastore_paths)\n   File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/data\/_loggerfactory.py\", line 126, in wrapper\n     return func(*args, **kwargs)\n   File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/data\/dataset_factory.py\", line 308, in from_delimited_files\n     quoting=support_multi_line)\n   File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/readers.py\", line 100, in read_csv\n     df = Dataflow._path_to_get_files_block(path, archive_options)\n   File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/dataflow.py\", line 2387, in _path_to_get_files_block\n     return datastore_to_dataflow(path)\n   File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/_datastore_helper.py\", line 41, in datastore_to_dataflow\n     datastore, datastore_value = get_datastore_value(source)\n   File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/_datastore_helper.py\", line 83, in get_datastore_value\n     _set_auth_type(workspace)\n   File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/_datastore_helper.py\", line 134, in _set_auth_type\n     get_engine_api().set_aml_auth(SetAmlAuthMessageArgument(AuthType.SERVICEPRINCIPAL, json.dumps(auth)))\n   File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py\", line 18, in get_engine_api\n     _engine_api = EngineAPI()\n   File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py\", line 55, in __init__\n     self._message_channel = launch_engine()\n   File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/engine.py\", line 300, in launch_engine\n     dependencies_path = runtime.ensure_dependencies()\n   File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/dotnetcore2\/runtime.py\", line 141, in ensure_dependencies\n     with _FileLock(deps_lock_path, raise_on_timeout=timeout_exception):\n   File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/dotnetcore2\/runtime.py\", line 113, in __enter__\n     self.acquire()\n   File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/dotnetcore2\/runtime.py\", line 72, in acquire\n     self.lockfile = os.open(self.lockfile_path, os.O_CREAT | os.O_EXCL | os.O_RDWR)\n    \n    at Microsoft.Azure.WebJobs.Script.Description.WorkerFunctionInvoker.InvokeCore(Object[] parameters, FunctionInvocationContext context) in \/src\/azure-functions-host\/src\/WebJobs.Script\/Description\/Workers\/WorkerFunctionInvoker.cs:line 85\n    at Microsoft.Azure.WebJobs.Script.Description.FunctionInvokerBase.Invoke(Object[] parameters) in \/src\/azure-functions-host\/src\/WebJobs.Script\/Description\/FunctionInvokerBase.cs:line 85\n    at Microsoft.Azure.WebJobs.Script.Description.FunctionGenerator.Coerce[T](Task`1 src) in \/src\/azure-functions-host\/src\/WebJobs.Script\/Description\/FunctionGenerator.cs:line 225\n    at Microsoft.Azure.WebJobs.Host.Executors.FunctionInvoker`2.InvokeAsync(Object instance, Object[] arguments) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionInvoker.cs:line 52\n    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.InvokeAsync(IFunctionInvoker invoker, ParameterHelper parameterHelper, CancellationTokenSource timeoutTokenSource, CancellationTokenSource functionCancellationTokenSource, Boolean throwOnTimeout, TimeSpan timerInterval, IFunctionInstance instance) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 587\n    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.ExecuteWithWatchersAsync(IFunctionInstanceEx instance, ParameterHelper parameterHelper, ILogger logger, CancellationTokenSource functionCancellationTokenSource) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 532\n    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.ExecuteWithLoggingAsync(IFunctionInstanceEx instance, ParameterHelper parameterHelper, IFunctionOutputDefinition outputDefinition, ILogger logger, CancellationTokenSource functionCancellationTokenSource) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 470\n    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.ExecuteWithLoggingAsync(IFunctionInstanceEx instance, FunctionStartedMessage message, FunctionInstanceLogEntry instanceLogEntry, ParameterHelper parameterHelper, ILogger logger, CancellationToken cancellationToken) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 278\n    --- End of inner exception stack trace ---\n    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.ExecuteWithLoggingAsync(IFunctionInstanceEx instance, FunctionStartedMessage message, FunctionInstanceLogEntry instanceLogEntry, ParameterHelper parameterHelper, ILogger logger, CancellationToken cancellationToken) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 325\n    at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor.TryExecuteAsyncCore(IFunctionInstanceEx functionInstance, CancellationToken cancellationToken) in C:\\projects\\azure-webjobs-sdk-rqm4t\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:line 117",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-16T22:21:17.787Z",
                "Answer_score":1,
                "Answer_body":"The issue was an incompatible OS version in my virtual environment.\n\nA huge thanks goes to PramodValavala-MSFT for his idea to create a docker container! Following his suggestion, I suddenly got the following error message for the dataset = Dataset.Tabular.from_delimited_files(path = datastore_paths) command:\n\nException: NotImplementedError: Unsupported Linux distribution debian 10.\n\nwhich reminded me of the following warning in the azure machine learning documentation:\n\nChoosing the predefined docker image 2.0-python3.7 (running Debian 9) instead of 3.0-python3.7 (running Debian 10) solved the issue (see https:\/\/hub.docker.com\/_\/microsoft-azure-functions-python).\n\nI suspect that the default virtual environment, which I was using originally, also ran on an incompatible OS.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-08-24T14:54:39.657Z",
                "Answer_score":0,
                "Answer_body":"getting this error while doing the operation:\n\nravikiran@Azure:~$ az group create -l eastus -n AZURE\nTraceback (most recent call last):\nFile \"\/opt\/az\/lib\/python3.6\/site-packages\/azure\/cli\/core\/_session.py\", line 47, in load\nself.save()\nFile \"\/opt\/az\/lib\/python3.6\/site-packages\/azure\/cli\/core\/_session.py\", line 65, in save\nwith codecs_open(self.filename, 'w', encoding=self._encoding) as f:\nFile \"\/usr\/bin\/..\/..\/opt\/az\/lib\/python3.6\/codecs.py\", line 897, in open\nfile = builtins.open(filename, mode, buffering)\nOSError: [Errno 30] Read-only file system: '\/home\/ravikiran\/.azure\/az.sess'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\nFile \"\/opt\/az\/lib\/python3.6\/runpy.py\", line 193, in run_module_as_main\n\"main\", mod_spec)\nFile \"\/opt\/az\/lib\/python3.6\/runpy.py\", line 85, in run_code\nexec(code, run_globals)\nFile \"\/opt\/az\/lib\/python3.6\/site-packages\/azure\/cli\/main.py\", line 38, in <module>\naz_cli = get_default_cli()\nFile \"\/opt\/az\/lib\/python3.6\/site-packages\/azure\/cli\/core\/init.py\", line 920, in get_default_cli\nhelp_cls=AzCliHelp)\nFile \"\/opt\/az\/lib\/python3.6\/site-packages\/azure\/cli\/core\/init.py\", line 82, in init\nSESSION.load(os.path.join(azure_folder, 'az.sess'), max_age=3600)\nFile \"\/opt\/az\/lib\/python3.6\/site-packages\/azure\/cli\/core\/_session.py\", line 61, in load\nself.save()\nFile \"\/opt\/az\/lib\/python3.6\/site-packages\/azure\/cli\/core\/_session.py\", line 65, in save\nwith codecs_open(self.filename, 'w', encoding=self._encoding) as f:\nFile \"\/usr\/bin\/..\/..\/opt\/az\/lib\/python3.6\/codecs.py\", line 897, in open\nfile = builtins.open(filename, mode, buffering)\nOSError: [Errno 30] Read-only file system: '\/home\/ravikiran\/.azure\/az.ses",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Input data sample training clarifications",
        "Question_creation_time":1629368813483,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/520325\/input-data-sample-training-clarifications.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Dear users and experts,\nI am not clear about how is used the input data sample.\nI have a csv file with 5 fields and 20k lines entries.\nWhen I run a classification training, does the 20k entries used ? Or the algorithm split this data sample randomly?\n\nMy final goal is to ensure that I am training on the desired examples I am providing, in order to make my training better when I find some new examples on which the algortihm is doing wrong.\n\nBest regards.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-20T04:04:24.663Z",
                "Answer_score":0,
                "Answer_body":"@DJamin-2804 Thanks for the question. The algorithm will not split the data. The idea is to split the whole dataset into training and test, where the test dataset is held back from training your model. Then in the training stage, the original training dataset is divided again into the (secondary) training dataset and validation dataset, where the validation dataset is also held back from training your model. The reason for the second split of training dataset is that the most models have some hyperparameters that need to be tuned, where the role of validation dataset is to be used for this purpose with a specific model. Thus, if my model does not have hyperparameters to be tuned, I do not need to have the training dataset split into the (secondary) training and validation datasets.\n\n\u2022 Training Dataset: The sample of data used to fit the model.\n\u2022 Validation Dataset: The sample of data used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters.\n\u2022 Test Dataset: The sample of data used to provide an unbiased evaluation of a final model fit on the training dataset.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-08-20T11:05:10.763Z",
                "Answer_score":0,
                "Answer_body":"Dear expert,\nthanks for the feedback.\nBut sorry I am not clear with your explanation of the splitting.\nThe whole 20k dataset is used for training and these same 20k entries are used again for evaluation?\n\nI have another last question : is there a way to provide a training sample that will be used fully. And then provide a test sample (containing different data) to evaluate the accuracy of the training. This test sample will be used fully too.\n\nI want to ensure that all the desired data will be used for learning.\nAnyone knows if such possiblity exists?\nBest regards.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azuremlsdk for R hangs on update while solving environment",
        "Question_creation_time":1624849818327,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/453836\/azuremlsdk-for-r-hangs-on-update-while-solving-env.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_comment_count":6,
        "Question_follower_count":12,
        "Question_score":2,
        "Question_body":"I haven't used azuremlsdk for R in a few weeks. When I tried to use it today it said it had to update, the update seems to get stuck on step 17.\n\nThis is the last message before it timeouts in 1h 30m.\n\nStep 17\/23 : RUN conda install -p \/azureml-envs\/azureml_da3e97fcb51801118b8e80207f3e01ad -c r -y r-essentials=3.6.0 rpy2 r-checkpoint && pip install --no-cache-dir azureml-defaults ---> Running in 30337f6502b4 Solving environment: ...working...\n\nI have tried updating miniconda from the anaconda prompt and I've tried deleting my azureml resource and creating a new one. Any ideas what is going on?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-30T20:09:46.047Z",
                "Answer_score":1,
                "Answer_body":"Exactly the same problem for me.\n\nI tried on 2 different compute clusters (Standard_D2_v2, Standard_DS12_v2) both in eastus.\n\nI am trying to execute a tutorial directly from Azure ML Notebook (azureml-sdk-for-r\/vignettes\/train-and-deploy-first-model)\n\n\n\n\nHere the last message I have in the build log\n\nDownloading and Extracting Packages\nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\n[91m\n[0mRemoving intermediate container e514a28cde98\n---> 57dfbf426dfa\nStep 17\/23 : RUN conda install -p \/azureml-envs\/azureml_da3e97fcb51801118b8e80207f3e01ad -c r -y r-essentials=3.6.0 rpy2 r-checkpoint && pip install --no-cache-dir azureml-defaults\n---> Running in 0ab44ea8e6a3\nSolving environment: ...working...",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-05T13:53:58.41Z",
                "Answer_score":0,
                "Answer_body":"@ramr-msft any news on this?\nI have tried many times but it still doesn't work.\nThank you",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-30T15:04:12.567Z",
                "Answer_score":0,
                "Answer_body":"@ramr-msft Is there any update for this, I'm also having exactly the same issue described.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-08-23T12:44:52.16Z",
                "Answer_score":0,
                "Answer_body":"@JamieWallis-0781 @Eric-4026 what is the base image you are using for your environments? conda 4.5 resolver is experiencing issues like that recently, so old base images could be the root cause of your issue",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"i cannot make labeling project enabled",
        "Question_creation_time":1629489536580,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/522604\/i-cannot-make-labeling-project-enabled.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I have a labeling project.\nIt is now stopped.\nWhen I click \"Resume\", something happens on for several hours, then a message that an error \"Failed\" has occurred and that's it.\nthe project remains unavailable.\nNo changes have been made to it since the stop.\n\nWhat is the reason for the error? Can I get around it somehow? or somehow copy this project so as not to lose the markup that has already been done in it?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"I cannot see the progress of my modules run on Azure ML. Its stuck at the first module",
        "Question_creation_time":1629204002400,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/517242\/i-cannot-see-the-progress-of-my-modules-run-on-azu.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"When I run my ML on Azure ML Designer. I am unable to see the progress of the modules. The program runs at the back end however the designer interface seems to be stuck at the first module of Designer. If an error happens in any module, i dont get to know as I still see it stuck at the first module. I am using ML compute in US East",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-17T22:01:44.697Z",
                "Answer_score":0,
                "Answer_body":"Hi, can you please clarify what you mean by stuck on the first module. If there's an error, you should see an error icon on the module as shown here for example. This document shows how to view logs for a run.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-08-18T01:56:30.497Z",
                "Answer_score":0,
                "Answer_body":"Its a strange Problem. The desinger runs in the background . However in the designer interface it woudl not show me the progres of modules. It continues to show me 'queued' in the first module. The below screen shot was taken some 5 min after starting the run. Once the ML run is complete, i get a notification that the run is complete however in the designer view it still shows running. Then i have to cancel the run. Once I cancel the run, I can see all modules completed. I can see the results of the run as well .",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning - Uses invalid Pytorch version when training",
        "Question_creation_time":1629119160593,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/515579\/azure-machine-learning-uses-invalid-pytorch-versio.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"Hi, I am training my models via Azure Machine Learning.\n\nOn other day, my training is running with GPU support, however today I found my training is running on a CPU.\nI'm not modified training environment, only training script was modified.\nMy computing cluster is NC6v3 - have a GPU.\n\nI investigate a situation, and I found training script is running on PyTorch 1.6.0.\nOn other day, it ran on Pytorch 1.8.1.\nI think my \"don't use GPU\" problem is caused by the situation that CUDA toolkit version is not suitable for Pytorch version.\n\nThen, I output a installed package to the log.\nThe log says 'Pytorch 1.8.1 was installed, however uses 1.6.0'.\nI confused by this weird circumstances.\nCan someone tell me the solution?\n\n<My code snippet>\n<<conda_dependencies.yaml>>\n\nchannels:\n- conda-forge\n- pytorch\n- nvidia\ndependencies:\n- python=3.8.10\n- mesa-libgl-cos6-x86_64\n- cudatoolkit=11.1\n- pytorch==1.8.1\n- torchvision==0.9.1\n- tqdm\n- scikit-learn\n- matplotlib\n- pandas\n- pip < 20.3\n- pip:\n- azureml-defaults\n- opencv-python-headless\n- pillow==8.2.0\n\n<<Environment definition>>\nenvironment_definition_file = experiment_dir \/ 'conda_dependencies.yaml'\nenvironment_name = 'pytorch-1.8.1-gpu'\nbase_image_name = 'mcr.microsoft.com\/azureml\/openmpi4.1.0-cuda11.0.3-cudnn8-ubuntu18.04'\nenvironment = Environment.from_docker_image(environment_name, base_image_name, conda_specification = environment_definition_file)\ndocker_run_config = DockerConfiguration(use_docker=True)\n\nscript_run_config = ScriptRunConfig(\nsource_directory = experiment_dir,\nscript = SCRIPT_FILE_NAME,\narguments = arguments,\ncompute_target = compute_target,\ndocker_runtime_config = docker_run_config,\nenvironment = environment)\n\n<<Output a log in the training script>>\nimport torch\nimport pip\n\npip.main(['list'])\nprint(f'PyTorch version: {torch.version}')\n\n<My logs>\nPackage Version\n\n\nadal 1.2.7\napplicationinsights 0.11.10\n(omission)\ntorch 1.8.1\ntorchvision 0.9.0a0\n(omission)\n\nPyTorch version: 1.6.0",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-16T23:24:59.363Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. These are the supported versions for PyTorch. Please refer to this document for creating a custom environment. As shown, you'll need to use versions <= 1.6.0. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-08-20T10:33:00.493Z",
                "Answer_score":0,
                "Answer_body":"Hi, GiftA-MSFT\n\nThank you for your reply.\nI understand that AML supports Pytorch <= 1.6.0.\n\nI hope AML supports Pytorch 1.8.x at early days.\n\n\n\n\nSincerely,",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"mapInputPort error",
        "Question_creation_time":1628930290343,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/513716\/mapinputport-error.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"unable to execute maml.mapInputPort(1) on microsoft azure machine learning studio. please help",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"'NoneType' error on trained models (unresolvable error)",
        "Question_creation_time":1629137715607,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/515918\/39nonetype39-error-on-trained-models-unresolvable.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hello, have been struggling with this error for a while now. So the training of the model is fine, working well. However, after training when I try to retrieved the train model from the workspace and make a prediction, sometimes it give me this error. It seems to be related to space remaining on the machine? I am guessing the old models are being over-written and they are gone. But the metrics such as their accuracy or log loss is still showing on the monitoring tab. There are no stackoverflow answers related to this error, can I get any help?\n\n\n\n\nThis is the code used to retrieved the saved models.\nCURRENT_RUN = Experiment(ws, experiment_name).workspace.get_run(RUNID)\nbest_run, best_model = CURRENT_RUN.get_output()\n\n\n\n\nMessage: object of type 'NoneType' has no len()\nInnerException: TypeError: object of type 'NoneType' has no len()\nErrorResponse\n{\n\"error\": {\n\"code\": \"SystemError\",\n\"message\": \"Encountered an internal AutoML error. Error Message\/Code: PredictionException. Additional Info: PredictionException:\\n\\tMessage: object of type 'NoneType' has no len()\\n\\tInnerException: None\\n\\tErrorResponse \\n{\\n \\\"error\\\": {\\n \\\"message\\\": \\\"object of type 'NoneType' has no len()\\\",\\n \\\"target\\\": \\\"CalibratedModel\\\",\\n \\\"reference_code\\\": \\\"CalibratedModel\\\"\\n }\\n}\",\n\"details_uri\": \"https:\/\/aka.ms\/automltroubleshoot\",\n\"target\": \"CalibratedModel\",\n\"inner_error\": {\n\"code\": \"ClientError\",\n\"inner_error\": {\n\"code\": \"AutoMLInternal\"\n}\n},\n\"reference_code\": \"CalibratedModel\"\n}\n}",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Can I build the environment in the computing cluster using pip?",
        "Question_creation_time":1628609652357,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/508278\/can-i-build-the-environment-in-the-computing-clust.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":1,
        "Question_body":"I want to train AI model, and in the VM instance executing the command below worked well\n\n pip install -r requirement.txt\n python ~\n\n\n\nThen in order to train the Ai model in the same environment in the VM computing cluster, in the Python 3.8 - AzureML notebook I executed below (I'm sorry I couldn't attach the screenshot)\n\n import azureml.core\n from azureml.core import Workspace\n import os\n from azureml.core import ScriptRunConfig\n from azureml.core import Datastore\n from azureml.core import Experiment\n from azureml.core import Dataset\n from azureml.core.compute import AmlCompute\n from azureml.core.compute import ComputeTarget\n from azureml.core import Environment\n import datetime\n    \n cluster_name = 'high-2x-v100-1'\n gpu_name = 'Standard_NC12s_v3'\n experiment_name = 'training_agent_print'\n hyperparameters = [\n     '--max_train_time', '172800'\n ]\n script_folder = '.\/script_folder'\n    \n # workspace\n ws = Workspace.from_config()\n print(ws.name, ws.location, ws.resource_group, sep='\\t')\n    \n # compute cluster\n compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", cluster_name)\n compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", gpu_name)\n    \n if compute_name in ws.compute_targets:\n     compute_target = ws.compute_targets[compute_name]\n     if compute_target and type(compute_target) is AmlCompute:\n         print('found compute target. just use it. ' + compute_name)\n else:\n     print('creating a new compute target...')\n     provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n                                                                 min_nodes=compute_min_nodes,\n                                                                 max_nodes=compute_max_nodes)\n     compute_target = ComputeTarget.create(\n         ws, compute_name, provisioning_config)\n # environment\n env = Environment.from_pip_requirements(name = \"m8-pip-training\", file_path = \".\/requirements.txt\")\n exp = Experiment(workspace=ws,name=experiment_name)\n    \n # run\n src = ScriptRunConfig(source_directory=script_folder,\n     script='main.py',\n     arguments=hyperparameters,\n     compute_target=compute_target,\n     environment=env\n )\n run = exp.submit(config=src)\n\n\n\n\nas a result, in the 20_image_build_log.txt file, I got the log as below\n\n ==> WARNING: A newer version of conda exists. <==\n   current version: 4.9.2\n   latest version: 4.10.3\n    \n Please update conda by running\n    \n     $ conda update -n base -c defaults conda\n    \n    \n Pip subprocess error:\n ERROR: Could not find a version that satisfies the requirement parlai==1.3.0 (from -r \/azureml-environment-setup\/condaenv.5svatkzc.requirements.txt (line 55)) (from versions: 0.1.20200409, 0.1.20200416, 0.1.20200610, 0.1.20200713, 0.1.20200716, 0.8.0, 0.9.0, 0.9.1, 0.9.2, 0.9.3, 0.9.4)\n ERROR: No matching distribution found for parlai==1.3.0 (from -r \/azureml-environment-setup\/condaenv.5svatkzc.requirements.txt (line 55))\n    \n    \n CondaEnvException: Pip failed\n    \n  [0mThe command '\/bin\/sh -c ldconfig \/usr\/local\/cuda\/lib64\/stubs && conda env create -p \/azureml-envs\/azureml_ba289e67ead35c3dbaac125150111737 -f azureml-environment-setup\/mutated_conda_dependencies.yml && rm -rf \"$HOME\/.cache\/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR\/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig' returned a non-zero code: 1\n 2021\/08\/10 15:13:41 Container failed during run: acb_step_0. No retries remaining.\n failed to run step ID: acb_step_0: exit status 1\n    \n Run ID: caj failed after 2m24s. Error: failed during run, err: exit status 1\n\n\n\n\nAns the experiment failed. I have 3 questions\n1. Why computing cluster is using conda to build image even though I export the file from pip?\n2. Can I build the environment using pip?\n3. As there is WARNING, if I can update the conda to latest version, the experiment might not faile. Can I update the conda in the computing cluster?\n\nThank you so much",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-11T10:13:07.957Z",
                "Answer_score":1,
                "Answer_body":"Summary:\n- Option 1: try to create a working Conda environment, either on your own computer or in the VM; run conda list --export my-conda-specification.yml, and specify your Environment with Environment.from_conda_specification('my-env-name', 'my-conda-specification.yml')\n- Option 2: create a Docker image, for example FROM mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04, and install your Python packages in there. Once it's working, publish the Docker image and tell Environment to use it.\n\nMore details and some links below.\n\nWhy computing cluster is using conda to build image even though I export the file from pip?\n\nWhy MS uses Conda: unlike Pip, Conda can also control non-Python dependencies. Conda is also better at managing precompiled packages and tracking and solving their dependencies. (Under the hood, Conda uses Pip, which is why you're seeing \"Pip subprocess error\" in 20_image_build_log.txt.)\n\nIt is not very hard to translate Pip's requirements.txt file to something Conda understands; I think Conda can even read requirements.txt directly. That is how it is possible that you can export a requirements.txt file from Pip, and Conda reads it.\n\nCan I build the environment using pip?\n\nThere are two ways you can reproducibly specify the environment you need: either create a conda specification, or successfully use pip in Docker image and use the resulting Docker image.\n\nA. Create a conda specification that successfully builds the environment.\n\nIf you have a working conda environment:\n- you can run activate it and run conda list --export conda-specification.txt to get the specification file (it will include any pip-installed dependencies!)\n- you can create a new environment from that file using conda create --name my_env_name --file conda-specification.txt\n- Hopefully it is also possible to run Environment.from_conda_specification('my-env-name', 'my-conda-specification.txt'). The reason I'm not sure is that conda list --export creates a plain text file, and Environment.from_conda_specification might expect a YAML file instead.\n\nIf you're creating a YAML file to specify an environment, it probably looks like this (below) and is called something like conda-spec.yml.\n\n# conda-spec.yml\nname: img-classification-part3-deploy-encrypted\ndependencies:\n - package1  # installed by `conda install`\n - package2  # installed by conda\n - pip:\n - azureml-sdk\n   - matplotlib\n   - pandas\n   - azureml-opendatasets\n   - encrypted-inference==0.9\n   - azure-storage-blob\n\n\n\n\nCreation, again, takes place via one of\n- conda create --name my_env_name --file my-conda-yaml.yml\n- Environment.from_conda_specification('my-env-name', 'my-conda-specification.txt')\n\nMore details in these two URLs:\n- https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-environments\n- https:\/\/azure.github.io\/azureml-cheatsheets\/docs\/cheatsheets\/python\/v1\/environment\/\n\n\n\n\nB. Build a Docker image with a working environment, and tell Environment to use that Docker file.\n\nTo get the Azure requirements, use FROM mcr.microsoft.com\/azureml\/openmpi3.1.2-ubuntu18.04 (or, if you need GPU, one of the image tags in https:\/\/github.com\/Azure\/AzureML-Containers#featured-tags)\n\n\nExample of telling Environment to use a Docker image : https:\/\/azure.github.io\/azureml-cheatsheets\/docs\/cheatsheets\/python\/v1\/environment\/\n\nAs there is WARNING, if I can update the conda to latest version, the experiment might not faile. Can I update the conda in the computing cluster?\n\nI don't specifically know if you can update conda in the cluster; but I know that updating Conda should not change which packages Conda finds or (tries to) install, so this probably will not help.\n\n\n\n\nI hope something of the above will help you. Good luck!\n\n\n\n\nEDIT 2021-08-17:\n- Use the correct command to export a conda env definition. I accidentally wrote the create command, instead...",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Execure R scripting and R Desktop output varies",
        "Question_creation_time":1626086340790,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/472103\/execure-r-scripting-and-r-desktop-output-varies.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\nExecuting a model with Execute R Script in Azure ML produces a different result compared to R desktop (R 4.1.0)\nHere are step I followed\na. With Azure ML studio ,Imported the 2 data sets Testb.csv and Testc,csv\nand using the 2 datasets , executed the R script ( see AzureMLR.txt)\nand executed the almost same script in R Desktop ( except i had to read from csv files instead from the ports) ( see RDesktopcode.txt)\n\nI see a big difference in output produced by both\nRefer this snapshot where one on left is from AzureML and right is R Desktop\n\nYou may to rename testb.txt and textc.txt as csv files to use them . I could not upload csv files so changed to txt files\n\nTHanks",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Can't connect Azure Machine Learning to hierarchical namespace storage account",
        "Question_creation_time":1628837885567,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/512512\/can39t-connect-azure-machine-learning-to-data-lake.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"When trying to connect Azure ML to a Storage account on ARM, I get this error:\n\n {\n   \"code\": \"DeploymentFailed\",\n   \"message\": \"At least one resource deployment operation failed. Please list deployment operations for details. Please see https:\/\/aka.ms\/DeployOperations for usage details.\",\n   \"details\": [\n     {\n       \"code\": \"BadRequest\",\n       \"message\": \"Cannot use storage with HNS enabled.\"\n     }\n   ]\n }\n\n\n\nBut when reading the documentation, it seems like ADLS Gen2 (which requires HNS) should be supported. How do I get this fixed?\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-13T09:49:35.057Z",
                "Answer_score":0,
                "Answer_body":"@JamesLee-0129 I think a storage account with HNS enabled cannot be used with Azure ML workspace. This is documented here in Azure ML documentation.\n\nBy default, the storage account is a general-purpose v1 account. You can upgrade this to general-purpose v2 after the workspace has been created. Do not enable hierarchical namespace on the storage account after upgrading to general-purpose v2.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Real-time enpoint and AutoML models",
        "Question_creation_time":1629033615787,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/514207\/real-time-enpoint-and-automl-models.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"Hi Azure community,\n\nI am experiencing a probem with Real-time endopoint when trying to deploy models trained using AutoML.\n\nSince deploying AutoML models directly from the portal has some problems due to recent changes in azureml-defaults==1.33.0 (see here: https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/511349\/auto-model-deployment-in-container-instance-no-mod.html), I found a work around and managed to deploy AutoML models to real-time-endpoint using the script in attachment (123179-automl-endpoint-deploy-workaround.txt).\n\nAll it does is to create a conda environment from a yml file (123353-conda-env-v-1-0-0.txt) to solve the issues introduced with azureml-defaults==1.33.0 and use the same entry scripts that are available after AutoML training.\nThis works in most cases but for ExtremeRandomTrees models. In these cases I get the following error message:\n\nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n\nDo you have any idea what the is problem here? Is there any particular package I should add to the conda enviroment?\nI cannot find anything similar on the web, so I decided to ask here.\n\nAlso, these real-time-endopoints got stuck in transitioning state and I cannot simply remove them from the Portal. How could I remove them instead?\n\nAny idea and help would be very much appreciated thanks.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Cuda not compatible with PyTorch installation error while training the model with 8xA100",
        "Question_creation_time":1629092753013,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/514710\/cuda-not-compatible-with-pytorch-installation-erro.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I tried to train the model with A100 computing cluster\nI implemented the totally same command I used for V100 computing cluster, but it doesn't work and I got the error like below\n\n \/azureml-envs\/azureml_9f42dddb00266f3582208ef8cdab4701\/lib\/python3.7\/site-packages\/torch\/cuda\/__init__.py:104: UserWarning: \n A100-SXM4-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.\n The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n If you want to use the A100-SXM4-40GB GPU with PyTorch, please check the instructions at https:\/\/pytorch.org\/get-started\/locally\/\n\nso I visited https:\/\/pytorch.org\/get-started\/locally\/ and followed to implement conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch but it doesn't work. Neither did conda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c nvidia\n\nwarnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n\nso I visited https:\/\/pytorch.org\/get-started\/locally\/ and followed to implement conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch but it doesn't work. Neither did conda install pytorch torchvision torchaudio cudatoolkit=11.1 -c pytorch -c nvidia\n\nHow can I solve this problem?\n\nThank you so much\n\nAdd:\nIn the conda environment below,\n\nchannels:\n- anaconda\n- defaults\ndependencies:\n- argon2-cffi=20.1.0=py37h27cfd23_1\n- async_generator=1.10=py37h28b3542_0\n- attrs=20.2.0=py_0\n- backcall=0.2.0=pyhd3eb1b0_0\n- blas=1.0=mkl\n- bleach=3.3.1=pyhd3eb1b0_0\n- ca-certificates=2021.7.5=h06a4308_1\n- certifi=2021.5.30=py37h06a4308_0\n- cffi=1.14.6=py37h400218f_0\n- cycler=0.10.0=py37_0\n- dbus=1.13.18=hb2f20db_0\n- defusedxml=0.7.1=pyhd3eb1b0_0\n- entrypoints=0.3=py37_0\n- expat=2.3.0=h2531618_2\n- fontconfig=2.13.1=h6c09931_0\n- freetype=2.10.4=h5ab3b9f_0\n- glib=2.68.1=h36276a3_0\n- gst-plugins-base=1.14.0=h8213a91_2\n- gstreamer=1.14.0=h28cd5cc_2\n- icu=58.2=he6710b0_3\n- importlib_metadata=3.10.0=hd3eb1b0_0\n- intel-openmp=2021.2.0=h06a4308_610\n- ipykernel=5.3.4=py37h5ca1d4c_0\n- ipython_genutils=0.2.0=pyhd3eb1b0_1\n- jpeg=9b=h024ee3a_2\n- jsonschema=3.2.0=py_2\n- jupyter_client=6.1.12=pyhd3eb1b0_0\n- jupyter_core=4.7.1=py37h06a4308_0\n- jupyterlab_pygments=0.1.2=py_0\n- kiwisolver=1.3.1=py37h2531618_0\n- lcms2=2.12=h3be6417_0\n- ld_impl_linux-64=2.33.1=h53a641e_7\n- libedit=3.1.20191231=h14c3975_1\n- libffi=3.3=he6710b0_2\n- libgcc-ng=9.1.0=hdf63c60_0\n- libpng=1.6.37=hbc83047_0\n- libsodium=1.0.18=h7b6447c_0\n- libstdcxx-ng=9.1.0=hdf63c60_0\n- libtiff=4.1.0=h2733197_1\n- libuuid=1.0.3=h1bed415_2\n- libxcb=1.14=h7b6447c_0\n- libxml2=2.9.10=hb55368b_3\n- lz4-c=1.9.3=h2531618_0\n- markupsafe=1.1.1=py37h14c3975_1\n- matplotlib=3.3.4=py37h06a4308_0\n- matplotlib-base=3.3.4=py37h62a2d02_0\n- mistune=0.8.4=py37h14c3975_1001\n- mkl=2021.2.0=h06a4308_296\n- mkl-service=2.3.0=py37h27cfd23_1\n- mkl_fft=1.3.0=py37h42c9631_2\n- mkl_random=1.2.1=py37ha9443f7_2\n- nbclient=0.5.3=pyhd3eb1b0_0\n- nbconvert=6.1.0=py37h06a4308_0\n- nbformat=5.1.3=pyhd3eb1b0_0\n- ncurses=6.2=he6710b0_1\n- nest-asyncio=1.5.1=pyhd3eb1b0_0\n- notebook=6.4.0=py37h06a4308_0\n- olefile=0.46=py37_0\n- openjpeg=2.3.0=h05c96fa_1\n- openssl=1.1.1k=h27cfd23_0\n- pandocfilters=1.4.3=py37h06a4308_1\n- parso=0.8.2=pyhd3eb1b0_0\n- pcre=8.44=he6710b0_0\n- pickleshare=0.7.5=pyhd3eb1b0_1003\n- pip=20.2.4=py37_0\n- prometheus_client=0.11.0=pyhd3eb1b0_0\n- ptyprocess=0.7.0=pyhd3eb1b0_2\n- pycparser=2.20=py_2\n- pyparsing=2.4.7=pyhd3eb1b0_0\n- pyqt=5.9.2=py37h05f1152_2\n- pyrsistent=0.17.3=py37h7b6447c_0\n- python=3.7.9=h7579374_0\n- python-dateutil=2.8.1=pyhd3eb1b0_0\n- qt=5.9.7=h5867ecd_1\n- readline=8.0=h7b6447c_0\n- send2trash=1.5.0=pyhd3eb1b0_1\n- setuptools=50.3.0=py37hb0f4dca_1\n- sip=4.19.8=py37hf484d3e_0\n- six=1.15.0=py37h06a4308_0\n- sqlite=3.33.0=h62c20be_0\n- terminado=0.9.4=py37h06a4308_0\n- testpath=0.5.0=pyhd3eb1b0_0\n- tk=8.6.10=hbc83047_0\n- tornado=6.0.4=py37h7b6447c_1\n- traitlets=5.0.5=pyhd3eb1b0_0\n- wcwidth=0.2.5=py_0\n- webencodings=0.5.1=py37_1\n- wheel=0.35.1=py_0\n- xz=5.2.5=h7b6447c_0\n- zeromq=4.3.4=h2531618_0\n- zlib=1.2.11=h7b6447c_3\n- zstd=1.4.9=haebb681_0\n- pip:\n- absl-py==0.12.0\n- adal==1.2.7\n- alabaster==0.7.12\n- antlr4-python3-runtime==4.8\n- azure-common==1.1.27\n- azure-core==1.16.0\n- azure-graphrbac==0.61.1\n- azure-mgmt-authorization==0.61.0\n- azure-mgmt-containerregistry==8.0.0\n- azure-mgmt-core==1.3.0\n- azure-mgmt-keyvault==9.0.0\n- azure-mgmt-resource==13.0.0\n- azure-mgmt-storage==11.2.0\n- azureml-core==1.32.0\n- babel==2.9.0\n- backports-tempfile==1.0\n- backports-weakref==1.0.post1\n- boto3==1.9.246\n- botocore==1.12.246\n- cachetools==4.2.2\n- chardet==4.0.0\n- coloredlogs==14.0\n- contextlib2==0.6.0.post1\n- cryptography==3.4.7\n- datasets==1.4.1\n- decorator==5.0.7\n- dill==0.3.3\n- docformatter==1.3\n- docker==4.4.4\n- docutils==0.15.2\n- emoji==0.5.4\n- filelock==3.0.12\n- flake8==3.7.8\n- flake8-bugbear==19.8.0\n- fsspec==2021.4.0\n- fvcore==0.1.1.post20200716\n- gitdb2==2.0.5\n- gitpython==3.0.3\n- google-auth==1.30.0\n- google-auth-oauthlib==0.4.4\n- grpcio==1.37.0\n- huggingface-hub==0.0.2\n- humanfriendly==9.1\n- hydra-core==1.0.6\n- idna==2.10\n- imagesize==1.2.0\n- importlib-metadata==4.0.1\n- importlib-resources==5.1.2\n- ipython==7.19.0\n- isodate==0.6.0\n- jedi==0.18.0\n- jeepney==0.7.0\n- jinja2==2.11.3\n- jmespath==0.10.0\n- joblib==0.14.1\n- jsonlines==1.2.0\n- jsonpickle==2.0.0\n- markdown==3.3.4\n- markdown-it-py==0.5.8\n- mccabe==0.6.1\n- more-itertools==8.7.0\n- msrest==0.6.21\n- msrestazure==0.6.4\n- multiprocess==0.70.11.1\n- myst-parser==0.12.10\n- ndg-httpsclient==0.5.1\n- nltk==3.4.5\n- numpy==1.17.5\n- oauthlib==3.1.0\n- omegaconf==2.0.6\n- packaging==20.9\n- pandas==1.1.1\n- pathspec==0.8.1\n- pexpect==4.7.0\n- pillow==8.1.1\n- pluggy==0.13.1\n- portalocker==2.3.0\n- prompt-toolkit==3.0.18\n- protobuf==3.15.8\n- py==1.10.0\n- py-gfm==1.0.2\n- py-rouge==1.1\n- pyarrow==4.0.0\n- pyasn1==0.4.8\n- pyasn1-modules==0.2.8\n- pycodestyle==2.5.0\n- pyflakes==2.1.1\n- pygments==2.8.1\n- pyjwt==2.1.0\n- pyopenssl==20.0.1\n- pytest==5.3.2\n- pytest-datadir==1.3.1\n- pytest-regressions==2.1.1\n- pytz==2021.1\n- pyyaml==5.4\n- pyzmq==18.1.0\n- regex==2020.1.8\n- requests==2.25.1\n- requests-mock==1.7.0\n- requests-oauthlib==1.3.0\n- rsa==4.7.2\n- ruamel-yaml==0.17.4\n- ruamel-yaml-clib==0.2.6\n- s3transfer==0.2.1\n- scikit-learn==0.23.1\n- scipy==1.4.1\n- secretstorage==3.3.1\n- sh==1.12.14\n- smmap==4.0.0\n- smmap2==3.0.1\n- snowballstemmer==2.1.0\n- sphinx==2.2.2\n- sphinx-autodoc-typehints==1.10.3\n- sphinx-rtd-theme==0.4.3\n- sphinxcontrib-applehelp==1.0.2\n- sphinxcontrib-devhelp==1.0.2\n- sphinxcontrib-htmlhelp==1.0.3\n- sphinxcontrib-jsmath==1.0.1\n- sphinxcontrib-qthelp==1.0.3\n- sphinxcontrib-serializinghtml==1.1.4\n- subword-nmt==0.3.7\n- tabulate==0.8.9\n- tensorboard==2.3.0\n- tensorboard-plugin-wit==1.8.0\n- tensorboardx==2.1\n- termcolor==1.1.0\n- threadpoolctl==2.1.0\n- tokenizers==0.10.2\n- torch==1.8.1\n- torchtext==0.9.1\n- tqdm==4.36.1\n- typing-extensions==3.7.4.1\n- unidecode==1.1.1\n- untokenize==0.1.1\n- urllib3==1.25.11\n- websocket-client==0.56.0\n- websocket-server==0.4\n- werkzeug==1.0.1\n- xxhash==2.0.2\n- yacs==0.1.8\n- zipp==3.4.1\n\nI implemented conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch, and export to yml file.\nThen in order to create job to computing cliuster I implemented below\n\n #A100ver\n cluster_name = 'high-A100'\n gpu_name = 'Standard_ND96asr_v4'\n experiment_name = 'speaker_identification_training_A100'\n hyperparameters = [\n     '--max_train_time', '172800'\n ]\n script_folder = '.\/script_folder'\n    \n # workspace\n ws = Workspace.from_config()\n print(ws.name, ws.location, ws.resource_group, sep='\\t')\n    \n # compute cluster\n compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", cluster_name)\n compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", gpu_name)\n    \n if compute_name in ws.compute_targets:\n     compute_target = ws.compute_targets[compute_name]\n     if compute_target and type(compute_target) is AmlCompute:\n         print('found compute target. just use it. ' + compute_name)\n else:\n     print('creating a new compute target...')\n     provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n                                                                 min_nodes=compute_min_nodes,\n                                                                 max_nodes=compute_max_nodes)\n     compute_target = ComputeTarget.create(\n         ws, compute_name, provisioning_config)\n    \n env = Environment.load_from_directory(path=\".\/.azureml6\/\")\n exp = Experiment(workspace=ws,name=experiment_name)\n command = \"pwd && pip install azure-storage-blob && python main.py\"\n # run\n src = ScriptRunConfig(source_directory=script_folder,\n  command=command,\n  compute_target=compute_target,\n  environment=env\n )\n run = exp.submit(config=src)\n\n\n\n\nActually I found that in order to use A100, pytoch version should be 1.8.1+cu111. But by implementing conda install pytorch==1.8.1 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=11.1 -c pytorch -c conda-forge, I got the error like below\n\nCollecting package metadata (current_repodata.json): done\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\nSolving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\nCollecting package metadata (repodata.json): done\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\nSolving environment: |\nFound conflicts! Looking for incompatible packages.\nThis can take several minutes. Press CTRL-C to abort.\nfailed\n\n\nUnsatisfiableError: The following specifications were found\nto be incompatible with the existing python installation in your environment:\n\n\nSpecifications:\n\n\npytorch==1.8.1 -> python[version='2.7.|3.5.|3.6.|3.6.12|3.6.12|3.7.10|3.7.10|>=2.7,<2.8.0a0|>=3.5,<3.6.0a0|>=3.5|>=3.7|>=3.6,<3.7|3.7.9|3.6.9|3.6.9|3.6.9|3.6.9|3.4.',build='1_73_pypy|2_73_pypy|3_73_pypy|4_73_pypy|1_73_pypy|0_73_pypy|5_73_pypy|5_73_pypy|0_73_pypy']\n- torchaudio==0.8.0 -> python[version='2.7.|3.5.|3.6.|>=2.7,<2.8.0a0|>=3.5,<3.6.0a0|3.4.|3.9.*']\n\n\nYour python: python==3.7.9=h7579374_0\n\n\nIf python is on the left-most side of the chain, that's the version you've asked for.\nWhen python appears to the right, that indicates that the thing on the left is somehow\nnot available for the python version you are constrained to. Note that conda will not\nchange your python version to a different minor version unless you explicitly specify\nthat.\n\n\nThe following specifications were found to be incompatible with each other:\n\n\nOutput in format: Requested package -> Available versions\n\n\nPackage cudnn conflicts for:\ntorchvision==0.9.0 -> pytorch[version='>=1.8.0',build=cuda*] -> cudnn[version='>=8.2.1.32,<9.0a0']\ntorchvision==0.9.0 -> cudnn[version='>=7.6.5.32,<8.0a0|>=8.1.0.77,<9.0a0']\n\n\nPackage cudatoolkit conflicts for:\ntorchvision==0.9.0 -> cudatoolkit[version='10.2|10.2.|11.0|11.0.|11.1|11.1.|>=10.1,<10.2|>=10.2,<10.3|>=11.1,<11.2|11.2|11.2.']\ntorchaudio==0.8.0 -> pytorch==1.8.0 -> cudatoolkit[version='10.2|10.2.|11.0|11.0.|11.1|11.1.|11.2|11.2.|>=10.1,<10.2|>=11.1,<11.2|>=10.2,<10.3']\ntorchvision==0.9.0 -> cudnn[version='>=8.1.0.77,<9.0a0'] -> cudatoolkit[version='10.0|10.0.|10.1|10.1.|10.2.|11.|>=11.3,<11.4|9.2|9.2.*']\npytorch==1.8.1 -> cudatoolkit[version='>=10.1,<10.2|>=11.1,<11.2|>=10.2,<10.3']\n\n\nPackage libstdcxx-ng conflicts for:\npython==3.7.9=h7579374_0 -> libffi[version='>=3.3,<3.4.0a0'] -> libstdcxx-ng[version='>=7.3.0|>=7.5.0']\ntorchaudio==0.8.0 -> numpy[version='>=1.11'] -> libstdcxx-ng[version='>=4.9|>=7.3.0|>=9.3.0|>=7.5.0|>=7.2.0']\ntorchvision==0.9.0 -> libstdcxx-ng[version='>=7.5.0']\ntorchvision==0.9.0 -> cudatoolkit[version='>=11.1,<11.2'] -> libstdcxx-ng[version='>=3.4|>=4.9|>=7.3.0|>=9.3.0|>=7.2.0']\npytorch==1.8.1 -> cudatoolkit[version='>=11.1,<11.2'] -> libstdcxx-ng[version='>=4.9|>=7.3.0|>=9.3.0|>=7.2.0']\npytorch==1.8.1 -> libstdcxx-ng[version='>=7.5.0']\ncudatoolkit=11.1 -> libstdcxx-ng[version='>=9.3.0']\n\n\nPackage libgcc-ng conflicts for:\npython==3.7.9=h7579374_0 -> libgcc-ng[version='>=7.3.0']\npython==3.7.9=h7579374_0 -> libffi[version='>=3.3,<3.4.0a0'] -> libgcc-ng[version='>=4.9|>=7.5.0|>=9.4.0|>=9.3.0|>=7.2.0']\n\n\nPackage _libgcc_mutex conflicts for:\npython==3.7.9=h7579374_0 -> libgcc-ng[version='>=7.3.0'] -> _libgcc_mutex[version='|0.1|0.1',build='main|main|conda_forge']\ncudatoolkit=11.1 -> libgcc-ng[version='>=9.3.0'] -> _libgcc_mutex[version='|0.1',build='main|main|conda_forge']\ntorchvision==0.9.0 -> libgcc-ng[version='>=7.5.0'] -> _libgcc_mutex[version='|0.1|0.1',build='main|main|conda_forge']\npytorch==1.8.1 -> _openmp_mutex -> _libgcc_mutex[version='|0.1',build='main|main|conda_forge']\n\n\nPackage pytorch conflicts for:\ntorchvision==0.9.0 -> pytorch[version='1.8.0|>=1.8.0|>=1.8.0',build='cuda*|cpu*']\ntorchaudio==0.8.0 -> pytorch==1.8.0\n\n\nPackage nccl conflicts for:\ntorchvision==0.9.0 -> pytorch==1.8.0 -> nccl[version='>=2.10.3.1,<3.0a0|>=2.7.8.1,<3.0a0|>=2.8.4.1,<3.0a0']\ntorchaudio==0.8.0 -> pytorch==1.8.0 -> nccl[version='>=2.7.8.1,<3.0a0|>=2.8.4.1,<3.0a0']\n\n\nPackage typing-extensions conflicts for:\npytorch==1.8.1 -> typing-extensions\ntorchvision==0.9.0 -> pytorch[version='>=1.8.0',build=cpu*] -> typing-extensionsThe following specifications were found to be incompatible with your system:\n\n\nfeature:\/linux-64::__glibc==2.27=0\n- feature:|@\/linux-64::__glibc==2.27=0\n- cudatoolkit=11.1 -> __glibc[version='>=2.17,<3.0.a0']\n- cudatoolkit=11.1 -> libgcc-ng[version='>=9.3.0'] -> __glibc[version='>=2.17']\n- pytorch==1.8.1 -> cudatoolkit[version='>=11.1,<11.2'] -> __glibc[version='>=2.17|>=2.17,<3.0.a0']\n- torchaudio==0.8.0 -> pytorch==1.8.0 -> __glibc[version='>=2.17|>=2.17,<3.0.a0']\n- torchvision==0.9.0 -> __glibc[version='>=2.17|>=2.17,<3.0.a0']\n\n\nYour installed version is: 2.27\n\n\n\n\n\nCan I solve this problem by adjusting the environment? or should I give up using A100?\n\nThank you so much",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-17T03:41:43.467Z",
                "Answer_score":0,
                "Answer_body":"In the conda environment below,\n\nchannels:\n- anaconda\n- defaults\ndependencies:\n- argon2-cffi=20.1.0=py37h27cfd23_1\n- async_generator=1.10=py37h28b3542_0\n- attrs=20.2.0=py_0\n- backcall=0.2.0=pyhd3eb1b0_0\n- blas=1.0=mkl\n- bleach=3.3.1=pyhd3eb1b0_0\n- ca-certificates=2021.7.5=h06a4308_1\n- certifi=2021.5.30=py37h06a4308_0\n- cffi=1.14.6=py37h400218f_0\n- cycler=0.10.0=py37_0\n- dbus=1.13.18=hb2f20db_0\n- defusedxml=0.7.1=pyhd3eb1b0_0\n- entrypoints=0.3=py37_0\n- expat=2.3.0=h2531618_2\n- fontconfig=2.13.1=h6c09931_0\n- freetype=2.10.4=h5ab3b9f_0\n- glib=2.68.1=h36276a3_0\n- gst-plugins-base=1.14.0=h8213a91_2\n- gstreamer=1.14.0=h28cd5cc_2\n- icu=58.2=he6710b0_3\n- importlib_metadata=3.10.0=hd3eb1b0_0\n- intel-openmp=2021.2.0=h06a4308_610\n- ipykernel=5.3.4=py37h5ca1d4c_0\n- ipython_genutils=0.2.0=pyhd3eb1b0_1\n- jpeg=9b=h024ee3a_2\n- jsonschema=3.2.0=py_2\n- jupyter_client=6.1.12=pyhd3eb1b0_0\n- jupyter_core=4.7.1=py37h06a4308_0\n- jupyterlab_pygments=0.1.2=py_0\n- kiwisolver=1.3.1=py37h2531618_0\n- lcms2=2.12=h3be6417_0\n- ld_impl_linux-64=2.33.1=h53a641e_7\n- libedit=3.1.20191231=h14c3975_1\n- libffi=3.3=he6710b0_2\n- libgcc-ng=9.1.0=hdf63c60_0\n- libpng=1.6.37=hbc83047_0\n- libsodium=1.0.18=h7b6447c_0\n- libstdcxx-ng=9.1.0=hdf63c60_0\n- libtiff=4.1.0=h2733197_1\n- libuuid=1.0.3=h1bed415_2\n- libxcb=1.14=h7b6447c_0\n- libxml2=2.9.10=hb55368b_3\n- lz4-c=1.9.3=h2531618_0\n- markupsafe=1.1.1=py37h14c3975_1\n- matplotlib=3.3.4=py37h06a4308_0\n- matplotlib-base=3.3.4=py37h62a2d02_0\n- mistune=0.8.4=py37h14c3975_1001\n- mkl=2021.2.0=h06a4308_296\n- mkl-service=2.3.0=py37h27cfd23_1\n- mkl_fft=1.3.0=py37h42c9631_2\n- mkl_random=1.2.1=py37ha9443f7_2\n- nbclient=0.5.3=pyhd3eb1b0_0\n- nbconvert=6.1.0=py37h06a4308_0\n- nbformat=5.1.3=pyhd3eb1b0_0\n- ncurses=6.2=he6710b0_1\n- nest-asyncio=1.5.1=pyhd3eb1b0_0\n- notebook=6.4.0=py37h06a4308_0\n- olefile=0.46=py37_0\n- openjpeg=2.3.0=h05c96fa_1\n- openssl=1.1.1k=h27cfd23_0\n- pandocfilters=1.4.3=py37h06a4308_1\n- parso=0.8.2=pyhd3eb1b0_0\n- pcre=8.44=he6710b0_0\n- pickleshare=0.7.5=pyhd3eb1b0_1003\n- pip=20.2.4=py37_0\n- prometheus_client=0.11.0=pyhd3eb1b0_0\n- ptyprocess=0.7.0=pyhd3eb1b0_2\n- pycparser=2.20=py_2\n- pyparsing=2.4.7=pyhd3eb1b0_0\n- pyqt=5.9.2=py37h05f1152_2\n- pyrsistent=0.17.3=py37h7b6447c_0\n- python=3.7.9=h7579374_0\n- python-dateutil=2.8.1=pyhd3eb1b0_0\n- qt=5.9.7=h5867ecd_1\n- readline=8.0=h7b6447c_0\n- send2trash=1.5.0=pyhd3eb1b0_1\n- setuptools=50.3.0=py37hb0f4dca_1\n- sip=4.19.8=py37hf484d3e_0\n- six=1.15.0=py37h06a4308_0\n- sqlite=3.33.0=h62c20be_0\n- terminado=0.9.4=py37h06a4308_0\n- testpath=0.5.0=pyhd3eb1b0_0\n- tk=8.6.10=hbc83047_0\n- tornado=6.0.4=py37h7b6447c_1\n- traitlets=5.0.5=pyhd3eb1b0_0\n- wcwidth=0.2.5=py_0\n- webencodings=0.5.1=py37_1\n- wheel=0.35.1=py_0\n- xz=5.2.5=h7b6447c_0\n- zeromq=4.3.4=h2531618_0\n- zlib=1.2.11=h7b6447c_3\n- zstd=1.4.9=haebb681_0\n- pip:\n- absl-py==0.12.0\n- adal==1.2.7\n- alabaster==0.7.12\n- antlr4-python3-runtime==4.8\n- azure-common==1.1.27\n- azure-core==1.16.0\n- azure-graphrbac==0.61.1\n- azure-mgmt-authorization==0.61.0\n- azure-mgmt-containerregistry==8.0.0\n- azure-mgmt-core==1.3.0\n- azure-mgmt-keyvault==9.0.0\n- azure-mgmt-resource==13.0.0\n- azure-mgmt-storage==11.2.0\n- azureml-core==1.32.0\n- babel==2.9.0\n- backports-tempfile==1.0\n- backports-weakref==1.0.post1\n- boto3==1.9.246\n- botocore==1.12.246\n- cachetools==4.2.2\n- chardet==4.0.0\n- coloredlogs==14.0\n- contextlib2==0.6.0.post1\n- cryptography==3.4.7\n- datasets==1.4.1\n- decorator==5.0.7\n- dill==0.3.3\n- docformatter==1.3\n- docker==4.4.4\n- docutils==0.15.2\n- emoji==0.5.4\n- filelock==3.0.12\n- flake8==3.7.8\n- flake8-bugbear==19.8.0\n- fsspec==2021.4.0\n- fvcore==0.1.1.post20200716\n- gitdb2==2.0.5\n- gitpython==3.0.3\n- google-auth==1.30.0\n- google-auth-oauthlib==0.4.4\n- grpcio==1.37.0\n- huggingface-hub==0.0.2\n- humanfriendly==9.1\n- hydra-core==1.0.6\n- idna==2.10\n- imagesize==1.2.0\n- importlib-metadata==4.0.1\n- importlib-resources==5.1.2\n- ipython==7.19.0\n- isodate==0.6.0\n- jedi==0.18.0\n- jeepney==0.7.0\n- jinja2==2.11.3\n- jmespath==0.10.0\n- joblib==0.14.1\n- jsonlines==1.2.0\n- jsonpickle==2.0.0\n- markdown==3.3.4\n- markdown-it-py==0.5.8\n- mccabe==0.6.1\n- more-itertools==8.7.0\n- msrest==0.6.21\n- msrestazure==0.6.4\n- multiprocess==0.70.11.1\n- myst-parser==0.12.10\n- ndg-httpsclient==0.5.1\n- nltk==3.4.5\n- numpy==1.17.5\n- oauthlib==3.1.0\n- omegaconf==2.0.6\n- packaging==20.9\n- pandas==1.1.1\n- pathspec==0.8.1\n- pexpect==4.7.0\n- pillow==8.1.1\n- pluggy==0.13.1\n- portalocker==2.3.0\n- prompt-toolkit==3.0.18\n- protobuf==3.15.8\n- py==1.10.0\n- py-gfm==1.0.2\n- py-rouge==1.1\n- pyarrow==4.0.0\n- pyasn1==0.4.8\n- pyasn1-modules==0.2.8\n- pycodestyle==2.5.0\n- pyflakes==2.1.1\n- pygments==2.8.1\n- pyjwt==2.1.0\n- pyopenssl==20.0.1\n- pytest==5.3.2\n- pytest-datadir==1.3.1\n- pytest-regressions==2.1.1\n- pytz==2021.1\n- pyyaml==5.4\n- pyzmq==18.1.0\n- regex==2020.1.8\n- requests==2.25.1\n- requests-mock==1.7.0\n- requests-oauthlib==1.3.0\n- rsa==4.7.2\n- ruamel-yaml==0.17.4\n- ruamel-yaml-clib==0.2.6\n- s3transfer==0.2.1\n- scikit-learn==0.23.1\n- scipy==1.4.1\n- secretstorage==3.3.1\n- sh==1.12.14\n- smmap==4.0.0\n- smmap2==3.0.1\n- snowballstemmer==2.1.0\n- sphinx==2.2.2\n- sphinx-autodoc-typehints==1.10.3\n- sphinx-rtd-theme==0.4.3\n- sphinxcontrib-applehelp==1.0.2\n- sphinxcontrib-devhelp==1.0.2\n- sphinxcontrib-htmlhelp==1.0.3\n- sphinxcontrib-jsmath==1.0.1\n- sphinxcontrib-qthelp==1.0.3\n- sphinxcontrib-serializinghtml==1.1.4\n- subword-nmt==0.3.7\n- tabulate==0.8.9\n- tensorboard==2.3.0\n- tensorboard-plugin-wit==1.8.0\n- tensorboardx==2.1\n- termcolor==1.1.0\n- threadpoolctl==2.1.0\n- tokenizers==0.10.2\n- torch==1.8.1\n- torchtext==0.9.1\n- tqdm==4.36.1\n- typing-extensions==3.7.4.1\n- unidecode==1.1.1\n- untokenize==0.1.1\n- urllib3==1.25.11\n- websocket-client==0.56.0\n- websocket-server==0.4\n- werkzeug==1.0.1\n- xxhash==2.0.2\n- yacs==0.1.8\n- zipp==3.4.1\n\nI implemented conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch, and export to yml file.\nThen in order to create job to computing cliuster I implemented below\n\n #A100ver\n cluster_name = 'high-A100'\n gpu_name = 'Standard_ND96asr_v4'\n experiment_name = 'speaker_identification_training_A100'\n hyperparameters = [\n     '--max_train_time', '172800'\n ]\n script_folder = '.\/script_folder'\n    \n # workspace\n ws = Workspace.from_config()\n print(ws.name, ws.location, ws.resource_group, sep='\\t')\n    \n # compute cluster\n compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", cluster_name)\n compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", gpu_name)\n    \n if compute_name in ws.compute_targets:\n     compute_target = ws.compute_targets[compute_name]\n     if compute_target and type(compute_target) is AmlCompute:\n         print('found compute target. just use it. ' + compute_name)\n else:\n     print('creating a new compute target...')\n     provisioning_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n                                                                 min_nodes=compute_min_nodes,\n                                                                 max_nodes=compute_max_nodes)\n     compute_target = ComputeTarget.create(\n         ws, compute_name, provisioning_config)\n    \n env = Environment.load_from_directory(path=\".\/.azureml6\/\")\n exp = Experiment(workspace=ws,name=experiment_name)\n command = \"pwd && pip install azure-storage-blob && python main.py\"\n # run\n src = ScriptRunConfig(source_directory=script_folder,\n  command=command,\n  compute_target=compute_target,\n  environment=env\n )\n run = exp.submit(config=src)\n\n\n\n\nActually I found that in order to use A100, pytoch version should be 1.8.1+cu111. But by implementing conda install pytorch==1.8.1 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=11.1 -c pytorch -c conda-forge, I got the error like below\n\nCollecting package metadata (current_repodata.json): done\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\nSolving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\nCollecting package metadata (repodata.json): done\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\nSolving environment: |\nFound conflicts! Looking for incompatible packages.\nThis can take several minutes. Press CTRL-C to abort.\nfailed\n\n\nUnsatisfiableError: The following specifications were found\nto be incompatible with the existing python installation in your environment:\n\n\nSpecifications:\n\n\npytorch==1.8.1 -> python[version='2.7.|3.5.|3.6.|3.6.12|3.6.12|3.7.10|3.7.10|>=2.7,<2.8.0a0|>=3.5,<3.6.0a0|>=3.5|>=3.7|>=3.6,<3.7|3.7.9|3.6.9|3.6.9|3.6.9|3.6.9|3.4.',build='1_73_pypy|2_73_pypy|3_73_pypy|4_73_pypy|1_73_pypy|0_73_pypy|5_73_pypy|5_73_pypy|0_73_pypy']\n- torchaudio==0.8.0 -> python[version='2.7.|3.5.|3.6.|>=2.7,<2.8.0a0|>=3.5,<3.6.0a0|3.4.|3.9.*']\n\n\nYour python: python==3.7.9=h7579374_0\n\n\nIf python is on the left-most side of the chain, that's the version you've asked for.\nWhen python appears to the right, that indicates that the thing on the left is somehow\nnot available for the python version you are constrained to. Note that conda will not\nchange your python version to a different minor version unless you explicitly specify\nthat.\n\n\nThe following specifications were found to be incompatible with each other:\n\n\nOutput in format: Requested package -> Available versions\n\n\nPackage cudnn conflicts for:\ntorchvision==0.9.0 -> pytorch[version='>=1.8.0',build=cuda*] -> cudnn[version='>=8.2.1.32,<9.0a0']\ntorchvision==0.9.0 -> cudnn[version='>=7.6.5.32,<8.0a0|>=8.1.0.77,<9.0a0']\n\n\nPackage cudatoolkit conflicts for:\ntorchvision==0.9.0 -> cudatoolkit[version='10.2|10.2.|11.0|11.0.|11.1|11.1.|>=10.1,<10.2|>=10.2,<10.3|>=11.1,<11.2|11.2|11.2.']\ntorchaudio==0.8.0 -> pytorch==1.8.0 -> cudatoolkit[version='10.2|10.2.|11.0|11.0.|11.1|11.1.|11.2|11.2.|>=10.1,<10.2|>=11.1,<11.2|>=10.2,<10.3']\ntorchvision==0.9.0 -> cudnn[version='>=8.1.0.77,<9.0a0'] -> cudatoolkit[version='10.0|10.0.|10.1|10.1.|10.2.|11.|>=11.3,<11.4|9.2|9.2.*']\npytorch==1.8.1 -> cudatoolkit[version='>=10.1,<10.2|>=11.1,<11.2|>=10.2,<10.3']\n\n\nPackage libstdcxx-ng conflicts for:\npython==3.7.9=h7579374_0 -> libffi[version='>=3.3,<3.4.0a0'] -> libstdcxx-ng[version='>=7.3.0|>=7.5.0']\ntorchaudio==0.8.0 -> numpy[version='>=1.11'] -> libstdcxx-ng[version='>=4.9|>=7.3.0|>=9.3.0|>=7.5.0|>=7.2.0']\ntorchvision==0.9.0 -> libstdcxx-ng[version='>=7.5.0']\ntorchvision==0.9.0 -> cudatoolkit[version='>=11.1,<11.2'] -> libstdcxx-ng[version='>=3.4|>=4.9|>=7.3.0|>=9.3.0|>=7.2.0']\npytorch==1.8.1 -> cudatoolkit[version='>=11.1,<11.2'] -> libstdcxx-ng[version='>=4.9|>=7.3.0|>=9.3.0|>=7.2.0']\npytorch==1.8.1 -> libstdcxx-ng[version='>=7.5.0']\ncudatoolkit=11.1 -> libstdcxx-ng[version='>=9.3.0']\n\n\nPackage libgcc-ng conflicts for:\npython==3.7.9=h7579374_0 -> libgcc-ng[version='>=7.3.0']\npython==3.7.9=h7579374_0 -> libffi[version='>=3.3,<3.4.0a0'] -> libgcc-ng[version='>=4.9|>=7.5.0|>=9.4.0|>=9.3.0|>=7.2.0']\n\n\nPackage _libgcc_mutex conflicts for:\npython==3.7.9=h7579374_0 -> libgcc-ng[version='>=7.3.0'] -> _libgcc_mutex[version='|0.1|0.1',build='main|main|conda_forge']\ncudatoolkit=11.1 -> libgcc-ng[version='>=9.3.0'] -> _libgcc_mutex[version='|0.1',build='main|main|conda_forge']\ntorchvision==0.9.0 -> libgcc-ng[version='>=7.5.0'] -> _libgcc_mutex[version='|0.1|0.1',build='main|main|conda_forge']\npytorch==1.8.1 -> _openmp_mutex -> _libgcc_mutex[version='|0.1',build='main|main|conda_forge']\n\n\nPackage pytorch conflicts for:\ntorchvision==0.9.0 -> pytorch[version='1.8.0|>=1.8.0|>=1.8.0',build='cuda*|cpu*']\ntorchaudio==0.8.0 -> pytorch==1.8.0\n\n\nPackage nccl conflicts for:\ntorchvision==0.9.0 -> pytorch==1.8.0 -> nccl[version='>=2.10.3.1,<3.0a0|>=2.7.8.1,<3.0a0|>=2.8.4.1,<3.0a0']\ntorchaudio==0.8.0 -> pytorch==1.8.0 -> nccl[version='>=2.7.8.1,<3.0a0|>=2.8.4.1,<3.0a0']\n\n\nPackage typing-extensions conflicts for:\npytorch==1.8.1 -> typing-extensions\ntorchvision==0.9.0 -> pytorch[version='>=1.8.0',build=cpu*] -> typing-extensionsThe following specifications were found to be incompatible with your system:\n\n\nfeature:\/linux-64::__glibc==2.27=0\n- feature:|@\/linux-64::__glibc==2.27=0\n- cudatoolkit=11.1 -> __glibc[version='>=2.17,<3.0.a0']\n- cudatoolkit=11.1 -> libgcc-ng[version='>=9.3.0'] -> __glibc[version='>=2.17']\n- pytorch==1.8.1 -> cudatoolkit[version='>=11.1,<11.2'] -> __glibc[version='>=2.17|>=2.17,<3.0.a0']\n- torchaudio==0.8.0 -> pytorch==1.8.0 -> __glibc[version='>=2.17|>=2.17,<3.0.a0']\n- torchvision==0.9.0 -> __glibc[version='>=2.17|>=2.17,<3.0.a0']\n\n\nYour installed version is: 2.27\n\n\n\n\n\nCan I solve this problem by adjusting the environment? or should I give up using A100?\n\nThank you so much",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Question: how to define custom Module in Designer",
        "Question_creation_time":1594757308663,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/46908\/question-how-to-define-custom-module-in-designer.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":40,
        "Question_score":2,
        "Question_body":"How do I define a custom Module in Azure ML Designer? In Studio (classic), I found this documentation:\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/custom-r-modules\n\nbut I have yet to find something similar for the modern version of Azure ML. The closest thing I've found is Execute Python Script, but that has several limitations:\n\nUnnecessary overhead from casting to a pandas DataFrame and back to the internal data structure\n\n\nNo ability to add parameters\n\n\nDifficult to reuse\n\n\nCan't customize number of ports, module name, etc.\n\nAlso, is it possible to upstream any custom Modules I write? For example, there are currently no Data Transforms for handling timestamps, which I imagine are common in many datasets. I would love to contribute one upstream so that other users can use it, but I haven't yet found a GitHub repo for it.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-15T08:35:00.713Z",
                "Answer_score":2,
                "Answer_body":"Hi @AdamStewart-2203 , Thanks for your feedback.\nThis is Blanca, working on AML Designer.\nI'd love to set up a call with you to understand our scenario and introduce our new features.\nPlease contact keli19@microsoft.com, since I serched your name but not sure to contact whom....",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-03-12T13:32:32.347Z",
                "Answer_score":0,
                "Answer_body":"Hi, I have the same question. However, it seems that the solution has not been communicated via this blog.\nCould you please share the solution? Many thanks, Koen",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-08-16T11:25:49.477Z",
                "Answer_score":0,
                "Answer_body":"I agree with Koen.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"how to delete Azure ML real-time endpoints which is in transition state",
        "Question_creation_time":1628858328673,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/513012\/how-to-delete-azure-ml-real-time-endpoints-which-i.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"Hi,\n\nI have made deployment of the model from the AutoML experiment, due to the issue in the resources associated. Deployment has failed.\n\nBut the real-time endpoint has been in the transition state for few hours, I can't delete it and the model registered along with it due to this. How can I force delete in this case. Please provide a solution.\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-16T11:16:36.937Z",
                "Answer_score":0,
                "Answer_body":"Thank you for the response @romungi-MSFT. I have left the feedback to the team.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"No Data being exported from 'Export Data' module in Azure ML",
        "Question_creation_time":1629008927050,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/514067\/no-data-being-exported-from-39export-data39-module.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\n\nI am trying to export data from Azure ML to an Azure SQL Database using the 'Export Data' module but the log file contains the following messages and no data is exported to the database.\n\n\"Not exporting to run RunHistory as the exporter is either stopped or there is no data\"\n\n\"Process exiting with code: 0\n\nThere is definitely data flowing to the 'Export Data' module from an 'Execute R Script' module as I have checked the Result dataset.\n\nWould appreciate some assistance.\n\nThank you.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-16T09:39:07.877Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nI have resolved this issue. I had set the export table to be dbo.TestTable rather than just TestTable. As the table dbo.TestTable did not exist the 'Export module' created it in the dbo schema so the table name effectively became dbo.dbo.TestTable.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Is their limit on number of records in dataset for Azure automated ML timeserires forecasting",
        "Question_creation_time":1628484429713,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/505948\/is-their-limit-on-number-of-records-in-dataset-for.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Hi\n\nI am facing issue with number of records while creating datasets automated ML timeseries forecasting, It is loading only first 10000 records rest of the records are ignored.\n\nIs their any limit on number of records in the datasets for Azure automated ML timeseries forecasting.\n\n\n\n\nIf there limits in number of records , how to increase number of records\n\nThanks\nRamabadran",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Not able to consume predict-auto-price endpoint",
        "Question_creation_time":1628625065883,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/508671\/not-able-to-consume-predict-auto-price-endpoint.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi,\nI was following Create a Regression Model with Azure Machine Learning Designer\n\nI reached to deploy and created an endpoint for the service. But when I click consume, it keeps on loading and after sometime page become unresponsive. What can be the possible reasons for this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-12T05:53:31.667Z",
                "Answer_score":1,
                "Answer_body":"@devkapilbansal This issue is now fixed. A hotfix was deployed to fix this. Please reload the page and check again.\n\nPlease feel free to accept the same as answer if it helped.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How to register Managed SQL Instance as a datastore in Azure Machine Learning workspace?",
        "Question_creation_time":1603811671907,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/141428\/how-to-register-managed-sql-instance-as-a-datastor.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":2,
        "Question_body":"I am trying to connect a database within the Managed SQL Instance as a datastore. Managed Instance is not among the datastore type options so I tried to select the Azure SQL database and \"enter manually\" option for account selection. When I enter the full hostname of the managed instance which is something like \"xxx-xxxx-xxx-xxxx-sql.45bsa4569.database.windows.net\" it complaints due to dot \".\" that comes after 'sql'. Since I do not have control over that part of the hostname (Azure adds something like '.45bsa4569' on the managed instance name itself) I do not know how to fix it.\n\nQuestions:\n1. Is it possible to register a managed instance as a datastore by using the method above? (Azure SQL database and 'enter manually' options).\n2. If possible, how to handle the '.' in the host name so that it does not complain?\n\nFYI: The managed instance is behind a vnet so I am using service principal to authenticate.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-28T12:16:20.347Z",
                "Answer_score":0,
                "Answer_body":"@EnginKapti-9217 Thanks for the question. Please follow the repo and snapshot.\n\nSupported data storage types:https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data#supported-data-storage-service-types\n\nAzure SQL MI is not officially supported per doc .\nIt's possible to create a datastore on Azure SQL MI, by providing connection string to API register_azure_sql_database, but unexpected behavior may occur.\n\nWe have forwarded to the product team and AzureML data team is looking into this issue, and will update if we find any work around.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-08-12T12:59:15.757Z",
                "Answer_score":1,
                "Answer_body":"@azure-machine-learning",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-08-12T12:59:24.057Z",
                "Answer_score":0,
                "Answer_body":"[azure-machine-learning]",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Terminal of computer instance keeps loading and at the same time VS code cannot connect to it",
        "Question_creation_time":1625832970633,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/469700\/terminal-of-computer-instance-keeps-loading-and-at.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"It happens quite often, sometimes after I just started the computer instance, and sometimes after I used it for a while. Then I have to restart the computer instance.\nIt happens not only to one but to different computer instances.\nPlease see the screenshots below:\n\nterminal keeps loading\n\n\n\nVS code cannot connect to the computer instance\n\n\nIn the end the webpage of Notebooks shows\n\"Terminal not available\nCurrent terminal is encountering some issues, please switch compute or restart your current compute and retry.\"\nwith some message as below:\n\n\nAnd VS codes just keep trying \"Installing VS Code server on <computer instance> Retry - <some number>\"\n\nCould anyone please tell me what the problem is or solve this issue in the background? Thanks a lot!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-10T03:54:51.76Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us here. But this looks like a VS code side issue more.\n\nYou can ask questions and search for answers on Stack Overflow and enter issues and feature requests directly in our GitHub repository.\n\nIf you'd like to contact a professional support engineer, you can open a ticket with the Microsoft assisted support team.\n\nSorry for the inconvenience.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Deploy azureml model service principal authentication",
        "Question_creation_time":1628163912977,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/502812\/deploy-azureml-model-authentication.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi, I would like to implement a way to automate model deployment from an AzureML pipeline. My issue is that I keep having to manually authenticate when deploying a model. The entire pipeline works fine using service principal authentication, except the model deployment part.\n\nI'm using the following code:\n\n ws = Workspace(subscription_id=subscription_id, resource_group=resource_group, workspace_name=workspace_name, auth=svc_pr)\n    \n model = model.deploy(overwrite=True, name=model_name, deployment_target=cpu_cluster, show_output=True, workspace=ws, models=[model], inference_config=inference_config, deployment_config=deployment_config)\n\n\n\nIs it possible to do model deployment from a pipeline without having to do the token authentication in the deployment logs?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-05T22:11:01.817Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. If you enabled token-based authentication, users have to present token to the web service to access it. The token expires after a specified time-frame and needs to be refreshed to continue making calls. Please review Configure Authentication for more details. Hope this helps!",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Automated ML model - endPoint goes for toss",
        "Question_creation_time":1628591307843,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/507900\/automated-ml-model-endpoint-goes-for-toss.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi\n\nI created \"Automated ML \" model for the given set of data. After creating the model, I deployed model as ACI , while test the model under \"Home > endpoint>modelname, I am facing below problem\n\nWhole page hangs indefinitely , refer to attach snap shot\n\n\nSometime i get he page , input like to forecast time is not editable refer to snapshot\n\n\n\n\n\nThanks in advance for the support\nRamabadran",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-10T13:04:11.69Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. What browser are you using? Have you tried using a different browser?",
                "Answer_comment_count":5,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"My ACI endpoint in stuck in transitionning for hours, can't delete the model",
        "Question_creation_time":1628023814677,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/500472\/my-aci-endpoint-in-stuck-in-transitionning-for-hou.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"My endpoint is still in transitionning after hours. No logs are available...I can't delete the model either since it's attached to the endpoint..\nHow can I force the deletion \/ stop the deployment ?\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-04T00:55:05.55Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nDeployment stuck on transitioning could be due to container startup issues caused by failure to load model, improper deployment configuration, or code issues in score.py. Could you please give us some further information so we can help:\n\nwhich compute target did you attempt to deploy, e.g. ACI or AKS\n\n\n\n\nwhat's your model size and deployment configuration\n\nwhat was the error messages?\n\nNote local debug usually will help you identify one of above issues mentioned. https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment-local\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML MSI deployment over ARM Templates enables purge protection on Key Vault",
        "Question_creation_time":1627468001263,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/492841\/azure-ml-msi-deployment-over-arm-templates-enables.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":2,
        "Question_body":"I have discovered lately that when you deploy an Azure ML instance from the ARM Template, the MSI will override the purge protection settings of the Key Vault. It will enable purge protection on the Key Vault. This is not the behavior that I am looking for, because when trying to deploy it again, the template will fail saying that the Key Vault with the name already exists and you can't deleted before the retention period. This was my conclusion after doing several tests. Is my assumption correct?\n\nIf you deploy the Azure ML instance manually and select the Key Vault, it will keep the disable purge settings. Any ideas how can we keep purge disabled hier?\n\nThe Azure ML properties that we used are mentioned bellow:\n\n   {\n     \"type\": \"Microsoft.MachineLearningServices\/workspaces\",\n     \"apiVersion\": \"2020-09-01-preview\",\n     \"name\": \"[variables('machineLearningWorkspaceName')]\",\n     \"location\": \"[parameters('location')]\",\n     \"identity\": {\n       \"type\": \"[parameters('amlManagedIdentityOption')]\"\n     },\n     \"dependsOn\": [\n       \"[resourceId('Microsoft.Storage\/storageAccounts', variables('storageAccountName'))]\",\n       \"[resourceId('Microsoft.Insights\/components', variables('applicationInsightsName'))]\",\n       \"[resourceId('Microsoft.ContainerRegistry\/registries', variables('containerRegistryName'))]\"\n     ],\n     \"tags\": \"[parameters('resourceTags')]\",\n     \"properties\": {\n       \"friendlyName\": \"[variables('machineLearningWorkspaceName')]\",\n       \"storageAccount\": \"[variables('storageAccount')]\",\n       **\"keyVault\": \"[variables('keyVault')]\",**\n       \"applicationInsights\": \"[variables('applicationInsights')]\",\n       \"containerRegistry\": \"[ variables('containerRegistry')]\",\n       \"adbWorkspace\": \"[variables('adbWorkSpace')]\",\n       \"hbiWorkspace\": \"[parameters('confidential_data')]\",\n       \"allowPublicAccessWhenBehindVnet\": \"[parameters('allowPublicAccessWhenBehindVnet')]\"\n     }\n   }\n\n\n\n\n\nOn the Key Vault created also via ARM we have:\n\n         \"properties\": {\n                 \"enabledForDeployment\": \"[parameters('enabledForDeployment')]\",\n                 \"enabledForTemplateDeployment\": \"[parameters('enabledForTemplateDeployment')]\",\n                 \"enabledForVolumeEncryption\": \"[parameters('enableVaultForVolumeEncryption')]\",\n                 \"softDeleteRetentionInDays\": 7,\n                 \"tenantId\": \"[subscription().tenantId]\",\n                 \"copy\": [\n                     {\n                         \"name\": \"accessPolicies\",\n                         \"count\": \"[length(parameters('userObjectId'))]\",\n                         \"input\": {\n                             \"tenantId\": \"[subscription().tenantId]\",\n                             \"objectId\": \"[parameters('userObjectId')[copyIndex('accessPolicies')].Id]\",\n                             \"permissions\": \"[parameters('userObjectId')[copyIndex('accessPolicies')].Permissions]\"\n                         }\n }",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-29T19:22:12.813Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for your feedback. Soft delete is enabled by default on new key vaults that are created with a new workspace (without bringing existing key vault).",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Save trained model from AutoML\/Designer as pickle file to disk - Azure ML",
        "Question_creation_time":1617893768667,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/349669\/save-trained-model-from-automldesigner-as-pickle-f.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\n\nI want to save trained machine learning model as pickle file(.pkl) to disk which is trained in AutoML\/Designer.\n\nPlease let me know is there any way to do that?\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-08T15:17:00.257Z",
                "Answer_score":0,
                "Answer_body":"Hi @Bhaskar11-9991\n\nRefer the below URL it may helps you.\nhttps:\/\/docs.microsoft.com\/en-us\/answers\/questions\/297882\/how-to-use-a-model-trained-by-azure-automl.html\n\n\n\n\nIf the Answer is helpful, please click Accept Answer and up-vote, this can be beneficial to other community members.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-04-08T17:20:45.26Z",
                "Answer_score":0,
                "Answer_body":"@Bhaskar11-9991 Thanks, Please follow this document: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-model-designer. Basically you can register a trained model in Designer bring it out with SDK\/CLI to deploy it.\n\nSharing a reference notebook from @Nicholas Moore: https:\/\/github.com\/nfmoore\/aml-designer-iot-edge\/blob\/main\/00-containerize-designer-model.ipynb.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How can I access a FileDataset without filling local disk?",
        "Question_creation_time":1628529752433,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/506820\/how-can-i-access-a-filedataset-without-filling-loc.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello!\n\nI'm setting up a pipeline for machine learning. Reading the docs I understood that when I pass my FileDataset as_mount it is mounted, similar to mounting an external drive. However, three hours into my training, my pipeline crashed, out of storage. It seems that as_mount actually is downloading per file, rather than the entire Dataset, but still uses local disk space. Is this correct? If so, how can I train on a FileDataset that is too large for any of the available compute options?\n\nDavid",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-10T12:31:26.553Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. When you mount, only the data files used by your script are loaded at the time of processing. When you download, all files referenced by the dataset will be downloaded to the compute target. If your data size exceeds the compute disk size, we recommend mounting (which reads only a subset of the data). Based on your post, you may need to use a larger compute instance to handle your workload. Please review mount vs download documentation. Hope this helps.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unable to test my ML model created with Azure Automated ML model endpoints",
        "Question_creation_time":1628598159740,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/507969\/unable-to-test-my-ml-model-created-with-azure-auto.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi\n\nI am unable to test the model (Microsoft azure Machine learning ->endpoints->modelname ->Test , even though some model i could execute on 09-Aug-2021 late evening. Please help to resolve issue\n\n\n\n\nThanks\nRamabadran",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-10T13:07:13.11Z",
                "Answer_score":0,
                "Answer_body":"Please follow-up on this thread. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Integrate Azure ML with Azure Data Factory",
        "Question_creation_time":1627308102200,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/489630\/integrate-azure-ml-with-azure-data-factory.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hello,\n\nI have an Azure ML Batch Endpoint that successfully submits. I have made the input dataset a parameter. Now, ideally, I'd want to do the following:\n- Execute the Endpoint from Azure Data Factory, while passing in a dynamic dataset that exists on Blob Storage.\n- Receive the output dataset and continue consuming the returned dataset with other activities on Azure Data Factory.\n\nSo far, I've had no luck or access to clear documentation that can help me achieve this functionality:\n- I followed this tutorial but it seems you can use this Activity on Azure Data Factory only to trigger an experiment on Azure ML and this doesn't mention passing in datasets from Azure Data Factory.\n- I set up my batch endpoint using this tutorial and the only way this mentions the consumption of an endpoint is either manually through Azure ML or through the REST Api.\n\nOverall, I'd like to know the feasibility of my desired solution. The worst case seems that I'd have to write a Python script that can create datasets on Azure ML, then trigger the batch endpoint pipeline (using the REST Api), and then re-upload the model output on a desired location in Blob Storage, and run this Python script on a Execute Batch Activity.\n\nAdditionally, I was wondering if it's possible to get sample code for the REST API code for consuming the batch endpoint like I did for a real-time endpoint.\n\nThanks,\nVarun.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How to solve the \"Stopping site because it is not healthy\" when deploying ml model into an Azure Function?",
        "Question_creation_time":1616116277480,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/321539\/how-to-solve-the-34stopping-site-because-it-is-not.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hello there!\nWhile trying to complete following tutorial I faced following issue:\n\"Stopping site mymlfunction because it is not healthy.\"\n\nBelow the complete log lines I see:\n\n\"\n2021-03-18T23:25:12.553Z INFO - Logging is not enabled for this container. Please use https:\/\/aka.ms\/linux-diagnostics to enable logging to see container logs here.\n2021-03-18T23:25:17.915Z INFO - Initiating warmup request to container mymlfunction_0_216cb03b for site mymlfunction\n2021-03-18T23:25:33.337Z INFO - Waiting for response to warmup request for container mymlfunction_0_216cb03b. Elapsed time = 15.4220545 sec\n2021-03-18T23:25:45.612Z INFO - Container mymlfunction_0_216cb03b for site mymlfunction initialized successfully and is ready to serve requests.\n2021-03-18T23:25:45.614Z INFO - Initiating warmup request to container mymlfunction_0_216cb03b_middleware for site mymlfunction\n2021-03-18T23:25:47.009Z INFO - Container mymlfunction_0_216cb03b_middleware for site mymlfunction initialized successfully and is ready to serve requests.\n2021-03-18T23:25:52.051Z ERROR - Container for mymlfunction_0_216cb03b site mymlfunction is unhealthy, Stopping site.\n2021-03-18T23:25:52.056Z INFO - Stopping site mymlfunction because it is not healthy.\n\"\n\nWhen this happens, the system falls into a loop trying to initialize the Azure Function but fails since due to the error above just right after saying that the container was successfully deployed.\n\nI was able to complete the majority of the tutorial until the last step which configures the Azure Function to use my ACR user and password but still seeing same issue, see last step of the tutorial in link below:\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/azure-cache-for-redis\/cache-ml#deploy-image-as-a-web-app\n\nThe container to be deployed was build from Azure ML workspace using following python script:\n\n\"\nfrom azureml.contrib.functions import package\nfrom azureml.contrib.functions import HTTP_TRIGGER\nfrom azureml.core import Workspace\nfrom azureml.core.model import Model\n\nws = Workspace.from_config()\nmodel = Model(ws, 'sklearn_mnist')\n\nmodel_package = package(ws, [model], inference_config, functions_enabled=True, trigger=HTTP_TRIGGER)\nmodel_package.wait_for_creation(show_output=True)\n\nDisplay the package location\/ACR path\n\nprint(model_package.location)\n\"\n\nCan somebody help me resolve this issue?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-19T12:38:01.353Z",
                "Answer_score":0,
                "Answer_body":"@JuanPoncedeLeon-1388 Thanks for the question. Can you please share the full log details. The deployment of a ML model to Azure Functions is in preview. The ability to package model (aka containerize the model) via Azure ML and deploying to Azure Functions, you can enable app insights, model telemetry etc. to check the full log details.\nHere is the doc:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-functions",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-08-09T13:23:48.96Z",
                "Answer_score":0,
                "Answer_body":"Hi guys, any luck with this issue? I'm facing the same error when trying to follow this tutorial https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-functions on how to deploy ML models to Functions.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Experiment running became extremely slow",
        "Question_creation_time":1628240565393,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/503939\/experiment-running-became-extremely-slow.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I'm running some tutorials that involves using SDK to perform ML tasks. Everything was working fine till yesterday where the tasks become running very slowly and python code always ends up with Timed Out error code.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-07T18:11:04.787Z",
                "Answer_score":0,
                "Answer_body":"Hi @ramr-msft ,\n\nThe problem is that i'm not getting an error. The tasks keeps running for extremely long time till the script on notebook throws a timed out error message.\n\nI'm going through some tutorial that I'm running for the second time. Everything was working fine until a couple of days back till this degradation in performance becomes very noticeable.\n\nRegistering a small dataset (2 Csv files of 1000 rows and 10 columns is taking 7 to 10 minutes. A datadrift running on 2-node cluster (STANDARD_DS11_V2) is taking around 20 mns as shown in the screenshot below:\n\nAny explanation of the long running time.\nThanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Voice\/Speech to Text Train Model",
        "Question_creation_time":1627330507383,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/490113\/voicespeech-to-text-train-model.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi.\n\nSo I would like to create a model that 'listens' to audio from movies\/podcasts (with subtitles) then returns the text transcript from it. Problem is, it's in a language not supported by Azure (or most of the big cloud providers). How would I go about and, from scratch, build a model that is trained on the audio from a new language? The input audio all will have subtitles or captions.\n\nI tried Azure ML studio but I couldn't create datasets with audio files. Not sure if I missed something there. Also tried Speech studio but it only supports a select number of languages. Would that be possible at all?\n\nAny suggestions would be appreciated. Thanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-04T23:39:40.253Z",
                "Answer_score":0,
                "Answer_body":"@NathanCarns-0092 Yes, you are correct, to develop a model for speech to text we need a deep learning model here. This is out of the scope of Azure Machine Learning Studio(classic). But I think Azure Machine Learning service should support it, please refer to this: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-deep-learning-vs-machine-learning#machine-translation\n\nI have found one post which may help: https:\/\/towardsdatascience.com\/audio-deep-learning-made-simple-automatic-speech-recognition-asr-how-it-works-716cfce4c706\n\nMoreover, I have forwarded your feedback to see any plan here for Nigerian in Azure.\n\nThanks.\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure sql database Machine learning",
        "Question_creation_time":1625235917747,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/461404\/azure-sql-database-machine-learning.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"Hi Team,\n\nI would like to know, do we have an option to use Machine learning with Azure SQL database or is it only available with Azure SQL managed instance\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-02T15:08:50.343Z",
                "Answer_score":0,
                "Answer_body":"Hi @AnashwarN-4785\n\nMachine Learning Services is a feature of Azure SQL Managed Instance that provides in-database machine learning, supporting both Python and R scripts. The feature includes Microsoft Python and R packages for high-performance predictive analytics and machine learning.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/azure-sql\/managed-instance\/machine-learning-services-overview\nhttps:\/\/docs.microsoft.com\/en-us\/sql\/machine-learning\/?view=sql-server-ver15\n\nKey differences between Machine Learning Services in Azure SQL Managed Instance and SQL Server\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/azure-sql\/managed-instance\/machine-learning-services-differences\n\n\n\n\n\n\nIf the Answer is helpful, please click Accept Answer and up-vote, this can be beneficial to other community members.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-02T23:02:17.767Z",
                "Answer_score":0,
                "Answer_body":"@learn2skills Thank you for your contribution\n@AnashwarN-4785 Thank you for posting your question on Microsoft Q&A. Machine Learning Services is a feature of Azure SQL Managed Instance that provides in-database machine learning, supporting both Python and R scripts as mentioned in this document. Machine learning is it only available with Azure SQL managed instance. To provide feedback or to request new features , create an entry via user voice..\nRegards,\nOury",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Machine Learning CI Pipeline: Submitting an experiment failed",
        "Question_creation_time":1625658861767,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/466362\/machine-learning-ci-pipeline-submitting-an-experim.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hello everybody.\n\nI am currently working on a CI Pipeline for a Machine Learning Model.\n\nAt the Task where the training should happen my code fails at submitting an experiment.\n\nI get following Error:\n\n   File \"C:\\hostedtoolcache\\windows\\Python\\3.6.8\\x64\\lib\\multiprocessing\\pool.py\", line 119, in worker\n     result = (True, func(*args, **kwds))\n   File \"C:\\hostedtoolcache\\windows\\Python\\3.6.8\\x64\\lib\\site-packages\\azureml\\_restclient\\snapshots_client.py\", line 137, in create_snapshot\n     return self.create_snapshot(file_or_folder_path, retry_on_failure=False)\n   File \"C:\\hostedtoolcache\\windows\\Python\\3.6.8\\x64\\lib\\site-packages\\azureml\\_restclient\\snapshots_client.py\", line 139, in create_snapshot\n     raise SnapshotException(get_http_exception_response_string(response))\n azureml.exceptions._azureml_exception.SnapshotException: SnapshotException:\n     Message: {\n     \"error_details\": {\n         \"componentName\": \"project\",\n         \"correlation\": {\n             \"operation\": \"dsda3eb68326da4fa76b73560e39c8ac7\",\n             \"request\": \"23876ee7f425484f\"\n         },\n         \"environment\": \"westeurope\",\n         \"error\": {\n             \"code\": \"UserError\",\n             \"innerError\": {\n                 \"code\": \"NotFoundError\"\n             },\n             \"message\": \"Unable to find storage with address: Primary = 'https:\/\/blobstorage354836.blob.core.windows.net\/snapshots\/b8f73541-be8a-44dc-b851-780e7a05486d'; Secondary = 'https:\/\/blobstorage354836-secondary.blob.core.windows.net\/snapshots\/b8f82531-be8a-44dc-b851-780e7a05486d'\"\n         },\n         \"location\": \"northeurope\",\n         \"time\": \"2021-07-07T11:39:05.0508466+00:00\"\n     },\n     \"status_code\": 404,\n     \"url\": \"https:\/\/westeurope.experiments.azureml.net\/content\/v2.0\/subscriptions\/13f6ec8e-c4c1-4b2e-9f8b-80e2f17b0306\/resourceGroups\/ZA-GR-Prod-RPD\/providers\/Microsoft.MachineLearningServices\/workspaces\/Project_X\/snapshots\/b8f73541-be8a-44dc-b851-780e7a05486d\"\n }\n     InnerException None\n     ErrorResponse \n {\n     \"error\": {\n         \"message\": \"{\\n    \\\"error_details\\\": {\\n        \\\"componentName\\\": \\\"project\\\",\\n        \\\"correlation\\\": {\\n            \\\"operation\\\": \\\"d636a3eb634da4fa76b7230e39c8ac7\\\",\\n            \\\"request\\\": \\\"40f26ee7f456384f\\\"\\n        },\\n        \\\"environment\\\": \\\"northeurope\\\",\\n        \\\"error\\\": {\\n            \\\"code\\\": \\\"UserError\\\",\\n            \\\"innerError\\\": {\\n                \\\"code\\\": \\\"NotFoundError\\\"\\n            },\\n            \\\"message\\\": \\\"Unable to find storage with address: Primary = 'https:\/\/blobstorage354836.blob.core.windows.net\/snapshots\/b8f73541-be8a-44dc-b851-780e7a05486d'; Secondary = 'https:\/\/blobstorage354836-secondary.blob.core.windows.net\/snapshots\/b8f73541-be8a-44dc-b851-780e7a05486d'\\\"\\n        },\\n        \\\"location\\\": \\\"westeurope\\\",\\n        \\\"time\\\": \\\"2021-07-07T11:39:05.0508466+00:00\\\"\\n    },\\n    \\\"status_code\\\": 404,\\n    \\\"url\\\": \\\"https:\/\/westeurope.experiments.azureml.net\/content\/v2.0\/subscriptions\/13f6ec8e-c4c1-4b2e-9f8b-80e2f17b0306\/resourceGroups\/Ressource_cencored\/providers\/Microsoft.MachineLearningServices\/workspaces\/Projet_X\/snapshots\/b8f73541-be8a-44dc-b851-780e7a05486d\\\"\\n}\"\n\n\n\nCan anyone help me?\n\nThanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-05T03:00:44.467Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nHope you have solved this issue already. For issue like client application receives an HTTP 404 (Not found) message from the server, this implies that the object the client was attempting to use (such as an entity, table, blob, container, or queue) does not exist in the storage service. There are a number of possible reasons for this, such as:\n\nThe client or another process previously deleted the object : https:\/\/docs.microsoft.com\/en-us\/azure\/storage\/common\/storage-monitoring-diagnosing-troubleshooting?tabs=dotnet#client-previously-deleted-the-object\n\nA Shared Access Signature (SAS) authorization issue: https:\/\/docs.microsoft.com\/en-us\/azure\/storage\/common\/storage-monitoring-diagnosing-troubleshooting?tabs=dotnet#SAS-authorization-issue\n\nClient-side JavaScript code does not have permission to access the object: https:\/\/docs.microsoft.com\/en-us\/azure\/storage\/common\/storage-monitoring-diagnosing-troubleshooting?tabs=dotnet#JavaScript-code-does-not-have-permission\n\nNetwork failure: https:\/\/docs.microsoft.com\/en-us\/azure\/storage\/common\/storage-monitoring-diagnosing-troubleshooting?tabs=dotnet#network-failure\n\nSAS issue will be the most possible reason based on my experience. Please do let us know if you are still blocked by this issue.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Workspace Windows Server Compute Instance",
        "Question_creation_time":1626842114250,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/483713\/azure-ml-workspace-windows-server-compute-instance.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\n\nWould like to know is Windows Server Compute Instance available in Azure ML Workspace?\n\nI do understand there is DSVM for windows, but it won't have direct link to datasources and the jupyter notebook, or it is possible for me to link the compute once I have created the VM?\n\nI'm having a problem to migrate a conda environment from Windows to Linux, may I know what is the best practice for such migration?\n\nThanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-04T23:20:17.447Z",
                "Answer_score":0,
                "Answer_body":"@SoonJooGenting-3682 Hello, I have reached out to DSVM, actually they support Azure service and JupyterNotebook.\n\nAs the document said:\n\n> It also allows you to access services on the Azure cloud platform. Azure provides several compute, storage, data analytics, and other services that you can administer and access from your DSVM.\n\n\nTo administer your Azure subscription and cloud resources, you have two options:\n\n\nUse your browser and go to the Azure portal.\n\n\nUse PowerShell scripts. Run Azure PowerShell from a shortcut on the desktop or from the Start menu. See the Microsoft Azure PowerShell documentation for full details.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/data-science-virtual-machine\/vm-do-ten-things#manage-azure-resources\n\nTo start the Jupyter Notebook, select the Jupyter Notebook icon on the Start menu or on the desktop. In the DSVM command prompt, you can also run the command jupyter notebook from the directory where you have existing notebooks or where you want to create new notebooks.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/data-science-virtual-machine\/vm-do-ten-things#use-jupyter-notebooks\n\nHope this helps.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Execute R Script install.packages gives error: cannot open URL 'http:\/\/cran.us.r-project.org\/src\/contrib\/PACKAGES'",
        "Question_creation_time":1628025270273,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/500419\/execute-r-script-installpackages-gives-error-canno.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"Hi, I'm trying to install the NbClust R package from an Execute R Script block in Designer:\n\nCode:\n\n azureml_main <- function(dataframe1, dataframe2){\n    \n   # Install required libraries\n   print(\"**** START: Installing required libraries ****\")\n    \n   install.packages(\"NbClust\",repos = \"http:\/\/cran.us.r-project.org\")  \n   library(NbClust)\n    \n   print(\"**** END: Installing required libraries ****\") \n    \n   print(\"R script run.\")\n    \n   print(summary(dataframe1))\n      \n   # If a zip file is connected to the third input port, it is\n   # unzipped under \".\/Script Bundle\". This directory is added\n   # to sys.path.\n    \n   # Return datasets as a Named List\n   return(list(dataset1=dataframe1, dataset2=dataframe2))\n }\n\n\n\nError:\n\n[1] \"R script run.\"\n[1] \"Import packages.\"\nLoading required package: reticulate\nLoading required package: jsonlite\nLoading required package: dplyr\n\nAttaching package: \u2018dplyr\u2019\n\nThe following objects are masked from \u2018package:stats\u2019:\n\n filter, lag\n\n\n\nThe following objects are masked from \u2018package:base\u2019:\n\n intersect, setdiff, setequal, union\n\n\n\n[1] \"R read input parquet file.\"\n[1] \"0 columns have been set to origin types.\"\n[1] \" START: Installing required libraries \"\nWarning: unable to access index for repository http:\/\/cran.us.r-project.org\/src\/contrib:\ncannot open URL 'http:\/\/cran.us.r-project.org\/src\/contrib\/PACKAGES'\nError in library(NbClust) : there is no package called \u2018NbClust\u2019\nCalls: tryCatch ... tryCatchList -> withCallingHandlers -> azureml_main -> library\nIn addition: Warning message:\npackage \u2018NbClust\u2019 is not available (for R version 3.5.1)\nExecution halted\n\n\n\n\nThe same \"install.packages(\"NbClust\",repos = \"http:\/\/cran.us.r-project.org\")\nlibrary(NbClust)\" R code works just fine on my local computer.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-04T22:03:53.72Z",
                "Answer_score":0,
                "Answer_body":"Hi, I wasn't able to reproduce this issue in Designer, are you still unable to install the R package?\n\n downloaded 21 KB\n    \n * installing *source* package \u2018NbClust\u2019 ...\n ** package \u2018NbClust\u2019 successfully unpacked and MD5 sums checked\n ** R\n ** inst\n ** byte-compile and prepare package for lazy loading\n ** help\n *** installing help indices\n ** building package indices\n ** testing if installed package can be loaded\n * DONE (NbClust)",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is it possible to update automated machine learning model timeseries \"live\" as new events come in.",
        "Question_creation_time":1628032373347,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/500499\/is-it-possible-to-update-automated-machine-learnin.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I have trained a simple time series ML model and deployed it.\nGetting predictions works well enough, but I would like to keep the model up to date as new events come along each hour.\n\nFor example I want to predict an event that happens in 10 minutes.\nAfter 10 minutes has gone by, and I learn the real value, i'd like to push that value at the end of the ML model data array without having to re-train\/deploy everything.\nIs that possible in Automated ML ?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Clear Feature with Auto ML",
        "Question_creation_time":1627927876257,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/498759\/clear-feature-with-auto-ml.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hello, I am trying to add a user Id column to my dataset but I don't want the user Id to impact the results of the ML.\n\nI am using Auto ML on my dataset to generate a model and then deployed the model to an endpoint.\n\nCurrently I am calling the endpoint like:\n\n {\"data\":[\n        {\n           \"TEMP\":\"X\",\n         }\n     ]\n }\n\n\n\nand I would like to call it like:\n\n {\"data\":[\n     {\n       \"TEMP\":\"X\",\n       \"userID\": 5434643\n      }\n   ]}\n\n\n\nI'm wondering if there is a way I can do this? I've seen about using Clear Feature in Edit Metadata for the Designer but I'm wondering if something similar can be done for automated ML?\n\nThanks so much!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-03T00:16:45.197Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. You can customize featurization in automl to only include features relevant for prediction. Here's the documentation. Hope it helps!",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"What is the point of AzureML modules?",
        "Question_creation_time":1627306015463,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/489671\/what-is-the-point-of-azureml-modules.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello!\n\nI created an Azure ML pipeline in Python and used multiple PythonScriptSteps for each of my tasks. For example, I have three training steps running in parallel, so I create three PythonScriptSteps in a for loop with my train.py script and different data. Later, I came across the ModuleStep, which seems to do exactly this, but with an extra layer of (seemingly pointless) abstraction. What does the ModuleStep add to a PythonScriptStep?\n\nAlso, I imagined the ModuleStep might make it possible to use a custom PythonScriptStep in the pipeline designer (by creating a new drag and drop module), however this doesn't seem to be the case. Is there any way of doing this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-08-03T19:53:26.187Z",
                "Answer_score":0,
                "Answer_body":"Just to close this question, I have since discovered that the ModuleStep does create a custom drag-and-drop module in the designer. I don't know if I'd missed this (I imagine so) or if this is a new feature. Either way, that's the answer. @YutongTie-MSFT can you confirm if this was recently added?",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Different tensorflow version using azure ml portal vs VS Code",
        "Question_creation_time":1627517892667,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/493634\/different-tensorflow-version-using-azure-ml-portal.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I am using azure ML to run an python code in a jupyter notebook using tensorflow. I'm using \"Python 3.6 - Azure ML\" and an instance of azure compute to run it. It's showing tensorflow version as 2.1.0 .When I run the same code using VS Code connected to azure portal remotely, it's shows tensorflow version as 2.5.0. Why this discrepency?\n\nAlso I need tensorflow version 2.3.0 or up but there is not way for me to upgrade that using azure ml portal. Any help will be appreciated. Thank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-29T09:56:36.073Z",
                "Answer_score":0,
                "Answer_body":"@MJ-1993 I think the discrepancy is because the notebook is using a different environment with the kernel Python 3.6 - Azure ML. You can install the required version of tensorflow or any package with pip install from a new cell in the notebook.\n\n!pip install tensorflow==2.3.0\n\nThis should help you use this environment from the notebook. Thanks.",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error Creating Inference Clusters Assing IP to Load Balancer",
        "Question_creation_time":1609868045590,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/219545\/error-creating-inference-clusters-assing-ip-to-loa.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"To deploy an automated ML model, I created an inference cluster in Azure. The cluster stays in status \"creating\" for an hour then displays the following message.\nFailed: K8s failed to assign an IP for Load Balancer after waiting for an hour.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-20T01:37:55.313Z",
                "Answer_score":0,
                "Answer_body":"This issue has been fixed ^^ We are sorry for the experience. Please let us know if you have more questions.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-08-03T12:57:48.047Z",
                "Answer_score":0,
                "Answer_body":"WE are also experiencing similar issue. What could be the reason?\n\nK8s failed to assign an IP for Load Balancer after waiting for an hour.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to use a registred model in a python script(in Azure) ?",
        "Question_creation_time":1626012982337,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/470931\/how-to-use-a-registred-model-in-a-python-scriptin.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I used Azure AutoML service to test various models and after choosing the best one I registered it in my workspace.\n\nProcess done for registering:\n1. I downloaded the model(a zipped folder containing 3 files) into my laptop\n2. Unzipped the folder in my laptop\n3. Uploaded the unzipped folder(containing the score, environment yml and pkl file ) in the Azure \"Models\" pane and registered a model under the name \"lgbm\"\n\nWhat I want to achieve:\nI want to use the registered model to make some predictions on a \"validation\" Dataset I have in Azure(already registered) and check out the accuracy metrics once again.\n\nSteps done:\n1. Registered the validation dataset in Azure properly\n2. Started the Azure VM and Opened a new notebook\n3. Got the validation data into the script\n\nWhere I got stuck :\nUnable to get the registered model into my script and make predictions:\n\nCode:\n\nimport azureml.core\nfrom azureml.core import Workspace\n\nLoad the workspace from the saved config file\n\nws = Workspace.from_config()\nprint('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))\n\nfrom azureml.core import Dataset\nimport glob\ntab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'UI\/07-11-2021_055454_UTC\/test_pred.csv'))\ntab_data_set = tab_data_set.to_pandas_dataframe()\n\nmodel_path = Model.get_model_path('lgbm')\nmodel = joblib.load(model_path)\n\n\n\n\nError\nModelNotFoundException: ModelNotFoundException:\nMessage: Model lgbm not found in cache at azureml-models or in current working directory \/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/azuremlvm201\/code\/Users\/vishal_c_v. For more info, set logging level to DEBUG.\nInnerException None\nErrorResponse\n{\n\"error\": {\n\"message\": \"Model lgbm not found in cache at azureml-models or in current working directory \/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/azuremlvm201\/code\/Users\/vishal_c_v. For more info, set logging level to DEBUG.\"\n}\n}",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-12T13:49:23.027Z",
                "Answer_score":1,
                "Answer_body":"@vishalcv-5036 Thanks for the question. Can you check the get_details() and see the model name. You don't register a model by creating a Model object. To register a model from a an AutoML run, you can:\n\nmodel = run.register_model(description = description, iteration = iteration_id)\n\nIf you don't provide the iteration id (aka child run), then the model with the best metric will be registered.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-27T01:33:36.047Z",
                "Answer_score":0,
                "Answer_body":"@vishalcv-5036 Thanks for the details, AutoML does not automatically register models at this time. You can register manually via SDK or UI via the \"Deploy\" button (which registers and deploys the model).",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Problems connecting to workspace using Azure Machine Learning SDK for Python",
        "Question_creation_time":1606083056563,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/171465\/problems-connecting-to-workspace-using-azure-machi.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":5,
        "Question_comment_count":0,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"I am trying to connect to my Azure ML workspace using SDK for python, using Virtual Studio Code to do so. After pip installing the needed SDK packages:\npip install azureml-sdk\npip install azureml-sdk[notebooks,automl,explain]\n\nI downloaded the .json configuration file for my workspace, made sure it was in the correct location for the file path and tried the following code (with my subscription id, resource group and workspace name in place of the fillers in this chunk of code):\n\n {\n     \"subscription_id\": \"1234567-abcde-890-fgh...\",\n     \"resource_group\": \"aml-resources\",\n     \"workspace_name\": \"aml-workspace\"\n }\n\n\n\nUpon executing this in my ipy kernel in Virutal Studio Code I got a UserErrorException (see image below, I have blocked out subscription id's and other sensitive information):\n\n\n\n\n\n\nI then tried this alternative way to connect to my workspace using the following code (again with my info filled in instead of the fillers in the code):\nfrom azureml.core import Workspace\n\n from azureml.core import Workspace\n    \n ws = Workspace.get(name='aml-workspace',\n                    subscription_id='1234567-abcde-890-fgh...',\n                    resource_group='aml-resources')\n    \n ws = Workspace.from_config()\n\n\n\nThis produced the same error upon execution. I have tried using different subscriptions with different workspace names and resource groups and it gives me the same error every time. It appears to be telling me I do not have access to the subscription that I am logged in to? I am unsure how to fix this. I am trying to do this as part of the lessons in the Microsoft Azure Data Scientist certification if anyone is familiar with that or has run into the same problem while trying to complete the modules for that certification provided through Microsoft.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-23T02:07:42.373Z",
                "Answer_score":3,
                "Answer_body":"can you try using InteractiveLoginAuthentication?\n\nbelow code might help you\n\n from azureml.core.authentication import InteractiveLoginAuthentication\n ia = InteractiveLoginAuthentication(tenant_id='YourTenant id')\n # You can find tenant id under azure active directory->properties\n ws = Workspace.get(name='aml-workspace',\n                     subscription_id='1234567-abcde-890-fgh...',\n                     resource_group='aml-resources',auth=ia)",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2020-12-17T09:25:40.42Z",
                "Answer_score":0,
                "Answer_body":"Hello,\nI have the same problem. I tried InteractiveLoginAuthentication first but I had this error :\n\n\"error\": {\n\"message\": \"No workspaces found with name=projet7 in subscription=d9b1b5ff-XXX-XXXX-XXXX-XXXXXXXXXXXX\"\n}\n\nia = InteractiveLoginAuthentication(tenant_id='712a4781-YYYY-YYYY-YYYY-YYYYYYYYYYYY')\nws = Workspace.get(name='Projet7',\nsubscription_id='d9b1b5ff-XXX-XXXX-XXXX-XXXXXXXXXXXX',\nresource_group='classroom',auth=ia)\n\nI'm using a virtual machine azure sku='server-2019'; Python 3.6 - AzureML - AutoML",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-12-18T19:46:23.42Z",
                "Answer_score":0,
                "Answer_body":"I have already created Project7 by portal.\n\nI tried to create a new one.\n\nia = InteractiveLoginAuthentication(tenant_id=\"712a4781-YYYY-YYYY-YYYY-YYYYYYYYYYYY\")\nws = Workspace.create(name='RNN_workspace',\nsubscription_id='\/subscriptions\/d9b1b5ff-XXX-XXXX-XXXX-XXXXXXXXXXXX',\nresource_group='classroom',\ncreate_resource_group=False,\nlocation='West Europe',\nauth=ia\n)\n\nbut I had the same error :\n\nUserErrorException: UserErrorException:\nMessage: You are currently logged-in to 712a4781-YYYY-YYYY-YYYY- tenant. You don't have access to \/subscriptions\/d9b1b5ff-XXX-XXXX-XXXX-XXXXXXXXXXXX subscription, please check if it is in this tenant. All the subscriptions that you have access to in this tenant are =\n[SubscriptionInfo(subscription_name='Microsoft Azure ffffff', subscription_id='d9b1b5ff-XXX-XXXX-XXXX-'), SubscriptionInfo(subscription_name='Lab 2 - Extension name_axtension', subscription_id='59383c45-MMMM-MMMM-')].",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-12-18T20:17:50.353Z",
                "Answer_score":0,
                "Answer_body":"!az login\n[\n{\n\"cloudName\": \"AzureCloud\",\n\"homeTenantId\": \"712a4781-YYYY-YYYY-YYYY-YYYYYYYYYYYY\",\n\nYou have logged in. Now let us find all the subscriptions to which you have access...\nThe following tenants don't contain accessible subscriptions. Use 'az login --allow-no-subscriptions' to have tenant level access.\nc9587321-JJJJ-JJJJ-JJJJ-JJJJJJJJJJJJ\n\n\n\n \"id\": \"d9b1b5ff-XXX-XXXX-XXXX-XXXXXXXXXXXX\",\n \"isDefault\": true,\n \"managedByTenants\": [],\n \"name\": \"Microsoft Azure MMMM\",\n \"state\": \"Enabled\",\n \"tenantId\": \"712a4781-YYYY-YYYY-YYYY-YYYYYYYYYYYY\",\n \"user\": {\n   \"name\": \"adress\",\n   \"type\": \"user\"\n }\n\n},\n{\n\"cloudName\": \"AzureCloud\",\n\"homeTenantId\": \"712a4781-YYYY-YYYY-YYYY-YYYYYYYYYYYY\",\n\"id\": \"59383c45-RRRR-RRRR-RRRR-RRRRRRRRRRRR\",\n\"isDefault\": false,\n\"managedByTenants\": [],\n\"name\": \"Lab 2 - Extension RRRRR\",\n\"state\": \"Enabled\",\n\"tenantId\": \"712a4781-YYYY-YYYY-YYYY-YYYYYYYYYYYY\",\n\"user\": {\n\"name\": \"adress\",\n\"type\": \"user\"\n}\n}\n]\n\n\n\n\n\n!az account show\n{\n\"environmentName\": \"AzureCloud\",\n\"homeTenantId\": \"712a4781-YYYY-YYYY-YYYY-YYYYYYYYYYYY\",\n\"id\": \"d9b1b5ff-XXX-XXXX-XXXX-XXXXXXXXXXXX\",\n\"isDefault\": true,\n\"managedByTenants\": [],\n\"name\": \"Microsoft Azure MMMM\",\n\"state\": \"Enabled\",\n\"tenantId\": \"712a4781-YYYY-YYYY-YYYY-YYYYYYYYYYYY\",\n\"user\": {\n\"name\": \"adress\",\n\"type\": \"user\"\n}\n}\n\n\n\n\nI don't undestand why my tenant id can't contain accessible subscriptions !!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-02-10T11:40:37.92Z",
                "Answer_score":0,
                "Answer_body":"I have the same issue and my previous colleague had the same issue in his laptop. My previous colleague called support for help and solved the problem. But the solution MS support provided was not permanent. What MS support provided was to use interactive mode to clear caching and user information. But in the production development environment people cannot use interactive mode all the time to clear caching.\n\nNow I am having the same issue but in production environment. When switching subscriptions, somehow python sdk can not fetch new list of subscription ids. I have been added to this particular subscription for more than a week. Couldnot say my account was added \"recently\".\n\nI feel this is a bug.\n\n ServicePrincipalAuthentication(tenant_id=tenant_id,\n                     service_principal_id=service_principal_id,\n                     service_principal_password=service_principal_password,\n                     _enable_caching=False)\n Workspace.get('workspace',\n                     subscription_id='subscription_id',\n                     resource_group='resource_group',\n                     auth=sp)\n\n\n\n\nI created an issue in the GitHub where azure ml related are discussed.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Machine Learning Studio Issue",
        "Question_creation_time":1627253465317,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/488593\/machine-learning-studio-issue.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hey all,\n\nI'm working on a project for school in the machine learning studio classic and when I try to execute the following python script I get errors.\n\ndef azureml_main(frame1):\nimport matplotlib\nmatplotlib.use('agg')\n\n import pandas as pd \n import numpy as np \n import matplotlib.pyplot as plt\n import statsmodels.graphics.boxplots as sm\n Azure = True\nCreate a series of bar plots for the various levels of the\nstring columns in the data frame by readmi_class.\n names = list(frame1) \n num_cols = frame1.shape[1]\n for indx in range(num_cols - 1): \n         if(frame1.ix[:, indx].dtype not in [np.int64, np.int32, np.float64]):\n             temp1 = frame1.ix[frame1.readmi_class == 'YES', indx].value_counts()\n             temp0 = frame1.ix[frame1.readmi_class == 'NO', indx].value_counts()  \n             fig = plt.figure(figsize = (12,6)) \n             fig.clf()\n             ax1 = fig.add_subplot(1, 2, 1) \n             ax0 = fig.add_subplot(1, 2, 2) \n             temp1.plot(kind = 'bar', ax = ax1)\n             ax1.set_title('Values of ' + names[indx] + '\\n for readmitted patients')\n             temp0.plot(kind = 'bar', ax = ax0)\n             ax0.set_title('Values of ' + names[indx] + '\\n for patients not readmitted')\n              \n             if(Azure == True): fig.savefig('bar_' + names[indx] +'.png') \n                 ## Now make some box plots of the columns with numerical values. \n for indx in range(num_cols):\n         if(frame1.ix[:, indx].dtype in [np.int64, np.int32, np.float64]): \n             temp1 = frame1.ix[frame1.readmi_class == 'YES', indx] \n             temp0 = frame1.ix[frame1.readmi_class == 'NO', indx]\n          \n             fig = plt.figure(figsize = (12,6))             \n             fig.clf()\n             ax1 = fig.add_subplot(1, 2, 1)             \n             ax0 = fig.add_subplot(1, 2, 2)        \n             ax1.boxplot(temp1.as_matrix())\n             ax1.set_title('Box plot of ' + names[indx] + '\\n for readmitted patients')\n             ax0.boxplot(temp0.as_matrix())\n             ax0.set_title('Box plot of ' + names[indx] + '\\n for patients not readmitted')\n              \n             if(Azure == True): fig.savefig('box_' + names[indx] +'.png')               \n return frame1\n\n\n\nThe error I'm getting is:\nError 0085: The following error occurred during script evaluation, please view the output log for more information:\n---------- Start of error message from Python interpreter ----------\nCaught exception while executing function: Traceback (most recent call last):\nFile \"C:\\server\\invokepy.py\", line 199, in batch\nodfs = mod.azureml_main(*idfs)\nFile \"C:\\temp\\1f7ee68aea7d4914a540db6181eb53c8.py\", line 46, in azureml_main\ntemp1 = frame1.ix[frame1.readmi_class == 'YES', indx]\nFile \"C:\\pyhome\\lib\\site-packages\\pandas\\core\\generic.py\", line 2669, in getattr\nreturn object.getattribute(self, name)\nAttributeError: 'DataFrame' object has no attribute 'readmi_class'\nProcess returned with non-zero exit code 1\n\n---------- End of error message from Python interpreter ----------\nStart time: UTC 07\/25\/2021 22:45:40\nEnd time: UTC 07\/25\/2021 22:46:03\n\nHas anyone encountered this or know of a fix? I appreciate any help you can provide.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-26T10:32:45.15Z",
                "Answer_score":0,
                "Answer_body":"@HarrisToby-4269 I think the issue might be in what you have connected as input to the execute python script. Because, the input from dataframe1 or frame1 does not seem to contain the required attribute that is referenced. Are you following any documentation to review your entire experiment or could you cross check for any missed modules in your experiment?\n\nI would also recommend to try the reference this way in your current script at all occurrences:\n\n temp1 = frame1.ix[indx, frame1.readmi_class == 'YES']",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Custom Vision Stuck on 'Training'",
        "Question_creation_time":1627340240297,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/490215\/custom-vision-stuck-on-39training39.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I cannot train any models on Custom Vision. They stay stuck on 'Training' regardless if I choose quick or advanced training, and it stays stuck even after the maximum training time. This problem started a couple days ago, and I haven't had any problems in the past training with the same data\/ methods.\n\nThis is an example of the iteration details while the training job is in progress:\n\nIteration status: Training\nIteration Name: Iteration 1\nIteration training time (mins): 0\nIteration reserved budget time (hours): 12\nIteration training type: Advanced\nIteration classification type: None\nIteration error details: None\n\nYesterday I set a training job for 12 hours and it still had 0 mins for training time after 12 hours, so I had to manually delete the iteration.\n\nI am used both the python SDK and azure custom vision GUI to start the training job, with the same results.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-29T11:52:45.17Z",
                "Answer_score":0,
                "Answer_body":"@HazelErickson-8845 A backend issue caused training jobs to fail or they got stuck. This issue is now fixed.\nAll jobs that were pending should be in failed or success state now.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Endopint not consumable after successful model deployment to azure instance container (machine learning studio - designer)",
        "Question_creation_time":1627381840390,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/491097\/endopint-not-consumable-after-successful-model-dep.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"hi, after i register a model and then deploy it on Azure container istance via the graphical interface of the machine learning studio - designer, although the state is \"heathy\" i cannot test the endpoint with data or consume the endpoint. These are the logs of the deploiment\n\n2021-07-27 09:28:09,742 | root | INFO | 500 127.0.0.1 - - [27\/Jul\/2021:09:28:09 +0000] \"POST \/score?verbose=true HTTP\/1.0\" 500 37 \"-\" \"Go-http-client\/1.1\" Exception in worker process Traceback (most recent call last): File \"\/azureml-envs\/azureml_66791b0cfb22a4c054c681ce0ae95fcf\/lib\/python3.6\/site-packages\/gunicorn\/arbiter.py\", line 589, in spawn_worker worker.init_process() File \"\/azureml-envs\/azureml_66791b0cfb22a4c054c681ce0ae95fcf\/lib\/python3.6\/site-packages\/gunicorn\/workers\/base.py\", line 142, in init_process self.run() File \"\/azureml-envs\/azureml_66791b0cfb22a4c054c681ce0ae95fcf\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py\", line 125, in run self.run_for_one(timeout) File \"\/azureml-envs\/azureml_66791b0cfb22a4c054c681ce0ae95fcf\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py\", line 84, in run_for_one self.wait(timeout) File \"\/azureml-envs\/azureml_66791b0cfb22a4c054c681ce0ae95fcf\/lib\/python3.6\/site-packages\/gunicorn\/workers\/sync.py\", line 36, in wait ret = select.select(self.wait_fds, [], [], timeout) File \"\/var\/azureml-server\/routes_common.py\", line 162, in alarm_handler raise TimeoutException(error_message) timeout_exception.TimeoutException Worker exiting (pid: 90) worker timeout is set to 300 Booting worker with pid: 330 SPARK_HOME not set. Skipping PySpark Initialization. Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azureml-core 1.32.0 (\/azureml-envs\/azureml_66791b0cfb22a4c054c681ce0ae95fcf\/lib\/python3.6\/site-packages), Requirement.parse('azureml-core~=1.31.0')). Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azureml-core 1.32.0 (\/azureml-envs\/azureml_66791b0cfb22a4c054c681ce0ae95fcf\/lib\/python3.6\/site-packages), Requirement.parse('azureml-core~=1.31.0')). Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azureml-core 1.32.0 (\/azureml-envs\/azureml_66791b0cfb22a4c054c681ce0ae95fcf\/lib\/python3.6\/site-packages), Requirement.parse('azureml-core~=1.31.0')). Initializing logger 2021-07-27 09:29:12,687 | root | INFO | Starting up app insights client 2021-07-27 09:29:12,687 | root | INFO | Starting up request id generator 2021-07-27 09:29:12,687 | root | INFO | Starting up app insight hooks 2021-07-27 09:29:12,687 | root | INFO | Invoking user's init function 2021-07-27 09:29:12,882 | root | INFO | Users's init has completed successfully 2021-07-27 09:29:12,884 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled. 2021-07-27 09:29:12,884 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled. 2021-07-27 09:29:12,888 | root | INFO | Scoring timeout is found from os.environ: 60000 ms 2021-07-27 09:55:11,506 | root | INFO | Swagger file not present 2021-07-27 09:55:11,506 | root | INFO | 404 127.0.0.1 - - [27\/Jul\/2021:09:55:11 +0000] \"GET \/swagger.json HTTP\/1.0\" 404 19 \"-\" \"Go-http-client\/1.1\"\n\nalso if i try to consume the endpoint it ends with error 502, the specific error is this JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\ni'm trying to deploy the trained model, but the same thing happen if i try to deploy the inference pipeline\n\ni'm referring to this documentation\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-model-designer\n\nmy dount really is \" it seems that i can deploy a model to an Azure Instance Container directly from the deployment tab without creating a container instance separately before, since it seems that it is created at the moment. The process should be authomatic. then the deployment state is healthy, so its ok, but somewhere during the actual deployment something fails, because i can't consume the endpoint\"\n\nthanks for the support",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-27T12:16:12.313Z",
                "Answer_score":0,
                "Answer_body":"@TommasoBassignana-0564 Based on the error I think the input passed to your endpoint is not handled correctly by the entry script that is used. During the deployment process the entry script should contain the init() method to load your model and the run() method should parse the input or JSON and return the result. You can lookup a sample entry script here.\nIf there are any dependencies to be installed you can also add them as part of the conda dependencies file during the deployment. A healthy endpoint indicates successful creation of endpoint but it could still error out if the entry script does not handle the inputs. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unable to Connect Azure ML Workspace Through VSCode",
        "Question_creation_time":1627267451503,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/488719\/unable-to-connect-azure-ml-workspace-through-vscod.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I changed my Azure account and closed the workspace of the previous account linked to Azure ML.\n\nThen, I tried to connect my VSCode to my new Azure account and I got the following problems.\n\n\n\n\n\n\nThen I tried to connect Azure ML Compute Instance, it is keeping checking to see if the workspace exists.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-26T11:28:12.747Z",
                "Answer_score":0,
                "Answer_body":"@ZechengWang-5929 Thanks for the question. Can you please add more details about the steps that you performed and error logs.\n\nPlease follow the document to Connect to an Azure Machine Learning compute instance in Visual Studio Code (preview) and troubleshooting doc.\n\nPlease check the Prerequisites as mentioned in the document:\nCreate a workspace\nIn the Azure Machine Learning view, right-click your subscription node and select Create Workspace.\nA specification file appears. Configure the specification file.\nRight-click the specification file and select Azure ML: Create Resource.\nAlternatively, use the > Azure ML: Create Workspace command in the command palette.\nBlog Post: https:\/\/aka.ms\/azureml-vscode",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unable to deploy machine learning model - regression to predict auto car prices with the code from the MS docs documentation",
        "Question_creation_time":1627690246390,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/496628\/unable-to-deploy-machine-learning-model-regression.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"When I follow step by step as linked from the documentation to build and deploy a machine learning model with the car prices regression predictor, I get errors at the stage of adding a Python script after the score model block.\n\nI am using code and documentation from https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/\n\nMore precisely, I get an error when I have to input the custom run python script at https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/inference-pipeline\n\n\n\n\nHas anyone had trouble executing these scripts from Microsoft? It is simply renaming a column.\nSee script below\n\n\n\n\n\n\n import pandas as pd\n    \n def azureml_main(dataframe1 = None, dataframe2 = None):\n    \n     scored_results = dataframe1[['Scored Labels']]\n     scored_results.rename(columns={'Scored Labels':'predicted_price'},\n                         inplace=True)\n     return scored_results",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Score Recommender system - Item Recommendation failed to run",
        "Question_creation_time":1626681386490,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/480658\/score-recommender-system-item-recommendation-faile.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I am getting an error when trying to run the Score Recommender system for Item Recommendation.\n\nThe status details is 'Failed to run task; exceeded retry count for operation'. Can someone help to advise on this error?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-21T02:53:53.933Z",
                "Answer_score":0,
                "Answer_body":"The experiment i am trying to conduct here is a E-commerce Product Recommender to generate the top 5 item recommendations for each user.\nWhen i set the Recommended Item selection to be 'From All Items', the Score Recommender System will fail to run.\n\nExperiment link as below:\nhttps:\/\/studio.azureml.net\/Home\/ViewWorkspaceCached\/50eecd898bf54c7baca7704f89bc737b#Workspaces\/Experiments\/Experiment\/50eecd898bf54c7baca7704f89bc737b.f-id.671a7b68cb8a456282ed5ab7a8951f8e\/ViewExperiment",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"i am getting error when deploying machine learning model in aci",
        "Question_creation_time":1627565559387,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/494589\/i-am-getting-error-when-deploying-machine-learning.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"I am getting following error when trying to deploy machine learning model and when i deployed last time (1 month ago) with same score.py file it was deployed successfully, can anyone tell me why its giving error now\n\nError message as below\n\n\n\n\n\nservice.get_logs()\n\nReceived bad response from Model Management Service:\nResponse Code: 404\nHeaders: {'Date': 'Thu, 29 Jul 2021 12:34:55 GMT', 'Content-Type': 'application\/json',\n'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'x-ms-\nclient-request-id': '70679512-c060-4340-adb7-b48ce00449f5', 'x-ms-client-session-id':\n'1def55d9-4542-4b5b-b499-81aaa966e48a', 'api-supported-versions': '1.0, 2018-03-01-preview,\n2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'X-\nContent-Type-Options': 'nosniff', 'x-request-time': '0.961', 'Content-Encoding': 'gzip'}\n\nContent: b'{\"code\":\"NotFound\",\"statusCode\":404,\"message\":\"The specified resource was not found.\",\"details\":[{\"code\":\"ContainerLogNotAvailable\",\"message\":\"Log of container \\'gpvmod24\\' in container group \\'gpvmod24-wdh0omjSOE6ebtgW6F6kJQ\\' is not available yet. Please check container \\'InstanceView\\' for more information or retry later.\"}],\"correlation\":{\"RequestId\":\"0f3ed601-e1a9-4efb-ad42-2a6792c888c7\"}}'\n\nMy deployment code is below\naci_config = AciWebservice.deploy_configuration()\n\nservice = Model.deploy(workspace=ws,\nname='try',\nmodels=[model_x],\ninference_config=inference_config,\ndeployment_config=aci_config,overwrite=True)\nservice.wait_for_deployment(show_output=True)",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-29T13:46:34.847Z",
                "Answer_score":0,
                "Answer_body":"@prmanhas-MSFT @tbgangav-MSFT @vipullag-MSFT @TaoCuong-8759 @ramr-msft",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-29T17:27:45.33Z",
                "Answer_score":0,
                "Answer_body":"@srbose-msft @EasyOley-797 @nasreen-akter @MayankBargali-MSFT",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-30T14:58:49.473Z",
                "Answer_score":0,
                "Answer_body":"@VishalSuryavanshi-3563 Thanks for the question. Please follow the document to troubleshoot and solve, or work around, common errors you may encounter when deploying a model to Azure Container Instances (ACI) using Azure Machine Learning. Could you please check the compute instance status?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Endpoint fails with the model generated by Automated ML",
        "Question_creation_time":1626149341823,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/473223\/endpoint-fails-with-the-model-generated-by-automat.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":4,
        "Question_comment_count":3,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I have loaded bankmarketing_train.csv to get a dataset and auto generated a model to predict \"y\" field value with AutoML.\nVoting Ensemble model was generated as the best model and tested its behavior after deployed to the endpoint.\n\nSchema is generated like this for the endpoint.\n\n\nTried with the endpoint test feature in ML Studio. It worked and responded an expected output (left side in the fig below).\nBut my python REST call fails with 502 Bad Gateway(right side)\n\n\nUsing the REST plug-in for VSCode, I have requested as below. This also failed with the same response status code.\n\n POST http:\/\/d8e9f6ad-4112-4417-97c0-01b4246b284a.japaneast.azurecontainer.io\/score\n Content-Type: application\/json\n Authorization: Bearer === My correct key here ===\n    \n {\"data\": [{\"age\": 87, \"campaign\": 1, \"cons.conf.idx\": -46.2, \"cons.price.idx\": 92.893, \"contact\": \"cellular\", \"day_of_week\": \"mon\", \"default\": \"no\", \"duration\": 471, \"education\": \"university.degree\", \"emp.var.rate\": -1.8, \"euribor3m\": 1.299, \"housing\": \"yes\", \"job\": \"blue-collar\", \"loan\": \"yes\", \"marital\": \"married\", \"month\": \"may\", \"nr.employed\": 5099.1, \"pdays\": 999, \"poutcome\": \"failure\", \"previous\": 1}]}\n\n\n\n\nInvestigated in the App Insight and queried the exceptions.\nI found this end point tries to convert 'yes' to int value. Of course it fails.\n\n\nThe value 'yes' is set to 'loan' and 'housing\". Both are defined string value in the swagger.json for this endpoint.\n\nWhat do you think?\nAm I missing something?\nIs this a bug with the endpoint?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-13T09:21:31.357Z",
                "Answer_score":0,
                "Answer_body":"Yes, I tried that. Following is the code coming from the consume, the values are set accordingly.\n\n\n\n import urllib.request\n import json\n import os\n import ssl\n    \n def allowSelfSignedHttps(allowed):\n     # bypass the server certificate verification on client side\n     if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n         ssl._create_default_https_context = ssl._create_unverified_context\n    \n allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n    \n # Request data goes here\n    \n data = {\"data\":\n         [\n           {\n             \"age\": \"17\",\n             \"campaign\": \"1\",\n             \"cons.conf.idx\": \"-46.2\",\n             \"cons.price.idx\": \"92.893\",\n             \"contact\": \"cellular\",\n             \"day_of_week\": \"mon\",\n             \"default\": \"no\",\n             \"duration\": \"971\",\n             \"education\": \"university.degree\",\n             \"emp.var.rate\": \"-1.8\",\n             \"euribor3m\": \"1.299\",\n             \"housing\": \"yes\",\n             \"job\": \"blue-collar\",\n             \"loan\": \"yes\",\n             \"marital\": \"married\",\n             \"month\": \"may\",\n             \"nr.employed\": \"5099.1\",\n             \"pdays\": \"999\",\n             \"poutcome\": \"failure\",\n             \"previous\": \"1\"\n           }\n       ]\n     }\n    \n    \n body = str.encode(json.dumps(data))\n    \n url = 'http:\/\/d8e9f6ad-4112-4417-97c0-01b4246b284a.japaneast.azurecontainer.io\/score'\n api_key = '<key>' # Replace this with the API key for the web service\n headers = {'Content-Type':'application\/json', 'Authorization':('Bearer '+ api_key)}\n    \n req = urllib.request.Request(url, body, headers)\n    \n try:\n     response = urllib.request.urlopen(req)\n    \n     result = response.read()\n     print(result)\n except urllib.error.HTTPError as error:\n     print(\"The request failed with status code: \" + str(error.code))\n    \n     # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n     print(error.info())\n     print(json.loads(error.read().decode(\"utf8\", 'ignore')))\n\n\n\n\nThe result was the same. 'yes' was tried to cast to int and failed.\n\n\n\n\nIn the deployment log, following exception observed. Something is happening inside the server call, which I cannot see.\n\n 2021-07-13 08:56:49,684 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n   File \"\/var\/azureml-server\/synchronous\/routes.py\", line 64, in run_scoring\n     response = invoke_user_with_timer(service_input, request_headers)\n   File \"\/var\/azureml-server\/synchronous\/routes.py\", line 97, in invoke_user_with_timer\n     result = user_main.run(**params)\n   File \"\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/wrapt\/wrappers.py\", line 567, in __call__\n     args, kwargs)\n   File \"\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/inference_schema\/schema_decorators.py\", line 57, in decorator_input\n     kwargs[param_name] = _deserialize_input_argument(kwargs[param_name], param_type, param_name)\n   File \"\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/inference_schema\/schema_decorators.py\", line 285, in _deserialize_input_argument\n     input_data = param_type.deserialize_input(input_data)\n   File \"\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/inference_schema\/parameter_types\/pandas_parameter_type.py\", line 79, in deserialize_input\n     data_frame = data_frame.astype(dtype=converted_types)\n   File \"\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/generic.py\", line 5865, in astype\n     dtype=dtype[col_name], copy=copy, errors=errors, **kwargs\n   File \"\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/generic.py\", line 5882, in astype\n     dtype=dtype, copy=copy, errors=errors, **kwargs\n   File \"\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/internals\/managers.py\", line 581, in astype\n     return self.apply(\"astype\", dtype=dtype, **kwargs)\n   File \"\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/internals\/managers.py\", line 438, in apply\n     applied = getattr(b, f)(**kwargs)\n   File \"\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/internals\/blocks.py\", line 559, in astype\n     return self._astype(dtype, copy=copy, errors=errors, values=values, **kwargs)\n   File \"\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/internals\/blocks.py\", line 643, in _astype\n     values = astype_nansafe(vals1d, dtype, copy=True, **kwargs)\n   File \"\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/pandas\/core\/dtypes\/cast.py\", line 707, in astype_nansafe\n     return lib.astype_intsafe(arr.ravel(), dtype).reshape(arr.shape)\n   File \"pandas\/_libs\/lib.pyx\", line 547, in pandas._libs.lib.astype_intsafe\n ValueError: invalid literal for int() with base 10: 'yes'\n    \n During handling of the above exception, another exception occurred:\n    \n Traceback (most recent call last):\n   File \"\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1832, in full_dispatch_request\n     rv = self.dispatch_request()\n   File \"\/azureml-envs\/azureml_429e58b1641c78c2352efc8ad21c49d9\/lib\/python3.6\/site-packages\/flask\/app.py\", line 1818, in dispatch_request\n     return self.view_functions[rule.endpoint](**req.view_args)\n   File \"\/var\/azureml-server\/synchronous\/routes.py\", line 43, in score_realtime\n     return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n   File \"\/var\/azureml-server\/synchronous\/routes.py\", line 77, in run_scoring\n     raise RunFunctionException(str(exc))\n run_function_exception.RunFunctionException",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-07-13T16:08:37.257Z",
                "Answer_score":0,
                "Answer_body":"OK, I will.\nThank you for your support > @romungi-MSFT",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-15T02:22:06.927Z",
                "Answer_score":1,
                "Answer_body":"I got a response from MS together with a workaround. I have confirmed the workaround is effective in this case.\n\nThe order of keys should be the same as the one defined in the model schema.\n\nAfter I update the data definition in my client python file, it starts working.\n\n data = {\"data\":\n         [\n           {\n             \"age\": 17,\n             \"job\": \"blue-collar\",\n             \"marital\": \"married\",\n             \"education\": \"university.degree\",\n             \"default\": \"no\",\n             \"housing\": \"yes\",\n             \"loan\": \"yes\",\n             \"contact\": \"cellular\",\n             \"month\": \"may\",\n             \"day_of_week\": \"mon\",\n             \"duration\": 971,\n             \"campaign\": 1,\n             \"pdays\": 999,\n             \"previous\": 1,\n\n\n\n\nThank you.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-29T14:12:33.17Z",
                "Answer_score":1,
                "Answer_body":"We just ran into this issue as well. Found out that the order of properties in the \"data\" structure must match exactly with the order of columns in the dataset.\n\nThis does not make sense to me, since the property names are passed in the json, why would the order matter also?\n\nOn top of that, we use C#, and the example code generated in the Azure ML Portal looks like:\n\n          using (var client = new HttpClient(handler))\n         {\n             \/\/ Request data goes here\n             var scoreRequest = new Dictionary<string, List<Dictionary<string, string>>>()\n             {\n                 {\n                     \"data\",\n                     new List<Dictionary<string, string>>()\n                     {\n                         new Dictionary<string, string>()\n                         {\n\n\n\n\nThis uses a Dictionary for the properties, but the order of elements in a C# Dictionary is undefined and it does not guarantee the order when reading elements from it.\nSo the generated\/example C# code is prone to errors.\n\nIs this a known issue? Or am I missing something here?\n\nThanks in advance!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to filter a FileDataset by name?",
        "Question_creation_time":1627412512923,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/491736\/how-to-filter-a-filedataset-by-name.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello!\n\nI'm trying to pass a filtered dataset to a PythonScriptStep in a Pipeline. It doesn't have to be a FileDataset format, a OutputFileDatasetConfig or PipelineData would work as well. However, I don't want the step to access the entire dataset, so I want to filter it by name (without making copies of my data). Fortunately, FileDataset has a filter function which does exactly this, allowing me to mount a \"folder\" with filtered files. Unfortunately, I can't work out how to filter by name, and the filter function only mentions filtering by Size, Extension, etc.\n\nAny suggestions as to how can I achieve this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-28T06:56:05.377Z",
                "Answer_score":0,
                "Answer_body":"@David-3633 I think with the filter() function will only support the attributes returned by the file_metadata() function. Since, each row for filedataset corresponds to a path of a file, filtering by column value is not helpful. You could print the files to_path() and create a dictionary with the file names and then filter them.\n\nIf mylist is ['\/features.npy', '\/labels.npy']\n\n mylist=dataset.to_path()\n name_dict=dict.fromkeys(mylist,\"name\")\n name_dict\n\nname_dict would become {'\/features.npy': 'name', '\/labels.npy': 'name'}\n\nThis could be an overhead if you have large number of files depending on your next step in the pipeline.\n\nAn easier way I think, could be to register files that are only required using the from_files() to create the filedataset. This might not be useful if multiple filedataset classes are required for your pipeline but easier to manage if file names are available in a certain pattern in your datastore.\n\n from azureml.core import Dataset, Datastore\n    \n    # create file dataset from a single file in datastore\n    datastore = Datastore.get(workspace, 'workspaceblobstore')\n    file_dataset_1 = Dataset.File.from_files(path=(datastore,'image\/dog.jpg'))\n    \n    # create file dataset from a single directory in datastore\n    file_dataset_2 = Dataset.File.from_files(path=(datastore, 'image\/'))\n    \n    # create file dataset from all jpeg files in the directory\n    file_dataset_3 = Dataset.File.from_files(path=(datastore,'image\/**\/*.jpg'))\n    \n    # create filedataset from multiple paths\n    data_paths = [(datastore, 'image\/dog.jpg'), (datastore, 'image\/cat.jpg')]\n    file_dataset_4 = Dataset.File.from_files(path=data_paths)\n    \n    # create file dataset from url\n    file_dataset_5 = Dataset.File.from_files(path='https:\/\/url\/image\/cat.jpg')",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Automated machine learning model deployment issue",
        "Question_creation_time":1627371604967,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/490809\/automated-machine-learning-model-deployment-issue.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"So I'm having an issue with setting up an endpoint for a machine learning model which was trained using Azure AutoML. When I try to test the deployed model, I get an error saying that the service is temporarily unavailable. After looking online, I found that this might happen because of an error in the run() function in the entry script.\n\nWhen I try to test the entry script on a notebook in Azure ML studio, on a fresh compute instance, there are two problems:\nFirst I get the error: AttributeError: 'MSIAuthentication' object has no attribute 'get_token'\nWhich is solved by running: pip install azureml-core\n\nThen I get the error: ModuleNotFoundError: No module named 'azureml.automl.runtime'\nWhich I try to solve using: pip install azureml-automl-runtime\nBut this throws a lot of incompatibility errors during the installation. When I then try to run the entry script I get an error with the message: \"Failed while applying learned transformations.\"\n\nSo I setup a new virtual environment on my local machine in which I only installed azure-automl-runtime. Using that setup the entry script works perfectly fine. So I created a custom environment in Azure ML studio using the conda file of that local virtual environment. Unfortunatly I still get the error \"service temporarily unavailable\" when trying to test the endpoint.\n\nI have a feeling the default Azure ML containers are incompatible with azureml-automl-runtime, since installing this on a ML studio notebook also throws a lot of errors.\n\nI feel like there should be an elegant way to deploy an AutoML model, am I doing something wrong here?\n\n\n\n\n\nUpdate: I found out I didn't change the environment for the endpoint, so that is why I was getting the same error probably. When using the custom environment I got errors from gunicorn, so I also added that package to the environment. Now I get the following error:\n\n       File \"\/var\/azureml-server\/entry.py\", line 1, in <module>\n     import create_app\n   File \"\/var\/azureml-server\/create_app.py\", line 4, in <module>\n     from routes_common import main\n   File \"\/var\/azureml-server\/routes_common.py\", line 39, in <module>\n     from azure.ml.api.exceptions.ClientSideException import ClientSideException\n ModuleNotFoundError: No module named 'azure.ml'\n\n\n\n\nSo what do I install to fix this? Is there a list somewhere of required packages for an ML model endpoint?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-28T09:19:56.087Z",
                "Answer_score":1,
                "Answer_body":"I managed to fix the issue with the environment by just adding everything that would throw an error. Then I found out the return value has to be a json\/dict object, which if not done throws the exact same 'service temporarily unavailable' error.\n\nBut my issue with the confusing curated environments and azureml-automl-runtime in ML studio notebooks remain. Maybe this is worth looking into @ramr-msft .",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-07-27T13:52:34.27Z",
                "Answer_score":0,
                "Answer_body":"@Hidde-5466 Thanks, Can you try this notebook for deployment and if that works for you (it should), compare with your code?\nhttps:\/\/github.com\/CESARDELATORRE\/Easy-AutoML-MLOps\/blob\/master\/notebooks\/5-automl-model-service-deployment-and-inference\/automl-model-service-deployment-and-inference-safe-driver-classifier.ipynb\n\nYou\u2019ll first need to train and register the model with this previous notebook using a pipeline:\nhttps:\/\/github.com\/CESARDELATORRE\/Easy-AutoML-MLOps\/blob\/master\/notebooks\/4-automlstep-pipeline-run\/automlstep-pipeline-run-safe-driver-classifier.ipynb\n\nYou can also use the notebook with a simple AutoML remote run, but you might need to change the name of the model when registering it in the Workspace since it\u2019s a different name to what the deployment notebook is using:\nhttps:\/\/github.com\/CESARDELATORRE\/Easy-AutoML-MLOps\/blob\/master\/notebooks\/3-automl-remote-compute-run\/automl-remote-compute-run-safe-driver-classifier.ipynb",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Cannot use ```%matplotlib qt``` in Jupyter notebook in Azure Machine Learning",
        "Question_creation_time":1626886810050,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/484527\/cannot-use-matplotlib-qt-in-jupyter-notebook-in-az-1.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I am asking this question again, because I haven't got any update for my previous question, even though I have made new comments 20 days ago to describe my issue. The question can be found here.\n\nTo summarize:\nAfter restarting the kernel, I run the following suggested solution\nimport matplotlib\nmatplotlib.use('Qt5Agg')\nimport matplotlib.pyplot as plt\n, and still got the same error:\nImportError: Cannot load backend 'Qt5Agg' which requires the 'qt5' interactive framework, as 'headless' is currently running\n\nCan someone please help me to solve this problem? It is really important for me to use interactive plots.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-26T17:18:37.453Z",
                "Answer_score":0,
                "Answer_body":"We redirected this issue to support team. @Lu-3578 Please let me know if you have any block during that process.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Model deployment stuck in \"Transitioning\" state",
        "Question_creation_time":1626878916563,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/484403\/model-deployment-stuck-in-34transitioning34-state.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I have been trying to deploy a service on Azure ML workspace from a model both using an Azure DevOps pipeline and manually from the portal.\nIn both cases the deployment get stuck in \"Transitioning\" state for hours.\nWhat can I do to solve this issue?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Execute R Script in ML Studio",
        "Question_creation_time":1627017183467,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/486775\/execute-r-script-in-ml-studio.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\n\nI am trying to runt the following R Script in an 'Execute R Script' module in Machine Learning Studio.\n\ndata.set <- data.frame(installed.packages())\nmaml.mapOutputPort(\"data.set\")\n\nThis script is taken from the 'Get started with Machine Learning Studio (classic)' in R page (https:\/\/docs.microsoft.com\/en-au\/azure\/machine-learning\/classic\/r-get-started#timeseries)\n\nWhilst it works in ML (classic) I receive the following error when running it in Machine Learning Studio;\n\nError in maml.mapOutputPort(\"data.set\"): could not find function \"maml.mapOutputPort\"\n\nWhat additional config settings are needed to enable R scripts in ML Studio?\n\nThank you.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-23T08:21:10.717Z",
                "Answer_score":0,
                "Answer_body":"@GrahamBenson-6517 For the designer version of the Azure ML studio you could follow the steps in this document to install the packages and run any R scripts. Unlike the classic version you need to select or create compute for your experiment before the experiment can be submitted.\n\nExample for installing a package:\n\n azureml_main <- function(dataframe1, dataframe2){\n   print(\"R script run.\")\n      \n   if(!require(zoo)) install.packages(\"zoo\",repos = \"http:\/\/cran.us.r-project.org\")\n   library(zoo)\n   # Return datasets as a Named List\n   return(list(dataset1=dataframe1, dataset2=dataframe2))\n }",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Is it possible to include the IP address of a specific Azure Machine Learning workspace in its storage account selected networks and get all functionality enabled?",
        "Question_creation_time":1626459319327,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/479209\/is-it-possible-to-include-the-ip-address-of-a-spec.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"We have secured the storage account of a Machine Learning workspace behind a vnet and have authorized a set of IPs to access the storage account. Since the workspace is not secured behind the vnet, a set of functions is disabled. Is there a way to get the IP of the workspace and include it in the list authorized networks for the storage account in order to have all workspace functionalities available? We know the official solution involves securing the workspace behind the vnet and enabling point-to-site, site-to-site or connecting through a VM, but these are not possible in our case. Thanks for the help.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Problem exporting data to azure ml scored dataset to sql database from designer",
        "Question_creation_time":1626948657997,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/485734\/problem-exporting-data-to-azure-ml-scored-dataset.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"I am trying to export scored data from azure ML pipeline to azure sql database but its running for 6 hours and still not creating any table. I am not sure how to approach to this problem.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-22T21:43:58.777Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. I wasn't able to reproduce this issue. I created an experiment using the sample provided in AML Designer. I was able to export the data to Azure SQL Database successfully. If issue persists, can you share your dataset and steps to reproduce this issue? Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Workspace Labelling Project Validation",
        "Question_creation_time":1626623101170,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/479940\/azure-ml-workspace-labelling-project-validation.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"HI, I am using Azure ML workspace Data Labelling project. I would like to know how can I trigger the Validation and Inference steps? I follow the instruction to manually labelled images, the project managed to trigger the Training steps, but there is no sign of Validation steps. I am not sure how to execute it or what is the condition to make the Validation step start. I also need to know how to trigger Inference steps as the documents I can get is limited. Any input is highly appreciated.\n\nThank you.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-labeling-projects",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-19T07:02:33.637Z",
                "Answer_score":0,
                "Answer_body":"@SJYap-8820 The labeling projects allows user to label data with instructions and then export the same as CSV, Coco file or Azure ML dataset for use. If you are planning to consume this project with Azure ML then you could export the same as Azure ML dataset.\n\nAfter exporting the project this will be available as a dataset under the dataset tab, This can be consumed from the SDK by using it as any other data.\n\n.\n\nIf you would like to consume it from the Azure machine learning designer studio you can drag and drop the dataset on studio canvas and connect the required modules to create and run an experiment. When the experiment is run successfully you can convert it to a real time inference pipeline and then deploy it as a endpoint for inference.\n\nBasically, the labeled data could be used as input dataset in your Azure ML experiments either through the SDK or the designer studio. I hope this helps!!",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"azure ml update service erro AttributeError: AttributeError: 'str' object has no attribute 'id'",
        "Question_creation_time":1626917581717,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/485052\/azure-ml-update-service-erro-attributeerror-attrib.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I am tying to update existing webservice using new Azure ML package\nIts failing with error - AttributeError: 'str' object has no attribute 'id'\n\nHere is the script I am using -\n\n ws = Workspace.get(\n         name=workspace_name,\n         subscription_id=subscription_id,\n         resource_group=resource_group,\n         auth=cli_auth)\n model = Model.register(model_path = model_path,\n                    model_name = model_name,\n                    #tags = {\"key\": \"1\"},\n                    description = model_description,\n                    workspace = ws)\n image_config = ContainerImage.image_configuration(execution_script=\"score.py\", \n                                               runtime=\"python\", \n                                               conda_file=\"packagesenv.yml\")\n image = 'testazureml'\n service_name = 'testazureml'\n # Retrieve existing service\n service = Webservice(name = service_name, workspace = ws)\n print(service)\n service.update(image,'image.id')\n\n\n\nplease help\nI have been trying with different methods\nas - 'id', 'image_id'\nits still failing",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-22T02:33:24.353Z",
                "Answer_score":0,
                "Answer_body":"@AkankshaKothari-4630 Thanks for the question. Please follow the webservice class to update and document to deploy update web service.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment-local#update-the-service",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Import Data Error",
        "Question_creation_time":1626779418893,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/482751\/import-data-error.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi all,\nI am a newbie and trying to practice data analysis with the Machine Learning Studio Classic & I use the published data set URL as the input to run the experiment and it did not work successfully as expected (check below for the error please)\n\n*Import Data Error\nError while downloading the file: Error 0039: Error while completing operation: System.Net.WebException: An exception occurred during a WebClient request. ---> Microsoft.Analytics.Exceptions.ErrorMapping+ModuleException: Error 0078: Http redirection not allowed . ( Error 0030 )\n\nAnyone can help, please? Appreciate!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-21T07:27:46.31Z",
                "Answer_score":0,
                "Answer_body":"@LinhBui-5340 Thanks for the question. Can you please add more details about the module that throws the error.\n\nWe would recommend using Designer(Drag and Drop) and follow the below document for Import data.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/import-data",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Datastore\\Datasets",
        "Question_creation_time":1626270339670,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/475768\/azure-ml-datastoredatasets.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello:\n\nI want to know that if it is possible automate copy file from azure storage to Azure ML folder.\n\nI understand that it is duplication of data, but I want to know if yes, how I can do that.\n\nAny pointer is greatly appreciated.\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-16T11:50:11.017Z",
                "Answer_score":1,
                "Answer_body":"Depending on the frequency at which you would like to move data you can create scripts that could run on crontab to move the data between source storage account to your workspace blob store. For example, use azcopy to perform this activity.\n\nA very comprehensive method to move storage between storage accounts is available as a Microsoft learn module that you could take to understand the possibilities and attain this from code to automate in your application.\n\nI would ideally assume that you would like to pull data when your experiment kicks off because you cannot move data to an experiments run id folder unless the experiment has started, In this case you could use the first option to place the data in your workspace blob store and then use it in your experiment without moving it to any other storage. I hope this helps.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Python script before ML endpoint",
        "Question_creation_time":1626725693000,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/481697\/python-script-before-ml-endpoint.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello,\n\nI'm wondering if there is somewhere in Azure that I can add a python script that will process my data before sending it to a Machine Learning Endpoint?(the model is already deployed)\n\nThanks so much!",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Passing data from Azure Data Factory into Azure ML",
        "Question_creation_time":1626444050490,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/479034\/passing-data-from-azure-data-factory-into-azure-ml.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"In Azure ML the input data has to be defined as a Dataset (to create a pipeline). In my code I am passing datasets with the following syntax: input_data = Dataset.File.from_files(datapath)\n\nI would like to change this datapath as an input parameter from Data Factory (for example via PipelineParamater), so I can apply the same Data Factory pipeline for different datasets. However, in Data Factory you can only pass string as a parameter, not a DataPath.\n\nWhat is the solution around this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-19T11:14:55.843Z",
                "Answer_score":0,
                "Answer_body":"Hi @IlzeAmanda-9677 ,\n\nThank you for posting your query on Microsoft Q&A Portal and sharing clarifications on ask.\n\nUnfortunately, we cannot create user defined types in Azure data factory at this moment.\n\nBut, I will encourage you to log your feedback using below link. Product team will actively monitor feedback there and consider them for future releases. Thank you.\nhttps:\/\/feedback.azure.com\/forums\/270578-data-factory\n\nHope this will help.\n\nPlease accept an answer if correct. Original posters help the community find answers faster by identifying the correct answer. Here is how.\n\n\nWant a reminder to come back and check responses? Here is how to subscribe to a notification.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Find best activity for implemet ML scenario in Azure Data Factory",
        "Question_creation_time":1625846969290,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/470071\/find-best-activity-for-implemet-ml-scenario-in-azu.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"I'm new to Azure Data Factory. I want to implement the below scenario and I want to know which activity is suitable for this scenario.\n1. My data is on the Postgres database.\n2. Our data factory an activity copies data from the Postgres database.\n3. In this step run preprocessing function then is a python file. Also, the Python function needs the \"scaler.sav\" file.\n4. The output of step 3 use as input for step 4 and run the classification function then is a python file. Also, the Python function needs the \"ExtraTreesClassifier.sav\" file.\n5. Insert the output of step 4 into the database.\n\nThe diagram of this scenario. I need help to know which activity should use for this scenario.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-13T00:25:11.19Z",
                "Answer_score":0,
                "Answer_body":"Hello @MohsenAkhavan,\nThanks for the ask and using the Microsoft Q&A platform .\n\nAs I understand at this time you have couple of options .\n\nUse Azure databricks activity : Since you are using Python , you can use ADB activity which will call a notebook and you can run you python script . This should work .\n\nUse custom activity : You can use a custom activity and run the azure batch in the back ground . Please read about the same here .\n\n\n\n\nPlease do let me know how it goes .\nThanks\nHimanshu\nPlease do consider clicking on \"Accept Answer\" and \"Up-vote\" on the post that helps you, as it can be beneficial to other community members",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unable to stop Azure ML Compute instance",
        "Question_creation_time":1626257651013,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/475562\/unable-to-stop-azure-ml-compute-instance.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I'm unable to stop my Azure ML Compute instance as it fails with the following error:\n\n Failed to stop compute\n ResourceNotReady: Request failed with status code 400.\n    \n Trace ID : 698a7727-f014-4d38-9dc1-a058158a2b09\n Client request ID : 7f491fb9-cdd3-4a82-86f3-3eebb19b8419\n Service request ID : |00-872699f1c7573e4bbb4b130d59759cab-9f1ee7b43cfb3f4c-01.ad2a11cf_\n\n\n\nIn DevTools in the browser, I can see this additional information:\n\n message\":\"There is already an active operation submitted.\"",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-14T21:59:29.57Z",
                "Answer_score":0,
                "Answer_body":"Hi, this is probably an intermittent issue. Please let us know if issue persists so we can investigate further. Thanks!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"where to find the equation for the line after making Azure ML linear regression model, 2 slopes and 1 y intercept",
        "Question_creation_time":1626236136657,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/474924\/where-to-find-the-equation-for-the-line-after-maki.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"Hi, I've made a model and it's predicting prices of cars. hooray! I cannot find the the equation for Azure's Regression Linear model anywhere. I made this model using Designer GUI. For example, in R, the coefficients are returned by running summary(mymodel)\n= y-intercept + (slope miles) + (slope year)\n= 21022.96 + (-0.0249*98500) + (-6.5668*2016)\nsomething like this equation for a line is what I'm looking for in Azure.\n\nwhat I've tried:\n1. If it was only 1 feature, I could solve for an equation using (y2-y1) \/ (miles2-miles1) to find slope and the solve to y intercept. But this model uses miles and year as variables.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-14T15:44:15.03Z",
                "Answer_score":0,
                "Answer_body":"@@MikeRichardson-3493 Thanks, We currently do not have coefficients for regression models, but we will forward this with our data science team to check on this. We are working on an interface to surface models that compose ensembles, model weights and more. While not as involved of an interface, some of this information is available today within the model details tags sections:.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-07-14T21:43:48.24Z",
                "Answer_score":1,
                "Answer_body":"ok, thanks. If I understand correctly, I could make this model an ensemble model containing two algorithms, that each use one factor\/feature variable, and then this would allow me to add weights at each model. And the calculation of the equation can be made if it's linear regression on one feature. I will look forward to trying this. Thanks for the insight.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML AutoML : Data transformation diagram only 1 column",
        "Question_creation_time":1626184752807,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/474091\/azure-ml-automl-data-transformation-diagram-only-1.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hello, I am using the AutoML of Azure ML. I don't understand the diagram of Data transformation (that is still in preview). It tells me that I start with 26 columns, which is correct, but then says I'm ending up with 1 column only, after a MeanImputer. ![114216-1column.png][1] If I check the engineered features in the code, I get this table, so 26 columns with the application of MeanImputer for each of them. ![114215-allcolumns.png][2] Could you tell me why the diagram tells me that there is only 1 column at the end? [1]: \/answers\/storage\/attachments\/114216-1column.png [2]: \/answers\/storage\/attachments\/114215-allcolumns.png",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-14T19:36:10.617Z",
                "Answer_score":0,
                "Answer_body":"Thanks for pointing this out. This feature is still in preview, I followed up with the product team, we currently have a work item to improve this feature (we don't have an ETA at the moment). Please disregard the summary workflow for now. Will follow-up with updates accordingly. Hope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Got an error when running an experiment in Azure ML studio",
        "Question_creation_time":1605143753147,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/159889\/got-an-error-when-running-an-experiment-in-azure-m.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Please take a look at the following link.\n\nhttps:\/\/gallery.azure.ai\/Experiment\/Retail-Forecasting-Step-1-of-6-data-preprocessing-5\n\nWhen running step 5 of the experiment, I got an error. Please see screenshot",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-12T07:50:16.383Z",
                "Answer_score":0,
                "Answer_body":"anonymous userLuk-9638 According to the list of supported packages car is listed as supported for R Open 3.2.2 but since this is the classic version of the studio there have been no active updates since the launch of ML designer version of the studio. This library might not longer be available in the open version or you can use CRAN R 3.1.0 and try again.\n\nIf the package is available from open libraries it needs to be zipped and uploaded as a dataset to studio and connected to 3rd port of Execute R script to be used during runtime.",
                "Answer_comment_count":5,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Regarding spot instances",
        "Question_creation_time":1626182886860,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/474023\/regarding-spot-instances.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I have recently received a research grant which I'm planning on using to rent 8xV100 instances (or maybe 16xV100 too). My question is, how long do the spot instances last, specifically ND40rs v2 spot instances, as they are only $2.4\/hr, which is great for my use case. My second question is, can I stack 16 such instances together for $38.4\/hr? That would be very helpful if I can get such instances for say a day at a time.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-13T15:22:47.097Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. The following document provides detailed information regarding Spot Instances. Please review Pricing and FAQ sections as well. You can also contact sales for further assistance if needed. Hope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Cannot use GPU on Azure Notebooks in Azure Machine Learning Studio",
        "Question_creation_time":1625492823860,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/463398\/cannot-use-gpu-on-azure-notebooks-in-azure-machine.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hey All,\n\nI am new to Azure Machine Learning Studio and am currently trying to train some models on a GPU compute instance in on Azure Machine Learning Studio. The compute instance that I am using is Standard_NC6.\n\nThe problem I am currently facing is that even though I can successfully train my models, I realize that Tensorflow is using the CPU instead of the GPU when I run\n\n device_name = tensorflow.test.gpu_device_name()\n if device_name != '\/device:GPU:0':\n   raise SystemError('GPU device not found')\n print('Found GPU at: {}'.format(device_name))\n print(\"Num GPUs Available: \", len(tensorflow.config.list_physical_devices('GPU')))\n\n\n\nwhich raises the system error. Am I doing something wrong in the setup, my code is literally the same from when I was training on Google Colab and can successfully train on a Tesla K80 there but it is somehow not working within the Azure Notebook.\n\nAppreciate any help given!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-06T06:22:02.327Z",
                "Answer_score":1,
                "Answer_body":"@LimZiLian-7585 I have noticed a similar issue earlier but it was observed on a DSVM machine Jupyter installation rather than a studio notebook. But, since the compute for these machines might be similar I suspect the package for tensorflow gpu might need an upgrade. Could you please check the installed version of tensorflow and upgrade it to 2.5.0 from your notebook cell and then check again after a kernel restart?\n\n !pip install --upgrade tensorflow-gpu",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Getting BadRequest when creating deployment for ML online endpoint",
        "Question_creation_time":1626097427733,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/472314\/getting-badrequest-when-creating-deployment-for-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I'm trying to create a managed online endpoint for a ML model using the Azure Machine Learning Studio (so GUI not CLI). It succeeds on the first four steps, but when it comes to \"Microsoft.MachineLearningServices\/workspaces\/onlineEndpoints\/deployments\" it fails with a BadRequest error. The status message isn't much help either:\n{\n\"status\": \"Failed\",\n\"error\": {}\n}\nAny suggestions?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-13T00:40:05.167Z",
                "Answer_score":0,
                "Answer_body":"@YutongTie-MSFT thank you for getting back!\n\nI couldn't really find a detailed tutorial for deploying using the studio, but (as this implies) the wizard was pretty straightforward. I also used the entry script from here for testing. Once it started giving me errors, I started searching other documentation, including trying to do it using the CLI and ARM templates, copies from the studio. This successfully deployed once, but I wasn't able to replicate it (a lot more BadRequest errors and missing assets, etc. - I'm still learning to use the CLI, etc.).\n\nRegarding region, I'm using West US, as it's for testing.\n\nThank you again,\nDavid",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-13T00:55:57.307Z",
                "Answer_score":0,
                "Answer_body":"I deleted your post with your subscription ID to protect your private. I\u2019ve enabled one-time Free Technical Support for you. To create the support request, please do the following:\n\n\n\n\n\u2022 Go to the Health Advisory section within the Azure Portal: https:\/\/aka.ms\/healthadvisories\n\u2022 Select the Issue Name \"You have been enabled for one-time Free Technical Support\"\n\u2022 Details will populate below in the Summary Tab within the reading pane and you can click on the link \"Create a Support Request\" to the right of the message\n\nLet me know what your support request number is so that I can keep track of your case. If you run into any issues, feel free to let me know.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-13T01:24:00.37Z",
                "Answer_score":0,
                "Answer_body":"@YutongTie-MSFT I didn't realise that was private, thanks! I've created my support request and the ID is 2107130040000396. Hope I haven't missed something too obvious!\n\nThank you very much for your help!\nDavid",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Tutorial - Failed to load entrypoint automl",
        "Question_creation_time":1623826462663,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/438183\/azure-ml-tutorial-failed-to-load-entrypoint-automl.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I'm doing following tutorial. I run successfully \"Create and run a Python script\", but failed failed to run \"Create a control script\".\n\nWhat could be wrong?\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-hello-world\n\n azureuser@kensmlcompute:~\/cloudfiles\/code\/Users\/my.name\/get-started$ python run-hello.py \n Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = \n azureml.train.automl.run:AutoMLRun._from_run_dto with exception (pyarrow 4.0.0 \n (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), \n Requirement.parse('pyarrow<4.0.0,>=0.17.0'), {'azureml-dataset-runtime'}).\n https:\/\/ml.azure.com\/runs\/day1-experiment-hello_1623766747_073126f5? \n wsid=\/subscriptions\/1679753a-501e-4e46-9bff- \n 6120ed5694cf\/resourcegroups\/kensazuremlrg\/workspaces\/kensazuremlws&tid=94fe1041-ba47-4f49- \n 866b- \n 06c297c116cc\n azureuser@kensmlcompute:~\/cloudfiles\/code\/Users\/my.name\/get-started$",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-16T09:17:33.743Z",
                "Answer_score":0,
                "Answer_body":"@Kenny-8557 I think the error indicates that your environment is using pyarrow package which is of version 4.0.0 whereas azureml-dataset-runtime requires the package to be >=0.17.0 but <4.0.0\n\nIt would be easier for you to uninstall the package and install a specific version. The list of releases of pyarrow are available here.\n\nSince you are using a notebook create new cells and run these commands.\n\n !pip uninstall pyarrow\n !pip install -y pyarrow==3.0.0\n\n\n\n\n\nPlease feel free to mark the answer as accepted if it helps. Thanks.",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unable to parse the response from the Azure ML Web Service - PowerBI, Azure Auto ML, Time Series",
        "Question_creation_time":1611654540273,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/245495\/unable-to-parse-the-response-from-the-azure-ml-web.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":10,
        "Question_score":2,
        "Question_body":"Hi everyone,\n\nI have issues while interfacing Azure ML with PowerBI. I deployed a model from Auto ML, and tried to consume it in PowerBI. I successfully completed the following tutorials create a predictive model by using auto ML and consume a model in PowerBI . But when it comes to implement my proper model, I get this error : \"Unable to parse the response from the Azure ML Web Service\".\n\nI have to add that my model forecasts time series. On the contrary, the model was a regression in the Microsoft tutorials. And I didn't use R or Python script, I used exactly the same method as the second tutorial about PowerBI.\n\nThank you very much for your help ! don't hesitate to ask me if you need more information.\n\nMary",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-05T13:28:32.4Z",
                "Answer_score":0,
                "Answer_body":"I am facing the exact same problem.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-01T18:48:13.203Z",
                "Answer_score":1,
                "Answer_body":"Had the same issue myself, and I figured out that time series models in Azure AutoML only accept input datetime that's later than the latest datetime used when training. I have monthly data and I used until Sep 2020 to train my model, so when I filtered my input data in Power BI to only Oct 2020 and later, the AutoML model finally ran successfully. Hopefully this is helpful.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to call azure endpoint rest api from model generated by visual studio 2019 ml builder?",
        "Question_creation_time":1625718765327,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/467346\/how-to-call-azure-endpoint-rest-api-from-model-gen.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I have tried visual studio 2019 model builder for object detection. I have followed a tutorial about stop sign image object detection which will use Azure for training. I then use the model generated to make inference. So far everything is working fine. I can genereate web api too which will use json input { \"ImageSource\": \"path to local image\" } and this works too.\n\nNow the problem is I am trying not to use my local cpu to do the inference. I want to use Azure to do the inference. And what I do is look for the experiment generated by model builder. Find the model and deploy the model to the endpoint.\n\nNow when I go to the endpoint generated, there is a test tab there and I suppose that I need to supply the json for the inference. What is the json format needed since I try all of these and all of them not working:\n- just the url of the image file\n- use { \"url\" : \"url to the image\" }\n- use { \"imageSource\": \"url to the image\" }\n- use { \"data\": [ {\"url\" : \"url to the image\"} ] }\n- use { \"data\": [ {\"imageSource\" : \"url to the image\"} ] }\n\nAnd I can't find any documentation about the exact format of the json. And when I call rest api from postman\/insomnia it always says time out error.\n\nBelow is my deployment log when I try test.\n\nStarting the inference\n\/azureml-envs\/azureml_a5cc75b048d996dfdd3ff5c7e66b85eb\/lib\/python3.7\/site-packages\/azureml\/contrib\/automl\/dnn\/vision\/common\/utils.py: since ignore_data_errors is True, file will be ignored.\nGot AutoMLVisionDataException as all images in the current batch are invalid. Skipping the batch.\nNumber of lines written to prediction file: 0\nTotal scoring time 0.0095 for 0 batches. Batch avg: 0.0000.\nMem stats scoring: {}.\nGPU stats scoring: {}{}.\nFinished inferencing.\n2021-07-08 04:15:27,849 | root | INFO | run() output is HTTP Response\n2021-07-08 04:15:27,849 | root | INFO | 200\n127.0.0.1 - - [08\/Jul\/2021:04:15:27 +0000] \"POST \/score?verbose=true HTTP\/1.0\" 200 0 \"-\" \"Go-http-client\/1.1\"",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure Machine Learning Endpoint attempting to cast string parameter as an int",
        "Question_creation_time":1625151488777,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/459799\/azure-machine-learning-endpoit-attempting-to-cast.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi,\n\nI have created a an ML model in Azure ML using auto ML. This has been deployed as an endpoint using the UI.\nThis is a sample of the original dataset:\n\n\nIts deployed as a container instance and the deployment state is healthy.\n\nWhen I test the endpoint, it pre-populates the test form with some example values, for the various paratmeters which are strings and ints.\n\n\n\n\nHowever, if I populate the blank fields with ints and leave the strings, .\n\nthen test the service, I get an error that suggests it is trying to convert attribute13 to an int\n\nas you can see, it is fine with the productName parameter being a string, but tries to convert Attribute13 to an int.\nThe same happens with the other attributesXX.\nIf I set all the attributes to numerical values, the test completes and the endpoint returns a value from the model as expected.\n\nIF i check the swagger file, it shows that the api is expecting a string:\n\nSo that all suggests the issue exists somewhere in the python code created automatically.\nThis is kinda where I get stuck - I see resources on debugging the python code, I can see in my score.py file the example sample passes specifies these as 'object' dtypes:\n\n\nAnd after that I dont know where to go from here - feels like it should just work 'out of the box' as I got to this point purely through the UI.\n\nAny help greatly appreciated.\n\nSteve",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-07T10:52:37.923Z",
                "Answer_score":3,
                "Answer_body":"TL;DR: Don't have column names that are numerical.\n\nI have discovered that if I send the attributes in the order the appear in they dataset - ignoring the order that they are named on the api, then they are all parsed to the correct type. Effectively the 3 columns named 341, 513, 514 belong at the end, but for some reason have been lined up with the wrong parameter names.\n\n\n(this returns expected values)\n\nSo i renamed the columns in my training data pandas dataframe so they are not numerical (e.g. System341, System513, System514) and re-ran the AutoML, and deployed the new model.\n\nnow the order of columns matches that of the dataset- and IT WORKS!",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Cannot use ```%matplotlib qt``` in Jupyter notebook in Azure Machine Learning",
        "Question_creation_time":1625144022410,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/459776\/cannot-use-matplotlib-qt-in-jupyter-notebook-in-az.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I would like to interact with the plots. But I got the error for %matplotlib qt :\nImportError: Cannot load backend 'Qt5Agg' which requires the 'qt5' interactive framework, as 'headless' is currently running",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Timeout on AutoMLConfig is not a hard timeout",
        "Question_creation_time":1624927301677,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/455257\/timeout-on-automlconfig-is-not-a-hard-timeout.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"When setting the timeout on the AutoMLConfig, it is not respected. Why?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-29T06:44:35.72Z",
                "Answer_score":0,
                "Answer_body":"@AxelSirota-0156 Referring to the AutoMLConfig documentation the parameter for timeout seems to be in hours rather than minutes.\n\nWhich version of the SDK are you using? Could you try to change the config accordingly for minutes to probably 0.25 i.e 15 minutes and check again?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Memoy Error during batch teste in Azure ML Studio",
        "Question_creation_time":1624966131983,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/456139\/memoy-error-during-batch-teste-in-azure-ml-studio.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hello guys,\n\nI am using Azure ML Studio to build a multiclassification model based on decision forest.\nNow, I am trying to predict new samples using Excel batch test, however I am getting the error :\"OutOfMemoryLimit\",\"message\":\"The model consumed more memory than was appropriated for it. Maximum allowed memory for the model is 2560 MB. Please check your model for issues.\"\n\nThis message is appearing even without running with new data, only with sample data generated by the Azure itself.\n\nHow Can I fix that? I have a standard account.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-30T08:18:31.263Z",
                "Answer_score":0,
                "Answer_body":"@mary-1005 I think you are using the classic studio endpoint where the error is encountered. Unfortunately, this restriction cannot be increased due to limitation of classic services. Please see a similar thread with the same error message.\n\nI would recommend to try the Azure ML Designer and use required compute for inference on AKS which does not have any such limits.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Add ID column after feature selection processing in Azure ML studio",
        "Question_creation_time":1625449418397,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/462403\/add-id-column-after-feature-selection-processing-i.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi all,\n\nIn my dataset, i have one ID key with 100 features and target column. After using feature filtering function, i select top 50 feature for the prediction. the problem is, after i covert my experiment to predictive experiment, i still need to report final result as: id, scored label.\n\ni found id column was missed in the predictive experiments and was not included in the SCORE MODLE - Probably due to feature filtering process.\n\nHow can i include ID column back to the final score model ?\n\nthx.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-05T07:54:44.607Z",
                "Answer_score":0,
                "Answer_body":"@XuJeff-1256 How is your pipeline configured in the designer? Are you using any normalization module and included the ID in it?\nIdeally you can include your ID and the scored label in your web output as mentioned in this sample. But, of course your score model module does not have it so you can't include it. Something like this,",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"CROSS VALIDATION WITH HYPER PARAMETER TUNING IN AZURE ML NOTEBOOK USING PYTHON SDK",
        "Question_creation_time":1624357454270,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/446761\/cross-validation-with-hyper-parameter-tuning-in-az.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"is there any way to use cross validation in azure notebook using python sdk, while using hyperdrive config for hyper parameter tuning?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-07T03:36:08.927Z",
                "Answer_score":0,
                "Answer_body":"@krishnakategaru-8347 Thanks, Please follow the document for Sampling the hyperparameter space.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-tune-hyperparameters#sampling-the-hyperparameter-space",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Facing problem in deplying pyhton application from github- unable to load tensorflow saved model in AZURE.",
        "Question_creation_time":1625428420640,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/462250\/facing-problem-in-deplying-pyhton-application-from.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I am trying to deploy a classification TensorFlow model on AZURE from GitHub. It is getting deployed correctly which can be seen from the below logs.\n![111656-image.png][1]\n\n\n\n\nBut I'm getting an OSError on log Stream saying saved model doesn't exist as shown below. The error msg is highlighted in red.\n![111560-image.png][2]\n\nBut this is working correctly on local. This model has been checked locally.\nThe repository for this can be checked at https:\/\/github.com\/Vikeshkr-DSP\/cassava-leaf-disease-prediction.\nThanks in advance for your help.\n[1]: \/answers\/storage\/attachments\/111656-image.png\n[2]: \/answers\/storage\/attachments\/111560-image.png",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-06T14:43:55.013Z",
                "Answer_score":0,
                "Answer_body":"The above issue on OSError: SavedModel file does not exist at: cassava_leaf.h5\/{saved_model.pbtxt|saved_model.pb} was due to a bit large size of model and we did not provide an absolute path to the model location, the application could not find the same during startup.\n\nThe issue resolved by manually transferring the h5-model file to a location like \/home on the App Service and updated the app.py file to use an absolute path in order to refer the file.\n\nSimilar to: model=load_model('\/home\/cassava_leaf.h5')",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure ML (Designer): Endpoint deploys initially, but can't consume or test it after that.",
        "Question_creation_time":1624896031587,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/454914\/azure-ml-designer-endpoint-deploys-initially-but-c.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello,\n\nI recently deployed an Azure Machine Learning Model (Designer). I have followed this tutorial (but for my model). The inference pipeline looks like this:\n\nThis endpoint was then deployed with the following configurations:\n\nCompute Type: Azure Container Instances\n\n\nCPU : 2\n\n\nMemory: 2 Gb\n\nFrom my understanding, when a model-endpoint is deployed initially, there is a test run (which tries to consume the endpoint) that is automatically run by Azure ML, and this has always worked for me (I have tried AKS too, and ACI with lower compute power). Attached, please find the logs.\n\n109955-initial-test-endpoint.txt\n\nAfter the test run, I can either test it from the interface itself, or I can execute some Python code (which Azure ML provides) that can consume it for me. In both cases, I get a 500-Bad Gateway error (checked through Deployment Logs):\n109962-endpoint-test.txt\n\nThis is what the Python code outputs:\n\n\nI have monitored the status of the endpoint while I try to consume it, and it is always healthy.\n\nI hope I have provided enough details. If not, please let me know what else is needed to understand the issue here. Any help is appreciated.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Unknown error occurred during authentication. Error detail: Unexpected polling state code_expired",
        "Question_creation_time":1625066182160,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/458139\/unknown-error-occurred-during-authentication-error.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\nI want to submit some training scripts and got this error. In the meantime I got the warning:\n\n{\n  \"error\": {\n    \"code\": \"UserError\",\n    \"severity\": null,\n    \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n    \"messageFormat\": \"{Message}\",\n    \"messageParameters\": {\n      \"Message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\"\n    },\n    \"referenceCode\": null,\n    \"detailsUri\": null,\n    \"target\": null,\n    \"details\": [],\n    \"innerError\": {\n      \"code\": \"UserTrainingScriptFailed\",\n      \"innerError\": null\n    },\n    \"debugInfo\": null,\n    \"additionalInfo\": null\n  },\n  \"correlation\": {\n    \"operation\": \"4ce06386a423624f8db9086f4cde3909\",\n    \"request\": \"96625a89e839edc7\"\n  },\n  \"environment\": \"westeurope\",\n  \"location\": \"westeurope\",\n  \"time\": \"2021-06-30T14:00:14.3853285+00:00\",\n  \"componentName\": \"execution-worker\"\n}\n\n\n\n\nI run the same scripts in a compute instance and didn't get the error above. Only if I submit it to the computer cluster I get this error.\nRunning in the compute instance I got the following failure messages, though the codes can run till the end:\n\nFailure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage<16.0.0,>=1.5.0'), {'azureml-core'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage<16.0.0,>=1.5.0'), {'azureml-core'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage<16.0.0,>=1.5.0'), {'azureml-core'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage<16.0.0,>=1.5.0'), {'azureml-core'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage<16.0.0,>=1.5.0'), {'azureml-core'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage<16.0.0,>=1.5.0')).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage<16.0.0,>=1.5.0'), {'azureml-core'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage<16.0.0,>=1.5.0'), {'azureml-core'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage<16.0.0,>=1.5.0'), {'azureml-core'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage<16.0.0,>=1.5.0'), {'azureml-core'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage<16.0.0,>=1.5.0'), {'azureml-core'}).\nFailure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (azure-mgmt-storage 18.0.0 (\/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages), Requirement.parse('azure-mgmt-storage<16.0.0,>=1.5.0')).\n\n\n\n\nUpdate: I changed to another conda environment and submit the scripts, still got the same error. Running in the terminal worked without any error and also without the failure messages.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-05T21:29:47.803Z",
                "Answer_score":0,
                "Answer_body":"The workaround from the customer for this issue:\n\nRemove the following lines for reading input data from main.py script, which is called in ScriptRunConfig, while submitting:\n\n ws = Workspace.from_config()\n datastore = ws.get_default_datastore()\n dataset = Dataset.File.from_files(path=(datastore, 'datasets\/exampledata'))\n\n\n\n\nThanks to Lu for sharing this.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Python code deployment using Azureml and swaggee json",
        "Question_creation_time":1622869038110,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/423211\/python-code-deployment-using-azureml-and-swaggee-j.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hii..I am trying to deploy a model built in python using azureml-model-management-sdk package and then writing to swagger json. The python function - the model simply takes 2 inputs and give an output.\nBoth the inputs are string and can contain special characters like ', \" \/ etc. Have added the handling of such special characters in the python code itself using re. But when the inputs contain these characters in the deployment setup it gives an error saying http 400 bad request. Is there a way to allow single and double quotes in the json directly to rectify this issue. Have searched all over the internet but haven't found a solution for the same. Please help.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-07T08:49:56.923Z",
                "Answer_score":0,
                "Answer_body":"@AbhishekRao-9629 Thanks for the question. Can you please share the score.py to check the schema and If you've enabled an OpenAPI(Swagger) specification for your deployment, you can use tools such as swagger-codegen to create client libraries for your service.\nPlease follow the samples to consume an Azure Machine Learning model deployed as a web service.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"DPHistogram Component returns True has type <class 'numpy.bool_'>, but expected one of: (<class 'bool'>, <class 'numbers.Integral'>)",
        "Question_creation_time":1620007339690,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/379955\/dphistogram-component-returns-true-has-type-ltclas.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi there,\n\nI am running the below code from here but getting a strange error, how can I fix the issue\n\n ages = list(range(0, 130, 10))\n age = diabetes.Age\n with sn.Analysis() as analysis:\n     data = sn.Dataset(path = data_path, column_names = cols)\n     age_histogram = sn.dp_histogram(\n         sn.cast(data['Age'], atomic_type='int', lower=0, upper=120),\n         edges = ages,\n         upper = 1000,\n         null_value = -1,\n         privacy_usage = {'epsilon': 0.5}\n         )\n        \n analysis.release()\n plt.ylim([0,100])\n width=4\n agecat_left = [x + width for x in ages]\n agecat_right = [x + 2*width for x in ages]\n plt.bar(list(range(0,120,10)), n_age, width=width, color='blue', alpha=0.7, label='True')\n plt.bar(agecat_left, age_histogram.value, width=width, color='orange', alpha=0.7, label='Private')\n plt.legend()\n plt.title('Histogram of Age')\n plt.xlabel('Age')\n plt.ylabel('Frequency')\n plt.show()\n print(age_histogram.value)\n\n\n\n\nand the error\n\n\n\nTypeError Traceback (most recent call last)\n<ipython-input-67-ed764f55a5fe> in <module>\n10 )\n11\n---> 12 analysis.release()\n\n~\\anaconda3\\lib\\site-packages\\opendp\\smartnoise\\core\\base.py in release(self)\n799 response_proto: api_pb2.ResponseRelease.Success = core_library.compute_release(\n800 serialize_analysis(self),\n--> 801 serialize_release(self.release_values),\n802 self.stack_traces,\n803 serialize_filter_level(self.filter_level))\n\n~\\anaconda3\\lib\\site-packages\\opendp\\smartnoise\\core\\value.py in serialize_release(release_values)\n103 def serialize_release(release_values):\n104 return base_pb2.Release(\n--> 105 values={\n106 component_id: serialize_release_node(release_node)\n107 for component_id, release_node in release_values.items()\n\n~\\anaconda3\\lib\\site-packages\\opendp\\smartnoise\\core\\value.py in <dictcomp>(.0)\n104 return base_pb2.Release(\n105 values={\n--> 106 component_id: serialize_release_node(release_node)\n107 for component_id, release_node in release_values.items()\n108 if release_node['value'] is not None\n\n~\\anaconda3\\lib\\site-packages\\opendp\\smartnoise\\core\\value.py in serialize_release_node(release_node)\n112 def serialize_release_node(release_node):\n113 return base_pb2.ReleaseNode(\n--> 114 value=serialize_value(\n115 release_node['value'],\n116 release_node.get(\"value_format\")),\n\n~\\anaconda3\\lib\\site-packages\\opendp\\smartnoise\\core\\value.py in serialize_value(value, value_format)\n210 array=value_pb2.Array(\n211 shape=list(array.shape),\n--> 212 flattened=serialize_array1d(array.flatten())\n213 ))\n214\n\n~\\anaconda3\\lib\\site-packages\\opendp\\smartnoise\\core\\value.py in serialize_array1d(array)\n152\n153 return value_pb2.Array1d(**{\n--> 154 data_type: container_type(data=list(array))\n155 })\n156\n\n~\\anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py in init(self, **kwargs)\n551 field_value = [_GetIntegerEnumValue(field.enum_type, val)\n552 for val in field_value]\n--> 553 copy.extend(field_value)\n554 self._fields[field] = copy\n555 elif field.cpp_type == _FieldDescriptor.CPPTYPE_MESSAGE:\n\n~\\anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\containers.py in extend(self, elem_seq)\n283 raise\n284\n--> 285 new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]\n286 if new_values:\n287 self._values.extend(new_values)\n\n~\\anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\containers.py in <listcomp>(.0)\n283 raise\n284\n--> 285 new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]\n286 if new_values:\n287 self._values.extend(new_values)\n\n~\\anaconda3\\lib\\site-packages\\google\\protobuf\\internal\\type_checkers.py in CheckValue(self, proposed_value)\n135 message = ('%.1024r has type %s, but expected one of: %s' %\n136 (proposed_value, type(proposed_value), self._acceptable_types))\n--> 137 raise TypeError(message)\n138 # Some field types(float, double and bool) accept other types, must\n139 # convert to the correct type in such cases.\n\nTypeError: True has type <class 'numpy.bool_'>, but expected one of: (<class 'bool'>, <class 'numbers.Integral'>)",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-06T20:06:41.193Z",
                "Answer_score":0,
                "Answer_body":"I'm having the same error when doing 13 - Explore Diferential privacy.ipynb from the exam DP-100. Is this issue solved yet? \ud83e\udd7a",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Price Difference between Azure ML vs Azure VM",
        "Question_creation_time":1625211332020,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/460862\/difference-between-azure-ml-vs-azure-vm.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":17,
        "Question_score":0,
        "Question_body":"Hi,\nour team is using AzureML for company's Machine Learning project.\n\nMy question is this:\n\nWhat's the price difference between AzureML and AzureVM when executing python script?\n\n\n\n\nif we use AzureVM, we may use Azure Registry together, i think.\n\nBecause our team is newbie in Azure, we are unfamiliar with this price policy\n\n\n\n\nthanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-02T15:25:30.937Z",
                "Answer_score":1,
                "Answer_body":"@ParkYoungMinDX-3445 Thank you for your query!!!\n\nDepending upon your requirement there are different possibilities.\n\nNow as per your statement you want to understand cost associated with Azure ML and Azure VM for running Python Script.\n\nNow as such for Machine Learning on Azure the Machine Learning surcharges are free and you are only charged for series of VM you use.\n\nIt has been best described in example here:\n\nYou will be billed daily. For billing purposes, a day commences at midnight UTC. Bills are generated monthly.\n\nTraining:\nAs a specific example, let\u2019s say you train a model for 100 hours using 10 DS14 v2 VMs on an Basic workspace in US West 2. For a billing month of 30 days, your bill will be as follows:\n\nAzure VM Charge: (10 machines $1.196 per machine) 100 hours = $1,196\n\nAzure Machine Learning Charge: (10 machines 16 cores $0 per core) * 100 hours = $0\n\nTotal: $1,196 + $0 = $1,196\n\nInferencing:\nAs a specific example, let\u2019s say you deploy a model for inferencing all day for a 30-day billing month using 10 DS14 v2 VMs in Basic in US West 2. For a billing month of 30 days, your bill will be as follows:\n\nAzure VM Charge: (10 machines $1.196 per machine) (24 hours * 30 days) = $8,611.20\n\nAzure Machine Learning Charge: (10 machines 16 cores $0 per core) (24 hours 30 days) = $0\n\nTotal: $8,611.20 + $0 = $8,611.20\n\nThis already includes the use of VM.\n\nNow the other scenario you are talking about is around deployment of Python App where you might need to make use of containers and the cost associated with them which is a seperate topic.\n\nNow let us come to your basic question where I do assume that you might want to explore the options available to you for running Python Script in Azure.\n\nBoth Azure Automation and Azure Functions support running Python scripts and do not require the creation of any VM's for same.\n\nFor Azure Function you can refer to this. and for cost you can refer to this.\n\nFor Azure Automation you can refer to this. For cost incurred for automation you can refer to this which mostly depends upon the Job you create.\n\nNow if you check both the option they are not billed particularly for Python script you are running but more around resources being used for what time which you can have a rough estimation from Pricing calculator links mentioned in above links.\n\nFurther now if you want to deploy or run your Python App in Azure there are mainly 4 ways as mentioned here:\n\nCreate a simple Python web app on Azure\n\n\nBuild and deploy a serverless Python app\n\n\nTry Azure Machine Learning scenarios in a preconfigured environment\n\n\nSee more ways to use Python on Azure\n\nYou don't need to worry about the Python script incurring you charges but you can check the price of associated resource you are using basically any Azure resource here on Pricing Calculator as well.\n\nHope it helps :) !!!\n\nPlease \"Accept as Answer\" if it helped so it can help others in community looking for help on similar topics.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Hyperparameter search with HyperDriveConfig for ReinforcementLearningEstimator",
        "Question_creation_time":1624459443980,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/448819\/hyperparameter-search-hyperdriveconfig-for-reinfor.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hello,\n\nI would like to automatize Hyperparameter search for my Reinforcement Learning training jobs.\nIn my understanding the workflow can be written as\n\ntraining_estimator = rl.ReinforcementLearningEstimator(\n        source_directory='.\/src',\n        entry_script=entry_script,\n        script_params=script_params,\n        compute_target=compute_target,\n        rl_framework=rl.Ray(),\n        environment=env_settings)\n    grid_sampling = hyperdrive.GridParameterSampling(parameter_space={'lr': hyperdrive.choice([0.007, 0.005])})\n    hd_config = hyperdrive.HyperDriveConfig(estimator=training_estimator,\n                                            hyperparameter_sampling=grid_sampling,\n                                            policy=early_termination_policy,\n                                            primary_metric_name=\"episode_reward_mean\",\n                                            primary_metric_goal=hyperdrive.PrimaryMetricGoal.MAXIMIZE,\n                                            max_total_runs=100,\n                                            max_concurrent_runs=4)\n    run = exp.submit(hd_config)\n\n\n\n\nHowever, this gets rejected because ReinforcementLearningEstimator does not implement MMLBaseEstimator.\n\nIs there any trick that I'm missing or this use case isn't supported by Azure?\n\n\n\n\nEDIT:\n\nThis code fails with the following error message\n\n\n\nTraceback (most recent call last):\n  File \"hyperdriverun.py\", line 188, in <module>\n    run = exp.submit(hd_config)\n  File \"\/home\/...\/python3.7\/site-packages\/azureml\/core\/experiment.py\", line 220, in submit\n    run = submit_func(config, self.workspace, self.name, **kwargs)\n  File \"\/home\/...\/python3.7\/site-packages\/azureml\/train\/hyperdrive\/_search.py\", line 145, in search\n    telemetry_values, activity_logger, **kwargs)\n  File \"\/home\/...\/python3.7\/site-packages\/azureml\/train\/hyperdrive\/_search.py\", line 38, in _create_experiment_dto\n    platform_config = hyperdrive_config._get_platform_config(workspace, experiment_name, **kwargs)\n  File \"\/home\/...\/python3.7\/site-packages\/azureml\/train\/hyperdrive\/runconfig.py\", line 672, in _get_platform_config\n    platform_config.update(self._get_platform_config_data_from_run_config(workspace))\n  File \"\/home\/...\/python3.7\/site-packages\/azureml\/train\/hyperdrive\/runconfig.py\", line 684, in _get_platform_config_data_from_run_config\n    run_config = get_run_config_from_script_run(self.estimator._get_script_run_config())\nAttributeError: 'ReinforcementLearningEstimator' object has no attribute '_get_script_run_config'",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-30T14:28:14.033Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for the information. From what I understand, you're trying to use the hyperdrive config along with reinforcement learning estimator. Hyperdrive uses scriptrunconfig which this is missing in the submit, so the error is seen. Ideally, hyperdrive will use scriptrunconfig class. Here's an example, hyperdrive config uses run_config as src which in turn is scriptconfig class. The following document explains how to use this estimator in an experiment. Hope this helps.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"FeaturizationConfig() not working",
        "Question_creation_time":1623985200440,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/441498\/featurizationconfig-not-working.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Hi,\n\nI am trying to implement FeaturizationConfig() . My dataset has 30+ columns and the featurization:'auto' works fine. But I want to specify the imputer type and column purpose.\n\n ftrzn = FeaturizationConfig()\n ftrzn.add_column_purpose('Industry', 'CategoricalHash')  # --> Doesnt work\n # ftrzn.add_column_purpose('OpportunityName', 'CategoricalHash')   --> Doesnt work\n # ftrzn.blocked_transformers = ['CatImputer', 'Imputer']\n # Fill missing values in the target column, Quantity, with zeros.\n ftrzn.add_transformer_params('Imputer', ['SFDC_ACV_GP'] , {\"strategy\": \"constant\", \"fill_value\": 0})\n    \n automl_settings = {\n     \"iteration_timeout_minutes\": 70,\n     \"enable_early_stopping\": True,\n     \"primary_metric\": 'accuracy',\n     \"featurization\": ftrzn,\n     \"verbosity\": logging.ERROR,\n     # \"n_cross_validations\": 2,\n }\n    \n # Specify training data an d type of model\n automl_config = AutoMLConfig(task='classification',\n                               debug_log='automated_ml_errors.log',\n                               training_data=dataTrainingA,\n                               validation_data=dataTestingA,\n                               label_column_name='win',\n                               **automl_settings)\n    \n    \n This is my code, and it gives me the following error:\n ErrorResponseException                    Traceback (most recent call last)\n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_with_arguments(self, func, args_list, *args, **kwargs)\n     588             else:\n --> 589                 return self._call_api(func, *args_list, **kwargs)\n     590         except ErrorResponseException as e:\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/clientbase.py in _call_api(self, func, *args, **kwargs)\n     244             else:\n --> 245                 return self._execute_with_base_arguments(func, *args, **kwargs)\n     246 \n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_with_base_arguments(self, func, *args, **kwargs)\n     333         return ClientBase._execute_func_internal(\n --> 334             back_off, total_retry, self._logger, func, _noop_reset, *args, **kwargs)\n     335 \n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_func_internal(cls, back_off, total_retry, logger, func, reset_func, *args, **kwargs)\n     366             except Exception as error:\n --> 367                 left_retry = cls._handle_retry(back_off, left_retry, total_retry, error, logger, func)\n     368 \n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/clientbase.py in _handle_retry(cls, back_off, left_retry, total_retry, error, logger, func)\n     425             elif error.response.status_code < 500 and error.response.status_code != 408:\n --> 426                 raise error\n     427         elif isinstance(error, ClientRequestError):\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_func_internal(cls, back_off, total_retry, logger, func, reset_func, *args, **kwargs)\n     357                 logger.debug(\"ClientBase: Calling {} with url {}\".format(func_name, func_url))\n --> 358                 response = func(*args, **kwargs)\n     359                 if (isinstance(response, Response) and cls._is_retryable_status_code(response.status_code) and\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/operations\/jasmine_operations.py in create_parent_run_method(self, subscription_id, resource_group_name, workspace_name, experiment_id, create_parent_run_dto, custom_headers, raw, **operation_config)\n     310         if response.status_code not in [200]:\n --> 311             raise models.ErrorResponseException(self._deserialize, response)\n     312 \n    \n ErrorResponseException: (UserError) Feature Engineering Customization: Feature is not available for requested compute target: Local\n    \n During handling of the above exception, another exception occurred:\n    \n ServiceException                          Traceback (most recent call last)\n <ipython-input-17-650bbcc7b694> in <module>\n       2 experiment_name = 'test-auto-3'\n       3 exp = Experiment(workspace=ws, name=experiment_name)\n ----> 4 local_run = exp.submit(automl_config, show_output=True)\n       5 # https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-auto-train-models\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/experiment.py in submit(self, config, tags, **kwargs)\n     218         submit_func = get_experiment_submit(config)\n     219         with self._log_context(\"submit config {}\".format(config.__class__.__name__)):\n --> 220             run = submit_func(config, self.workspace, self.name, **kwargs)\n     221         if tags is not None:\n     222             run.set_tags(tags)\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py in _automl_static_submit(automl_config_object, workspace, experiment_name, **kwargs)\n     105             compute_target,\n     106             parent_run_id,\n --> 107             show_output)\n     108 \n     109         automl_run.add_properties(global_tracking_info_registry.gather_all(settings.path))\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py in _start_execution(experiment, settings_obj, fit_params, run_config, compute_target, parent_run_id, show_output)\n     209                 ignored_dependencies=package_utilities._PACKAGES_TO_IGNORE_VERSIONS\n     210             )\n --> 211         automl_run = _default_execution(experiment, settings_obj, fit_params, True, show_output, parent_run_id)\n     212     elif is_managed:\n     213         logger.info(\"Submitting local managed run.\")\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/automlconfig.py in _default_execution(experiment, settings_obj, fit_params, legacy_local, show_output, parent_run_id)\n     129     experiment_state.console_writer.show_output = show_output\n     130     driver = ExperimentDriver(experiment_state)\n --> 131     updated_params = driver.create_parent_run(**fit_params)\n     132     start_params = _combine_start_params(updated_params, **fit_params)\n     133     return driver.start(**start_params)\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/_experiment_drivers\/experiment_driver.py in create_parent_run(self, run_configuration, compute_target, X, y, sample_weight, X_valid, y_valid, sample_weight_valid, cv_splits_indices, existing_run, training_data, validation_data, test_data, _script_run, parent_run_id, kwargs)\n     219             _script_run,\n     220             parent_run_id,\n --> 221             kwargs)\n     222         assert self.experiment_state.current_run\n     223         self.experiment_state.parent_run_id = self.experiment_state.current_run.id\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/runtime\/_experiment_drivers\/local_experiment_driver.py in create_parent_run(self, run_configuration, compute_target, X, y, sample_weight, X_valid, y_valid, sample_weight_valid, cv_splits_indices, existing_run, training_data, validation_data, test_data, _script_run, parent_run_id, kwargs)\n     176                 existing_run,\n     177                 managed_run_id=self.experiment_state.automl_settings._local_managed_run_id,\n --> 178                 _script_run=_script_run\n     179             )\n     180 \n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/runtime\/_experiment_drivers\/local_experiment_driver.py in _create_parent_run_for_local(self, parent_run_dto, existing_run, managed_run_id, _script_run)\n     509                     logger.info(\"Start creating parent run\")\n     510                     self.experiment_state.parent_run_id = self.experiment_state.jasmine_client.post_parent_run(\n --> 511                         parent_run_dto\n     512                     )\n     513 \n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/jasmine_client.py in post_parent_run(self, create_parent_run_dto)\n      75         \"\"\"\n      76         return self._execute_with_experimentid_arguments(\n ---> 77             self._client.jasmine.create_parent_run_method, create_parent_run_dto)\n      78 \n      79     def post_remote_jasmine_snapshot_run(self, parent_run_id, run_definition, snapshotId):\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/experiment_client.py in _execute_with_experimentid_arguments(self, func, *args, **kwargs)\n     264                                             copy.deepcopy(\n     265                                                 self._experiment_arguments_with_experiment_id),\n --> 266                                             *args, **kwargs)\n     267 \n     268     def _combine_with_experiment_paginated_dto(self, func, count_to_download=0, *args, **kwargs):\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_with_arguments(self, func, args_list, *args, **kwargs)\n     589                 return self._call_api(func, *args_list, **kwargs)\n     590         except ErrorResponseException as e:\n --> 591             raise ServiceException(e)\n    \n ServiceException: ServiceException:\n     Code: 401\n     Message: (UserError) Feature Engineering Customization: Feature is not available for requested compute target: Local\n     Details:\n    \n     Headers: {\n         \"Date\": \"Fri, 18 Jun 2021 02:54:07 GMT\",\n         \"Content-Type\": \"application\/json; charset=utf-8\",\n         \"Content-Length\": \"783\",\n         \"Connection\": \"keep-alive\",\n         \"Request-Context\": \"appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d\",\n         \"x-ms-response-type\": \"error\",\n         \"x-ms-client-request-id\": \"e243c9bb-8253-4eb3-94ac-029920be77d7\",\n         \"x-ms-client-session-id\": \"\",\n         \"Strict-Transport-Security\": \"max-age=15724800; includeSubDomains; preload\",\n         \"X-Content-Type-Options\": \"nosniff\",\n         \"x-request-time\": \"0.095\"\n     }\n     InnerException: {\n     \"additional_properties\": {},\n     \"error\": {\n         \"additional_properties\": {\n             \"debugInfo\": null,\n             \"additionalInfo\": null\n         },\n         \"code\": \"UserError\",\n         \"severity\": null,\n         \"message\": \"Feature Engineering Customization: Feature is not available for requested compute target: Local\",\n         \"message_format\": null,\n         \"message_parameters\": null,\n         \"reference_code\": null,\n         \"details_uri\": null,\n         \"target\": null,\n         \"details\": [],\n         \"inner_error\": {\n             \"additional_properties\": {},\n             \"code\": \"AuthorizationError\",\n             \"inner_error\": {\n                 \"additional_properties\": {},\n                 \"code\": \"FeatureUnavailableError\",\n                 \"inner_error\": null\n             }\n         }\n     },\n     \"correlation\": {\n         \"operation\": \"ba0a493b549fde42b742c2a4eef8a7c0\",\n         \"request\": \"02cd58b16cf07b46\"\n     },\n     \"environment\": \"eastus2\",\n     \"location\": \"eastus2\",\n     \"time\": {},\n     \"component_name\": \"jasmine\"\n }",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-18T12:47:01.637Z",
                "Answer_score":0,
                "Answer_body":"@VanshiqaAgrawal-5661 Thanks for the question .Can you please share the notebook that you are trying. Feature config which comes with \u2018auto\u2019 like imputation. Please follow the docs to customize-feature-engineering for automl.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-features#featurization\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train#customize-feature-engineering",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unable to install Detectron2 Azure ML 3.8",
        "Question_creation_time":1624259210607,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/444357\/unable-to-install-detectron2-azure-ml-38.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I have created a NC6_SV3 compute\nCreated new conda environment in terminal\nThis command : python -m pip install 'git+https:\/\/github.com\/facebookresearch\/detectron2.git'\nIs giving error :\nERROR: Command errored out with exit status 1: \/anaconda\/envs\/darthgo\/bin\/python -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'\/tmp\/pip-req-build-x6bevf0j\/setup.py'\"'\"'; file='\"'\"'\/tmp\/pip-req-build-x6bevf0j\/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(file) if os.path.exists(file) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, file, '\"'\"'exec'\"'\"'))' install --record \/tmp\/pip-record-4_jvac6y\/install-record.txt --single-version-externally-managed --compile --install-headers \/anaconda\/envs\/darthgo\/include\/python3.8\/detectron2 Check the logs for full command output.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-22T07:41:06.977Z",
                "Answer_score":0,
                "Answer_body":"@parthdandavate-0616 Thanks for the question. We are able to reproduce this issue and we have forwarded to the product team to check.\n\nPlease raise an issue in the following link https:\/\/github.com\/facebookresearch\/detectron2\/issues for this error.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Can i automate ML training?",
        "Question_creation_time":1624953599093,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/455797\/can-i-automate-ml-training.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hello,\n\nCan i automate the procedure of training a machine learning model in Azure Machine Learning Studio and add a trigger to initiate all this?\n\nThank you.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-02T04:53:34.78Z",
                "Answer_score":0,
                "Answer_body":"@MichalisPapallis Thanks for the details. Please follow the document Eventhub to trigger the Azure Machine Learning Pipeline.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-event-grid#sample-scenarios\n\nImage from MLOPSPython:",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Deploy model on AKS ModuleNotFoundError: No module named 'main'",
        "Question_creation_time":1624613802117,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/451760\/deploy-model-on-aks-modulenotfounderror-no-module.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"When trying to deploy a model on AKS an error occurs.\nThe traceback is the following:\nException in worker process\nTraceback (most recent call last):\nFile \"\/azureml-envs\/azureml_828a57093157f4d4d37377511c7dd8a0\/lib\/python3.7\/site-packages\/gunicorn\/arbiter.py\", line 583, in spawn_worker\nworker.init_process()\nFile \"\/azureml-envs\/azureml_828a57093157f4d4d37377511c7dd8a0\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 129, in init_process\nself.load_wsgi()\nFile \"\/azureml-envs\/azureml_828a57093157f4d4d37377511c7dd8a0\/lib\/python3.7\/site-packages\/gunicorn\/workers\/base.py\", line 138, in load_wsgi\nself.wsgi = self.app.wsgi()\nFile \"\/azureml-envs\/azureml_828a57093157f4d4d37377511c7dd8a0\/lib\/python3.7\/site-packages\/gunicorn\/app\/base.py\", line 67, in wsgi\nself.callable = self.load()\nFile \"\/azureml-envs\/azureml_828a57093157f4d4d37377511c7dd8a0\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 52, in load\nreturn self.load_wsgiapp()\nFile \"\/azureml-envs\/azureml_828a57093157f4d4d37377511c7dd8a0\/lib\/python3.7\/site-packages\/gunicorn\/app\/wsgiapp.py\", line 41, in load_wsgiapp\nreturn util.import_app(self.app_uri)\nFile \"\/azureml-envs\/azureml_828a57093157f4d4d37377511c7dd8a0\/lib\/python3.7\/site-packages\/gunicorn\/util.py\", line 350, in import_app\nimport(module)\nFile \"\/var\/azureml-server\/entry.py\", line 1, in <module>\nimport create_app\nFile \"\/var\/azureml-server\/create_app.py\", line 4, in <module>\nfrom routes_common import main\nFile \"\/var\/azureml-server\/routes_common.py\", line 32, in <module>\nfrom aml_blueprint import AMLBlueprint\nFile \"\/var\/azureml-server\/aml_blueprint.py\", line 29, in <module>\nimport main\nModuleNotFoundError: No module named 'main'",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-07-02T04:59:21.207Z",
                "Answer_score":0,
                "Answer_body":"Thanks for the details. The product team is checking on this and updates at the following link for the same.\n\nhttps:\/\/github.com\/Azure\/azure-sdk-for-python\/issues\/19493",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to save and load ML model with Azure Data Factory",
        "Question_creation_time":1623657811393,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/434449\/how-to-save-and-load-ml-model-with-azure-data-fact.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I have an Azure Data factory that receives data from a service bus and then I want to classify my data with an ML model.\n\nIs there any solution to save and load the ML model on the Azure Data Factory pipeline?\n\nFor your information, I want to use cloud base solution. I don't use the PICKLE library.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-16T16:21:07.257Z",
                "Answer_score":0,
                "Answer_body":"Hello @MohsenAkhavan,\nThanks for the ask and using the Microsoft Q&A platform .\n\nI think you can use the machine learning activity . Read and watch the video here .\n\nThe challenge in your case is the data is in EH and at this time ADF cannot read EH data . I suggest you to use a Azure stream analytics jobs and read the data from EH and write it to SQL or blob . Once the data is in any of these two sources ADF can be used to read the data .\n\nPlease do let me know how it goes .\nThanks\nHimanshu\nPlease do consider clicking on \"Accept Answer\" and \"Up-vote\" on the post that helps you, as it can be beneficial to other community members",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure ML Pipeline deployment",
        "Question_creation_time":1625044229433,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/457784\/azure-ml-pipeline-deployment.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi there,\n\nWhat is the method to deploy a specific Experiment Run of Azure ML Pipeline from Experiment tab?\n\nThanks,\nHamsini Sharma",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-30T13:05:16.19Z",
                "Answer_score":0,
                "Answer_body":"Hi @HamsiniS-9867\n\nRefer to the below url it is explained.\n1. https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-automated-ml-for-ml-models\n2. https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-automlstep-in-pipelines\n\n\n\n\n\nIf the Answer is helpful, please click Accept Answer and up-vote, this can be beneficial to other community members.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-07-01T06:25:16.07Z",
                "Answer_score":0,
                "Answer_body":"Hi there,\n\nThanks for your response. I need the method to deploy the model from a specific experiment run of a Pipeline build from Designer.\n\nFor example, below screen is the experiment runs of Pipeline Automobile_Price_Prediction created from Designer. How can I deploy the Run 51.\n\n\n\n\n\nFYI - As per MS documentation, we can only deploy the latest pipeline present in the designer.\n\nThanks,",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to read csv file(already registered in azureblobstore) as pandas DataFrame in score.py?",
        "Question_creation_time":1625061831393,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/458181\/how-to-read-csv-filealready-registered-in-azureblo.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"I am creating a ACI web service in azureml where I need to include a csv file (which I have registered in azureblobstore) in the score.py file. I have tried \"Dataset.get_by_name(ws,'dataset_name', version='latest')\" which is working fine in my local machine but getting error while deploying as web service.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure machine learning data labelling- Is it possible to assign different labelers to label same data in a single project to reach a consensus?",
        "Question_creation_time":1625056620740,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/458004\/azure-machine-learning-data-labelling-is-it-possib.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Currently! I'm experimenting with the azure data labelling tool in the machine learning workspace for image classification, what I found was azure shows only the unlabelled data to each user i.e if a user has already labelled an image, other users won't be shown the same image again.\nIs there any setting that exists, which can be enabled or disabled so that we can let more than one labeller label the same data?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-30T17:13:49.547Z",
                "Answer_score":0,
                "Answer_body":"Thanks for reaching to us. This capability is currently in development, and expected to release soon.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Transforming the Data Columns of Imported Data from Cosmos DB",
        "Question_creation_time":1623844869557,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/438667\/transforming-the-data-columns-of-imported-data-fro.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hi,\nI store edge device data to Cosmos DB and in Azure ML the Import Data shows the data as\nTimestamp, Name, Value and for each timestamp there are as many rows as there are parameters as shown in this snapshot \n\n\n\n\n\nI suppose for downstream processing in Azure ML, I need to transform the data as 1 Row for each Timestamp and parameters as Column\nTimestamp parameter1 para2 para3\n12:23:23 3.2 3.4 2\n12:23:24 .......\n\nis that Right ?\nis yes, how to transform data in Azure ML\nI tried Import Data -> Convert to Dataset ->sql transformation and wrote a sql query\n\nselect ts,\nmax(case when nm = 'parameter1' then vl end) as parameter1,\nmax(case when nm = 'parameter2' then vl end) as parameter2,\nmax(case when nm = 'parameter3' then vl end) as parameter3\nfrom t1\ngroup by ts\n\nThis works fine, but i cannot hard code the parameter name as they will vary for each model\n\nSo is my approach right ? or is there better way of doing this ?\nif this is approach, what should be sql query so it can handle any parameter name ?\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-17T10:03:16.54Z",
                "Answer_score":0,
                "Answer_body":"@HCLAZURECloudConnectedECOSystems-0579 Thanks for the question. Can you please confirm are you using Designer or Azure ML SDK and details about the usecase?. You can do the Data processing before. Please follow the sample notebook to work with timeseries dataset. In the Designer, To filter data you can use Apply SQL Transformation to write SQL query or Split Data. You can also use Execute Python Script module to write your own data processing logic.\n\nPreparing Data:https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-forecast#preparing-data",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unable to create pyspark DataFrame from Datastore in azureml-sdk (version 1.12.0)",
        "Question_creation_time":1602510230157,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/123772\/unable-to-create-pyspark-dataframe-from-datastore.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":3,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"I am trying to read contents from a CSV file into Spark DataFrame using azureml-sdk using following code but an exception is being thrown.\n\nCode throwing exception\n\n import pyspark.sql as spark\n from azureml.core import Dataset\n dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, file_path)], header = False)\n sdf: spark.DataFrame = dataset.to_spark_dataframe()\n sdf.show()\n\n\n\nException\n\n ---------------------------------------------------------------------------\n Py4JJavaError                             Traceback (most recent call last)\n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/dataset_error_handling.py in _try_execute(action, operation, dataset_info, **kwargs)\n     100         else:\n --> 101             return action()\n     102     except Exception as e:\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/_loggerfactory.py in wrapper(*args, **kwargs)\n     178                 try:\n --> 179                     return func(*args, **kwargs)\n     180                 except Exception as e:\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/dataflow.py in to_spark_dataframe(self)\n     763         self._raise_if_missing_secrets()\n --> 764         return self._spark_executor.get_dataframe(steps_to_block_datas(self._steps), use_sampling=False)\n     765 \n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/sparkexecution.py in get_dataframe(self, steps, use_sampling, overrides, use_first_record_schema)\n     136                              overrides,\n --> 137                              use_first_record_schema)\n     138 \n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/sparkexecution.py in _execute(self, blocks, export_format, use_sampling, overrides, use_first_record_schema)\n     169                                           + lariat_version + '.')\n --> 170             raise e\n     171 \n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/sparkexecution.py in _execute(self, blocks, export_format, use_sampling, overrides, use_first_record_schema)\n     160             if export_format == ExportScriptFormat.PYSPARKDATAFRAMELOADER:\n --> 161                 return module.LoadData(secrets=secrets, schemaFromFirstRecord=use_first_record_schema)\n     162             else:\n    \n \/tmp\/spark-6ce53791-c8e4-4db0-bd37-bedb53a1ef1e\/userFiles-dda6cd30-5d1e-48cf-af87-9c7c2a4b8038\/loaderb9bc01c2b40c4b7aa86a95d343021e0c.py in LoadData(secrets, schemaFromFirstRecord)\n       8 def LoadData(secrets=dict(), schemaFromFirstRecord=False):\n ----> 9     pex = Executor(\"S4ddf53ee8d5f4173bd3dcf4b51d78247\", \"dprep_2.11\", \"0.116.0\", \"42315\", \"39a925e4-9ae9-4588-93c4-5433250b7f73\")\n      10     jex = pex.jex\n    \n \/tmp\/spark-6ce53791-c8e4-4db0-bd37-bedb53a1ef1e\/userFiles-dda6cd30-5d1e-48cf-af87-9c7c2a4b8038\/Executor.py in __init__(self, scalaName, dprepMavenPackageName, dprepMavenPackageMatchingVersion, pythonHostChannelPort, pythonHostSecret)\n      54             pythonHostChannelPort,\n ---> 55             pythonHostSecret)\n      56 \n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/py4j\/java_gateway.py in __call__(self, *args)\n    1568         return_value = get_return_value(\n -> 1569             answer, self._gateway_client, None, self._fqn)\n    1570 \n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/py4j\/protocol.py in get_return_value(answer, gateway_client, target_id, name)\n     327                     \"An error occurred while calling {0}{1}{2}.\\n\".\n --> 328                     format(target_id, \".\", name), value)\n     329             else:\n    \n Py4JJavaError: An error occurred while calling None.com.microsoft.dprep.execution.PySparkExecutor.\n : java.lang.NoClassDefFoundError: Could not initialize class com.microsoft.dprep.integration.azureml.AmlPySdkInvoker$\n     at com.microsoft.dprep.execution.PySparkExecutor.<init>(PySparkExecutor.scala:79)\n     at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n     at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n     at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n     at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n     at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n     at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n     at py4j.Gateway.invoke(Gateway.java:238)\n     at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n     at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n     at py4j.GatewayConnection.run(GatewayConnection.java:238)\n     at java.lang.Thread.run(Thread.java:748)\n    \n    \n During handling of the above exception, another exception occurred:\n    \n AzureMLException                          Traceback (most recent call last)\n <ipython-input-30-c546b1aded42> in <module>\n       2 from azureml.core import Dataset\n       3 dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, file_path)], header = False)\n ----> 4 sdf: spark.DataFrame = dataset.to_spark_dataframe()\n       5 sdf.show()\n       6 \n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/_loggerfactory.py in wrapper(*args, **kwargs)\n     124             with _LoggerFactory.track_activity(logger, func.__name__, activity_type, custom_dimensions) as al:\n     125                 try:\n --> 126                     return func(*args, **kwargs)\n     127                 except Exception as e:\n     128                     if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/tabular_dataset.py in to_spark_dataframe(self)\n     187         return _try_execute(dataflow.to_spark_dataframe,\n     188                             'to_spark_dataframe',\n --> 189                             None if self.id is None else {'id': self.id, 'name': self.name, 'version': self.version})\n     190 \n     191     @track(_get_logger, custom_dimensions={'app_name': 'TabularDataset'}, activity_type=_PUBLIC_API)\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/dataset_error_handling.py in _try_execute(action, operation, dataset_info, **kwargs)\n     102     except Exception as e:\n     103         message, is_dprep_exception = _construct_message_and_check_exception_type(e, dataset_info, operation)\n --> 104         _dataprep_error_handler(e, message, is_dprep_exception)\n     105 \n     106 \n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/dataset_error_handling.py in _dataprep_error_handler(e, message, is_dprep_exception)\n     143         raise AzureMLException(message, inner_exception=e)\n     144     else:\n --> 145         raise AzureMLException(message, inner_exception=e)\n     146 \n     147 \n    \n AzureMLException: AzureMLException:\n     Message: Execution failed unexpectedly due to: Py4JJavaError\n     InnerException An error occurred while calling None.com.microsoft.dprep.execution.PySparkExecutor.\n : java.lang.NoClassDefFoundError: Could not initialize class com.microsoft.dprep.integration.azureml.AmlPySdkInvoker$\n     at com.microsoft.dprep.execution.PySparkExecutor.<init>(PySparkExecutor.scala:79)\n     at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n     at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n     at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n     at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n     at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n     at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n     at py4j.Gateway.invoke(Gateway.java:238)\n     at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n     at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n     at py4j.GatewayConnection.run(GatewayConnection.java:238)\n     at java.lang.Thread.run(Thread.java:748)\n    \n     ErrorResponse \n {\n     \"error\": {\n         \"message\": \"Execution failed unexpectedly due to: Py4JJavaError\"\n     }\n }\n\n\n\nHowever, I can read and print the data with the following code i.e. create as a Panda's DataFrame.\n\nWorking code\n\n dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, file_path)], header = False)\n #sdf: spark.DataFrame = dataset.to_spark_dataframe()\n sdf: pd.DataFrame = dataset.to_pandas_dataframe()\n print(sdf.head(3))",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-13T12:56:36.877Z",
                "Answer_score":0,
                "Answer_body":"@ramr-msft The CSV file is on ADLS Gen2. The error is on the following line. Like I've mentioned in the issue, I can create the Pandas DataFrame without any issues.\n\n sdf: spark.DataFrame = dataset.to_spark_dataframe()",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-06-29T20:02:50.94Z",
                "Answer_score":1,
                "Answer_body":"Hi there,\n\nWas this problem resolved? I'm getting the same error.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Model Profiling",
        "Question_creation_time":1623937967690,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/440711\/azure-ml-model-profiling.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I have a model already deployed on AzureML using AKS. Now i want to use the same model for Model Profiling so that we can set up an auto-scaler. But Model Profiling throws an error every time.\n\nERROR: UserWarning: Model Profiling operation failed with the following error: Model service has failed with status: CrashLoopBackOff: Back-off restarting failed. This may be caused by errors in your scoring file's init() function. Error logs URL: Log upload failed.\n\nIt says there is some problem in the init() function. But the same model is deployed on AKS.\n\nAnd sometimes it shows an error is in the run() function.\n\nERROR: Too many scoring request failures experienced while testing the model.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Integrate Logic Apps with Machine Learning",
        "Question_creation_time":1624612238463,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/451893\/integrate-logic-apps-with-machine-learning.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"Hello everyone,\n\nIs it possible to integrate Logic Apps with Machine Learning so that i can trigger the Logic App and then the Logic App starts a ML model training automatically?\n\nThank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-28T11:28:51.723Z",
                "Answer_score":1,
                "Answer_body":"@MichalisPapallis-0974 With respect to Azure Machine learning you can create trigger for HTTP action to run published ML pipelines, these are basically endpoints that are published of the pipeline. So, if you have setup your pipeline using the SDK then you can use that endpoint with a trigger to run the pipeline.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Attaching local computer to ML Studio and use it with Azure AutoML and Azure Designer",
        "Question_creation_time":1624632132377,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/452250\/attaching-local-computer-to-ml-studio-and-use-it-w.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hey there,\n\nI was wondering, whether it is possible to connect your local computer as a compute target to the workspace and then access it as a compute target for AutoML and the Designer in the ML Studio (instead of a compute cluster)?\nI have read through the documentation and I feel like if this is possible, it is not very well-documented.\n\nThanks in advance!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-25T20:20:23.443Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. You can use local compute for model training\/deployment including automl. However, you cannot attach it directly in Designer or ML Studio interface. You can only attach it from your local environment. Hope this helps!",
                "Answer_comment_count":5,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Failure while loading azureml_run_type_providers",
        "Question_creation_time":1599302705087,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/87272\/failure-while-loading-azureml-run-type-providers.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"I am running RStudio on azureml compute instance.\n\nRunning the test examples in vignettes used to work.\n\nHowever, today I encountered this error:\n\n\n\n library(azuremlsdk)\n # current directory set to source code \n # config file in current folder \"config.js\"\n ws <- load_workspace_from_config() \n    \n Error:\n Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (portalocker 2.0.0 (\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages), Requirement.parse('portalocker~=1.0'), {'msal-extensions'}).\n\n\n\nHerman",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-07T14:13:15.257Z",
                "Answer_score":0,
                "Answer_body":"@HermanTan-5956 Thanks for the question. Can you please share the sample that you are trying. If possible please share the full service logs to check.\n\nWe have forwarded to the product team to check on this error.\nPlease follow the below at the azuremlsdk package, which operationalizes R to Azure ML service and is built on reticulate.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-r-experiment\n\nhttps:\/\/azure.github.io\/azureml-sdk-for-r\/\n\nhttps:\/\/github.com\/Azure\/azureml-sdk-for-r",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-09-18T14:28:53.323Z",
                "Answer_score":2,
                "Answer_body":"I was able to get rid of it using this pip install\n\n$ pip install azureml-sdk[notebooks]",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Dataset for inference data is registered with wrong path when deployed on Kubernetes",
        "Question_creation_time":1624590394283,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/451349\/dataset-for-inference-data-is-registered-with-wron.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"When model is deployed on Kubernetes with model data collection set to true, the dataset which gets registered in workspace has a wrong path.\nThe blob storage path where this data being collected has default in it but the path registered doesn't have default.\n\nFor example, actual path on storage:\n\n azuremlwsdev\/modeldata\/GUID\/ad\/ad-workspace-dev\/dev-ad-model-v1-2-jen\/model\/default\/inputs\n\n\n\nPath dataset is registered with:\n\n GUID\/ad\/ad-workspace-dev\/dev-ad-model-v1-2-jen\/model\/inputs\/**\/inputs*.csv\n\n\n\nCode inside our scoring service to init collector and use them:\n\n def init():    \n     global inputs_dc, prediction_dc\n     ...\n     inputs_dc = ModelDataCollector('model', designation=\"inputs\", feature_names=feature_set.columns.values.tolist())\n     prediction_dc = ModelDataCollector('model', designation=\"predictions\", feature_names=[\"score\"])\n    \n def run(raw_data):\n     inputs_dc.collect(X)\n     prediction_dc.collect(y_pred)\n\n\n\nBelow are the library versions being used:\n\n azureml-defaults==1.1.5\n azureml-monitoring==0.1.0a21",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Has Anyone Been Able to Successfully Parallelize Their Code on a VM?",
        "Question_creation_time":1618799484800,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/361772\/has-anyone-been-able-to-successfully-parallelize-t.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"I wrote a script to train a large number of time series models on my Azure VM and it uses the multiprocessing.Pool package to parallelize the code to reduce the training time period. The code runs perfectly on my local machine, but does not parallelize across the available cores when I run the script on my Azure VM. If anyone has run into this problem with the Pool package or has alternate suggestions as to how to parallelize training on a VM, I'd appreciate your insight. Thanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-19T14:25:19.597Z",
                "Answer_score":0,
                "Answer_body":"@GregoryJacobs-3642 Thanks for the question. For parallel\/distributed training - if deep learning, frameworks like PyTorch and Tensorflow can typically be distributed directly or use something like Horovod to easily scale out on Azure ML Clusters - see an example here.\n\nAnother I've been watching is HyperGBM\/Hypernets: DataCanvasIO\/Hypernets: A General Automated Machine Learning framework to simplify the development of End-to-end AutoML toolkits in specific domains. (github.com), DataCanvasIO\/HyperGBM: A full pipeline AutoML tool for tabular data (github.com).",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"why I do not have \"Open in a new Notebook\" in my menu",
        "Question_creation_time":1624421404470,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/447926\/why-i-do-not-have-34open-in-a-new-notebook34-in-my.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"I tried Azure machine learning workspace and I try to use 'right click' -> 'CSV dataset' -> There is no \"Open in a new Notebook\" in the menu, even a grey one. Could someone please guide me? Thank you",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-24T08:37:10.93Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nI added a screenshot, hope this helps.\n\nRegards,",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Where to Report Issues with Azure ML Command Line",
        "Question_creation_time":1619791289953,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/378845\/where-to-report-issues-with-azure-ml-command-line.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"I am using az ml command line and finding several broken pieces of functionality. How do I report these broken features to the team that maintains the az ml command line tools?\n\n\n\n\nExample:\n\nPS C:\\projects\\Lead-Score-POC> az ml dataset show --id 154c7483-bc04-43b5-a614-3d278e211111\nMissing required package \"azureml-dataset-runtime\", which is unavailable for 32bit Python.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-03T13:14:02.79Z",
                "Answer_score":0,
                "Answer_body":"please forward my original post.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-05T00:08:15.533Z",
                "Answer_score":1,
                "Answer_body":"Hello @JeremiahAdams-0775\n\nThanks for the feedback, I have forwarded this to engineering team, will let you know if I have any response from them.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"The columns appears with another name",
        "Question_creation_time":1624312518567,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/445579\/the-columns-appears-with-another-name.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello I'm practicing in Microsoft Machine Learning Studio.\n\nIn a experiment I use de control \"Import data\", then in the properties I use the data source: https:\/\/github.com\/rdiazconcha\/lil-azure-machine-learning-y-ai\/blob\/master\/modulo-2\/power-export_min.csv\n\nThat is the file to practice in my course.\n\nThe resto of the fields are filled like this:\n\n\n\n\nBut, when I use the choice visualize, appears like this:\n\n\n\n\n\nBut, those are not the names of the columns.\nWhat I'm doing wrong?\n\nThanks a lot for your help.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-22T17:40:47.527Z",
                "Answer_score":0,
                "Answer_body":"@CASTANEDARODRIGUEZDAMIAN-2301 Hello, I got you! Please click \"raw\" and use the url then to use the resource file. https:\/\/raw.githubusercontent.com\/rdiazconcha\/lil-azure-machine-learning-y-ai\/master\/modulo-2\/power-export_min.csv\n\n\nThen you should be good! Thanks.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-06-22T00:04:45.333Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nThanks for reaching out to us.\n\nSince you are using the data source wizard, you need to tell the studio you have a header row. Studio will use the header row as your column name as below.\n\n\n\n\nLet me know if you have more questions! Thanks! ^^\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-06-22T14:09:59.227Z",
                "Answer_score":0,
                "Answer_body":"Hello YutongTie-MSFT\n\nI did it. I selected that checkbox:\n\n\n\n\nBut is appearing like this yet:\n\n\n\n\n\nIs missing me something to do?\n\nThanks for your help.\n\nRegards.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-06-23T15:37:54.913Z",
                "Answer_score":0,
                "Answer_body":"@YutongTie-MSFT : It works!\nThank you so much!\nRegards.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"While registering a dataframe in AzureML pipeline, getting error: 'DataFrame' object has no attribute 'register. How do we actually store dataframe into Azure Blob Storage?",
        "Question_creation_time":1624431973167,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/448224\/while-registering-a-dataframe-in-azureml-pipeline.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"While registering a dataframe in AzureML pipeline, getting error: 'DataFrame' object has no attribute 'register. How do we actually store dataframe into Azure Blob Storage?\n\nCode snippet-\n\n<DataFrame>.register(workspace=ws, name='<abc>', description='<abc>', tags = {'format':'CSV'}, create_new_version=True)",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-23T10:48:47.457Z",
                "Answer_score":0,
                "Answer_body":"@JitenderKumarChandel-0663 I think this is a valid error since the dataset cannot be registered with the above command. You should try the steps mentioned in this notebook.\n\nThese steps should help to register your CSV data as dataframe.\n\n datastore = ws.get_default_datastore()\n datastore.upload_files(files = ['.\/train-dataset\/iris.csv'],\n                        target_path = 'train-dataset\/tabular\/',\n                        overwrite = True,\n                        show_progress = True)\n    \n from azureml.core import Dataset\n dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, 'train-dataset\/tabular\/iris.csv')])\n    \n # preview the first 3 rows of the dataset\n dataset.take(3).to_pandas_dataframe()\n\n\n\nPlease feel free to accept the above response as answer if it helped. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to increase the number of parameters logged in MLFlow (current max limit is 100)",
        "Question_creation_time":1623455284870,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/433155\/how-to-increase-the-number-of-parameters-logged-in.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"I'm using AzureML to train some networks and the recommended MLFlow to log parameters and metrics.\nHowever, I have reached the maximum limit of 100 parameters (mostly configuration options I pass to the trainer but also real model parameters). And I get the following error:\n\nmlflow.exceptions.RestException: BAD_REQUEST: Response: {'Error': {'Code': 'UserError', 'Severity': None, 'Message': 'A field of the entity is over the size limit. FieldName=Parameters, Limit=100, Size=101. See https:\/\/aka.ms\/azure-machine-learning-limits for service limits documentation.', 'MessageFormat': None, 'MessageParameters': None, 'ReferenceCode': None, 'DetailsUri': None, 'Target': None, 'Details': [], 'InnerError': None, 'DebugInfo': None, 'AdditionalInfo': None}, 'Correlation': {'operation': 'a9544317f5dd99458be006824948b38d', 'request': '0b131227514b3b4b'}, 'Environment': 'eastus', 'Location': 'eastus', 'ComponentName': 'mlflow', 'error_code': 'BAD_REQUEST'}\n\nIs there a way to increase this limit? If not, are there any other workarounds?\n\nThank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-14T06:55:54.64Z",
                "Answer_score":0,
                "Answer_body":"@JS-0758 Unfortunately, it looks like we only allow logging 100 parameters per run id. Are you using autolog or manually logging more than 100 params?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Not exporting to RunHistory as the exporter is either stopped or there is no data",
        "Question_creation_time":1624366258553,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/446927\/not-exporting-to-runhistory-as-the-exporter-is-eit.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi Everyone!\n\nI'm new in Azure ML and I am getting a error message that I wasn't able to solve.\nI got the following message \"Not exporting to RunHistory as the exporter is either stopped or there is no data.\"\nThe instance compute is on anb the dataset was added in the Azure ML\n\nFollow the script :\n\n1\/06\/22 12:21:47 Starting App Insight Logger for task: runTaskLet\n2021\/06\/22 12:21:47 Version: 3.0.01622.0001 Branch: .SourceBranch Commit: 1141612\n2021\/06\/22 12:21:47 Attempt 1 of http call to http:\/\/10.0.0.5:16384\/sendlogstoartifacts\/info\n2021\/06\/22 12:21:47 Attempt 1 of http call to http:\/\/10.0.0.5:16384\/sendlogstoartifacts\/status\n[2021-06-22T12:21:47.687869] Entering context manager injector.\n[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['training\/train_aml.py', '--model_name', 'prjVerzani_model.pkl', '--step_output', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/mlops-vzn-aml-ws\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\/mounts\/workspaceblobstore\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\/pipeline_data', '--dataset_version', 'latest', '--data_file_path', 'none', '--caller_run_id', 'none', '--dataset_name', 'verzani'])\nScript type = None\n[2021-06-22T12:21:48.081067] Entering Run History Context Manager.\n[2021-06-22T12:21:48.983332] Current directory: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/mlops-vzn-aml-ws\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\/wd\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\n[2021-06-22T12:21:48.983550] Preparing to call script [training\/train_aml.py] with arguments:['--model_name', 'prjVerzani_model.pkl', '--step_output', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/mlops-vzn-aml-ws\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\/mounts\/workspaceblobstore\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\/pipeline_data', '--dataset_version', 'latest', '--data_file_path', 'none', '--caller_run_id', 'none', '--dataset_name', 'verzani']\n[2021-06-22T12:21:48.983571] After variable expansion, calling script [training\/train_aml.py] with arguments:['--model_name', 'prjVerzani_model.pkl', '--step_output', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/mlops-vzn-aml-ws\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\/mounts\/workspaceblobstore\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\/pipeline_data', '--dataset_version', 'latest', '--data_file_path', 'none', '--caller_run_id', 'none', '--dataset_name', 'verzani']\n\n\nRunning train_aml.py\nArgument [model_name]: prjVerzani_model.pkl\nArgument [step_output]: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/mlops-vzn-aml-ws\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\/mounts\/workspaceblobstore\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\/pipeline_data\nArgument [dataset_version]: latest\nArgument [data_file_path]: none\nArgument [caller_run_id]: none\nArgument [dataset_name]: verzani\nGetting training parameters\nParameters: {'n_estimators': 100, 'max_depth': 3, 'warm_start': True, 'random_state': 42}\n2021\/06\/22 12:21:52 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\nbash: line 1: 115 Killed \/azureml-envs\/azureml_ebb66c9c8565cab685eeed5fbcc8b544\/bin\/python $AZ_BATCHAI_JOB_TEMP\/azureml\/53814dea-db07-448f-820a-1f3bc510c581\/azureml-setup\/context_manager_injector.py \"-i\" \"ProjectPythonPath:context_managers.ProjectPythonPath\" \"-i\" \"RunHistory:context_managers.RunHistory\" \"-i\" \"TrackUserError:context_managers.TrackUserError\" \"training\/train_aml.py\" \"--model_name\" \"$AML_PARAMETER_model_name\" \"--step_output\" \"$AZUREML_DATAREFERENCE_pipeline_data\" \"--dataset_version\" \"$AML_PARAMETER_dataset_version\" \"--data_file_path\" \"$AML_PARAMETER_data_file_path\" \"--caller_run_id\" \"$AML_PARAMETER_caller_run_id\" \"--dataset_name\" \"verzani\"\n2021\/06\/22 12:22:11 Skipping parsing control script error. Reason: Error json file doesn't exist. This most likely means that no errors were written to the file. File path: \/mnt\/batch\/tasks\/workitems\/ff9b58ce-7857-4d95-87be-5f16c783b667\/job-1\/53814dea-db07-448f-8_f9045680-fd73-4e1d-b941-e0b1eefbf3cb\/wd\/runTaskLetTask_error.json\n2021\/06\/22 12:22:11 Wrapper cmd failed with err: exit status 137\n2021\/06\/22 12:22:11 Attempt 1 of http call to http:\/\/10.0.0.5:16384\/sendlogstoartifacts\/status\n2021\/06\/22 12:22:11 mpirun version string: {\nIntel(R) MPI Library for Linux* OS, Version 2018 Update 3 Build 20180411 (id: 18329)\nCopyright 2003-2018 Intel Corporation.\n}\n2021\/06\/22 12:22:11 MPI publisher: intel ; version: 2018\n2021\/06\/22 12:22:11 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 2\nFilteredData: 0.\n2021\/06\/22 12:22:11 Process Exiting with Code: 137\n2021\/06\/22 12:22:11 All App Insights Logs was send successfully",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"StreamAccessException was caused by UnexpectedException. Too many open files in system",
        "Question_creation_time":1602352746733,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/122455\/streamaccessexception-was-caused-by-unexpectedexce.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"I have the ADLSGen2 registered as a DataStore and trying to access the excel data from one of its folders from the Notebook. Following is the code\n\n from azureml.data.datapath import DataPath\n from azureml.data.data_reference import DataReference\n from azureml.core import Workspace, Datastore, Dataset\n    \n ws = get_ws()\n dstore_name = 'ssss_aravind_store'\n    \n aravind_dstore = Datastore.get(ws, dstore_name)\n    \n raw_input_path = DataReference(\n     datastore=aravind_dstore, \n     data_reference_name='ticket_raw_data_ref',\n     path_on_datastore='semi-structured\/ticket-incident-emails\/raw_input_data_eng.xlsx')\n print('Raw DataReference:', raw_input_path)\n    \n parent_keywords_path = DataReference(\n     datastore=aravind_dstore, \n     data_reference_name='parent_keywords_data_ref',\n     path_on_datastore='semi-structured\/ticket-incident-emails\/parent_keywords.xlsx')\n print('Parent Keywords DataReference:', parent_keywords_path)\n    \n third_level_keywords_path = DataReference(\n     datastore=aravind_dstore, \n     data_reference_name='parent_keywords_data_ref',\n     path_on_datastore='semi-structured\/ticket-incident-emails\/third_level_keywords.xlsx')\n print('3rd Level Keywords DataReference:', third_level_keywords_path)\n    \n cleaned_data_path = DataReference(\n     datastore=aravind_dstore, \n     data_reference_name='ticket_phase1_data_ref',\n     path_on_datastore='semi-structured\/ticket-incident-emails\/phase1_op_dummy_data.xlsx')\n print('Cleaned DataReference:', cleaned_data_path)\n    \n raw_dset = Dataset.from_excel_files(raw_input_path, sheet_name= 'data', use_column_headers=True, infer_column_types=True)\n parent_kwords_dset = Dataset.from_excel_files(parent_keywords_path, sheet_name= 'New_keywords', use_column_headers=True, infer_column_types=True)\n level3_kwords_dset = Dataset.from_excel_files(third_level_keywords_path,  use_column_headers=True, infer_column_types=True)\n cleaned_dset = Dataset.from_excel_files(cleaned_data_path, sheet_name= 'phase1_op', use_column_headers=True, infer_column_types=True)\n\n\n\n\nError\n\n ---------------------------------------------------------------------------\n ExecutionError                            Traceback (most recent call last)\n <ipython-input-22-c4226f154137> in <module>\n      44 # from_excel_files(path, sheet_name=None, use_column_headers=False, skip_rows=0, include_path=False, infer_column_types=True,\n      45 # partition_format=None)\n ---> 46 raw_dset = Dataset.from_excel_files(raw_input_path, sheet_name= 'data', use_column_headers=True, infer_column_types=True)\n      47 parent_kwords_dset = Dataset.from_excel_files(parent_keywords_path, sheet_name= 'New_keywords', use_column_headers=True, infer_column_types=True)\n      48 level3_kwords_dset = Dataset.from_excel_files(third_level_keywords_path,  use_column_headers=True, infer_column_types=True)\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/_dataset_deprecation.py in wrapper(*args, **kwargs)\n      20                 _warn_deprecation(target, replacement)  # only raise warning for top-level invocation\n      21                 _warning_silenced_for = target\n ---> 22             result = func(*args, **kwargs)\n      23             if _warning_silenced_for == target:\n      24                 _warning_silenced_for = None\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/_loggerfactory.py in wrapper(*args, **kwargs)\n     124             with _LoggerFactory.track_activity(logger, func.__name__, activity_type, custom_dimensions) as al:\n     125                 try:\n --> 126                     return func(*args, **kwargs)\n     127                 except Exception as e:\n     128                     if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/dataset.py in from_excel_files(path, sheet_name, use_column_headers, skip_rows, include_path, infer_column_types, partition_format)\n     661             include_path,\n     662             infer_column_types,\n --> 663             partition_format)\n     664 \n     665     @staticmethod\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/data\/_dataset_client.py in from_excel_files(path, sheet_name, use_column_headers, skip_rows, include_path, infer_column_types, partition_format)\n     810             inference_arguments = dprep.InferenceArguments(day_first=True)\n     811         dataflow = dprep.read_excel(\n --> 812             path, sheet_name, use_column_headers, inference_arguments, skip_rows, include_path)\n     813         dataflow._name = sheet_name\n     814         return _DatasetClient._get_dataset_from_dataflow(\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/readers.py in read_excel(path, sheet_name, use_column_headers, inference_arguments, skip_rows, include_path, infer_column_types, verify_exists)\n     186     df = df.read_excel(sheet_name, use_column_headers, skip_rows)\n     187 \n --> 188     df = _handle_type_inference_and_path(df, inference_arguments, infer_column_types, include_path)\n     189 \n     190     if verify_exists:\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/readers.py in _handle_type_inference_and_path(df, inference_arguments, infer_column_types, include_path)\n      32         column_types_builder = df.builders.set_column_types()\n      33         if use_inference_arguments:\n ---> 34             column_types_builder.learn(inference_arguments)\n      35         else:\n      36             column_types_builder.learn()\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/builders.py in learn(self, inference_arguments)\n     193             if inference_arguments is not None and not isinstance(inference_arguments, InferenceArguments):\n     194                 raise ValueError('Unexpected inference arguments. Expected instance of InferenceArguments class')\n --> 195             self._conversion_candidates = self._run_type_inference(self._dataflow._get_steps())\n     196             if inference_arguments is not None:\n     197                 self._resolve_date_ambiguity(inference_arguments.day_first)\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/builders.py in _run_type_inference(self, steps)\n      79             inferences = self._engine_api.infer_types_with_span_context(InferTypesWithSpanContextMessageArguments(\n      80                 blocks=steps_to_block_datas(steps),\n ---> 81                 span_context=to_dprep_span_context(span.get_context())\n      82             ))\n      83             return {col: _inference_info_from_result(inference) for col, inference in inferences.items()}\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/_aml_helper.py in wrapper(op_code, message, cancellation_token)\n      36             if len(changed) > 0:\n      37                 engine_api_func().update_environment_variable(changed)\n ---> 38             return send_message_func(op_code, message, cancellation_token)\n      39 \n      40         return wrapper\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py in infer_types_with_span_context(self, message_args, cancellation_token)\n     183     @update_aml_env_vars(get_engine_api)\n     184     def infer_types_with_span_context(self, message_args: typedefinitions.InferTypesWithSpanContextMessageArguments, cancellation_token: CancellationToken = None) -> Dict[str, typedefinitions.FieldInference]:\n --> 185         response = self._message_channel.send_message('Engine.InferTypesWithSpanContextMessage', message_args, cancellation_token)\n     186         return {k: typedefinitions.FieldInference.from_pod(v) if v is not None else None for k, v in response.items()} if response is not None else None\n     187 \n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/engineapi\/engine.py in send_message(self, op_code, message, cancellation_token)\n     180                 response = self._read_response()\n     181                 if 'error' in response:\n --> 182                     raise_engine_error(response['error'])\n     183                 elif response.get('id') == message_id:\n     184                     return response['result']\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/dataprep\/api\/errorhandlers.py in raise_engine_error(error_response)\n       8     error_code = error_response['errorCode']\n       9     if 'ScriptExecution' in error_code:\n ---> 10         raise ExecutionError(error_response)\n      11     if 'Validation' in error_code:\n      12         raise ValidationError(error_response)\n    \n ExecutionError: \n Error Code: ScriptExecution.StreamAccess.Unexpected\n Failed Step: 0....\n Error Message: ScriptExecutionException was caused by StreamAccessException.\n   StreamAccessException was caused by UnexpectedException.\n     Unexpected error when attempting 'GetHttpResourceStream' for 'https:\/\/stgaccount.dfs.core.windows.net\/aravind\/semi-structured\/ticket-incident-emails\/raw_input_data_eng.xlsx'.\n       Too many open files in system\n | session_id=ff6......",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-12T13:35:17.137Z",
                "Answer_score":0,
                "Answer_body":"@AravindYarram-8844 Thanks for the question, Based on the error message i.e., ScriptExecutionException was caused by StreamAccessException.\nFor a service identity to access ADL-S gen 2 storage, it needs to pass two criteria:\n\nThe machine running under that service identity needs to pass the storage firewall rules.\nWith your firewall settings, this criterion should pass.\nThe specific service identity needs to have read access to the ADL-S storage.\nFor this, you should create an Azure App Identity and give it (at a minimum) read access to the ADL-S gen 2 instance. Then register the ADL-S instance as a datastore in your AML workspace using the client ID and secret of that app identity. Your code running in AML will then be able to access this data via the corresponding datastore registered in AML.\n\nIf possible could you please share the link to the sample that you are trying.\n\nPlease follow this doc to set up the permission to access data behind vnet on studio?\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-virtual-network#configure-a-datastore-to-use-managed-identity",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Getting Authenticatin error for python script step in pipeline",
        "Question_creation_time":1623207954850,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/427884\/getting-authenticatin-error-for-python-script-step.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"I am trying to create a azure pipeline for learning purpose. I followed the steps mentioned in this notebook:\nhttps:\/\/github.com\/MicrosoftLearning\/mslearn-dp100\/blob\/main\/08%20-%20Create%20a%20Pipeline.ipynb\n\n\n\n     #%% connect to a workspace from config\n # use service principal authentication - https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/manage-azureml-service\/authentication-in-azureml\/authentication-in-azureml.ipynb\n    \n azure_svppwd = os.environ.get(\"AZUREML_PASSWD\") # use os.environ[\"AZUREML_PASSWD\"] = ' from azure service client secret\"\n auth_pwd = ServicePrincipalAuthentication(\n     tenant_id=\"7da05296-d70e-4398-8a3d-f113e0dad997\",\n     service_principal_id=\"57bac230-cbb8-409e-be64-5c4516d40771\",\n     service_principal_password=azure_svppwd)\n ws = Workspace.from_config('config',auth=auth_pwd)    \n print(\"Found workspace {} at location {}\".format(ws.name, ws.location))    \n # get the data from datasets\n    \n in_data = ws.datasets.get('testparquet') # dataset is registered through Azure UI which refers to some parquet files in another container\n    \n #%% create environment\n env = Environment.from_conda_specification(name='azenv',file_path='envspec.yml')\n env.register(ws)  # Save the environment for future use and retreival\n #%% create compute target - compute clusters\n try:\n     comp_cluster = ComputeTarget(ws,'amltryoutcluster')\n     print('amltryoutcluster found existing and will be used')\n except 'ComputeTargetException':\n        \n     comp_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D3',min_nodes=0,max_nodes=6)\n     # vm_size in above line indicates the type of computation powe we need\n     comp_cluster = ComputeTarget.create(ws,'amltryoutcluster',comp_config)\n     comp_cluster.wait_for_completion(show_output=True)\n #%% Create pipeline data object and steps\n prep_data = PipelineData(name=\"pipedata\",datastore=ws.get_default_datastore())\n #%% Create pipeline steps\n #%% pipeline configuration\n pipe_config = RunConfiguration()\n pipe_config.target = comp_cluster\n pipe_config.environment= Environment.get(ws,\"azenv\")\n prep_step = PythonScriptStep(name=\"prep\",\n                              script_name=\"prep_script.py\",             \n                             source_directory='.\/',                \n                              arguments=['--ipdata',in_data.as_named_input(\"inparquet\"),\n                                         '--oppath',prep_data],\n                              outputs=[prep_data],\n                              compute_target = comp_cluster,\n                              runconfig =pipe_config,\n                              allow_reuse=True)\n train_step = PythonScriptStep(name='train',\n                               script_name='train_script.py',\n                               source_directory='.\/',\n                               arguments=['--prepdata',prep_data],\n                               inputs=[prep_data],\n                               compute_target=comp_cluster,\n                               runconfig=pipe_config,\n                               allow_reuse=True)\n # get experiment and run pipeline\n # Construct the pipeline\n pipeline_steps = [prep_step, train_step]\n pipeline = Pipeline(workspace=ws, steps=pipeline_steps,default_datastore='parquet_ingestion')\n exp =Experiment(ws,'amltryout')\n pipeline_run = exp.submit(pipeline, regenerate_outputs=True)\n\n\n\nIn the prep_script.py, I have the following :\n\n from azureml.core import Experiment,Workspace,Datastore,Dataset\n import pandas as pd\n import argparse\n from azureml.core import Run\n from sklearn import preprocessing\n import os\n    \n parse = argparse.ArgumentParser()\n parse.add_argument('--ipdata')\n parse.add_argument('--oppath')\n args = parse.parse_args()\n save_folder = args.oppath\n    \n run = Run.get_context()\n    \n #https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/work-with-data-in-aml\/5-using-datasets\n pqdata = run.input_datasets['inparquet'].to_pandas_dataframe()\n # ws = run.experiment.workspace\n # pqdata = Dataset.get_by_id(ws, id='testparquet')\n run.log(\"count\",pqdata.count())\n    \n sel_data = pqdata[['title','country','salary']]\n str_enc = preprocessing.LabelEncoder()\n    \n sel_data['title','country'] = str_enc.fit_transform(sel_data['title','country']) \n    \n    \n os.makedirs(save_folder, exist_ok=True)\n save_path = os.path.join(save_folder,'data_prep.csv')\n sel_data.to_csv(save_path)\n    \n run.complete()\n\n\n\n\nAlso some steps in train_script , but when I submit the pipeline it fails at prep step with the following error :\n\nAuthentication failed for Container Registry: 3495c636784040b2ae0f5c8e7ee4133a.azurecr.io.\n\nAm I missing something here?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-09T13:11:50.927Z",
                "Answer_score":1,
                "Answer_body":"@RaghuvarranVH-5191 Thanks for the question. Can you please add more details about the Docker Container Registry that you are trying and share error log snapshot to check.\nTo Initialize Workspace, Please follow the below doc.\nInitialize a workspace object from persisted configuration.\n\n ws = Workspace.from_config()\n print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n\n\n\nFor Azure machine learning pipelines quickstart please follow the below notebook.\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-getting-started.ipynb",
                "Answer_comment_count":5,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to improve particular tag accuracy in Form recognizer",
        "Question_creation_time":1623650782897,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/434228\/how-to-improve-particular-tag-accuracy-in-form-rec.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"as you can see, I made a custom model(OCR) and trained it. But only some tags are well learned, and others are not well learned poorly. even if additional learning data set is added, training error occurs and learning is no longer possible.\nMy data format is pdf and not all parts of the file are tagged, but only some of them are tagged.\n\nis there a way to increase the accuracy of particular tag?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-14T11:22:56.1Z",
                "Answer_score":0,
                "Answer_body":"@yurileeDBMSKE-4795 Thanks for the question. Can you please add more details about the training error that you are getting. You can improve model accuracy by labeling additional forms and retraining to create a new model. We recommend starting by labeling five forms and adding more forms as needed.\n\nPlease checkout the the Knowledge Extraction Recipes resource.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error while submitting pipeline using Azure ML Designer",
        "Question_creation_time":1619901578667,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/379556\/error-while-submitting-pipeline-using-azure-ml-des.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":1,
        "Question_body":"Hello, I am pretty new to AzureML and facing the following issue while submitting the pipeline.\nI have attached the screenshot for your reference.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-03T15:08:38.607Z",
                "Answer_score":1,
                "Answer_body":"I have the same issue currently, I'm in Western Europe region",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-03T15:50:19.213Z",
                "Answer_score":0,
                "Answer_body":"In dataset Version change from \"Always use latest\" to 1 or anyother version, worked for me",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Deploying spark-nlp model using custom docker image fails in Azure Machine Learning",
        "Question_creation_time":1623911523677,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/439911\/deploying-spark-nlp-model-using-custom-docker-imag.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Issue while deploying spark-nlp model to AML\n\nI am trying to deploy a SPARK-NLP trained model from here to Azure Machine learning (using Python environment)\n\nWhile deploying I am using a custom docker image provided by the spark-nlp documentation here\nThis is because when I try to use an existing image such as\nenv = Environment.get(ws, name='AzureML-PySpark-MmlSpark-0.15')\nthen we get errors when loading the model in the scoring script as spark-nlp libraries are not found in that AzureML-PySpark image.\n\nSo now I am using custom docker file as below:\n\ndockerfile = r\"\"\"\n\nFROM ubuntu:18.04\n\nENV NB_USER yuefeng\nENV NB_UID 1000\nENV HOME \/home\/${NB_USER}\n\nENV PYSPARK_PYTHON=python3\nENV PYSPARK_DRIVER_PYTHON=python3\n\nRUN apt-get update && apt-get install -y \\\ntar \\\nwget \\\nbash \\\nrsync \\\ngcc \\\nlibfreetype6-dev \\\nlibhdf5-serial-dev \\\nlibpng-dev \\\nlibzmq3-dev \\\npython3 \\\npython3-dev \\\npython3-pip \\\nunzip \\\npkg-config \\\nsoftware-properties-common \\\ngraphviz\n\nRUN adduser --disabled-password \\\n--gecos \"Default user\" \\\n--uid ${NB_UID} \\\n${NB_USER}\n\n\n\n\nRUN apt-get update && \\\napt-get install -y openjdk-8-jdk && \\\napt-get install -y ant && \\\napt-get clean;\n\n\n\n\nRUN apt-get update && \\\napt-get install ca-certificates-java && \\\napt-get clean && \\\nupdate-ca-certificates -f;\n\nENV JAVA_HOME \/usr\/lib\/jvm\/java-8-openjdk-amd64\/\nRUN export JAVA_HOME\n\nRUN echo \"export JAVA_HOME=\/usr\/lib\/jvm\/java-8-openjdk-amd64\/\" >> ~\/.bashrc\n\nRUN apt-get clean && rm -rf \/var\/lib\/apt\/lists\/ \/tmp\/ \/var\/tmp\/*\n\nRUN pip3 install --upgrade pip\nRUN pip3 install --no-cache-dir notebook==5.* numpy pyspark==2.4.4 spark-nlp==2.5.1 azureml-sdk azureml-core pandas mlflow Keras scikit-spark scikit-learn scipy matplotlib pydot tensorflow graphviz\n\nUSER root\nRUN chown -R ${NB_UID} ${HOME}\nUSER ${NB_USER}\n\nWORKDIR ${HOME}\n\n\n\n\nCMD [\"jupyter\", \"notebook\", \"--ip\", \"0.0.0.0\"]\n\"\"\"\n\nMy environment configuration is as below:\n\n\n\nfrom azureml.core import Environment\nfrom azureml.core.model import InferenceConfig\n\nenv=Environment(\"myenv\")\nenv.docker.base_image=None\nenv.docker.base_dockerfile = dockerfile\n\nenv.inferencing_stack_version='latest'\n\ninf_config = InferenceConfig(environment=env, entry_script=\"score.py\")\n\nthe entry script, score.py looks like below:\n\n\n\n%%writefile score.py\nimport json\nimport pyspark\n\nimport azureml.core\nfrom azureml.core.model import Model\nfrom azureml.core import Workspace\nfrom pyspark.ml import PipelineModel\nfrom pyspark.context import SparkContext\nfrom pyspark.sql.session import SparkSession\nimport sys, glob, os\n\nglobal trainedModel\nglobal spark\ndef init():\nsys.path.extend(glob.glob(os.path.join(os.path.expanduser(\"~\"), \".ivy2\/jars\/*.jar\")))\nspark = SparkSession.builder.appName(\"Spark NLP\").master(\"local[4]\").config(\"spark.driver.memory\",\"16G\").config(\"spark.driver.maxResultSize\", \"2G\") .config(\"spark.kryoserializer.buffer.max\", \"2000M\").config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.6.1,com.google.cloud.spark:spark-bigquery-with-dependencies_2.11:0.15.1-beta\").getOrCreate()\nmodel_name = \"nlp_test-register\" #interpolated\nmodel_path = Model.get_model_path(model_name)\ntrainedModel = PipelineModel.load(model_path)\n\ndef run(input_json):\nif isinstance(trainedModel, Exception):\nreturn json.dumps({<!-- -->{\"trainedModel\":str(trainedModel)}})\n\n try:\n     sc = spark.sparkContext\n     input_list = json.loads(input_json)\n     input_rdd = sc.parallelize(input_list)\n     input_df = spark.read.json(input_rdd)\n    \n    \n     prediction = trainedModel.transform(input_df)\n      \n     predictions = prediction.collect()\n \n     \n     preds = [str(x['ntokens']) for x in predictions.select('ntokens').collect()]\n     result = \",\".join(preds)\n    \n     return result\n except Exception as e:\n     result = str(e)\n     return result\n\n\n\nthe spark-nlp trained model is registered successfully in the workspace.\n\nfrom azureml.core.model import Model\n--Register model\nresgistered_Model = Model.register(ws, model_name=\"nlp_test-register\", model_path=\".\/test.mml\")\n\nNow, when trying to deploy the model as a local webservice:\n\ndeployment_config = LocalWebservice.deploy_configuration(port=6789) service = Model.deploy( ws, \"myservice\", [model], inf_config, deployment_config, overwrite=True, ) service.wait_for_deployment(show_output=True)\n\nI get error when trying to build the environment:\n\nStep 32\/45 : RUN if dpkg --compare-versions conda --version | grep -oE '[^ ]+$' lt 4.4.11; then conda install conda==4.4.11; fi\n---> Running in 1d06aaf8f181\n\/bin\/sh: 1: conda: not found\ndpkg: error: --compare-versions takes three arguments: <version> <relation> <version>\n\nType dpkg --help for help about installing and deinstalling packages [];\nUse 'apt' or 'aptitude' for user-friendly package management;\nType dpkg -Dhelp for a list of dpkg debug flag values;\nType dpkg --force-help for a list of forcing options;\nType dpkg-deb --help for help about manipulating .deb files;\n...\nStep 33\/45 : COPY azureml-environment-setup\/mutated_conda_dependencies.yml azureml-environment-setup\/mutated_conda_dependencies.yml\n---> efe6235c07d2\nStep 34\/45 : RUN ldconfig \/usr\/local\/cuda\/lib64\/stubs && conda env create -p \/azureml-envs\/azureml_da3e97fcb51801118b8e80207f3e01ad -f azureml-environment-setup\/mutated_conda_dependencies.yml && rm -rf \"$HOME\/.cache\/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR\/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name pycache -exec rm -rf {} + && ldconfig\n---> Running in 5382859f6b89\n\/bin\/sh: 1: conda: not found\nThe command '\/bin\/sh -c ldconfig \/usr\/local\/cuda\/lib64\/stubs && conda env create -p \/azureml-envs\/azureml_da3e97fcb51801118b8e80207f3e01ad -f azureml-environment-setup\/mutated_conda_dependencies.yml && rm -rf \"$HOME\/.cache\/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR\/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name pycache -exec rm -rf {} + && ldconfig' returned a non-zero code: 127\n2021\/06\/17 02:47:36 Container failed during run: acb_step_0. No retries remaining.\nfailed to run step ID: acb_step_0: exit status 127\n\nRun ID: ccx failed after 13m28s. Error: failed during run, err: exit status 1\nPackage creation Failed\n\nDoes it mean conda is not available in the docker image? How to install CONDA in the docker image? What commands should be given in the docker file?\n<img width=\"960\" alt=\"error\" src=\"https:\/\/user-images.githubusercontent.com\/50163025\/122332624-4d47d100-cf69-11eb-92d2-ce025500e410.PNG\">;",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-17T14:53:21.397Z",
                "Answer_score":0,
                "Answer_body":"@PriyankaShah-7526 Thanks for the question. Yes, Instead of using a existing curated environment, you can try creating your own environment with the required package version dependencies specified in the requirements file\/ conda yml configuration?\nPlease follow the below document for the same.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-environments#use-conda-dependencies-or-pip-requirements-files",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Preparing ML object detction dataset for deep learning in PyTorch or similar",
        "Question_creation_time":1607567444300,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/192973\/preparing-ml-object-detction-dataset-for-deep-lear.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":2,
        "Question_body":"The intent of what I'm trying to achieve is:\n\nExport data labelling project as a Dataset\n\n\nConsume the Dataset in a notebook (converting to a Pandas dataframe)\n\n\nPerform a custom train \/ test split that maintains particular file groupings\n\n\nRegister the resulting training and testing dataframes as Datasets\n\n\nUse these Datasets to train and test a custom object detection model\n\n\n\n\nI need help in preparing the data for that final step. I'm familiar with different deep learning libraries, but have never implemented them in the Azure environment before. I've managed to complete 1 to 4. For step 4, I ended up writing the data to csv files and uploading these to the datastore.\n\n # define path for training data file and create new delimited file\n train_path = '.\/data\/train.csv'\n train_dataframe.to_csv(train_path, sep = ';', index = False)\n    \n # repeat for testing\n test_path = '.\/data\/test.csv'\n test_dataframe.to_csv(test_path, sep = ';', index = False)\n    \n # get the datastore to upload prepared data\n datastore = Datastore.get(ws, datastore_name='learningdata')\n    \n # upload the local files from src_dir to the target_path in datastore\n datastore.upload(src_dir='data', target_path='train-test', overwrite=True)\n    \n # create and register training dataset from datastore files\n training_ds = Dataset.Tabular.from_delimited_files(path = [(datastore, 'train-test\/train.csv')], separator=';')\n training_ds = training_ds.register(workspace=ws, name = 'train', description = 'training dataset sampled from labelled data', create_new_version=True)\n    \n # create and register testing dataset from datastore files\n testing_ds = Dataset.Tabular.from_delimited_files(path = [(datastore, 'train-test\/test.csv')], separator=';')\n testing_ds = testing_ds.register(workspace=ws, name = 'test', description = 'testing dataset sampled from labelled data', create_new_version=True)\n\n\n\nThe approach I was intending to use for step 5 was to use to_torchvision() to convert it into a Torchvision dataset. This doesn't work, I receive the following error:\n\n UserErrorException: UserErrorException:\n  Message: Cannot perform torchvision conversion on dataset without labeled columns defined\n  InnerException None\n  ErrorResponse \n {\n     \"error\": {\n         \"code\": \"UserError\",\n         \"message\": \"Cannot perform torchvision conversion on dataset without labeled columns defined\"\n     }\n }\n\n\n\nI suspect that the issue has to do with DataTypes. The original Dataset (exported from the data labelling project) has the DataTypes displayed below. By comparison, all column types in the train and test Datasets are parsed as strings. From my understanding, there's no way to convert to these data types.\n\nimage_url = Stream\n\n\nlabel = List\n\n\nlabel_confidence = List\n\nAny advice on how to prepare this dataset for use in PyTorch or recommendation for an alternative approach would be greatly appreciated.\n\n\n\n\n\n\nUpdate as per comment below:\n\nI'm currently mounting the dataframe rather than downloading it due to data size.\n\n\nI can view images from the originally mounted Dataset, but when loading the newly registered training Dataset I can't access images as '\/tmp\/tmpog809x4v\/[...].jpg' is no longer relevant.\n\n\nI can't perform random split because I'm using clustered sampling.\n\n\nI'm working on creating a class object to define the dataset, but I cannot currently create the PIL Image object as required by PyTorch (https:\/\/pytorch.org\/tutorials\/intermediate\/torchvision_tutorial.html#defining-the-dataset)",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-15T22:30:13.793Z",
                "Answer_score":0,
                "Answer_body":"I modified the methodology and was able to successfully resolve this issue as follows:\n\nExport data labelling project as Dataset\n\n\nConsume the Dataset in the notebook by creating both a PyTorch dataset and a Pandas dataframe\n\n\nUse the Pandas dataframe to determine indices for the train \/ test split based on required sampling\n\n\nUse the indices as an input to torch.utils.data.Subset() to split the PyTorch dataset into train and test",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2020-12-10T13:06:31.287Z",
                "Answer_score":0,
                "Answer_body":"@JoeDuncan-2610 Thanks for the great question. End-to-end image detection that leverages training\/test datasets created from a Data Labeling project. you are well aware that you can also \u2018solve\u2019 this problem with CustomVision, but I\u2019d like to showcase how a custom vision problem which may not be handle well enough by Custom Vision could be handled easily with Azure ML with full control of the underlying ML algorithms and the power of Data Labeling.\n\nThe best practices to get back to the images referenced by the dataset, i.e. leverage the DataStore \/ StreamInfo from the TabularDataset extracted DataFrame, to prepare the data for a model training.\n\nThis code here that I put together is probably the way to proceed to retrieve the original image assets from a labeled TabularDataset.\n\n # azureml-core of version 1.0.72 or higher is required\n # azureml-contrib-dataset of version 1.0.72 or higher is required\n    \n    \n from azureml.core import Workspace, Dataset, Datastore\n import azureml.contrib.dataset\n import azureml.dataprep.native\n     \n subscription_id = '_set_it_to_yours_'\n resource_group = '_set_it_to_yours_'\n workspace_name = '_set_it_to_yours_'\n     \n workspace = Workspace(subscription_id, resource_group, workspace_name)\n     \n # get dataset and extract as a DataFrame\n ds = Dataset.get_by_name(workspace, name=_set_it_to_yours_')\n df = ds.to_pandas_dataframe()\n     \n # download images\n index = 0\n datastore = None\n while index < len(df):\n     # image_url is a azureml.dataprep.native.StreamInfo object, convert to dict with to_pod()\n     si = df.loc[index].image_url.to_pod()\n     if index == 0:\n         # retrieve datastore based on metadata from first row\n         # assuming all images come from the same store\n         # since they come from a single dataset\n         datastore = Datastore.get(workspace, si['arguments']['datastoreName'])\n     # download image locally\n     datastore.download(target_path='.',prefix=si['resourceIdentifier'],overwrite=True,show_progress=True)\n     index += 1\n     \n # create training, test sets\n [training, test] = ds.random_split(0.8)\n\n\n\nbuild model based on image assets and labels...\nFrom there, build your train_x,y and test_x,y datasets\u2026\n\n\n\n\nWe have checked in a sample notebook about labeled dataset to public github repo. You can find it here:\n\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/work-with-data\/datasets-tutorial\/labeled-datasets\/labeled-datasets.ipynb",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error while deploying an Webservice using an ACI",
        "Question_creation_time":1623853256203,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/438730\/error-while-deploying-an-webservice-using-an-aci.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\n\nI am receiving the following message when I try the deploy a webservice using azure SDK.\n\n\"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\nNOTE : here is my init():\n\n**def init():\ntry:\nglobal model_cbf\nglobal model_frequenceAchat\nglobal date_ajd\nglobal model_cf\nglobal Feature\nglobal Empty_Feature\nglobal MultiSparseInfo\n\n     model_path_cbf = Model.get_model_path(\"content-based_filtering\")    \n     model_cbf = joblib.load(model_path_cbf)\n        \n     model_path_frequence_achat = Model.get_model_path(\"frequence_dachat\")\n     model_frequenceAchat = joblib.load(model_path_frequence_achat)    \n     date_ajd = datetime.datetime(2014, 7, 8)\n        \n     Feature = namedtuple(\"Feature\", [\"name\", \"index\"])\n     Empty_Feature = Feature(name=[], index=[])\n    \n     MultiSparseInfo = namedtuple(\"MultiSparseInfo\",\n                              [\"field_offset\", \"field_len\", \"feat_oov\"])\n        \n     model_cf_data = Model.get_model_path(\"donnees_collaborative_filtering\") \n     data_info = DataInfo.load2(model_cf_data[1])\n     model_cf = SVD(task = model_cf_data[0]['task'], data_info = data_info)\n     model_cf.load2(model_cf_data[2])\n except:\n     Exception as e:\n     print(str(e))**\n\n\n\n\nI suspect that the presence of a class definition in the entry script might be the problem. What do you guys think?\n\nThank you,\n\nVincent",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-17T13:59:29.327Z",
                "Answer_score":1,
                "Answer_body":"Hi,\n\nThank you for the quick response.\n\nThe error was that I wasnt deserializing the model \"donnees_collaborative_filtering\".\n\nVincent",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Why do i get :NotLabeledDataset: There is no label column in",
        "Question_creation_time":1622732290603,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/421203\/why-do-i-get-notlabeleddataset-there-is-no-label-c.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello I am trying to make a classification model using the ml designer.\n\nI registert a dataset whit images. Maybe i did it wrong?\nI used the sample that Microsoft designer suplies densnet for image classification. I only changed the dataset whit one that i made.\n\nI have 5 classes and each one is in thier own subfolder i uploaded the folder. a file type.\n\ni keep getting the message",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-04T12:53:42.51Z",
                "Answer_score":0,
                "Answer_body":"Thank you for your response.\n\nThe train pytorch module.\nthis is the structure of the folder i uploaded",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-06-15T20:41:10.153Z",
                "Answer_score":0,
                "Answer_body":"I'm facing the same issue with a dataset folder setup with the same hierarchy as above using the Image Classification using DenseNet architecture.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-06-15T22:46:23.77Z",
                "Answer_score":0,
                "Answer_body":"Thanks all for your inquiry. After further review, I discovered that if you create a dataset by uploading images and registering it, it removes the structure and uploads all images into one folder. Please try to upload the images into separate folders in your blob container (..\/UI\/Folder\/Subfolder) and run the experiment again. I was able to resolve the issue with the steps mentioned above. Hope it helps!",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Metrics tab.",
        "Question_creation_time":1623816222417,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/437991\/metrics-tab.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Next to the Normalized root mean squared error value, select View all other metrics to see values of other possible evaluation metrics for a regression model.\n\nSelect the Metrics tab and select the residuals and predicted_true charts if they are not already selected. Then review the charts, which show the performance of the model by comparing the predicted values against the true values, and by showing the residuals (differences between predicted and actual values) as a histogram.\n\nAs per the above lines, I am not able to find the Metrics tab and not able to see the predicted true charts.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-16T06:20:30.657Z",
                "Answer_score":0,
                "Answer_body":"@sashanksai-9144 You will have to first click on the algorithm name from the screen shot first.\n\n\n\n\nThen you will see the metrics tab and the charts.\n\n\n\n\n\n\n\nPlease feel free to accept the answer if it helped. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Ambiguous error in Azure Machine Learning Designer 'Evaluate Model' Module",
        "Question_creation_time":1622567822803,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/418016\/ambiguous-error-in-azure-machine-learning-designer.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I am getting the following error from the Evaluate Model module in Azure Machine Learning Designer:\n\n\nWhen I open the Assigned Data to Clusters module everything seems fine. I downloaded the output for Assigned Data to Clusters and played with cluster number 31 and there doesn't seem to be any issue. Additionally, I am using Azure Modules, so I am confused as to why this is failing. Please provide some clarity into this issue. This is a part of my pipeline:\n\nAdditionally, it seems unless I successfully run the Evaluate Model module, I cannot create an inference pipeline. If this is untrue, please help me out here as well. There is no option for me to 'Create an Inference Pipeline' which shown in this tutorial; step 1.\n\nPlease let me know if you need any other information.\n\nThanks in advance.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-11T22:35:57.477Z",
                "Answer_score":1,
                "Answer_body":"Can you please check if the Assignment cluster 31 has NaN value? The Assign Data to Clusters leverages SKlearn, and from the error message, seems the Assignment column had NaN value which resulted in an error. If that's the case, let us know, so we can enable Evaluate Module module to deal with NaN values, and in the meantime, here's a short-term workaround:\n\nConnect Clean Missing Data module to Assign Data to Cluster module, to clean the missing values.\n\n\n\nUse Edit Metadata module to convert Assignment to Integer and categorical type, this is because if Assignment column has NaN value before and its column type was double, we need to convert it to integer.\n\n\n\nConnect Edit Metadata to Evaluate Model module.\n\n\n\n\nHope this help!",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"What is the difference between online learning and offline learning",
        "Question_creation_time":1623786913570,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/437505\/what-is-the-difference-between-online-learning-and.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I am a new learner of machine learning and computer science, I wonder the difference between these two terms. I am confused on the concept, can someone answer this question?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-15T20:10:40.78Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us here. They are both machine learning methods for training. online machine learning is a method of machine learning in which data becomes available in a sequential order and is used to update the best predictor for future data at each step, as opposed to batch learning techniques which generate the best predictor by learning on the entire training data set at once.\n\nLike, one more data coming in, the predictor moves once. This method is good for scenario like stock prediction, optimization...\n\nLinear least square is a very good example to understand.\nhttps:\/\/en.wikipedia.org\/wiki\/Linear_least_squares\n\n\n\n\nFor Machine Learning beginner, Machine Learning Designer is a very good point to start. You can try any algorithms to see the difference.\nhttps:\/\/azure.microsoft.com\/en-us\/services\/machine-learning\/designer\/\n\nPlease feel free to let us know if you have more questions.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-06-15T19:59:03.03Z",
                "Answer_score":0,
                "Answer_body":"Hi @Louis-4194,\n\nOnline learning normally means that your performing learning as the data comes in, while offline learning means that you use a static data.\nHere's a great post about this:\nhttps:\/\/stats.stackexchange.com\/questions\/897\/online-vs-offline-learning\n\nIf the reply was helpful please don't forget to upvote and\/or accept as answer, thank you!\n\n\n\n\nBest regards,\nLeon",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Explaining a model in AzureML Studio",
        "Question_creation_time":1623017811457,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/423931\/explicacion-de-un-modelo-en-azureml-studio.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi,\n\nThere is an issue when I try to explain a Time Series model created with AzureML Studio, with the AutoML service.\n\nWhen the proccess finishes and the best model is automatically explained, I'd like to see a chart with the information of \"Predicted Values vs True Values\" but I can\u00b4t find anything similar. Then I realized that when I click on the explanation of the model, the next message is showed:\n\n\"Las estad\u00edsticas de rendimiento del modelo requieren que se proporcionen los resultados verdaderos adem\u00e1s de los previstos.\"\n\nTranslated: \"The performance statistics of the model require to provide true values in addition to the predicted ones.\"\n\nHow can I provide the model with the true values? I think it should be done automatically by the process, isn\u00b4t it? I mean, true values is part of the dataset, it is in fact the target column.\n\nFurthermore, I tried to create a classification model and I don\u00b4t have that problem there.\n\nAnyone could help me? Without a chart where I can compare true vs predicted values, the model doesn\u00b4t make sense.\n\n\n\n\nThank you very much in advance.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-08T03:19:11.683Z",
                "Answer_score":0,
                "Answer_body":"@FernndezCalvoAlberto-0353 Thanks, For forecasting experiment the predicted vs. true chart plots the relationship between the target feature (true\/actual values) and the model's predictions. Please follow the document for Predicted vs. true charts.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-understand-automated-ml#prerequisites",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"What algorithms are available in Azure ML for marketing puposes, especially compaign planning?",
        "Question_creation_time":1623341042097,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/430909\/what-algorithms-are-available-in-azure-ml-for-mark.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi there,\n\nI'm interested in the solution of Optimize Marketing with Machine Learning (https:\/\/docs.microsoft.com\/en-us\/azure\/architecture\/solution-ideas\/articles\/optimize-marketing-with-machine-learning). It would be very helpful if someone could give me more insides into this solution.\n\nI'm wondering whether I can use this for my use-case (campaign planning) and if so, how it would look like.\n\nKind regards,\n\nJerom",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-11T01:05:49.553Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. It depends on the ML problem you're trying to solve. This document provides guidance on how to select an algorithm. Below are some references. If you'd like to see us expand the article with more information, submit GitHub Feedback. Hope this helps!\n\nMachineLearningSamples-MarketCampaign\n\n\nClassification with Deployment using a Bank Marketing Dataset\n\n\nAzure AI Gallery",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-06-11T17:13:55.133Z",
                "Answer_score":0,
                "Answer_body":"Based on your inquiry, it seems you are trying to predict values (sales, prices) and categories (channels). So regression and classification algorithms would be appropriate. This document helps you to determine which algorithm to choose based on your business scenario but you'd have to build the optimization solution yourself. For a complete solution as suggested in the document, the best option is to submit GitHub Feedback. I will also share your feedback internally to determine if we have any existing solutions or share opportunity to create one for your scenario.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to solve train error from running model fit in ES_RNN model?",
        "Question_creation_time":1623252586213,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/428948\/how-to-solve-train-error-from-running-model-fit-in.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I cloned Github notebooks(https:\/\/github.com\/Azure\/DeepLearningForTimeSeriesForecasting) provided by Microsoft and was trying to run 4_ES_RNN.ipynb.\n\nHowever, I am getting the following error for train model fit. Below is the code and error that I received.\n\nCode:\n\n\nmodel.fit(train_inputs['X'],\ntrain_inputs['target'],\nbatch_size=BATCH_SIZE,\nshuffle=False,\nepochs=EPOCHS,\n#validation_data=(valid_inputs['X'], valid_inputs['target']),\nvalidation_split=0.1,\ncallbacks=[earlystop],\nverbose=1)\n\nError:\n\n\nInvalidArgumentError: Expected size[0] in [0, 21], but got 29\n[[{<!-- -->{node es_1\/Slice_13}} = Slice[Index=DT_INT32, T=DT_FLOAT, _device=\"\/job:localhost\/replica:0\/task:0\/device:CPU:0\"](_arg_input_1_0_0, es_1\/Slice_13\/begin, es_1\/Slice_13\/size)]]\n\nAny recommendation would be greatly appreciated, thanks!",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How can i clone an old notebook azure library?",
        "Question_creation_time":1623400226543,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/432090\/how-can-i-clone-an-old-notebook-azure-library.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi,\nI'm a student and currently working on an [article][1]. The writer of the article mentioned that i can found the full code and dataset on https:\/\/notebooks.azure.com\/william-mc\/libraries\/edge-detection link!\n\nWhen i click it, nothing happens and i faced a page that says:\n\nThe Azure Notebooks preview has ended. You can enjoy powerful, integrated Jupyter notebooks with the following products and services from Microsoft and GitHub.\n\n\n\n\ni really need that codes. how can i access them? is there anyway to clone from azure notebooks please?\n[1]: https:\/\/core.ac.uk\/download\/pdf\/161875032.pdf",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-11T15:19:40.397Z",
                "Answer_score":1,
                "Answer_body":"@OmidAdibfar-7088 Thanks for the question. We have forwarded to the product team to check. Do you have github link to the code. Please follow the doc to recreate the notebook environment in the azure machine learning.\n\nDoc to run Jupyter notebooks: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-run-jupyter-notebooks",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Does Azure AutoML use (or plan to use) FLAML for the hyperparameter tuning?",
        "Question_creation_time":1623298947587,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/429832\/does-azure-automl-use-or-plan-to-use-flaml-for-the.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"FLAML looks like it performs better than Azure AutoML for hyperparameter tuning (based on the benchmarking in the Arxiv paper): https:\/\/arxiv.org\/pdf\/1911.04706v1.pdf\n\nIs it now being used or is there a plan to integrate it for the hyperparameter tuning in Azure Machine Learning Services? If so, when is that expected to become available?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-11T05:57:12.69Z",
                "Answer_score":0,
                "Answer_body":"@rainerhillermann Thanks, We are not using the FLAML for Azure AutoML for the hyperparameter tuning, You can raise a user voice request here so the community can vote and provide their feedback, the product team then checks this feedback and implements the feature in future releases.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Downloading images built during ML experiment",
        "Question_creation_time":1623337578827,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/430883\/downloading-images-built-during-ml-experiment.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I have successfully run a AML experiment . In the beginning of the experiment, I included the below command to build a conda environment with my requirements into a pre built image:\n\n env = azc.Environment.from_conda_specification(name='my-env', file_path='.\/envspec.yml')\n env.docker.enabled = True\n env.docker.base_image = 'mcr.microsoft.com\/azureml\/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04'\n\n\n\nI understand that during the preparation phase the image is built with the specified dependencies and the experiment is run.\nNow, where I can access this built image? I tried in the Azure container Registry inside my resource group but couldnt find anything.\n\nIs there a way I can download this image and use it in a different experiment as a custom image? I assume this must save time in downloading dependencies and ensures reptroduciblity.\n\nAny known way of doing this?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Machine Learning studio Data Labeling Dataset",
        "Question_creation_time":1623134368530,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/426209\/machine-learning-studio-data-labeling-dataset.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi ,\n\nI have a have a dataset from the labelled data using the ML Data Labeling tool , my question is how can use the dataset to train a model ? , I tried Automated ML but I cannot make ant connection with the dataset .\n\nThanks for your help.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-09T12:04:26.353Z",
                "Answer_score":0,
                "Answer_body":"@hernandoZ-8172 I can confirm that using labeling data in the designer is currently not supported. This is however part of the roadmap in the future releases of designer. You can consume the data with the SDK as mentioned above.",
                "Answer_comment_count":4,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Leave-one-group-out cross-validation in Azure AutoML",
        "Question_creation_time":1618488817010,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/358763\/leave-one-group-out-cross-validation-in-azure-auto.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I have a dataset where each row is a data sample, and there is a a column indicating a group this sample came from. So, each group has several data points, and each one is a row in the dataframe. I would like to run the cross-validation so that at each fold, the data points from one group are used as the validation set, and the data points from other groups as the training test. Is this currently somehow possible in Azure AutoML ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-15T17:30:05.537Z",
                "Answer_score":0,
                "Answer_body":"Yes, you can specify custom cross-validation data folds based on columns. More details are provided in the following document. Hope this helps.\n\nExample:\n\n automl_config = AutoMLConfig(compute_target = aml_remote_compute,\n                              task = 'classification',\n                              primary_metric = 'AUC_weighted',\n                              training_data = dataset,\n                              label_column_name = 'y',\n                              cv_split_column_names = ['cv1', 'cv2']\n                             )",
                "Answer_comment_count":5,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"AzureML Designer - batch execution endpoint",
        "Question_creation_time":1622424345223,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/415354\/azureml-designer-batch-execution-endpoint.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\n\nI am migrating something from classic Azure ML to the current Azure ML and I have been using the batch execution endpoint. . I know there are examples how to publish a real-time endpoint through the designer, but is it possible to publish a batch execution endpoint (which is what I have been using in classic Azure ML) through the designer interface?\n\nI found this documentation online: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/classic\/migrate-rebuild-web-service\nMy pipeline don't have a 'trained model' though it only includes a single Execute Python script module, is there a way to get around that and publish a batch inference endpoint",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-31T08:08:50.197Z",
                "Answer_score":0,
                "Answer_body":"@hunga-1270 Yes, in this case you would need a trained model to publish a pipeline. You could try the scenario to use a create python model module and then use your script to create an experiment and run. If it is successful I think you should be able to create a pipeline.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Suggest solution for reading data from Azure Service Bus with Azure Data Factory",
        "Question_creation_time":1623054369990,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/424698\/suggest-solution-for-reading-data-from-azure-servi.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hi,\n\nI need a suggestion about the below scenario.\nI receive data every second on Azure Service Bus. Now, I want Azure Data Factory to fetch this data and run the ML model on data.\nAs I checked there isn't a link between Azure Service Bus and Azure Data Factory.\nWhat is the solution for this scenario?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-06-08T01:51:24.013Z",
                "Answer_score":0,
                "Answer_body":"@MohsenAkhavan Sharing previous Q&A discussion on the same.\n\n<SNIP>\n\nData Factory does not have a connector for Service bus. However there are several options available to you.\n\nYou can create a consumer for Data Factory to call upon.\n\n\nYou can raise a feature request in the feedback forum.\n\n\nYou could re-route your messages to be written to blob, and then leverage the Blob Event Trigger.\n\n\nUse ADF Web Activity to retrieve a message.\n\nBy \"create a consumer for Data Factory to call upon,\" I mean either create a Function App which batch-reads the messages, and returns them, utilizing ADF Azure Function, or , create some code to do the same with the ADF Batch Service Custom Activity. There are more variations as well.\n\nWhich one to use, depends upon your volume and cadence (frequency).\n\nPlease let me know if you desire more information.\n\n<\/SNIP>",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unable to deploy Azure ML endpoint",
        "Question_creation_time":1619760120333,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/378131\/unable-to-deploy-azure-ml-endpoint.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I am able to build real-time inference pipeline for Wikipedia example but get error when deployed\n\n\ue946\nUpdate: Service status is healthy, but test call return 'GatewayTimeout'.view real-time endpoint\n\nI am able to deploy car price prediction example without errors.\n\nWhat am i doing wrong?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-01T09:36:27.157Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. I'm not able to reproduce this error. I followed the steps outlined in this document and I was able to deploy the real-time endpoint successfully. If you continue to experience errors, can you verify the error details in deployment logs (ML Studio > Endpoints > Deployment Logs)?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-03T03:02:05.68Z",
                "Answer_score":0,
                "Answer_body":"Link to deployment log file\n\nhttps:\/\/ml.azure.com\/endpoints\/lists\/realtimeendpoints\/testnlp\/logs?wsid=\/subscriptions\/031a3c8a-3a6c-4f2f-986d-3da4de8939f3\/resourceGroups\/Strabacus-1\/providers\/Microsoft.MachineLearningServices\/workspaces\/Med-NLP&tid=0e2f81da-258d-4872-b7f0-7cad11eb044a\n\nI am unable to attach a ~100KB txt file which contains the log, hence refer to the link above.\n\nDeployment error\nUpdate: Service status is healthy, but test call return 'GatewayTimeout'.view real-time endpoint\n\n\n\n\nTest result:\n\nFailed to test real-time endpoint\nTimeout of 20000ms exceeded.\n\nI realized, link to endpoint error no longer exists after I deleted the endpoint. Is there a way to attach the txt file.\n\nDo I need to increase timeout to provide enough time for processing? If yes, how?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-06T05:28:55.387Z",
                "Answer_score":0,
                "Answer_body":"@GiftA-MSFT\n\nRegion - West US 2\nCompute - Virtual machine size\nStandard_D2_v2 (2 cores, 7 GB RAM, 100 GB disk)\nProcessing unit\nCPU - General purpose\n\nLink to errorlog\n\nhttps:\/\/app.box.com\/s\/t1mewexil483ylragx94bxgdcwbraqzi",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-29T03:19:54.933Z",
                "Answer_score":0,
                "Answer_body":"101538-nlp-error-v1.txtBased on the linked document - there are 2 models in the pipeline - Feature hashing and Ngram, so it would not work for deployment. Moreover, I also get an error to that effect.\n\nI created 2 different versions 1) Feature Hashing only 2) NGram only followed rest of the steps as outlined in the linked document for deployment. As a note it is container deployment.\n\nI still get the timeout error.\n\nUpdate: Service status is healthy, but test call return 'BadGateway'. view real-time endpoint\n\nAny help to get it resolved would be appreciated.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Docker container for compute instance in machine learning",
        "Question_creation_time":1622313582447,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/414823\/docker-container-for-compute-instance-in-machine-l.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi Everyone,\n\nI'm new to the cloud environment and the Microsoft Azure so incase this question doesn't belong here, my apologies in advance.\n\nI was wondering if it's possible to create a docker container for a python environment within compute instance?\n\nI'm working my way towards getting DP-100 certification. The other day I was trying to follow a tutorial here https:\/\/github.com\/MicrosoftLearning\/mslearn-dp100\/blob\/main\/07%20-%20Work%20with%20Compute.ipynb\nThere's a section in there 'Create a compute cluster' in which a docker configuration is specified within ScriptRunConfig. I tried running in this code on a compute instance instead of a cluster and got the following error\n\n\n\n\n\n\nThe code works perfectly fine if I use a compute cluster instead of a compute instance",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-31T10:07:49.41Z",
                "Answer_score":0,
                "Answer_body":"@KamalTanwar-5600 Thanks for the question. Can you please add more details about the docker container that you are trying.\n\nPlease follow the document to train a model by using custom docker image. The base images are available on Github.\nYou can also use these Docker images as base images for your custom Azure ML Environments. If you specify any conda dependencies in your Environment, the extra dependencies are installed on top of the dependencies in the Docker image.\n\nPlease follow Prebuilt Docker images for inference (before Inference-optimized curated images). This provides with a faster and simpler deployment experience. These prebuilt Docker Images come with popular machine learning frameworks and python packages.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Request failed with status code 400 in Azure ML",
        "Question_creation_time":1622118479387,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/412196\/request-failed-with-status-code-400-in-azure-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":24,
        "Question_score":0,
        "Question_body":"Created a new Azure ML account. Have set up a workspace, resource group and compute instance as required to run the experiment.\nHowever when i run the model in Designer i get the following error:\nUserError: Request failed with status code 400.\n\nTrace ID : 97ee92cd-cb3c-4b76-b5e5-d2a37be0f33b\nClient request ID : 5e39d178-6437-4594-9cdc-21c0a160fa22\n\nCan someone please advice how do i sort this issue.\n\nThanks.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"DevOps ML Studio Connection",
        "Question_creation_time":1622190501230,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/413565\/devops-ml-studio-connection.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I am trying to create a pipline for machine learning model to be able to logged and run through ML Studio. I created the pipeline on DevOps and created GPU Cluster on ML Studio, estabilished service connection.\n\nWhen I run the pipeline every stage is running well and run is logged to ML Studio but I am having the following error while trying to run train.py\n\n Unable to fetch workspace resources\n\n\n\nSo how can i overcome this issue?\n\nWhat I tried so far:\n\nReestablish connection\n\n\nTried to Run pipeline from ML Studio\n\n\nDeleted Cluster and created a new one",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure ML Upload Data to Azure SQL without Data Factory and Data Transfer Step",
        "Question_creation_time":1622098940050,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/411746\/azure-ml-upload-data-to-azure-sql-without-data-fac.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"From the documentation I could find ways to read data from Azure SQL database registered as datastore in azureML,but not ways to upload or write output data to azure SQL database from azureML. Can anyone please guide me on the same?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-28T04:18:35.477Z",
                "Answer_score":0,
                "Answer_body":"@AndreasMeier-3689 Thanks for the question. Are you trying to upload data using AML Designer or AML python SDK?. You can upload data using upload_directory API.\n\nThe OutputDatasetConfig allows even to register the output as a Dataset, where getting rid of such folder structure makes sense. From the docs itself: \"Represent how to copy the output of a run and be promoted as a FileDataset. The OutputFileDatasetConfig allows you to specify how you want a particular local path on the compute target to be uploaded to the specified destination\".",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Permission error while finishing auto ml run",
        "Question_creation_time":1621886630607,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/407580\/permission-error-while-finishing-auto-ml-run.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I get the following error inside the child runs in ML studio while doing an Automated ML experiment.\n\n\"Identity does not have permissions for Microsoft.MachineLearningServices\/workspaces\/metadata\/artifacts\/write actions.\"\n\nI am the owner of the resource group so I am not sure what the issue is.\n\n\n\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-25T19:35:10.163Z",
                "Answer_score":0,
                "Answer_body":"Hello everyone, @ShubhamMiglani-1182 @NickSchafer-7538\n\nWe have identified the issue and a hot fix is rolling out. It will be fixed in all regions by end of today. Sorry for the experience.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-05-25T00:27:59.687Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us. It seems there is something wrong with the role-base. I would suggest you check on your current role or reassign roles to yourself and have a try as below:\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-assign-roles#manage-workspace-access\n\nPlease let me know if you still have any question.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-25T16:11:34.89Z",
                "Answer_score":0,
                "Answer_body":"We are having the same issue. I think that a change that Microsoft made some time within the last few days either deleted a bunch of custom roles or created new roles that are now required inside of the Machine Learning Workspace. Any thoughts @ramr-msft ?",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-26T17:41:12.733Z",
                "Answer_score":0,
                "Answer_body":"Hello everyone,\n\nThis issue should be fixed. Please check and let me know if you are still facing any issue.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Pipeline can not be built using a HyperdriveStep inside a Pipeline",
        "Question_creation_time":1621515534017,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/403018\/pipeline-can-not-be-built-using-a-hyperdrivestep-i.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":10,
        "Question_score":1,
        "Question_body":"Hei, I'm trying to build a pipeline including a HyperdriveStep to tuen the hyperparameters.\nThe pipeline should later on run automatically and be tuned at each pipeline run.\n\nThe pipeline consists of three steps: a preparation step resulting in a PipelineData Object, the HyperdriveStep and a final PythonRegisterStep, where the best model should be registered.\n\nHowever, when creating the pipeline object I'm getting an error I can not relate to.\n\n\n\n\nTraceback (most recent call last):\n\n       File \"\/Users\/xxx\/Desktop\/azure_test\/pipeline-folder\/azure_pipeline_wrapper1.py\", line 168, in <module>\n         pipeline = Pipeline(workspace=ws, steps=pipeline_steps, description=\"Pipeline for hyperparameter tuning\")\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/core\/_experiment_method.py\", line 104, in wrapper\n         return init_func(self, *args, **kwargs)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/pipeline.py\", line 177, in __init__\n         self._graph = self._graph_builder.build(self._name, steps, finalize=False)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py\", line 1481, in build\n         graph = self.construct(name, steps)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py\", line 1503, in construct\n         self.process_collection(steps)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py\", line 1539, in process_collection\n         builder.process_collection(collection)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py\", line 1830, in process_collection\n         self._base_builder.process_collection(item)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py\", line 1533, in process_collection\n         return self.process_step(collection)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/core\/builder.py\", line 1577, in process_step\n         node = step.create_node(self._graph, self._default_datastore, self._context)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/steps\/hyper_drive_step.py\", line 270, in create_node\n         hyperdrive_config, reuse_hashable_config = self._get_hyperdrive_config(context._workspace,\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/pipeline\/steps\/hyper_drive_step.py\", line 346, in _get_hyperdrive_config\n         hyperdrive_dto = _search._create_experiment_dto(self._hyperdrive_config, workspace,\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/train\/hyperdrive\/_search.py\", line 38, in _create_experiment_dto\n         platform_config = hyperdrive_config._get_platform_config(workspace, experiment_name, **kwargs)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/train\/hyperdrive\/runconfig.py\", line 672, in _get_platform_config\n         platform_config.update(self._get_platform_config_data_from_run_config(workspace))\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/train\/hyperdrive\/runconfig.py\", line 686, in _get_platform_config_data_from_run_config\n         run_config = get_run_config_from_script_run(self.run_config)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/site-packages\/azureml\/core\/script_run_config.py\", line 84, in get_run_config_from_script_run\n         run_config.arguments = deepcopy(script_run_config.arguments)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 146, in deepcopy\n         y = copier(x, memo)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 205, in _deepcopy_list\n         append(deepcopy(a, memo))\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 172, in deepcopy\n         y = _reconstruct(x, memo, *rv)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 270, in _reconstruct\n         state = deepcopy(state, memo)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 146, in deepcopy\n         y = copier(x, memo)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 230, in _deepcopy_dict\n         y[deepcopy(key, memo)] = deepcopy(value, memo)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 172, in deepcopy\n         y = _reconstruct(x, memo, *rv)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 270, in _reconstruct\n         state = deepcopy(state, memo)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 146, in deepcopy\n         y = copier(x, memo)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 230, in _deepcopy_dict\n         y[deepcopy(key, memo)] = deepcopy(value, memo)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 172, in deepcopy\n         y = _reconstruct(x, memo, *rv)\n        \n       File \"\/Users\/xxx\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copy.py\", line 264, in _reconstruct\n         y = func(*args)\n        \n       File \"\/Users\/xxxr\/opt\/anaconda3\/envs\/azure_env\/lib\/python3.8\/copyreg.py\", line 91, in __newobj__\n         return cls.__new__(cls, *args)\n        \n     TypeError: __new__() missing 2 required positional arguments: 'workspace' and 'name'\n\n\n\n\n\nMy Code:\n\n # Connect to workspace \n ws = Workspace.from_config()\n print(ws.name, \"loaded\")\n    \n # Set compute target\n cluster_name = \"compcluster234\"\n pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n    \n # Create new environment\n sklearn_env = Environment(\"sklearn_env\")\n # Adds dependencies to PythonSection of sklaern_env\n env_packages = CondaDependencies.create(conda_packages=['scikit-learn'])\n sklearn_env.docker.enabled = True\n sklearn_env.python.conda_dependencies = env_packages\n # Register the environment\n sklearn_env.register(workspace=ws)\n    \n # =============================================================================\n # Run Configuration\n # =============================================================================\n    \n # Create Run configuration \n # Pipeline_folder\n pipeline_folder = path + '\/pipeline-folder'\n # Create a new runconfig object for the pipeline\n pipeline_run_config = RunConfiguration()\n # Use the compute you created above. \n pipeline_run_config.target = pipeline_cluster\n # Assign the environment to the run configuration\n # In comparison to the ScriptRunCnfig object, the RunConfig is more generous\n pipeline_run_config.environment = sklearn_env\n print (\"Run configuration created.\")\n    \n # =============================================================================\n # DataPath\n # =============================================================================\n    \n # Get the default datastore\n default_ds = ws.get_default_datastore()\n # Create a DataPath object \n datapath = DataPath(datastore = default_ds,\n                      path_on_datastore = 'cancer-data')\n # Make the datapath a PipelineParameter\n datapath_pipeline_param = PipelineParameter(name='input-data',   \n                                             default_value=datapath)\n datapath_input = (datapath_pipeline_param, \n                    DataPathComputeBinding(mode = 'mount'))\n    \n # =============================================================================\n # PipelineData\n # =============================================================================\n    \n # Create a PipelineData (temporary Data Reference) for the preppared data folder\n prepped_data_folder = PipelineData(name=\"prepped_data_folder\",\n                                    datastore=ws.get_default_datastore())\n    \n # Create PipelineData objects for the Metrics and the saved model\n metrics_output_name = 'metrics_output'\n metrics_data = PipelineData(name='metrics_data',\n                             datastore=default_ds,\n                             pipeline_output_name=metrics_output_name,\n                             training_output=TrainingOutput(\"Metrics\"))\n    \n model_output_name = 'model_output'\n saved_model = PipelineData(name='saved_model',\n                            datastore=default_ds,\n                            pipeline_output_name=model_output_name,\n                            training_output=TrainingOutput(\"Model\",\n                                                           model_file=\"outputs\/model\/cancer_model.pkl\"))\n    \n # =============================================================================\n # Pipeline Steps\n # =============================================================================\n    \n # Step 1, Run the data prep script\n prep_step = PythonScriptStep(name = \"prepare_data\",\n                                 source_directory = pipeline_folder,\n                                 script_name = \"cancer_pipeline_preprocessing.py\",\n                                 arguments = ['--input-data', datapath_input,\n                                              '--prepped-data', prepped_data_folder],\n                                 inputs=[datapath_input],\n                                 outputs=[prepped_data_folder],\n                                 compute_target = pipeline_cluster,\n                                 runconfig = pipeline_run_config,\n                                 allow_reuse = False)\n    \n # Define the search strategy and parameter space for hyperparameter tuning\n ps = GridParameterSampling({ '--max_depth': choice(1,2,3)})\n # Define a early stopping criteria\n early_termination_policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n # Define a ScriptRunConfig for the Training script\n # The ScriptRunConfig is based on the RunConfig of the Pipeline\n script_run_config = ScriptRunConfig(script=\"cancer_pipeline_tuning.py\",\n                                     source_directory=pipeline_folder,\n                                     # Add non-hyperparameter arguments -in this case, the training dataset\n                                     arguments = ['--training_folder', prepped_data_folder],\n                                     run_config=pipeline_run_config)\n # Define a HyperDriveConfiguration\n # The primary_metric_name must be completely idential to the metric name logged during training (inside the training script)\n hd_config = HyperDriveConfig(run_config=script_run_config, \n                              hyperparameter_sampling=ps,\n                              policy=early_termination_policy,\n                              primary_metric_name='Accuracy', \n                              primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n                              max_total_runs=3,\n                              max_concurrent_runs=2)\n    \n # Step 2b, define a HyperDriveStep\n # HyperDriveStep can be used to run HyperDrive job as a step in pipeline.\n # No arguments need to be set as they are already set inside the ScriptRunConfig\n hyperdrive_step = HyperDriveStep(name=\"tune_hyperparameters\",\n                                  hyperdrive_config=hd_config,\n                                  inputs=[prepped_data_folder],\n                                  outputs=[metrics_data, saved_model])\n    \n hyperdrive_step.run_after(prep_step)    \n    \n # Step 3, Run the model registration step\n register_step = PythonScriptStep(name=\"register_model\",\n                                        script_name='cancer_pipeline_register1.py',\n                                        source_directory = pipeline_folder,\n                                        arguments=[\"--saved_model\", saved_model],\n                                        inputs=[saved_model],\n                                        compute_target = pipeline_cluster,\n                                        runconfig=pipeline_run_config,\n                                        allow_reuse = False)\n    \n register_step.run_after(hyperdrive_step)    \n print(\"Pipeline steps defined\")\n    \n    \n # Construct the pipeline\n pipeline_steps = [prep_step, hyperdrive_step, register_step]\n pipeline = Pipeline(workspace=ws, steps=pipeline_steps, description=\"Pipeline for hyperparameter tuning\")\n print(\"Pipeline is built.\")",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-27T06:48:25.463Z",
                "Answer_score":4,
                "Answer_body":"Solved the issue!\n\nHad to remove the arguments argument of the ScriptRunConfig and instead set the values to the Hyperdrive Steps estimator_entry_script_arguments argument.\n\n # Step 1, Run the data prep script\n prep_step = PythonScriptStep(name = \"prepare_data\",\n                                 source_directory = pipeline_folder,\n                                 script_name = \"cancer_pipeline_preprocessing.py\",\n                                 arguments = ['--input-data', datapath_input,\n                                              '--prepped-data', prepped_data_folder],\n                                 inputs=[datapath_input],\n                                 outputs=[prepped_data_folder],\n                                 compute_target = pipeline_cluster,\n                                 runconfig = pipeline_run_config,\n                                 allow_reuse=False)\n    \n # Define the search strategy and parameter space for hyperparameter tuning\n ps = GridParameterSampling({'--max_depth': choice(1,2,3),\n                             '--n_estimators': choice(100,300)})\n # Define a early stopping criteria\n early_termination_policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n # Define a ScriptRunConfig for the Training script\n # The ScriptRunConfig is based on the RunConfig of the Pipeline\n script_run_config = ScriptRunConfig(script=\"cancer_pipeline_tuning.py\",\n                                     source_directory=pipeline_folder,\n                                     run_config=pipeline_run_config)\n # Define a HyperDriveConfiguration\n # The primary_metric_name must be completely idential to the metric name logged during training (inside the training script)\n hd_config = HyperDriveConfig(run_config=script_run_config, \n                              hyperparameter_sampling=ps,\n                              policy=None,\n                              primary_metric_name=\"Accuracy\", \n                              primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n                              max_total_runs=6,\n                              max_concurrent_runs=2)\n    \n # Step 2b, define a HyperDriveStep\n # HyperDriveStep can be used to run HyperDrive job as a step in pipeline.\n # No arguments need to be set as they are already set inside the ScriptRunConfig\n hyperdrive_step = HyperDriveStep(name=\"tune_hyperparameters\",\n                                  hyperdrive_config=hd_config,\n                                  # Add non-hyperparameter arguments -in this case, the training dataset\n                                  # IMPORTANT: Don't add them already in the ScriptRunConfig\n                                  estimator_entry_script_arguments=['--training_folder', prepped_data_folder],\n                                  inputs=[prepped_data_folder],\n                                  outputs=[metrics_data, saved_model],\n                                  allow_reuse=False)",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-05-20T13:03:44.283Z",
                "Answer_score":0,
                "Answer_body":"The product group for Azure DevOps \/ TFS actively monitors questions over at\nhttps:\/\/developercommunity.visualstudio.com\/report?space=21&entry=problem\nhttps:\/\/developercommunity.visualstudio.com\/report?space=22&entry=problem\n\n--please don't forget to Accept as answer if the reply is helpful--",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How do I access an input parameter in Azure Machine Learning endpoints?",
        "Question_creation_time":1602485723003,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/123204\/how-do-i-access-an-input-parameter-in-azure-machin.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"I've created an Azure ML Endpoint Pipeline with a single 'Execute Python Script'. From the script, I am looking for a way to access the input 'ParameterAssignments' that I POST to the endpoint to trigger the pipeline. I expected to see them somewhere in Run.get_context(), but I haven't had any luck. I simply need a way to POST arbitrary values that my Python scripts can access. Thank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-19T01:08:06.24Z",
                "Answer_score":1,
                "Answer_body":"I just confirmed with our engineer that you cannot set up a pipeline parameter and use it without tying it with any of the module parameter. So the workaround is - make the pipeline parameter as one of the inputs (i.e. dataset) to \"Execute Python Script\" module and set it as pipeline parameter. Then you can change it every time when calling the pipeline.",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-05-27T06:21:17.273Z",
                "Answer_score":0,
                "Answer_body":"Hi @LuZhangAI-1027, I am finding a way to connect to Postgres in my pipeline. I don't think 'Import Data' supports it, so I am thinking to write my own 'Execute Python Script' to load the data from Postgres. As I don't use 'Import Data', is there another way to access the pipeline parameters inside 'Execute Python Script'?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Auth Problems with Machine Learning Execute Pipeline Activity.",
        "Question_creation_time":1621952386747,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/408869\/auth-problems-with-machine-learning-execute-pipeli.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":3,
        "Question_comment_count":3,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hello. Can anyone help with this error? Can not execute Azure ML activity from ADF.\nEverything was ok, no changes was done but suddenly(two-three days ago) I got this error.\n\n Request sent to Azure ML Service for operation 'submitMLPipelineRun' failed with http status code 'Forbidden'. Error message from Azure ML Service: '{ \"error\": { \"code\": \"UserError\", \"severity\": null, \"message\": \"Identity does not have permissions for Microsoft.MachineLearningServices\/workspaces\/experiments\/runs\/submit\/action, Microsoft.MachineLearningServices\/workspaces\/endpoints\/pipelines\/read actions.\", \"messageFormat\": null, \"messageParameters\": null, \"referenceCode\": null, \"detailsUri\": null, \"target\": null, \"details\": [], \"innerError\": { \"code\": \"ForbiddenError\", \"innerError\": null } '.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-25T19:35:57.963Z",
                "Answer_score":1,
                "Answer_body":"@DenisBruk-6507\n\nWe have identified the issue and a hot fix is rolling out. It will be fixed in all regions by end of today. Sorry for the experience.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-05-25T17:34:38.503Z",
                "Answer_score":1,
                "Answer_body":"@YutongTie-5848 I think that this may also be related to our issue. I'm also getting a \"code\": \"ForbiddenError\" and the problem for this user arose at almost exactly the same time that it arose for us.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-26T17:41:58.203Z",
                "Answer_score":1,
                "Answer_body":"Hello everyone,\n\nThis issue should be fixed. Please check and let me know if you are still facing any issue.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Customvision run trained tensorflow model in Python: Placeholder:0 refers to a non existing tensor in image classification",
        "Question_creation_time":1621939072900,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/408585\/customvision-run-trained-tensorflow-model-in-pytho.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi all,\n\nI have trained an image classifier with the customvision service, which worked as charm. Now I would like to run the model inference locally with a python script on my PC. Therefore I have been following the tutorial on https:\/\/docs.microsoft.com\/en-us\/azure\/cognitive-services\/custom-vision-service\/export-model-python\n\nI am having troubles with sess.graph.get_tensor_by_name('Placeholder:0').shape.as_list()\n\nCould you please provide some information on the system requirements and the python package versions? An openCV 4.5.1 C++ code snippet on how to consume the downloaded model would be also great if possible.\n\nI am using Python 3.8.5\n\nThank you",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-26T07:34:21.963Z",
                "Answer_score":0,
                "Answer_body":"Thank you, will do.\n\nI have solved the issue with using C++ openCV instead and WinML also helps with rapid prototyping.\n\nThis was a particularly good example I have found:\n\nhttps:\/\/github.com\/Azure-Samples\/cognitive-services-onnx-customvision-sample\n\nWould be great to have more of those.\n\nBest.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Custom Vision for Canada region",
        "Question_creation_time":1606512423207,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/178721\/custom-vision-for-canada-region.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"I used Custom Vision to create a small proof of concept project, and it works super nice; however, now that we are ready for the next steps to see if it is doable to use it, I have got some questions that might be roadblocks if I were to go ahead and work on the business implementation:\n\nThe service cannot be deployed in Canada regions. Is this something that will be considered in the future? This is a huge block because the items classified may contain data that should not leave the Canadian space\n\n\nWhat's the privacy terms of using custom vision or where can I find them to read? As the previous item describes, the items classified could contain compromised data, so it would be unfeasible to use the custom vision service if the data is going to be \"shared\" or \"used\" by Microsoft or other parties for other purposes.\n\nAs a side question, is this service capable of classifying PDF documents as images? And if not, is there a known Azure\/Microsoft service that does so?\n\nThanks a bunch! :)\n\nKenny Perroni",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-30T04:09:44.577Z",
                "Answer_score":1,
                "Answer_body":"@KennyPerroni-1017 Thanks for the feedback. We have forwarded this feedback to our product team, You can also raise a user voice request here so the community can vote and provide their feedback, the product team then checks this feedback and implements the same for Canada region. For Region availability please check the following link\n\nFor custom vision service you control over the storage and deletion of any customer data that store as part of the service. Please follow the below for privacy and compliance. As with all of the Cognitive Services, developers using the Custom Vision service should be aware of Microsoft's policies on customer data. See the below Cognitive Services page on the Microsoft Trust Center to learn more.\nhttps:\/\/azure.microsoft.com\/en-us\/support\/legal\/cognitive-services-compliance-and-privacy\/\n\n\n\n\nThe Computer vision Read service support PDF document as images. Here is the link for vision best practice and samples. Also the Form Recognizer supports OCR and PDF documents with AI builder.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Fisher Linear Discriminant Analysis Azure",
        "Question_creation_time":1621855005240,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/407053\/fisher-linear-discriminant-analysis-azure.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"How is the output of Fisher Linear Discriminant Analysis experiment interpreted now that the column labels in the output are replaced with Col1, Col2, Col3.......etc? How can the model be used to predict clusters of other input data as deployed web service requires even the dependent valuable(the same same ones we wish to predict)?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-24T22:27:20.423Z",
                "Answer_score":0,
                "Answer_body":"Are you referring to the categories generated from LDA module? If so, then that's expected. LDA is an unsupervised technique, it groups words into categories\/topics and it's up to the analyst to interpret it by observing the results and transforming the output dataset accordingly. Here's are some examples of LDA approach in Azure AI Gallery. Hope this helps.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Submitted script failed with a non-zero exit code; see the driver log file for details.",
        "Question_creation_time":1621178105710,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/396708\/submitted-script-failed-with-a-non-zero-exit-code-1.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hello, I'm trying to do Hyperparameter tuning a model with Azure Machine Learning with this : https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-tune-hyperparameters.\n\nThis time I created dataset from blob storage and used tensor-flow for model.\n\nI run the code and faced the error saying :\n\nAzureMLCompute job failed.\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\nReason: Job failed with non-zero exit Code\n\nso I looked at the driver log file and I guess the error happed around tensor-flow because of ~~ Could not load dynamic library 'libcudart.so.11.0~~\nSo I searched on Google but still I cannot understand. Is tensor-flow model need GPU? or what? Someone could help?\n\n\n\n\nThis is my driver log:\n\n2021\/05\/16 10:51:45 Starting App Insight Logger for task: runTaskLet\n2021\/05\/16 10:51:45 Attempt 1 of http call to http:\/\/10.0.0.5:16384\/sendlogstoartifacts\/info\n2021\/05\/16 10:51:45 Attempt 1 of http call to http:\/\/10.0.0.5:16384\/sendlogstoartifacts\/status\n[2021-05-16T10:51:45.699995] Entering context manager injector.\n[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['train.py', '--data-folder', 'DatasetConsumptionConfig:input_c9585223', '--Learning_rate', '0.051451410113531125', '--batchsize', '16', '--epochs', '150', '--monitor', 'val_loss', '--optimizer', 'Adam'])\nScript type = None\n[2021-05-16T10:51:47.320428] Entering Run History Context Manager.\n[2021-05-16T10:51:48.009123] Current directory: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/koichi_2\/azureml\/hd_15c1b55e-af9d-4a09-a51a-77021483d144_1\/mounts\/workspaceblobstore\/azureml\/HD_15c1b55e-af9d-4a09-a51a-77021483d144_1\n[2021-05-16T10:51:48.009468] Preparing to call script [train.py] with arguments:['--data-folder', '$input_c9585223', '--Learning_rate', '0.051451410113531125', '--batchsize', '16', '--epochs', '150', '--monitor', 'val_loss', '--optimizer', 'Adam']\n[2021-05-16T10:51:48.009538] After variable expansion, calling script [train.py] with arguments:['--data-folder', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/koichi_2\/azureml\/hd_15c1b55e-af9d-4a09-a51a-77021483d144_1\/wd\/tmpjipv9560', '--Learning_rate', '0.051451410113531125', '--batchsize', '16', '--epochs', '150', '--monitor', 'val_loss', '--optimizer', 'Adam']\n\n2021-05-16 10:51:48.499303: W tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: \/opt\/intel\/compilers_and_libraries_2018.3.222\/linux\/mpi\/intel64\/lib:\/opt\/intel\/compilers_and_libraries_2018.3.222\/linux\/mpi\/mic\/lib:\/opt\/intel\/compilers_and_libraries_2018.3.222\/linux\/mpi\/intel64\/lib:\/opt\/intel\/compilers_and_libraries_2018.3.222\/linux\/mpi\/mic\/lib:\/azureml-envs\/azureml_9a5f179879cdab6df3327a8de34708df\/lib:\n2021-05-16 10:51:48.499444: I tensorflow\/stream_executor\/cuda\/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2021\/05\/16 10:51:50 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\nData folder: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/koichi_2\/azureml\/hd_15c1b55e-af9d-4a09-a51a-77021483d144_1\/wd\/tmpjipv9560\n\n\n\n\n[2021-05-16T10:52:00.314862] The experiment failed. Finalizing run...\nCleaning up all outstanding Run operations, waiting 900.0 seconds\n1 items cleaning up...\nCleanup took 0.07348918914794922 seconds\nTraceback (most recent call last):\nFile \"train.py\", line 66, in <module>\ncategory = int((filename.split('.')[0]).split('_')[1])\nIndexError: list index out of range\n\n[2021-05-16T10:52:00.547629] Finished context manager injector with Exception.\n2021\/05\/16 10:52:02 Skipping parsing control script error. Reason: Error json file doesn't exist. This most likely means that no errors were written to the file. File path: \/mnt\/batch\/tasks\/workitems\/0e6791a9-a28d-438a-b11f-36b36ecd8da0\/job-1\/hd_15c1b55e-af9d-4a0_5be5fa54-845a-471b-8be4-e1ea80f84819\/wd\/runTaskLetTask_error.json\n2021\/05\/16 10:52:02 Failed to run the wrapper cmd with err: exit status 1\n2021\/05\/16 10:52:02 Attempt 1 of http call to http:\/\/10.0.0.5:16384\/sendlogstoartifacts\/status\n2021\/05\/16 10:52:02 mpirun version string: {\nIntel(R) MPI Library for Linux* OS, Version 2018 Update 3 Build 20180411 (id: 18329)\nCopyright 2003-2018 Intel Corporation.\n}\n2021\/05\/16 10:52:02 MPI publisher: intel ; version: 2018\n2021\/05\/16 10:52:02 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 2\nFilteredData: 0.\n2021\/05\/16 10:52:02 Process Exiting with Code: 1\n2021\/05\/16 10:52:02 All App Insights Logs was send successfully",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How can i access azure ml pipeline parameters from a python script running in designer?",
        "Question_creation_time":1620522230407,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/387875\/how-can-i-access-azure-ml-pipeline-parameters-from.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I would like to perform some data transformations using the Python script module in Designer for which i would need to access some pipeline parameters. How can i get those values?\n\nWhat would be the equivalent for an R script?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-18T04:06:56.287Z",
                "Answer_score":0,
                "Answer_body":"@javier-8889 Thanks, Currently passing a pipeline parameter to the script of Execute Python\/R Module is not supported. We have a new feature custom module which is in private preview. you can write your own module and use in Designer. If it's a common case, it might be better to use custom module.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Wrong display of .ilearner file",
        "Question_creation_time":1620835289703,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/392953\/wrong-display-of-ilearner-file.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Can anyone help me with this issue please ?\nI get the file (in .ilearner format) cannot be correctly displayed cuz it contains an unknown extension when I try to open it.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-25T06:55:57.853Z",
                "Answer_score":0,
                "Answer_body":"@Salah-1213 Hello Salah,\n\nPer my research, the ilearn interface is supported on Azure Machine Learning Studio(class), but I can not find any official document indicate this is supported on Azure Machine Learning Designer as well. Sorry for the experience. https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/ilearner-interface\n\nIf there is any document you are using has any clue please let me know.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"azuremlsdk for R error Could not retrieve user token. Please run 'az login'",
        "Question_creation_time":1621290302507,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/398420\/azuremlsdk-for-r-error-could-not-retrieve-user-tok.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I'm trying to create a workspace in azure machine learning and receiving this error after 2 browser Windows open and I click log in.\n\nlibrary(azuremlsdk)\nnew_ws <- create_workspace(name = 'muffin',\n\n\n+ subscription_id = 'XXXXXXXXXXXX',\n+ resource_group = 'white',\n+ location = 'eastus2',\n+ create_resource_group = T)\nNote, we have launched a browser for you to login. For old experience with device code, use \"az login --use-device-code\"\nYou have logged in. Now let us find all the subscriptions to which you have access...\nNote, we have launched a browser for you to login. For old experience with device code, use \"az login --use-device-code\"\nYou have logged in. Now let us find all the subscriptions to which you have access...\nError in py_call_impl(callable, dots$args, dots$keywords) :\nAuthenticationException: AuthenticationException:\nMessage: Could not retrieve user token. Please run 'az login'\nInnerException It is required that you pass in a value for the \"algorithms\" argument when calling decode().\nErrorResponse\n{\n\"error\": {\n\"code\": \"UserError\",\n\"inner_error\": {\n\"code\": \"Authentication\"\n},\n\"message\": \"Could not retrieve user token. Please run 'az login'\"\n}\n}\n\n\nhow do I get passed this error?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-24T08:27:35.833Z",
                "Answer_score":0,
                "Answer_body":"You have to use this command to make it install the correct version of miniconda reticulate::py_install(\"PyJWT==1.7.1\"). If you don't do that it seems to install the wrong version. I also had to manually delete the r-miniconda folder in \\appdata\\local\\r-miniconda which got installed previously to get it to install the correct version. It's pretty outrageous they leave that out of the tutorial when it ain't going to work otherwise.\n\nIf you try to do the accident.R tutorial for azuremlsdk-r next make sure you add the line\n\ninteractive_auth <- interactive_login_authentication(tenant_id=\"<tenant id>\")\n\nto your code otherwise you'll get a permissions error and it won't work.\n\nThen to the create_workspace or get_workspace function you have to add auth = interactive_auth after a comma.\n\nIt should look like this\n\nnew_ws <- get_workspace(name = \"<workspace name>\",\nsubscription_id = \"<subscription id>\",\nresource_group = \"<resource name>\",\nauth = interactive_auth)\n\nTo find the tenant ID I had to download the azure CLI and run the command az login. Not sure if there is another way to find a tenant ID or not.\n\n\n\n\nTo leave out critical steps from a tutorial is gross incompetence on the part of Azure. How anyone who isn't a comp sci phd uses this service is a mystery to me.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Which Microsoft tool to apply AI & ML to analyze livechat coversations?",
        "Question_creation_time":1621258587277,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/397779\/which-microsoft-tool-to-apply-ai-amp-ml-to-analyze.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\n\nI have a project where we want to analyze the content of the livechat, i.e, the livechat conversations (stored in the Azure cloud) with AI and potentially show this information in Power BI dashboards. For example, to identify the topics more discussed in the chat and so on or identify new trends in the chat data\n\nWhich would be the best Microsoft features for such a purpose? R and Azure Microsoft learning?\nAny idea\/recommendations\n\nThanks so much,\nJFB",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-17T22:27:02.563Z",
                "Answer_score":0,
                "Answer_body":"Hi thanks for reaching out. Based on your scenario, Azure ML would be ideal. It has modules for text analytics including topic modeling. You can leverage the Execute R\/Python Script module to perform more customization. You can also create reports in PowerBI based on your deployed model. Hope this helps!",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning - correct input dataset however cannot open files needed due to '[Errno 2] No such file or directory'",
        "Question_creation_time":1621502815900,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/402690\/azure-machine-learning-correct-input-dataset-howev.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"I'm using Microsoft Azure Machine Learning to train a CNN. This is the link to the github where the model is stored: https:\/\/github.com\/rodekruis\/caladrius\/tree\/handle_imbalance\/caladrius. This code already works, I'm just trying to run the model (so do both training\/testing) myself in my own Microsoft Azure Machine Learning environment now. I have the data needed for training, and by following the 'Tutorial: use your own data' (https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-1st-experiment-bring-data) I uploaded the data in a datastore, which is of type 'Azure Blob Storage'. Then, I want to run the model such that it starts training. In order to do so, the 'run.py' file in the Github has to be run and I created the following control script to run it in the Microsoft Azure environment:\n\n from azureml.core import Run, Workspace, Datastore, Dataset, Experiment, ScriptRunConfig, Environment\n from azure.identity import DefaultAzureCredential\n from azureml.data.datapath import DataPath\n from azureml.data.dataset_consumption_config import DatasetConsumptionConfig\n from azureml.data import OutputFileDatasetConfig\n    \n if __name__ == \"__main__\":\n     run = Run.get_context()\n     credential = DefaultAzureCredential()\n     ws = Workspace.from_config()\n     datastore = Datastore.get(ws, 'xview')\n     dataset_small = Dataset.File.from_files(path=(datastore, '\/test_small\/**'))\n     #print(dataset_small.to_path())\n     #data_path = DataPath(datastore=datastore, path_on_datastore='test_small\/')\n    \n     checkpoint = OutputFileDatasetConfig(destination=(datastore, '\/test_small\/runs\/'))\n    \n     experiment = Experiment(workspace=ws, name='thesis-sanne')\n     config = ScriptRunConfig(source_directory='', \n     script='run.py', \n     compute_target='standardK80GPU', \n     arguments = ['--data-path',dataset_small.as_named_input('input').as_mount(), \n     '--output-type', 'classification',\n     '--run-name', 'test1',\n     '--checkpoint-path', checkpoint,\n     ]\n     )  \n    \n     env= Environment.from_conda_specification(name='caladriusenv', file_path='caladriusenv.yml')\n     config.run_config.environment = env\n    \n     run = experiment.submit(config)\n     aml_url = run.get_portal_url()\n     print(aml_url)\n\n\n\nwhen I submit this run, the run fails after receiving the following error:\n\nUserError: [Errno 2] No such file or directory: '9e3238da-8b8f-441a-a71a-2f6911f58f33\/train\/labels.txt'\n\nSee also in this picture: Error message from run\n\nThe exact error message given in the 70_driver_log.txt file is:\n\n[2021-05-16T08:26:21.977916] The experiment failed. Finalizing run...\n2021-05-16 08:26:21,978 main INFO Exiting context: TrackUserError\n[2021-05-16T08:26:21.984462] Writing error with error_code UserError and error_hierarchy UserError\/FileNotFoundError to hosttool error file located at \/mnt\/batch\/tasks\/workitems\/073df44a-2932-4bfb-a484-64e6382d81a1\/job-1\/thesis-sanne_1621153_5c453238-c8de-474e-b42c-44f791fbccea\/wd\/runTaskLetTask_error.json\nStarting the daemon thread to refresh tokens in background for process with pid = 85\n2021-05-16 08:26:22,061 main INFO Exiting context: RunHistory\n2021-05-16 08:26:22,061 main INFO Exiting context: Dataset\n2021-05-16 08:26:22,062 main INFO Exiting context: ProjectPythonPath\nTraceback (most recent call last):\nFile \"run.py\", line 59, in <module>\nmain()\nFile \"run.py\", line 46, in main\nrun_report, datasets, args.number_of_epochs, args.selection_metric\nFile \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/azureaccount\/azureml\/thesis-sanne_1621153514_fc6d0c0e\/mounts\/workspaceblobstore\/azureml\/thesis-sanne_1621153514_fc6d0c0e\/model\/trainer.py\", line 395, in train\ntrain_set, train_loader = datasets.load(\"train\")\nFile \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/azureaccount\/azureml\/thesis-sanne_1621153514_fc6d0c0e\/mounts\/workspaceblobstore\/azureml\/thesis-sanne_1621153514_fc6d0c0e\/model\/data.py\", line 144, in load\naugment_type=self.augment_type,\nFile \"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/azureaccount\/azureml\/thesis-sanne_1621153514_fc6d0c0e\/mounts\/workspaceblobstore\/azureml\/thesis-sanne_1621153514_fc6d0c0e\/model\/data.py\", line 75, in init\nos.path.join(self.directory, self.labels_filename) #self.labels_filename) # \"labels.txt\")\nFileNotFoundError: [Errno 2] No such file or directory: '9e3238da-8b8f-441a-a71a-2f6911f58f33\/train\/labels.txt'\n\nHowever, the datastore itself is found correctly and is stated as the 'Input datasets' in the picture, which includes the 'train\/labels.txt' file I'm trying to open. I checked this in the script, by printing:\n\nprint(dataset_small.to_path())\n\nAnd the output of this included the file '\/train\/labels.txt'\n\nI think my problem is that the script does correctly call the dataset, however the data-path it needs to open the files, is incorrect. Trying to solve this problem I've already tried the following:\n\nInstead of '--data-path', dataset_small.as_named_input('input').as_mount() I used:\n\n\n\n\nDataPath(datastore=datastore, path_on_datastore='test_small\/'), however this doesn't work as a DataPath object is not JSON serializable\n\n\nDataReference(datastore, path_on_datastore='.\/test_small\/', mode='mount'), however this doesn't work as a DataReference object is not JSON serializable\n\n\nDatasetConsumptionConfig('dataset', dataset_small, mode='direct', path_on_compute=None), this is essentially what I do with Dataset.File.from_files() already and thus also doesn't work\n\n\nDataPathComputeBinding(mode='mount', path_on_compute=None, overwrite=False), however this doesn't work as a DataPathComputeBinding object is not JSON serializable\n\n\ndatastore_paths = [(blob_datastore, 'test_small')], however this doesn't work as this object is not JSON serializable\n\nInstead of accessing the datastore in the Azure Machine Learning environment I tried accessing the datacontainer including the data directly from my Azure Storage account\/container. However the same problem occured.\n\n\n\n\nThus the problem shortly is that my Azure Machine Learning does find the dataset I want it to use, which includes everything needed. However the model is not able to open the datafiles because it says they don't exist whereas I'm sure that they do exist and the Azure Machine Learning environment does know where to find them but does not know how to access\/open them properly I think?\n\nIt seems to be an easy to fix problem, however I've tried every way I could think of or was proposed online and still nothing has worked yet. So hopefully someone here can help me, thank you so much in advance! If extra information is needed to clarify things, I'd be glad to provide it.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-20T15:44:44.003Z",
                "Answer_score":0,
                "Answer_body":"@Sanne-7647 Thanks for the question, I usually find OutputFileDatasetConfig very powerful. Please follow the below to reference folder\/directory with ScriptRunConfig in Azureml.\n\n from azureml.core import ScriptRunConfig, Experiment\n from azureml.data import OutputFileDatasetConfig\n output_port = OutputFileDatasetConfig(\n     destination=(def_data_store, \"outputs\/test_diroutputFileDatasetConfig\/\"), name=\"dir_test\"\n )\n     \n experiment = Experiment(ws, 'MyExperiment')\n config = ScriptRunConfig(source_directory='modules\/test_output_dir\/',\n                          script='copy.py',\n                          arguments = ['--output',\n                                   output_port],\n                          compute_target=\" \")\n script_run = experiment.submit(config)\n\n\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-register-datasets#create-a-filedataset\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-register-datasets#create-a-tabulardataset\n\nMachineLearningNotebooks\/file-dataset-image-inference-mnist.ipynb at master \u00b7 Azure\/MachineLearningNotebooks (github.com)",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Python Kernel 3.8.1 runs conda 3.6.9",
        "Question_creation_time":1621493873427,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/402465\/python-kernel-381-runs-conda-369.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Hello,\nI have been trying to run !python trainp.py from yolov5, but is required to have python>=3.7. I tryied to run in the same path the command !python38 train.py but suddently it cant open the file. Is it an azure issue or python issue? How can i fix it.\nThank you.\n\nI am working in an Azure ML Notebook.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Cortana Intelligence Current Diagram",
        "Question_creation_time":1621295370853,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/398494\/cortana-intelligence-current-diagram.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Hello. Does anyone have a current diagram like the attached schematic on Cortana Intelligence? This diagram seems to be outdated.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-19T17:04:21.35Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nI have seen a lot of similar version but I can't find any official date for it. Could you please share where\/ which conference you found this so that we can check with related team for more information?\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"is there any way I can serialize the R model which trained using caret or some other libraries instead of RevoScaleR?",
        "Question_creation_time":1621302852490,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/398544\/is-there-any-way-i-can-serialize-the-r-model-which.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":16,
        "Question_score":0,
        "Question_body":"I am using SQL Server Machine Learning services to Run a R model. I am able to serialize it using RevoScaleR and rxSerializeModel but I want to use caret instead of RevoScaleR here is my code which is giving an error when asks to serialiaze the trained model\n\nStep1 train model using SP\n\nDROP PROCEDURE IF EXISTS generate_PCL_R_native_model;\ngo\nCREATE PROCEDURE generate_PCL_R_native_model (@model_type varchar(30), @trained_model varbinary(max) OUTPUT)\nAS\nBEGIN\n\n EXECUTE sp_execute_external_script\n   @language = N'R'                                  -- Spesify langauge and R code \n , @script = N'                                      \n\nrequire(\"RevoScaleR\")\nrequire(\"caret\")\nrequire(\"ranger\")\nlibrary(caret)\nlibrary(ranger)\n\nfitControl <- trainControl(method = \"cv\",\nnumber = 5,\n\n                        savePredictions = TRUE\n                       ,\n                           \n                        classProbs = T, \n                       verboseIter = F\n                        )\n                        rf_grid <- expand.grid(mtry = 2,\n                    splitrule = c(\"gini\", \"extratrees\"),\n                    min.node.size = c(1, 3, 5));\n\n\n\nif(model_type == \"dtree\") {\nmodel_linmod <-\ntrain(pclitemspct10r_new ~\n\n + d1\n + d2\n + d3\n + d4\n + d5\n + d6\n + d7\n + e1\n + e2\n + e3\n + e4\n + e5\n + e6\n + marriedd1\n + marriedd2\n    \n    \n    \n , data = PCL_train_data, \n             method = \"ranger\",\n             trControl = fitControl,\n             #tuneGrid = rf_grid\n             )\n    \n #serialize the model\n    \n trained_model <- as.raw(serialize((model_linmod, NULL));\n }\n\n'\n\n , @input_data_1 = N'select  * from [dbo].[training_IOP_data_new]'\n , @input_data_1_name = N'PCL_train_data'; \n\nSTEP 2 - Setup model table for storing the model\n\nDROP TABLE IF EXISTS PCL_models;\nGO\nCREATE TABLE PCL_models (\nmodel_name VARCHAR(30) NOT NULL DEFAULT('default model'),\nlang VARCHAR(30),\nmodel VARBINARY(MAX),\nnative_model VARBINARY(MAX),\nPRIMARY KEY (model_name, lang)\n\n);\nGO\nStep 3 Save the model in table format\n\nDECLARE @model2 VARBINARY(MAX);\nEXEC generate_PCL_R_native_model \"dtree\", @model2 OUTPUT;\nINSERT INTO PCL_models (model_name, native_model, lang) VALUES('dtree_model', @model2, 'R');\n\nis there any way I can serialize the R model which trained using caret or some other libraries instead of RevoScaleR.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Cannot create Azure ML resource",
        "Question_creation_time":1621368566277,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/399949\/cannot-create-azure-ml-resource.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I am trying to create a Machine Learning resource in a resource group where I am a Contributor but I get an error saying:\n\n{\"code\":\"AuthorizationFailed\",\"message\":\"The client 'XXXXXXX' with object id 'XXXXX-XXXXXX_XXXXXX' does not have authorization to perform action 'Microsoft.MachineLearningServices\/register\/action' over scope '\/subscriptions\/XXXXX-XXXX-XXXXXXX' or the scope is invalid. If access was recently granted, please refresh your credentials. (Code: AuthorizationFailed)\"}\n\nI have had access for a while now and I can create other resources like a Azure Databricks Service or VM so I am not sure if this a permissions issue or what I need to change to be able to create a Machine Learning resource.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-19T06:38:42.883Z",
                "Answer_score":0,
                "Answer_body":"What method is you used to create the ML resource? It looks like that not provide correct resource group to create the ML resource.\nAs reference you can read this doc: https:\/\/github.com\/marketplace\/actions\/azure-machine-learning-workspace\nBy the way, when you create ML service, you need to create storage account, app insight, key vault and container registry at same time. So you can also check the Azure policy to make sure these resource have not prevent to be created.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML - Notebook - Jupyter Kernel Error - No Kernel Connecl",
        "Question_creation_time":1595605454123,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/52057\/azure-ml-notebook-jupyter-kernel-error-no-kernel-c.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":0,
        "Question_score":0,
        "Question_body":"In Azure ML i am following the tutorial to execute a notebook and when i open the notebook and have a valid compute (running as well as the green icon) it shows an error 'Jupyter Kernel Error'. On the far right of the screen it says 'No Kernel Connnected'. What is needed to connect the kernel?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-28T02:40:35.287Z",
                "Answer_score":0,
                "Answer_body":"Hi,\nmay I know which tutorial you are mentioning? If you are facing issue with notebooks.azure.com then the most likely scenario is your project is not running. Please navigate back to the project page and run your project before opening the required notebook in a new window which should show all the options to select the kernel and run a cell.\n\nThanks,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-19T06:18:42.667Z",
                "Answer_score":0,
                "Answer_body":"In new ML workspace you need to setup the computing resource to run the jupyter. The resource can be single VM, cluster (available set) or container set. You also can select using GPU or not.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Debugging the Execute Python Scripts model in Azure\u2013ML: Where can I find the print statements?",
        "Question_creation_time":1621349529943,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/399653\/debugging-the-execute-python-scripts-model-in-azur.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"Hi,\n\nI am using Azure Machine Learning \u2013 Designer (drag-n-drop) \u2013\u00a0to train an ML model. While doing so, I require to execute some Python code & hence decided to use the Execute Python Script module available.\n\nWhile writing the script, I added print statements because it would allow for easier debugging. However, I have had no luck in finding a file where the print statements are stored.\n\nI have tried the following solution. On failure of the script, this method (opening 70_driver_log.txt and searching for messages) only shows me the error returned by the Python Interpreter, but it doesn't show me any print statements at all. For example:\n\nSimilarly, on success, no print statements are displayed.\n\nAdditionally, logs > azureml > stdoutlogs .txt is completely empty.\n\nWhat clue am I missing? Any help is appreciated!",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Variable Importance in AutoML Experiment",
        "Question_creation_time":1620845444243,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/393120\/variable-importance-in-automl-experiment.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"We have create a classification experiment using AutoML. We can not find any output related to variable importance, propensity scores, or coefficients. Please tell us how to get this or find it?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-12T23:59:42.687Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nPlease check on the guidance: Use the interpretability package to explain ML models & predictions in Python (preview)\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-machine-learning-interpretability-aml#generate-feature-importance-values-via-remote-runs\n\nIt contains guidance about Explain the entire model behavior (global explanation), Explain an individual prediction (local explanation) and also Generate feature importance values via remote runs\/ local runs\n\nHope this helps.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Designer: Automatically Update AKS Webservice After Training",
        "Question_creation_time":1620652503773,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/389170\/azure-ml-designer-automatically-update-aks-webserv.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"As part of our MLOps flow, we need to retrain a machine learning model using the AML designer, and then update the AKS webservice with the new machine learning model (+ a couple of other supplementary training artifacts), also from the designer.\n\nWe have built an inference pipeline to do this, and are able to run it manually. However, the solution requirements require this process to be automated. We have previously successfully automated this through the python SDK and the akswebservice.update method, but this solution has a hard requirement to use the designer only (custom python code blocks would be allowed, however).\n\nIs there a way, using any Azure services (eg Azure Data Factory, Azure DevOps), that we can kick off a designer real time inference update pipeline immediately after its associated training pipeline finishes executing, in order to get the latest model version into the webservice, without any manual intervention? To be clear though, manual intervention is acceptable to build the initial inference pipeline for version 1, but not on the retraining cycle.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-11T00:03:37.853Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. Currently, you can only use the Azure Machine Learning SDK to automatically update the web service. I'm inquiring from the product team whether there are plans to support this scenario (will share updates accordingly). Hope this helps.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure AutoML via User Interface",
        "Question_creation_time":1621023165310,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/396020\/azure-automl-via-user-interface.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"When we use Azure AutoML via User Interface, what data do they use to calculate the metrics?\nDo they train test split? If so, the metrics return from the test data?\nOr they use the whole data to validate the models. Thus, the metrics are from cross-validation.\nIf they use the whole data set to train, I should do the train-test split and only upload a train data set (I should clean data first). Then deploy the models with the test data to see how accurate the model is.\nIf it is that case, this function is such a useless function.\nI can use Python SDK directly.\nPlease help me to clarify if it is that case. The metrics are only from cross-validation.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-17T11:18:34.47Z",
                "Answer_score":0,
                "Answer_body":"@TheoSun-0585 Thanks for the question. For validation, you have the Validation metrics available when training any AutoML models.\nAbout TEST METRICS, that\u2019s something else.\nYes, we\u2019re almost going to release in PRIVATE PREVIEW (in the upcoming weeks) for a way in AutoML (using Python SDK and alternatively also the UI) to provide a TEST DATASET (new data) so you will easily test the model and get TEST METRICS without needing to deploy the model or test it by code in Python.\n\nNote that you can today TEST any AutoML model today in a Python Jupyter notebook but instantiating the .pkl model and then making predictions and calculating the test metrics in your notebook, without needing to deploy the model (using REST API to try it): Example notebook with \u201cyour\u201d TEST METRICS: Easy-AutoML-MLOps\/automl-remote-compute-run-safe-driver-classifier.ipynb at master \u00b7 CESARDELATORRE\/Easy-AutoML-MLOps (github.com) (Check section \u201cCalculate the ROC AUC with probabilities vs. the Test Dataset\u201d).\n\nBut with the PRIVATE PREVIEW of TEST DATASET SUPPORT, you\u2019ll be able to provide the TEST DATASET when creating the experiment, too. Or test an already trained model on demand in the UI or SDK, making it simpler.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to configure the runs combine pipeline and hyperdrive",
        "Question_creation_time":1619990039720,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/379819\/how-to-configure-the-runs-combine-pipeline-and-hyp.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hi there,\n\nI have a pipeline that is composed of \"data prep\" and \"training\" steps and I need to test different hyperparameters on the training step. I cannot figure out how I should use hyperdrive config within the pipeline.\n\n\n\n\nfrom azureml.core import Environment\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.core.runconfig import RunConfiguration\n\nCreate a Python environment for the experiment\n\ndiabetes_env = Environment(\"diabetes-pipeline-env\")\ndiabetes_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\ndiabetes_env.docker.enabled = True # Use a docker container\n\nCreate a set of package dependencies\n\ndiabetes_packages = CondaDependencies.create(conda_packages=['scikit-learn','ipykernel','matplotlib','pandas','pip'],\npip_packages=['azureml-defaults','azureml-dataprep[pandas]','pyarrow'])\n\nAdd the dependencies to the environment\n\ndiabetes_env.python.conda_dependencies = diabetes_packages\n\nRegister the environment\n\n\n\ndiabetes_env.register(workspace=ws)\nregistered_env = Environment.get(ws, 'diabetes-pipeline-env')\n\nCreate a new runconfig object for the pipeline\n\nrun_config = RunConfiguration()\n\nUse the compute you created above.\n\n\n\nrun_config.target = ComputerTarget_Crea\n\nAssign the environment to the run configuration\n\nrun_config.environment = registered_env\n\nprint (\"Run configuration created.\")\n\n\n\nGet the training dataset\n\ndiabetes_ds = ws.datasets.get(\"diabetes dataset\")\n\nCreate a PipelineData (temporary Data Reference) for the model folder\n\nprepped_data_folder = PipelineData(\"prepped_data_folder\", datastore=ws.get_default_datastore())\n\n\n\n\nCreate a script config\n\nscript_config = ScriptRunConfig(source_directory=experiment_folder,\nscript='diabetes_training.py',\n# Add non-hyperparameter arguments -in this case, the training dataset\narguments = ['--input-data', diabetes_ds.as_named_input('training_data')],\nenvironment=registered_env,\ncompute_target = ComputerTarget_Crea)\n\nSample a range of parameter values\n\nparams = GridParameterSampling(\n{\n# Hyperdrive will try 6 combinations, adding these as script arguments\n'--learning_rate': choice(0.01, 0.1, 1.0),\n'--n_estimators' : choice(10, 100)\n}\n)\n\n\n\n\n\n\n\nhyperdrive = HyperDriveConfig(run_config=script_config,\nhyperparameter_sampling=params,\npolicy=None, # No early stopping policy\nprimary_metric_name='AUC', # Find the highest AUC metric\nprimary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\nmax_total_runs=6, # Restict the experiment to 6 iterations\nmax_concurrent_runs=2) # Run up to 2 iterations in parallel\n\n\n\n\n\nStep 1, Run the data prep script\n\nprep_step = PythonScriptStep(name = \"Prepare Data\",\nsource_directory = experiment_folder,\nscript_name = \"prep_diabetes.py\",\narguments = ['--input-data', diabetes_ds.as_named_input('raw_data'),\n'--prepped-data', prepped_data_folder],\noutputs=[prepped_data_folder],\ncompute_target = ComputerTarget_Crea,\nrunconfig = run_config,\nallow_reuse = True)\n\nStep 2, run the training script\n\ntrain_step = PythonScriptStep(name = \"Train and Register Model\",\nsource_directory = experiment_folder,\nscript_name = \"train_diabetes.py\",\narguments = ['--training-folder', prepped_data_folder],\ninputs=[prepped_data_folder],\ncompute_target = ComputerTarget_Crea,\nrunconfig = hyperdrive,\nallow_reuse = True)\n\n\n\nError I get\n\nExpected a StepRun object but received <class 'azureml.core.run.Run'> instead.\nThis usually indicates a package conflict with one of the dependencies of azureml-core or azureml-pipeline-core.\nPlease check for package conflicts in your python environment\n\nTypeError Traceback (most recent call last)\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\pipeline\\core\\run.py in wait_for_completion(self, show_output, timeout_seconds, raise_on_error)\n293 try:\n--> 294 step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,\n295 raise_on_error=raise_on_error)\n\nTypeError: wait_for_completion() got an unexpected keyword argument 'timeout_seconds'\n\nDuring handling of the above exception, another exception occurred:\n\nActivityFailedException Traceback (most recent call last)\n<ipython-input-29-e1c5033d6731> in <module>\n13 print(\"Pipeline submitted for execution.\")\n14 RunDetails(pipeline_run).show()\n---> 15 pipeline_run.wait_for_completion(show_output=True)\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\pipeline\\core\\run.py in wait_for_completion(self, show_output, timeout_seconds, raise_on_error)\n307 'azureml-core or azureml-pipeline-core.\\n' +\n308 'Please check for package conflicts in your python environment')\n--> 309 step_run.wait_for_completion(raise_on_error=raise_on_error)\n310 else:\n311 # Different error than the run rehydration issue\n\n~\\anaconda3\\lib\\site-packages\\azureml\\core\\run.py in wait_for_completion(self, show_output, wait_post_processing, raise_on_error)\n819\n820 if raise_on_error:\n--> 821 raise ActivityFailedException(error_details=json.dumps(error, indent=4))\n822\n823 return final_details\n\nActivityFailedException: ActivityFailedException:\nMessage: Activity Failed:\n{\n\"error\": {\n\"code\": \"UserError\",\n\"message\": \"Unexpected character encountered while parsing value: <. Path '', line 0, position 0.\",\n\"messageParameters\": {},\n\"details\": []\n},\n\"time\": \"0001-01-01T00:00:00.000Z\"\n}\nInnerException None\nErrorResponse\n{\n\"error\": {\n\"message\": \"Activity Failed:\\n{\\n \\\"error\\\": {\\n \\\"code\\\": \\\"UserError\\\",\\n \\\"message\\\": \\\"Unexpected character encountered while parsing value: <. Path '', line 0, position 0.\\\",\\n \\\"messageParameters\\\": {},\\n \\\"details\\\": []\\n },\\n \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n}\n}",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-04T13:19:55.287Z",
                "Answer_score":1,
                "Answer_body":"@MohsenSichani Thanks for the question. Please follow the sample that demonstrate the use of HyperDriveStep in AML Pipeline.\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/intro-to-pipelines\/aml-pipelines-parameter-tuning-with-hyperdrive.ipynb",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"In Azure Machine Learning Attach Compute - what is the format of private key?",
        "Question_creation_time":1621000694820,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/395761\/in-azure-machine-learning-attach-compute-what-is-t.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hello,\n\nI am trying to attach an Azure Data Science Virtual Machine in my workspace.\nI have created the Azure VM previously and had the wizard generate public\/private key for me. During creation I was prompted to download the private key and I have that on my machine. I am also able to SSH into the machine successfully by passing the path to the private key on my machine.\n\nHowever, during the wizard to attach this machine to my machine workspace I am not sure what 'value' I actually need to put into the private key box.\n\nFurthermore, during the creation of the VM - I was never asked to input a passphrase.\n\nShould I create a new key once I SSH into the VM?\nEven with that - what is the value one pastes into this box?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-15T01:14:21.677Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. You need to paste the private key that you downloaded. Passphrase is optional and only needed if you initially set it up while creating an ssh key pair. Hope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",",
        "Question_creation_time":1619621454417,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/375577\/submitted-script-failed-with-a-non-zero-exit-code.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hi All,\nI am trying to creating batch inference of my pretrained churn classification model. I was following this github of iris batch inference [1]: https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/machine-learning-pipelines\/parallel-run\/tabular-dataset-inference-iris.ipynb .\nBut I am getting error , please help me how can I fix this error.\n\nHere my code:\n\n\n\n\n\n\n\n\n\nHere my errors:\n\n\n\n ========================================================================================================================\n 2\n . Please ignore this if the GPUs don't utilize NVIDIA\u00ae NVLink\u00ae switches.\n 2021-04-28T12:53:39Z Starting output-watcher...\n 2021-04-28T12:53:39Z IsDedicatedCompute == False, starting polling for Low-Pri Preemption\n 2021-04-28T12:53:39Z Executing 'Copy ACR Details file' on 10.0.0.4\n 2021-04-28T12:53:39Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n >>>   \n >>>   \n Login Succeeded\n Using default tag: latest\n latest: Pulling from azureml\/azureml_af590fdfaae8ba3ead1eba5ea12b0fb3\n 4007a89234b4: Pulling fs layer\n 5dfa26c6b9c9: Pulling fs layer\n 0ba7bf18aa40: Pulling fs layer\n 4c6ec688ebe3: Pulling fs layer\n 574f361512d6: Pulling fs layer\n db4d1e2d7079: Pulling fs layer\n e544ee0f522d: Pulling fs layer\n c655136086be: Pulling fs layer\n 2ec37f44090c: Pulling fs layer\n 5fba3bd4a2c4: Pulling fs layer\n 7e0ea9d0a1ab: Pulling fs layer\n da005f826951: Pulling fs layer\n 6e842608b724: Pulling fs layer\n 6b1a4187f1d0: Pulling fs layer\n db4d1e2d7079: Waiting\n c763bae43813: Pulling fs layer\n 490d7c37a7d7: Pulling fs layer\n 791bb1082f38: Pulling fs layer\n e544ee0f522d: Waiting\n e863af755720: Pulling fs layer\n c655136086be: Waiting\n 4c6ec688ebe3: Waiting\n 0cb6e30b3f1c: Pulling fs layer\n 88468e3f4c2c: Pulling fs layer\n 77d6ac8c0bf7: Pulling fs layer\n 574f361512d6: Waiting\n 2ec37f44090c: Waiting\n da005f826951: Waiting\n 5fba3bd4a2c4: Waiting\n 6e842608b724: Waiting\n 6b1a4187f1d0: Waiting\n c763bae43813: Waiting\n 490d7c37a7d7: Waiting\n 791bb1082f38: Waiting\n e863af755720: Waiting\n 0cb6e30b3f1c: Waiting\n 88468e3f4c2c: Waiting\n 77d6ac8c0bf7: Waiting\n 7e0ea9d0a1ab: Waiting\n 0ba7bf18aa40: Verifying Checksum\n 0ba7bf18aa40: Download complete\n 5dfa26c6b9c9: Verifying Checksum\n 5dfa26c6b9c9: Download complete\n 4c6ec688ebe3: Verifying Checksum\n 4c6ec688ebe3: Download complete\n 4007a89234b4: Download complete\n db4d1e2d7079: Verifying Checksum\n db4d1e2d7079: Download complete\n e544ee0f522d: Verifying Checksum\n e544ee0f522d: Download complete\n 574f361512d6: Verifying Checksum\n 574f361512d6: Download complete\n 4007a89234b4: Pull complete\n 5dfa26c6b9c9: Pull complete\n 0ba7bf18aa40: Pull complete\n 4c6ec688ebe3: Pull complete\n 5fba3bd4a2c4: Download complete\n c655136086be: Verifying Checksum\n c655136086be: Download complete\n 7e0ea9d0a1ab: Verifying Checksum\n 7e0ea9d0a1ab: Download complete\n da005f826951: Verifying Checksum\n da005f826951: Download complete\n 6e842608b724: Download complete\n 6b1a4187f1d0: Download complete\n c763bae43813: Verifying Checksum\n c763bae43813: Download complete\n 2ec37f44090c: Verifying Checksum\n 2ec37f44090c: Download complete\n 490d7c37a7d7: Verifying Checksum\n 490d7c37a7d7: Download complete\n 0cb6e30b3f1c: Verifying Checksum\n 0cb6e30b3f1c: Download complete\n e863af755720: Verifying Checksum\n e863af755720: Download complete\n 77d6ac8c0bf7: Verifying Checksum\n 77d6ac8c0bf7: Download complete\n 88468e3f4c2c: Verifying Checksum\n 88468e3f4c2c: Download complete\n 574f361512d6: Pull complete\n db4d1e2d7079: Pull complete\n e544ee0f522d: Pull complete\n 791bb1082f38: Verifying Checksum\n 791bb1082f38: Download complete\n c655136086be: Pull complete\n 2ec37f44090c: Pull complete\n 5fba3bd4a2c4: Pull complete\n 7e0ea9d0a1ab: Pull complete\n da005f826951: Pull complete\n 6e842608b724: Pull complete\n 6b1a4187f1d0: Pull complete\n c763bae43813: Pull complete\n 490d7c37a7d7: Pull complete\n    \n Streaming azureml-logs\/65_job_prep-tvmps_287cfab3497943a39d90c089311555c3223ca350d504acc72af6aceb3d957ba3_p.txt\n ===============================================================================================================\n [2021-04-28T12:54:05.020376] Entering job preparation.\n [2021-04-28T12:54:08.337333] Starting job preparation.\n [2021-04-28T12:54:08.337375] Extracting the control code.\n [2021-04-28T12:54:08.365360] fetching and extracting the control code on master node.\n [2021-04-28T12:54:08.365417] Starting extract_project.\n [2021-04-28T12:54:08.365467] Starting to extract zip file.\n [2021-04-28T12:54:09.302078] Finished extracting zip file.\n [2021-04-28T12:54:09.804262] Using urllib.request Python 3.0 or later\n [2021-04-28T12:54:09.804327] Start fetching snapshots.\n [2021-04-28T12:54:09.804373] Start fetching snapshot.\n [2021-04-28T12:54:09.804391] Retrieving project from snapshot: f4a38de4-3230-4038-ac4b-cde33bdd63e5\n Starting the daemon thread to refresh tokens in background for process with pid = 51\n [2021-04-28T12:54:10.714200] Finished fetching snapshot.\n [2021-04-28T12:54:10.714233] Start fetching snapshot.\n [2021-04-28T12:54:10.714251] Retrieving project from snapshot: b71de588-0f3c-44ae-b144-ea24a905546e\n [2021-04-28T12:54:24.343681] Finished fetching snapshot.\n [2021-04-28T12:54:24.343714] Finished fetching snapshots.\n [2021-04-28T12:54:24.343728] Finished extract_project.\n [2021-04-28T12:54:24.360941] Finished fetching and extracting the control code.\n [2021-04-28T12:54:24.364330] downloadDataStore - Download from datastores if requested.\n [2021-04-28T12:54:24.365371] Start run_history_prep.\n [2021-04-28T12:54:24.436823] Entering context manager injector.\n Acquired lockfile \/tmp\/a1c4fded-7336-4024-8c9e-fed19f5d1b37-datastore.lock to downloading input data references\n [2021-04-28T12:54:24.903804] downloadDataStore completed\n [2021-04-28T12:54:24.906597] Job preparation is complete.\n    \n Streaming azureml-logs\/70_driver_log.txt\n ========================================\n 2021\/04\/28 12:54:26 Starting App Insight Logger for task:  runTaskLet\n 2021\/04\/28 12:54:26 Attempt 1 of http call to http:\/\/10.0.0.4:16384\/sendlogstoartifacts\/info\n 2021\/04\/28 12:54:26 Attempt 1 of http call to http:\/\/10.0.0.4:16384\/sendlogstoartifacts\/status\n [2021-04-28T12:54:27.564276] Entering context manager injector.\n [context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', '\n 2021\/04\/28 12:54:31 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n Stopped: false\n OriginalData: 1\n FilteredData: 0.\n    \n Streaming azureml-logs\/75_job_post-tvmps_287cfab3497943a39d90c089311555c3223ca350d504acc72af6aceb3d957ba3_p.txt\n ===============================================================================================================\n [2021-04-28T13:02:20.275818] Entering job release\n [2021-04-28T13:02:21.348190] Starting job release\n [2021-04-28T13:02:21.348739] Logging experiment finalizing status in history service.\n Starting the daemon thread to refresh tokens in background for process with pid = 1369\n [2021-04-28T13:02:21.349418] job release stage : upload_datastore starting...\n [2021-04-28T13:02:21.349812] job release stage : start importing azureml.history._tracking in run_history_release.\n [2021-04-28T13:02:21.352029] job release stage : copy_batchai_cached_logs starting...\n [2021-04-28T13:02:21.352142] job release stage : execute_job_release starting...\n [2021-04-28T13:02:21.357651] job release stage : copy_batchai_cached_logs completed...\n [2021-04-28T13:02:21.358513] Entering context manager injector.\n [2021-04-28T13:02:21.372410] job release stage : upload_datastore completed...\n [2021-04-28T13:02:21.595288] job release stage : execute_job_release completed...\n [2021-04-28T13:02:21.628735] job release stage : send_run_telemetry starting...\n [2021-04-28T13:02:21.849387] get vm size and vm region successfully.\n [2021-04-28T13:02:22.175695] get compute meta data successfully.\n [2021-04-28T13:02:22.444070] post artifact meta request successfully.\n [2021-04-28T13:02:22.471466] upload compute record artifact successfully.\n [2021-04-28T13:02:22.471531] job release stage : send_run_telemetry completed...\n [2021-04-28T13:02:22.471747] Job release is complete\n    \n StepRun(batch-score) Execution Summary\n =======================================\n StepRun( batch-score ) Status: Failed\n ---------------------------------------------------------------------------\n ActivityFailedException                   Traceback (most recent call last)\n <ipython-input-30-49d7d34a142d> in <module>\n       3 # Run the pipeline as an experiment\n       4 pipeline_run = Experiment(ws, 'batc-prediction_pipeline').submit(pipeline)\n ----> 5 pipeline_run.wait_for_completion(show_output=True)\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/run.py in wait_for_completion(self, show_output, timeout_seconds, raise_on_error)\n     293                             try:\n     294                                 step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,\n --> 295                                                              raise_on_error=raise_on_error)\n     296                             except TypeError as e:\n     297                                 # If there are package conflicts in the user's environment, the run rehydration\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/run.py in wait_for_completion(self, show_output, timeout_seconds, raise_on_error)\n     735             try:\n     736                 return self._stream_run_output(timeout_seconds=timeout_seconds,\n --> 737                                                raise_on_error=raise_on_error)\n     738             except KeyboardInterrupt:\n     739                 error_message = \"The output streaming for the run interrupted.\\n\" \\\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/run.py in _stream_run_output(self, timeout_seconds, raise_on_error)\n     823             print(json.dumps(error, indent=4))\n     824         if error and raise_on_error:\n --> 825             raise ActivityFailedException(error_details=json.dumps(error, indent=4))\n     826 \n     827         print(final_details)\n    \n ActivityFailedException: ActivityFailedException:\n  Message: Activity Failed:\n {\n     \"error\": {\n         \"code\": \"UserError\",\n         \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n         \"messageFormat\": \"{Message}\",\n         \"messageParameters\": {\n             \"Message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\"\n         },\n         \"details\": [],\n         \"innerError\": {\n             \"code\": \"UserTrainingScriptFailed\"\n         }\n     },\n     \"correlation\": {\n         \"operation\": null,\n         \"request\": \"6833f86b6a0c0af1\"\n     },\n     \"environment\": \"eastus\",\n     \"location\": \"eastus\",\n     \"time\": \"2021-04-28T13:02:41.490064Z\",\n     \"componentName\": \"execution-worker\"\n }\n  InnerException None\n  ErrorResponse \n {\n     \"error\": {\n         \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\\n\\\\tReason: Job failed with non-zero exit Code\\\",\\n        \\\"messageFormat\\\": \\\"{Message}\\\",\\n        \\\"messageParameters\\\": {\\n            \\\"Message\\\": \\\"AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\\n\\\\tReason: Job failed with non-zero exit Code\\\"\\n        },\\n        \\\"details\\\": [],\\n        \\\"innerError\\\": {\\n            \\\"code\\\": \\\"UserTrainingScriptFailed\\\"\\n        }\\n    },\\n    \\\"correlation\\\": {\\n        \\\"operation\\\": null,\\n        \\\"request\\\": \\\"6833f86b6a0c0af1\\\"\\n    },\\n    \\\"environment\\\": \\\"eastus\\\",\\n    \\\"location\\\": \\\"eastus\\\",\\n    \\\"time\\\": \\\"2021-04-28T13:02:41.490064Z\\\",\\n    \\\"componentName\\\": \\\"execution-worker\\\"\\n}\"\n     }\n }\n    \n \u200b",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure ML Designer - Replace existing real-time inference endpoint error",
        "Question_creation_time":1613636477313,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/278158\/azure-ml-designer-replace-existing-real-time-infer.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":7,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"Hi,\n\nWhen replacing an existing, healthy Azure ML End-point through the Azure ML Designer, I get the following error:\n\n Failed on Preparing to deploy. Details: AzureML service API error. Error calling ServicePatch: {\"code\":\"BadRequest\",\"statusCode\":400,\"message\":\"The request is invalid.\",\"details\":[{\"code\":\"EmptyOrInvalidParameter\",\"message\":\"Cannot set both number of replicas and auto scale settings in the same request\"}],\"correlation\":{\"RequestId\":\"14982e6e-dc63-4732-964b-55027243dac3\"}}\n\nThe current endpoint I'm trying to replace was created a few days ago. It has:\n\nAutoscale enabled == true\n\n\nMin\/Max replicas == 1\/10\n\nThe deploy menu does not contain an option to change or set these values. Therefore, I do not understand why the request fails.\n\nCould you help me fix this issue?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Help for Azure ML Studio experiment mapping",
        "Question_creation_time":1620716372030,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/390316\/help-for-azure-ml-studio-experiment-mapping.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I am learning Azure ML (Studio) and please help me for below scenarios,\nI have a bank customer data having column labelled as customer age, family members (1,2,3 &4), credit card (Yes \/no) Personal Loan (Yes \/no), education (1. Undergrad 2. Graduate 3. Advanced\/professional).\n\nHow to filter age column and find number of customers less than 45 years in % of total number of customers?\n\n\nAlso need % customers who are having credit card as well Personal loan?\n\n\nwhich education category of customers are more prone to subscribe to personal loan?\n\n\nHow to do visual analysis?\n\n\nHow to calculate correlation between 2 columns?\n\nThanks in advance for your guidance. and incase tag to wrong group please guide to appropriate group",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-11T23:07:34.347Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. I am assuming you are using Azure ML Studio Designer to work on this scenario. Please review response below:\n\n\n\n\nHow to filter age column and find number of customers less than 45 years in % of total number of customers? As part of your data preparations step, you can use available data transformation modules such as apply sql transformation and apply math operation to perform data transformations.\n\nAlso need % customers who are having credit card as well Personal loan? Similar to 1 above.\n\nWhich education category of customers are more prone to subscribe to personal loan? This seems to be a multi-classification problem where you'd want to predict several categories. AML Studio has the following modules and algorithms for predicting classes. For future reference, this document helps you identify which algorithm to select based on the ML scenario.\n\nHow to do visual analysis? With Azure ML Designer, you can Right Click on a module and select Visualize to visualize dataset output or results.\n\nHow to calculate correlation between 2 columns? You can use Filter Based Feature Selection to identify the columns in your input dataset that have the greatest predictive power. The module includes correlation methods such as Pearson correlation and Chi-Squared.\n\n\n\n\nAlso, here are some useful resources to help get you started:\n\nAzure Machine Learning Documentation.\n\n\nSample tutorials are available in Designer (newer drag and drop interface. Click Designer, select More Samples) and Classic (older drag and drop interface, via Azure AI Gallery, although some modules may not be available in designer, but a great starting point as well).\n\nHope this helps!",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Pre-existing Compute Resource necessary for running a scheduled ML pipeline?",
        "Question_creation_time":1620803656847,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/392165\/pre-existing-compute-resource-necessary-for-runnin.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi fellows,\nI have been exploring Azure ML Pipeline. I am referring to this notebook for the below code:\n\nHere is a small snippet from a MS Repo:\ntrain_step = PythonScriptStep(name = \"Prepare Data\",\nsource_directory = experiment_folder,\nscript_name = \"prep_diabetes.py\",\narguments = ['--input-data', diabetes_ds.as_named_input('raw_data'),\n'--prepped-data', prepped_data_folder],\noutputs=[prepped_data_folder],\ncompute_target = pipeline_cluster,\nrunconfig = pipeline_run_config,\nallow_reuse = True)\n\nThis suggests that while defining a pipeline, we must provide it a compute resource. This obviously makes sense, since specific compute might be required for a specific step.\n\nBut do we need to have this compute resource up and running always, so that whenever a pipeline is triggered, it can find the compute resource?\n\nAlso, i figured we can probably keep a cluster with Zero minimum nodes, in which cases cluster is resized whenever pipeline is triggered. But i think there is a minimal cost incurrent in probably container registry regularly in such a setup. Is this the recommended way to deploy ML pipelines or some more efficient approach is possible?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-13T10:02:30.86Z",
                "Answer_score":0,
                "Answer_body":"@HimanshuGautam-0592 Thanks for the question. AmlCompute clusters are designed to scale dynamically based on your workload. The cluster can be scaled up to the maximum number of nodes you configure. As each run completes, the cluster will release nodes and scale to your configured minimum node count.\n\nTo avoid charges when no jobs are running, set the minimum nodes to 0. This setting allows Azure Machine Learning to de-allocate the nodes when they aren't in use. Any value larger than 0 will keep that number of nodes running, even if they are not in use.\n\n\n\n\nAnother way to save money on compute resources is Azure Reserved VM Instance. amlcompute supports reserved instances out of the box. These reservations can be used across azure compute resources (vmss\/batch\/vm) and AzureML compute.\n\nCheck out this article to learn more about planning and managing costs : https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-plan-manage-cost",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Images are not shown in AML notebooks output cell",
        "Question_creation_time":1620103839040,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/381476\/images-are-not-shown-in-aml-notebooks-output-cell.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"The matplotlib \/ raster libraries show method doesn't show the images plotted in notebook cell output.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"AttributeError: \/anaconda\/envs\/azureml_py36\/lib\/libxgboost.so: undefined symbol: XGBoosterUnserializeFromBuffer",
        "Question_creation_time":1620076989343,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/381203\/attributeerror-anacondaenvsazureml-py36liblibxgboo.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I am following automated ML guideline.:\n\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/automated-machine-learning\/regression\/auto-ml-regression.ipynb\n\nI created development environment according to the documentation. As recommended, I am using version 1.27.0 of the Azure ML SDK.\n\nAfter remote_run completed, I got the error for the following command \"best_run, fitted_model = remote_run.get_output()\"\n\nI would appreciate if you could help me.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-05T03:08:05.86Z",
                "Answer_score":0,
                "Answer_body":"@CagatayTopcu-5553 Thanks for the question. Can you please try manually downgrade xgboost with: pip install xgboost==0.90 or Create a new Compute Instance which should have xgboost==0.90.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Experiment on Azure Machine Learning services is not starting.",
        "Question_creation_time":1620678944347,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/389811\/experiment-on-azure-machine-learning-services-is-n.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I run an experiment in the azure ml service using an associated VM, but the experiment status is as follows:\n\nJob runstatus is NotStarted\n\nID execution 75ff42c9-2fbd-48c2-beec-b72aa38f1d00",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-11T01:51:49.837Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us. I just check on my side and there is no problem for me.\n\nAre you referring below two guidance to train and deploy your pipeline?\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy\n\nIs there any guidance you are following so that we can help investigate more?\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-11T14:46:42.987Z",
                "Answer_score":0,
                "Answer_body":"Hi,\nI'm not using the designer or Azure ML Studio, I'm building the pipeline trough code in python.\n\nI'm followig this tutorial:\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/training\/train-on-remote-vm\/train-on-remote-vm.ipynb\n\nI have a Remote VM ( (ubuntu 18.04)) which has a VPN connected, I'm trying to use this VM to execute a script but In the pipeline it does not initiate.\n\n\n\n\n\n\nIn addition to this, any of the experiment I have sent were completed. In the image we can clearly see that it says duration 16 h until i have to cancel the experiment. whereas the script only have to print a string for testing",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"azure ml pipeline fails at sql transform task",
        "Question_creation_time":1620697549357,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/390003\/azure-ml-pipeline-fails-giving-no-error.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"Hi, I'm using Azure ML Designer to run a pipeline. The pipeline performs a few steps and then it cancels the work throwing an error message with no further details.\n\nIf I re-submit the pipeline it completes the previously failed step but fails on the next step. If I re-submit the same thing happens (completes previously failed step to then fail the next step)... until it gets stuck in a specific sql transform step (see log below)\n\n\n\n\nHere is a sequence of run ids related with the issue:\nd33d23a2-2e60-4198-a6b6-f47e6e27ef4e\n57e04c1e-73e8-4ddf-91a8-c407cd1ad5ef\nad7dc826-6549-4eb3-9536-9a801d8e8c0b\ne6623f6f-b7b9-4f19-9501-c8c28f53ab23\n\nIt may be due to the way my pipeline is built but seems like JOIN, SQL Transform and SELECT Column operations tend to fail the most.\n\nWould much appreciate any help on this.\n\n 2021\/05\/11 01:57:24 Starting App Insight Logger for task:  runTaskLet\n 2021\/05\/11 01:57:24 Attempt 1 of http call to http:\/\/10.0.0.6:16384\/sendlogstoartifacts\/info\n 2021\/05\/11 01:57:24 Attempt 1 of http call to http:\/\/10.0.0.6:16384\/sendlogstoartifacts\/status\n [2021-05-11T01:57:24.912444] Entering context manager injector.\n [context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['urldecode_invoker.py', 'python', '-m', 'azureml.designer.modules.datatransform.invoker', 'ApplySqlTransModule', '--dataset', 'DatasetOutputConfig:Result_dataset', '--t1=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr', '--t2=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy', '--t3=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji', '--sqlquery=%22select+b.*%2cc.*%0d%0afrom+(%0d%0a++++select+a.customer_id%2c+a.sku_id%0d%0a++++from+(%0d%0a++++++++select+*+from+t1+cross+join+t2%0d%0a++++)+a%0d%0a++++where+exists+(%0d%0a++++++++select+t3.top_skus%0d%0a++++++++from+t3%0d%0a++++++++where+t3.sku_id+%3d+a.sku_id%0d%0a++++)%0d%0a)+b%0d%0ainner+join+(%0d%0a++++select+distinct+sku_id%2c+top_skus%0d%0a++++from+t3%0d%0a)+c%0d%0aon+c.sku_id+%3d+b.sku_id%22'])\n Script type = None\n [2021-05-11T01:57:26.142183] Entering Run History Context Manager.\n [2021-05-11T01:57:26.734197] Current directory: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/mounts\/workspaceblobstore\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\n [2021-05-11T01:57:26.734493] Preparing to call script [urldecode_invoker.py] with arguments:['python', '-m', 'azureml.designer.modules.datatransform.invoker', 'ApplySqlTransModule', '--dataset', '$Result_dataset', '--t1=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr', '--t2=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy', '--t3=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji', '--sqlquery=%22select+b.*%2cc.*%0d%0afrom+(%0d%0a++++select+a.customer_id%2c+a.sku_id%0d%0a++++from+(%0d%0a++++++++select+*+from+t1+cross+join+t2%0d%0a++++)+a%0d%0a++++where+exists+(%0d%0a++++++++select+t3.top_skus%0d%0a++++++++from+t3%0d%0a++++++++where+t3.sku_id+%3d+a.sku_id%0d%0a++++)%0d%0a)+b%0d%0ainner+join+(%0d%0a++++select+distinct+sku_id%2c+top_skus%0d%0a++++from+t3%0d%0a)+c%0d%0aon+c.sku_id+%3d+b.sku_id%22']\n [2021-05-11T01:57:26.734551] After variable expansion, calling script [urldecode_invoker.py] with arguments:['python', '-m', 'azureml.designer.modules.datatransform.invoker', 'ApplySqlTransModule', '--dataset', '\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpnbybe4mu', '--t1=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr', '--t2=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy', '--t3=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji', '--sqlquery=%22select+b.*%2cc.*%0d%0afrom+(%0d%0a++++select+a.customer_id%2c+a.sku_id%0d%0a++++from+(%0d%0a++++++++select+*+from+t1+cross+join+t2%0d%0a++++)+a%0d%0a++++where+exists+(%0d%0a++++++++select+t3.top_skus%0d%0a++++++++from+t3%0d%0a++++++++where+t3.sku_id+%3d+a.sku_id%0d%0a++++)%0d%0a)+b%0d%0ainner+join+(%0d%0a++++select+distinct+sku_id%2c+top_skus%0d%0a++++from+t3%0d%0a)+c%0d%0aon+c.sku_id+%3d+b.sku_id%22']\n    \n Session_id = 4b5b4c29-cfda-4ab6-a715-47fee287c468\n Invoking module by urldecode_invoker 0.0.8.\n    \n Module type: custom module.\n    \n Using runpy to invoke module 'azureml.designer.modules.datatransform.invoker'.\n    \n \/azureml-envs\/azureml_7c975cabc8bb1dc19c3de94457d707fd\/lib\/python3.6\/site-packages\/azureml\/designer\/modules\/datatransform\/tools\/dataframe_utils.py:2: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n   from pandas.util.testing import assert_frame_equal\n 2021-05-11 01:57:27,324 [             invoker] [    INFO] .[main] Start custom modules\n 2021-05-11 01:57:27,337 [             invoker] [    INFO] .[main] Module version: 0.0.74\n 2021-05-11 01:57:27,344 [             invoker] [    INFO] .[main] args: azureml.designer.modules.datatransform.invoker, ApplySqlTransModule, --dataset, \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpnbybe4mu, --t1=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr, --t2=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy, --t3=\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji, --sqlquery=select b.*,c.*\n from (\n     select a.customer_id, a.sku_id\n     from (\n         select * from t1 cross join t2\n     ) a\n     where exists (\n         select t3.top_skus\n         from t3\n         where t3.sku_id = a.sku_id\n     )\n ) b\n inner join (\n     select distinct sku_id, top_skus\n     from t3\n ) c\n on c.sku_id = b.sku_id\n 2021-05-11 01:57:27,352 [             invoker] [    INFO] .[main] \"transform_module_class_name\": ApplySqlTransModule\n 2021-05-11 01:57:27,444 [         module_base] [    INFO] ...[get_arg_parser] Construct arg parser\n 2021-05-11 01:57:27,460 [         module_base] [    INFO] ...[get_arg_parser] arg: t1\n 2021-05-11 01:57:27,468 [         module_base] [    INFO] ...[get_arg_parser] arg: t2\n 2021-05-11 01:57:27,476 [         module_base] [    INFO] ...[get_arg_parser] arg: t3\n 2021-05-11 01:57:27,484 [         module_base] [    INFO] ...[get_arg_parser] arg: dataset\n 2021-05-11 01:57:27,492 [         module_base] [    INFO] ...[get_arg_parser] arg: sqlquery\n 2021-05-11 01:57:27,500 [         module_base] [    INFO] ..[parse_and_insert_args] invoker args:\n  module_classname = ApplySqlTransModule\n  t1 = \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr\n  t2 = \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy\n  t3 = \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji\n  dataset = \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpnbybe4mu\n  sqlquery = select b.*,c.*\n from (\n     select a.customer_id, a.sku_id\n     from (\n         select * from t1 cross join t2\n     ) a\n     where exists (\n         select t3.top_skus\n         from t3\n         where t3.sku_id = a.sku_id\n     )\n ) b\n inner join (\n     select distinct sku_id, top_skus\n     from t3\n ) c\n on c.sku_id = b.sku_id\n    \n 2021-05-11 01:57:27,508 [             invoker] [    INFO] .[main] start to run custom module: ApplySqlTransModule\n 2021-05-11 01:57:27,516 [apply_sql_trans_module] [    INFO] ...[run] Construct SQLite Server\n 2021-05-11 01:57:27,530 [    module_parameter] [    INFO] ......[data] Read data from \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpmflqzlpr\n 2021-05-11 01:57:29,215 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t1 with only column names\n 2021-05-11 01:57:29,227 [    module_parameter] [    INFO] ......[data] Read data from \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpl9h5snzy\n 2021\/05\/11 01:57:29 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n Stopped: false\n OriginalData: 1\n FilteredData: 0.\n 2021-05-11 01:57:30,093 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t2 with only column names\n 2021-05-11 01:57:30,106 [    module_parameter] [    INFO] ......[data] Read data from \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/test\/azureml\/e5e84dde-4b32-4ea3-9965-adc71f7ab0f6\/wd\/tmpuhf3n5ji\n 2021-05-11 01:57:30,876 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t3 with only column names\n 2021-05-11 01:57:30,888 [apply_sql_trans_module] [    INFO] ...[run] Read SQL script query\n 2021-05-11 01:57:30,895 [apply_sql_trans_module] [    INFO] ...[run] Validate SQL script query\n 2021-05-11 01:57:30,912 [apply_sql_trans_module] [    INFO] ...[run] Insert data to SQLite Server\n 2021-05-11 01:57:30,919 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t1\n 2021-05-11 01:57:30,930 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t2\n 2021-05-11 01:57:30,970 [apply_sql_trans_module] [    INFO] ....[_transform_df_to_sql] Insert t3\n 2021-05-11 01:57:31,053 [apply_sql_trans_module] [    INFO] ...[run] Generate SQL query result from SQLite Server",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-11T13:29:57.13Z",
                "Answer_score":1,
                "Answer_body":"Found the problem.\n\nThere was a task failing but due to the size of the canvas I wasn't able to spot it at first (working late hours didn't help also).\n\nHowever it certainly didn't help the fact that the error message didn't provide any info regarding which task failed, so maybe the AML team would like to add more descriptive messages in cases like this one.\n\nthanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Receive error GraphDatasetNotFound: Request failed with status code 400 when submitting pipeline",
        "Question_creation_time":1619957038450,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/379678\/receive-error-graphdatasetnotfound-request-failed.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":3,
        "Question_comment_count":3,
        "Question_follower_count":20,
        "Question_score":4,
        "Question_body":"I am running through the tutorial at ..https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/create-clustering-model-azure-machine-learning-designer\/explore-data\n\nWhen I submit my pipeline I am seeing the error ...\n\nAn error occurred while submitting pipeline run\nGraphDatasetNotFound: Request failed with status code 400\n\nThis is an incredibly unhelpful message. I believe I have followed the steps as per the tutorial.\n\nAny idea what is the cause of this error?\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-03T15:51:30.88Z",
                "Answer_score":14,
                "Answer_body":"In dataset Version change from \"Always use latest\" to 1 or anyother version, worked for me",
                "Answer_comment_count":9,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-05-04T19:31:52.053Z",
                "Answer_score":0,
                "Answer_body":"@DebayanRoy-8817, how exactly should we go about changing the dataset version? Mine has been greyed out to the dataset version 1. Your help will be very much appreciated!",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-08T14:14:30.57Z",
                "Answer_score":0,
                "Answer_body":"This solved the problem. thanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Read data from CDM folder",
        "Question_creation_time":1620478169427,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/387697\/read-data-from-cdm-folder.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I have a CDM folder with data coming from Dynamics 365 Business Central.\nI need to do some data cleaning\/preprocessing and then apply my models on that data, but I didn't find a proper way to read CDM folders.\nI found some code on the Microsoft github repository, but is marked as obsolete.\n\nAzure-Samples\/cdm-azure-data-services-integration\n\nI'm searching for something like the Apache Spark CDM connector but to use within Azure Machine Learning service.\n\nps: I know that is possible to copy\/transform files with Azure Data Factory and that is supports CDM folders too, but is not what I want. I want to read CDM folder from python, do my stuff (data cleaning, preprocessing, applying models, ecc) then save the results.\n\nIs there any way?\nAny advice is welcome.\n\nThanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-10T22:59:13.12Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. The data source you specified isn't a supported storage type in AML. If you're using unsupported storage, we recommend that you move your data to supported Azure storage solutions. Currently, we don't have a python connector for connecting to CRMs. A workaround would be to load your data to a database and connect to the database using python. Hope this helps, sorry for any inconvenience.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"When using Azure Machine Learning Designer why are two way visualizations not available in the Series version, while they are with the older Studio (Classic) version?",
        "Question_creation_time":1620661630457,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/389481\/when-using-azure-machine-learning-designer-why-are.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I am a Data Scientist that is new to Azure ML. I have been experimenting with Designer using both the Azure Machine Learning and the older Classic version. As far as I can see the older version has more useful functionality. When looking at the raw data it is easy to compare the dependent and independent variables using the visualization option on the Classic version. In the new version the visualization only looks at each variable separately and cannot compare one against another. Also once the scores have been created, they can be quickly be compared to the actual values to see how they are correlated.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-10T18:37:14.13Z",
                "Answer_score":0,
                "Answer_body":"Hello Mike,\n\nThanks for the feedback. I will check with engineering team to see if we have any roadmap for the similar function.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML designer: force pipeline to execute with only an underlying data change",
        "Question_creation_time":1620410422613,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/387140\/azure-ml-designer-force-pipeline-to-execute-with-o.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"We are deploying an ML model through the Azure ML designer. Over time the underlying data changes and so the model needs to be regularly retrained. The actual designer pipeline and the dataset definition (a query on a SQL database) are not changed, only the underlying data in the Azure SQL database.\n\nRight now, the pipeline API can be triggered, but it does not execute (as expected). This is equivalent to the default allow_reuse = True in the Azure ML SDK. Is there a way to disable this setting (or set in to False) in the designer so that when the API is triggered we can force it to re-execute the pipeline every time we want to do a retraining (eg once a week) as new data comes in, so that a new model version is generated every time.\n\nTo be clear, the training takes around 20 minutes, and the compute cluster it runs on has a 120 second scale-down time, so cost considerations etc (ie the reason for this feature being enabled by default) are not a concern.\n\nThanks in advance for any help.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-08T18:43:30.677Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nUse the following steps to update a module pipeline parameter:\n\nAt the top of the canvas, select the gear icon.\nIn the Pipeline parameters section, you can view and update the name and default value for all of your pipeline parameter.\n\nHope this helps. Thanks.\n\nRegards,\nYutong",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure services without CC",
        "Question_creation_time":1620486974020,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/387725\/azure-services-without-cc.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I am currently enrolled in the Cloud Skill Challenge where I get the opportunity to get to know all the services Microsoft provide and get certified. As a student, I do not have a credit card but a debit credit card I use in all online purchases. In order to continue with my challenge, I need access to Azure Machine Learning, but my card is not accepted. Why is it so difficult to be able to use the trial without a \"credit card\"? In 2021, I have to say there is a huge amount of paying methods and credit cards are definitely not common in Europe...",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-09T07:57:25.727Z",
                "Answer_score":1,
                "Answer_body":"Probably you can try for Azure for students account else the only option is to get a new CC.\n\nhttps:\/\/azure.microsoft.com\/en-us\/free\/free-account-students-faq\/\n\nPlease don't forget to Accept Answer and Up-vote if the response helped -- Vaibhav",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML datetime format issue in output",
        "Question_creation_time":1606058533223,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/171333\/azure-ml-datetime-format-issue-in-output.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"HI ,\n\nAm trying to do some prediction for time series. When I get the output it is converting to MM\/DD\/YYYY format which is an issue.\n\nWhen I give input in YYYY-MM-DD format why is it not returning me in the same format. Please see the screenshot of input vs output",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Can't find the run button",
        "Question_creation_time":1617852662423,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/348777\/can39t-find-the-run-button.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":1,
        "Question_body":"Do I need to add the .ipynb extension manually to my notebook file ?\nI can't find the run button.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-08T09:06:51.417Z",
                "Answer_score":2,
                "Answer_body":"@paulgureghian-9874 You can re-name your file with .ipynb extension which should help to display the cells and the available options like run button for cell. Usually while creating new files in your workspace the UI prompts to select the extension of the file. If you can create a new file with .ipynb extension and copy these cells individually that should also work. Thanks.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-04-08T19:02:09.323Z",
                "Answer_score":0,
                "Answer_body":"Thanks. will add the .ipynb extension.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"What are the differences between LightGBM and FastTree algorithms used by ML.Net's modelbuilder?",
        "Question_creation_time":1620299148307,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/385365\/what-are-the-differences-between-lightgbm-and-fast.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"For my master thesis, I am using ML.Net library with the model builder to build machine learning models for regression \/ to predict values. My field of study is in constructional mechanics, so I'm rather new to machine learning.\n\nFor most of my models, tree-based regression algorithms seem to be the best performing, and of these LightGBM and FastTree are the best performing algorithms.\n\nI've tried to read up on LightGBM here: https:\/\/www.microsoft.com\/en-us\/research\/publication\/lightgbm-a-highly-efficient-gradient-boosting-decision-tree\/ And FastTree here: https:\/\/docs.microsoft.com\/en-us\/dotnet\/api\/microsoft.ml.trainers.fasttree.fasttreeregressiontrainer?view=ml-dotnet\n\nHowever, I struggle to distinguish what the difference between these algorithms is. Could someone explain what the difference between LightGBM and FastTree is?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-06T21:50:12.9Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us! The right place for ML.NET related question is the GitHub forum here, and the Gitter community. Sorry for the inconveniences.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"UserProcessKilledBySystemSignal: Job failed since the user script received system termination signal usually due to out-of-memory or segfault.",
        "Question_creation_time":1620234016640,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/384152\/userprocesskilledbysystemsignal-job-failed-since-t.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi, I am getting this error when scoring a model.\n\nSeems like it is an out-of-memory issue or a segfault issue (no idea what that means).\n\nI'm using Designer while my compute is Standard Dv2 Family vCPUs. Have made no changes to my storage account key.\n\nAny advice on how to debug this one? Many thanks in advance\n\nAzureMLCompute job failed.\nUserProcessKilledBySystemSignal: Job failed since the user script received system termination signal usually due to out-of-memory or segfault.\nReason: Process Killed with either 6:aborted or 9:killed or 11:segment fault. exit code here is from wrapping bash hence 128 + n\nCause: killed\nTaskIndex:\nNodeIp: 10.0.0.5\nNodeId: tvmps_ee452edcf7395836bdf60c0e0cd5f3a6308fafbb41c860c50a47be1367393df6_d\nReason: Job failed with non-zero exit Code",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-05T17:25:17.22Z",
                "Answer_score":0,
                "Answer_body":"Seems like it was an out-of-memory problem. If I reduce the trainning set, I get no error.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-05-06T21:07:20.663Z",
                "Answer_score":0,
                "Answer_body":"Thanks for the update the confirmation regarding to this. ^^\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Group Categorical Data module missing in Designer, how to reduce number of levels?",
        "Question_creation_time":1620183260377,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/383026\/group-categorical-data-module-missing-in-designer.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hi there,\n\nI'm working through a tutorial on reducing the number of levels of a categorical variable before using the \"Convert to Indicator Values\" module. In the tutorial, the presenter is using the classic studio which has a module called \"Group Categorical Data\". Unfortunately, I'm using ML Designer and it doesn't have that module.\n\nIs there an easy workaround to reduce the number of categorical levels in Designer before using the Convert to Indicator Values module?\n\nThanks kindly,",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-06T03:47:55.663Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for your feedback. Based on further exploration and confirmation from the product team, it seems Designer does not currently support 'Group Categorical Data' module. The recommendation is to use Execute Python\/R Script module to perform custom data transformations. Sorry for any inconvenience.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure - VS Code - 'No subscriptions were found'",
        "Question_creation_time":1620124730477,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/382060\/azure-vs-code-39no-subscriptions-were-found39.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I want to run an experiment with Azure Machine Learning and using Visual Studio Code.\n\nI am on a free trial subscription which is still in effect - my subscription is not empty as I have created resource groups to experiment with Azure Machine Learning service.\n\nI have installed 'Azure Machine Learning' visual studio code extension, I can sign in (email address of my Azure account appears in the Status Bar) BUT the subscription does not appear in the Azure explorer, neither can I choose a subscription. I get an error 'No subscriptions were found. Set up your account at http..'",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-04T22:57:16.943Z",
                "Answer_score":1,
                "Answer_body":"Hi, thanks for reaching out. Here are some steps to try:\n\nEnsure that you've signed into the right account for your resource\n\n\nAdd your tenant ID in the settings\n\n\n\nSearch for subscription using the command Azure: Select Subscriptions\n\n\n\n\nIf error persists after trying above steps, then I suggest reaching out to Azure Support so they can perform proper investigation. Hope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Cannot authenticate to Azure Machine Learning from RServer",
        "Question_creation_time":1619076064070,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/367167\/cannot-authenticate-to-azure-machine-learning-from.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Hi everyone,\n\nI cannot authenticate from Rserver (the one on compute instance azureml)\n\nI got prompted to open the devicelogin site and enter the code, did that and still got prompted again and then errors. It kept happening no matter what I tried.\n\nI can't find any documentation or discussion online that can help with this. Please help!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-03T00:28:29.717Z",
                "Answer_score":0,
                "Answer_body":"Hi YutongTie, it's been a while and I haven't got any help to get through this. Could yourself or anyone please point me to the right direction please ? If I don't get through this hurdle I won't be able to do anything else with AzureML in R. I'm testing this to validate the possibility of using AzureML in my team, given R is our current programming language.\n\nMany thanks !",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-04T00:26:38.057Z",
                "Answer_score":0,
                "Answer_body":"@VivianMai-2566 Sure thing!\n\nYou have been enabled for one-time Free Technical Support. To create the support request, please do the following as detailed below. It may take up to 1 hour for the free support ticket enablement to go through.\n\n\u2022 Go to the Health Advisory section within the Azure Portal: https:\/\/aka.ms\/healthadvisories\n\u2022 Select the Issue Name \"You have been enabled for one-time Free Technical Support\"\n\u2022 Details will populate below in the Summary Tab within the reading pane and you can click on the link \"Create a Support Request\" to the right of the message\n\nOnce created, please share the ticket number with me. I will help to track and make it smooth. Thanks a lot.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-05-04T00:58:16.593Z",
                "Answer_score":0,
                "Answer_body":"Thanks @YutongTie-5848 , the Tracking ID is LK43-P8Z.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Accessing Data from azure container from a notebook",
        "Question_creation_time":1617804754800,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/348022\/accessing-data-from-azure-container-from-a-noteboo.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hey there,\n\ni have a question concerning the navigation in the file system of the azure cloud.\n\nHow can i access data (like images) from my container through a azure notebook?\nCan i navigate in the cloud like in the file system of my local machine?\n\nBest regards and thank you in advance!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-04T00:17:58.567Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThere are several ways to get access Juypter Notebook from Azure offerings as bellow:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/notebooks\/quickstart-export-jupyter-notebook-project#use-notebooks-in-visual-studio-code\n\nBut unfortunately, I don't think any of them supports clickable UI as File system in UI. But you can call you data in code, it is the same as normal.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/storage\/blobs\/authorize-data-operations-portal\n\nOne way you can manage your data as clickable UI as File system is you can go to data blob\/ container directly.\n\nAlso, please feel free to share the scenario you want to do this, I will help to forward this feedback to engineering group for future development.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"unable to install AzureStor in R script in Azure ML Studio",
        "Question_creation_time":1619361821370,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/370607\/unable-to-install-azurestor-in-r-script-in-azure-m.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I got this error when trying to install older version\n\n0063: The following error occurred during evaluation of R script:\n---------- Start of error message from R ----------\n'AzureStor' is not a valid installed package\n\n\n\n\nwhen tried to install newer version of zip downloaded from cran. then it was giving error can not read version 3",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-27T01:41:47.423Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us. Unfortunately, this is not supported in Azure Machine Learning studio (classic), to install packages that are not supported as part of default Azure ML studio you can upload them as zip. Here is an example of how to upload various R packages as a zip file dataset and installed them using install.packages() and library() to load them in the execute R script.\n\nYou need to connect the .zip file dataset as script file bundle input.\n\nThen in your execute R script install and load them.\n\ninstall.packages(\"src\/XML_3.98-1.19.zip\",lib=\".\",repos=NULL, verbose = TRUE)\ninstall.packages(\"src\/survival_2.44-1.1.zip\",lib=\".\",repos=NULL, verbose = TRUE)\ninstall.packages(\"src\/parallelMap_1.3.zip\",lib=\".\",repos=NULL, verbose = TRUE)\ninstall.packages(\"src\/data.table_1.12.2.zip\",lib=\".\",repos=NULL, verbose = TRUE)\ninstall.packages(\"src\/checkmate_1.9.1.zip\",lib=\".\",repos=NULL, verbose = TRUE)\ninstall.packages(\"src\/stringi_1.4.3.zip\",lib=\".\",repos=NULL, verbose = TRUE)\ninstall.packages(\"src\/stats19_0.2.1.zip\",lib=\".\",repos=NULL, verbose = TRUE)\ninstall.packages(\"src\/ggplot2_3.1.1.zip\",lib=\".\",repos=NULL, verbose = TRUE)\ninstall.packages(\"src\/backports_1.1.3.zip\",lib=\".\",repos=NULL, verbose = TRUE)\ninstall.packages(\"src\/BBmisc_1.11.zip\",lib=\".\",repos=NULL, verbose = TRUE)\ninstall.packages(\"src\/ParamHelpers_1.12.zip\",lib=\".\",repos=NULL, verbose = TRUE)\ninstall.packages(\"src\/mlr_2.13.zip\",lib=\".\",repos=NULL, verbose = TRUE)\n\nlibrary(XML,lib.loc=\".\", verbose=TRUE)\nlibrary(survival,lib.loc=\".\", verbose=TRUE)\nlibrary(parallelMap,lib.loc=\".\", verbose=TRUE)\nlibrary(data.table,lib.loc=\".\", verbose=TRUE)\nlibrary(checkmate,lib.loc=\".\", verbose=TRUE)\nlibrary(stringi,lib.loc=\".\", verbose=TRUE)\nlibrary(stats19,lib.loc=\".\", verbose=TRUE)\nlibrary(ggplot2,lib.loc=\".\", verbose=TRUE)\nlibrary(backports,lib.loc=\".\", verbose=TRUE)\nlibrary(BBmisc,lib.loc=\".\", verbose=TRUE)\nlibrary(ParamHelpers,lib.loc=\".\", verbose=TRUE)\nlibrary(mlr,lib.loc=\".\", verbose=TRUE)\n\n\n\n\nYour Zip file should be a zip of zips of all these packages as seen below.\n\nPlease note you cannot use plain R script as input to Script Bundle input port of Execute R script module.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"ML model deployment issue",
        "Question_creation_time":1619524308143,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/373687\/ml-model-deployement-issue.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I am trying to deploy an ML classification model on Azure using GUI.\n\nAfter registering\/uploading the model inside the portal, I am deploying the model in the Azure container instance, with custom entry_script and the conda dependencies.\n\nEntry Script\n\n # Importing Pacakges\n import pandas as pd\n import pickle\n import regex, json\n import numpy as np\n import sklearn\n import os\n    \n from inference_schema.schema_decorators import input_schema, output_schema\n from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n    \n def init():\n     global model\n     global classes\n     model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'randomForest50.pkl')\n     model = pickle.load(open(model_path, \"rb\"))\n     classes = lambda x : [\"F\", \"M\"][x]\n    \n input_sample = np.array([['Thomas', 'Anna']])\n output_sample = np.array(['m', 'F'])\n    \n    \n @input_schema('data', NumpyParameterType(input_sample))\n @output_schema(NumpyParameterType(output_sample))\n def run(data):\n     try:\n         namesList = json.loads(data)[\"data\"][\"names\"]\n         pred = list(map(classes, model.predict(preprocessing(namesList))))\n         return str(pred[0])\n     except Exception as e:\n         error = str(e)\n         return error\n\n\n\n\nConda.yaml\n\n name: prediction\n dependencies:\n - python=3.7\n - numpy\n - scikit-learn\n - pip:\n     - azureml-defaults\n     - pandas\n     - pickle4\n     - regex\n     - inference-schema[numpy-support]   \n\n\n\nAfter deployment, the endpoint deployment state goes to unhealthy. and the logs show that program is stuck in a loop. Check logs below:\n\n 2021-04-26T08:14:55,433967500+00:00 - rsyslog\/run \n 2021-04-26T08:14:55,421414500+00:00 - iot-server\/run \n 2021-04-26T08:14:55,540534600+00:00 - gunicorn\/run \n 2021-04-26T08:14:55,646209100+00:00 - nginx\/run \n EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n 2021-04-26T08:14:58,234212800+00:00 - iot-server\/finish 1 0\n 2021-04-26T08:14:58,324505300+00:00 - Exit code 1 is normal. Not restarting iot-server.\n Starting gunicorn 19.9.0\n Listening at: http:\/\/127.0.0.1:31311 (62)\n Using worker: sync\n worker timeout is set to 300\n Booting worker with pid: 89\n SPARK_HOME not set. Skipping PySpark Initialization.\n Initializing logger\n 2021-04-26 08:15:11,623 | root | INFO | Starting up app insights client\n 2021-04-26 08:15:11,624 | root | INFO | Starting up request id generator\n 2021-04-26 08:15:11,631 | root | INFO | Starting up app insight hooks\n 2021-04-26 08:15:11,632 | root | INFO | Invoking user's init function\n worker timeout is set to 300\n Booting worker with pid: 91\n SPARK_HOME not set. Skipping PySpark Initialization.\n Initializing logger\n 2021-04-26 08:15:29,014 | root | INFO | Starting up app insights client\n 2021-04-26 08:15:29,014 | root | INFO | Starting up request id generator\n 2021-04-26 08:15:29,014 | root | INFO | Starting up app insight hooks\n 2021-04-26 08:15:29,014 | root | INFO | Invoking user's init function\n worker timeout is set to 300\n Booting worker with pid: 98\n SPARK_HOME not set. Skipping PySpark Initialization.\n ...\n ...\n ...\n\n\n\n\nI tried to deploy the model using python also. But it also failed with message:\n\n WebserviceException: WebserviceException:\n  Message: Service deployment polling reached non-successful terminal state, current service state: Failed\n Operation ID: 98e464d4-5b15-4606-936f-a2625f7bd1fd\n More information can be found using '.get_logs()'\n Error:\n {\n   \"code\": \"AciDeploymentFailed\",\n   \"statusCode\": 400,\n   \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: d16. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image 20dd0f745f704eeb89ef4d52057871a0.azurecr.io\/azureml\/azureml_b9e8a2e66019f74c902eacced9684631 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\",\n   \"details\": [\n     {\n       \"code\": \"CrashLoopBackOff\",\n       \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: d16. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image 20dd0f745f704eeb89ef4d52057871a0.azurecr.io\/azureml\/azureml_b9e8a2e66019f74c902eacced9684631 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\"\n     },\n     {\n       \"code\": \"AciDeploymentFailed\",\n       \"message\": \"Your container application crashed. Please follow the steps to debug:\\n\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.\\n\\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.\\n\\t3. You can also interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\\n\\\"RestartCount\\\": 3\\n\\\"CurrentState\\\": {\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"}\\n\\\"PreviousState\\\": {\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2021-04-27T10:46:03.903Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2021-04-27T10:46:07.524Z\\\",\\\"detailStatus\\\":\\\"Error\\\"}\\n\\\"Events\\\":\\n{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2021-04-27T10:42:37Z\\\",\\\"lastTimestamp\\\":\\\"2021-04-27T10:42:37Z\\\",\\\"name\\\":\\\"Pulling\\\",\\\"message\\\":\\\"pulling image \\\\\\\"20dd0f745f704eeb89ef4d52057871a0.azurecr.io\/azureml\/azureml_b9e8a2e66019f74c902eacced9684631@sha256:322ebafbe88e98b0f57104fd0afad08a5caf57cc5e7f64b3b629c3ea50f54bb3\\\\\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":1,\\\"firstTimestamp\\\":\\\"2021-04-27T10:44:15Z\\\",\\\"lastTimestamp\\\":\\\"2021-04-27T10:44:15Z\\\",\\\"name\\\":\\\"Pulled\\\",\\\"message\\\":\\\"Successfully pulled image \\\\\\\"20dd0f745f704eeb89ef4d52057871a0.azurecr.io\/azureml\/azureml_b9e8a2e66019f74c902eacced9684631@sha256:322ebafbe88e98b0f57104fd0afad08a5caf57cc5e7f64b3b629c3ea50f54bb3\\\\\\\"\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-04-27T10:44:40Z\\\",\\\"lastTimestamp\\\":\\\"2021-04-27T10:46:03Z\\\",\\\"name\\\":\\\"Started\\\",\\\"message\\\":\\\"Started container\\\",\\\"type\\\":\\\"Normal\\\"}\\n{\\\"count\\\":4,\\\"firstTimestamp\\\":\\\"2021-04-27T10:44:43Z\\\",\\\"lastTimestamp\\\":\\\"2021-04-27T10:46:07Z\\\",\\\"name\\\":\\\"Killing\\\",\\\"message\\\":\\\"Killing container with id 5c5ddb266c4b38b1c306367712d9bec0687e5f6979e34afea7f6b943edf7db75.\\\",\\\"type\\\":\\\"Normal\\\"}\\n\"\n     }\n   ]\n }\n  InnerException None\n  ErrorResponse \n {\n     \"error\": {\n         \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: 98e464d4-5b15-4606-936f-a2625f7bd1fd\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\n\\\\t1. Please check the logs for your container instance: d16. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\\\n\\\\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\n\\\\t3. You can also try to run image 20dd0f745f704eeb89ef4d52057871a0.azurecr.io\/azureml\/azureml_b9e8a2e66019f74c902eacced9684631 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\\\n\\\\t1. Please check the logs for your container instance: d16. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\\\n\\\\t2. You can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\n\\\\t3. You can also try to run image 20dd0f745f704eeb89ef4d52057871a0.azurecr.io\/azureml\/azureml_b9e8a2e66019f74c902eacced9684631 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\\\n\\\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https:\/\/aka.ms\/debugimage#dockerlog for more information.\\\\n\\\\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.\\\\n\\\\t3. You can also interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\\\n\\\\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\\\\n\\\\\\\"RestartCount\\\\\\\": 3\\\\n\\\\\\\"CurrentState\\\\\\\": {\\\\\\\"state\\\\\\\":\\\\\\\"Waiting\\\\\\\",\\\\\\\"startTime\\\\\\\":null,\\\\\\\"exitCode\\\\\\\":null,\\\\\\\"finishTime\\\\\\\":null,\\\\\\\"detailStatus\\\\\\\":\\\\\\\"CrashLoopBackOff: Back-off restarting failed\\\\\\\"}\\\\n\\\\\\\"PreviousState\\\\\\\": {\\\\\\\"state\\\\\\\":\\\\\\\"Terminated\\\\\\\",\\\\\\\"startTime\\\\\\\":\\\\\\\"2021-04-27T10:46:03.903Z\\\\\\\",\\\\\\\"exitCode\\\\\\\":111,\\\\\\\"finishTime\\\\\\\":\\\\\\\"2021-04-27T10:46:07.524Z\\\\\\\",\\\\\\\"detailStatus\\\\\\\":\\\\\\\"Error\\\\\\\"}\\\\n\\\\\\\"Events\\\\\\\":\\\\n{\\\\\\\"count\\\\\\\":1,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2021-04-27T10:42:37Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2021-04-27T10:42:37Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Pulling\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"pulling image \\\\\\\\\\\\\\\"20dd0f745f704eeb89ef4d52057871a0.azurecr.io\/azureml\/azureml_b9e8a2e66019f74c902eacced9684631@sha256:322ebafbe88e98b0f57104fd0afad08a5caf57cc5e7f64b3b629c3ea50f54bb3\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"}\\\\n{\\\\\\\"count\\\\\\\":1,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2021-04-27T10:44:15Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2021-04-27T10:44:15Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Pulled\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Successfully pulled image \\\\\\\\\\\\\\\"20dd0f745f704eeb89ef4d52057871a0.azurecr.io\/azureml\/azureml_b9e8a2e66019f74c902eacced9684631@sha256:322ebafbe88e98b0f57104fd0afad08a5caf57cc5e7f64b3b629c3ea50f54bb3\\\\\\\\\\\\\\\"\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"}\\\\n{\\\\\\\"count\\\\\\\":4,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2021-04-27T10:44:40Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2021-04-27T10:46:03Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Started\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Started container\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"}\\\\n{\\\\\\\"count\\\\\\\":4,\\\\\\\"firstTimestamp\\\\\\\":\\\\\\\"2021-04-27T10:44:43Z\\\\\\\",\\\\\\\"lastTimestamp\\\\\\\":\\\\\\\"2021-04-27T10:46:07Z\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"Killing\\\\\\\",\\\\\\\"message\\\\\\\":\\\\\\\"Killing container with id 5c5ddb266c4b38b1c306367712d9bec0687e5f6979e34afea7f6b943edf7db75.\\\\\\\",\\\\\\\"type\\\\\\\":\\\\\\\"Normal\\\\\\\"}\\\\n\\\"\\n    }\\n  ]\\n}\"\n     }\n }\n\n\n\nI have deployed the same model with the same entryScript.py and the same conda.yaml previously, and it worked fine.\n\nI cannot figure out what can be the issue here. Can anybody please suggest to me something for solving this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-27T19:57:27.553Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us. Based on the log, it seems your container application crashed and this may be caused by errors in your scoring file's init() function.\n\nYou can run service.get_logs() to get log information from the unhealthy service to see what's causing it to fail. Please refer to https:\/\/aka.ms\/debugimage#debug-locally for more information.\n\nYou can interactively debug your scoring file locally. Please refer to https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information. View the diagnostic events to check status of container, it may help you to debug the issue.\n\nYou can also try to run image 20dd0f745f704eeb89ef4d52057871a0.azurecr.io\/azureml\/azureml_b9e8a2e66019f74c902eacced9684631 locally. Please refer to https:\/\/aka.ms\/debugimage#service-launch-fails for more information.\n\nMore information will help to find out the reason.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AutoML: problem with univariate time series forecasting",
        "Question_creation_time":1617739313070,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/346598\/automl-problem-with-univariate-time-series-forecas.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I'm having troubles generating univariate time series forecasts with Azure Automated Machine Learning (I know...).\n\nWhat I'm doing\n\nSo I have about 5 years worth of monthly observations in a dataframe that looks like this:\n\n\tdate\ttarget_value\t\n\t2015-02-01\t123\t\n\t2015-03-01\t456\t\n\t2015-04-01\t789\t\n\t...\t...\t\n\nI want to forecast target_value based on past values of target_value, i.e. univariate forecasting like ARIMA for instance.\nSo I am setting up the AutoML forecast like this:\n\n\n\n # that's the dataframe as shown above\n train_data = Dataset.Tabular.from_delimited_files(path=datastore.path(my_remote_filename))\n    \n # ...other code...\n    \n forecasting_parameters = ForecastingParameters(\n     time_column_name='date',\n     forecast_horizon=2,\n     target_lags='auto',\n     freq='MS'\n )\n    \n automl_config = AutoMLConfig(task='forecasting',\n                              debug_log='automl_forecasting_function.log',\n                              primary_metric='normalized_root_mean_squared_error',\n                              enable_dnn=True,\n                              experiment_timeout_hours=8.0,\n                              enable_early_stopping=True,\n                              training_data=train_data,\n                              compute_target='my-cluster',\n                              n_cross_validations=3,\n                              verbosity=logging.INFO,\n                              max_concurrent_iterations=4,\n                              max_cores_per_iteration=-1,\n                              label_column_name='target_value',\n                              forecasting_parameters=forecasting_parameters)\n\n\n\nWhat the problem is\n\nBut AutoML does not seem to generate the forecast for target_value based on past values of target_value. It seems to use the date column as the independent variable!\nThe feature importance chart also shows date as the input feature:\n\nAs a side note: running multivariate forecasts works fine.\nWhen I use a dataset like this, feature_1 and feature_2 are used (i.e. as the X) to forecast target_value (i.e. the y)\n\n\tdate\tfeature_1\tfeature_2\ttarget_value\t\n\t2015-02-01\t10\t7\t123\t\n\t2015-03-01\t30\t2\t456\t\n\t2015-04-01\t20\t5\t789\t\n\t...\t...\t...\t...\t\n\nMy questions therefore\nHow do I need to set up a univariate AutoML forecast to forecast target_value based on past observations target_value?\nI assumed generating lagged values for target_value etc. is exactly what AutoML is supposed to do.\n\nThanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-08T04:12:36.817Z",
                "Answer_score":0,
                "Answer_body":"@movingabout-2877 Thanks, AutoML does use the date column as an independent variable. We engineer several features from it, this is a standard practice for learning seasonal patterns. In the given scenario the date column will be featurized to represent 'day', 'month', 'day of week' etc. This is done to train regression-based model on this data, which will use the generated columns for prediction.\n\nPlease remove the target_lags='auto' to allow selection of Arima. We have to block certain models (e.g. Arima) when the target lags are set. This is a product gap that we're in the process of fixing.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"DSVM can support SQL Server Developer Edition for Ubuntu",
        "Question_creation_time":1618980125337,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/365284\/dsvm-can-support-sql-server-developer-edition-for.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"According to this\n- https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/data-science-virtual-machine\/tools-included#store-retrieve-and-manipulate-data,\nit appears that the SQL Server Developer Edition (Ubuntu) is being supported in DSVM but I couldn\u2019t find the name in the supported list here https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/data-science-virtual-machine\/dsvm-tools-data-platforms#sql-server-developer-edition,\nfurthermore there is no guide line for Linux Guide line but only windows guideline is there.\nI\u2019d like make sure the followings :\n\nCan DSVM support SQL Server Developer Edition for Ubuntu?\n\n\nIf yes, where is the guideline for this?\n\n\nIf no, the documentation is wrong? And any particular supporting plan for SQL Server Developer Edition for Ubuntu?\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-22T05:37:42.617Z",
                "Answer_score":0,
                "Answer_body":"@JunghyeonRyu-6784 Thanks for the question. We don't preinstall SQL Server Developer Edition on the Ubuntu images but you can install it on your own. Here is the documentation and steps.",
                "Answer_comment_count":5,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"how to update azure ml model from adf?",
        "Question_creation_time":1619624088887,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/375702\/how-to-update-azure-ml-model-from-adf.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"Hi, I manage to run a azure ml trainning pipeline in adf. Then I can see that I can create\/update a batch inference pipeline from the Designer. But can I update the batch inference pipeline from adf?\n\nthanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-28T17:13:15.207Z",
                "Answer_score":0,
                "Answer_body":"Hi @javier-8889,\n\nThanks for using Microsoft Q&A !!\n\nUnfortunately this is not supported using Azure Data Factory and you can only update the scoring web service using Azure Machine Learning Studio (classic) update resource activity Can you please provide your scenario\/use case in details so that I can check internally. I also suggest you to please post this as a feedback at ADDF UserVoice. This will allow the community to upvote and for the product team to include into their plans\n\nPlease do not forget to \"Accept the answer\" wherever the information provided helps you to help others in the community.\n\nThanks\nSaurabh",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How to Delete Data Backing a Dataset",
        "Question_creation_time":1619800286227,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/379022\/how-to-delete-data-backing-a-dataset.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"How do I delete the data backing a dataset?\n\nI've got a ton of datasets our data scientist created. Some of these are good, but most are no longer relevant. These are growing and I want to delete these since they cost money to store.\n\nI think these files located in \"blobstore-<UUID>\/UI\" may be backing files. There are *.csv files.\n\n\n\n\n\nWhat are these files located in \"blobstore-<UUID>\/azureml?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-03T13:45:33.607Z",
                "Answer_score":0,
                "Answer_body":"@JeremiahAdams-0775 Thanks for the question. If you wish to delete the file in Blob storage, you can do that via Azure Storage Explorer\/the portal provided you have the appropriate permissions to that storage service.\n\nThis is in fact by design that \u201cunregister\u201d doesn\u2019t actually delete your underlying storage; since an Azure ML Dataset is a reference point to your data in storage, this means we don\u2019t copy your data to your workspace so no extra storage cost is incurred. This also helps safeguard against accidentally deleting files in storage when cleaning up assets in an Azure ML workspace.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning ExperimentExecutionException while submitting a distributed training run !",
        "Question_creation_time":1619892981027,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/379458\/azure-machine-learning-experimentexecutionexceptio.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":1,
        "Question_body":"Hi, here is the details of my issue.\nI want to execute a distributed training run with the Tensorflow framework and Horovod.\nTo do this, I've configured a environment called \"tf_env\" as follow :\n\n # Create the environment : the dependencies are in the .yml file\n tf_env = Environment.from_conda_specification(name=\"tensorflow_environment\", file_path=\"experiments\/package-list.yml\")\n    \n # Register the environment\n tf_env.register(workspace=ws)\n    \n # Specify a GPU base image\n tf_env.docker.enabled = True\n tf_env.docker.base_image = 'mcr.microsoft.com\/azureml\/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04'\n\n\n\nWhere my \"package-list.yml\" contains all the dependencies my \"train_script.py\" requires.\nI've defined my ScriptConfigRun as follow :\n\n arguments = [\n     (... other arguments ...)\n     \"--ds\",  images_ds.as_mount()\n ]\n    \n src = ScriptRunConfig(\n     source_directory=\"experiments\",\n     script='train_script.py',\n     arguments=arguments,\n     compute_target=compute_target,\n     environment=tf_env,\n     distributed_job_config=MpiConfiguration(node_count=2)\n )\n\n\n\nThen, when I want to submit the run :\n\n run = best_model_experiment.submit(config=src)\n\n\n\n... it raises this error I don't understand :\n\n ExperimentExecutionException: ExperimentExecutionException:\n     Message: {\n     \"error_details\": {\n         \"componentName\": \"execution\",\n         \"correlation\": {\n             \"operation\": \"***\",\n             \"request\": \"***\"\n         },\n         \"environment\": \"westeurope\",\n         \"error\": {\n             \"code\": \"UserError\",\n             \"message\": \"Error when parsing request; unable to deserialize request body\"\n         },\n         \"location\": \"westeurope\",\n         \"time\": \"***\"\n     },\n     \"status_code\": 400,\n     \"url\": \"https:\/\/westeurope.experiments.azureml.net\/execution\/v1.0\/subscriptions\/***\/resourceGroups\/***\/providers\/Microsoft.MachineLearningServices\/workspaces\/***\/experiments\/experiment\/snapshotrun?runId=experiment***\"\n }\n     InnerException None\n     ErrorResponse \n {\n     \"error\": {\n         \"message\": \"{\\n    \\\"error_details\\\": {\\n        \\\"componentName\\\": \\\"execution\\\",\\n        \\\"correlation\\\": {\\n            \\\"operation\\\": \\\"***\\\",\\n            \\\"request\\\": \\\"***\\\"\\n        },\\n        \\\"environment\\\": \\\"westeurope\\\",\\n        \\\"error\\\": {\\n            \\\"code\\\": \\\"UserError\\\",\\n            \\\"message\\\": \\\"Error when parsing request; unable to deserialize request body\\\"\\n        },\\n        \\\"location\\\": \\\"westeurope\\\",\\n        \\\"time\\\": \\\"***\\\"\\n    },\\n    \\\"status_code\\\": 400,\\n    \\\"url\\\": \\\"https:\/\/westeurope.experiments.azureml.net\/execution\/v1.0\/subscriptions\/***\/resourceGroups\/***\/providers\/Microsoft.MachineLearningServices\/workspaces\/***\/experiments\/experiment\/snapshotrun?runId=experiment_***\\\"\\n}\"\n     }\n }\n\n\n\n\nCould you please help me decrypt this error ?\nThank you.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-03T06:48:41.707Z",
                "Answer_score":0,
                "Answer_body":"Issue solved ! I've given a list in arguments to argparse so it could'nt deserialized the object.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Devops for Data Science Project",
        "Question_creation_time":1620038832133,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/380561\/devops-for-data-science-project.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi Team,\nI have a use case wherein some machine learning models will be developed by a team. My team will be developing an application to consume that model. Also we have to do the CI Cd for that models , in such a way that every time the other team uploads a model in a blob storage , pipeline should be triggered and entire application should work the same way if new model performs better than previous one.\nThere is a documentation from microsoft but it is for VSTS.\n\nhttps:\/\/github.com\/Azure\/DevOps-For-AI-Apps\/blob\/jainr-refactor\/Tutorial.md\n\nThe steps mentioned here is exactly what I would like to do but I need the same tutorial for Azure Devops.Since I see many changes in VSTS and Devops portal.\n\n@ChrisPatterson-0930",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-03T12:31:53.03Z",
                "Answer_score":0,
                "Answer_body":"Devops \/ TFS is not currently supported here on QnA. The product group for Azure DevOps \/ TFS actively monitors questions over at\nhttps:\/\/developercommunity.visualstudio.com\/report?space=21&entry=problem\nhttps:\/\/developercommunity.visualstudio.com\/report?space=22&entry=problem\n\n--please don't forget to Accept as answer if the reply is helpful--",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Notebook Python kernel never loads",
        "Question_creation_time":1618279137097,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/354727\/azure-ml-notebook-python-kernel-never-loads.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"Hello,\n\nI'm working through mslearn examples. I created a Workspace and a Compute instance based on provided specs [Standard_DS11_v2 (2 cores, 14 GB RAM, 28 GB disk)]\n\nThe compute instance deploys and runs fine. I tried to open a terminal to clone the dp100 examples, but the terminal always fails, even with the compute instance selected. I tried restarting the compute instance and the terminal never loaded.\n\nParallel to that, when I create an ML Studio notebook, the compute instance says its running, but the Python 3.6 kernel never loads so I can't run cells from the Notebook. However, if I open the contents of the Notebook in the Jupyter editor it runs fine.\n\nI was able to run the git clone code using the above, but I'd like to understand why the notebooks and terminal aren't working as they should be.\n\nI was following these instructions: https:\/\/microsoftlearning.github.io\/mslearn-dp100\/instructions\/01-create-a-workspace.html",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-15T03:16:36.117Z",
                "Answer_score":0,
                "Answer_body":"Thanks for the confirmation.\n\nYes, this should work now. Please let us know if you see this again. I will convert my comment to answer, please feel free to accept. Thanks.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Automated ML(interface) choosing primary metrics to handle imbalanced data",
        "Question_creation_time":1593398061863,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/40792\/azure-automated-mlinterface-choosing-primary-metri.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":6,
        "Question_score":1,
        "Question_body":"I figured out that there are some primary metrics I can choose when I run an automated ML experiment. Yet the number of primary metrics is fewer than the run metrics in the result page. I want to deal with imbalanced data(10:1 or 20:1) and\n\nlooked up the links below:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-manage-ml-pitfalls#identify-models-with-imbalanced-data\nand\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train\n\nIt seems F1 score is recommended to evaluate each model with imbalanced data.\n\nHere are my questions:\n\nIs there any way to set F1 score or multiple measures as a primary metric?\n\n\nIf there is no such way, should I do it manually?\n\n\nOf all the given primary metrics, which primary metric is the most appropriate(to build a Classification model with imbalanced data)?\n\n\n\n\n\nThanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-30T09:20:12.347Z",
                "Answer_score":0,
                "Answer_body":"For imbalanced data, it is preferred to choose AUC Weighted. Also user should then choose a metric that is appropriate to work well for imbalance. E.g. F1, micro averaged AUC, balanced accuracy for model evaluation. For primary metric (metric used for model optimization) the user should preferably choose AUC Weighted instead of accuracy.\nCurrently from the ml.azure.com the following metrics are supported. To add F1 score metric forwarded to product team to check on this.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train#primary-metric",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"azure ml designer: how to use parameters with sql transformation?",
        "Question_creation_time":1619281429040,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/370365\/azure-ml-designer-how-to-use-parameters-with-sql-t.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hi, I would like to apply an SQL Query Transformation to my data in Azure ML Designer but the transformation needs to take two parameters as inputs. How do I reference them\n\nThe idea is to have something like this:\n\n select * from customers where account = [param1] and cuType = [param2] \n\n\n\n\nI have defined param1 and param2 as pipeline parameters but not sure how to reference them in the sql script",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-26T10:55:52.5Z",
                "Answer_score":0,
                "Answer_body":"@javier-8889 Thanks for the question, When designing a pipeline in Azure ML Designer, each step or module creates intermediate datasets that can be seen using the UI. Those datasets are persisted in the blob storage. To filter data, you can use Apply SQL Transformation to write SQL query or Split Data using regular expression. You can also use Execute Python Script and Execute R script module to write your own data processing logic.\n\nDesigner Pipeline Documentation:https:\/\/github.com\/Azure\/AzureMachineLearningGallery\/blob\/main\/pipelines\/README.md",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Pytorch cannot detect GPU when using an AML Compute Cluster with a GPU",
        "Question_creation_time":1617721297227,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/346224\/pytorch-cannot-detect-gpu-when-using-an-aml-comput.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hi,\n\nI've been trying to train a pytorch model on the Azure ML compute clusters (STANDARD_NV6) but I cannot get the code to detect and use the GPU device, torch.cuda.is_available() always returns False.\n\nI'm using a custom environment and have tried using a few different dockerfiles as base images from the Microsoft container repository. For example, I've tried the \"mcr.microsoft.com\/azureml\/openmpi3.1.2-cuda10.2-cudnn7-ubuntu18.04\" base image.\n\nIn the build log, I can see that the correct dependencies are installed each time but the code still doesn't detect a GPU. I tried forcing docker to use the GPU with docker_arguments = [\"--gpus\", \"all\"] but this causes the build to fail with this error:\n\n AzureMLCompute job failed.\n FailedStartingContainer: Unable to start docker container\n     FailedContainerStart: Unable to start docker container\n     err: warning: your kernel does not support swap limit capabilities or the cgroup is not mounted. memory limited without swap.\n docker: error response from daemon: oci runtime create failed: container_linux.go:370: starting container process caused: process_linux.go:459: container init caused: running hook #1:: error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: mount error: file creation failed: \/mnt\/docker\/overlay2\/66b78fe178db5d08ca4db26528f1a6de00aba65b528a6568649b1abcbea22348\/merged\/run\/nvidia-persistenced\/socket: no such device or address: unknown.\n    \n     Reason: warning: your kernel does not support swap limit capabilities or the cgroup is not mounted. memory limited without swap.\n docker: error response from daemon: oci runtime create failed: container_linux.go:370: starting container process caused: process_linux.go:459: container init caused: running hook #1:: error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: mount error: file creation failed: \/mnt\/docker\/overlay2\/66b78fe178db5d08ca4db26528f1a6de00aba65b528a6568649b1abcbea22348\/merged\/run\/nvidia-persistenced\/socket: no such device or address: unknown.\n    \n     Info: Failed to prepare an environment for the job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.\n\n\n\nIt feels like I've missed some obvious step somewhere...\n\nThanks for any help!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-07T10:11:49.583Z",
                "Answer_score":0,
                "Answer_body":"@ClaudiaVanea-8710 Thanks for the question. which means driver issues, Can you please add more details about the Pytorch version that you using. Especially with pytorch where somehow the pytorch doesn\u2019t install correctly with the latest CUDA drivers. Can you please try installing the latest nvdia drivers.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Failure in Sidecar: Failed to read file line by line.",
        "Question_creation_time":1619675273623,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/376584\/failure-in-sidecar-failed-to-read-file-line-by-lin.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I was running 100 identical jobs on a compute cluster via Azure Machine Learning of which 97 failed and 3 succeeded without issues. The failed jobs failed half-way through with the following error message\n\n AzureMLCompute job failed.\n JobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\n     Reason: Job failed with non-zero exit Code\n     Reason: runSpecialJobTask failed with with non zero exit code\n     stderr: runSpecialJobTask: postprocessing: Failure in Sidecar:\n Failed to read file line by line.\n     Reason: Job release task failed with non-zero exit Code\n\n\n\nThere is no error message in the driver log or any other log file to indicate what went wrong. It seems like the failed jobs stopped half-way for no reason. The wording of the error message \"Failed to read file line by line.\" does not seem to be a standard python error message. Is there a way I can find out what happened in the sidecar and trace this error?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Send new data to Deployed model",
        "Question_creation_time":1619546083177,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/374180\/send-new-data-to-deployed-model.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":16,
        "Question_score":0,
        "Question_body":"Hello,\n\nWe are sending data from a smartwatch -> IoT Central -> Event Hubs -> Data Explorer -> Blob Storage.\n\nWe are then using the blob storage as a datastore in Machine Learning, which we make a dataset of.\n\nWe deployed a model we trained locally to Azure Machine Learning.\n\nWe now want to send new data from the watch to the model to make predictions on.\n\nWe are wondering how we can do this?\n\nDo we just update the dataset the same way we are currently sending the data? and if so, how can we then auto send it to the model?\n\nOr is there another way to send this new data? Can we still send through blob storage? Or should we send the data directly from the watch to the webservice made by the model?\n\nThanks so much!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-27T22:16:06.013Z",
                "Answer_score":1,
                "Answer_body":"Hello @yjay-4307 ,\n\nso you get new data from devices and you want to predict using that data?\n\nCheck out Azure Stream Analytics which can ingest messages from the Event Hub.\n\nThen, you can Azure ML as a function on make decisions based on the incoming data using ML.",
                "Answer_comment_count":7,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Error while accessing the dataset from a datastore",
        "Question_creation_time":1619698599813,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/377203\/error-while-accessing-the-dataset-from-a-datastore.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":1,
        "Question_body":"I have tried to read the dataset from datastore. Also tried to create the dataset also.\n\nThe code for reading the dataset is below\n\n from azureml.core import Workspace\n ws = Workspace.from_config()\n datastore = Datastore.get(ws, 'qdataset')\n\n\n\nIt works fine still now.\n\n from azureml.core.dataset import Dataset\n six_dataset = Dataset.get_by_name(workspace=ws, name='combined_classifier')\n\n\n\nAlso i have tried from azureml.core import Dataset\n\nIt shows the following error:\n\n2021-04-29 11:56:47.284077 | ActivityCompleted: Activity=_dataflow, HowEnded=Failure, Duration=0.0 [ms], Info = {'activity_id': 'xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx', 'activity_name': '_dataflow', 'activity_type': 'InternalCall', 'app_name': 'dataset', 'source': 'azureml.dataset', 'version': '1.27.0', 'dataprepVersion': '2.14.2', 'subscription': '', 'run_id': '', 'resource_group': '', 'workspace_name': '', 'experiment_id': '', 'location': '', 'completionStatus': 'Failure', 'durationMs': 962.01}, Exception=AttributeError; module 'azureml.dataprep' has no attribute 'api'\n\n\n\n\nAttributeError Traceback (most recent call last)\n<ipython-input-34-ac7a8d35da4d> in <module>\n1 from azureml.core.dataset import Dataset\n----> 2 six_dataset = Dataset.get_by_name(workspace=ws, name='combined_classifier')\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data_loggerfactory.py in wrapper(args, *kwargs)\n127 with LoggerFactory.track_activity(logger, func.name_, activity_type, custom_dimensions) as al:\n128 try:\n--> 129 return func(args, *kwargs)\n130 except Exception as e:\n131 if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data\\abstract_dataset.py in get_by_name(workspace, name, version)\n87 :rtype: typing.Union[azureml.data.TabularDataset, azureml.data.FileDataset]\n88 \"\"\"\n---> 89 dataset = AbstractDataset._get_by_name(workspace, name, version)\n90 AbstractDataset._track_lineage([dataset])\n91 return dataset\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data\\abstract_dataset.py in _get_by_name(workspace, name, version)\n652 if not success:\n653 raise result\n--> 654 dataset = _dto_to_dataset(workspace, result)\n655 warn_deprecated_blocks(dataset)\n656 return dataset\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data_dataset_rest_helper.py in _dto_to_dataset(workspace, dto)\n93 registration=registration)\n94 if dto.dataset_type == _DATASET_TYPE_FILE:\n---> 95 return FileDataset._create(\n96 definition=dataflow_json,\n97 properties=dto.latest.properties,\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data_loggerfactory.py in wrapper(args, *kwargs)\n127 with LoggerFactory.track_activity(logger, func.name_, activity_type, custom_dimensions) as al:\n128 try:\n--> 129 return func(args, *kwargs)\n130 except Exception as e:\n131 if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data\\abstract_dataset.py in _create(cls, definition, properties, registration, telemetry_info)\n555 from azureml.data._partition_format import parse_partition_format\n556\n--> 557 steps = dataset._dataflow._get_steps()\n558 partition_keys = []\n559 for step in steps:\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data_loggerfactory.py in wrapper(args, *kwargs)\n127 with LoggerFactory.track_activity(logger, func.name_, activity_type, custom_dimensions) as al:\n128 try:\n--> 129 return func(args, *kwargs)\n130 except Exception as e:\n131 if hasattr(al, 'activity_info') and hasattr(e, 'error_code'):\n\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\azureml\\data\\abstract_dataset.py in _dataflow(self)\n215 raise UserErrorException('Dataset definition is missing. Please check how the dataset is created.')\n216 if self._registration and self._registration.workspace:\n--> 217 dataprep().api._datastore_helper._set_auth_type(self._registration.workspace)\n218 if not isinstance(self._definition, dataprep().Dataflow):\n219 try:\n\nAttributeError: module 'azureml.dataprep' has no attribute 'api'\n\n\n\n\n\nPlease give a solution to solve this",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-29T13:22:51.567Z",
                "Answer_score":1,
                "Answer_body":"It now worked..\nWe need to install azure-ml-api-sdk using this command\n\npip install azure-ml-api-sdk",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How to deploy ML Designer pipeline as real-time inference pipeline using N-Gram",
        "Question_creation_time":1606307286153,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/175242\/how-to-deploy-ml-designer-pipeline-as-real-time-in.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Hi,\ni deployed a real-time inference pipeline using ML Designer. Training and deploying works fine. But when I'm consuming\/testing my API it doesn't work. Postman gives me Errorcode 500 and \"Internal Server Error. Run: Server internal error is from Module Extract N-Gram Features from Text\".\n\nThis is my training pipeline:\n\n\nI read this: https:\/\/github.com\/MicrosoftDocs\/azure-docs\/blob\/master\/articles\/machine-learning\/algorithm-module-reference\/extract-n-gram-features-from-text.md#score-or-publish-a-model-that-uses-n-grams\n\nBut I don't know how to achieve this.\n\nThanks in advance.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-26T05:06:13.387Z",
                "Answer_score":0,
                "Answer_body":"Once you create a real-time inference pipeline, please make the further modifications below:\n\nFind the output Result_vocabulary dataset from Extract N-Gram Features from Text module.\n\n\n\nRegister the dataset as with a name\n\n\n\nUpdate real-time inference pipeline like below:\n\n\n\n\n\nWe will improve the documentation accordingly. Thanks for reporting the issue!",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-04-28T06:35:33.063Z",
                "Answer_score":0,
                "Answer_body":"Hi @LuZhang-4441 do not see Output datasets to select for registering them. How should I proceed? I have also attached screenshot.\n\nInput datasets\nNone\n\nOutput datasets\nNone",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Deploy AML Model to ACI with SSL Enabled",
        "Question_creation_time":1619607996060,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/375249\/deploy-aml-model-to-aci-with-ssl-enabled.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi,\n\nI am trying to deploy a model to ACI with SSL enabled in AML Studio that keeps hanging. I am able to successfully deploy the model without SSL but struggling to do so with SSL enabled. I am following the article:\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-web-service\n\nWe have purchased a domain and certificate (pem encoded) from a CA and updated our DNS as per the article. The certificate and key files have been uploaded to Azure Machine Learning Studio under the same folder as the register and deploy python script.\n\nThe following code in the register and deploy python script should set up the ACI Webservice. deployment configuration:\n\nfrom azureml.core.webservice import AciWebservice\n\naciconfig = AciWebservice.deploy_configuration(cpu_cores=2,\nmemory_gb=10,\ntags={\"x\": \"xx\", \"xxx\"},\ndescription=<some text>,\nauth_enabled=True,\nssl_enabled=True,\nssl_cert_pem_file=\"<name of cert file>\",\nssl_key_pem_file=\"<name of key file\",\nssl_cname=\"<domain>\")\n\nAll looks fine but then when running the following code to deploy the model, execution starts but the Jupyter kernel is just hanging, without providing much logging information:\n\n%%time\nfrom azureml.core.webservice import Webservice\n\nservice = Model.deploy(workspace=ws,\nname='<name>',\nmodels=[model],\ninference_config=inference_config,\ndeployment_config=aciconfig,\noverwrite = True)\n\nservice.wait_for_deployment(show_output=True)\n\nAfter a while of execution I eventually interrupt the kernel which suggests execution has stopped. However, when trying to deploy again it suggests that something is still running, forcing me to stop and restart the compute cluster. So something is still hanging in the background as a result of my deployment attempt.\n\nThe logs don't give much with the last line stating the following:\n2021-04-28 10:12:56,189 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n\nAny help would be much appreciated - thanks!",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure On-Demand ML cluster from a search in the data catalog",
        "Question_creation_time":1619209726297,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/369952\/azure-on-demand-ml-cluster-from-a-search-in-the-da.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":1,
        "Question_body":"I'm trying to implement a self-service solution in Azure so users can run a Jupyter or PySpark notebook on-Demand\/automatically with the dataset they found a search in the Azure Data Catalog. I visualize, once the user finds the data in a search, there will be a link that will take him\/her to a Notebook and the dataset can be used for analysis. Any suggestion would be very much appreciated!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-26T10:22:10.247Z",
                "Answer_score":0,
                "Answer_body":"@JairoMelo-1657 Thanks for the question.Azure Purview can find, understand, and consume data sources. Please follow the Azure Purview documentation: https:\/\/docs.microsoft.com\/en-us\/azure\/purview\/\n\nand We have Azure Open Datasets where you can download a Notebook for AML, Databricks or Synapse that explores the data: Azure Open Datasets Catalog | Microsoft Azure. What are open datasets? Curated public datasets - Azure Open Datasets | Microsoft Docs.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-04-28T11:51:31.093Z",
                "Answer_score":1,
                "Answer_body":"Thank you very much for your response. I'll look into Azure Purview. Best! J.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"how can i retrain the model after a period of time",
        "Question_creation_time":1619232734657,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/370080\/how-can-i-retrain-the-model-after-a-period-of-time.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hello everyone, i'm using lambda architecture to build a fraud detection project , i build my model using machine learning in databricks , after saving the model , i load the model in the speed layer to predict the incoming data, i want to know how can i retrain this model using new incoming data from eventhub ??\ndoes the retrain should be in the batch layer ?\nthanks for helping",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-27T06:45:34.227Z",
                "Answer_score":0,
                "Answer_body":"@NadineBenharrath-4116 Thanks, Please follow the document to retrain the model using the new data.\n\nCurrently Data Drift Monitor (Data Drift->EventGrid->LogicApp->Trigger Pipeline) allows to trigger a pipeline when dataset drift has been detected.\n\nPublic Repo of the architecture and code: https:\/\/github.com\/Microsoft\/MLOps",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-04-27T07:10:26.91Z",
                "Answer_score":0,
                "Answer_body":"@ramr-msft the problem that i trained my model using databricks and i tracked it with mlflow , i'm not using azure ML because my dataset is imbalanced ?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"azure ml designer: how to call a pipeline from another pipeline",
        "Question_creation_time":1619288778083,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/370433\/azure-ml-designer-how-to-call-a-pipeline-from-anot.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I'm using ML Designer and i have created a sub-pipeline that i want to use it in other pipelines. how do i call that sub-pipeline from the designer?\n\nThe purpose of the subpipeline is to transform data, so the output is a dataset.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-26T14:59:45.637Z",
                "Answer_score":0,
                "Answer_body":"@javier-8889Thanks for the question. Can you please add more details about the pipeline steps. You can implement an AML pipeline with Python code, but also with the new AML designer which under the covers is creating an AML Pipeline defining that \u201cvisual workflow\u201d. Basically you can register a trained model in Designer bring it out with SDK\/CLI to deploy it. Currently only Data Drift Monitor (Data Drift->EventGrid->LogicApp->Trigger Pipeline) allows to trigger a pipeline when dataset drift has been detected.\n\nWhen designing a pipeline in Azure ML Designer, each step or module creates intermediate datasets that can be seen using the UI using Visualize option. Those datasets are persisted in the blob storage.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure ML Studio and Git\/AzureDevOps",
        "Question_creation_time":1618340223767,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/355882\/azure-ml-studio-and-gitazuredevops.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"We have created an Azure ML Studio based proof of concept. I would like to get the \"source code\" into a source code repository. We use Git on AzureDevOps.\n\nI'm at a loss where to begin since the designer has no source files with which to interact. All of the project is point-and-click via the Designer. This is a ML project built following this tutorial: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-train-score\n\nWe've created our own models, data, etc and have a solution.\n\nWhat artifacts from an Azure ML Studio project should be included in a version control system? Where are these files located?\n\nThanks for any insight.\n\n-jeremiah",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-14T10:10:18.257Z",
                "Answer_score":0,
                "Answer_body":"@JeremiahAdams-0775 Thanks for the question. Can you share a snippet of how you are uploading to azure Devops?. Please follow this document: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-model-designer. Basically you can register a trained model in Designer bring it out with SDK\/CLI to deploy it. Just run az ml model download - that will get all of the files.\n\nAlso look at the MLOPs demo.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-04-14T10:18:18.573Z",
                "Answer_score":0,
                "Answer_body":"@JeremiahAdams-0775 Azure ML designer is designed to simplify the user interface of using machine learning modules as a drag and drop interface where users can train and create models which can be deployed as a service. The interface's backend which creates connections between modules or the experiments are available to view in the ml portal from the designer interface or from the run ids which are under experiments tab. These run details can be from different sources like automl, designer or simply runs created by using the azure ml SDKs. The runs from designer are always set with a tag of azureml.Designer: true which makes it easy to find the runs from a particular designer experiment. All the runs contain details of the metrics, logs, steps, etc. which can be viewed and can be downloaded as a notebook file. For example:\n\nYou can use these files under your version control but the run details are always available in your workspace under different run ids and you can add additional tags to these runs for managing them under your workspace.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"getting error 151",
        "Question_creation_time":1619442149707,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/371888\/getting-error-151.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Error writing to cloud storage: The remote server returned an error: (400) Bad Request.. Please check the url. . ( Error 0151 )\nwhen trying to export data frame from output port to blob storage as csv file from azure ML studio",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-26T16:07:47.717Z",
                "Answer_score":0,
                "Answer_body":"According to the offical tutorial Export to Azure Blob Storage, there are two authentication types for exporting data to Azure Blob Storage: SAS and Account. The description for them as below.\n\nFor Authentication type, choose Public (SAS URL) if you know that the storage supports access via a SAS URL.\n\n\nA SAS URL is a special type of URL that can be generated by using an Azure storage utility, and is available for only a limited time. It contains all the information that is needed for authentication and download.\n\n\nFor URI, type or paste the full URI that defines the account and the public blob.\n\n\nFor private accounts, choose Account, and provide the account name and the account key, so that the experiment can write to the storage account.\n\n\nAccount name: Type or paste the name of the account where you want to save the data. For example, if the full URL of the storage account is http:\/\/myshared.blob.core.windows.net, you would type myshared.\n\n\nAccount key: Paste the storage access key that is associated with the account.\n\n\n\n\nThis error in Azure Machine Learning occurs when the module tries to write data to cloud storage but the URL is unavailable or invalid.\n\nResolution Check the URL and verify that it is writable.\n\nException Messages\n\nError writing to cloud storage (possibly a bad url).\nError writing to cloud storage: {0}. Please check the url.\n\nBased on the error description above, the error should be caused by the blob url with SAS incorrectly generated by the Export Data module code with account information. May I think the code is old and not compatible with the new V2 storage API or API version information. You can report it to feedback.azure.com.\n\nHowever, I switched to use SAS authentication type to type a blob url with a SAS query string of my container which I generated via Azure Storage Explorer tool as below, it works fine.\n\n1: Right click on the container of your Blob Storage account, and click the Get Shared Access Signature\n\n2: Enable the permission Write and click Create button\n\n\n\n\n3: Copy the Query string value, and build a blob url with a container SAS query string like https:\/\/<account name>.blob.core.windows.net\/<container name>\/<blob name><query string>\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"ModuleExceptionMessage:ModuleOutOfMemory: Memory has been exhausted, unable to complete running of module.",
        "Question_creation_time":1619357291613,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/370636\/moduleexceptionmessagemoduleoutofmemory-memory-has.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hi, I am getting the error from the subject line when i try to inner join a dataset of 850K rows and 3 columns (parquet data file of around 4mb) with another with 300K rows and 10 columns (parquet data file is about 1mb). I'm using Azure ML Studio Designer\n\nMy compute is Standard Dv2 Family vCPUs (20% of utilization).\n\nI was surprised by this hitting a limit. Any idea on how i should proceed?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-26T13:37:13.763Z",
                "Answer_score":0,
                "Answer_body":"i manage to do this by trainning the model in a subset of records (using the Sample model).\n\nAlso noted that the documentation implies that an out of memory error is dependant on the RAM of the client \/ Designer user machine not the compute selected (or at least that is my understanding of the note at the beginning of the doc)",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Test data after deploying model",
        "Question_creation_time":1619200443810,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/369813\/test-data-after-deploying-model.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hello,\n\nWe are deploying our model built locally to Azure Machine Learning resource. The model was successfully registered and deployed.\n\nWe are now trying to test the model but keeping getting different errors such as:\n\n Traceback (most recent call last):\n   File \"MLMain.py\", line 248, in <module>\n     test = bytes(test, encoding='utf8')\n\nand\n\n TypeError: encoding without a string argument\n Inference result = float() argument must be a string or a number, not 'dict'\n\n\n\nOur MLMain.py looks like:\n\n ........\n    \n print('************ REGISTER MODEL ******\\n')\n     model = run.register_model(model_name='TempModel',\n                        tags={'Temp': 'SelfTrainingClassifier'},\n                        model_path='outputs\/TempModel.pkl')\n     print(model.name, model.id, model.version, sep='\\t')\n        \n     print('************ DEPLOY MODEL ******\\n')\n     service_name = 'test123'\n     #aks_target = AksCompute(workspace,\"testCompute\")\n     deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, \n                                                            memory_gb = 1)\n        \n     #env.python.conda_dependencies.add_pip_package(\"inference-schema[numpy-support]\")\n     #env.python.conda_dependencies.save_to_file(\".\", \"myenv.yml\")\n     inference_config = InferenceConfig(entry_script=\".\/TempModel\/score.py\",\n                                    environment=env)\n            \n     service = Model.deploy(workspace, service_name, [model], inference_config, deployment_config)\n     service.wait_for_deployment(show_output = True)\n     print(service.state)\n     print(service.scoring_uri)\n        \n        \n     print('*********** TEST MODEL *****\\n')\n     test = {\n     \"data\":   [[177,44]]\n     }\n        \n     test = bytes(test, encoding='utf8')\n     y_hat = service.run(input_data=test)\n\n\n\n\nThe score.py looks like:\n\n def run(data):\n     try:\n         data = np.array(json.loads(data))\n         result = model.predict(data)\n         # You can return any data type, as long as it is JSON serializable.\n         return result.tolist()\n     except Exception as e:\n         error = str(e)\n         return error\n\n\n\nWhen we run the model locally we are able to predict on:\n\n loaded_model = pickle.load(open('self_training_model5.pkl', 'rb'))\n    \n result = loaded_model.predict([[177,89]])\n\n\n\n\nAny ideas would be great.\nThanks so much!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-24T06:30:13.933Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThe cause of the TypeError encoding without a string argument is that we're telling bytes to encode a variable into a bytes object, and it's expecting a string as input. So let's do a simple check.\n\n if isinstance(test, bytes):\n     test = test\n else:\n     test = bytes(test,'utf-8')\n\n\n\nHope this helps.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is it possible to do machine learning in Azure IoT Central?",
        "Question_creation_time":1618360709993,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/356183\/is-it-possible-to-do-machine-learning-in-azure-iot.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I was wondering if it is possible to do machine learning on Azure IoT central. I read in some places that it is possible to do so in Azure IoT Edge. I saw a template for Video Analytics but cannot seem to find a way to implement my own models. If Edge is the only way to perform machine learning in Azure IoT, is there some way to use IoT Edge with IoT Central? Or, is it possible to train your own Tensorflow Lite Models with Raspberry Pi and just host the Pi in IoT Hub? If both are possible, which of the two would be the easiest?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-14T16:12:08.863Z",
                "Answer_score":1,
                "Answer_body":"@KC-6678 it looks like you are having great challenges ahead :)!\n\nTo your main question, the direct answer is yes you can use Machine Learning in conjunction with an Azure IoT Central Solution which ingests data from an Azure IoT Edge device previously trained by your own Tensorflow Lite Models.\n\nThe bigger question is how do you want to do it and what are the current constraints you have + when do you want the actionable decisions coming from your connected device sensors to be made?\n\nMy advice is that you follow one of our Learning paths or Modules, for example:\n\nAI edge engineer\n\n\nIdentify anomalies by routing data via IoT Hub to a built-in ML model in Azure Stream Analytics\n\nYou will learn how to use a trained model and clearly distinguish when you need an ML model running in the Edge vs in the Cloud.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to create batch inference Pipline for forecasting model using AutoML",
        "Question_creation_time":1618831327213,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/362632\/how-to-create-batch-inference-pipline-for-forecast.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hi everyone,\n\nI am beginner for Azure auto ML. So I deployed the Forecasting Model Using Auto ML notebooks, Now I am trying to creating the Batch Inference Pipeline using ML my best Forecasting Model. please help me how can I create the Batch Inference Pipeline for forecasting model . please refer me Any doc to me.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-19T19:46:19.34Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. Please review evaluate step of this sample tutorial. Hope this helps!",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"\"Explanation_dataTransform: e.every is not a function\" Error AutoML Explanation Preview",
        "Question_creation_time":1619105132597,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/367955\/34explanation-datatransform-eevery-is-not-a-functi.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Although child run of the explanation is completed successfully, we are not able to see the explanation preview. We would appreciate if you could help us.\n\nBest regards,\n\nCagatay Topcu",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Why does my pipeline take so long to run?",
        "Question_creation_time":1618607050577,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/360906\/why-does-my-pipeline-take-so-long-to-run.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi\n\nI am trying out the free subscription of MS Azure. I am running a Machine learning pipeline and it seems to take a very long time to run. My input datasource is an excell spreadsheet of only 50 rows and just the 'select columns in dataset' component takes 3 or 4 minutes to complete. The same thing (as in the step that converts the spreadsheet to a pandas dataframe and selects the columns for the dependent and independent variables) takes a matter of seconds when I run it in Google Colab. Why does MS Azure take so much longer to run?\n\nThanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-18T02:25:01.69Z",
                "Answer_score":0,
                "Answer_body":"better have a check what is in that excel, sometimes there are some \"blank\" rows there?",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Separate data in data explorer and use as datastore",
        "Question_creation_time":1619036349177,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/366532\/separate-data-in-data-explorer-and-use-as-datastor.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"Hello,\n\nWe are sending data from IoT Central to Event Hubs and then to Data Explorer, with the hopes of then sending the data to Azure Machine Learning.\n\nIn order to send data from Event Hubs to Data Explorer it needs a data ingestion into a table on data explorer.\n\nFor this data ingestion, it needs a json mapping.\n\nWe could ingest the data, but the message from the iot central data goes to event hubs that goes to data explorer carries the telemetry data as a dynamic type (a json inside a json).\n\n (\"telemetry\":{\"Temp:\"37\",\"Vol\":\"97\"})\n\n\n\n\nWe want to separate the telemetry data in different columns.\n\nSo Temp will have one column and Vol another.\n\nI am wondering how that can be done?\n\nAnd additionally, since we would like to send the data to ML, can data explorer be used as a datastore in ML?\n\nThanks!!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-22T08:36:44.29Z",
                "Answer_score":1,
                "Answer_body":"Hello @yjay-4307,\n\nYou can use parse operator - Evaluates a string expression and parses its value into one or more calculated columns. The calculated columns will have nulls, for unsuccessfully parsed strings.\n\nFor more details, refer SO thread addressing similar issue.\n\nUnfortuantely, Azure Data Explorer is not a supported storage solution with Azure Machine Learning.\n\nDatastores currently support storing connection information to the storage services listed in the following matrix.\n\nFor unsupported storage solutions, and to save data egress cost during ML experiments, move your data to a supported Azure storage solution.\n\nReference: Connect to storage services on Azure - Azure Machine Learning.\n\nHope this helps. Do let us know if you any further queries.\n\nPlease don\u2019t forget to Accept Answer and Up-Vote wherever the information provided helps you, this can be beneficial to other community members.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"slowness of azure ml cloud compute",
        "Question_creation_time":1618714586367,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/361307\/slowness-of-azure-ml-cloud-compute.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I am doing a speed comparison test between my machine and azure ml cloud compute. My PC is 8 cores with 64 GB RAM. The compute instance I created on azure is \"Standard_D14_v2 (16 cores, 112 GB RAM, 800 GB disk)\". One test I did was to run a XGBoost model and it took about 1h15m locally. On the cloud, it took 1h45m. I thought I would have a better performance with the instance created on azure. Could someone explain to me why I saw the opposite? Thank you so much!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-19T06:01:13.52Z",
                "Answer_score":0,
                "Answer_body":"@XrLi23-3087 One factor that could effect while running your experiment on Azure ML is the setup time of the compute while running the experiment. Normally, compute is setup run time when the experiment run is initiated to avoid costs of running compute when not required. In this case the difference is still 30 minutes which is large and the setup usually takes few minutes depending on the availability of compute and region you are using.\n\nAnother factor could be the settings used in the experiment, since you are using the SDK or designer the default settings might be set for some configurations for optimization. If these settings are not changed then these might slow down the run time of the experiment, depending on your configuration these settings can be reviewed to check if there is a possibility to optimize it further.\n\nIf the above scenarios do not help we would recommend to raise a support issue to check what could be causing slowness in your workspace. Thanks.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Train Split clarification in Automated ML",
        "Question_creation_time":1618754770423,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/361456\/train-split-clarification-in-automated-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"In Azure automated ML experiment: 30,000 rows:\nIn Additional configurations -> Validation -> Validation Type\n\nWhen selecting Auto, which 10% of the dataset is taken for validation?\na. The first 10% of the dataset?\nb. The last 10% of the dataset?\nc. Random 10% of the dataset?\n\nWhen selecting Train-validation split, which X% of the dataset is taken for validation?\na. The first X% of the dataset?\nb. The last X% of the dataset?\nc. Random X% of the dataset?\n\nIf none of the answers is b, how can I run an automated ML experiment with a specified Train dataset and another totally separate validation dataset that was prepared beforehand?\n\nThanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-19T07:43:48.32Z",
                "Answer_score":0,
                "Answer_body":"@superrichmann-5996 I think in both the scenarios the dataset will be random. Please see the following page for details as there is no option to select the first or last % for dataset of >20000\n\nWith the SDK there is an option to provide custom cross validation folds based on column names. I think this may help.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to add r2 and adj r2 metric in linear regression model - AzureML Studio?",
        "Question_creation_time":1618843927707,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/362850\/how-to-add-r2-metric-in-linear-regression-model-az.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I have trained a linear regression model in AzureML studio which was created in designer as pipeline.\n\nI could not able to see R square and adj-R square metric in Evaluate Model step.\n\nCould any throw thoughts how can I add these 2 metrics to my trained model\n\n\n\n\n\n\n\n\n\nThanks\nBhaskar",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-20T00:19:19.74Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nSorry for the confusing. Actually, Coefficient of determination, often referred to as R2, represents the predictive power of the model as a value between 0 and 1. Zero means the model is random (explains nothing); 1 means there is a perfect fit. However, caution should be used in interpreting R2 values, as low values can be entirely normal and high values can be suspect in Azure Machine Learning Designer.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/evaluate-model#metrics-for-regression-models\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"error: assertation failed, dataset empty?",
        "Question_creation_time":1617618683170,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/344326\/error-assertation-failed-dataset-empty.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I'm using automl from the interface to make a time series forecast.\nWhen I launch the experiment, after 10\/15 minutes I get the following issue:\n\nEncountered an internal AutoML error. Error Message\/Code: InvalidOperationException. Additional Info: InvalidOperationException:\nMessage: Assertion Failed. Invalid Operation. Target: X. Reference Code: 04504092-88e9-11ea-bdbb-04d3b0c6010a. Details: Dataset input was empty, resulting in empty validation set\nInnerException: None\nErrorResponse\n{\n\"error\": {\n\"message\": \"Assertion Failed. Invalid Operation. Target: X. Reference Code: 04504092-88e9-11ea-bdbb-04d3b0c6010a. Details: Dataset input was empty, resulting in empty validation set\",\n\"target\": \"X\",\n\"reference_code\": \"04504092-88e9-11ea-bdbb-04d3b0c6010a\"\n}\n}\n\nBut my dataset isn't empty.\nI can provide more informations if needed.\nAny idea on how to fix that?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-05T18:28:11.14Z",
                "Answer_score":0,
                "Answer_body":"Okay, there might be something wrong with your configuration. Can you try this sample experiment to determine if you experience the same issue? Otherwise, we'd need a way to reproduce the issue you've described. Please let us know if sample experiment works for you. Also, please note, if your data is behind a virtual network, you need to enable the skip the validation function to ensure that the workspace can access your data. Looking forward to your feedback, thanks.",
                "Answer_comment_count":7,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"can not install opendp.smartnoise in Azure ML",
        "Question_creation_time":1618600497387,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/360860\/can-not-install-opendpsmartnoise-in-azure-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I am using Azure ML via jupyter notebook Python 3.8 - AzureML and Standard_D2s_v3 as computing power\nI want to apply differential privacy via opendp according to official tutorials. Hovewer When I try to install it I have an error\n\n!pip install opendp-smartnoise\n\n\nfrom opendp.smartnoise.metadata import CollectionMetadata\nfrom opendp.smartnoise.sql import PandasReader, PrivateReader\nimport opendp.smartnoise.core as sn\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError Traceback (most recent call last)\n<ipython-input-15-29fe0b8b627f> in <module>\n1 get_ipython().system('pip install opendp-smartnoise')\n2\n----> 3 from opendp.smartnoise.metadata import CollectionMetadata\n4 from opendp.smartnoise.sql import PandasReader, PrivateReader\n5 import opendp.smartnoise.core as sn\n\n\nModuleNotFoundError: No module named 'opendp'",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"VM Environment Fails Because It Cannot Find ipkernal Module",
        "Question_creation_time":1618545455163,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/359692\/vm-environment-fails-because-it-cannot-find-ipkern.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"I have created a python script using Azure SDK to train a machine learning model and save an output .csv file. I created a python environment with all of the conda and pip dependencies needed to run the script and registered that environment to the workspace. However, when I go to run my script using the registered environment my experiments keep failing. The error message in the log that I cannot figure out states that the script fails because it cannot find the 'ipykernal' module when trying to import matplotlib. Here is the full text of error message:\n\n[2021-04-15T22:52:41.716160] The experiment failed. Finalizing run...\n[2021-04-15T22:52:41.716178] Start FinalizingInRunHistory\n[2021-04-15T22:52:41.717507] Logging experiment finalizing status in history service.\nStarting the daemon thread to refresh tokens in background for process with pid = 22305\nCleaning up all outstanding Run operations, waiting 300.0 seconds\n1 items cleaning up...\nCleanup took 0.07227706909179688 seconds\nTraceback (most recent call last):\nFile \"prod_model.py\", line 5, in <module>\nimport matplotlib.pyplot as plt\nFile \"\/home\/azureuser\/.azureml\/envs\/azureml_1525a6aa7633563e0d590fe86701d51d\/lib\/python3.7\/site-packages\/matplotlib\/pyplot.py\", line 2356, in <module>\nswitch_backend(rcParams[\"backend\"])\nFile \"\/home\/azureuser\/.azureml\/envs\/azureml_1525a6aa7633563e0d590fe86701d51d\/lib\/python3.7\/site-packages\/matplotlib\/pyplot.py\", line 221, in switch_backend\nbackend_mod = importlib.import_module(backend_name)\nFile \"\/home\/azureuser\/.azureml\/envs\/azureml_1525a6aa7633563e0d590fe86701d51d\/lib\/python3.7\/importlib\/init.py\", line 127, in import_module\nreturn _bootstrap._gcd_import(name[level:], package, level)\nModuleNotFoundError: No module named 'ipykernel'\n\n[2021-04-15T22:52:42.232402] Finished context manager injector with Exception.\n\n\n\n\n\nI have tried to import ipykernal as both a conda and pip package when creating the environment, but neither method is able to find the ipykernal package when I try to run the environment creation code. I have even tried to include the exact same version of every package that I have downloaded on my local machine (where the code runs without errors).\n\nIf anyone has any thoughts as to how to resolve this issue, I'd love to hear them. Thanks in advance for any help you can provide.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-19T02:35:25.91Z",
                "Answer_score":1,
                "Answer_body":"UPDATE - I was able to resolve this issue by adding the ipykernal package as a dependency when building the python environment for my VM to run. The key was to load the ipykernel package into the environment before loading matplotlib - if I tried to load matplotlib first, it resulted in an error.\n\nThanks for your help!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Model Explanation Run Error: Object of type 'Timestamp' is not JSON serializable",
        "Question_creation_time":1618588503547,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/360712\/model-explanation-run-error-object-of-type-39times.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"All my model explanation run have following error. (For different data, algorithm, model,...)\n\n\n\n\nEncountered an internal AutoML error. Error Message\/Code: ClientException. Additional Info: ClientException:\nMessage: Object of type 'Timestamp' is not JSON serializable\nInnerException: None\nErrorResponse\n{\n\"error\": {\n\"message\": \"Object of type 'Timestamp' is not JSON serializable\"\n}\n}\n\nI would appreciate if you could help me to solve",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"ML.NET support CUDA 11",
        "Question_creation_time":1618583468453,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/360545\/mlnet-support-cuda-11.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Loading model from: F:\\V2Sorter\\DataSet\\03.01.2021\\imageClassifier_2.zip\n2021-04-16 16:06:33.457209: I tensorflow\/core\/common_runtime\/gpu\/gpu_device.cc:1720] Found device 0 with properties:\npciBusID: 0000:03:00.0 name: GeForce RTX 3080 computeCapability: 8.6\ncoreClock: 1.905GHz coreCount: 68 deviceMemorySize: 10.00GiB deviceMemoryBandwidth: 707.88GiB\/s\n2021-04-16 16:06:33.458465: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n2021-04-16 16:06:33.459114: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\n2021-04-16 16:06:33.459639: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\n2021-04-16 16:06:33.460164: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\n2021-04-16 16:06:33.460705: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\n2021-04-16 16:06:33.461270: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\n2021-04-16 16:06:33.461946: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\n2021-04-16 16:06:33.462589: I tensorflow\/stream_executor\/platform\/default\/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\n2021-04-16 16:06:33.463409: I tensorflow\/core\/common_runtime\/gpu\/gpu_device.cc:1862] Adding visible gpu devices: 0\n2021-04-16 16:06:33.464111: I tensorflow\/core\/common_runtime\/gpu\/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n2021-04-16 16:06:33.464830: I tensorflow\/core\/common_runtime\/gpu\/gpu_device.cc:1267] 0\n2021-04-16 16:06:33.465221: I tensorflow\/core\/common_runtime\/gpu\/gpu_device.cc:1280] 0: N\n2021-04-16 16:06:33.465788: I tensorflow\/core\/common_runtime\/gpu\/gpu_device.cc:1406] Created TensorFlow device (\/job:localhost\/replica:0\/task:0\/device:GPU:0 with 7745 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:03:00.0, compute capability: 8.6)\nException thrown: 'System.EntryPointNotFoundException' in Microsoft.ML.Vision.dll\ndevice is disconnected\nException thrown: 'System.IO.FileNotFoundException' in mscorlib.dll\nException thrown: 'System.IO.FileNotFoundException' in mscorlib.dll\nThe thread 0x2f80 has exited with code 0 (0x0).\n\nI'm using \"SciSharp.TensorFlow.Redist-Windows-GPU\" with CUDA 2.4.0 support but get the exception \"Exception thrown: 'System.EntryPointNotFoundException' in Microsoft.ML.Vision.dll\"\nwhat could be the problem?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-16T19:06:11.1Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us. But the tag azure-machine-learning is not the right tag for ML.NET. I have added the right tag for it and also there is another good forum in gitter as well: https:\/\/gitter.im\/dotnet\/mlnet?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Filter blob storage data and send to Machine Learning",
        "Question_creation_time":1617134052800,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/338053\/filter-blob-storage-data-and-send-to-machine-learn.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":14,
        "Question_score":0,
        "Question_body":"Hi,\n\nAs a kind of continuation of my previous question: Send data from IoT central to Azure Machine Learning Resource\nI am wondering how I can filter my data to send to Machine Learning. I have multiple devices that are exporting data from IoT Central to Azure Blob Storage, I am wondering how I can filter the data for each device so I can send to a Machine Learning model?\n\nAdditionally, do I need to create multiple ML models for each device or can I send all filtered data to the same model? (For ex. If I have 5 devices collecting temperature data and I want to predict if the device user has a cold, I want to use the same model that predicts colds but I want to predict separately for each user based on their data)\n\nThanks so much!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-31T10:19:14.807Z",
                "Answer_score":0,
                "Answer_body":"@yjay-4307\n\nI am wondering how I can filter my data to send to Machine Learning. I have multiple devices that are exporting data from IoT Central to Azure Blob Storage, I am wondering how I can filter the data for each device so I can send to a Machine Learning model?\n\nYou can add filters to reduce the amount of data exported. There are different types of filter available for each data export type:\n\nTo filter telemetry, you can:\n\nFilter the exported stream to only contain telemetry from devices that match the device name, device ID, and device template filter condition.\n\n\nFilter over capabilities: If you choose a telemetry item in the Name dropdown, the exported stream only contains telemetry that meets the filter condition. If you choose a device or cloud property item in the Name dropdown, the exported stream only contains telemetry from devices with properties matching the filter condition.\n\n\nMessage property filter: Devices that use the device SDKs can send message properties or application properties on each telemetry message. The properties are a bag of key-value pairs that tag the message with custom identifiers. To create a message property filter, enter the message property key you're looking for, and specify a condition. Only telemetry messages with properties that match the specified filter condition are exported. The following string comparison operators are supported: equals, does not equal, contains, does not contain, exists, does not exist. Learn more about application properties from IoT Hub docs.\n\n\n\n\nAdditionally, do I need to create multiple ML models for each device or can I send all filtered data to the same model? (For ex. If I have 5 devices collecting temperature data and I want to predict if the device user has a cold, I want to use the same model that predicts colds but I want to predict separately for each user based on their data)\n\nI am enquiring at the moment and will update you with my findings.",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Manually deploy azureml docker image to app service",
        "Question_creation_time":1614951059587,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/300934\/manually-deploy-azureml-webservice-endpoint-to-app.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":13,
        "Question_score":1,
        "Question_body":"I am trying to deploy an Azure ML webservice endpoint to an app service. I prefer to use an app service instead of ACI or AKS endpoints, because an app service has the benefit of scaling and deploying SSL certificates, withouth having to maintain and setup a fully secured AKS cluster. ACI is not advised to use in a production environment.\n\nThe docker image I am trying to deploy is the same docker image produced with ACI or AKS deployment. To do so I ran 'az model deploy' command for an ACI endpoint, which builds and packages all resources needed for the endpoint into an Docker image stored in ACR. I set up an app service which pulls this docker image from an ACR. Copying the startup command runsvdir \/var\/runit and azureml environment variables from a working ACI example should give an working webservice endpoint as app service. Unfortunately, I am struggling with an error that the azureml-app directory could not be found, which contains the model, model code and model execution scripts.\n\n 2021-03-05T08:38:53.803756130Z 2021-03-05T08:38:53,786438768+00:00 - gunicorn\/run \n 2021-03-05T08:38:53.806168222Z .\/run: line 13: cd: \/var\/azureml-app: No such file or directory\n\n\n\nPulling the docker image from the ACR and inspecting manually indeed confirmed there is no \/var\/azureml-app directory. But connecting to the ACI and inspecting the running container has a directory \/var\/azureml-app. For me it's not clear when this folder and data is pulled into the image\/container. I would expect during 'az ml deploy' command which builds tjhe docker image, but clearly this is not the case. This is the only thing preventing me from having a working app service, does anyone have an idea how to solve this?\n\nMore info about the docker image build by AzureML Docker Image AzureML",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-08T05:34:13.947Z",
                "Answer_score":0,
                "Answer_body":"@KuikenPhilipvan-5195 Thanks for the question. We can perform local inference, If we use Model.deploy to deploy the model, SDK won\u2019t attach the azureml-app folder to the image. Therefore, if we pull the image from ACR and docker run your image locally, you have to place at least your score.py and model.pkl under azureml-app and use the below example command to start the container:\n\ndocker run -dit -p 5001:5001 -e AZUREML_MODEL_DIR=azureml-models\/<model_name>\/<version> -e AZUREML_ENTRY_SCRIPT=score.py --mount src=\"<local_filepath>\",target=\/var\/azureml-app,type=bind <image_id> runsvdir \/var\/runit",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-04-15T17:24:44.717Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nI am also interested in doing local inference. I have made an inference docker image using the SDK, following this guide https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-local. Though I want to run the inference just using the docker image. Your command above:\n\ndocker run -dit -p 5001:5001 -e AZUREML_MODEL_DIR=azureml-models\/<model_name>\/<version> -e AZUREML_ENTRY_SCRIPT=score.py --mount src=\"<local_filepath>\",target=\/var\/azureml-app,type=bind <image_id> runsvdir \/var\/runit\n\nI dont fully understand, what is the point of the --mount and what should be inputted for <local_filepath>. Also it's so hard to find documentation on this. Is there somewhere in the Azure docs which describes the above command for running the docker image for inference?\n\nAny help is much appreciated, ;).",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"ServicePrincipalAuthentication no longer working in Databricks",
        "Question_creation_time":1618246743070,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/354148\/serviceprincipalauthentication-no-longer-working-i.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi all.\n\nI've had this problem for MONTHS now and, not having the option to give up, I'm getting desperate.\n\nI have a databricks set up where an azure file-share is mounted, and this is used to extract data and read it into a database. Up until Monday it was been working fine.\n\nRecently, although nothing has changed about the way the drive is mounted (via Azure ML libraries):\n\nsp = ServicePrincipalAuthentication(tenant_id=\"x\", # tenantID service_principal_id=\"y\", clientId service_principal_password=\"z\")\n\nclientSecret ws = Workspace.get(name=\"wsname\", auth=sp, subscription_id=\"a\")\n\nListing the contents of a directory suddenly takes an enormous amount of time to finish (50 minutes), before no longer being able to find the folder. Essentially, it repeatedly tries to switch back to interactive authentication before failing altogether, saying [Errno22]: Invalid Argument.\n\nimport os\n\nfolder = \"\/mnt\/tmp\/xx\/a\/b\/c\"\n\npatient_names = os.listdir(\"\/mnt\/tmp\/xx\/a\/b\/c\") print(patient_names)\n\nI'm lost, is there anywhere I should be looking to try and find out what's wrong?\n\nIt works fine using Interactive authentication and WAS working with SPA, but suddenly does not.\nI've tried:\n\n\n\n\n\nRecreating the datastore and dataset in ML\n\n\nCreating new databricks clusters on which to run the code.\n\n\nCreating another service principal\n\n\nRunning the code on my windows work machine with Pycharm and Python 3.7\n\n\nCreating an Ubuntu environment with Pycharm and Python 3.7\n\n\nCreating a new machine learning environment\n\n\nRunning the code with the python logging module to see if anything useful has come back.\n\n\nTrying several different versions of azureml-sdk[databricks]\n\n\nTrying yet another service principal.\n\nNothing has worked. I don't understand how\/why service principals are suddenly being ignored, why there are no error messages or useful information of any kind, or how nobody else has come across this problem?\n\nPlease can someone help?\n\nThank you.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Error while trying to run data",
        "Question_creation_time":1604177052600,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/147105\/error-while-trying-to-run-data.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"i am new on Azure ML and trying to get familiar.i imported my data from the Web URL via HTTP. i tried running but it cant be completed as it keeps giving me Error 0030 , error while downloading the file , error 0039, error while completing operations.\nkindly help ou as i cant proceed",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-02T15:54:20.51Z",
                "Answer_score":0,
                "Answer_body":"@feyi-4924 Thanks for the question, Please share the steps that you performed, Also please share the web url to check. Here are the samples to work with the data.\n\nConnect data to UI:https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-connect-data-ui",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-04-14T18:41:10.61Z",
                "Answer_score":0,
                "Answer_body":"I come across the same issues as the person above in a similar environment. The URL: https:\/\/docs.google.com\/spreadsheets\/d\/1kIQlTMT871e9REV5UABr-PTcCJ-6BMb7TteMxYBOYeo\/pub?gid=1225723766&single=true&output=csv. I use always comes back as failed with the 0030 error. When I create the experiment, I drag the import data in. Then I change the data source to HTTP. Next I paste the URL into the source URL box. After that I connect a summarize box under the import data box to attempt to see the results but each time I run it, I always fail.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Where are the variables quotients after doing a regression run in ML?",
        "Question_creation_time":1617200123477,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/339422\/where-are-the-variables-quotients-after-doing-a-re.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Having done my first Azure ML Studio session, the presented output metrics are global (Spearman, Explained variance, etc) are somewhat secondary to my requirement of knowing how each of my hundreds of variables have contributed to these. But I cannot find them. I would appreciate some guidance to where such numbers are - I know they have to be somewhere, as they (in total) provide the shown metrics.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure Machine learning and attached compute instance",
        "Question_creation_time":1617888515360,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/349518\/azure-machine-learning-and-attached-compute-instan.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":15,
        "Question_score":0,
        "Question_body":"Hello,\nMy initial one-month free credits have expired and I registered my credit card. In the first year there are several free resources which can be used free of charge for a limited capacity.\nI have created a Standard B2s (2 vcpus, 4 GiB memory) VM and a Machine Learning resource in the same resource group.\nI have successfully attached this VM to the ML computing resources as you can see on the photo:\n\nHowever whether in the notebook part if I create a new notebook or in the pipeline part if I create a new pipeline I can't select this attached compute resource to be the compute target.\n\nCan you please help how to manage this situation?\nI am in the learning phase of Azure ML and I would like to use the free resource until I have enough experience to create the production pipeline.\nThanks in advance",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-09T08:24:08.453Z",
                "Answer_score":0,
                "Answer_body":"@PetzTams-5415 From the screen shot above you seem to have created an attached compute which is primarily compute that is not managed by Azure ML. This type of compute needs additional steps to be used by your experiments in the workspace.\n\nIn your scenario to use the notebook and designer experiments you need to create a compute instance from the compute instance tab for the notebook. This type of compute allows a notebook to pickup a kernel and run Jupyter notebooks on cloud with some extended capabilities.\n\nFor designer experiments with compute and inference scenarios the compute clusters and inference clusters are used as part of the experiment or the pipeline that is deployed from these experiments. All these types of compute are managed from Azure ML workspace so you have the ability to use them for different experiments and scale them down to 0 when not required or stop the compute for notebooks.\n\nYou can utilize free resources for all the above scenarios since Azure ML only charges for the compute and other resources that are created as part of your experiments. I would recommend to delete the attached compute that is already created and use the compute instance for notebook if you are new to Azure ML. I hope this helps.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AssertError:read can not have position excceed buffer length",
        "Question_creation_time":1618316417143,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/355512\/asserterrorread-can-not-have-position-excceed-buff.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hi i am getting following error when trying to predict using externally generated R xgboost model in azure ML studio\n\nError 0063: The following error occurred during evaluation of R script:\n---------- Start of error message from R ----------\nAssertError:read can not have position excceed buffer length",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-13T16:22:15.963Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. There might be a conflict between versions of xgboost. Can you confirm that version used to create the model is <=0.90?",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"NOTEBOOK TERMINAL AZURE",
        "Question_creation_time":1618331988847,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/355752\/notebook-terminal-azure.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I COPIED AND PASTED, pip install -r requirements.txt --user --upgrade UNDER MY NOTEBOOK TERMINAL IN AZURE. IT STARTED LAUNCHING BUT LAPTOP SHUTDOWN. I RESTARTED IT, TRIED COPYING AND PASTING THE ABOVE LINK, BUT NOW IT GIVES THE MESSAGE BELOW. HELP PLEASE.\n\nRequirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in \/anaconda\/envs\/azureml_py38\/lib\/python3.8\/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->-r requirements.txt (line 32)) (3.1.0)",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Convert to tabular from file dataset",
        "Question_creation_time":1617956083027,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/350780\/convert-to-tabular-from-file-dataset.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Yesterday I ran the \u2018consume\u2019 code to pull the data onto the cluster and it seemed to work but I still can\u2019t use it from ML designer as it\u2019s a file dataset rather than a tabular dataset. I\u2019ve tried a couple of ways of converting it without success, my next avenue of exploration is to use the SDK rather than trying to do it through the console",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-09T20:14:35.61Z",
                "Answer_score":0,
                "Answer_body":"Hi, Designer only supports tabular dataset, hence you'd need to use SDK to work with file dataset. Based on the documentation, there's no method for converting file dataset to tabular dataset. Is your file in csv format? Perhaps you can create a datastore and connect to your blob storage. Then, use the import data module in designer to connect to your datastore(data path in blob storage). You can also create tabular dataset from datastore. Let me know if you have further questions, thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning Studios Deploy Model - Obtain logs",
        "Question_creation_time":1618204695277,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/353046\/azure-machine-learning-studios-deploy-model-obtain.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I am attempting to deploy a model to an Endpoint in MS Azure Machine Learning studio but I get some errror.\n\n2 Questions\n1) How can we get the logs for a deployed model (See my attempts below)\n2) How do models get loaded into the docker images as I suspect for some reason it didn't get copied into the docker image.\n\n\n\n\nStep 1) Upload the model: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-existing-model\n\n\nWhich is successful. I can see and download that my model is correct.\n\nStep 2) Deploy to Azure Container Instances: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-container-instance\n\nI use this code snippet to deploy my code\n\n from azureml.core.model import InferenceConfig\n from azureml.core.webservice import AciWebservice\n from azureml.core.webservice import Webservice\n from azureml.core.model import Model\n from azureml.core.environment import Environment\n    \n script_file_name = 'inference\/score.py'\n    \n inference_config = InferenceConfig(entry_script=script_file_name, environment=tf_env)\n    \n aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n                                                memory_gb = 1, \n                                                tags = {'iris': \"rh1832\", 'type': \"sklearn\"}, \n                                                description = 'sample service for iris')\n    \n aci_service_name = 'rh1832-iris-demo'\n print(aci_service_name)\n aci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)\n aci_service.wait_for_deployment(True)\n print(aci_service.state)\n\n\n\nAnd my score.py inference script looks like\n\n # ---------------------------------------------------------\n # Copyright (c) Microsoft Corporation. All rights reserved.\n # ---------------------------------------------------------\n import json\n import logging\n import os\n import pickle\n import numpy as np\n import pandas as pd\n import joblib\n    \n try:\n     logger = logging.getLogger('azureml.automl.core.scoring_script')\n except:\n     pass\n    \n    \n def init():\n     global model\n     model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'sklearn_model')\n     path = os.path.normpath(model_path)\n     path_split = path.split(os.sep)\n     logger.info(\"Loading model from path.\")\n     model = joblib.load(model_path)\n     logger.info(\"Loading successful.\")\n    \n    \n def run(data):\n     try:\n         target_names = ['database', 'network', 'resource']\n         result = model.predict([data])\n         return json.dumps(target_names[result[0]])\n     except Exception as e:\n         print(\"error: \" + str(e))\n         result = str(e)\n         return json.dumps({\"error\": result})\n\n\n\n\nAfter submitting the webservice to be deployed i get an error that just says its in crashloopbackoff state with no details for which part of the script failed.\n\n\nStep 3) I attempted to debug the logs by follow this guide: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-troubleshoot-deployment?tabs=azcli#dockerlog\n\n1) Running script locally which I was able to successfully run score.py\n2) Running docker image locally I didn't see the model in the folder azureml-environment-setup in the docker container:\n\nroot@09e7230839e3:\/azureml-environment-setup# ls\nenvironment_context.json log4j.properties mutated_conda_dependencies.yml send_conda_dependencies.py spark_cache.py\n\nand also i didn't see the entrypoint for running the docker container. Is there any guide for running the docker image locally?\n\n3) Finally I attempted to get the logs using Azure CLI and it only return an Null list it appeared",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-12T08:15:59.617Z",
                "Answer_score":0,
                "Answer_body":"You can try https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Can't disable a scheduled pipeline endpoint",
        "Question_creation_time":1618002234640,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/351921\/can39t-disable-a-scheduled-pipeline-endpoint.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hello,\nI scheduled my pipeline to run weekly. Now I want to disable it. However, when I disable on Azure ML Studio, an error shows as below:\n\nAn error occurred while disabling pipeline\nBadRequest: Cannot deprecate a pipeline with active schedules.\n\nTrace ID : cded492c-84a5-47aa-afc4-0a678e611e5b\nClient request ID : 4e904a8b-90f5-4572-815d-c23a0249c43b\n\nCould you look into this? and instruct me how to stop that scheduled pipeline.\nThanks,",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-09T23:13:45.673Z",
                "Answer_score":1,
                "Answer_body":"Hello,\n\nThanks for reaching out to us.\n\nIf you have a Pipeline that is published, but not scheduled, you can disable it with:\n\n\n\n pipeline = PublishedPipeline.get(ws, id=pipeline_id)\n pipeline.disable()\n\n\n\nIf the pipeline is scheduled, you must cancel the schedule first. Retrieve the schedule's identifier from the portal or by running:\n\n\n\n ss = Schedule.list(ws)\n for s in ss:\n     print(s)\n\n\n\n\nOnce you have the schedule_id you wish to disable, run:\n\n\n\n def stop_by_schedule_id(ws, schedule_id):\n     s = next(s for s in Schedule.list(ws) if s.id == schedule_id)\n     s.disable()\n     return s\n stop_by_schedule_id(ws, schedule_id)\n\n\n\nIf you then run Schedule.list(ws) again, you should get an empty list.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Does compute cluster & Endpoints costs if we dont delete after use ?",
        "Question_creation_time":1617894953567,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/349617\/does-compute-cluster-amp-endpoints-costs-if-we-don.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":1,
        "Question_body":"Hi,\n\nI'm aware that running compute Instance costs us for the number of hours we used. So, we stop it when ever we don't need it.\n\nSimilarly, does compute cluster & Endpoints also costs us if we do not delete them after use?\n\n\n\n\nThanks\nBhaskar",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-08T15:33:31.617Z",
                "Answer_score":5,
                "Answer_body":"Hi @Bhaskar11-9991\n\nWhen a compute cluster is idle, it autoscales to 0 nodes, so you don't pay when it's not in use. A compute instance is always on and doesn't autoscale. You should stop the compute instance when you aren't using it to avoid extra cost.\nrefer - https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-compute-target\n\n\n\n\nIf the Answer is helpful, please click Accept Answer and up-vote, this can be beneficial to other community members.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Paste into a .ipynb notebook",
        "Question_creation_time":1617916645243,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/349979\/paste-into-a-ipynb-notebook.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I have a created .ipynb file but I can't seem to be a able to paste copied code into the cells.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-08T23:25:09.293Z",
                "Answer_score":0,
                "Answer_body":"Hi, I'm not able to reproduce this issue. I have the following questions:\n\nIs this relating to Azure ML Notebook?\n\n\nCan you try opening the notebook in Jupyter?\n\n\nCan you try a different browser (private browsing)?\n\n\nRight click > paste option instead?\n\n\nAre you trying to paste from a particular source, can you try another source?",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Deployment Failed: Microsoft.MachineLearningServices Internal service error",
        "Question_creation_time":1617654155327,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/344946\/deployment-failed-microsoftmachinelearningservices.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I am trying to deploy an Azure ML workspace with the Azure portal, no matter what settings I choose I get an Internal service error on creation of the workspace, all the other resources deploy without issues. Is there a way to debug this with a better error message?\n\n\n\n {\n     \"status\": \"Failed\",\n     \"error\": {\n         \"code\": \"InternalServerError\",\n         \"message\": \"InternalServerError\"\n     }\n }",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-07T15:43:15.157Z",
                "Answer_score":0,
                "Answer_body":"Following-up. Are you still experiencing the above error? If so, please follow the steps here to provide more details about the error. Alternatively, you can raise a support request or use the feedback \"smiley\" button at the top in Azure portal to submit feedback. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Files in gitignore are not excluded in snapshot created by ML pipeline",
        "Question_creation_time":1617897599523,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/349783\/files-in-gitignore-are-not-excluded-in-snapshot-cr.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"I'm trying to run a pipeline (built via Python SDK), and I want the repo to be snapshotted, because the different modules are called inside the pipeline scripts. The source folder I pass to the pipeline has the following structure:\n\nrepo\n- src\n- data\n- script_step1.py\n- script_step2.py\n- script_step3.py\n- .gitignore\n\n\n\n\nI want the data folder to be ignored in the snapshot, so in my gitignore file I have al line with written \/data\/*, but when I try to run the pipeline I get an error that tells me that the snapshot is too big (I checked the size of the other stuff except for data folder and it is very little)\nI'm not understanding why that happens.\nThanks a lot in advance",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure ML Hyperdrive",
        "Question_creation_time":1617723280093,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/346257\/azure-ml-hyperdrive.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"When running the hyperdrive step, I would like to get the hyper parameters that were selected for the best model and export them to use in a subsequent model. How would I got about doing that? I saw a method get_hyperparameters but from what I can tell that just gets all child runs. I am essentially wanting to use the same model but change alpha levels.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-06T21:26:11.18Z",
                "Answer_score":0,
                "Answer_body":"Hello.\n\nI think below is what you are looking for. Could you please take a look?\n\nOnce all of the hyperparameter tuning runs have completed, identify the best performing configuration and hyperparameter values:\n\n best_run = hyperdrive_run.get_best_run_by_primary_metric()\n best_run_metrics = best_run.get_metrics()\n parameter_values = best_run.get_details()['runDefinition']['Arguments']\n    \n print('Best Run Id: ', best_run.id)\n print('\\n Accuracy:', best_run_metrics['accuracy'])\n print('\\n learning rate:',parameter_values[3])\n print('\\n keep probability:',parameter_values[5])\n print('\\n batch size:',parameter_values[7])\n\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Why can't a label the rest of my set?",
        "Question_creation_time":1616799706400,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/333975\/why-can39t-a-label-the-rest-of-my-set.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Can anyone suggest why I can't label the rest of my pending images??\n\nSee screenshot for example..\n\n\n\n\n\n\nRegards,\nChris",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure machine learning designer - edit columns stuck on loading",
        "Question_creation_time":1617486098190,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/343332\/azure-machine-learning-designer-edit-columns-stuck.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":12,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Azure machine learning designer :\n\nI have a dataset on the designer connected to a Normalize data module but it keeps loading when i try to Edit columns on Normalize data module with no result or errors.\nThe same thing happens with Select columns in dataset module.\n\nI have tried to recreate and restart and even deleted the whole resource group but no luck.\nI tried on both mac and windows with different browsers but still getting stuck on the same place.\n\nany idea on how to solve this issue?\n\nThanks!\n\nScreenshot:\nhttps:\/\/i.imgur.com\/P0oWrGR.png",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-06T12:14:07.023Z",
                "Answer_score":1,
                "Answer_body":"@AyushBhardwaj-4354 @yazeenjasim-8837 @AnshulSharma-6861 This issue is now fixed in all regions and it does not require an additional parameter to be added to the URL. Please try and let us know if it works fine.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Get transformation function inside entry script",
        "Question_creation_time":1617723042437,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/346270\/get-transformation-function-inside-entry-script.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hello everyone,\n\ni am currently getting into Azure Machine Learning. I am trying out the learning path for Data Scientists. In that learning path, the Designer is introduced, where Pipelines are being published to be consumed as a real time inference pipeline.\n\nSince I dont want to use the Designer all the time I want to do the same in python and convert the tutorial inference pipeline (here: https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/inference-pipeline) to a python script for deployment. For that I am refering to the learning path on how to deploy a model (here: https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/register-and-deploy-model-with-amls\/2-deploy-model).\n\nMy current issue is that in the designer inference pipeline the transformation steps seem to get a transformation function to transform new incoming data based on the transformation that was done during training. The ressources in the azure documentation do not explain anywhere on how to retrieve this function from a training pipeline to do the same transformation in an entry script using python.\n\nI would be happy if you could help me with this issue since I am eager to learn and use Azure Machine Learning in the future.\nBest regards and Thank you.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"After selecting the \"Edit column\" button of the \"Select Columns in Dataset\" module in Designer, it will be stuck in the \"loading\" state.",
        "Question_creation_time":1617523186537,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/343427\/after-selecting-the-34edit-column34-button-of-the.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":7,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hello everyone!\n\nI am taking the Create a Regression Model with Azure Machine Learning designer course in Microsoft Learn. When I perform the steps in the Explore Data section, after selecting the \"Edit column\" button of the \"Select Columns in Dataset\" module in Designer, it will be stuck in the \"loading\" state. Therefore, I cannot proceed to the next step.\n\n\n\n\n\nThank you very much!\n\nBest regards,\nLing",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-06T12:12:52.38Z",
                "Answer_score":1,
                "Answer_body":"@KaiXiuGao This issue is now fixed in all regions and it does not require an additional parameter to be added to the URL. Please try and let us know if it works fine.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Group Categorical Values in Azure ML Designer",
        "Question_creation_time":1615818855177,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/315002\/group-categorical-values-in-azure-ml-designer.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hello,\nis there any possibility to do the same in Azure ML Studio designer as it is able in Azure ML Studio? I need to group categorical values, but in Azure ML Studio designer there option for Group Data into Bins. When I am trying to do it by chosing custom edges, it does not seem to work with data column which is categorical.\n\nEDIT\nI have rating 1-5, and I would like to make it in from 1-2-3-4-5 to 1-5. When creating bins I only can get categorized as 1 and 2.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-05T07:34:31.703Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nWe are sorry that have not heard from you. Azure ML Designer officially supports Group data into Bins with custom edge. I have highlighted the essential part below.\n\nAdd the Group Data Into Bins module to your pipeline in the designer. You can find this module in the category Data Transformation.\n\n\n\n\nConnect the dataset that has numerical data to bin. Quantization can be applied only to columns that contain numeric data.\n\nIf the dataset contains non-numeric columns, use the Select Columns in Dataset module to select a subset of columns to work with.\n\nSpecify the binning mode. The binning mode determines other parameters, so be sure to select the Binning mode option first. The following types of binning are supported:\n\nQuantiles: The quantile method assigns values to bins based on percentile ranks. This method is also known as equal height binning.\n\nEqual Width: With this option, you must specify the total number of bins. The values from the data column are placed in the bins such that each bin has the same interval between starting and ending values. As a result, some bins might have more values if data is clumped around a certain point.\n\nCustom Edges: You can specify the values that begin each bin. The edge value is always the lower boundary of the bin.\n\nFor example, assume you want to group values into two bins. One will have values greater than 0, and one will have values less than or equal to 0. In this case, for bin edges, you enter 0 in Comma-separated list of bin edges. The output of the module will be 1 and 2, indicating the bin index for each row value. Note that the comma-separated value list must be in an ascending order, such as 1, 3, 5, 7.\n\nNote\n\nEntropy MDL mode is defined in Studio (classic) and there's no corresponding open source package which can be leveraged to support in Designer yet.\n\nIf you're using the Quantiles and Equal Width binning modes, use the Number of bins option to specify how many bins, or quantiles, you want to create.\n\n\n\n\nFor Columns to bin, use the column selector to choose the columns that have the values you want to bin. Columns must be a numeric data type.\n\nThe same binning rule is applied to all applicable columns that you choose. If you need to bin some columns by using a different method, use a separate instance of the Group Data into Bins module for each set of columns.\n\nWarning\n\nIf you choose a column that's not an allowed type, a runtime error is generated. The module returns an error as soon as it finds any column of a disallowed type. If you get an error, review all selected columns. The error does not list all invalid columns.\n\nFor Output mode, indicate how you want to output the quantized values:\n\nAppend: Creates a new column with the binned values, and appends that to the input table.\n\nInplace: Replaces the original values with the new values in the dataset.\n\nResultOnly: Returns just the result columns.\n\nIf you select the Quantiles binning mode, use the Quantile normalization option to determine how values are normalized before sorting into quantiles. Note that normalizing values transforms the values but doesn't affect the final number of bins.\n\n\n\n\n\nThe following normalization types are supported:\n\nPercent: Values are normalized within the range [0,100].\n\nPQuantile: Values are normalized within the range [0,1].\n\nQuantileIndex: Values are normalized within the range [1,number of bins].\n\nIf you choose the Custom Edges option, enter a comma-separated list of numbers to use as bin edges in the Comma-separated list of bin edges text box.\n\n\n\n\nThe values mark the point that divides bins. For example, if you enter one bin edge value, two bins will be generated. If you enter two bin edge values, three bins will be generated.\n\nThe values must be sorted in the order that the bins are created, from lowest to highest.\n\nSelect the Tag columns as categorical option to indicate that the quantized columns should be handled as categorical variables.\n\n\n\n\nSubmit the pipeline.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Train model fail \/ error",
        "Question_creation_time":1615749764870,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/313505\/train-model-fail-error.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Hello, when I create a model and try to train it, it always fails. The same model on different two compute targets are these:\n\nAzureMLCompute job failed. UserProcessKilledBySystemSignal: Job failed since the user script received system termination signal usually due to out-of-memory or segfault. Reason: Process Killed with either 6:aborted or 9:killed or 11:segment fault. exit code here is from wrapping bash hence 128 + n Cause: killed TaskIndex: NodeIp: 10.0.0.4 NodeId: tvmps_2b4c1352eab879faa7df6dd68985461ea7ef172338311bc4bd278f1c7c66b3ad_d Reason: Job failed with non-zero exit Code\n\n\nAmlExceptionMessage:AzureMLCompute job failed. JobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details. Reason: Job failed with non-zero exit Code ModuleExceptionMessage:InvalidTrainingDataset: Dataset contains invalid data for training. Learner type: Binary classifier. Reason: The number of label classes should equal to 2, got 5 classes.\n\n\nAzureMLCompute job failed. JobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details. Reason: Job failed with non-zero exit Code",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-15T10:18:29.553Z",
                "Answer_score":1,
                "Answer_body":"@Laimis-8077 Thanks for the question. Can you please add more details about the steps that you performed and compute cluster details to check.\nCan you please confirm are you using the AML Studio Designer to train the model?\nIs the AML storage account restricts access to specific VNETs and the Compute Cluster isn\u2019t in that VNET?\n\nAlso please confirm did you change your Default storage account key?\n\nYou can Update storage account key with below command.\nChange storage account access keys - Azure Machine Learning | Microsoft Docs\naz ml workspace sync-keys -w myworkspace -g myresourcegroup",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Auto ML forecasting - dependent variables",
        "Question_creation_time":1613448096113,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/274229\/azure-auto-ml-forecasting-dependent-variables.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":1,
        "Question_body":"Hi, I am trying to use Azure auto ML for forecasting. The dataset has a date_time column, a target variable and other columns that affect the target variable. I have deployed the model as a web service. But I am finding it hard to use the service\/model for forecasting future frames. Let's say I need to forecast for the next 4 hours (data frequency is 5 minutes), but the model is asking for other column inputs as well. Can you please help me to resolve this?\nTIA,\nRajesh",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-16T16:33:58.797Z",
                "Answer_score":0,
                "Answer_body":"@RajeshkumarMourya-0547 Thanks for the question. Can you please add more details about the use case that you are trying. Here is the docs\/samples for Automated ML forecasting enables businesses to forecast revenue, inventory, sales, or customer demand. Customers can run Automated ML experiments by using a no-code UI experience or a code-first Python SDK experience and sample Jupyter Notebooks depending on their expertise.\nDocumentation: HTTPS:\/\/AKA.MS\/AUTOMLFORECAST",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Using \"cv_splits_indices\" in AutoMLConfig",
        "Question_creation_time":1614846003803,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/298513\/using-34cv-splits-indices34-in-automlconfig.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"When training an regression model with AutoMLConfig with n_cross_validations being a normal int, I'm facing no problems.\n\nNow I want to use TimeSeriesSplit as the cross validation method for training a model with AutoMLConfig. For this there is a \"cv_splits_indices\" argument where I put in a list of lists of indicis like the following when n_splits=5 in TimeSeriesSplit :\n\n\n\n array([[array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n         array([11, 12, 13, 14])],\n        [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n         array([15, 16, 17, 18])],\n        [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n        17, 18]),\n         array([19, 20, 21, 22])],\n        [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n        17, 18, 19, 20, 21, 22]),\n         array([23, 24, 25, 26])],\n        [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n        17, 18, 19, 20, 21, 22, 23, 24, 25, 26]),\n         array([27, 28, 29, 30])]], dtype=object)\n\n\n\nUnfortunately when running the following cell:\n\n automl_settings = {\n     \"iteration_timeout_minutes\": 15,\n     \"experiment_timeout_hours\": 0.3,\n     \"max_cores_per_iteration\" : -1,\n     \"enable_early_stopping\": True,\n     \"primary_metric\": 'normalized_root_mean_squared_error',\n     \"featurization\": 'auto',\n     \"verbosity\": logging.INFO,\n     \"cv_splits_indices\": idxs\n }\n    \n automl_config = AutoMLConfig(task='regression',\n                              debug_log=f'automated_ml_errors_.log',\n                              training_data=train,\n                              validation_data=train,\n                              label_column_name=y_var,\n                              **automl_settings)\n\n\n\nI receive the following error:\n\n ConfigException: ConfigException:\n  Message: cv_splits_indices should be a List of List[numpy.ndarray]. Each List[numpy.ndarray] corresponds to a CV fold and should have just 2 elements: The indices for training set and for the validation set.\n  InnerException: None\n  ErrorResponse \n {\n     \"error\": {\n         \"code\": \"UserError\",\n         \"message\": \"cv_splits_indices should be a List of List[numpy.ndarray]. Each List[numpy.ndarray] corresponds to a CV fold and should have just 2 elements: The indices for training set and for the validation set.\",\n         \"details_uri\": \"https:\/\/aka.ms\/AutoMLConfig\",\n         \"target\": \"cv_splits_indices\",\n         \"inner_error\": {\n             \"code\": \"BadArgument\",\n             \"inner_error\": {\n                 \"code\": \"ArgumentInvalid\"\n             }\n         },\n         \"reference_code\": \"XXXXXXREDACTEDXXXX\"\n     }\n }\n\n\n\nWhat is going wrong here? My input looks correct?\n\nThank you",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-04T14:48:46.463Z",
                "Answer_score":0,
                "Answer_body":"@BrianBarbieri-1018 Thanks for the question. Can you please add more details about the azure ML SDK version.\nHere is the doc for cross validation data folds.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AML AKS - Failed to Pull Image",
        "Question_creation_time":1617400984927,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/342829\/aml-aks-failed-to-pull-image.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"We are using a preview future from AKS to stop our cluster with our real-time inference cluster.\n\nFrom time to time when we start the Cluster we wait to all of the services get ready but some of the pods stay without starting. Today researching about this issue in the logs we saw this error:\n\nFailed to pull image\n\"viennaglobal.azurecr.io\/azureml\/azureml_d401b6211d79af733a3b055ae6394****\n\n\n\n\n\nSome of our models that are deployed to this AKS are created and deployed with AML Designer and endpoint publisher\n\nIf i'm not wrong this image is an AML \"base\" image and it is not ours. I saw all of our suscription container registry and i cannot see a registry with this endpoint or even an image with this ID.\n\nIs this a \"public\" AML repository? Is this container registry repository available or it has some problem on it?\n\nThanks",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Production Web API pricing",
        "Question_creation_time":1617359262120,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/342374\/production-web-api-pricing.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hello everyone,\n\nI'd like to try AutoML and deploy a machine learning model and consume it as a web service in an application.\n\nCan please someone explains more about Production Web API pricing just the Dev\/Test version.\n\nI would be most grateful if you could provide a documentation link that can guide me through the above.\n\nYour help will be highly appreciated.\n\nThank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-02T18:37:12.067Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. This document provides detailed information on how to plan and manage cost for AML. You can also use the pricing calculator to estimate costs. Also, please refer to our pricing document. Let us know if you have additional questions. Hope this helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How do I get started predictive Maintanance using Machine Learning?",
        "Question_creation_time":1617360731433,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/342399\/how-do-i-get-started-predictive-maintanance-using.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Give me a brief description of the predictive maintenance using machine learning.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-02T17:29:51.977Z",
                "Answer_score":0,
                "Answer_body":"Hi, if your question is with regards to Azure ML, here's our official documentation.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"What syntax references Pipeline parameters in the where clause of a SQL query of 'Import Data' modules in Microsoft Azure Machine Learning designer?",
        "Question_creation_time":1616787456817,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/333816\/what-syntax-references-pipeline-parameters-in-the.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I have created a pipeline in Microsoft Azure Machine Learning designer. I have added a Pipeline parameter myNumber in the pipeline settings, with a valid default value, to accept the unique ID of the asset in our DB so that the pipeline can return only the asset-specific data for use as our model input. Specifically I want to reference that pipeline parameter in the where clause of the SQL query in the 'Import Data' module that connects to our Azure SQL server.\n\nI cannot find a reference in the documentation on how to do this. I have tried the methods specified for accomplishing this task in Azure Data Factory, using where RowId = @pipeline().parameters.myNumber or where RowId = @{variables('myNumber')} but the experiment fails with SqlException error code '137', variable not defined.\n\nCan you please tell me the necessary syntax to reference Pipeline parameters in the where clause of a SQL query of 'Import Data' modules of Microsoft Azure Machine Learning designer?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-31T17:14:50.84Z",
                "Answer_score":0,
                "Answer_body":"Hi, designer does not support referencing pipeline parameters in sql query of \"Import Data\". However, you can write a one-line sql query and set the whole \"database query\" parameter as pipeline parameter as shown below. Hope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-03-31T17:32:04.787Z",
                "Answer_score":0,
                "Answer_body":"Thank you for replying and the suggestion, GiftA-MSFT.\n\nI would not feel comfortable having an endpoint which accepts a wildcard query as a pipeline parameter as that sounds like a major security violation. Is there really no way at all to inject Pipeline parameters into the query? If that's the case, it sounds like the pipeline were only designed to use static data, which makes sense for training a model, but not for preprocessing input to be passed to a trained model that is deployed to an endpoint.\n\nIs there a different Azure tool I should be using to create dynamic \"Input Data\" pipelines for preprocessing prior model scoring?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Model training \"canceled\" on Microsoft Azure",
        "Question_creation_time":1616758467970,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/333336\/model-training-34canceled34-on-microsoft-azure.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Frequently while training Machine Learning models on Azure, the loss and accuracy output freezes half way through training. A \"canceled\" message in red is appearing the notebook cell. However, the kernel is still displaying a \"busy\" message.\n\nI am paying for a GPU and this is making the service unusable for me as I don't know if the model is training correctly.\n\nIt appears that I have to pay for technical support to register a ticket. What a joke!!!",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"web app model deployment",
        "Question_creation_time":1616240230297,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/323724\/web-app-model-deployment.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"I am deploying my prediction model as web app for first time in Azure through github actions step.\nI can see the deployment process is successful in github actions window. When I browse my app from azure window, it is not connecting to my web app. There is some issue. but the app is up & running.\n\nmy subscription id - 06facb88-7723-4e1e-82cd-774f082c46d5\n\nAttached is the sample images.\n\n\n\n\n[1]: \/answers\/storage\/attachments\/79718-1.png\n\n[2]: \/answers\/storage\/attachments\/79719-2.png\n\n[3]: \/answers\/storage\/attachments\/79720-3.png",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-22T10:07:54.367Z",
                "Answer_score":0,
                "Answer_body":"@23174178 Thanks for the question. Can you please add more details about the prediction model that you are trying and error details to check. Can you please confirm are you using the Designer?\n\nCurrently App Service and Azure functions(preview) as deployment target via Azure ML is currently documented as a recipe to facilitate the model packaging story for customers with affinity to Web Apps. Please follow the doc to deploy to Azure App services and doc on choosing Inference compute target here (AKS for real-time and AMLCompute for batch).",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AZURE ML - Web Service",
        "Question_creation_time":1616267169727,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/323764\/azure-ml-web-service.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"How to configure the input fields with drop down values from the experiment. Eg: if car make is a field, the input field for the car make should start showing options when you start entering.\n\n\nList item\n\nIn the below example, fuel field should show drop down values like, diesel, petrol etc. ![79842-image.png][1] [1]: \/answers\/storage\/attachments\/79842-image.png",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-22T12:37:47.683Z",
                "Answer_score":0,
                "Answer_body":"@LizRay-1175 Thanks for the question. Can you please add more details about the steps that you performed. Please follow this document to deploy with designer and consume the real time endpoint.: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-model-designer? Basically you can register a trained model in Designer bring it out with SDK\/CLI to deploy it.\n\nSharing a reference notebook from Nicholas Moore: https:\/\/github.com\/nfmoore\/aml-designer-iot-edge\/blob\/main\/00-containerize-designer-model.ipynb.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning Data Labelling - Zoom broken on prelabelled tasks??",
        "Question_creation_time":1616185580847,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/323305\/azure-machine-learning-data-labelling-zoom-broken.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":1,
        "Question_body":"My dataset now has enough samples to start pre-labeling a set of labels (bounding boxes for image identification).\n\nHowever, rather worryingly this seems fundamentally broken?\nWe appear to have lost the ability to zoom the image (zoom just appears to zoom the bounding boxes, and not the underlying image) which basically makes this entire functionality useless.\n\nAm I missing something or is this feature completely broken?\nI hope the former, as the pre-labeling was a significant factor in choosing this platform.\n\nWe have tried multiple browsers in case this was a browser issue but to no success, they all present the same issue.\n\nIs anyone able to advise??",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-22T07:27:35.64Z",
                "Answer_score":0,
                "Answer_body":"@ChrisH-5786 Thanks for the question. Can you please share image and snapshot for the same. We are able to zoom the underlying image using the data labeling.\n\nPlease follow the doc to Tag images and specify bounding boxes for object detection.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Conda environment locked by another AzureML job",
        "Question_creation_time":1611713493223,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/246501\/conda-environment-locked-by-another-azureml-job.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":7,
        "Question_score":2,
        "Question_body":"I tried to run an experiments. There was an error in my first submit and the run did not go through. However, a lock has been created which is preventing me from submitting further runs. I am getting the following error.\n\n\"The conda environment is currently locked by another AzureML job. Further job submission will wait until the other process finishes. If there are no other jobs running, please delete \/home\/azureuser\/.azureml\/locks\/azureml_conda_lock\"\n\nI tried to use:\naz ml run cancel -r exp_id\n\nin CLI. However, this gives me an error:\nError, default experiment not set and experiment name parameter not provided.\\nPlease provide a value for the experiment name parameter.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-27T12:23:43.017Z",
                "Answer_score":0,
                "Answer_body":"@KanyanLawrence-5964 Thanks for the question. Could you please add more details about the steps\/link to the code that you are trying.\nHere is the doc to configure and submit training runs.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-set-up-training-targets#persistent",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Does ML Studio\/Designer\/AutoML support Natural Language Processing?",
        "Question_creation_time":1615905694633,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/316809\/does-ml-studiodesignerautoml-support-natural-langu.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":4,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hey everyone,\nI think Microsoft doesn't explicitly state this anywhere so I was wondering if I can create models (via AutoML or via the manual designer) using datasets containing text in natural language (such as a couple sentences, paragraphs etc.). AutoML doesn't really indicate that it can process paragraphs using NLP anywhere.\nThere are Text Analytics features in the designer and I heard about Azure AutoML's BERT support so I suppose it should be possible but I just wanted to make sure.\nRight now I can upload such dataset and create a classification model based on it but I don't know if it treats these cells containing paragraphs just as one long string and doesn't do anything or if it actually processes the individual words etc.\nCould anyone let me know, please? And if it does support NLP, what can I do besides classification? Can it do sentiment analysis, entity extraction etc.?\n\nThanks a lot!\n\n(I don't see a tag for AutoML or the designer, that's why I tagged the classic Studio.)",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-17T11:16:24.56Z",
                "Answer_score":0,
                "Answer_body":"@YutongTie-5848 (For whatever reason the reply button doesn't work for me, that's why I posted it this way.)\n\nWell, let's say it's an email classification. So you got a .csv file where you have the text of an e-mail in one column and its class in the other column. Example could be:\n\"Click here to win $1000.\",spam\n\"Hey, how are you?\",normal\n\"Hello, PFA pictures.\",normal\n\nThis is just an example with the text of the e-mails being just one sentence but you can imagine e-mails can be longer (like a paragraph or even more). You obviously can't treat a paragraph of text (like here) the same way you would treat a classification with the text being just one word.\n\nI saw the e-mail classification (and other similar ones) being done in Azure AI gallery (https:\/\/gallery.azure.ai\/Experiment\/Email-Classification-for-Automated-Support-Ticket-Generation-Step-1-of-2-Train-and-Evaluate-Models-3) but that's in the studio\/designer, not AutoML.\n\nMy expected result is classification but I wanted to know if AutoML can do other common tasks where NLP is used (named-entity recognition, sentiment analysis etc.).\n\nWhen I choose the featurization settings, I see that there is a \"Text\" option as a feature type but one word is probably also \"Text\". So I'm asking if AutoML processes long strings in a different way.\n\nI know there is the API but I would like to create models specifically via AutoML (or designer but preferably AutoML) for now.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-03-22T19:39:06.593Z",
                "Answer_score":0,
                "Answer_body":"@MicroMe-4183\n\nHello,\n\nHere is a list of the samples we have right now. https:\/\/github.com\/Azure\/MachineLearningNotebooks\/tree\/master\/how-to-use-azureml\/automated-machine-learning\n\nI see the first three scenarios are very similar to yours. Could you please check if that fits your scenario?\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning Services - AutoMl - Error running experiment.submit: \"\/anaconda\/envs\/azureml_py36\/lib\/libxgboost.so: undefined symbol: XGDMatrixSetDenseInfo\"",
        "Question_creation_time":1616170731780,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/322886\/azure-machine-learning-services-automl-error-runni.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hello,\n\nI created a notebook in the workspace and when I sent the experiment for training I received error message undefined symbol: XGDMatrixSetDenseInfo for algorithm Xgboost. Do you know how to fix the problem?\n\n\n\n\nAzure ML Version: 1.22.0\nCompute Instance: Standard_DS3_v2\n\nCode:\n\nimport logging\nfrom azureml.train.automl import AutoMLConfig\nfrom azureml.core.experiment import Experiment\n\nautoml_settings = {\n\"iteration_timeout_minutes\": 10,\n\"experiment_timeout_hours\": 0.3,\n\"enable_early_stopping\": True,\n\"primary_metric\": 'normalized_root_mean_squared_error',\n\"featurization\": 'auto',\n\"verbosity\": logging.INFO,\n\"n_cross_validations\": 5\n}\n\nautoml_config = AutoMLConfig(task='regression',\ndebug_log='automated_ml_errors.log',\ntraining_data=x_train,\nlabel_column_name=\"production_time\",\n**automl_settings)\n\nexperiment = Experiment(ws, \"train-model\")\nlocal_run = experiment.submit(automl_config, show_output=True)\n\nFull Error Message:\n\n\n\n\nERROR: FitException:\nMessage: \/anaconda\/envs\/azureml_py36\/lib\/libxgboost.so: undefined symbol: XGDMatrixSetDenseInfo\nInnerException: AttributeError: \/anaconda\/envs\/azureml_py36\/lib\/libxgboost.so: undefined symbol: XGDMatrixSetDenseInfo\nErrorResponse\n{\n\"error\": {\n\"code\": \"SystemError\",\n\"message\": \"Encountered an internal AutoML error. Error Message\/Code: FitException. Additional Info: FitException:\\n\\tMessage: \/anaconda\/envs\/azureml_py36\/lib\/libxgboost.so: undefined symbol: XGDMatrixSetDenseInfo\\n\\tInnerException: None\\n\\tErrorResponse \\n{\\n \\\"error\\\": {\\n \\\"message\\\": \\\"\/anaconda\/envs\/azureml_py36\/lib\/libxgboost.so: undefined symbol: XGDMatrixSetDenseInfo\\\",\\n \\\"target\\\": \\\"Xgboost\\\",\\n \\\"reference_code\\\": \\\"Xgboost\\\"\\n }\\n}\",\n\"details_uri\": \"https:\/\/docs.microsoft.com\/azure\/machine-learning\/resource-known-issues#automated-machine-learning\",\n\"target\": \"Xgboost\",\n\"inner_error\": {\n\"code\": \"ClientError\",\n\"inner_error\": {\n\"code\": \"AutoMLInternal\"\n}\n},\n\"reference_code\": \"Xgboost\"\n}\n}\n\n\n\n\n\nBest regards,\nCristina\n\n\n\n\n\n\n\n\n79658-packages.txt",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-19T23:29:59.997Z",
                "Answer_score":0,
                "Answer_body":"Hi, can you try uninstalling and reinstalling Xgboost (try versions <= 0.90 if you continue to get errors).",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Secure Azure Machine Learning REST Endpoints (deployed in ACI) with TLS",
        "Question_creation_time":1615991231360,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/318807\/secure-azure-machine-learning-rest-endpoints-deplo.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"We have developed and deployed machine learning models in AML Studio. The models were deployed using ACI and we have REST endpoints that we can make calls to successfully. Next thing that I need to do is to secure the endpoints using TLS. I am going through the following article:\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-web-service#enable\n\nThe article suggests that I need to get a domain and then update our DNS point to the IP address of scoring endpoint. I have a subdomain ready to use but as for the IP address, I can't work out where I would get the IP address of the scoring endpoint and how I would even be able to map this to the endpoint as the current endpoint do not contain and IP address and look nothing like the example in the article.\n\nURIs currently look like the following:\nhttp:\/\/xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxx.northeurope.azurecontainer.io\/score\n\nAnyone able to help with this one please as it's a little confusing and I can't find any guidance online anywhere?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-18T03:31:43.613Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nYou can do it according to DNS.\n\nA \u201cURL\u201d is a full specification to a page. For example:\n\nhttp:\/\/example.com\/this_is_example.html is a URL. It has three parts:\n\nThe protocol specifier: http:\n\nThe domain name: example.com\n\nThe page location: \/this_is_example.html\n\nThe protocol specifies the port that will be used. http, for example, is\nport 80. ftp uses ports 20 and 21. SMTP, the mail sending protocol, is usually\non port 25. You can actually find the full list of \u201cofficial\u201d ports here.\n\nIt\u2019s only the domain name that has an IP address associated with it. So that\u2019s what you would be looking up.\n\nMy approach is to use the \u201cping\u201d command in a Windows command prompt. For\nexample:\n\nC:\\>ping example.com\n\nThen you can get it.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Data Import error for Azure table storage to Azure ML studio ?",
        "Question_creation_time":1616070530733,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/320696\/data-import-error-for-azure-table-storage-to-azure.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi Team,\n\nI tried connecting to Azure table storage in Azure ML Studio. It shows connection successful after updating all credentials but after hitting run, import is landing to internal system error.\nBelow is the message :\n[Critical] Error: Sorry, it seems that you have encountered an internal system error. Please contact amlforum@microsoft.com with the full URL in the browser and the time you experienced the failure. We can locate this error with your help and investigate further. Thank you.\n\nRequesting you to please assist in this case.\n\nRegards,\nSachin",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-22T06:53:02.957Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThere is a known issue that Azure ML Studio only supports \u201chttp\u201d protocol when connecting with Azure Storage Account. You might hit this issue when using the Import Data module.\n\n\n\n\nHere is a quick work around:\nPlease check the \u201cConfiguration\u201d of your Storage Account, and make sure the \u201cSecure transfer required\u201d is disabled (see the figure below).\n\nIf still encountering error after taking these steps, please double check and make sure the account key is correct.\n\n@SachinGaikwad-5400 Please accept the answer if you feel the work around works. Thank you!\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Unable to creata a compute instance",
        "Question_creation_time":1616247083753,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/323742\/unable-to-creata-a-compute-instance.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I'm trying to follow the steps given here - https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/explore-analyze-data-with-python\/2-exercise-explore-data\n\nI've tried regions east us2 and east us for creating the instance but it fails after taking more than half an hour. I tried virtual machine sizes - Standard_DS11_v2 & Standard_DS3_v2.\n\nAny help would be appreciated.\n\nEdit - I don't have any other instances running in my subscription, so it should not be a quota issue. The error message says \"An internal server error occurred.\".",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-20T23:14:19.877Z",
                "Answer_score":0,
                "Answer_body":"Good day @AatishSuman-7641\n\nDid you read the comment in the compute page?\n\nPlease confirm that you are using an account which fit the limitations\n\nFor more information please check this post:\n\nhttps:\/\/azure.microsoft.com\/en-us\/blog\/update-2-on-microsoft-cloud-services-continuity\/\n\nNote: I followed the tutorial which you provided the link to and it is working well for me. Therefore, I assume the issue is related to the above comment.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-03-20T13:46:48.237Z",
                "Answer_score":0,
                "Answer_body":"Hi @AatishSuman-7641\nThank You for posting in Q & A.\n\nPlease verify in azure portal you have Quota available for this virtual machine sizes - Standard_DS11_v2 & Standard_DS3_v2.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/azure-resource-manager\/templates\/error-resource-quota#solution\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/networking\/check-usage-against-limits\n\nCan you share exact error message so that we can have more information to provide a solution.\n\n\n\n\nIf the Answer is helpful, please click Accept Answer and up-vote, this can be beneficial to other community members.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AML Tutorials on Docs.Microsoft",
        "Question_creation_time":1616289490963,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/324003\/aml-tutorials-on-docsmicrosoft.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"These tutorial files are out of sync on the docs vs. the notebooks? Is this intentional?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-21T03:53:42.943Z",
                "Answer_score":0,
                "Answer_body":"On every docs.microsoft document page, you should see below like option which you can use to submit the feedback which are monitored by support and product team\n\n\n\n\n\nPlease don't forget to Accept Answer and Up-vote if the response helped -- Vaibhav",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Can't create a VM in compute - Creation failed",
        "Question_creation_time":1615983139490,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/318685\/can39t-create-a-vm-in-compute-creation-failed.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":1,
        "Question_body":"Hi\nI am unable to create a VM in Compute. Status is at Creating for an hour and then it fails.\nI tried several times without luck.\n\n\n\n\n\n\n\n\n\nDoes anyone know how to solve this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-18T07:31:13.92Z",
                "Answer_score":1,
                "Answer_body":"I was able to delete all the failed VMs and create one today.\nThe solution in this case was to wait it out.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-03-17T13:50:45.417Z",
                "Answer_score":0,
                "Answer_body":"@ArkanVasie-2880 Thanks for the question. There are known issues, We would recommend to raise a Azure support desk ticket from Help+Support blade from Azure portal for your service resource. This will help you to share the details securely and work with an engineer who can provide more insights about the issue.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Compute Instances List is not displaying any of my previously create instance",
        "Question_creation_time":1615936137423,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/317533\/compute-instances-list-is-not-displaying-any-of-my.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Compute Instances List is not displaying any of my previously create instance\n\nwhen i log in and go to the machine learning studio and click on the link it display an error.\n\nIts like the list is timing out\n\nI have tried this on multiple machines\n\nerror\n\n'Failed to load computes Your request for data wasn\u2019t sent. Here are some things to try: Check your network and internet connection, make sure a proxy server is not blocking your connection, follow our guidelines if you\u2019re using a private link, and check if you have AdBlock turned on. Trace ID : 6c0087da-5c17-4aea-814b-59d8292caa5b Client request ID : fa33bb7f-d4dd-4975-a538-cb119b7a2d64 '",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-17T08:58:48.193Z",
                "Answer_score":0,
                "Answer_body":"@lukemcredmond Does your network have any restrictions which could block any backend calls to the service? Do you have any other azure machine learning workspace and does that display a similar behavior?\n\nDue to the nature of the issue you could also pass the above trace id to our team from ML portal from the top right hand corner which enables them to contact you if required. Thanks!!",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"The request failed with status code: 502 error while consuming the model deployed",
        "Question_creation_time":1615982217267,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/318618\/the-request-failed-with-status-code-502-error-whil.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I have deployed an ML model trained with combining CSVs through dataset. When I try to consume the model REST endpoint through python. I get 502 error. In score.py, I predicted by using the dataset in the workspace as I need to use Count vectorizer. Below is my score.py code for your reference.\n\n def init():\n     global model\n     model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), \"prediction-model.pickle\")\n     model = joblib.load(model_path)\n    \n    \n def run(data):\n     try:\n         data = json.loads(data)['data']\n         print(data)\n         workspace = Workspace.get(name=\"xxx\", subscription_id='xxx',\n                                   resource_group='xxx')\n         dataset_name = 'prediction_ds'\n         prediction_ds = Dataset.get_by_name(workspace=workspace, name=dataset_name)\n         df = prediction_ds.to_pandas_dataframe()\n         df = df[pd.notnull(df['DESCRIPTION'])]\n         df = df[pd.notnull(df['CUSTOMERCODE'])]\n         col = ['CUSTOMERCODE', 'DESCRIPTION']\n         df = df[col]\n         df.columns = ['CUSTOMERCODE', 'DESCRIPTION']\n         df['category_id'] = df['DESCRIPTION'].factorize()[0]\n         df = df.applymap(str)\n         X_train, X_test, y_train, y_test = train_test_split(df['CUSTOMERCODE'], df['DESCRIPTION'], random_state=0)\n         count_vect = CountVectorizer()\n         count_vect.fit_transform(X_train)\n         predicted_result = model.predict(count_vect.transform(data))\n         return predicted_result.tolist()\n     except Exception as e:\n         print(\"exception occured\")\n         error = str(e)\n         print(error)\n         logging.info(error)\n         return error",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Retrieve Notebooks Azure Files",
        "Question_creation_time":1615959743450,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/317875\/retrieve-notebooks-azure-files.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Is it possible to retrieve notebooks that were hosted on notebooks.azure.com? If so, how? The service is now discontinued but I would like to retrieve files that were hosted on the service.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-17T10:07:29.02Z",
                "Answer_score":1,
                "Answer_body":"@sean-9375 I am afraid that the option to retrieve this data is not possible. Please refer this thread for information and the options that were available before the last day to migrate them. Thanks!!",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Program on VM automatically crash after long idle",
        "Question_creation_time":1615873089030,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/315909\/program-on-vm-automatically-crash-after-long-idle.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Hi,\n\nI am training machine learning model on Azure VM with NC6 promo GPU. Everything was fine at the beginning, but after a while I went back to check and realized my training program was stopped. Also, I got this message \"client_loop: send disconnect: Broken pipe\". Is there any solution for this problem since it cost me a lot of time and money.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-16T11:31:53.397Z",
                "Answer_score":0,
                "Answer_body":"@LeNguyenMinhHuy-2051 Thanks for the question. We have forwarded to the product team to check on this issue. You can try the following.\n\nThe sshd\/server settings in \/etc\/ssh\/sshd_config :\nTCPKeepAlive yes\nClientAliveInterval 60\nClientAliveCountMax 40000\n\nAND\n\nthe ssh\/client setting in ~\/.ssh\/config :\nServerAliveInterval 60\n\n\n\n\nWe would recommend to raise a Azure support desk ticket from Help+Support blade from Azure portal for your service resource. This will help you to share the details securely and work with an engineer who can provide more insights about the issue that if it can be replicated.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"MS Azure Machine Learning: MemoryError: Unable to allocate 5.43 GiB for an array with shape (23847, 30582) and data type int64",
        "Question_creation_time":1615935222203,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/317531\/ms-azure-machine-learning-memoryerror-unable-to-al.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I am trying to extract pixel values from a raster image using xarray module. I tried to \"stack\" the coordinates to get a third dimension but I end up getting the error above. I create a compute instance of 56GB RAM so I was wondering why the 5.43 GiB, I would have expected going beyond 56GB but the values seems off.\n\nThank you.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-17T08:06:23.09Z",
                "Answer_score":0,
                "Answer_body":"@PG-6613 Thanks for the question. Can you please add more details about the code that you are trying and the compute instance series details. There are some operations that will require a pick of memory usage while executing. So even when your dataframe fits in memory, the operation requires some more during operation.\n\nWe would recommend using the M series. We introduced this new vm family recently for high memory operations. There are known outage issue in storage, please raise a azure support ticket with the details..\nDoc for M Series:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/virtual-machines\/m-series?toc=\/azure\/virtual-machines\/linux\/toc.json&bc=\/azure\/virtual-machines\/linux\/breadcrumb\/toc.json\n\nYou can get a summary of the memory used by a Pandas DataFrame by calling df.info(memory_usage=\u201ddeep\u201d)\ndocs: https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.info.html",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"R script error on Azure machine learning (Error 1000)",
        "Question_creation_time":1615375884937,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/307755\/r-script-error-on-azure-machine-learning-error-100.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":2,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"When I try to connect my data source to the \"Execute R script\" then I run the experiment, the experiment does not run and I get this error message \"Execute R Script Error\nRPackage library exception: Attempting to obtain R output before invoking execution process . ( Error 1000 )\"\n\nPlease advice me how to solve this error and In general how to connect my datasets on Azure machine learning for D365 demand forecasting.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-11T17:55:27.87Z",
                "Answer_score":1,
                "Answer_body":"You use the import data module to import data from local files or online sources. The Azure AI gallery is also a great resource to view sample experiments. Here's a forecasting model for Dynamics 365 example. Regarding the error message, can you please share the module that generated this error as well as more details about the error by viewing the output log (detailed error message is displayed in the last two lines of the window)?",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-03-15T14:54:31.61Z",
                "Answer_score":0,
                "Answer_body":"It was just a simple CSV file.\n\nI need the Azure ML to analyze the data in the Excel file or the CSV I attach to the experiment and generate the forecast based on it not based on the historical transactions in D365, I will tell you the steps I know as I still a beginner and kindly provide me the correct steps:\n1- I will upload the sheet to my Azure studio library(it should be CSV format not normal Excel,right?)\n2- Then I will choose the sheet from \"my saved data sets\" and drag it into the experiment.\n3- Then I will drag \"convert to dataset\" into the experiment and I will connect the sheet to it then connect the \"convert to dataset\" to the \"Execute R script\" (Sheet>>Connected to \"convert to dataset\">>connected to \"Execute R script\").\n4- Then I will run the experiment then deploy the service.\n\nAre those correct steps? and should I remove \"Web service input\" to only analyze and generate based on the data in the sheet not the data in the D365?\n\nKindly advice @GiftA-MSFT",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-03-16T03:44:33.477Z",
                "Answer_score":0,
                "Answer_body":"Hi there, if you are uploading a local file:\n\nI recommend that you import a .csv file instead of excel\n\n\nYou can connect from csv to Execute R Script module directly.\n\n\nIn some cases, you may need to Edit Metadata and then Convert to Dataset\n\n\nCheck the data output by right clicking the module and select Dataset > Visualize to ensure the data is in expected format\n\n\nConnect your .csv file to the Execute R Script module and run the experiment (start with simple R commands and see if it runs)\n\n\nEnsure no errors before deploying the web service\n\n\nAs for web service input\/output, you specify those when you want to deploy your model\n\nYou may find this sample experiment helpful (click open in studio) and view import data and Execute R script modules respectively. . Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"ML Model data output",
        "Question_creation_time":1615488109277,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/310400\/ml-model-data-output.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\n\nI was running several time series model using Azure automated machine learning, I didn't write any code. After the running was completed, there are some datasets stored in Azure Blob Storage. But I don't know if these files include the prediction results or not because I can't find a right software to open it . I don't need to deploy the model. I just need a plain spreadsheet which contains the result. Why it is so hard? The attachment is the screenshot of the fiels stored in Blob of the model I ran? What do those files mean?\nAnd I just check the running outcome, it shows there is no output dataset. I was so confused! Do I need to change something when I set the model running?\n][1]",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-12T08:00:46.453Z",
                "Answer_score":0,
                "Answer_body":"@MarcusGonzalez-1907 I think you might be interested to check your models explainability which tells more about the results of your run and performance of your model. Since you are not planning to deploy your model as a service running explain for all the models will help you choose the best model that can be later used for deployment. The steps to run explain are mentioned in this document.\n\nThe files you might be referring to are files that might have been used for processing your data based on the input settings or configuration of your automl run. The files might be different between child runs as these child runs are basically run against an algorithm and different algorithms produce different set of files. Usually, the end user need not refer these files as automl gets the best model for you from all the child runs which is deployed as a web service on ACI or AKS.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Machine learning job stuck on queued and then cancelled",
        "Question_creation_time":1614676942043,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/294828\/machine-learnin-job-stuck-on-queued-and-then-cance.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I have a job which I set to run last night, only to find out it was queued for over 2 hours and eventually cancelled (not by me).\n\nThis morning, my machine learning run is again, stuck on queued.\n\nIs there any way to fix this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-02T13:46:00.057Z",
                "Answer_score":0,
                "Answer_body":"@CarterBouley-1225 Usually a failed job or a run is available from the Experiments tab on azure ML portal ml.azure.com, Do you see these runs or the logs related to these runs on this tab to provide more details of the errors?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Can we append data to an existing csv file stored in Azure blob storage?",
        "Question_creation_time":1615437989000,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/308980\/can-we-append-data-to-an-existing-csv-file-stored.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I have a machine learning model deployed in azure designer studio. I need to retrain it everyday with new data through python code. I need to keep the existing csv data in the blob storage and also add some more data to the existing csv and retrain it. If I retrain the model with only the new data, the old data is lost so I need to retrain the model by appending new data to existing data. Is there any way to do it through python coding?\n\nI have also researched about append blob but they add only in the end of the blob. In the documentation, they have mentioned we cannot update or add to an existing blob.\n\nAny help is appreciated. Thanks a lot.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-11T10:11:06.027Z",
                "Answer_score":0,
                "Answer_body":"@SenthilMuruganRAMACHANDRAN-7389 The best practice with respect to Azure Machine learning is to register your dataset and version it if you would like to retrain it to create a new model. You can infact have multiple csv files in your storage and create a single tabular dataset from the files. For example:\n\nHere we are using files from a blob container which are placed at different times and registering the dataset with versioning. If you would like to add more file, you can simply add more csv files to the web path and then register a new version or use the older versions again if required.\n\n # create a TabularDataset from Titanic training data\n web_paths = ['https:\/\/dprepdata.blob.core.windows.net\/demo\/Titanic.csv',\n              'https:\/\/dprepdata.blob.core.windows.net\/demo\/Titanic2.csv']\n titanic_ds = Dataset.Tabular.from_delimited_files(path=web_paths)\n    \n # create a new version of titanic_ds\n titanic_ds = titanic_ds.register(workspace = workspace,\n                                  name = 'titanic_ds',\n                                  description = 'new titanic training data',\n                                  create_new_version = True)",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Automate machine learning model on Azure portal failed",
        "Question_creation_time":1614327752400,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/290347\/automate-machine-learning-model-on-azure-portal-fa.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"User is not authorized to query provided resources due to s2s call not providing any active baggage to verify role-based access.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-01T05:40:33.697Z",
                "Answer_score":1,
                "Answer_body":"No update yet.\n\nI have been receiving emails from Microsoft that they will disable my account for going against their policy.\n\nReason was because I am frequently using the Azure platform.\n\nI decided to take a break from the platform to avoid them deleting my account.\n\n\n\n\nDon't know what to do \ud83d\ude2d next",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-03-01T15:13:40.477Z",
                "Answer_score":0,
                "Answer_body":"@IkechukwuAttah-1468\n\nHello, I am sorry but there is no action we can do here. If you have received an email that states account disablement, a better suggestion to you would be to contact Azure subscription management team by raising a support request. https:\/\/azure.microsoft.com\/en-us\/support\/create-ticket\/\n\nThere will be someone from professional subscription team to help. Thanks.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"help me fix error 0085",
        "Question_creation_time":1615644585240,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/312960\/help-me-fix-error-0085.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Error 0085: The following error occurred during script evaluation, please view the output log for more information:\n---------- Start of error message from Python interpreter ----------\nCaught exception while executing function: Traceback (most recent call last):\nFile \"C:\\server\\invokepy.py\", line 199, in batch\nodfs = mod.azureml_main(*idfs)\nFile \"C:\\temp\\dcc32c6db61a425eb482bb3deadd6e41.py\", line 25, in azureml_main\ndataset.columns = ['sentiment', 'tweets']\nFile \"C:\\pyhome\\lib\\site-packages\\pandas\\core\\generic.py\", line 2682, in setattr\nreturn object.setattr(self, name, value)\nFile \"pandas\\src\\properties.pyx\", line 65, in pandas.lib.AxisProperty.set (pandas\\lib.c:45018)\nFile \"C:\\pyhome\\lib\\site-packages\\pandas\\core\\generic.py\", line 425, in _set_axis\nself._data.set_axis(axis, labels)\nFile \"C:\\pyhome\\lib\\site-packages\\pandas\\core\\internals.py\", line 2578, in set_axis\n(old_len, new_len))\nValueError: Length mismatch: Expected axis has 3 elements, new values have 2 elements\nProcess returned with non-zero exit code 1\n\n---------- End of error message from Python interpreter ----------\nStart time: UTC 03\/13\/2021 14:06:38\nEnd time: UTC 03\/13\/2021 14:07:11",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How to import CSV file as a dataset for Azure machine learning",
        "Question_creation_time":1615376822993,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/307727\/how-to-import-csv-file-as-a-dataset-for-azure-mach.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I need to import CSV files as a dataset for my Azure machine learning experiment but I will get an error in execution, kindly provide me with the correct steps.\nThe aim of the experiment is to generate a demand forecast in MS D365 F&O based on the historical data provided in the CSV files.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-11T07:27:22.347Z",
                "Answer_score":1,
                "Answer_body":"Hi @AbdelrahmanMorsy-9613\nThank you for posting in Q & A.\n\nAzure ML Studio Classic import data\nImport your training data into Azure Machine Learning Studio (classic) from various data sources\n\nAzure ML Designer import data\nImport data into Azure Machine Learning designer\n\n\n\n\nPlease don\u2019t forget to Accept the answer and up-vote wherever the information provided helps you, this can be beneficial to other community members.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-03-11T17:58:47.43Z",
                "Answer_score":0,
                "Answer_body":"The Azure AI gallery is a great resource to view sample experiments. Here's a forecasting model for Dynamics 365 example. Regarding the error, please follow-up on this thread. Thanks!",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"update real interference pipeline",
        "Question_creation_time":1615298736310,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/305899\/update-real-interference-pipeline.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I deployed my Training pipeline and my Real-time inference pipeline.\nWith the REST-Api of my training pipeline I'm able to retrain my ML model. Is it possible to use that retrained model automated in my real inference pipeline?\nWhen i trigger the pipeline in ML studio I have to update my real inference pipeline manually. Since I want to trigger my retraining external that is not possible.\nThanks in advance.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-12T19:59:09.187Z",
                "Answer_score":0,
                "Answer_body":"Hi, here's a reference on which technology to use based on a given scenario. For your scenario, you should be able to create an Azure Machine Learning pipeline using the SDK to trigger a pipeline based on a time\/change based schedule and then update the web service accordingly. Depending on the complexity of your triggers or data prep needs, you can leverage other technologies such as Logic Apps or Azure Data Factory to trigger your Azure Machine Learning pipeline. Currently, you can only use the Azure Machine Learning SDK to automatically update the web service. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-03-09T21:20:25.76Z",
                "Answer_score":0,
                "Answer_body":"Hi, when you deploy a web service from designer, you can select to \"deploy as a new real-time endpoint\" or \"replace an existing real-time endpoint\". The option (replace an existing real-time endpoint) enables you to update the previous endpoint. Currently, there's no way to trigger an update to real-time endpoint, it's still a manual process (I will verify and share updates). To programmatically update your web service using Azure ML SDK, please refer to this document.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to use a model trained by Azure AutoML",
        "Question_creation_time":1614822360083,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/297882\/how-to-use-a-model-trained-by-azure-automl.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\nI've trained a classification model using Azure AutoML. In the \"Output\" folder of the best model page I can see these files:\n][1]][1]\n\n1- How should I use this model to predict new observations. I want to do this on Azure Machine Learning Studio, so no need to deploy it as a web service or take it to a local computer as a pickle file.\n\n\n\n\n2- I saw a few examples where people downloading their model as a PKL file and loading and running it to get predictions. I tried it by using the following code:\n\n import pickle\n Pkl_Filename = \"testPickle.pkl\"\n with open(Pkl_Filename, 'rb') as file:  \n     Pickled_LR_Model = pickle.load(file)\n Pickled_LR_Model\n\n\n\nand got the below error:\n\nModuleNotFoundError Traceback (most recent call last)\n<ipython-input-14-1e47995f2929> in <module>\n2 Pkl_Filename = \"testPickle.pkl\"\n3 with open(Pkl_Filename, 'rb') as file:\n----> 4 Pickled_LR_Model = pickle.load(file)\n5\n6 Pickled_LR_Model\n\nModuleNotFoundError: No module named 'azureml.automl.runtime._ml_engine.featurizer_suggestion'\n\n\n\n\n\nAlso used the joblib library to load the model and got the same error. Please help me with detailed step-by-step instructions (including scripts) if it is possible. I'm new to Azure Machine Learning Studio.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-10T20:16:29.617Z",
                "Answer_score":1,
                "Answer_body":"I fixed this problem by creating a new compute instance and using it to load the pickle file. Sounds strange but it seems this error happens due to a mismatch between the azureml sdk on the jupyter instance and on the compute instance.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-03-04T22:04:35.927Z",
                "Answer_score":0,
                "Answer_body":"Hi, it is possible to unpickle a model.pkl file, but you need to do so in a conda environment that is compatible with the runtime env where the pickle was created. Try installing the full automl package: pip install azureml-automl-runtime to see if it helps resolve the issue.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Image build failed. For more details, check log file azureml-logs\/20_image_build_log.txt.",
        "Question_creation_time":1615209277803,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/303859\/image-build-failed-for-more-details-check-log-file.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hi,\n\nWhen we wanted to get an explanation of a model, we received following error. \"Image build failed. For more details, check log file azureml-logs\/20_image_build_log.txt.\"\n\nYou can find the log file attached.\n\nI would appreciate if you could help us to resolve the issue. The model is very successful. It is important for us. Thus, we would like to understand it better with the explanation.\n\nThank you very much in advance for your interest and support!\n\nBest regards,\n\nCagatay Topcu75409-20-image-build-log.pdf",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Cross Validation",
        "Question_creation_time":1612476102827,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/259529\/cross-validation.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hello, I am getting an error when training a model with Cross validation.\n\nrequestId = 511f53ca6e0d4bdd991ece1e5c34a62b errorComponent=Module. taskStatusCode=500. {\"Exception\":{\"ErrorId\":\"InternalError\",\"ErrorCode\":\"0000\",\"ExceptionType\":\"ModuleException\",\"Message\":\"Sorry, it seems that you have encountered an internal system error. Please contact amlforum@microsoft.com with the full URL in the browser and the time you experienced the failure. We can locate this error with your help and investigate further. Thank you.\",\"Exception\":{\"ExceptionType\":\"Exception\",\"Message\":\"Exception has been thrown by the target of an invocation.\",\"Exception\":{\"ExceptionType\":\"Exception\",\"Message\":\"Right hand side shape must match region being assigned to\"}}}}Error: Sorry, it seems that you have encountered an internal system error. Please contact amlforum@microsoft.com with the full URL in the browser and the time you experienced the failure. We can locate this error with your help and investigate further. Thank you. Process exited with error code -2\n\nUrl adress:\n\nhttps:\/\/studio.azureml.net\/Home\/ViewWorkspaceCached\/9a8580b8f8e2410bba1214d24539753c?#Workspaces\/Experiments\/Experiment\/9a8580b8f8e2410bba1214d24539753c.f-id.f8dc50a742e04a0fa02c13cd730ef124\/ViewExperiment",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-08T20:10:58.883Z",
                "Answer_score":0,
                "Answer_body":"If you authorize my user, I can examine the model. lerosoft@outlook.com",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure automated ml Error: Run timed out.",
        "Question_creation_time":1614109931990,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/285527\/azure-automated-ml-error-run-timed-out.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"I got the below error while trying to run an experiment that uses automated machine learning to train a regression model. ![71149-azure-ml-errorcapture.png][1]\n\nI followed the MS Learn setting here: https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/use-auto-ml.\n\nI tried increasing the Training job time from 0.25 to 0.5 and it still failed. Thanks for any direction. [1]: \/answers\/storage\/attachments\/71149-azure-ml-errorcapture.png",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-08T20:05:56.687Z",
                "Answer_score":0,
                "Answer_body":"I guess your data set is too big. Do you try to shrink it down or do you have a chance to increase the compute source?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"export trained model in MS Azure designer",
        "Question_creation_time":1613562176760,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/276752\/export-trained-model-in-ms-azure-designer.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"how to export trained model in MS Azure designer in onnx format?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-18T09:29:11.363Z",
                "Answer_score":1,
                "Answer_body":"Hello,\n\nI don't think Machine Learning Designer supports export model as ONNX format at this moment. But I can check with the pm to see if there any plan ongoing or workaround available. Thanks.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Excel en Microsoft Azure",
        "Question_creation_time":1614968855700,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/301247\/excel-en-microsoft-azure.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Hola a todos, perdon quiza sea muy basica mi pregunta, no se como importar un excel como Dataset. Solo puedo importar CSV, etc. Muchas gracias",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-05T19:58:39.96Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. Excel is not a supported format for Azure ML Tabular datasets. I recommend that you convert your excel file to .csv file (save as .csv) before importing to Azure ML. Hope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-03-05T19:47:20.593Z",
                "Answer_score":0,
                "Answer_body":"QnA forums are currently English only. I'd try asking for help over here in dedicated forums.\nhttps:\/\/answers.microsoft.com\/es-es\/msoffice\/forum\/msoffice_excel\n\n--please don't forget to Accept as answer if the reply is helpful--",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Missing principal component analysis module in Azure ML Designer",
        "Question_creation_time":1614943157500,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/300776\/missing-principal-component-analysis-module-in-azu.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hi, I cannot find the Principal Component module in Azure ml designer. For the classic ML studio version it used to be under the data transformation group of transformations but seems to be no longer there. Am I missing something? Thanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-05T19:36:26.153Z",
                "Answer_score":0,
                "Answer_body":"Hi, it is under Anomaly Detection drop down menu.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"predict() missing 1 required positional argument: 'X' while consuming a deployed web service through python in azure",
        "Question_creation_time":1614169733667,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/286859\/predict-missing-1-required-positional-argument-39x.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I'm trying to consume a web service that I deployed and I get predict() missing 1 required positional argument: 'X' error. Here is a link for reference about m previous question: error-while-consuming-the-deployed-web-service-thr.html\n\n\n\n\n\nHere is my train.py file\n\ndf = pd.read_csv('prediction_data01.csv')\ndf = df[pd.notnull(df['DESCRIPTION'])]\ndf = df[pd.notnull(df['CUSTOMERCODE'])]\ncol = ['CUSTOMERCODE', 'DESCRIPTION']\ndf = df[col]\ndf.columns = ['CUSTOMERCODE', 'DESCRIPTION']\ndf['category_id'] = df['DESCRIPTION'].factorize()[0]\n\n\ntfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 4), stop_words='english')\nfeatures = tfidf.fit_transform(df.DESCRIPTION).toarray()\nlabels = df.category_id\n\n\ndf = df.applymap(str)\nX_train, X_test, y_train, y_test = train_test_split(df['CUSTOMERCODE'], df['DESCRIPTION'], random_state=0)\ncount_vect = CountVectorizer()\nX_train_counts = count_vect.fit_transform(X_train)\ntfidf_transformer = TfidfTransformer()\nX_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n\n\nclf = MultinomialNB().fit(X_train_tfidf, y_train)\nos.makedirs(\".\/outputs\", exist_ok=True)\njoblib.dump(clf, 'prediction-model.pickle')\n\nHere is my score.py file:\n\ndef init():\nglobal model\n# AZUREML_MODEL_DIR is an environment variable created during deployment.\n# It is the path to the model folder (.\/azureml-models\/$MODEL_NAME\/$VERSION)\n# For multiple models, it points to the folder containing all deployed models (.\/azureml-models)\nmodel_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), \"prediction-model.pickle\")\nmodel = joblib.load(model_path)\n\n\ndef run(raw_data):\ndata = np.array(json.loads(raw_data)['data'])\n# make prediction\ny_hat = model.predict(data)\n# you can return any data type as long as it is JSON-serializable\nreturn y_hat.tolist()",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-25T18:46:23.327Z",
                "Answer_score":0,
                "Answer_body":"Please review my response on this thread, thanks!",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-03-02T02:42:35.233Z",
                "Answer_score":0,
                "Answer_body":"Hi, can you try testing your model locally first to view the results and the expected format for your test data? It seems you performed some transformations when fitting the model, so you need to ensure that you are providing your test data with the expected shape and dimension of the array. Hope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-03-05T05:47:40.24Z",
                "Answer_score":0,
                "Answer_body":"Hi, I have tested the model results locally and it's working fine. I predicted the results of the model and with the below code.\n\nclf = MultinomialNB().fit(X_train_tfidf, y_train)\nwith open(\"prediction.pickle\", \"wb\") as f:\npickle.dump(MultinomialNB, f)\nprint(clf.predict(count_vect.transform([\"18339\"])))\n\nI'm able to predict successfully with the above code and also I'm able to predict with loading the saved model pickle file using the below code.\n\n\npickle_in = open(\"prediction.pickle\", \"rb\")\nMultinomial_model = pickle.load(pickle_in)\nclf = Multinomial_model().fit(X_train_tfidf, y_train)\nprint(clf.predict(count_vect.transform([\"18339\"])))\n\nI get this error -- fit() missing 1 required positional argument: 'y'-- when I do not use parenthesis in the above code fit method.\n\nclf = Multinomial_model.fit(X_train_tfidf, y_train)\n\nHope you understand the issue. Thanks for the continuous response. I think the issue is also with the score.py. Any help is appreciated Thanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning Errors",
        "Question_creation_time":1614300692297,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/289691\/azure-machine-learning-errors.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hello, I am trying to run some of the sample notebooks from Microsoft Docs for Azure Machine Learning. I am running into the following error and cannot find a workaround though this appears to be a common error that others have also encountered with no workaround. cannot import name 'AzureMLAggregatedException' from 'azureml.exceptions'",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-05T02:51:15.36Z",
                "Answer_score":0,
                "Answer_body":"Hi,\nIt is the explanation dashboards and the fairness dashboards and it cannot find the Lime library or its methods.\nRegards,\nAmy",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to open successfully a terminal in jupyter notebook",
        "Question_creation_time":1614840049767,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/298197\/how-to-open-successfully-a-terminal-in-jupyter-not.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hi,\n\nOpening a terminal from jupyter notebook created in the compute resource is failing with the following error:\n\nfailed: Error during WebSocket handshake: Unexpected response code: 426 make_terminal @ terminado.js:4 index.js:5\nUncaught TypeError: Cannot read property 'parentElement' of undefined at proposeGeometry (index.js:5) at fit (index.js:30) at Terminal.terminalConstructor.fit (index.js:44) at window.onresize (main.js:54)\n\n\nI have deleted and created again the compute instance with the following characteristics:\nAttributes\nCompute name: veracruz\nCompute type: Compute instance\nSubscription ID: 7aa3fe31-0364-453e-bd8f-ff5c11be8727\nResource group: machine-learning-cgi\nWorkspace: ml-practice-2021 Region: eastus2\nCreated by: Reyes Lopez, Arturo\n\nSteps to reproduce: The compute instance is running:\n\nWhen clicking on Jupyter and selecting New-> Terminal getting the mentioned error above in Google Chrome and Microsoft Edge browsers:\n\n\n\n\n\nWhat can be the issue when opening the terminal from jupyter notebook? The issue is when following this steps after the creation of compute resource: https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/explore-analyze-data-with-python\/2-exercise-explore-data#clone-the-ml-basics-repository\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-04T17:12:24.75Z",
                "Answer_score":1,
                "Answer_body":"Hi @romungi-MSFT\n\nI realized it is a proxy issue related in the laptop. When moving to a different laptop I not longer had the issue.\n\n\n\n\nThanks :)",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Anaconda commercial use on Azure Data Science Virtual Machine",
        "Question_creation_time":1614757334137,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/296502\/anaconda-commercial-use-on-azure-data-science-virt.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I would like to know if there is any problem in terms of license if enterprise companies use Anaconda that is preinstalled in Azure Data Science Virtual Machine. In another inquiry, I saw an answer that Anaconda included in Azure Machine Learning service has no problem in terms of the license but I would like to confirm whether DSVM also has a problem or not. https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/165312\/anaconda-commercial-use-on-azure-machine-learning.html",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-03T10:10:34.917Z",
                "Answer_score":0,
                "Answer_body":"@kenta-takahashi The thread referenced by a user was in a different context who wanted to check if they had to subscribe to commercial license to use Azure ML. In the case of DSVM where anaconda packages are installed they are still configured to use open source packages irrespective of the subscription that spins them up. So, you can definitely use the DSVM for your purposes and configure any license's that were acquired to enhance your usage experience with the tools that have been pre-installed. Thanks!!",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"AzureML Notebooks: how to access data from an experiment",
        "Question_creation_time":1614762558803,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/296661\/azureml-notebooks-how-to-access-data-from-an-exper.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":1,
        "Question_body":"Hi, I am new to Azure ML, and I have been trying to replicate the same structure presented in the MNIST tutorial, but I don't understand how to adapt it to my case.\n\nI am running a python file from the experiment, but I don't understand how I can access data that is currently in a folder in the cloud file system from the script running in the experiment.\nI have found many examples about accessing one single .csv file, but my data is made of many images.\n\nFrom my understanding I should first load the folder to a datastore, then use Dataset.File.upload_directory to create a dataset containing my folder, and here is how I tried to do it:\n\n # Create dataset from data directory\n datastore = Datastore.get(ws, 'workspaceblobstore')\n dataset = Dataset.File.upload_directory(path_data, target, pattern=None, overwrite=False, show_progress=True)\n    \n file_dataset = dataset.register(workspace=ws, name='reduced_classification_dataset',\n                                                  description='reduced_classification_dataset',\n                                                  create_new_version=True)\n\n\n\nBut then I don't understand if and how I can access this data like a normal file system from my python script, or I need further steps to be able to do that.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-04T04:48:33.09Z",
                "Answer_score":0,
                "Answer_body":"@Matzof Thanks for the question. Please follow the below code for writing.\n\n    datastore = ## get your defined in Workspace as Datastore \n datastore.upload(src_dir='.\/files\/to\/copy\/...',\n                  target_path='target\/directory',\n                  overwrite=True)\n\n\n\nDatastore.upload only support blob and fileshare. For adlsgen2 upload, you can try our new dataset upload API:\n\n\n\n from azureml.core import Dataset, Datastore\n datastore = Datastore.get(workspace, 'mayadlsgen2')\n Dataset.File.upload_directory(src_dir='.\/data', target=(datastore,'data'))\n\n\n\n\nPandas is integrated with fsspec which provides Pythonic implementation for filesystems including s3, gcs, and Azure. You can check the source for Azure here: dask\/adlfs: fsspec-compatible Azure Datake and Azure Blob Storage access (github.com). With this you can use normal filesystem operations like ls, glob, info, etc.\n\nYou can find an example (for reading data) here: azureml-examples\/1.intro-to-dask.ipynb at main \u00b7 Azure\/azureml-examples (github.com)\n\nWriting is essentially the same as reading, you need to switch the protocol to abfs (or az), slightly modify how you're accessing the data, and provide credentials unless your blob has public write access.\n\nYou can use the Azure ML Datastore to retrieve credentials like this (taken from example):",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Importing Data in Azure ML Studio Experiment",
        "Question_creation_time":1614362680897,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/291213\/importing-data-in-an-experiment-issue.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I\u2019m having an issue importing the data into my Machine Learning Studio. It shows me a Red Cross with the error 0030 - which means that there\u2019s an issue in downloading the data. For background, I\u2019m importing data from the Web URL via HTTP option. I looked up the issue on the troubleshooting page, followed the advice, which shows I\u2019ve done everything correctly. My data link works perfectly fine in my browser. When I enter the http link into my browser, it immediately downloads the csv file. However, my studio is not downloading the data. Importing the data is the first step in my experiment, and I can\u2019t move forward without it. Immediate help would be greatly appreciated! I\u2019ve attached pictures for reference. [1]: \/answers\/storage\/attachments\/72499-0ebb78a4-4805-46e8-a7f1-fbf99682af5f.png",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-03T08:19:34.36Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThis exception in Azure Machine Learning occurs when it is not possible to download a file. You will receive this exception when an attempted read from an HTTP source has failed after three (3) retry attempts.\n\nResolution: Verify that the URI to the HTTP source is correct and that the site is currently accessible via the Internet.\n\nIs this file on any place need authentication?\n\nRegards,\nYutong",
                "Answer_comment_count":7,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Framing API for Azure Workspace Experiments Runs",
        "Question_creation_time":1612790580067,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/263728\/framing-api-for-azure-workspace-experiments-runs.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Hi there,\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-rest\n\nAs explained in the doc here, could you help me to frame the API URL to fetch all the runs of an experiment of a workspace.\n\nThanks,",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Module not found when custom python package installed via shell script",
        "Question_creation_time":1612719050957,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/262423\/module-not-found-when-custom-python-package-instal.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Hi All,\n\nI am using Azure ML designer to run zipped python scripts. But the code is complaining about the 'No module Found' error.\nFrom the main python script where azureml_main() is present I am calling a bash script using following call:\n\n proc = call([\"bash\", \"Script Bundle\/setup.sh\"])\n # \/bin\/bash\n echo \"Hello World !!!\"\n pip install -r 'Script Bundle\/requirement.txt'\n python account_test.py\n   \n #account_test.py\n import os\n import json\n import xmltodict\n    \n from bankaccount import BankAccount\n    \n my_account = BankAccount(50)\n my_account.withdraw(5)\n print (my_account.balance, my_account.overdrawn())\n    \n with open('Script Bundle\/person.json') as f:\n    data = json.load(f)\n    print(data)\n    \n with open('Script Bundle\/sample.xml') as fd:\n     doc = xmltodict.parse(fd.read())\n     print(doc)\n\n\n\nInside the bash script I am installing the custom module using pip and immediately calling an entry python script(python account_test.py) to call a chain of scripts. But the code is unable to find the module(xmltodict) and is failing eventually.\n\nMy assumption is the module is getting installed in a separate process and main process do not have access to that. But I tried with calling the python file from same shell script, still it is not working.\n\nLooking for your help.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-08T13:46:57.837Z",
                "Answer_score":0,
                "Answer_body":"@KT-3471 Thanks for the question. Could you please share link to the code to check on this. Here is the doc for supported python packages.\nThere\u2019s a trouble shooting doc: Troubleshoot designer module errors - Azure Machine Learning | Microsoft Docs",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AutoML error: Microsoft.DPrep.SharedLibrary.ErrorHandling.UnexpectedException: 'Access token authentication is not supported.'",
        "Question_creation_time":1613661513130,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/278775\/automl-error-microsoftdprepsharedlibraryerrorhandl.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I'm implementing a pipeline where a step involves creating and submitting an AutoML run. The issue I'm seeing occurs when the run starts \"ActivityStarted: StreamingFit\". I've gone ahead and pasted the error trace below.\n\nMy best guess would be something to do with authentication to our ADLS gen 2 which houses the files for our Dataset. I've tried remaking the same Dataset under the workspace default storage and it works fine. Both the cluster and the service principal associated with the AutoML run have full blob storage access.\n\nAppreciate any help on this.\n\nEdit: for clarity. I have a PythonScriptStep that sets up and submits an AutoMLRun.\n\n\n\n 2021-02-18 14:52:12.367 - INFO - ActivityStarted: StreamingFit\n Error: *** Microsoft.DPrep.SharedLibrary.ErrorHandling.UnexpectedException: 'Access token authentication is not supported.' StackTrace: Elapsed time: 00:00:06.7332685\n 2021-02-18 14:52:19.361 - CRITICAL - Type: AutoMLInternal\n Class: FitException\n Message: FitException:\n  Message: Error: *** Microsoft.DPrep.SharedLibrary.ErrorHandling.UnexpectedException: 'Access token authentication is not supported.' \n  InnerException: BridgeRuntimeError: Error: *** Microsoft.DPrep.SharedLibrary.ErrorHandling.UnexpectedException: 'Access token authentication is not supported.' \n  ErrorResponse \n {\n     \"error\": {\n         \"code\": \"SystemError\",\n         \"message\": \"Encountered an internal AutoML error. Error Message\/Code: FitException. Additional Info: FitException:\\n\\tMessage: Error: *** Microsoft.DPrep.SharedLibrary.ErrorHandling.UnexpectedException: 'Access token authentication is not supported.' \\n\\tInnerException: None\\n\\tErrorResponse \\n{\\n    \\\"error\\\": {\\n        \\\"message\\\": \\\"Error: *** Microsoft.DPrep.SharedLibrary.ErrorHandling.UnexpectedException: 'Access token authentication is not supported.' \\\",\\n        \\\"target\\\": \\\"NimbusML\\\",\\n        \\\"reference_code\\\": \\\"NimbusML\\\"\\n    }\\n}\",\n         \"details_uri\": \"https:\/\/docs.microsoft.com\/azure\/machine-learning\/resource-known-issues#automated-machine-learning\",\n         \"target\": \"NimbusML\",\n         \"inner_error\": {\n             \"code\": \"ClientError\",\n             \"inner_error\": {\n                 \"code\": \"AutoMLInternal\"\n             }\n         },\n         \"reference_code\": \"NimbusML\"\n     }\n }\n Traceback:\n   File \"telemetry_activity_logger.py\", line 57, in _log_activity\n     yield\n   File \"streaming_featurizer.py\", line 165, in learn_transformations\n     estimator.fit(self._training_data)\n   File \"streaming_estimator.py\", line 70, in fit\n     \"nimbus ml failed to fit during featurization at {0}\".format(bre.callstack))\n   File \"streaming_estimator.py\", line 66, in fit\n     self._pipeline.fit(datastream_X)\n   File \"utils.py\", line 220, in wrapper\n     params = func(*args, **kwargs)\n   File \"pipeline.py\", line 1086, in fit\n     raise e\n   File \"pipeline.py\", line 1073, in fit\n     **params)\n   File \"entrypoints.py\", line 460, in run\n     output_predictor_modelfilename)\n   File \"entrypoints.py\", line 315, in _try_call_bridge\n     model=output_modelfilename)",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-19T10:06:49.077Z",
                "Answer_score":0,
                "Answer_body":"@ChowAndy-9377 Thanks for the question, AML allows to register ADLS Gen2 as data store with Workspace\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data#azure-data-lake-storage-generation-2\n\nCurrently you can register ADLS Gen2 container as blob using account key or SaS key.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Jupyter Notebook not running as fast as expected?",
        "Question_creation_time":1614288658810,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/289526\/jupyter-notebook-not-running-as-fast-as-expected.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hi,\n\nI have recently started using Azure because I need to run a very demanding piece of code on Jupyter Notebook. I am attempting to run the notebooks by creating a workspace via Azure Machine Learning\n\nI have obtained quotas for High Performance Computing but still, the time required to run my code is the same as it is with my laptop. My laptop isn't the greatest so I suspect there's either something wrong with my connectivity or the way I set up the notebook. Is it enough to just connect to a compute instance or do I need to set up an environment at the very top?\n\nEDIT: The device I am using is a Standard_HB60rs with 60 cores, 223.52GB RAM and 700GB Storage which costs $2.28\/hour. I am importing a package that is used for simulations of quantum mechanical systems called qutip.\n\n\n\nInstalling Qutip\n\n\n\nconda install numpy scipy cython matplotlib nose jupyter notebook spyder\n\nconda config --append channels conda-forge\n\nconda install qutip\n\n\n\nThe installation seems to be working as I have been able to run the next cells which use the package.\n\n\n\n\nCell 1 where I import all necessary packages\n\n\n\n%matplotlib notebook\n\nimport copy\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\nfrom qutip.qip.noise import RandomNoise\n\npi = np.pi\n\nfrom qutip.qip.device import Processor\nfrom qutip.operators import sigmaz, sigmay, sigmax, destroy\nfrom qutip.states import basis\nfrom qutip.metrics import fidelity\nfrom qutip.qip.operations import rx, ry, rz, hadamard_transform\n\nhbar = 1.0545718 (10-34) #in Js\nh = hbar 2 np.pi #in Js\neV = 1.60217662 (10*-19)\nh_eV = 6.58 (10*-22)(10**6) #h in eVs\n\n\n\nCell 2\n\n\n\nprocessor = Processor(N=1) #this command builds a 2-level quantum mechanical system\n\nparameters for some of the functions that will be used\n\n\n\nDelta = (2*(10*9)) (h) #in Joules\nDelta_2 = ((Delta\/(h)) 2 pi)\/(10**13) #in Hz units\n\nprocessor.add_control((0.5*Delta_2*sigmax()), targets=0, label=\"sigmaz\") #Hamiltonian of the system\n\nCell 3. Here, I drive my system from its ground state to a superposed state.\n\n\n\n\nw_min = (pi\/2\/Delta_2)(10*-2)\nw_max = (pi\/2\/Delta_2)\nstep = 0.01\n\ntpoints = np.linspace(w_min,w_max,123)\n\nbasis0 = basis(2,0)\n\nfinal_states = []\n\nfor t in tpoints:\ntlist = np.linspace(0,t,1000)\nprocessor.pulses[0].coeff = np.array([1 for t in tlist])\nprocessor.pulses[0].tlist = tlist\nresult = processor.run_state(init_state=basis0)\nfinal_states.append(result.states[-1])\n\n\n\n\nThe Physics of the matter isn't the matter here. I know the code does what it is supposed to do; the remaining of the code includes various loops which do similar computations. The code in #cell 3 would usually take between 10-20 seconds to run on my laptop. I was surprised to see that it would take the same time on Azure.\n\nHope this is a bit more clear\n\n\n\n\n\nThank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-02T23:10:03.797Z",
                "Answer_score":0,
                "Answer_body":"Thanks for sharing detailed information. When using Azure ML Notebooks, you simply need to add compute instance, and depending on your workload you can request quota increase. However, various factors can affect performance. For example, writing large files of data on the OS disk of the compute instance or installing certain extensions can cause slow down performance. However, If you continue to experience unusually slow performance, I encourage you to contact Azure support for further analysis on the issue. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error while consuming the deployed web service through python",
        "Question_creation_time":1613996362460,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/282967\/error-while-consuming-the-deployed-web-service-thr.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I have tried consuming the web service with python with the link how-to-consume-web-service. I'm getting an error\n\npredict() missing 1 required positional argument: 'X'\n\n\nI have trained the model to predict only one field \" DESCRIPTION\" and two input fields \"CUSTOMERCODE\", \"DESCRIPTION\"\n\nwhen I try to predict with input data with the code below:\n\n\n\nimport requests\nimport json\n\n\nURL for the web service\n\nscoring_uri = 'xxx'\n# If the service is authenticated, set the key or token\nkey = 'xxx'\n\n\nTwo sets of data to score, so we get two results back\n\ndata = {\"data\":\n[\n[\n\"10000\",\n\"CAPPUCINO\"\n],\n[\n\"12345\",\n\"CAFFINE\"\n]\n]\n}\ninput_data = json.dumps(data)\nheaders = {'Content-Type': 'application\/json'}\nheaders['Authorization'] = f'Bearer {key}'\nresp = requests.post(scoring_uri, input_data, headers=headers)\nprint(resp.text)",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-25T18:44:25.18Z",
                "Answer_score":0,
                "Answer_body":"It seems your input is CUSTOMERCODE and target is DESCRIPTION, however, you are entering data for the target column when it is expecting only CUSTOMERCODE as input. Hope this helps!",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-03-02T02:43:22.363Z",
                "Answer_score":0,
                "Answer_body":"Hi, can you try testing your model locally first to view the results and the expected format for your test data? It seems you performed some transformations when fitting the model, so you need to ensure that you are providing your test data with the expected shape and dimension of the array. Hope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Using Python visual in Power BI for calling ML Azure rest API works in desktop version but not when published",
        "Question_creation_time":1613593697693,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/277404\/using-python-visual-in-power-bi-for-calling-ml-azu.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I created a dashboard in Power BI desktop. I have a trained model from ML Azure which I already deployed and has it's rest API. I need to call this rest API from the dashboard itself using measures I created (not from the query editor). I did it using the Python visual to send the input data and get back the output from the rest API and plotting the result (a number). This works perfectly in the desktop version. I need to publish this dashboard to share with other members of my organization but in the web version the script gives a runtime error. ![69200-capture.png][1] How to make it work? [1]: \/answers\/storage\/attachments\/69200-capture.png",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-18T07:54:29.523Z",
                "Answer_score":0,
                "Answer_body":"anonymous user There is a documented procedure to connect a Azure ML workspace on powerBI desktop and select the model and service before publishing this.\nIn this case it looks like you used python visual to consume your REST API but after publishing it the same script might be failing to even connect to the API. Not sure if any port needs to be opened up when published to web.\n\nI think you can try the above procedure again with powerBI desktop using query editor and then try to publish the report to web.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Compute instance showing cross against starting",
        "Question_creation_time":1613826664207,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/281408\/compute-instance-showing-cross-against-starting.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I am trying to start a compute instance on ML studio and the starting process has been running for a while now. Previously while running it showed a green status symbol while starting now it is showing red cross and it does not seem to be starting.\n\n\n\n\n\nWhen I am trying to create a new compute I get the below error",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-22T05:58:40.88Z",
                "Answer_score":0,
                "Answer_body":"@gtrgouthamtraj Is it possible to try and create another type of compute instance? It looks like you have quota available but the request is failing to create new instances.\n\nThe trace ids would have more details of the error but are accessible to authorized teams to check further which might need a support ticket or you can post from feedback section on top right corner by clicking the smiley icon.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How can I open the automated ML explanation in Jupyter notebooks?",
        "Question_creation_time":1614091964233,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/285089\/how-can-i-open-the-automated-ml-explanation-in-jup.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"What-If and Individual Conditional Expectation (ICE) plots are not supported in Azure Machine Learning studio under the Explanations tab since the uploaded explanation needs an active compute to recalculate predictions and probabilities of perturbed features. It is currently supported in Jupyter notebooks when run as a widget using the SDK. How can I open the automated ML explanation in Jupyter notebooks?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-03-01T15:58:38.55Z",
                "Answer_score":0,
                "Answer_body":"Hello Cagatay,\n\nIn jupyter notebook for AutoML models, you can download the trained model, then compute explanations locally and visualize the explanation results using ExplanationDashboard from interpret-community. Sample code below:-\n\n\n\n\n best_run, fitted_model = remote_run.get_output()\n     \n from azureml.train.automl.runtime.automl_explain_utilities import AutoMLExplainerSetupClass, automl_setup_model_explanations\n automl_explainer_setup_obj = automl_setup_model_explanations(fitted_model, X=X_train,\n                                                                                                                          X_test=X_test, y=y_train,\n                                                                                                                          task='regression')\n     \n from interpret.ext.glassbox import LGBMExplainableModel\n from azureml.interpret.mimic_wrapper import MimicWrapper\n explainer = MimicWrapper(ws, automl_explainer_setup_obj.automl_estimator, LGBMExplainableModel,\n                          init_dataset=automl_explainer_setup_obj.X_transform, run=best_run,\n                          features=automl_explainer_setup_obj.engineered_feature_names,\n                          feature_maps=[automl_explainer_setup_obj.feature_map],\n                          classes=automl_explainer_setup_obj.classes)\n     \n pip install interpret-community[visualization]\n     \n engineered_explanations = explainer.explain(['local', 'global'], eval_dataset=automl_explainer_setup_obj.X_test_transform)\n print(engineered_explanations.get_feature_importance_dict()),\n from interpret_community.widget import ExplanationDashboard\n ExplanationDashboard(engineered_explanations, automl_explainer_setup_obj.automl_estimator, datasetX=automl_explainer_setup_obj.X_test_transform)\n     \n raw_explanations = explainer.explain(['local', 'global'], get_raw=True, \n                                      raw_feature_names=automl_explainer_setup_obj.raw_feature_names,\n                                      eval_dataset=automl_explainer_setup_obj.X_test_transform)\n print(raw_explanations.get_feature_importance_dict()),\n from interpret_community.widget import ExplanationDashboard\n ExplanationDashboard(raw_explanations, automl_explainer_setup_obj.automl_pipeline, datasetX=automl_explainer_setup_obj.X_test_raw)\n\n\n\nThe code sample repo please refer to: https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/explain-model\/azure-integration\/scoring-time\/train-explain-model-locally-and-deploy.ipynb\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"When Analyzing using Explanations is it possible to unselect the first value?",
        "Question_creation_time":1614091600373,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/285095\/when-analyzing-using-explanations-is-it-possible-t.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":7,
        "Question_score":1,
        "Question_body":"When working with Azure Machine Learning AutoML I am unable to unselect the first value in the list when trying to create a new cohort using Explanations. For example in the below I am unable to unselect Female if I wish to only see how a factor affected the Male demographic. \n\nIs there a way to unselect this value?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Read\/Write from\/to Blob Storage in AzureML",
        "Question_creation_time":1613410517227,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/273787\/readwrite-fromto-blob-storage-in-azureml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"I am using AzureML and I have a blob storage container, where I want read data from it and write data to it. Can I achieve that with the path that is being passed to the experiment as follows (from here):\n\n from azureml.core import Workspace\n ws: Workspace = Workspace.from_config()\n compute_target: ComputeTarget = ws.compute_targets['<compute-target-name>']\n ds: Datastore = ws.get_default_datastore()\n    \n data_ref = ds.path('<path\/on\/datastore>').as_mount()\n    \n config = ScriptRunConfig(\n     source_directory='.',\n     script='script.py',\n     arguments=[str(data_ref)],               # returns environment variable $AZUREML_DATAREFERENCE_example_data\n     compute_target=compute_target,\n )\n    \n config.run_config.data_references[data_ref.data_reference_name] = data_ref.to_config()\n\n\n\nIf so, what is the purpose of OutputFileDatasetConfig class in the API? Is it just a convenient shortcut to the path in the container?\n\n from azureml.data import OutputFileDatasetConfig\n    \n output = OutputFileDatasetConfig(folder, destination=(datastore_obj, path_to_folder))\n arguments = [output]\n\n\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-16T08:07:14.03Z",
                "Answer_score":0,
                "Answer_body":"@Sep-8038 I think you can use this notebook to try the exact scenario as above.\nOutput is configured to write the result back to the blob store under the configured folder. More options to configure the output can be seen by running 'help(OutputFileDatasetConfig)'\n\nHope this helps!!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML - Deployed to Inference Cluster throws 500 Server Error - MissingFeaturesError",
        "Question_creation_time":1614113525043,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/285607\/azure-ml-deployed-to-inference-cluster-throws-500.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"We have an Azure ML model we are ready to deploy to an http endpoint for consumption and testing.\n\nWe are using this tutorial (https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy) as the jumping off point for deploying our ml model. We have created an inference cluster, converted the training model to a real-time inference model and deployed. Deployment looks successful. However, when testing (both via the Test tab in the Azure ML Workspace and via http POST) the server throws a 500. The MissingFeaturesError follows:\n\n\n\n\nFile \"\/azureml-envs\/azureml_9b50686470a92ca74f0d62e2629faaec\/lib\/python3.6\/site-packages\/azureml\/studio\/modules\/ml\/common\/base_learner.py\", line 289, in _validate_no_missing_feature\nErrorMapping.throw(MissingFeaturesError(required_feature_name=';'.join(missing_feature_list)))\n> missing_feature_list = ['Miles', 'Age', 'Gender', 'MarriagetPlans']\n\n\nFile \"\/azureml-envs\/azureml_9b50686470a92ca74f0d62e2629faaec\/lib\/python3.6\/site-packages\/azureml\/studio\/common\/error.py\", line 814, in throw\nraise err\n> err = MissingFeaturesError('Features for Miles;Age;Gender;MarriagetPlans required but not provided.',)\n\n\nMissingFeaturesError: Features for Miles;Age;Gender;MarriagetPlans required but not provided.\n\nIn both test cases (via Test tab in Azure and http POST to the endpoint) all the required data is indeed provided. The request body definitely includes Miles, Age, Gender, MarriagetPlans.\n\nWhat is going on here?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-24T03:41:55.38Z",
                "Answer_score":0,
                "Answer_body":"You can add a additional tag \"azure-machine-learning\" to make more people know your problem, I believe it's problem of AML studio",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-02-26T15:00:09.507Z",
                "Answer_score":0,
                "Answer_body":"bump Still a problem.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Use private Python packages with Azure Machine Learning - PAT Auth",
        "Question_creation_time":1614263822737,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/288955\/use-private-python-packages-with-azure-machine-lea.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Hi,\n\nI am trying to deploy a model on an AKS cluster in Azure Machine Learning that uses a Python package that is present as a package in a feed on Azure DevOps.\nI found the following article that explains how to do this:\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-private-python-packages\n\nIn the example it shows that in the Worspace.set_connection method, it passes a string as \"value\".\nIf I try to do the same in my code the following error appears:\n\nazureml._base_sdk_common.workspace.models.machine_learning_service_error.MachineLearningServiceErrorException: (ValidationError) JSON format is expected for Properties.Value\n\nLooking at the documentation (azureml.core.workspace.workspace) it actually says that it expects a JSON:\nvalue: the json format serialization string of the connection details)\n\nWhat format and what information should this JSON contain?\n\nThanks,\nG.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-26T10:02:41.517Z",
                "Answer_score":0,
                "Answer_body":"@GCocci Thanks for the question. Please find the example for PAT passing.\n\n from azureml.core import Workspace\n    \n pat_token = input(\"Enter secret token\")\n ws = Workspace.from_config()\n ws.set_connection(name=\"connection-1\", \n    category = \"PythonFeed\",\n    target = \"https:\/\/<my-org>.pkgs.visualstudio.com\", \n    authType = \"PAT\", \n    value = \u201c\\\u2019\u201d+pat_token+\u201d\\\u2019\u201d) \n\n\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-use-private-python-packages#use-a-repository-of-packages-from-azure-devops-feed",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning: Update Realtime endpoint",
        "Question_creation_time":1611847882743,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/249335\/azure-machine-learning-update-realtime-endpoint.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":1,
        "Question_body":"Hi,\n\nI've deployed an endpoint in Azure ML with the command \"az ml model deploy\" and it has created an realtime endpoint (in my case based on AKS cluster type).\n\nNow I want to update this endpoint, because for example I want to change some configuration or code in the score.py. If I try to relaunch the same command above with the option --overwrite, it prints an error regarding the unavailabilty of CPU and memory, even though their configuration is the same as the previous deployment.\n\n\n\n\n{'Azure-cli-ml Version': '1.20.0', 'Error': WebserviceException:\nMessage: Deployment request failed due to insufficient compute resource. For the specified compute target, 1 replica cannot be created per specified CPU\/Memory configuration(3 CPU Cores, 20GB Memory). You can address this problem by adjusting number of replicas, using a different CPU\/memory configuration, or using a different compute target.\nInnerException None\nErrorResponse\n{\n\"error\": {\n\"message\": \"Deployment request failed due to insufficient compute resource. For the specified compute target, 1 replica cannot be created per specified CPU\/Memory configuration(3 CPU Cores, 20GB Memory). You can address this problem by adjusting number of replicas, using a different CPU\/memory configuration, or using a different compute target.\"\n}\n}}\n\n\n\n\nI therefore think that it is not overwriting the endpoint, but creating a parallel environment.\n\nI also tried to create a new version of the endpoint with the commands \"az ml endpoint realtime create-version\" and \"az ml endpoint realtime update-version\", but in this case it always tells me that it doesn't find the endpoint I'm trying to update (despite with the command \"list\" it finds me exactly my endpoint).\n\nError Message:\n\n{\n\"Azure-cli-ml Version\": \"1.20.0\",\n\"Error\": {\n\"Error\": \"Error, no service\/endpoint with name <endpoint-name> found in workspace <workspace-name> in resource group <resource-group-name> of type aksendpoint.\"\n}\n}\n\nSo, how can I overwrite my endpoint? I hope there is a better solution than manually deleting the endpoint each time and recreating it.\n\n\n\n\nThank you very much,\n\nG.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-29T12:01:04.773Z",
                "Answer_score":0,
                "Answer_body":"@GCocci Thanks, You can use the AKS recipes for real time inference and alternatively take the ParallelRunStep approach for handling offline batch inferences for many models.\n\nThe approaches are captured in the solution accelerator here:\nhttps:\/\/github.com\/microsoft\/solution-accelerator-many-models\n\nHere are the steps to Group all models into a single routing endpoint.\nWe can now group all the services into a single entry point, so that we don't have to handle each endpoint separately. For that, we'll register the endpoints object as a model, and deploy it as a webservice. This webservice will receive the incoming requests and route them to the appropiate model service, acting as the unique entry point for outside requests.\n\nRegister endpoints dict as an AML model\n\n\n\n\nimport joblib\n\n joblib.dump(models_deployed, 'models_deployed.pkl')\n    \n dep_model = Model.register(\n     workspace=ws, \n     model_path ='models_deployed.pkl', \n     model_name='deployed_models_info',\n     tags={'ModelType': '_meta_'},\n     description='Dictionary of the service endpoint where each model is deployed'\n )\n\n\n\nDeploy routing webservice\n\nfrom azureml.core import Environment\nfrom azureml.core.conda_dependencies import CondaDependencies\nfrom azureml.core.runconfig import DEFAULT_CPU_IMAGE\nrouting_env = Environment(name=\"many_models_routing_environment\")\nrouting_env_deps = CondaDependencies.create(pip_packages=['azureml-defaults', 'joblib'])\nrouting_env.python.conda_dependencies = routing_env_deps\n\n  routing_infconfig = InferenceConfig(\n         entry_script='routing_webservice.py',\n         source_directory='.\/scripts',\n         environment=routing_env\n     )\n\n\n\nReuse deployment config with lower capacity\n\n deployment_config.cpu_cores = 0.1\n deployment_config.memory_gb = 0.5\n    \n routing_service = Model.deploy(\n     workspace=ws,\n     name='routing-manymodels',\n     models=[dep_model],\n     inference_config=routing_infconfig,\n     deployment_config=deployment_config,\n     deployment_target=deployment_target,\n     overwrite=True\n )\n routing_service.wait_for_deployment(show_output=True)\n    \n assert routing_service.state == 'Healthy'\n    \n print('Routing endpoint deployed with URL: {}'.format(routing_service.scoring_uri))",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-02-25T14:51:13.933Z",
                "Answer_score":1,
                "Answer_body":"I solved it by rewriting all the code in Python and using the AKSWebService.update_endpoint method to update the endpoint without having to delete it each time (which was happening using the Model.deploy method).\n\nThanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to train TensorFlow pretrained Object Detection model in AzureML?",
        "Question_creation_time":1612228828727,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/254691\/how-to-train-tensorflow-pretrained-object-detectio.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"I have a problem to do custom TensorFlow2 Object Detection in AzureML (see https:\/\/www.tensorflow.org\/hub\/tutorials\/tf2_object_detection). I failed to install the API with error message as follow:\nobject_detection\/protos\/calibration.proto:41:3: Expected \"required\", \"optional\", or \"repeated\".\nobject_detection\/protos\/calibration.proto:41:6: Expected field name.\nobject_detection\/protos\/calibration.proto:53:3: Expected \"required\", \"optional\", or \"repeated\".\nobject_detection\/protos\/calibration.proto:53:6: Expected field name.\nERROR: Could not install packages due to an EnvironmentError: [('\/mnt\/batch\/tasks\/shared\/LS_root\/mounts\/clusters\/gpu-notebook\/code\/Users\/mengoon.lee\/models\/research\/a3c_blogpost\/a3c_cartpole.py',\nPlease help me. Thanks in advance.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-24T13:59:00.253Z",
                "Answer_score":0,
                "Answer_body":"@MengOonLee-5731 Thanks, Please follow the doc for protoc installation. We have tried from the AML Jupyter notebook compute instance (ex: Virtual machine size STANDARD_DS3_V2 CPU) we are able to follow the steps without the error that you are facing.\n\nThis is an underlying issue with shutil.copytree when doing dev install from mounted share to local conda env. https:\/\/bugs.python.org\/issue24564\n\nMitigation is to use the disk rather than fileshare for dev installs.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"'str' object has no attribute 'items'",
        "Question_creation_time":1613362872313,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/272689\/39str39-object-has-no-attribute-39items39.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I'm trying to consume a model that I deployed from Azure Machine Learning as a web service but I keep getting an error: 'str' object has no attribute 'items' Help: https:\/\/go.microsoft.com\/fwlink\/?linkid=2146748.\n\nI am following the Consume an Azure Machine Learning model deployed as a web service tutorial for calling the service using python.\n\nI followed the formatting as shown in the documentation but I still keep getting this error.\n\n import requests\n import json\n    \n # URL for the web service\n scoring_uri = 'http:\/\/00.00.00.00:00\/api\/v1\/service\/test\/score'\n # If the service is authenticated, set the key or token\n    \n    \n # Two sets of data to score, so we get two results back\n data = {\"data\":\n         [\n             {'volume': 0.23, \n              'temp': 0.66, }\n         ]\n         }\n # Convert to JSON string\n input_data = json.dumps(data)\n print(input_data)\n    \n # Set the content type\n headers = {'Content-Type': 'application\/json'}\n    \n    \n # Make the request and display the response\n resp = requests.post(scoring_uri, input_data, headers=headers)\n print(resp.text)\n\n\n\nAny ideas would be great, thanks!\n\nUPDATE:\nScoring script:\n\n import os\n import json\n    \n from azureml.studio.core.io.model_directory import ModelDirectory\n from pathlib import Path\n from azureml.studio.modules.ml.score.score_generic_module.score_generic_module import ScoreModelModule\n from azureml.designer.serving.dagengine.converter import create_dfd_from_dict\n from collections import defaultdict\n from azureml.designer.serving.dagengine.utils import decode_nan\n from azureml.studio.common.datatable.data_table import DataTable\n    \n    \n model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'trained_model_outputs')\n schema_file_path = Path(model_path) \/ '_schema.json'\n with open(schema_file_path) as fp:\n     schema_data = json.load(fp)\n    \n    \n def init():\n     global model\n     model = ModelDirectory.load(model_path).model\n    \n    \n def run(data):\n     data = json.loads(data)\n     input_entry = defaultdict(list)\n     for row in data:\n         for key, val in row.items():\n             input_entry[key].append(decode_nan(val))\n    \n     data_frame_directory = create_dfd_from_dict(input_entry, schema_data)\n     score_module = ScoreModelModule()\n     result, = score_module.run(\n         learner=model,\n         test_data=DataTable.from_dfd(data_frame_directory),\n         append_or_result_only=True)\n     return json.dumps({\"result\": result.data_frame.values.tolist()})",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-24T10:51:25.007Z",
                "Answer_score":0,
                "Answer_body":"@yjay-4307 Thanks, Here is the example, for the Multiclass Classification - Letter Recognition sample, the inference results are as follows:",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is There a Way to Visualize the Decision Tree AML Used?",
        "Question_creation_time":1612898717163,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/265984\/is-there-a-way-to-visualize-the-decision-tree-aml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":1,
        "Question_body":"I have used a Two-Class Boosted Decision Tree in Azure ML to make some predictions on data that I am analyzing. Once the model has completed training is there a way for me to visualize the structure of the decision tree that was ultimately used by Azure?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-10T16:17:06.287Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us. If you are under Azure Machine Learning Studio(Classic), you can easily do it by Right-click on the output node of the \"Train Model\" module and select \"Visualize\".\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/two-class-boosted-decision-tree#results\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-02-23T06:33:10.683Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nI have confirmed we don't have visualize function for Azure Machine Learning Designer now, but we would like to learn why you are asking about this feature and what you want to do with the visualized graph. We are caring customers' experience and will consider this function if that makes sense.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Fastai error running experiment on Azure ML",
        "Question_creation_time":1613753712050,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/280802\/fastai-error-running-experiment-on-azure-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hello everybody,\nI\u2019m working with Fastai (V. 2.1.7) on Azure Machine Learning (Azure ML) and I\u2019m having an issue.\n\nIf I train a model directly in the notebook, everything looks ok.\nWhen I try to run exactly the same python code into an experiment I get the following error.\n\n Traceback (most recent call last):\n   File \"train.py\", line 75, in <module>\n     learn.fit_one_cycle(8, 3e-3)\n   File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/callback\/schedule.py\", line 112, in fit_one_cycle\n     self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd)\n   File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/learner.py\", line 205, in fit\n     self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n   File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/learner.py\", line 154, in _with_events\n     try:       self(f'before_{event_type}')       ;f()\n   File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/learner.py\", line 196, in _do_fit\n     self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n   File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/learner.py\", line 154, in _with_events\n     try:       self(f'before_{event_type}')       ;f()\n   File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/learner.py\", line 190, in _do_epoch\n     self._do_epoch_train()\n   File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/learner.py\", line 182, in _do_epoch_train\n     self._with_events(self.all_batches, 'train', CancelTrainException)\n   File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/learner.py\", line 154, in _with_events\n     try:       self(f'before_{event_type}')       ;f()\n   File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/learner.py\", line 160, in all_batches\n     for o in enumerate(self.dl): self.one_batch(*o)\n   File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/data\/load.py\", line 103, in __iter__\n     yield self.after_batch(b)\n   File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastcore\/transform.py\", line 198, in __call__\n     def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx)\n   File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastcore\/transform.py\", line 150, in compose_tfms\n     x = f(x, **kwargs)\n   File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/vision\/augment.py\", line 34, in __call__\n     self.before_call(b, split_idx=split_idx)\n   File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/vision\/augment.py\", line 377, in before_call\n     self.do,self.mat = True,self._get_affine_mat(b)\n   File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/vision\/augment.py\", line 388, in _get_affine_mat\n     aff_m = _init_mat(x)\n   File \"\/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/fastai\/vision\/augment.py\", line 286, in _init_mat\n     mat = torch.eye(3, device=x.device).float()\n AttributeError: 'list' object has no attribute 'device'\n\n\n\nHave you ever experienced the same issue?\nDo you have any idea about it?\nThanks a lot",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How to implment the Azure ML model in the .NET Core web service",
        "Question_creation_time":1613442662890,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/274165\/how-to-implment-the-azure-ml-model-in-the-net-core.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"][1]\n\n\n\n\n\nI want to run this model on the website. The website is running now but I do not know how can I put models on.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-16T04:16:58.453Z",
                "Answer_score":1,
                "Answer_body":"HI @YuxuanTian-3512\n\nThank You for posting in Q & A.\n\nBased on your request to deploy your machine learning or deep learning model as a web service in the Azure cloud, refer the below URL.\nDeploy machine learning models to Azure\nDeploy your existing model with Azure Machine Learning\nConsuming Azure Machine Learning in ASP.NET Core\n\n\n\n\nIf the Answer is helpful, please click Accept Answer and up-vote, this can be beneficial to other community members.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"MLOps For Python with R code",
        "Question_creation_time":1613119407860,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/270615\/mlops-for-python-with-r-code.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hello Azure MLOps Team,\n\nI am looking at the reference architecture https:\/\/docs.microsoft.com\/en-us\/azure\/architecture\/reference-architectures\/ai\/mlops-python.\n\nMost of our data science models are made in R. I am wondering, which part of the MLOps process (Azure Pipelines or Azure ML Compute\/Azure ML Pipelines) can be configured in Python for R code to run?\n\nOur preference is to leverage as much Python as possible for the code R code. I see there is an Azure ML SDK for python and R. Can we use Azure ML SDK in Python with R codebase?\n\nKind regards,\nSlava Keshkov",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-13T20:25:30.677Z",
                "Answer_score":0,
                "Answer_body":"Hi Slava,\n\nI found this for you: https:\/\/rstudio.com\/resources\/rstudioconf-2020\/mlops-for-r-with-azure-machine-learning\/\n\nIn the video David is talking about Devops for R at 10:58. Why dont you ping David on Twitter to inquire more about it? If Microsoft is not able to support it officially I think you can build your own pipelines deploying models within AKS and using Azure storage with Azure Functions for pushing data to the model and pulling out forcasts.\n\nHope this helps.\n\nThanks,\nVaibhav",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-02-19T23:31:16.65Z",
                "Answer_score":0,
                "Answer_body":"Here's the azureml sdk for R repo for your reference.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error in score.py file while deploying a machine learning model through python",
        "Question_creation_time":1613655483977,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/278693\/error-in-scorepy-file-while-deploying-a-machine-le.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I have trained a machine learning model through python locally and I'm trying to deploy it to Azure with inference cluster. I'm able to train, upload data, register model but I'm unable to deploy the model. It's throwing path error but I have tried all the possible paths for my model. What is the correct path to the model? I have attached the error and code below for your reference. Any help is appreciated. Thanks a lot.\n\nError:\n\"code\": \"KubernetesDeploymentFailed\",\n\"statusCode\": 400,\n\"message\": \"Kubernetes Deployment failed\",\ndetails\":\n\"code\": \"CrashLoopBackOff\",\n\"message\": \"Error in entry script, FileNotFoundError: [Errno 2] No such file or directory: 'azureml-models\/amlstudio-mlpredictionep01\/1\/sklearn_ml_exp', please run print(service.get_logs()) to get details.\"\n\nHere is my score.py file:\n\ndef init():\nglobal model\nmodel_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'sklearn_ml_exp')\nmodel = joblib.load(model_path)\n\n\ndef run(raw_data):\ndata = np.array(json.loads(raw_data)['data'])\ny_hat = model.predict(data)\nreturn y_hat.tolist()\n\nI registered the model with:\n\nmodel = Model.register(workspace=ws,\nmodel_name='sklearn_ml_exp',\nmodel_path='outputs\/prediction-model.pickle', # local path\ndescription='Prediction model',\ntags={'data-format': 'CSV'},\nmodel_framework=Model.Framework.SCIKITLEARN,\nmodel_framework_version='0.20.3')",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-18T20:27:19.747Z",
                "Answer_score":1,
                "Answer_body":"Hi, looks like you need to specify the correct model path that you used when you registered. It should look like this sklearn_mnist_model.pkl. The following document provides information on how to locate models in your entry script. Hope this helps!",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to change MS Learn Display Name in Microsoft Cloud Skills Challenge?",
        "Question_creation_time":1610604860147,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/230124\/how-to-change-ms-learn-display-name-in-microsoft-c.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":1,
        "Question_body":"Yesterday I enrolled Microsoft Cloud Skills Challenge for study.\n\nBut when I enroll the challenge, I did not write proper name at MS Learn Display Name blank.\n\nSo I want to change the MS Learn Display Name.\n\nHow can I do this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-14T06:27:38.933Z",
                "Answer_score":0,
                "Answer_body":"On right top of this page, click you profile icon and click on profile. Then in the settings you can update the display name\n\nIs that what you were looking for?\n\n\n\n\n\nPlease don't forget to Accept Answer and Up-vote if the response helped -- Vaibhav",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-02-18T22:54:19.773Z",
                "Answer_score":0,
                "Answer_body":"Thanks this was helpful",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Personal ML workspace",
        "Question_creation_time":1613672886057,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/279065\/personal-ml-workspace.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hi, I have an MS Azure account as part of Capita. I am interested in doing the Create Machine Learning Model course offered via MS Azure. To do this I am required to create an ML Workspace. Is it safe for me to do this? i.e. will this just be private to my user or will it be public? Thanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-18T21:40:13.647Z",
                "Answer_score":0,
                "Answer_body":"Hi, when creating a workspace, you have to specify the subscription id and resource group. With an enterprise subscription, members of your organization may have access to your resources (verify with your admin). However, you can manage access to an Azure Machine Learning workspace and view access to your resources. If it's your personal Azure account, then it should be private to you unless you grant access to others.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Autoscaling on Azure Machine Learning with R",
        "Question_creation_time":1612696726743,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/262211\/autoscaling-on-azure-machine-learning-with-r.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Hello, I have a two part question.\n\nI'm using Azure Machine Learning to train my model using Compute clusters. I'm using F64s v2 VM (64 vCPU and 128 GB of RAM). To be ablo to use all the 64 cores I used the doFuture package in R adding this code before tuning:\n\n registerDoFuture()\n n_cores <- parallel::detectCores()\n plan(\n     strategy = cluster,\n     workers = parallel::makeCluster(n_cores)\n )\n\n\n\nThis works on my Windows 10 machine so I though this would also work on the VM, is this correct?\n\n\n\n\nMy other question is related to the autoscaling of the Compute cluster. The cluster can scale up to three nodes, so I guess it could be 192 cores and 384 of RAM. When monitoring the cluster I was only using one node instead of all three, i.e. there was only one Busy nodes and two Unprovisioned nodes.\nIn the end the code failed with this error message:\nError in unserialize(node$con) :\nFailed to retrieve the value of ClusterFuture (doFuture-1) from cluster SOCKnode #1 (on \u2018localhost\u2019). The reason reported was \u2018error reading from connection\u2019\n\nwhich I think means I'm out of memory, is this correct? If so, why didn't the cluster scale up to three nodes?\n\n\n\n\nSee attached screenshot where only one node is busy but two unprovisioned.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-08T10:23:09.14Z",
                "Answer_score":0,
                "Answer_body":"@Vidar-9341 I am not really expert at R but based on some threads i looked up online the call to detect cores should work on a virtual machine too but with detectCores(logical = TRUE) instead of the default FALSE.\n\nWith respect to the compute cluster where only one node got provisioned, is there any limit on quota for your subscription for this series that needs to be increased? This is usually visible on the subscription page on Usage+Quotas tab. You can filter the resources with provide Microsoft.Compute and check the appropriate VM offering limits and request an increase for that region. The request for increase is a support case where the option is available on this page on the top right corner to Request Increase.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-02-08T13:18:36.347Z",
                "Answer_score":0,
                "Answer_body":"Hi @romungi-MSFT\n\nThank you so much for the answer. Regarding the quota limit, I have 200 cores limit and the VM I'm using is the following:\n\n\n\n\nso I should be able to use 3 nodes (64 * 3 = 192) if needed if I understand it correctly.\nThe two unprovisioned nodes are nodes not in use, right?",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to Consume a trained model saved as web service",
        "Question_creation_time":1612313789263,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/256246\/how-to-consume-a-trained-model-saved-as-web-servic.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Hello all,\n\nI trained a model which uses cross-validation. So I can not save it locally as trained model as far as I know. For this case, I tried to to deploy it as web service.\n\nFor example, I trained a model called X. Then, I created a new experiment called Y to consume this trained model X. I tried to drag and drop load trained model to use model X via web service. it does not work. Could you please guide me how I can consume my trained model that saved as web-services. Or Can you please let me know how I can save my model that using cross-validation locally?\n\n\n\n\n-Best",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-03T15:45:21.327Z",
                "Answer_score":0,
                "Answer_body":"@SultanFahadAAlmassariRITStudent-7775 Are you using the Azure ML classic studio or the designer? If you are using designer you should be able to download the model from the models tab on ml.azure.com\n\nIdeally, if you are using classic or designer models your trained models are available in the predictive experiment or real time inference pipeline after you complete the training.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Retrain a model programmatically with python",
        "Question_creation_time":1613484358493,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/275122\/retrain-a-model-programmatically-with-python.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I have created a Scikit-learn model with python and I have ran the experiment. Now , I need to retrain the model with new data through python but its mentioned in the documentation that we need to create a batch interference pipeline to retrain a model. If I create a batch interference pipeline, will I be able to deploy it? Any help will be appreciated. Thanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-16T21:45:05.22Z",
                "Answer_score":0,
                "Answer_body":"Batch Inference Pipeline is useful for making predictions on large data and you can publish the pipeline to your workspace. To retrain your model programmatically, you can simply run your experiment again, then save and register the model to use at the deployment stage. Please review Azure ML Pipelines for more details on how to optimize your workflow.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Update real-time webservice with the retrained endpoint or published pipeline",
        "Question_creation_time":1613014495637,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/268354\/update-real-time-webservice-with-the-retrained-end.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I have already tried with the documentation how-to-deploy-update-web-service. I need a detailed explanation on how to update a web service with the experiment run or pipeline endpoint. There is no clear explanation in the link. I trained the model in the designer from scratch. I need to automate the whole flow of retraining the model and updating the web service. Any help is appreciated.\n\nPlease answer the following questions:\n1) How do I give the model path for a trained model from the retrained experiment or published pipeline?\n2) What is the tags field that I need to mention ?\n3) what is the deploy environment I need to specify?\n4) What to specify in the place of score.py?\n\nws = Workspace.get(name=\"xxx\", subscription_id='xxx, resource_group='xxx')\nnew_model = Model.register(model_path=\"azureml\\\\ce6116ec-cd48-4115-a567-e0eeed49f5b5\\Trained_model\",\nmodel_name=\"Trained_model\",\ntags=tags)\ndeploy_env = Environment.get(workspace=ws, name=\"AzureML-PyTorch-1.4-GPU\", version=\"3\")\ninference_config = InferenceConfig(entry_script=\"score.py\",\nenvironment=deploy_env)",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-11T16:50:06.107Z",
                "Answer_score":0,
                "Answer_body":"Hi, you cannot use the SDK to update a web service published from the Azure Machine Learning designer. For designer, you need to go through the deploy process to deploy the endpoint. You can test the real-time endpoint directly in the portal to verify the output of your endpoint. To consume your model, you can use various clients for calling the web service. For a more automated workflow, please check out published pipelines for retraining models.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How do I deploy the run after retraining a published endpoint and consume it?",
        "Question_creation_time":1612959835657,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/267341\/how-do-i-deploy-the-run-after-retraining-a-publish.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I have created an ML model and created a real time endpoint with the model and also published the pipeline. I retrained it with a different parameter and ran the experiment. Also I have published the endpoint. Now how do I deploy it or replace it with the already created endpoint?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-10T19:16:27.887Z",
                "Answer_score":0,
                "Answer_body":"Hi, this document provides information on how to update a web service that was deployed with Azure Machine Learning. Hope this helps.",
                "Answer_comment_count":5,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Missing PIL from AzureML TF 2.3 curated environment",
        "Question_creation_time":1613413000850,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/273860\/missing-pil-from-azureml-tf-23-curated-environment.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I've been attempting to run my machine learning experiments (computer vision) on the curated environment AzureML provides, that has TensorFlow 2.3 (whose dependency should be PIL), but I keep getting an error stating that PIL is not present. Specifically, it crashed at it saying that PIL.Image cannot be imported.\n\nI have run my script on my local computer without issue using the same dependencies (as saved from the curated environment). The error only seems to happen on the remote during a run.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Training Auto ML models from a Python script via Azure Functions is failing with MemoryError",
        "Question_creation_time":1612783690643,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/263618\/training-auto-ml-models-from-a-python-script-via-a.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Hi,\n\nI'm trying to do the following:\n- I want to run an Auto ML training script in Azure Functions via a Python script.\n- I have configured a remote compute and a dataset in Azure ML that I'm using. The dataset is a 22 KB csv file.\n- When I start the experiment the script fails with a memory error complaining about the system running out of memory (see below)\n- I get the error regardless of what app service plan tier I'm using; the script isn't actually running out of memory based on the metrics\n\n 2021-02-08T11:11:09.395 [Error] Executed 'Functions.AutomatedAutoMLTrainerWorker' (Failed, Id=1857c033-8199-444f-8deb-b2de73d44741, Duration=73313ms)\n Result: FailureException: MemoryError: Engine process terminated. This is most likely due to system running out of memory. Please retry with increased memory. |session_id=c2ed81b1-66b1-4dda-82b6-056b335eaec0\n Stack:   \n File \"\/azure-functions-host\/workers\/python\/3.7\/LINUX\/X64\/azure_functions_worker\/dispatcher.py\", line 357, in _handle__invocation_requestself.__run_sync_func, invocation_id, fi.func, args)\n File \"\/usr\/local\/lib\/python3.7\/concurrent\/futures\/thread.py\", line 57, in runresult = self.fn(*self.args, **self.kwargs)File \"\/azure-functions-host\/workers\/python\/3.7\/LINUX\/X64\/azure_functions_worker\/dispatcher.py\", line 542, in __run_sync_funcreturn func(**params)\n File \"\/home\/site\/wwwroot\/AutomatedAutoMLTrainerWorker\/__init__.py\", line 64, in mainrun = experiment.submit(automl_config, show_output=True)\n File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/core\/experiment.py\", line 220, in submitrun = submit_func(config, self.workspace, self.name, **kwargs)\n File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/train\/automl\/automlconfig.py\", line 102, in _automl_static_submitshow_output)\n File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/train\/automl\/automlconfig.py\", line 214, in _start_executionautoml_run = _default_execution(experiment, settings_obj, fit_params, False, show_output)\n File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/train\/automl\/automlconfig.py\", line 127, in _default_executionreturn automl_estimator.fit(**fit_params)\n File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/train\/automl\/_azureautomlclient.py\", line 218, in fittest_data\n File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/automl\/core\/dataset_utilities.py\", line 90, in convert_inputs_datasetreturn tuple([_convert_to_trackable_definition(dataset) for dataset in datasets])\n File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/automl\/core\/dataset_utilities.py\", line 90, in <listcomp>return tuple([_convert_to_trackable_definition(dataset) for dataset in datasets])\n File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/automl\/core\/dataset_utilities.py\", line 162, in _convert_to_trackable_definitiondefinition, trackable = _reference_dataset(dataset)\n File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/automl\/core\/dataset_utilities.py\", line 178, in _reference_datasetreturn dataset._dataflow, False\n File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/data\/_loggerfactory.py\", line 129, in wrapperreturn func(*args, **kwargs)\n File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/data\/abstract_dataset.py\", line 208, in _dataflowdataprep().api._datastore_helper._set_auth_type(self._registration.workspace)\n File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/_datastore_helper.py\", line 143, in _set_auth_typeget_engine_api().set_aml_auth(SetAmlAuthMessageArgument(AuthType.DERIVED, json.dumps(auth)))\n File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py\", line 19, in get_engine_api_engine_api = EngineAPI()\n File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py\", line 69, in __init__connect_to_requests_channel()\n File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py\", line 56, in connect_to_requests_channelself._engine_server_secret = self.sync_host_secret(self.requests_channel.host_secret)\n File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/_aml_helper.py\", line 38, in wrapperreturn send_message_func(op_code, message, cancellation_token)\n File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/api.py\", line 260, in sync_host_secretresponse = self._message_channel.send_message('Engine.SyncHostSecret', message_args, cancellation_token)\n File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/engine.py\", line 275, in send_messageraise message['error']\n File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/engine.py\", line 223, in process_responsesresponse = self._read_response(caller='MultiThreadMessageChannel.process_responses')\n File \"\/home\/site\/wwwroot\/.python_packages\/lib\/site-packages\/azureml\/dataprep\/api\/engineapi\/engine.py\", line 148, in _read_responseraise error\n\n\n\nMy requirements.txt for the function app looks like this:\n\n azure-functions==1.6.0\n azureml-core==1.21.0\n azureml-train-automl-client==1.21.0\n azureml-contrib-functions==1.21.0\n azure-storage-queue==12.1.5\n ruamel.yaml>=0.16.5\n PyJWT==1.7.1\n\n\n\n\nMy training script looks like this:\n\n import logging\n    \n import azure.functions as func\n import os\n import tempfile\n    \n import azureml.core\n from azureml.core import Experiment, Workspace\n from azureml.core.environment import Environment\n from azureml.core.dataset import Dataset\n from azureml.core.compute import ComputeTarget, AmlCompute\n from azureml.core.authentication import MsiAuthentication\n from azureml.train.automl import AutoMLConfig\n    \n    \n def main(msg: func.QueueMessage) -> None:\n     tenant_id = os.getenv(\"TenantId\")\n     resource_group = os.getenv(\"AzureMLResourceGroup\")\n     workspace_name = os.getenv(\"AzureMLWorkspace\")\n     compute_name = os.getenv(\"AzureMLComputeName\")\n     dataset_name = os.getenv(\"AzureMLDataSetName\")\n     dataset_label_column = os.getenv(\"AzureMLDataSetLabelColumn\")\n     experiment_name = os.getenv(\"AzureMLExperimentName\")\n    \n     msi_auth = MsiAuthentication()\n     ws = Workspace(subscription_id=tenant_id,\n                resource_group=resource_group,\n                workspace_name=workspace_name,\n                auth=msi_auth)\n    \n     compute_target = ws.compute_targets[compute_name]\n    \n     dataset = Dataset.get_by_name(workspace=ws, name=dataset_name)\n    \n     tempFilePath = tempfile.gettempdir() + '\/debug.log'\n     automl_config = AutoMLConfig(task='regression',\n                                    experiment_timeout_minutes=60,\n                                    primary_metric='normalized_root_mean_squared_error',\n                                    training_data=dataset,\n                                    compute_target=compute_target,\n                                    label_column_name=dataset_label_column,\n                                    debug_log=tempFilePath)\n    \n     experiment = Experiment(ws, experiment_name)\n    \n     run = experiment.submit(automl_config, show_output=True)\n     run.wait_for_completion()\n\n\n\n\nDoes anyone have a clue what might be going wrong? :)",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-12T04:14:33.33Z",
                "Answer_score":0,
                "Answer_body":"@Joonasijl-7350 Thanks, are you able to increase the allocated memory for the container where the training is happening?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"R device Loading variable to data frame not complete",
        "Question_creation_time":1611736150143,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/246934\/r-device-loading-variable-to-data-frame-not-comple.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"This is my code\ndo.call ( rbind, with( dataset1, tapply(ShotonScreen2, interaction(LotnoS=LotnoS , ProductCode=ProductCode), quantile,\nprobs=c(0, .25,.5, 0.75, 1) ) ) )\n\nSelect data.frame to be sent to the output Dataset port\n\nmaml.mapOutputPort(\"dataset1\");\n\n\n\n\nR device port (Loading variable ) show \"Loading variable port1...\"\n0% 25% 50% 75% 100%\n6319\/A16.ZDE1DWW70500009 0.270 0.5050 0.740 0.9000 1.06\n6319\/A17.ZDE1DWW70500009 0.300 0.3825 0.445 0.5825 0.89\n6319\/A18.ZDE1DWW70500009 0.470 0.4700 0.470 0.4700 0.47\n6320\/A01.ZDE1DWW70500009 0.330 0.3725 0.475 1.2675 1.99\n\nHow to import this in table format for analysis\n\nI try to use\ndata.set <- data.frame (\ndo.call ( rbind, with( dataset1, tapply(ShotonScreen2, interaction(LotnoS=LotnoS , ProductCode=ProductCode), quantile,\nprobs=c(0, .25,.5, 0.75, 1) ) ) )\n)\n\nI get this that has not first column ( ex. 6319\/A16.ZDE1DWW70500009)\n0. X25. X50. X75. X100.\n\n0.27 0.505 0.74 0.9 1.06\n0.3 0.3825 0.445 0.5825 0.89\n0.47 0.47 0.47 0.47 0.47\n0.33 0.3725 0.475 1.2675 1.99\n0.2 0.2675 0.33 0.3925 0.52\n\nPlease suggest me,\nI sorry for my english is not good.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-28T06:57:16.997Z",
                "Answer_score":1,
                "Answer_body":"@PhatthaPhokasuntarangkoon-8088 I am not really familiar with R but it looks like you are trying to load your R module with a dataframe of input data and after processing the first column is not in the output dataset or port. Did you try just putting a simple code to return the input as-is as a list as mentioned in this first example? Just wanted to ensure the pre-processing is not stripping the first column and if the code above works outside R module of Azure machine learning designer. Thanks!!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-02-16T00:34:13.43Z",
                "Answer_score":0,
                "Answer_body":"I am very new in azure, would like to give more information.\nI want the result show in my dataset, not in r device.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Remote run model unable to be saved",
        "Question_creation_time":1613083790957,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/270011\/remote-run-model-unable-to-be-saved.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I've built models using the AutoML function and I'm trying to call the best model to deploy into production. The AutoML function ran correctly and produced the ~35 models. My goal is to pull the best model. Here is the code:\n\nbest_run, fitted_model = remote_run.get_output()\nfitted_model\n\nWhen runnning the code, I get the following error:\n\nAttributeError: 'DataTransformer' object has no attribute 'enable_dnn'\n\nAny help would be much appreciated.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-12T11:23:05.603Z",
                "Answer_score":0,
                "Answer_body":"@BernardoJaccoud-0827 Did your run configure enable_dnn i.e bert settings of automated ML? I am curious to understand what the status of your run is directly on the portal ml.azure.com?",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"unable to call Workspace class and save to variable ws, MSLearning Path module 08",
        "Question_creation_time":1611691140170,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/246099\/unable-to-call-workspace-class-and-save-to-variabl.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"I keep getting error, running commands in Jupyter notebook.\n\nimport azureml.core\nfrom azureml.core import Workspace\nws = Workspace.from_config()\nprint('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))\n\nreturn RED text line number = 4 # Load the workspace from the saved config file\n----> 5 ws = Workspace.from_config()\nanother line in RED = --> 292 resource_group=resource_group)\n\nI seem to be unable to call the Workspace Class\n\nI have tried these\n\nprint(Workspace.get('worksp_mike1')) fails with TypeError, _get_ambient_new() takes 1 positional argument but 2 were given\n\n\nWorkspace.get_details() ... return = TypeError: get_details() missing 1 required positional argument: 'self'\n\n\nI have run this successfully = !pip install --upgrade azureml-sdk azureml-widgets\n\n\nthis also runs OK, print(\"SDK version:\", azureml.core.VERSION) = SDK version: 1.21.0\n\n\nI get the same ws error in previous modules....\n\nthis is where I am, module 08 in Jupyter, \"Create a Pipeline\"\nhttps:\/\/microsoftlearning.github.io\/mslearn-dp100\/",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-27T07:50:26.537Z",
                "Answer_score":0,
                "Answer_body":"@MikeRichardson-3493 In this case it looks like the step wants to load a workspace from a config file. The config file will contain the subscription id, resource group and workspace name and when you run Workspace.from_config() the details are loaded from this file and used in the next cells. A configuration sample notebook is available here to setup and you can try to create this and load the workspace details and use them.\n\n from azureml.core import Workspace\n    \n subscription_id = \"<my-subscription-id>\"\n resource_group = \"<my-resource-group>\"\n workspace_name = \"<my-workspace-name>\"\n    \n ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n ws.write_config()",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-02-14T07:58:27.507Z",
                "Answer_score":0,
                "Answer_body":"I'm not sure what the actual issue is, as I was also initially unable to run the code block which instantiates the Workspace object, and was getting the same error as the OP.\n\nThis was when I cloned the repository into an Azure ML workspace I had previously created.\n\nTo fix it, I created a new workspace (https:\/\/microsoftlearning.github.io\/mslearn-dp100\/instructions\/01-create-a-workspace.html) and cloned the git repository for the learning path as specified, and then it somehow worked fine.\n\nI did not need to add the config file - from my understanding, you should only need to do that if you're using the SDK on your own machine, not if you're accessing Jupyter for your workspace via ML studio.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"standard NC6 is very slow",
        "Question_creation_time":1613141409857,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/271125\/standard-nc6-is-very-slow.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I run a code on a machine with a GPU (standard NC6) (a simple Keras model)\n\nI also run the same python code on google Colab for free\n\nthe Azure ML is extremely slow in performance compared to the Colab\n\nwhat is the problem with my machine?\n\nI'm thinking of deleting my azure account.\nhow can I delete it and remove my credit card?\n\n(You can see how frustrated I am)",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-12T23:20:21.527Z",
                "Answer_score":0,
                "Answer_body":"Hi, sorry you're experiencing slow performance. Have you tried other compute options to optimize performance? Please refer to these document for managing your Azure subscription and billing.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Why the storage account assosiated to azure machine learning has differenent region compared ML workspace?",
        "Question_creation_time":1613120096110,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/270693\/why-the-storage-account-assosiated-to-azure-machin.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I have created a machine learning workspace in West Europe region. But the storage account, key vault and application insights got created in East US region. All these got created by default with creation on ML workspace.\nSo I want to know the reason for different region and also want to move the storage account to West Europe region.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-12T22:09:04.633Z",
                "Answer_score":0,
                "Answer_body":"Hi, this is unusual. There's no way to move your default AML storage account to a different region. I recommend creating a new workspace or contacting Azure Support to investigate further.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"What is a working way to set up a custom Environment in AzureML using the Python SDK",
        "Question_creation_time":1612894252760,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/265924\/what-is-a-working-way-to-set-up-a-custom-environme.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"Below are my conda yml, Dockerfile and register.py(python SDK script) to create and register a custom environment in my AzureML Workspace. The AzureML documentation recommends this, if a custom system package should be installed. For me this is Graphviz. The conda environment and the docker file run successfully locally. However with my register.py script it fails:\n\n\n\n\n66005-register.txt\n\n\n\n\n66042-conda.txt\n\n\n\n\n66033-dockerfile.txt",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-10T14:22:09.727Z",
                "Answer_score":0,
                "Answer_body":"@SprangerJordi-5775 Thanks for the question. Environments provide a way to manage software dependency so that controlled environments are reproducible with minimal manual configuration as you move between local and distributed cloud development environments. For more information about using environments for training and deployment with Azure Machine Learning, see Create and manage reusable environments.\nHere is doc to add packages to an environment, Notebook to Train a model locally: Directly on your machine and within a Docker container.\n\nAML currently sends a deserialized version of the Conda spec to Azure Container Registry for image building. This means that local artifacts (e.g., local pip packages, local requirements files) don't exist at image build time. There is a long-term approach to fixing this, anticipated to land in near future.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"I have created an ML model and retrained it manually in the designer. While updating the web service, its asking for a score.py file. How do I prepare the score.py file for a model that I have created through designer?",
        "Question_creation_time":1613025843247,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/268585\/i-have-created-an-ml-model-and-retrained-it-manual.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I have trained a model , deployed and retrained completely through azure designer pipeline. Now , I need to update the existing web service with the new one after retraining. Its asking for a score.py file in the inference_config (python sdk). How do I prepare a score.py file for an existing model? Any help is appreciated. Thanks a lot :)",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-11T17:30:10.71Z",
                "Answer_score":0,
                "Answer_body":"Duplicate, please review response provided here.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning (and cognitive services) is not supported in Region \"Germany\"?",
        "Question_creation_time":1612860215177,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/265151\/azure-machine-learning-and-cognitive-services-is-n.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"I'm working for a campany located in Germany. We want to use Azure Machine Learning (and other stuff like that).\nWe are only allowed to use Azure in the Region \"Germany\", because the data of our customers cannot left germany.\n\nNow I saw, that a lot of stuff in Azure Machine Learning is not available in Germany?\n\nQuestions:\n1. Is that true?\n2. Does some one now, at what time Microsoft plans to make the stuff available in Germany?\n\nThank you for a answer!\n\nPatrick",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-09T09:16:36.647Z",
                "Answer_score":0,
                "Answer_body":"Hi @PatrickHuber-5684\nYes, Azure Machine Learning is not available in Germany region.\n\nPlease check in Azure feedback\n\nIf the Answer is helpful, please click Accept Answer and up-vote, this can be beneficial to other community members.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-02-10T08:23:01.1Z",
                "Answer_score":0,
                "Answer_body":"Thank you for your answser!\nDo you perhaps know anything about, when the features are supported?\n\nThank you!",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"ModuleNotFoundError: No module named 'azureml'",
        "Question_creation_time":1609112074090,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/211503\/modulenotfounderror-no-module-named-39azureml39.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Hi,\n\nI am doing the Challenge. https:\/\/docs.microsoft.com\/en-us\/learn\/modules\/intro-to-azure-machine-learning-service\/\n\n\n\n\nPlease see what I have installed:\n\npip install azureml-sdk\n\nI am getting the following messages at the end:\n\n\n\n\nERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n\n\nWe recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n\n\njupyterlab 2.2.9 requires jupyterlab-server<2.0,>=1.1.5, which is not installed.\nSuccessfully installed applicationinsights-0.11.9 azure-identity-1.4.1 azureml-automl-core-1.19.0 azureml-dataprep-2.6.3 azureml-dataprep-native-26.0.0 azureml-dataprep-rslex-1.4.0 azureml-dataset-runtime-1.19.0.post1 azureml-pipeline-1.19.0 azureml-pipeline-core-1.19.0 azureml-pipeline-steps-1.19.0 azureml-sdk-1.19.0 azureml-telemetry-1.19.0 azureml-train-1.19.0 azureml-train-automl-client-1.19.0 azureml-train-core-1.19.0 azureml-train-restclients-hyperdrive-1.19.0 distro-1.5.0 dotnetcore2-2.1.20 fusepy-3.0.1 msal-1.8.0 msal-extensions-0.2.2 numpy-1.19.3 portalocker-1.7.1 pyarrow-1.0.1 pywin32-227\n\n\n\n\nNow I am trying to start up and type the following in .py file in Visual Studio Code\n\nfrom azureml.core import Workspace\n\nThis is the error message I am getting:\n\nFile \"c:\/Users\/User\/OneDrive\/Desktop\/New folder\/Build AI Solution\/automl_python.py\", line 1, in <module>\nfrom azureml.core import Workspace\nModuleNotFoundError: No module named 'azureml'\n\n\n\n\nPlease could you help me?\n\nthanks,\n\nNaveen",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-15T23:26:14.427Z",
                "Answer_score":28,
                "Answer_body":"This is now solved. Thanks!",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2020-12-29T06:50:34.837Z",
                "Answer_score":1,
                "Answer_body":"@Naveen-5899 From the above error it looks like the package did not install successfully. Could you please try to downgrade jupyterlab to a version >=1.1.5 but <2.0 and try to re-install the azureml SDK? Currently you are using jupyterlab 2.2.9\n\nA more detailed procedure to install the SDK is available directly in the documentation.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to access user activity logs of azure machine learning workspace for audit purpose?",
        "Question_creation_time":1612341541173,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/256833\/how-to-access-user-activity-logs-of-azure-machine.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"We are looking for API or Azure services from which will be able to access the activity of users in the Azure ML workspace. And also access the user activity logs related Compute instances associated with ML workspace.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-10T10:16:16.417Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nYou can use Azure Monitor to moderate your service if you are the admin.\n\nAzure Machine Learning creates monitoring data using Azure Monitor, which is a full stack monitoring service in Azure. Azure Monitor provides a complete set of features to monitor your Azure resources. It can also monitor resources in other clouds and on-premises.\n\nPlease refer to below guidance about to how check the log.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/monitor-azure-machine-learning#analyzing-logs\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AzureML Classic Workspace New Webservices : New-AzMlWebService Powershell module",
        "Question_creation_time":1606389917980,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/176959\/azureml-classic-workspace-new-webservices-new-azml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"All,\nDoes anyone know how to use this powershell module to deploy a new webservice in the azure ml classic studio? I am able to deploy an existing experiment to a new webservice from the portal. I am trying to achieve the same using powershell.\nTried this cmdlet but couldnt succeed.\n\n\nAll I want is to deploy an experiment to a \"new\" webservice and choose a webservice plan using powershell.(like the following image action in the portal.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-10T09:14:10.467Z",
                "Answer_score":0,
                "Answer_body":"Hello Sriram,\n\nHope you are doing well. I am sorry for the late response according to this issue. To create a \"web service \" , you can use below command:\nNew-AzMlWebService (\"new\" web services)\nNew-AmlWebService (\"classic\" web services)\n\nNew-AzMlWebService\n-ResourceGroupName <String>\n-Location <String>\n-Name <String>\n-DefinitionFile <String>\n[-Force]\n[-DefaultProfile <IAzureContextContainer>]\n[-WhatIf]\n[-Confirm]\n[<CommonParameters>]\n\nMore information about this can be found in the guidance:\n\nSamples: https:\/\/github.com\/hning86\/azuremlps#new-amlwebservice\n\nInformation:https:\/\/docs.microsoft.com\/en-us\/powershell\/module\/az.machinelearning\/new-azmlwebservice?view=azps-5.5.0\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Dataset + Preprocessed Text : Parameter \"Stopwords columns\" value should be less than or equal to parameter \"1\" value. . ( Error 0007 )",
        "Question_creation_time":1612874807950,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/265397\/dataset-preprocessed-test-parameter-34stopwords-co.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"I encounter the following error :\n\nParameter \"Stopwords columns\" value should be less than or equal to parameter \"1\" value. . ( Error 0007 )\nwhen building a simple pipeline :\n\nwith a .csv Dataset followed by a \"Preprocessed Text\".\n\nNo parameter 'Stopwords columns' is available in the \"Preprocessed Text\" properties !!!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-09T13:42:08.547Z",
                "Answer_score":0,
                "Answer_body":"Solved.\n\nThere must be only one connection (left: Dataset) and not 2 connections (left : Dataset + right : Stopwords) from the \"Dataset\" to the \"Preprocessed Text\"",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"UNZIP large zip file in azure machine learning",
        "Question_creation_time":1612431352160,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/258610\/unzip-large-zip-file-in-azure-machine-learning.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I have a big zip file, I need to unzip it in order to use the files in my notebook\n\nI used this script in my notebook :\n\nimport os\nimport zipfile\nlocal_zip = 'Caltech101.zip'\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('Caltech101')\nzip_ref.close()\n\nit succeeded (green v in the notebook), but only the first two folders were unzipped.\nthis file is only 130 MB\nI also need to unzip 3 GB zip file",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-05T18:20:48.12Z",
                "Answer_score":0,
                "Answer_body":"Thanks for following up. Can you please try available public datasets in this dataset repository to determine if you experience the same issue? If you're able to upload other files to Azure ML Notebook and unzip them successfully, then the issue is most likely related to your file content\/format.",
                "Answer_comment_count":6,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Integrate Azure ML Model with Power BI by using Python",
        "Question_creation_time":1612444605970,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/258899\/integrate-azure-ml-model-with-power-bi-by-using-py.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Dear Sir\/ Madam,\nWhile I was trying to integrate Azure ML Model(classic) with Power BI I searched for Python script but was not able to find any code or video regarding the integration through Python.\n\nIf there is any way to integrate them please share.\n\nRegards,\nNikhil.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-06T02:56:39.573Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us. I am not sure what kind of Python script you are looking for.\n\nBut I do have posted the guidance of how to integrate machine learning model with PowerBI below. Please let me know more about your requirement so that we can help to find out the best guidance.\n\nhttps:\/\/docs.microsoft.com\/en-us\/power-bi\/connect-data\/service-aml-integrate\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Package \u2018AzureML\u2019 is not available In R",
        "Question_creation_time":1612444037050,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/258928\/package-azureml-is-not-available-in-r.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Dear Sir\/ Madam,\nI was trying to Integrate Azure ML Model(classic) with Power BI using R script and I was running following code.\n[\nwsid = \"\"\nauth = \"\"\nserviceName = \"Name of Exp\"\n\nwas trying to install AzureML but it shows the error attached in the picture.\n\nlibrary(\"AzureML\")\n\nws <- workspace(wsid, auth)\nds <- consume(services(ws, name = serviceName),dataset)\nds <- data.frame(ds,dataset)\n]\n\nI tried different version of R but it is giving me the same error, Please Help.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-08T16:01:28.457Z",
                "Answer_score":0,
                "Answer_body":"Hello,\nThanks for reaching out to us. Please make sure you are following below steps to install the enviorment.\n\nInstall Conda\nIf you do not have Conda already installed on your machine, you will first need to install it, since the Azure ML R SDK uses reticulate to bind to the Python SDK. We recommend installing Miniconda, which is a smaller, lightweight version of Anaconda. Choose the 64-bit binary for Python 3.5 or later.\n\nInstall the azuremlsdk R package\nThe stable release of the Azure ML SDK can be installed from CRAN or the development version can be installed from GitHub. You will need remotes to install the azuremlsdk package.\n\n install.packages('remotes')\n\n\n\nThen, you can use the install_github or install_cran functions to install the package.\n\n remotes::install_github('https:\/\/github.com\/Azure\/azureml-sdk-for-r')\n remotes::install_cran('azuremlsdk', repos = 'https:\/\/cloud.r-project.org\/')\n\n\n\nIf you are using R installed from CRAN, which comes with 32-bit and 64-bit binaries, you may need to specify the parameter INSTALL_opts=c(\"--no-multiarch\") to only build for the current 64-bit architecture.\n\n remotes::install_cran('azuremlsdk', repos = 'https:\/\/cloud.r-project.org\/', `INSTALL_opts=c(\"--no-multiarch\"))`\n\n\n\n\nhttps:\/\/azure.github.io\/azureml-sdk-for-r\/articles\/installation.html\n\nPlease do let me know if you still have issue.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Error: HTTPSConnectionPool(host='westus2.api.azureml.ms', port=443):",
        "Question_creation_time":1612285884163,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/255760\/azure-error-httpsconnectionpoolhost39westus2apiazu.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":1,
        "Question_body":"Hi,\nwe have a process that we have been running for over a year and suddenly have started failing and the error is not very descriptive. In this process, we run a train evaluation and a registration process from Azure DevOps.\n\nThe script that we are running is:\n\ndef main():\n    # Get Azure machine learning workspace\n    login_azure = ServicePrincipalAuthentication(tenant_id, app_id, app_secret)\n    aml_workspace = Workspace.get(\n        name=workspace_name,\n        subscription_id=subscription_id,\n        resource_group=resource_group,\n        auth=login_azure,\n    )\n    myenv = Environment(name=\"myenv\")\n    CONDA_YAML = \"src\/train\/conda_dependencies.yml\"\n    load_requirements_into_conda_yml(conda_yml=CONDA_YAML)\n    conda_dep = CondaDependencies(conda_dependencies_file_path=CONDA_YAML)\n    # We need this pip version\n    conda_dep.add_conda_package(\"pip==20.2.4\")\n    files_whl = []\n    os.chdir(\".\/ml_service\/pipelines\")\n    for file_whl in glob.glob(\"*.whl\"):\n        files_whl.append(file_whl)\n    for file_whl in files_whl:\n        try:\n            whl_url = Environment.add_private_pip_wheel(\n                workspace=aml_workspace, file_path=file_whl, exist_ok=True\n            )\n            conda_dep.add_pip_package(whl_url)\n        except Exception:\n            print(f\"Not able to add the wheel {file_whl}\")\n    os.chdir(\"..\/..\/\")\n    myenv.docker.base_image_registry.address = REGISTRY_CONTAINER_IMAGE\n    myenv.docker.base_image_registry.username = REGISTRY_CONTAINER_USERNAME\n    myenv.docker.base_image_registry.password = REGISTRY_CONTAINER_PASSWORD\n    # Environment Configuration\n    myenv.docker.enabled = True\n    myenv.python.user_managed_dependencies = False\n    myenv.docker.base_image = REGISTRY_BASE_IMAGE\n    myenv.python.conda_dependencies = conda_dep\n    run_config = RunConfiguration()\n    run_config.target = \"template-trainc\"\n    # Image configuration\n    model_name = PipelineParameter(name=\"model_name\", default_value=model_name)\n    release_id = PipelineParameter(name=\"release_id\", default_value=\"0\")\n    run_config.environment = myenv\n    train_step = PythonScriptStep(\n        name=\"Train Model\",\n        script_name=train_script_path,\n        compute_target=run_config.target,\n        source_directory=sources_directory_train,\n        arguments=[\"--release_id\", release_id, \"--model_name\", model_name],\n        runconfig=run_config,\n        allow_reuse=False,\n    )\n    print(\"Step Train created\")\n    evaluate_step = PythonScriptStep(\n        name=\"Evaluate Model \",\n        script_name=evaluate_script_path,\n        compute_target=run_config.target,\n        source_directory=sources_directory_train,\n        arguments=[\"--release_id\", release_id, \"--model_name\", model_name],\n        runconfig=run_config,\n        allow_reuse=False,\n    )\n    print(\"Step Evaluate created\")\n    evaluate_step.run_after(train_step)\n    steps = [evaluate_step]\n    train_pipeline = Pipeline(workspace=aml_workspace, steps=steps)\n    train_pipeline.validate()\n    published_pipeline = train_pipeline.publish(\n        name=pipeline_name, description=\"Model training\/retraining pipeline\", version=build_id\n    )\n    print(f\"Published pipeline: {published_pipeline.name}\")\n    print(f\"for build {published_pipeline.version}\")\n\n\n\nthe error is produced by this line:\n\npublished_pipeline = train_pipeline.publish(\n        name=pipeline_name, description=\"Model training\/retraining pipeline\", version=build_id\n    )\n\n\n\n\n\n\nWe are running the process in a container, that we have saved in azure acr, the container image that we are using is https:\/\/github.com\/microsoft\/MLOpsPython, with the requirements:\n\nadal==1.2.2\nantlr4-python3-runtime==4.7.2\napplicationinsights==0.11.9\nargcomplete==1.10.0\nasn1crypto==0.24.0\natomicwrites==1.3.0\nattrs==19.1.0\nazure-batch==7.0.0\nazure-cli==2.0.71\nazure-cli-command-modules-nspkg==2.0.3\nazure-cli-core==2.0.71\nazure-cli-nspkg==3.0.4\nazure-cli-telemetry==1.0.3\nazure-common==1.1.23\nazure-cosmos==3.1.1\nazure-datalake-store==0.0.47\nazure-functions-devops-build==0.0.22\nazure-graphrbac==0.60.0\nazure-keyvault==1.1.0\nazure-mgmt-advisor==2.0.1\nazure-mgmt-appconfiguration==0.1.0\nazure-mgmt-applicationinsights==0.1.1\nazure-mgmt-authorization==0.52.0\nazure-mgmt-batch==6.0.0\nazure-mgmt-batchai==2.0.0\nazure-mgmt-billing==0.2.0\nazure-mgmt-botservice==0.2.0\nazure-mgmt-cdn==3.1.0\nazure-mgmt-cognitiveservices==5.0.0\nazure-mgmt-compute==6.0.0\nazure-mgmt-consumption==2.0.0\nazure-mgmt-containerinstance==1.5.0\nazure-mgmt-containerregistry==3.0.0rc5\nazure-mgmt-containerservice==5.3.0\nazure-mgmt-cosmosdb==0.7.0\nazure-mgmt-datalake-analytics==0.2.1\nazure-mgmt-datalake-nspkg==3.0.1\nazure-mgmt-datalake-store==0.5.0\nazure-mgmt-datamigration==0.1.0\nazure-mgmt-deploymentmanager==0.1.0\nazure-mgmt-devtestlabs==2.2.0\nazure-mgmt-dns==2.1.0\nazure-mgmt-eventgrid==2.2.0\nazure-mgmt-eventhub==2.6.0\nazure-mgmt-hdinsight==1.1.0\nazure-mgmt-imagebuilder==0.2.1\nazure-mgmt-iotcentral==1.0.0\nazure-mgmt-iothub==0.8.2\nazure-mgmt-iothubprovisioningservices==0.2.0\nazure-mgmt-keyvault==1.1.0\nazure-mgmt-kusto==0.3.0\nazure-mgmt-loganalytics==0.2.0\nazure-mgmt-managedservices==1.0.0\nazure-mgmt-managementgroups==0.2.0\nazure-mgmt-maps==0.1.0\nazure-mgmt-marketplaceordering==0.2.1\nazure-mgmt-media==1.1.1\nazure-mgmt-monitor==0.5.2\nazure-mgmt-msi==0.2.0\nazure-mgmt-netapp==0.5.0\nazure-mgmt-network==3.0.0\nazure-mgmt-nspkg==3.0.2\nazure-mgmt-policyinsights==0.3.1\nazure-mgmt-privatedns==0.1.0\nazure-mgmt-rdbms==1.9.0\nazure-mgmt-recoveryservices==0.4.0\nazure-mgmt-recoveryservicesbackup==0.4.0\nazure-mgmt-redis==6.0.0\nazure-mgmt-relay==0.1.0\nazure-mgmt-reservations==0.3.1\nazure-mgmt-resource==2.2.0\nazure-mgmt-search==2.1.0\nazure-mgmt-security==0.1.0\nazure-mgmt-servicebus==0.6.0\nazure-mgmt-servicefabric==0.2.0\nazure-mgmt-signalr==0.1.1\nazure-mgmt-sql==0.13.0\nazure-mgmt-sqlvirtualmachine==0.4.0\nazure-mgmt-storage==4.0.0\nazure-mgmt-trafficmanager==0.51.0\nazure-mgmt-web==0.42.0\nazure-multiapi-storage==0.2.4\nazure-nspkg==3.0.2\nazure-storage-blob==1.5.0\nazure-storage-common==1.4.2\nazureml==0.2.7\nazureml-core==1.0.62\nazureml-dataprep==1.1.17\nazureml-dataprep-native==13.0.3\nazureml-pipeline==1.0.62\nazureml-pipeline-core==1.0.62\nazureml-pipeline-steps==1.0.62\nazureml-sdk==1.0.62\nazureml-telemetry==1.0.62\nazureml-train==1.0.62\nazureml-train-core==1.0.62\nazureml-train-restclients-hyperdrive==1.0.62\nbackports.tempfile==1.0\nbackports.weakref==1.0.post1\nbcrypt==3.1.7\ncertifi==2019.3.9\ncffi==1.11.5\nchardet==3.0.4\ncloudpickle==1.2.2\ncolorama==0.4.1\nconda==4.3.16\ncontextlib2==0.5.5\ncryptography==2.4.2\ndistro==1.4.0\ndocker==4.0.2\ndotnetcore2==2.1.8.1\nentrypoints==0.3\nfabric==2.5.0\nflake8==3.7.8\nflake8-formatter-junit-xml==0.0.6\nfusepy==3.0.1\nhumanfriendly==4.18\nidna==2.8\nimportlib-metadata==0.23\ninvoke==1.3.0\nisodate==0.6.0\njavaproperties==0.5.1\njeepney==0.4.1\nJinja2==2.10.1\njmespath==0.9.4\njsondiff==1.2.0\njsonpickle==1.2\njunit-xml==1.8\nknack==0.6.3\nMarkupSafe==1.1.1\nmccabe==0.6.1\nmock==2.0.0\nmore-itertools==7.2.0\nmsrest==0.6.10\nmsrestazure==0.6.2\nndg-httpsclient==0.5.1\nnumpy==1.19.4\noauthlib==3.1.0\npandas==1.1.4\nparamiko==2.6.0\npathspec==0.5.9\npbr==5.4.3\npip==18.1\npluggy==0.13.0\nportalocker==1.5.1\npsutil==5.6.3\npy==1.8.0\npyasn1==0.4.7\npycodestyle==2.5.0\npycosat==0.6.3\npycparser==2.19\npydocumentdb==2.3.3\npyflakes==2.1.1\nPygments==2.4.2\nPyJWT==1.7.1\nPyNaCl==1.3.0\npyOpenSSL==18.0.0\nPySocks==1.6.8\npytest==4.3.0\npython-dateutil==2.8.0\npython-dotenv==0.10.3\npytz==2019.1\nPyYAML==5.1.2\nrequests==2.22.0\nrequests-oauthlib==1.2.0\nruamel.yaml==0.16.12\nruamel.yaml.clib==0.2.2\nscp==0.13.2\nSecretStorage==3.1.1\nsetuptools==40.6.3\nsix==1.12.0\nsshtunnel==0.1.5\ntabulate==0.8.3\nurllib3==1.24.1\nvsts==0.1.25\nvsts-cd-manager==1.0.2\nwebsocket-client==0.56.0\nwheel==0.30.0\nxmltodict==0.12.0\nzipp==0.6.0\n\n\n\n\n\n\nError:\n\nFile \"\/usr\/local\/lib\/python3.7\/site-packages\/azureml\/pipeline\/core\/_aeva_provider.py\", line 100, in __init__\n    self.datatype_provider.ensure_default_datatypes()\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/azureml\/pipeline\/core\/_aeva_provider.py\", line 1512, in ensure_default_datatypes\n    ids = [datatype.id for datatype in self.get_all_datatypes()]\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/azureml\/pipeline\/core\/_aeva_provider.py\", line 1448, in get_all_datatypes\n    entities = self._service_caller.get_all_datatypes_async()\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/azureml\/pipeline\/core\/_restclients\/aeva\/service_caller.py\", line 499, in get_all_datatypes_async\n    workspace_name=self._workspace_name, custom_headers=self._get_custom_headers())\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/azureml\/pipeline\/core\/_restclients\/aeva\/aml_pipelines_api10.py\", line 813, in api_v10_subscriptions_by_subscription_id_resource_groups_by_resource_group_name_providers_microsoft_machine_learning_services_workspaces_by_workspace_name_data_types_get\n    response = self._client.send(request, header_parameters, stream=False, **operation_config)\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/msrest\/service_client.py\", line 336, in send\n    pipeline_response = self.config.pipeline.run(request, **kwargs)\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/msrest\/pipeline\/__init__.py\", line 197, in run\n    return first_node.send(pipeline_request, **kwargs)  # type: ignore\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/msrest\/pipeline\/__init__.py\", line 150, in send\n    response = self.next.send(request, **kwargs)\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/msrest\/pipeline\/requests.py\", line 137, in send\n    return self.next.send(request, **kwargs)\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/msrest\/pipeline\/__init__.py\", line 150, in send\n    response = self.next.send(request, **kwargs)\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/msrest\/pipeline\/requests.py\", line 193, in send\n    self.driver.send(request.http_request, **kwargs)\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/msrest\/universal_http\/requests.py\", line 333, in send\n    return super(RequestsHTTPSender, self).send(request, **requests_kwargs)\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/msrest\/universal_http\/requests.py\", line 145, in send\n    raise_with_traceback(ClientRequestError, msg, err)\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/msrest\/exceptions.py\", line 51, in raise_with_traceback\n    raise error.with_traceback(exc_traceback)\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/msrest\/universal_http\/requests.py\", line 142, in send\n    **kwargs)\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/requests\/sessions.py\", line 530, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/requests\/sessions.py\", line 643, in send\n    r = adapter.send(request, **kwargs)\n  File \"\/usr\/local\/lib\/python3.7\/site-packages\/requests\/adapters.py\", line 507, in send\n    raise RetryError(e, request=request)\nmsrest.exceptions.ClientRequestError: Error occurred in request., RetryError: HTTPSConnectionPool(host='westus2.api.azureml.ms', port=443): Max retries exceeded with url: \/api\/v1.0\/subscriptions\/01c989d5-4dec-4881-a9df-193efdcc5582\/resourceGroups\/trpacml01-AML-RG\/providers\/Microsoft.MachineLearningServices\/workspaces\/trpacml01-AML-WS\/DataTypes (Caused by ResponseError('too many 530 error responses'))\n##[error]Bash exited with code '1'.\n\n\n\n\nIs there is any new kind of requirement? proxy? or the service is unavailable?\n\nThank you so much!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-03T10:16:40.747Z",
                "Answer_score":0,
                "Answer_body":"@VirginiaLopezGil-6379 Does this error occur consistently with your workspace? Do you have any other workspace facing similar issues when you try to publish?\nYou may have to request a support case to get this looked in detail with the service team. If you do not have a support subscription we could help you get one for this issue. Thanks!!",
                "Answer_comment_count":5,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Update a deployed web service with published endpoint after retraining with new pipeline parameter.",
        "Question_creation_time":1612770312390,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/263253\/update-a-deployed-web-service-with-published-endpo.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":12,
        "Question_score":0,
        "Question_body":"I have created a model in the new Azure designer portal with some data and I have deployed it as a real-time interference pipeline. After that, I retrained the pipeline with the new pipeline parameter as mentioned in the link below.\n\nhow-to-retrain-designer\n\n\n\n\n\nOnce the model is retrained , I published it as a new endpoint and I got the RESTAPI to consume. But I don't know how to consume the updated endpoint with the REST API. Please let me know any links that helps to consume them.\n\nAlso there is no clear documentation on how to update the existing web service of the model with the old data to the new data.\nAlso I need to know how to do all these programmatically. Any help is appreciated. Many thanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-08T07:58:05.95Z",
                "Answer_score":0,
                "Answer_body":"please see documentation link below:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-update-web-service\n\nPlease let us know if you have any additional questions.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Microsoft Machine Learning getting sample sizes and other information",
        "Question_creation_time":1598192106863,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/74341\/microsoft-machine-learning-getting-sample-sizes-an.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":2,
        "Question_score":0,
        "Question_body":"Hi,\n\nWe are using the Microsoft Machine Learning library (Microsoft.ML). We have the following script working:\n\n            var trainingData = mlContext.Data.LoadFromTextFile<CSOData>(\n                 path: @\"C:\\Users\\Administrator\\source\\repos\\WindowsFormsApp1\\WindowsFormsApp1\\level-data - reduced.txt\",\n                 hasHeader: false,\n                 separatorChar: ',');\n    \n             \/\/ set up a learning pipeline\n             \/\/ step 1: concatenate input features into a single column\n             var pipeline = mlContext.Transforms.Concatenate(\n                 \"Features\",\n                 \"Level\")\n    \n                 \/\/ step 2: use the k-means clustering algorithm\n                 \/\/ assume there are 3 clusters\n                 .Append(mlContext.Clustering.Trainers.KMeans(\n                     \"Features\",\n                     numberOfClusters: 3));\n    \n             \/\/ train the model on the data file\n             Debug.WriteLine(\"Start training model....\");\n             TransformerChain<ClusteringPredictionTransformer<KMeansModelParameters>> model = pipeline.Fit(trainingData);\n             Debug.WriteLine(\"Model training complete!\");\n    \n             \/\/ Transform data\n             IDataView transformedData = model.Transform(trainingData);\n    \n             VBuffer<float>[] centroids = null;\n             var last = model.LastTransformer;\n             KMeansModelParameters kparams = (KMeansModelParameters)last.GetType().GetProperty(\"Model\").GetValue(last);\n             kparams.GetClusterCentroids(ref centroids, out int k);\n             float cluster1 = centroids[0].GetValues().ToArray().FirstOrDefault();\n             float cluster2 = centroids[1].GetValues().ToArray().FirstOrDefault();\n             float cluster3 = centroids[2].GetValues().ToArray().FirstOrDefault();\n    \n             Debug.WriteLine(cluster1);\n             Debug.WriteLine(cluster2);\n             Debug.WriteLine(cluster3);\n\n\n\nSo we are able to get the centroids of each cluster. What we need is the number of samples in each cluster and the withinss value for each cluster but we just cannot work out how to do this.\n\nDoes anyone know how to access these values?\n\nRegards\n\nIan Hannah",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-25T04:59:17.123Z",
                "Answer_score":0,
                "Answer_body":"@IanHannah-5056 Thanks for the question. We have forwarded to the product team to check on this.you can raise an issue in the following github windows machine learning.\n\n\n\n\nhttps:\/\/github.com\/Microsoft\/Windows-Machine-Learning\/issues",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Stopping ML Server Engine",
        "Question_creation_time":1612666795983,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/262003\/stopping-ml-server-engine.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"I'm running the Microsoft Machine Learning Server on my computer. Right now, there are no tasks\/nodes running, and task manager is showing multiple instances of the \"Microsoft ML Server Engine\" that are using nearly all my computer resources. I've gone into the administration utility, but can't seem to find a way of stopping this, short of brute \"End Task\" within TM.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-07T04:05:59.56Z",
                "Answer_score":1,
                "Answer_body":"HI @ThomasGraham-8689\n\nIn Machine Learning Server 9.3 and later, you can use admin extension of the Azure Command-Line Interface (Azure CLI) to set up and manage your configuration, including stopping and starting services.\nMonitor, stop, and start web & compute nodes\n\nIf the Answer is helpful, please click Accept Answer and up-vote, this can be beneficial to other community members.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How do I fix this Snapshot Exception?",
        "Question_creation_time":1612425944867,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/258581\/how-do-i-fix-this-snapshot-exception.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I'm doing a pipeline in Azure ML SDK. After I had run the pipeline for some amount of times it reported I had reached the Snapshot limit of 300MB. I followed some of the fixes that was proposed:\n\nEach step script is moved to a separate subfolder\n\n\nI added a datastore to the pipeline\n\n\nThis line was added: azureml._restclient.snapshots_client.SNAPSHOT_MAX_SIZE_BYTES = 1000\n\nBut then a new Snapshot error occurred after I submitted my pipeline:\n\n pipeline1 = Pipeline(default_source_directory=\".\", default_datastore=def_blob_store, workspace=ws, steps=[prep_step, hd_step, register_model_step])\n\n\n\nTHE ERROR MESSAGE:\n\n WARNING:root:If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n ---------------------------------------------------------------------------\n SnapshotException                         Traceback (most recent call last)\n <ipython-input-14-05c5aa4991aa> in <module>\n ----> 1 pipeline1 = Pipeline(default_source_directory=\".\", default_datastore=def_blob_store, workspace=ws, steps=[prep_step, hd_step, register_model_step])\n       2 pipeline1.validate()\n       3 pipeline_run = Experiment(ws, 'health_insuarance').submit(pipeline1, regenerate_outputs=False)\n       4 RunDetails(pipeline_run).show()\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/core\/_experiment_method.py in wrapper(self, *args, **kwargs)\n      95             \"\"\"\n      96             ExperimentSubmitRegistrar.register_submit_function(self.__class__, submit_function)\n ---> 97             return init_func(self, *args, **kwargs)\n      98         return wrapper\n      99     return real_decorator\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/pipeline.py in __init__(self, workspace, steps, description, default_datastore, default_source_directory, resolve_closure, _workflow_provider, _service_endpoint, **kwargs)\n     175                 raise ValueError('parameter %s is not recognized for Pipeline ' % key)\n     176         self._enable_email_notification = enable_email_notification\n --> 177         self._graph = self._graph_builder.build(self._name, steps, finalize=False)\n     178 \n     179     def _set_experiment_name(self, name):\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py in build(self, name, steps, finalize, regenerate_outputs)\n    1479                 pass\n    1480 \n -> 1481         graph = self.construct(name, steps)\n    1482         if finalize:\n    1483             graph.finalize(regenerate_outputs=regenerate_outputs)\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py in construct(self, name, steps)\n    1501         self._graph = Graph(name, self._context)\n    1502         self._nodeStack.append([])\n -> 1503         self.process_collection(steps)\n    1504         for builder in self._builderStack[::-1]:\n    1505             builder.apply_rules()\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py in process_collection(self, collection)\n    1537         self._nodeStack.append([])\n    1538         self._builderStack.append(builder)\n -> 1539         builder.process_collection(collection)\n    1540         added_nodes = self._nodeStack.pop()\n    1541         self._nodeStack[-1].extend(added_nodes)\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py in process_collection(self, collection)\n    1828         \"\"\"\n    1829         for item in collection:\n -> 1830             self._base_builder.process_collection(item)\n    1831 \n    1832     def apply_rules(self):\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py in process_collection(self, collection)\n    1531         # just a step?\n    1532         if isinstance(collection, PipelineStep):\n -> 1533             return self.process_step(collection)\n    1534 \n    1535         # delegate to correct builder\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/core\/builder.py in process_step(self, step)\n    1575             return self._step2node[step]\n    1576 \n -> 1577         node = step.create_node(self._graph, self._default_datastore, self._context)\n    1578         self.assert_node_valid(step, self._graph, node)\n    1579 \n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/steps\/hyper_drive_step.py in create_node(self, graph, default_datastore, context)\n     247         \"\"\"\n     248         hyperdrive_config, reuse_hashable_config = self._get_hyperdrive_config(context._workspace,\n --> 249                                                                                context._experiment_name)\n     250         self._params[HyperDriveStep._run_config_param_name] = json.dumps(hyperdrive_config)\n     251         self._params[HyperDriveStep._run_reuse_hashable_config] = json.dumps(reuse_hashable_config)\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/pipeline\/steps\/hyper_drive_step.py in _get_hyperdrive_config(self, workspace, experiment_name)\n     323 \n     324         hyperdrive_dto = _search._create_experiment_dto(self._hyperdrive_config, workspace,\n --> 325                                                         experiment_name, telemetry_values)\n     326 \n     327         hyperdrive_config = hyperdrive_dto.as_dict()\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/train\/hyperdrive\/_search.py in _create_experiment_dto(hyperdrive_config, workspace, experiment_name, telemetry_values, activity_logger, **kwargs)\n      41     if hyperdrive_config.source_directory is not None:\n      42         snapshot_client = SnapshotsClient(workspace.service_context)\n ---> 43         snapshot_id = snapshot_client.create_snapshot(hyperdrive_config.source_directory)\n      44 \n      45         if activity_logger is not None:\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/snapshots_client.py in create_snapshot(self, file_or_folder_path, retry_on_failure, raise_on_validation_failure)\n      83         exclude_function = ignore_file.is_file_excluded\n      84 \n ---> 85         self._validate_snapshot_size(file_or_folder_path, exclude_function, raise_on_validation_failure)\n      86 \n      87         # Get the previous snapshot for this project\n    \n \/anaconda\/envs\/azureml_py36\/lib\/python3.6\/site-packages\/azureml\/_restclient\/snapshots_client.py in _validate_snapshot_size(self, file_or_folder_path, exclude_function, raise_on_validation_failure)\n      61                             \"\\n\".format(file_or_folder_path, SNAPSHOT_MAX_SIZE_BYTES \/ ONE_MB)\n      62             if raise_on_validation_failure:\n ---> 63                 raise SnapshotException(error_message)\n      64             else:\n      65                 self._logger.warning(error_message)\n    \n SnapshotException: SnapshotException:\n     Message: ====================================================================\n    \n While attempting to take snapshot of .\/train\/\n Your total snapshot size exceeds the limit of 0.00095367431640625 MB.\n Please see http:\/\/aka.ms\/aml-largefiles on how to work with large files.\n    \n ====================================================================\n    \n    \n     InnerException None\n     ErrorResponse \n {\n     \"error\": {\n         \"message\": \"====================================================================\\n\\nWhile attempting to take snapshot of .\/train\/\\nYour total snapshot size exceeds the limit of 0.00095367431640625 MB.\\nPlease see http:\/\/aka.ms\/aml-largefiles on how to work with large files.\\n\\n====================================================================\\n\\n\"\n     }\n }\n \u200b\n\n\n\nAny idea how I fix this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-05T12:44:46.25Z",
                "Answer_score":1,
                "Answer_body":"Alright, so I found the fix.\n\nI changed this line by adding a number equvilant to 1GB: azureml._restclient.snapshots_client.SNAPSHOT_MAX_SIZE_BYTES = 1000000000\n\nFor some reason, you have to define the size in BYTES and not megabytes even though the default is 300 MB. Not especially intuitive.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How to specify HTTP response status code in AML R Web Service",
        "Question_creation_time":1612354860267,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/257156\/how-to-specify-http-response-status-code-in-aml-r.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Is there any way to return a custom HTTP status code from R Web Service in Azure ML?\n\nAll the examples of entry scripts in documentation return the response body from the scoring function. In Python Web Service, it is possible to return a HTTP response object with a custom status code. However, R's httr library does not seem to have any function to create response objects directly (only via HTTP method objects such as POST, which call a given URL).\n\nI would like to implement a custom exception handling scheme in R Web Service. Is there any way to return a custom HTTP code from the entry script?\n\nEDIT: Found this idea on the feedback forum, which suggests that the option is not available in Python Web Service either:\nhttps:\/\/feedback.azure.com\/forums\/257792-machine-learning\/suggestions\/40122838-make-http-status-codes-controllable-from-your-scor",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-03T23:14:52.687Z",
                "Answer_score":0,
                "Answer_body":"Hello Lauri,\n\nThanks for the feedback. Yes, we have this product idea in our backlog. I will help to bump up this idea to product group again. ^^\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-02-03T19:17:19.37Z",
                "Answer_score":0,
                "Answer_body":"I found that it is possible to return \"502 Replica failed\" by raising an exception in the entry script. However, it would still be nice to be able to return custom status codes.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-02-05T01:56:45.177Z",
                "Answer_score":0,
                "Answer_body":"This sample shows how to return custom StatusCode (returns 200 or 500):\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script#binary-data",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Internal server error while connecting to jupyter lab instance",
        "Question_creation_time":1610979567287,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/234805\/internal-server-error-while-connecting-to-jupyter.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":4,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"I have created an ML-compute instance from scratch, nothing particularly installed.\nBut when I try to connect to Jupiter Lab directly through the URL provided by the user interface I get the following error :\n\n{\n\"error\": {\n\"code\": \"ServiceError\",\n\"severity\": null,\n\"message\": \"InternalServerError\",\n\"messageFormat\": null,\n\"messageParameters\": null,\n\"referenceCode\": null,\n\"detailsUri\": null,\n\"target\": null,\n\"details\": [],\n\"innerError\": null,\n\"debugInfo\": null\n},\n\"correlation\": {\n\"operation\": \"716efa38ccc70341b4b5b93bc16e441b\",\n\"request\": \"170d9ccac55c9d42\"\n},\n\"environment\": \"westeurope\",\n\"location\": \"westeurope\",\n\"time\": \"2021-01-18T14:00:19.9517739+00:00\",\n\"componentName\": \"notebook-instance-proxy\"\n}\n\nI also tried to connect through SSH to this compute instance, I notice that there is a conflict about the version of the pillow package.\nThen I've fixed the version conflict but the error still persists even after rebooting the machine.\nAfter that, I've connected to the machine through SSH tunnelling and I could start the Jupiter lab instance (even though the error still persist when connecting through the Azure ML Interface).\n\nCould you please investigate the connection issue through the user interface please?\nThanks in advance",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-19T14:23:54.503Z",
                "Answer_score":1,
                "Answer_body":"@ramr-msft, I was able to launch a Jupyter Lab instance on Google Chrome.\nBut it's still not working on Safari, there must be a compatibility issue.\nMy safari version is 14.0.2\n\nTicket can be close.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-02-01T06:11:39.15Z",
                "Answer_score":0,
                "Answer_body":"@AbderrahimMEHDAOUI-4926 Thanks for the details. Can you please try turning off \"Deny 3rd party cookies\" and it works great for me with this config. We have forwarded to the product team to check for the fix. You can also raise a user voice request here so the community can vote and provide their feedback, the product team then checks this feedback and implements the same in future releases.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Using Estimator or SciptRunConfig for Pipeline with Hyperdrive and XGBoost?",
        "Question_creation_time":1611821264403,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/248696\/using-estimator-or-sciptrunconfig-for-pipeline-wit.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"I'm learning Azure ML and I'm trying to make a pipeline with HyperDrive and an Xgboost estimator. But I cannot figure out how I add the custom XGBoost environment to my HyperDriveConfig.\n\nEstimator is apparently deprecated and telling me to use ScriptRunConfig instead.\n\nSo I have created an Enviroment pointing to a yaml file with dependencies and a ScriptRunConfig pointing to the environment. But how should I use the ScriptRunConfig in HyperDriveConfig?\nThis is the code I'm trying atm:\n\n env = Environment.from_conda_specification(\"xgboost\", \"environment.yml\")\n    \n src = ScriptRunConfig(\n                     source_directory='.',\n                     script='train.py',\n                     compute_target=compute_target,\n                     environment=env,\n )\n hyperdrive_run_config = HyperDriveConfig(\n                                          hyperparameter_sampling=ps, \n                                          primary_metric_name='Accuracy',\n                                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n                                          max_total_runs=100,\n                                          max_concurrent_runs=4,\n                                         #run_config = aml_run_config,\n                                         policy=None,\n                                         estimator=src\n                                         )\n\n\n\n\nWhen I submit the pipeline get the following error:\n\nAttributeError: 'ScriptRunConfig' object has no attribute '_get_script_run_config'",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-28T11:34:05.093Z",
                "Answer_score":0,
                "Answer_body":"@MichaelSegaard-7801 I think the ScriptRunConfig() should be passed to the run_config parameter instead of the estimator. Here is the sample\n\n from azureml.train.hyperdrive import HyperDriveConfig\n hd_config = HyperDriveConfig(run_config=src,\n                              hyperparameter_sampling=param_sampling,\n                              policy=early_termination_policy,\n                              primary_metric_name=\"accuracy\",\n                              primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n                              max_total_runs=100,\n                              max_concurrent_runs=4)",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to disable Azure ML snapshots (for compute clusters)",
        "Question_creation_time":1611558384720,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/243585\/how-to-disable-azure-ml-snapshots-for-compute-clus.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"I am using the Azure ML Python SDK to spawn jobs using a prebuilt Docker image compute cluster. The Docker image has all of the dependencies installed and the source code I am running.\n\nAccording to the logs, Azure ML's \"snapshot\" operations (that I assume upload and then download the source directory to Azure ML jobs) increase the startup time from 2 minutes to 8-20 minutes (i.e., the time it takes for an Azure ML run to begin running my code). By comparison, when I run the exact same code on a compute instance instead of a compute cluster, startup time is 60-80 seconds. Notably, the startup logs for the compute instance make no mention of \"snapshots\".\n\nI already disabled saving snapshots for historical record, but that made little difference and the startup logs (for a cluster) still show operations for snapshots. I also significantly expanded our .amlignore file, which reduced the startup time by 10+ minutes, but 5-10 minutes are still spent on the \"fetching snapshots\" step (which we do not even use).\n\nQuestions:\n1. What is this \"fetching snapshot\" operation if it is not the saving of snapshots for historical record (which I already disabled and confirmed)?\n2. Why does this operation only occur for compute clusters but not compute instances?\n3. Why is this operation so slow? I.e., 5-10 minutes to \"fetch\" less than 10 MB of python files.\n4. Can I disable everything having to do with snapshots altogether? I assume this is possible because this occurs when using compute instances in Azure ML.\n\nThank you very much. Please let me know if there is anything more I can provide to help debug.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-25T11:57:35.397Z",
                "Answer_score":0,
                "Answer_body":"@DannyNemer Thanks for the question. To prevent unnecessary files from being included in the snapshot, make an ignore file (.gitignore or .amlignore) in the directory. With regards to the snapshotted set of files, you could create a \u201c.amlignore\u201d file following a similar syntax as a gitignore files to prevent uploading of files as a snapshot with your runs. I could see you have leveraged this.\n\nPlease follow the doc for the same.\n\nGenerally Compute target takes a long time to start: The Docker images for compute targets are loaded from Azure Container Registry (ACR). By default, Azure Machine Learning creates an ACR that uses the basic service tier. Changing the ACR for your workspace to standard or premium tier may reduce the time it takes to build and load images. For more information, see Azure Container Registry service tiers.\n\nCompute Instance is a managed cloud-based workstation for data scientists which makes it easy to get started with ML development on AzureML while providing management and enterprise readiness capabilities. Compute instances support the full lifecycle of inner-loop ML development on AzureML. Compute instance is fully customizable by data scientists and is tightly integrated with Azure ML workspace.\nCompute instances can be used for running notebooks through first-class web experiences for popular tools such as JupyterLab, Jupyter, and integrated notebooks and running R scripts. Compute instance can also be used as a training compute target.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"can we run a jupyter notebook using scriptrunconfig on target compute cluster ?",
        "Question_creation_time":1612203390137,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/254301\/can-we-run-a-jupyter-notebook-using-scriptrunconfi.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hi,\n\nI understood that we can run a python script using scriptrunconfig.\n\nMy question is whether we can run jupyter notebook ?\nWhat other type of scripts can we run ?\n\nThank you.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-02-01T21:46:21.163Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nFor Azure Machine Learning Service, you can create a notebook with designed Computer Instance: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-run-jupyter-notebooks\n\nThis guidance shows how to run your Jupyter notebooks directly in your workspace in Azure Machine Learning studio. While you can launch Jupyter or JupyterLab, you can also edit and run your notebooks without leaving the workspace.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"New Azure ML Service - Designer missing",
        "Question_creation_time":1611932220923,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/251151\/new-azure-ml-service-designer-missing.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Hello,\nThe Designer is suddenly missing in the new Azure ML Workspace. I was using it a few weeks back, any clue why this is happening? The service is in west europe.\n\nThanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-29T18:55:42.78Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nI am sorry for your experience. I just created a workspace in West Europe with no problem. Could you please try again?\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Get image id from deployed azureml Model?",
        "Question_creation_time":1611789072743,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/247987\/get-image-id-from-deployed-azureml-model.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"About a year ago when testing azure.train.automl models' deployments with AciContainer and AciWebServices the endpoint details also displayed an Image ID which our web services team could pull and deploy.\n\nNow with azure.core==1.19.0 the Image ID is not automatically produced.\n\nHow do I generate the Image ID for them to pull the image?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-28T09:50:42.463Z",
                "Answer_score":0,
                "Answer_body":"@MathBarbarian-1293 Thanks, Model.Resgister(Register Model > Create Image > Create Webservice) is old approach, you can use the latest SDK with Model.deploy to deploy the model. the Inference Config Class has a spot for environment which works with the Model.deploy method.\nModel.download will give you the model file\nModel.package will give you the model packaged into a docker image\n\nPlease follow the below steps to Deploy the best Model.\nDeploy the model registered in the previous slide, to Azure Container Instance (ACI) as a Web Service\nThere are 4 steps involved in model deployment\u200b\n\nStep 9.1 \u2013 Create scoring script\u200b\n\nStep 9.2 \u2013 Create environment file\u200b\n\nStep 9.3 \u2013 Create configuration file\u200b\n\nStep 9.4 \u2013 Deploy to ACI!\u200b\n\n\n\n\nhttps:\/\/github.com\/danielsc\/dogbreeds\/blob\/master\/webservice-test.ipynb\nhttps:\/\/github.com\/retkowsky\/AzureML_Excel\/blob\/master\/Boston%20ML%20ACI.ipynb",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Data entry webservice Azure consume: Transform values of data entered",
        "Question_creation_time":1611930985517,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/251134\/data-entry-webservice-azure-consume-transform-valu.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"Hello,\n\nI have built a predictive model within Azure that works fine. I am trying to improve this by grouping values for some columns.\nI have 2 columns: format1, format2. I need to roundup them (ceil function). I did it in the Azure model but I need now to round these values when the user enters imput via the webservice.\nExample :\nformat1 => 21 => should be 25\nformat2 => 31 => should be 35\nThen these values (25,35) will be used in the Azure model.\nI tried to add a \"apply math operation\" in the predictive experiment but it seems not adapted for this....\n\nThank you for your help.\n\nRegards,\n\nMohamed.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-29T15:00:33.297Z",
                "Answer_score":1,
                "Answer_body":"Hello,\n\nI got it, it works fine. Adding the module \"apply math operation in the predictive experiment and just after the data entry module is efficient.\n\nThx :)\n\nMohamed.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"AzureMLCompute job failed: container registry failed unexpectedly: container setup task failed",
        "Question_creation_time":1610999729247,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/235234\/azuremlcompute-job-failed-container-registry-faile.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":6,
        "Question_score":1,
        "Question_body":"Hi,\n\nCould you please help me with running python script in azureml environment? I created the workspace and azure container registry and pushed docker image to the container. This is the example of dockerfile:\n\n FROM python:3.7\n    \n RUN pip install --upgrade pip\n    \n RUN pip install virtualenv\n    \n ENV VIRTUAL_ENV=\/venv\n    \n RUN virtualenv venv -p python3\n    \n ENV PATH=\"VIRTUAL_ENV\/bin:$PATH\"\n    \n WORKDIR \/app\n    \n ADD . \/app\n    \n ENV PYTHON_PACKAGES=\"\\\n      numpy \\\n  pandas \\\n  seaborn \\\n  matplotlib \\\n  sklearn \\\n  scipy \\\n  imbalanced-learn \\\n  xgboost \\\n  joblib \\\n \" \n    \n RUN pip install --no-cache-dir $PYTHON_PACKAGES\n    \n ENTRYPOINT [\"python3\",\"train.py\"]\n\n\n\nWhen I run the experiment I get this error:\n\n\"Message\": \"AzureMLCompute job failed.\\nJobContainerConfigFailed: Container configuration failed unexpectedly\\n\\tJobContainerConfigFailed: Container configuration failed unexpectedly\\n\\terr: container setup task failed: exit status 1\\n\\tReason: container setup task failed: exit status 1\\n\\tInfo: Failed to prepare an environment for the job execution: Job environment preparation failed on 10.0.0.5 with err exit status 1.\"\n\n\n\n\nI do not understand what this error mean.\n\nThank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-20T10:39:50.733Z",
                "Answer_score":0,
                "Answer_body":"@MomirBeljic-9741 Thanks for the question. Could you please try the following solution given below.\nSolution:\nUpdated storage account key with below command.\nChange storage account access keys - Azure Machine Learning | Microsoft Docs\n\n\n\n\naz ml workspace sync-keys -w myworkspace -g myresourcegroup\n\nThis message occurs when the AML storage account restricts access to specific VNETs and the Compute Cluster isn\u2019t in that VNET.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Machine learning Workspace not loading. Shows a Request cannot be served error",
        "Question_creation_time":1611837281277,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/249069\/machine-learning-workspace-not-loading-shows-a-req.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"My ML workspace does not load. It shows like this.\n\nNeed a answer quickly. Thanks in advance",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-28T17:17:26.41Z",
                "Answer_score":1,
                "Answer_body":"@WindowsPC-1451 I tried to load and select workspaces on my browser and it seems to be loading my directory, subscriptions and workspaces. Could possible be a intermittent issue, could you please try again or with a different browser. Thanks!!",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"R device result",
        "Question_creation_time":1611814116917,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/248487\/r-device-result.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"R device Loading variable to data frame not complete\nThis is my code\ndo.call ( rbind, with( dataset1, tapply(ShotonScreen2, interaction(LotnoS=LotnoS , ProductCode=ProductCode), quantile,\nprobs=c(0, .25,.5, 0.75, 1) ) ) )\n\nSelect data.frame to be sent to the output Dataset port\nmaml.mapOutputPort(\"dataset1\");\n\n\n\n\nR device port (Loading variable ) show \"Loading variable port1...\"\n0% 25% 50% 75% 100%\n6319\/A16.ZDE1DWW70500009 0.270 0.5050 0.740 0.9000 1.06\n6319\/A17.ZDE1DWW70500009 0.300 0.3825 0.445 0.5825 0.89\n6319\/A18.ZDE1DWW70500009 0.470 0.4700 0.470 0.4700 0.47\n6320\/A01.ZDE1DWW70500009 0.330 0.3725 0.475 1.2675 1.99\n\nHow to import this in table format for analysis\n\nI try to use\ndata.set <- data.frame (\ndo.call ( rbind, with( dataset1, tapply(ShotonScreen2, interaction(LotnoS=LotnoS , ProductCode=ProductCode), quantile,\nprobs=c(0, .25,.5, 0.75, 1) ) ) )\n)\n\nI get this table that has not first column ( ex. 6319\/A16.ZDE1DWW70500009)\n0. X25. X50. X75. X100.\n\n0.27 0.505 0.74 0.9 1.06\n0.3 0.3825 0.445 0.5825 0.89\n0.47 0.47 0.47 0.47 0.47\n0.33 0.3725 0.475 1.2675 1.99\n0.2 0.2675 0.33 0.3925 0.52\n\nPlease suggest me,\nI sorry for my english is not good.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Time Series Forecasting \/ Regression - How to download the actual predictions?",
        "Question_creation_time":1608891234540,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/210527\/time-series-forecasting-regression-how-to-download.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hello,\n\nI have trained an auto regressive model and I can see its performance metrics.\nHow do I see the predictions or download as a cvs?\n\nIs there a start-to-end example explaining how to do regression \/ time series forecasting using machine learning?\nAll examples from microsoft I could find explain things up to creating a model, I can not find information on how to use the model for prediction.\nDetailed explanations on how data is expected as input would be much appreciated (example: should the dates go from most recent to least recent or the other way around? Should I use linux timesamps instead? Should the prediction values be marked as currency or integer or float or just normal?)\n\nThanks, Efe",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-28T10:12:44.87Z",
                "Answer_score":0,
                "Answer_body":"@EfeArda-8989 Thanks, You can use and explore AutoML on time-series data for forecasting use case.\nForecasting within automated machine learning (ML) now includes capabilities that improve the accuracy and performance of our recommended models.\n\nResources:\nAutomated ML Forecasting Blog\nAutomated ML Forecasting How-to\nAutomated ML Charts & Metrics\nGitHub Sample Notebooks",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-01-25T10:37:50.263Z",
                "Answer_score":0,
                "Answer_body":"Hi @EfeArda-8989, I've recently published a guide on forecasting crypto prices with AutoML, which I think covers your usecase. It demos how to retrieve & prepare historic data, how to configure and run Automated ML using the SDK, and how to use the model for predictions and interpret the results.\n\nHope it helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Forecasting and AutoMLConfig do not propagate to UI",
        "Question_creation_time":1611539077903,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/243175\/forecasting-and-automlconfig-do-not-propagate-to-u.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Hi! Using the SDK version 19 and setting the blocked_models as none or a given model do not propagate in the triggered run to only block that model, instead it blocks a bunch. Also the forecastingParameters do not propagate as well.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-25T09:02:01.93Z",
                "Answer_score":0,
                "Answer_body":"@AxelSirota-0156 Thanks for the question. blocked_models: A list of algorithms to ignore for an experiment. If enable_tf is False, TensorFlow models are included in blocked_models.\n\nHere is the sample for forecasting.\n\n\nSupported models for forecasting:\nhttps:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-train-automl-client\/azureml.train.automl.constants.supportedmodels.forecasting?view=azure-ml-py",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"how to get started about analysing time series with Azure?",
        "Question_creation_time":1611334374593,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/241953\/how-to-get-started-about-analysing-time-series-wit.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"We have a large amount of time series that get updated each month or week and would like to use some Azure based machine learning to QC this.\n\nHaving no practical experience of machine learning or azure, could you point me where\/how I could get started, please?\n\nOur data itself is located on the cloud in a Snowflake database.\n\n\n\n\nMany Thanks\n\nEric",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-23T10:35:18.64Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nNot sure which way you want to do but we have two sample for time-series training:\n\nFor Machine Learning SDK:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-forecast\n\nFor Machine Learning Studio:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/time-series\n\nThose two should be a good start.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unable to use notebook in Azure ML",
        "Question_creation_time":1611215759177,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/239535\/unable-to-use-notebook-in-azure-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"I have been following several ML tutorials and this is the second time that I cannot work in the notebook directly in Azure ML. I can open and edit it in Jupyter notebook, but it will never open in ML.\n\nAlso it states \"no kernel selected\" but its greyed out. I tried login in and out with no change.\n\nTutorial i followed:\ndocs.microsoft.comhttps:\/\/docs.microsoft.com\/da-dk\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/deploy-service",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Can I run ML on my own hardware or ARC connected cluster",
        "Question_creation_time":1611291212300,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/240991\/can-i-run-ml-on-my-own-hardware-or-arc-connected-c.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I am just trying to find a simple YES\/NO answer to this question\n\nCan I run Azure ML on my own hardware\/cluster? All the functions to register a new VM\/system via IP address have been deprecated and now requires a resource ID.\n\nI have created 2 resources in Azure ARC - A cluster and a server and I cant use either resource id to link to Azure ML via python or AZ command - both advise its not virtual machine.\n\nSo if someone could please put my out of my misery, can you run Azure ML on your own hardware.\n\nThanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-22T08:22:06.077Z",
                "Answer_score":0,
                "Answer_body":"Hi,\nHere are the supported compute targets. Note that there is local computer but it is possible only Automated Machine learning and not for pipelines and designer. This means that you do not add the local computer as target. There are links on how to use local computer target. ARC resources are different from the Azure resources for VMs and Kubernetes so it is not possible to add them.\n\nPlease \"Accept the answer\" if the information helped you. This will help us and others in the community as well.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"I can't delete Azure ML workspace",
        "Question_creation_time":1611219605467,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/239609\/i-can39t-delete-azure-ml-workspace.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":11,
        "Question_score":0,
        "Question_body":"I created azure ml workspace - region east us, after I tried to create compute instances in this workspace I found that those resources could't be allocated from that region and compute instances were in the unknown state. I decided to delete this workspace but the deletion is taking more than 8 hours, I want to delete this workspace as it decreases the available quotas for me for compute resources.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-21T14:48:35.17Z",
                "Answer_score":0,
                "Answer_body":"@NineliLashkarashvili-3910 Could you please try to delete your workspace from the CLI?\n\n az ml workspace delete [--all-resources]\n                        [--no-wait]\n                        [--output-metadata-file]\n                        [--path]\n                        [--resource-group]\n                        [--subscription-id]\n                        [--workspace-name]\n\n\n\n\nInstallation of the Azure CLI is easy and once you install and authenticate with az login\nAzure ML cli is an extension of Azure CLI which is installed when you run azure-cli-ml\n\nIf this fails to delete your workspace a support ticket might be required. We can help you with a one time free ticket if the above method does not work. Thanks!!",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML doesn't let me use notebooks",
        "Question_creation_time":1610372674263,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/226106\/azure-ml-doesn39t-let-me-use-notebooks.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I am going into my notebooks portal on one of my expiriments, and it says,\"The current subscription state does not allow this operation.\" It worked yesterday, but why not today?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-11T18:43:03.25Z",
                "Answer_score":0,
                "Answer_body":"Hi, can you please share a screenshot of this issue? Are you getting the error when you open your notebook from Azure ML Studio? Can you please ensure that your subscription is active?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Images Segmentation using Azure",
        "Question_creation_time":1610951620483,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/234232\/images-segmentation-using-azure.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"Hi,\nI have been using object detection from Custom Vision to train images. Classification do not suit my goal so I'm looking at alternative methods to training images. Can I get some suggestions with using Azure for images segmentation?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-18T07:40:18.9Z",
                "Answer_score":1,
                "Answer_body":"Hi @NamLy-3299\n\nSuggestions and refer below url for Azure for images segmentation.\n\nCustom Vision integration sample skill for cognitive search\n\nClassify images with the Custom Vision service\n\n\n\n\nPlease don\u2019t forget to Accept the answer and up-vote wherever the information provided helps you, this can be beneficial to other community members.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How do I orchestrate ML model retraining periodically?",
        "Question_creation_time":1610148728983,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/224481\/how-do-i-orchestrate-ml-model-retraining-periodica.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":1,
        "Question_body":"I have to retrain every month or so a PyTorch Model trained on data obtained from processing tables sitting in Azure Data Lake Storage gen 1.\n\nSo far, I have the following building blocks:\n\nA Databricks notebook that does the ETL job of transforming the ADLS gen 1 tables into train\/validation files that are written in blob storage\n\n\nPython scripts that I can execute locally to run in an AzureML workspace an experiment so to train the PyTorch model using a ScriptRunConfig + training script as in https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-pytorch mounting blob to get the training data.\n\nHow can I schedule steps 1. and 2. to be run in sequence in a pipeline? Azure Data Factory seems a possible way to go, but what should I use as activities in ADF?\n\nI see a few alternatives:\n\nStays surely a Databricks notebook\n2a. Databricks python script calling the azureml-sdk classes (?)\n\nAlternative for step 2a could be\n\n2b. a Batch Service custom activity calling the azureml-sdk classes - seems overkill to me\n2c. use a AzureML execute pipeline as ADF activity https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-ml-pipelines (not sure how...)\n2d. use a Python script Databricks activity train a PyTorch model with Databricks https:\/\/docs.microsoft.com\/en-us\/azure\/databricks\/applications\/mlflow\/tracking-ex-pytorch instead of calling the azureml-sdk classes\n\nCan someone point me to the current best practice for this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-11T08:57:22.71Z",
                "Answer_score":0,
                "Answer_body":"@DavideFiocco-7346 Thanks for the question. Activate a pipeline to retrain the model using AML pipeline. We have a functional repo with training \/ retraining available right here. The link below explains how to use Azure DevOps Project for build and release\/deployment pipelines along with Azure ML services for model retraining pipeline, model management and operationalization. Can you please add more details about the use case.\nHere are some links you might find useful:\n- https:\/\/github.com\/microsoft\/MLOps\n- https:\/\/github.com\/microsoft\/MLOpsPython\n- https:\/\/github.com\/csiebler\/azureml-workshop-2020\/blob\/master\/3-mlops\/MLOps_basic_example.md\n\n\n\n\nSample AI Reference Architectures.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning studio - Images which have filename containing square brackets is not shown in outputs folder.",
        "Question_creation_time":1610588261997,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/229808\/azure-machine-learning-studio-images-which-have-fi.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Hi, I am using Azure Machine Learning studio.\n\nI trained my deep learning model on computing cluster, and then outputs images onto 'outputs' directory.\nHowever, in Experiment > Run > outputs + logs tab, directories was displayed instead of my images.\n\nIs it possible to get my images from 'outputs' directory?\n\n\n\n\nAfter investigation, I recognized that images which have filename containing square brackets is not shown in the tab.\nFor instance, if I created 'outputs\/test[0].jpg', then 'outputs\/test' directory was shown in the tab.\n\n[Sample code]\n\n import cv2\n import numpy as np\n from pathlib import Path\n    \n # Check whether output directory exists or not\n output_dir = Path('.\/outputs\/')\n if not output_dir.exists():\n     output_dir.mkdir()\n    \n # Generate test image\n IMAGE_SIZE = (28, 28)\n    \n test_image = np.zeros(IMAGE_SIZE)\n    \n # Save image with filename which contained \/ not contained square brackets\n # 'test.jpg' and 'test' directory will be shown in the 'outputs' directory, however 'test[].jpg' and 'test[0].jpg' are disappeared.\n cv2.imwrite(str(output_dir \/ 'test.jpg'), test_image)\n cv2.imwrite(str(output_dir \/ 'test[].jpg'), test_image)\n cv2.imwrite(str(output_dir \/ 'test[0].jpg'), test_image)",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-14T17:44:42.36Z",
                "Answer_score":0,
                "Answer_body":"Hi, it probably recognizes the square bracket as wildcard. Try using a double-backticks to escape the brackets, otherwise, I recommend you rename without the brackets and train again.\n\n cv2.imwrite(str(output_dir \/ 'test``[``].jpg'), test_image)",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-01-15T01:47:53.393Z",
                "Answer_score":0,
                "Answer_body":"Appreciate your reply.\n\nAlthough I tried adding double-backticks to escape square brackets, I cannot find my images in the workspace.\n\n[Fixed Code]\n\n (Omission)\n    \n # Save image with filename which contained \/ not contained square brackets\n cv2.imwrite(str(output_dir \/ 'test.jpg'), test_image)\n cv2.imwrite(str(output_dir \/ 'test[].jpg'), test_image)\n cv2.imwrite(str(output_dir \/ 'test[0].jpg'), test_image)\n cv2.imwrite(str(output_dir \/ 'test``[``].jpg'), test_image)  # Escape square brackets with double-backticks\n cv2.imwrite(str(output_dir \/ 'test``[0``].jpg'), test_image) # Escape square brackets with double-backticks\n\n\n\nResults:\n\nNew directory with backticks appeared.\n\n\n\n\n\nAnd I will rename image files from next experiment,\nhowever I wish to get my image generated in my previous experiment because of the experiment's long elapsed time.\nAre there any good methods for that?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-01-18T00:38:16.14Z",
                "Answer_score":0,
                "Answer_body":"Appreciate your help.\n\nI will re-execute my experiment with images renaming.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is it possible to take a ML Azure Container Instance from the registry and deploy it elsewhere?",
        "Question_creation_time":1610554902053,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/229405\/is-it-possible-to-take-a-ml-azure-container-instan.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":1,
        "Question_body":"Hi,\n\nI was wondering if it was possible to take a ML Model deployed to a container instance and then take that and deploy that in docker elsewhere. I have managed to sync a repo with the Azure registry and download the container which was created in Azure ML. When i started the container though it didn't do anything; i logged into the container and nothing was running; i could start NGINX but wasn't sure if this was a supported?\n\nI was that you can do this with the Azure Sentiment Analysis Containers but wondering if you could do with ML Azure Container Instances?\n\nAny pointers would be good.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-15T18:26:56.77Z",
                "Answer_score":1,
                "Answer_body":"Thanks for reaching out. Yes, however, you need to run az ml model package to get an image with your model baked into it, otherwise, the model file is mounted by the deployment engine. Here's more information on how to package a registered model with Docker. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"check workspace details \/ settings",
        "Question_creation_time":1610192562230,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/224633\/check-workspace-details-settings.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":1,
        "Question_body":"Hi all,\n\nI am doing the following exercise: https:\/\/microsoftlearning.github.io\/mslearn-dp100\/instructions\/02-automated-ml.html\nIn step3 this is what I had to do:\n\u2022 Region: The same region as your workspace\n\u2022 Virtual Machine priority: Dedicated\n\u2022 Virtual Machine type: CPU\n\u2022 Virtual Machine size: Standard_DS11_v2\n\u2022 Compute name: enter a unique name\n\u2022 Minimum number of nodes: 0\n\u2022 Maximum number of nodes: 2\n\u2022 Idle seconds before scale down: 120\n\u2022 Enable SSH access: Unselected\n\nI think I went a bit too fast and did not check the following:\n\u2022 Minimum number of nodes: 0\n\u2022 Maximum number of nodes: 2\n\u2022 Idle seconds before scale down: 120\n\u2022 Enable SSH access: Unselected\n\nHow can I check if I selected the correct nodes, idle second and SSH access. Also, if these are not set correctly, how can I change these? I do not want to start again and create a new workspace.\n\nThanks,\n\nNaveen",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-11T11:05:40.417Z",
                "Answer_score":1,
                "Answer_body":"@Naveen-5216 Yes, you can edit your compute configuration. Please navigate to the compute cluster tab and click on the Edit option to change these settings and save when done. There is no need to create a new workspace, you can update this cluster configuration or create a new compute cluster if needed.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Docker container fails to run due to invalid --GPU switch",
        "Question_creation_time":1610298719520,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/225027\/docker-container-fails-to-run-due-to-invalid-gpu-s.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":7,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I have been testing Azure ML experiments running locally on my machine with docker. So far I have run into the same issue using several curated environments as well as using a conda dependencies file.\n\nThe run job is submitted successfully\n\n\nDocker container builds successfully\n\n\nThe docker run command fails due to the --gpu all switch\n\nThis switch gets added to every docker container I try to launch locally (doesn't matter the container type).\n\nI have tested this a few different ways\n- Using VScode and VScode insiders\n- Running the experiment from code\n- Running Experiment the Azure ML Extension in VScode\n\n\n\n\nAll attempts end with the docker container failing to run.\n\nAny thought on how to fix this would be appreciated.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"machine learning server",
        "Question_creation_time":1610574178773,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/229665\/machine-learning-server.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"Hi,\n\nI am not able to use my Jupyterlab and Jupyter Notebook. It cannot connect to a Kernel.\n\nWill this problem be solved when I uninstall Anaconda and install Microsoft Machine Learning Server.\n\nThanks,\n\nNaveen",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-13T23:52:37.883Z",
                "Answer_score":1,
                "Answer_body":"Hi, I'm assuming you're using your own development environment. I found some troubleshooting steps that may be helpful. Furthermore, Azure Machine Learning Server is an enterprise software that provides the tools for performing data science tasks. You can review Azure ML Server and other options to determine which option best suits your data science scenario. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Round columns in Azure ML",
        "Question_creation_time":1610454807547,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/227626\/round-columns-in-azure-ml.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"Hello,\n\nI have made an experiment in Azure ML with a coefficient of detemination reaching 86% (regression). I would like to improve it using the rounding of several features (columns). I would like to round some columns to \"xx-ten\" example: 1854 => 1850 (up and down if possible)\nI have used ceil functions before to avoid decimal numbers but here this is another case. I cannot see how to do this.\n\nCan anyone help in this please?\n\nKind Regards,\n\nMohamed.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-13T21:48:43.547Z",
                "Answer_score":1,
                "Answer_body":"Hello Dear,\n\nThank you for your advice. I have found in the rounding area the \"tomultiple\" function where I can decide to round a number to tens, hundreds... (example: tomultiple(2583,10) => 2580).\n\nThank you :)\n\nMohamed.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-01-12T20:22:24.783Z",
                "Answer_score":0,
                "Answer_body":"Hi, the Apply Math Operation module has a rounding operator that can be used to round up\/down on a given column set.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML time series model inference error during data input (python)",
        "Question_creation_time":1609993978043,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/221774\/azure-ml-time-series-model-inference-error-during.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I prepared a model for time series forecasting. The data have some rare gaps in all data sets. I am using the following code to call for a deployed Azure AutoML model as a web service:\n\n import requests\n import json\n import pandas as pd\n    \n # URL for the web service\n scoring_uri = 'http:\/\/xxxxxx-xxxxxx-xxxxx-xxxx.xxxxx.azurecontainer.io\/score'\n        \n # Two sets of data to score, so we get two results back\n new_data = pd.DataFrame([\n             ['2020-10-04 19:30:00',1.29281,1.29334,1.29334,1.29334,1],\n             ['2020-10-04 19:45:00',1.29334,1.29294,1.29294,1.29294,1],\n             ['2020-10-04 21:00:00',1.29294,1.29217,1.29334,1.29163,34],\n             ['2020-10-04 21:15:00',1.29217,1.29257,1.29301,1.29115,195]],\n             columns=['1','2','3','4','5','6']        \n )\n # Convert to JSON string\n input_data = json.dumps({'data': new_data.to_dict(orient='records')})\n    \n # Set the content type\n headers = {'Content-Type': 'application\/json'}\n        \n # Make the request and display the response\n resp = requests.post(scoring_uri, input_data, headers=headers)\n print(resp.text)\n\n\n\nI am getting an error:\n\n {\\\"error\\\": \\\"DataException:\\\\n\\\\tMessage: No y values were provided. We expected non-null target values as prediction context because there is a gap between train and test and the forecaster depends on previous values of target. If it is expected, please run forecast() with ignore_data_errors=True. In this case the values in the gap will be imputed.\\\\n\\\\tInnerException: None\\\\n\\\\tErrorResponse \\\\n{\\\\n\n\n\n\nI tried to add \"ignore_data_errors=True\" to different parts of the code without a success, hence, getting another error:\n\n TypeError: __init__() got an unexpected keyword argument 'ignore_data_errors'\n\n\n\nI would very much appreciate any help as I am stuck at this.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Speech to Text, Text to Speech, Speech Translation, PHP AP\u0130 document ?",
        "Question_creation_time":1610464220930,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/227739\/speech-to-text-text-to-speech-speech-translation-p.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Speech to Text, Text to Speech, Speech Translation We will use the services. I need a php document ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-12T20:32:17.047Z",
                "Answer_score":0,
                "Answer_body":"Hi, I couldn't find an official Speech services \"PHP\" Api document. However, a tool like postman can easily generate a PHP code snippets from your request. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is it possible to use a Windows Account for configuring Machine Learning Server 9.4.7?",
        "Question_creation_time":1610029811687,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/222486\/is-it-possible-to-use-a-windows-account-for-config.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"After configuring Machine Learning Server with a password, one connects to the server through the user name \"admin\" and the designated password. Is it possible configure Machine Learning Server to use a Windows Account instead of the default \"admin\"?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-09T00:30:26.617Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nIf you are asking the password at below step, the answer is no:\n\n\"Set a password used to protect your configuration settings. Later, after configuration is finished, anyone who wants to use the CLI to modify a configuration must provide this password to gain access to settings and operations.\n\nThe password must meet these requirements: 8-16 characters long, with at least one upper-case letter, one lower-case letter, one number, and one special character.\"\n\nPlease let me know if you have more questions. Thanks and happy new year.\n\nRegards,\nYutong",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to create a Compute Instance",
        "Question_creation_time":1609999991360,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/221759\/how-to-create-a-compute-instance.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Hello Folks,\n\nI'm currently using a free trial version of Azure.\n\nWhen creating a compute instance in machine learning studio, I cannot select a virtual machine.\nAll virtual machine names in the selection field are inactive.\n\n\nHow are these virtual machines activated?\n\n\n\n\n\nI am creating a virtual machine \"Standard_D2s_v3\".\nAnd I interpret this capture as showing that there are two available quarters for \"Standard DSv3 Family vCPUs\".If so, why is the virtual machine \"Standard_D2s_v3\" inactive?\n\n\n\n\n\nI'm sorry for my poor English.\nI very appreciate any help or direction. Thank you.\n\nRegards,\nKoki",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-07T08:31:53.753Z",
                "Answer_score":0,
                "Answer_body":"@Koki-2318 I think there could be two reasons here for this behaviour.\n\nThe second screen shot could be showing the availability in a different region than your Azure ML workspace region. Please verify if this is the case.\n\n\nThe Azure ML resource under the free tier has a special exception with regards to the compute that can be used. This is limited based on the available cores and the subscription offering. This is documented here with more details. If this is the case you can raise a quota increase and our team will evaluate the feasibility based on your subscription offering.\n\nIf the above two cases do not resolve you can convert to a pay as you go subscription and use the required compute size with your Azure ML experiments. Thanks!!",
                "Answer_comment_count":6,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Deepspeed gpt-2 megatron-LM problems",
        "Question_creation_time":1610037769210,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/222550\/deepspeed-gpt-2-megatron-lm-problems.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":7,
        "Question_score":1,
        "Question_body":"I am trying to make a GPT-2 model with deepspeed on an azure VM. I found ~2 bugs which I was able to patch, but I have stumbled upon a really tough one. You see, it says I need pytorch. No surprise. I install pytorch. It still says I don't have it. I used both pip and pip3 many times. I install pytorch from github and run setup.py. It says I need python 3. When I get python 3 it says the same. When I try google colab it gives me the following error:\nTraceback (most recent call last): File \"pretrain_gpt2.py\", line 709, in <module>\nmain() File \"pretrain_gpt2.py\", line 654, in main\nargs.eod_token = get_train_val_test_data(args) File \"pretrain_gpt2.py\", line 600, in get_train_val_test_data\nargs) File \"\/content\/DeepSpeedExamples\/Megatron-LM\/configure_data.py\", line 34, in apply\nreturn make_loaders(args) File \"\/content\/DeepSpeedExamples\/Megatron-LM\/configure_data.py\", line 170, in make_loaders\ntrain, tokenizer = data_utils.make_dataset(**data_set_args) File \"\/content\/DeepSpeedExamples\/Megatron-LM\/data_utils\/init.py\", line 109, in make_dataset\nds = split_ds(ds, split) File \"\/content\/DeepSpeedExamples\/Megatron-LM\/data_utils\/datasets.py\", line 194, in split_ds\nrtn_ds[i] = SplitDataset(ds, split_inds) File \"\/content\/DeepSpeedExamples\/Megatron-LM\/data_utils\/datasets.py\", line 134, in init\nself.lens = itemgetter(*self.split_inds)(list(self.wrapped_data.lens)) TypeError: itemgetter expected 1 arguments, got 0\n\nHow do I fix both the google colab and the azure VM errors?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-11T23:51:27.243Z",
                "Answer_score":1,
                "Answer_body":"@Sammyboy123\nI would start by installing PyTorch via pip. Instructions can be found here. There is also a verification section which will test if you have PyTorch installed correctly. You also might find the DeepSpeed Getting Started page helpful. There are specific tutorials for Azure and also a docker image available.\n\nLet me know if this doesn't work for you or you are still facing issues.\n\n\n\n\nPlease don\u2019t forget to \"Accept the answer\" and \u201cup-vote\u201d wherever the information provided helps you, this can be beneficial to other community members.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"RStudio Server stack limit error",
        "Question_creation_time":1609858201667,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/219363\/rstudio-server-stack-limit-error.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":6,
        "Question_score":1,
        "Question_body":"I'm using a free account with a default configuration. I'm trying to get through this tutorial https:\/\/docs.microsoft.com\/pl-pl\/azure\/machine-learning\/tutorial-1st-r-experiment.\n\nI encounter the error: C stack usage <big number> is too close to the limit.\n\nBecause of this, I cannot complete the tutorial. I'm wondering how to solve this issue. Is it about free account limitations like memory and\/or CPU?\n\nCan anyone help?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-11T16:09:10.667Z",
                "Answer_score":0,
                "Answer_body":"Hi, if you're still observing the above error, I found some troubleshooting steps that may be helpful.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to update azure ml webservice",
        "Question_creation_time":1601290286423,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/109836\/how-to-update-azure-ml-webservice.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I am trying to update azure ml webservice which already deployed with new scoring file . Can you please help me in this , i follow your instruction from https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-update-web-service but i am getting error as AttributeError: 'NoneType' object has no attribute 'lower' (https:\/\/stackoverflow.com\/questions\/63763564\/how-to-update-scoring-py-file-in-deployed-azure-ml-web-services-without-changing\/64095971#64095971 ) and i am not able to solve it , can you please help me .?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-28T23:21:02.563Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. Based on the error message, it is possible that you are calling .lower() on an object that is not a string or the data has a none value. You may want to review\/clean your dataset. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-10-15T14:27:50.737Z",
                "Answer_score":0,
                "Answer_body":"When I get this error it means that a string hasn't been found. In my case it was that that something didn't exist (a string is expected) and therefore None was returned which causes the error. I was looking up a registered model on Azure that didn't exist due to a name change, and this caused a similar error for me. Double check the error logs and trace back and see where things go wrong, maybe you are searching for something that doesn't exist.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-01-11T11:57:41.277Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nI have modified a few steps in my training experiment (new data set, add \"Principal Components Analysis\" module ...). But now I want to update my predictive experiment (webservice) but I cannot. The button for that does not appear, only \"deploy webservice\" button but it does not do anything..\nCan anyone help me in this please?\n\nRegards,\n\nMohamed.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ml for data series in 3 states (stages)",
        "Question_creation_time":1610145100317,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/224370\/azure-ml-for-data-series-in-3-states-stages.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":1,
        "Question_body":"Hello! I am new to using azure ml and I am trying to recreate in azure ml a process that is composed of 3 different states. State 1 influences state 2, state 1 and 2 influence state 3. Indeed I need azure ml to predict what will happen in stage 2, after analyzing stage 1 data, then what will happen in stage 3 after analyzing stage 1 data and 2. I can't find any way to put the data in azure ml in this configuration.If anyone has a suggestion ... it would help me. Thanks in advance for any help.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-09T04:30:00.617Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. Please review our documentation on ML Pipelines and how to move data between pipeline steps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"VBA And Azure Machine Learning Excel Add In",
        "Question_creation_time":1610149745593,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/224491\/vba-and-azure-machine-learning-excel-add-in.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Hi! I wanted to see if VBA and Azure Machine Learning Excel Add In can be connected to each other. Are there any way to code VBA (use VBA) for controlling or altering Azure Machine Learning Excel Add In? I have used Azure Machine Learning to rate candidate feedback as negative or positive, but it has like a 75 -80% success rate - there are still a good chunk of comments that are rated wrong. However, it is still an amazing tool that I want to use v- I was just wondering if I can increase the accuracy of it somehow by creating a VBA code that connects it to Azure Machine Learning where I can add words related to negative responses or vice versa for positive response to increase the accuracy.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-09T03:09:29.647Z",
                "Answer_score":0,
                "Answer_body":"Hi, we currently don't support VBA and Azure ML Excel add-in integration. You'll need to apply ML techniques for improving your model and re-deploy your model.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"AutoML automatic data preprocessing?",
        "Question_creation_time":1610102782470,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/223781\/automl-automatic-data-preprocessing.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"I used a dataset that contains missing values, and Auto ML reached over 90% accuracy. I am curious how Auto ML dealt with missing values and if there is a way to retrieve the preprocessed dataset that Auto ML created? Or does it ignore rows with missing data?\n\n\n\n\nAdditionally, I selected \"enable deep learning\" when creating my Auto ML instance, but when I look at the models tried after the process completes, I do not see deep learning models have been tried. Why is that? I see random forest, LightGBM, XG boost, but no deep neural nets.\n\n\n\n\nThank you.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-08T16:39:30.077Z",
                "Answer_score":0,
                "Answer_body":"@HyunJaeCho-5323 Thanks for the question. Here is the doc for Auto ML Data prep \/ feature engineering.\n\n\n\n\n\nMissing value imputaion: Mean, median, mode, one hot imputation marker.\n\nAre you using the SDK or UI? We are working on a progress bar which will show up when training DNNs. Until that is released, there are couple of different ways to verify DNNs in the model:\n1. Logs in portal \u2013 azureml_automl.log will have printed statement for pretrained transformer or bilstm transformer. You can search for the string \u201cAdded\u201d in the logs, which will tell what transformers were added in featurization. When BERT or BiLSTM is chosen, \u201cpretrained\u201d or \u201cbilstm\u201d transformer will appear in this log line\n2. After training the model, download the model and if you have all required dependencies locally available, you can unpickle the downloaded model and look into its featurization steps and it will list pretrained or bilstm transformer when the model pipeline includes it.\n\n\u2022 ML Interpretability dashboard supported to understand feature importance for all models except ForecastTCN.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is there any way to print auto ml rank value?",
        "Question_creation_time":1610014966120,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/222271\/%E1%84%8B%E1%85%A9%E1%84%90%E1%85%A9ml-%E1%84%89%E1%85%AE%E1%86%AB%E1%84%8B%E1%85%B1%E1%84%80%E1%85%A1%E1%86%B9-%E1%84%8E%E1%85%AE%E1%86%AF%E1%84%85%E1%85%A7%E1%86%A8%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB-%E1%84%87%E1%85%A1%E1%86%BC%E1%84%87%E1%85%A5%E1%86%B8%E1%84%8B%E1%85%B3%E1%86%AB-%E1%84%8B%E1%85%A5%E1%86%B9%E1%84%82%E1%85%A1%E1%84%8B%E1%85%AD.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":6,
        "Question_score":1,
        "Question_body":"\uc624\ud1a0ml \uc0ac\uc6a9\ud558\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n\uacb0\uacfc\uac12\uc744 \ub192\uc740 \ud655\ub960\uc21c\uc73c\ub85c\n1\uc21c\uc704 \uacb0\uacfc\uac12, 2\uc21c\uc704 \uacb0\uacfc\uac12, 3\uc21c\uc704 \uacb0\uacfc\uac12\uc73c\ub85c \ucd9c\ub825\ud558\uace0 \uc2f6\uc740\ub370\n\uc624\ud1a0ml\ub85c\ub294 1\uc21c\uc704 \uacb0\uacfc\uac12\ub9cc \ucd9c\ub825\uc774 \ub429\ub2c8\ub2e4.\n\uc5ec\ub7ec \uc21c\uc704\ub97c \ucd9c\ub825\ud558\ub294 \ubc29\ubc95\uc740 \uc5c6\uc744\uae4c\uc694??\n\n\n\n\nTranslated from Korean to English:\n\nI am using auto ml.\nResults in order of high probability\nI want to print the first result value, the second order result value, and the third order result value.\nWith auto ml, only the first priority result is output.\nIs there any way to print multiple ranks??",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Does the \"Estimated monthly costs\" for Azure Machine Learning in the Price Calculator include all other non-compute \"additional resources\" created in the workspace",
        "Question_creation_time":1609267518950,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/213635\/does-the-34estimated-monthly-costs34-for-azure-mac.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"When trying to use the Azure Pricing estimate in the Azure Pricing Calculator, the \"Estimated monthly costs\" seems to include but also far exceeds the compute cost. Does this Estimated Monthly cost include the other resources that get created?\neg. Azure Container Registry Basic account, Azure Block Blob Storage (general purpose v1), Key Vault\n\nThank you\nPeter",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-29T23:51:49.057Z",
                "Answer_score":1,
                "Answer_body":"Hi Peter.\n\nThanks for reaching out. I tried your selections but I don't have the same service as you. Have you selected other services in you calculator?\n\nFor your question, the estimated price is only for Azure Machine Learning Service. You need to select all services you need in the calculator like below:\n\n\nPlease note I only use random number for the example.\n\nFrom the number I guess you have selected 2 Machine Learning Services and also other services since they added to your basket when you clicked them, you can click the button to see what you have all as below.\n\n\nAlso you are selecting Reservation service, detail: https:\/\/docs.microsoft.com\/en-us\/azure\/cost-management-billing\/reservations\/save-compute-costs-reservations\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2021-01-07T20:58:48.993Z",
                "Answer_score":0,
                "Answer_body":"Thank you Yutong.\nI see now that the other services in the calculator caused this discrepency.\n\nthank you so much",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Data Labeling not accesible after Transfer billing ownership",
        "Question_creation_time":1609967334840,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/221503\/data-labeling-not-accesible-after-transfer-billing.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Hi,\n\nI transferred the billing ownership of my azure directory, and now I have not access to the ML data labeling project.\n\nEverything works fine in the destination account, but the data labeling project that was in progress.\n\nIf I create a new data labeling project using the same Datastore, It will work; I can label images as usual. But the original project will not work, I can even open the project but in the moment I try to \"Label Data\", it says I don't have permissions.\n\n\nThis error pops up even using the owner user.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Data input format (call the service) for Azure ML time series forecast model deployed as a web service (Python)",
        "Question_creation_time":1609733310997,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/217305\/data-input-format-call-the-service-for-azure-ml-ti.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":6,
        "Question_score":1,
        "Question_body":"Sorry in advance for the lengthy question as I wanted to explain it as detailed as possible. I used the Azure AutoML to train a model and deployed it as a web service. Now I can access (call) it over the REST endpoint.\n\nI have the following data types for attributes: date (timestamp), number, number, number, number, integer. I trained the model with the following parametres:\n\nTimestaps interval: 15 min\nForecast Horizon: 4 (I need the forecast every hour for the next hour)\nTarget rolling window size: 96 (the forecast must ba based on the last 24 hours of data)\n\nI have two questions.\n\nAs I understand, based on the above, I have to provide last 4 entries to the model for a correct prediction. Otherwise, it will consider a time gap. Am I right? In this case, how I could input 4 instances at a time for a single prediction? The following example is wrong as it asks for 4 predictions for each instance:\n\nimport requests\nimport json\n\nURL for the web service\n\nscoring_uri = 'http:\/\/xxxxx-xxxxxxx-xxxxxx-xxxxxxx.xxxxx.azurecontainer.io\/score'\n\ndata = {\"data\":\n[\n[\n2020-10-04 19:30:00,1.29281,1.29334,1.29334,1.29334,1\n],\n[\n2020-10-04 19:45:00,1.29334,1.29294,1.29294,1.29294,1\n],\n[\n2020-10-04 21:00:00,1.29294,1.29217,1.29334,1.29163,34\n],\n[\n2020-10-04 21:15:00,1.29217,1.29257,1.29301,1.29115,195]\n]\n}\n# Convert to JSON string\ninput_data = json.dumps(data)\n\nSet the content type\n\nheaders = {'Content-Type': 'application\/json'}\n\nMake the request and display the response\n\nresp = requests.post(scoring_uri, input_data, headers=headers)\nprint(resp.text)\n\nThe above code is based on the provided Microsoft example https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=python#call-the-service-python.\n\nI am unable to replicate the provided example with my data. I have an error \"SyntaxError: leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\" pointing to the date. I assume, I need to specify the data type but could not find how.\nI tried to load a line from a csv file but I have an error (SyntaxError: invalid syntax) pointing to \"with\" with the following:\n\ndata = {\"data\":\n[with open('file', \"r\") as f:\nfor line in f: pass\nprint(line)]\n}\n\nI tested getting the last line from a csv file intependetly and it works but not inside the full script.\n\nI very appreciate any help or direction. Thank you.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-04T21:41:48.693Z",
                "Answer_score":1,
                "Answer_body":"@AlexeyPisakov-8757\nPlease try the solution mentioned below.\n\nThe service takes data in form of deserialized pandas data frame. In the example below, it will look like:\nimport json\n\nX_test = pd.DataFrame([\n\n ['2020-10-04 19:30:00', 1.29281, 1.29334, 1.29334, 1.29334, 1],\n ['2020-10-04 19:45:00', 1.29334, 1.29294, 1.29294, 1.29294, 1],\n ['2020-10-04 21:00:00', 1.29294, 1.29217, 1.29334, 1.29163, 34],\n ['2020-10-04 21:15:00', 1.29217, 1.29257, 1.29301, 1.29115, 195]],\n columns=['date', 'number_1', 'number_2', 'number_3', 'number_4', 'integer']\n\n\n\n)\n\ntest_sample = json.dumps({'data': X_test.to_dict(orient='records')})\n\ntest_sample\n\n\n\n\nWhich will result in JSON string as:\n\n{\"data\": [{\"date\": \"2020-10-04 19:30:00\", \"number_1\": 1.29281, \"number_2\": 1.29334, \"number_3\": 1.29334, \"number_4\": 1.29334, \"integer\": 1}, {\"date\": \"2020-10-04 19:45:00\", \"number_1\": 1.29334, \"number_2\": 1.29294, \"number_3\": 1.29294, \"number_4\": 1.29294, \"integer\": 1}, {\"date\": \"2020-10-04 21:00:00\", \"number_1\": 1.29294, \"number_2\": 1.29217, \"number_3\": 1.29334, \"number_4\": 1.29163, \"integer\": 34}, {\"date\": \"2020-10-04 21:15:00\", \"number_1\": 1.29217, \"number_2\": 1.29257, \"number_3\": 1.29301, \"number_4\": 1.29115, \"integer\": 195}]}\n\n\n\n\nPlease rename the columns to the corresponding columns from the training data set.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How to deploy a keras or tensorflow model on iot edge and inference using onnx runtime?",
        "Question_creation_time":1608665108717,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/207778\/how-to-deploy-a-keras-or-tensorflow-model-on-iot-e.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I have developed a classification model in keras. I wish to deploy this model onto iot edge device.How can I inference this model using onnx runtime..How to write the scoring script.Is there any good source to refer the same?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-22T22:04:08.817Z",
                "Answer_score":0,
                "Answer_body":"Hello @AnuragShelar-8594\n\nThis is not a simple question to answer due to the many different ways of handling a model.\n\nI recommend checking out the MS Learn modules for the AI Edge Engineer role first.\n\nAfter that, check out this handson lab based on a yolo model on a Jetson Nano.\n\nLast but not least, look at this page and follow workflow WF1.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-01-05T16:51:31.507Z",
                "Answer_score":1,
                "Answer_body":"Check this reference sample for deploying ONNX models to IoT Edge devices. This reference implementation is using a DevOps pipeline to automate the retraining-deployment steps for CI\/CD. It uses a keras->onnx conversion to generate the ONNX graph in the Jupyter notebook.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Choice of Azure technology for a backend system - Azure newcomer",
        "Question_creation_time":1608401528893,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/204380\/choice-of-azure-technology-for-a-backend-system-az.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":1,
        "Question_body":"Hi,\n\nI would like to use Azure to:\n\nRun a server\/service (in a broad sense) issuing HTTP\/REST API requests to an online resource (think: Twitter) - probably not event-based, but rather periodically (e.g. every 5 minutes)\n\n\nHave the retrieved data in 1. being processed for some custom analytics (think: some statistics\/ML written in Python and ran on tweets). I'm not sure yet whether the unprocessed data should be stored, or if I will decide to process\/analyze them on the fly, and drop the \"raw\" input immediately afterwards\n\n\nStore the \"analytics\" result in some (probably relational) database for further use\n\nwhere all of the above should be \"in the cloud\". Given the abundance of options\/solutions in Azure, to which I'm new, what would be the names\/keywords\/technologies that I should read upon or google to get things started with my architecture?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-21T08:39:06.89Z",
                "Answer_score":0,
                "Answer_body":"Below documents should help to check if any similar architecture is suggested by Microsoft. Make use of filters\/index on left side of page\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/architecture\/browse\/\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/architecture\/guide\/\n\nAzure data factory - can be used to pull data from API and scheduling this process\nAzure data lake gen2 - to store raw and processed files\nAzure databricks - to connect to files stored in ADLS Gen2, process the data using python, scala etc.\nAzure SQL DB - to store relational data\n\nPlease don't forget to Accept Answer and Up-vote if the response helped -- Vaibhav",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is onnx the best way to deal with azure iot edge Machine Learning models?",
        "Question_creation_time":1609255835060,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/213450\/is-onnx-the-best-way-to-deal-with-azure-iot-edge-m.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"I am working on Azure IOT Edge. I have three models.\na)yolov3 object detection model in .weights format\nb)Resnet classfication model\nc)VGG16 classification model in .h5 format.\n\nI converted them to onnx and using onnx runtime inferenced them and wrote the necessary scoring scripts.\n\nI wanted to know how do I use these models in original format without converting them to onnx or is onnx the best way for iot edge modules?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-29T16:07:59.92Z",
                "Answer_score":1,
                "Answer_body":"Hi @AnuragShelar-8594 it is not mandatory that you convert your models to onnx. Check this doc:\n\nOpen-source integration with Azure Machine Learning projects\n\n\"You can train, deploy, and manage the end-to-end machine learning process in Azure Machine Learning by using open-source Python machine learning libraries and platforms. Use development tools, like Jupyter Notebooks and Visual Studio Code, to leverage your existing models and scripts in Azure Machine Learning.\"\n\nThanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2021-01-04T18:41:02.81Z",
                "Answer_score":1,
                "Answer_body":"If you didn't covert the models to ONNX then the respective inference engines will need to be included in your IOT-Edge module to run the inference.\n\nONNX provides the common format to represent the NN models from different training frameworks and execute using the same runtime, i.e. onnxruntime, on various edge device platforms. The same base docker image can be used to run the ONNX models across x86, arm64 devices with different accelerators like GPUs and VPUs.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Does AutoML support optimizing convolutional neural network over the number of layers and pool layer parameters?",
        "Question_creation_time":1607093437353,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/186789\/does-automl-support-optimizing-convolutional-neura.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Does AutoML support optimizing convolutional neural network over the number of layers and pool layer parameters?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-04T21:28:34.597Z",
                "Answer_score":0,
                "Answer_body":"AutoML doesn't currently support CNNs publicly, it's on our roadmap and it will come with optimizations across different parameters, so stay tuned. Hope this helps.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Is there a way to edit skipped images?",
        "Question_creation_time":1608134707420,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/200882\/is-there-a-way-to-edit-skipped-images.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"My team is using the Azure data labeling tool and in our current workflow, we sometimes skip an annotation because there is nothing to annotate.\n(We are missing global tags btw!)\n\nIs there a way to unskip an image? I've been looking at the storage account of the ML instance, but found nothing.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-17T03:56:03.387Z",
                "Answer_score":0,
                "Answer_body":"Thanks for reaching out. No, you'll have to create a new labeling project to label skipped tasks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-12-18T10:56:23.11Z",
                "Answer_score":0,
                "Answer_body":"I found 1 way to unskip images.\n\nYou have to pause the labeling task. Go to Details -> Label classes -> Add labels, then create a new label and select \"Start over, keep all labels\".\n\nThis'll have you keep all your work and the chance to relabel skipped images.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"I have been searching the documentation and cannot find this answer. Is every module in the Azure ML designer available in the Python SDK that lists the pipelines created and trigger with script",
        "Question_creation_time":1609736281147,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/217362\/i-have-been-searching-the-documentation-and-cannot.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":1,
        "Question_body":"I have an Azure ML pipeline created with designer utilities from the portal. I want to schedule the retraining by changing the input folder from the python script and try to automate it.\n\nI have searched the documentation and unable to find the answer.plz help",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-04T08:05:38.967Z",
                "Answer_score":1,
                "Answer_body":"Have you searched below document already? It has index (scrollbar) on left side where you can see all modules\n\nhttps:\/\/docs.microsoft.com\/en-us\/python\/api\/overview\/azure\/ml\/?view=azure-ml-py\n\nPlease don't forget to Accept Answer and Up-vote if the response helped -- Vaibhav",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How is Azure ML instance cost calculated?",
        "Question_creation_time":1606732706930,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/180023\/how-is-azure-ml-instance-cost-calculated.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"Hello,\n\nI've created an endpoint for scoring using a modified version of this tutorial: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-existing-model. I used this command for specifying resources: AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=12) and my resource group is \"West EU\". I'd like to know how the cost is calculated. I assume that the requested resources are converted to an instance (is that right?). I have found this useful website calculator but I cannot find which instance I am using.\n\nHow can I retrieve the information? Can I also do it programatically?\n\nMany thanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-30T13:35:11.803Z",
                "Answer_score":0,
                "Answer_body":"@martin-3510 Thanks for the question. On our website all the prices of Azure ML service are displayed and FAQ at the end.\nhttps:\/\/azure.microsoft.com\/en-us\/pricing\/details\/machine-learning\/\nYes, when you deploy your model to ACI with a default environment you can customize the deploy configuration (i.e. the number of cores and amount of memory made available for the deployment) using the AciWebservice.deploy_configuration().",
                "Answer_comment_count":4,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"MLOps using Azure Databricks & Azure ML - question on data prep for model inference and retraining.",
        "Question_creation_time":1607958581913,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/197618\/mlops-using-azure-databricks-amp-azure-ml-question.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":8,
        "Question_score":2,
        "Question_body":"I am using this blog (https:\/\/databricks.com\/blog\/2020\/10\/13\/using-mlops-with-mlflow-and-azure.html) to set-up MLOps using Azure Databricks & Azure ML. As mentioned in the blog, we deploy MLflow model into an Azure ML environment using the built in MLflow deployment capabilities, which is used for inference. A couple of questions -\n1. How and where does the data prep come into picture before inference and how I can integrate that piece.\n2. How to create a re-training workflow for the model?\n\nThanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-15T08:22:17.753Z",
                "Answer_score":0,
                "Answer_body":"@KiranPurushotham-8848 Thanks, using Databricks to build models and track using MLFlow. Then wants to deploy the model using MLFlow->AML service integration and wants to monitor the model. To work around the limitation of MLflow deployment, you can switch to AML deployment but use the model created and registered by MLFlow at AML.\nFirst, add mflow to conda dependencies to be able to use it in your scoring script, then in init method, load the model using mlflow API, for example:\nmodel = mlflow.pytorch.load_model(model_dir)\nYou need to check artifact structure of the mode registered in AML to construct model_dir correctly because it was created using MLFlow API.\n\nYou may implement ML Ops with a hybrid setup:\nCloud Part:\n\u2022 Azure DevOps can orchestrate Azure ML Service for MLOps practices.\n\u2022 Azure ML Service can be used to training and orchestrating model development, an MLOps manual in link.\n\nOn Prems:\n\u2022 We can train models using data & CPU power on local, on prems.\n\u2022 We can run Azure DevOps pipelines on prems with the Azure DevOps Server running on an On Prems Hardware.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Split Datasets on Auto ML",
        "Question_creation_time":1609436368370,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/215623\/split-datasets-on-auto-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Hi! On Azure AutoML with the UI there is no way to split our dataset automatically between train\/test sets. This is crucial and the docs don't reference it. How can we do it? Can we fix the docs?\n\nAlso, there is no clear way to use the Explainability runs with forecast models with the No-Code solution, which is crucial too! And how to evaluate our models in a final set to check overfitting.\n\nFinally, being able to check the learning curves would be useful too!",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-01-01T08:06:04.397Z",
                "Answer_score":0,
                "Answer_body":"In the UI, there is the option to set how the data is split under \"View additional configuration settings\" on the Task Type and Settings step of running an AutoML experiment. By default, it's based on the number of example cases in the dataset - if there are more than 20,000 rows, it will use 10% of the data for test, and for smaller datasets, cross-validation is used (with 10 folds for small datasets, and three folds for 1k - 20k rows). If you use the additional configuration settings, you can customize these settings to the percentage to use for train\/test, or the number of folds.\n\nThe technical details of the options are here: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-cross-validation-data-splits - while this is targeted at the code-based interface, the details are the same for both.\n\nThe Explainability features are available in the Experiments tab, along with the list of models tested. There's a few more clicks to get there (under Models, click on the model you're interested in, then choose \"Explain model\" - after around 15 mins, the explanation will be available).\n\nThe UI is great - some of the features are more hidden than others, but Microsoft are doing a great job of building new features in over time",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Creating a New linked service (Azure Machine Learning)",
        "Question_creation_time":1608828206490,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/210152\/creating-a-new-linked-service-azure-machine-learni.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I am getting this below error\n\nRequest sent to Azure ML Service for operation 'validateWorkspace' failed with http status code 'Forbidden'. Error message from Azure ML Service: '{\"error\":{\"code\":\"AuthorizationFailed\",\"message\":\"The client 'f7029fe4-3c72-4258-9195-d4e8a64f7c62' with object id 'f7029fe4-3c72-4258-9195-d4e8a64f7c62' does not have authorization to perform action 'Microsoft.MachineLearningServices\/workspaces\/read' over scope '\/subscriptions\/f9f0926a-ab30-492e-8951-e0b88e6da187\/resourceGroups\/machinelearning_rg\/providers\/Microsoft.MachineLearningServices\/workspaces\/ml_workspace' or the scope is invalid. If access was recently granted, please refresh your credentials.\"}}'. Activity ID: 81e99656-f46a-4375-a7de-6b4fe925c5d5.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-28T07:06:23.097Z",
                "Answer_score":0,
                "Answer_body":"@Bhakti-3239 Thanks for the question. Can you please add more details about the steps that you performed or doc that you are following. Also If you are using VNET, is it a part of the same VNet that the AML WS is linked to.\nCould you possibly open up this workspace then go to Access Control (IAM) on the left panel, and enter your name in the Check Access search bar and screenshot the result?\n\nIf you are with being on multiple tenants, The solution was to create service connections scoped to the specific machine learning workspace.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Why my testing always failed in Custom Speech?",
        "Question_creation_time":1608793221783,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/209520\/why-my-testing-always-failed-in-custom-speech.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Model path for a model folder that has json file and weights.",
        "Question_creation_time":1608489600887,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/204868\/model-path-for-a-model-folder-that-has-json-file-a.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"I am trying to create a score.py file for model deployment. In the folder where the model is present, there are two files present. One is the JSON model file another is a .h5 file which has weights of the model. how do I configure the file in this case in the init function of the score.py file?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-21T10:34:00.973Z",
                "Answer_score":0,
                "Answer_body":"@SHUBHAMJAIN01670271019016-8084 For the above scenario you need to save the model as a single file HDF5 file and then register the model using model.register() to register the model with the workspace and load the model in the scoring script using load_model.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"different results in clustering",
        "Question_creation_time":1608744570720,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/209102\/different-results-in-clustering.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"One of the disadvantage of clustering is the result can be different, because it randomly selects the initial mean point. It should impact on the time to take complete the clustering, but how it effects on the result?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-24T14:58:06.333Z",
                "Answer_score":0,
                "Answer_body":"@SanniddhaChakrabarti-9451 Thanks, You can use silhouette clustering to find out and validate the optimal number of cluster .\nReference \u2013 sklearn , wiki\n\nrunning a cluster elbow analysis. This is a method that worked well for me for example 1M rows and 5 features (computation time of about 10-15 seconds)\n\nhttps:\/\/www.geeksforgeeks.org\/elbow-method-for-optimal-value-of-k-in-kmeans\/",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"advantage of neural network",
        "Question_creation_time":1608746288657,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/208999\/advantage-of-neural-network.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"One advantage of neural network is it can take thousands of attributes. But we can take thousands of attributes in any algorithm. So, why it is the advantage of neural network only, why not for other algorithms?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-24T13:28:02.22Z",
                "Answer_score":0,
                "Answer_body":"@SanniddhaChakrabarti-9451 Thanks, You will get much better performance when using \u201cDNN \u201d when compared with the other algorithms.\n\nNeural networks are a series of algorithms that mimic the operations of a human brain to recognize relationships between vast amounts of data. Spark is best for larger data loads, MLS scale out is best for smaller data sets.\n\nNeural networks: https:\/\/www.youtube.com\/watch?v=aircAruvnKk",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"regression model",
        "Question_creation_time":1608745621877,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/209043\/regression-model.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Why we can't draw line (like jig jag line) which connect all the data points, in case of regression. Why we draw straight line?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-24T13:58:51.993Z",
                "Answer_score":0,
                "Answer_body":"@SanniddhaChakrabarti-9451 Thanks, vector valued regression i.e. to treat the dependent variables as a vector.\nAnother approach is multi-task learning which means that you treat each dependent variable as a task but you learn the two tasks jointly together. In many cases this outperforms learning the tasks separately.\n\nPlease follow the Regression.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Advantage of clustering algorithm",
        "Question_creation_time":1608719822847,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/208687\/advantage-of-clustering-algorithm.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"We don't need the name of attributes in clustering, so, if I do not know my attribute names how can I understand that which data should I enter and also if I do not know the name of the attributes how can I give the axis name of the plotted graph? If it is the advantage of clustering algorithm, then why it is not the advantage of other algorithms, because if we do not know the name of the attributes we can create our models because if we have attribute values that is enough, but why we need attribute names too in other algorithms?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-23T16:35:59.897Z",
                "Answer_score":0,
                "Answer_body":"@SanniddhaChakrabarti-9451 Thanks, If the products data is not already labeled and ready for training, you can start with a clustering problem.\nOnce you identify those clusters, a Domain Expert can review those clusters and try to set a name for each (the Categories\/classes).\nThen, all the data can be labeled according to those new categories\/classes and finally train a model.\n\nFrom there, with a trained model, you could \u201cpredict\u201d what category\/class a product should be assigned based on its product\u2019s name and description.\n\n\u2022 For the clustering problem you need to directly use a framework such as Scikit-Learn (or even ML.NET in C#).\n\u2022 Defining a category\/class name for each identified cluster needs to be done manually by a Domain Expert.\n\u2022 Labeling the data could be semi-automated with a custom program, based on the multiple clusters defined, it would label each row with a new class-caterogy-name defined for each of the identified clusters.\n\u2022 For the multi-class classification model training, you can use Azure Automated ML as the easiest approach.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Types of Regression Algorithm",
        "Question_creation_time":1608719172483,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/208685\/types-of-regression-algorithm.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"What are the types of Regression algorithm? Are there any kinds of regression called \"non-linear regression\"?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-24T13:50:48.27Z",
                "Answer_score":0,
                "Answer_body":"@SanniddhaChakrabarti-9451 Please follow the below document for Regression.\nhttps:\/\/www.analyticsvidhya.com\/blog\/2015\/08\/comprehensive-guide-regression\/#:~:text=Regression%20analysis%20is%20a%20form,effect%20relationship%20between%20the%20variables.\n\nTypes of Regressions:\nLinear Regression\nLogistic Regression\nPolynomial Regression\nStepwise Regression\nRidge Regression\nLasso Regression\nElasticNet Regression",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Advantage of decession tree",
        "Question_creation_time":1608720679863,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/208727\/advantage-of-decession-tree.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"One of the advantage of the decision trees is that it ignore outliers. But how outliers come in the sense in case of decision trees. Because decision trees use a set of data like humidity, month, etc. It not uses the data like temperature, population, distance, etc. In this example how outliers can happen ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-23T16:27:15.617Z",
                "Answer_score":0,
                "Answer_body":"@SanniddhaChakrabarti-9451 Thanks, there are plenty of good resources online, presented as some guidelines like this one: https:\/\/towardsdatascience.com\/how-to-tune-a-decision-tree-f03721801680",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Experiment creates local compute target, but shouldn't.",
        "Question_creation_time":1608483356530,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/204932\/experiment-creates-local-compute-target-but-should.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"I'm new to Azure and following a course on Udacity. In one of the assignments I need to create a grid search using Hyperdrive, and that part works fine. It runs and I get the results. Every time it attaches my compute target as it should but it also creates a local compute target which keeps running after all the runs have finished. The code is run in Jupyter and the local compute target gets created when I run my first block of code:\n\n from azureml.core import Workspace, Experiment\n    \n ws = Workspace.get(name=\"Michaels_test1\")\n exp = Experiment(workspace=ws, name=\"udacity-pipeline\")\n    \n print('Workspace name: ' + ws.name, \n       'Azure region: ' + ws.location, \n       'Subscription id: ' + ws.subscription_id, \n       'Resource group: ' + ws.resource_group, sep = '\\n')\n    \n run = exp.start_logging()\n\n\n\n\nAs far as I know it shouldn't create a local compute target and it also prevents me from running the rest of my jupytercode because I waits for the experiment to finish, which it never does because the local compute target keeps running.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How to get Azure Machine Learning Service Workspace details based on Logged in User",
        "Question_creation_time":1608547741557,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/205737\/how-to-get-azure-machine-learning-service-workspac.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Hi there,\n\nThis document page https:\/\/docs.microsoft.com\/en-us\/rest\/api\/azureml\/workspacesandcomputes\/workspaces page describes how we can retrieve (Get function) Workspace details based on the subscription.\n\nI am interested to get similar Workspace details based on the logged user. Please let me know how I can achieve it.\n\nThanks,\nHamsini Sharma",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Importing Libraries in Azure ML Designer",
        "Question_creation_time":1608525858523,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/205209\/importing-libraries-in-azure-ml-designer.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"Is it possible to Install and import libraries in Azure ML designer? Because i dont see kernal available in designer like the notebook.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-21T12:31:18.797Z",
                "Answer_score":0,
                "Answer_body":"@SrinivasanG-1471 Thanks, Please check this document: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-model-designer? Basically you can register a trained model in Designer bring it out with SDK\/CLI to deploy it.\n\nWe are developing a custom module experience which you can bring your own algo\/logic (including drift) as designer modules for reuse.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to add multiple csv's as .zip file new Azure Machine Learning Designer (Non-Classic)",
        "Question_creation_time":1608479520287,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/204887\/how-to-add-multiple-csv39s-as-zip-file-new-azure-m.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"In classic mode there was option of adding multiple csv files zipped into a folder and uploaded into the Azure ML studio (classic). I want to achieve the same in the new Azure Machine Learning designer (non-classic) but I don't see the option of upload .zip file.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-21T08:35:52.17Z",
                "Answer_score":0,
                "Answer_body":"@SoumyakantSahoo-4033 I believe you are referring to this feature of the classic version where the ability to unzip multiple csv files is available for a zip file.\nThis module in the designer though is not ported and the recommendation to import multiple files if they are in a similar format is to use the import data module with the files on your datastore where the tabular data can be imported with the following conditions:\n\nTo include all data files in the folder, you need to input folder_name\/** for Path.\n\n\nAll data files must be encoded in unicode-8.\n\n\nAll data files must have the same column numbers and column names.\n\n\nThe result of importing multiple data files is concatenating all rows from multiple files in order.\n\nAfter the above module runs successfully you can use the data manipulation modules to further process the data and train your model.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error: Incremental refresh of labeling project",
        "Question_creation_time":1607952473720,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/197548\/error-incremental-refresh-of-labeling-project.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":7,
        "Question_score":2,
        "Question_body":"https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-labeling-projects#--configure-incremental-refresh\n\nStates incremental refresh picks up new data every 24h.\nTested this on a cat\/dog dataset.\n\nFirst added 3 pictures of dogs in a dataset. Created classification labeling project, with incremental refresh enabled. Labeled 2 images. Updated dataset with 3 images of cats. confirmed updated dataset version ID is used on labeling project. However, images of cats are not included in the labeling project.\n\nAny help?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-18T20:57:48.347Z",
                "Answer_score":0,
                "Answer_body":"I wasn't able to reproduce this issue. After enabling incremental refresh, I uploaded new images to my connected blob storage, and the images were added to my project in less than 24hrs. Currently, there is no way to specify frequency but I've informed the product team of your request. If you continue to have issues with incremental refresh, it may be best to submit a support request to troubleshoot further since we're not able to reproduce this issue. Hope this helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Compute Clusters in Azure ML Notebook",
        "Question_creation_time":1608276696563,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/203139\/compute-clusters-in-azure-ml-notebook.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I created a compute cluster in Azure ML and I am able to see it in designer but not in the notebook. Can someone let me know the reason for this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-18T12:18:31.593Z",
                "Answer_score":0,
                "Answer_body":"@SrinivasanG-1471 This is an expected behavior while using notebooks on Azure ML portal. Compute clusters are used to train models and run experiments using the designer or pipelines. These cannot be used with notebooks.\nNotebooks are integrated to run on an compute instance which was previously termed as notebook VM. You can start\/stop the compute instance while using your notebook from Azure ML portal.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Unable to run a basic pipeline that summarizes the dataset.",
        "Question_creation_time":1608270119370,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/203047\/unable-to-run-a-basic-pipeline-that-summarizes-the.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I am trying to run some basic pipeline in Azure ML Workspace using the Trial account.\n\nJust use an example data and summarize the data.\n\nBut, when I run the pipeline, it stays forever in \"Not Started\" status despite of assigning descent Compute resources and making sure that Compute resources are running.\nAfter a while the run eventually fails with following error...\n\nUserError: Number of retries is exceeded the max count: 10, last error: Failure in GetDataStoreDto while calling service DataStoreClient; HttpMethod: GET; Response StatusCode: NotFound; Exception type: Microsoft.RelInfra.Extensions.HttpRequestDetailException\n\nWhat does it mean?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-18T06:21:07.67Z",
                "Answer_score":0,
                "Answer_body":"Nevermind. It worked in a new ML Workspace.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Migrate models from Azure Machine Learning Studio (classic) v1 to Azure Machine Learning Studio v2",
        "Question_creation_time":1601619807160,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/114944\/migrate-models-from-azure-machine-learning-studio.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Is it possible to migrate models created in Azure ML studio (classic) to Azure ML studio v2?\n\nCan I move my models from v1 to v2 in an easy way?\n\nThanks in advance!",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-11T17:55:17.847Z",
                "Answer_score":0,
                "Answer_body":"Hello Helena,\n\nThanks for your waiting. There is not a tool for auto-migration from V1 to V2 for now and future since the architecture of studio(classic) and machine learning studio is totally different. So I don't think it's easy to migrate. But we will have plan for migration in next few month, there should be a way to migrate from studio(classic) to machine learning studio with effort.\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2020-12-17T21:22:58.98Z",
                "Answer_score":0,
                "Answer_body":"Is there any update on migration efforts?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Can't run a basic model in Azure ML",
        "Question_creation_time":1607553548183,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/192735\/can39t-run-a-basic-model-in-azure-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Hello,\n\nI'm new to Azure Machine Learning, so I'm trying some tutorials on a free trial account.\n\nNone of the tutorials I've followed is running on my account, not even the most basic ones.\n\nFor example, the \"Flight Delay Prediction\" is running for several hours and then frustratingly it fails....\n\nThis is how the designer looks like:\n\n\n\n\n\n\nDoes this make sense?\nCan anyone help?\n\nThanks in advance!",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-10T07:45:59.39Z",
                "Answer_score":0,
                "Answer_body":"@nunonogueira From the screen shot it looks like your experiment is running with some modules run queued. Depending on the compute resources you have chosen the run time might vary and with a free trial account a lower compute power will slow down the run time. I have tried the same experiment with a STANDARD_DS2_V2 type with scaling option from 0-4 resources in the cluster and the run completed in around 23 minutes where most the time went to setup the compute since I do not have any running compute to run the experiment directly. You can try a similar setup with a higher compute and check if it runs faster.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How do I get Power BI to see Azure ML models",
        "Question_creation_time":1607979456767,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/198154\/how-do-i-get-power-bi-to-see-azure-ml-models.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I'm following these tutorials:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-power-bi-designer-model\nhttps:\/\/docs.microsoft.com\/en-us\/power-bi\/connect-data\/service-aml-integrate?context=azure\/machine-learning\/context\/ml-context\n\nI've setup the pipelines & endpoint. Attached is a screenshot of the endpoint.\n\nFor tutorial 2, on the Power BI Desktop, when I click Transform data to open the Power Query Editor, then click Azure Machine Learning, I originally got the prompt to login with my email (which I used my personal gmail for, the one that owns the Azure ML workspace). I keep seeing that no models are available, but I've followed the steps to tutorials & expect since the endpoint was successfully deployed, I can see the model.\n\nCan you help me understand what's missing please?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-14T20:59:11.633Z",
                "Answer_score":0,
                "Answer_body":"Power Bi is not currently supported here on QnA. They're actively answering Power Bi questions in dedicated forums here.\nhttps:\/\/community.powerbi.com\/\n\n--please don't forget to Accept as answer if the reply is helpful--",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-12-15T07:10:30.307Z",
                "Answer_score":0,
                "Answer_body":"@JustinNgai-3079 I have tried this scenario and it seems like a healthy endpoint is listed when we login to AzureML from powerbi desktop. From the screen shots your endpoint looks healthy but your powerbi AzureML login does not seem to list them, could you try to re-login to AzureML from your powerbi desktop. I found that we can do so by following the steps listed below:\n\nI hope your workspace has required permissions and this can pull your endpoint details which can be used with powerbi.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Register a dataset as model in azure",
        "Question_creation_time":1607946981470,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/197584\/register-a-dataset-as-model-in-azure.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"How is it possible to register a dataset or blob container directly as a model?\n\nAt the moment I have built a pipeline that outputs my trained models and registers them as datasets. I want to perform inference by deploying the models to for example AKS.\n\nAt the moment it appears the only way to register a model is by first downloading the dataset. Note I cannot register the model based on the runID because my model output is saved directly to blob storage through OutputFileDatasetConfig.\n\nThe motivation here is to avoid having to download and then upload large models.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-15T08:22:28.227Z",
                "Answer_score":0,
                "Answer_body":"@ReubenDenleyZotzWilson-3139 You can try to register your model\/file which is in the output directory of the run by using the azure ML cli command? Once you setup the configuration of your Azure account or workspace you can simply use this command with the run id and path of the output to register the model.\n\nExample:\naz ml model register -n sklearn_mnist --asset-path outputs\/sklearn_mnist_model.pkl --experiment-name myexperiment --run-id myrunid --tag area=mnist",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML studio (Error 0009 Exception occurs when the Azure storage account name or container name is specified incorrectly)",
        "Question_creation_time":1607923602410,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/197005\/azure-ml-studio-error-0009-exception-occurs-when-t.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Hi Team,\n\nI have tried to connect Azure blob and Azure ML studio but am facing following error (Error 0009 Exception occurs when the Azure storage account name or container name is specified incorrectly).\n\n\n\n\nTried out some solution as suggested by Microsoft . However we were facing the same issue again.\n\nCould you please help me on this.\n\nThanks,\nCharles",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-14T09:54:12.25Z",
                "Answer_score":0,
                "Answer_body":"@CharlesAnthony-5220 I believe you are referring to the solutions\/causes mentioned here in the documentation of classic studio?\nHave you tried the import data wizard from the import data module if the above error was seen while using the import data module?\n\nYou can test the basic connection to your container and then provide path to your datafile in the next steps.\n\nIf there is an access\/permission issue you can correct it from the storage explorer and then try again.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning - SQL Server",
        "Question_creation_time":1607409750170,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/190067\/azure-machine-learning-sql-server.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hello,\n\nI have a created a VM and installed SQL Sever in it and I want to use that data in Azure Machine learning. Is there a way to bring data from SQL server installed on VM to the Azure Machine learning? Please note VM is in a different Vnet (VPN gateway)",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-08T07:25:04.303Z",
                "Answer_score":0,
                "Answer_body":"Hi @SrinivasanG-1471,\n\nYou can try to use below options to move data to Azure SQL databases for Azure Machine Learning.\n\n1.Export to Flat File\n2. Database back up and restore\n3. Azure Data Factory\n\nPlease refer to Move data to an Azure SQL Database for Azure Machine Learning to get more information.\n\nBest regards,\nCathy\n\n\nIf the response is helpful, please click \"Accept Answer\" and upvote it.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Problem when launching a child run on AzureML",
        "Question_creation_time":1602870917083,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/129324\/problem-when-launching-a-child-run-on-azureml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":3,
        "Question_score":1,
        "Question_body":"Got a error when trying to launch child runs from a pipeline step.\n\nIn pipeline step I have this:\n\n import argparse\n from azureml.core import Run, ScriptRunConfig\n from azureml.core.model import Model\n from azureml.core.environment import Environment\n    \n run = Run.get_context()\n compute_target = run.experiment.workspace.compute_targets[run.get_details()['target']]\n     \n parser = argparse.ArgumentParser(\"args\")\n parser.add_argument(\"--train_path\", type=str, help=\"train_path\")\n parser.add_argument(\"--test_path\", type=str, help=\"test_path\")\n args = parser.parse_args()\n    \n child_config_xgboost = ScriptRunConfig(\n     source_directory=\".\",\n     script='xgboost_model.py',\n     arguments=['--train_path', args.train_path, \"--test_path\", args.test_path],\n     compute_target=compute_target,\n     environment=run.get_environment()\n )\n    \n child_xgboost=run.submit_child(child_config_xgboost)\n child_xgboost.wait_for_completion()\n\n\n\nI receive this error:\n\n Traceback (most recent call last):\n   File \"train.py\", line 7, in <module>\n     compute_target = run.experiment.workspace.compute_targets[run.get_details()['target']]\n   File \"\/azureml-envs\/azureml_912ebce86aa851a4f789bc2c01e320a3\/lib\/python3.6\/site-packages\/azureml\/core\/workspace.py\", line 1009, in compute_targets\n     compute_target.name: compute_target for compute_target in ComputeTarget.list(self)}\n   File \"\/azureml-envs\/azureml_912ebce86aa851a4f789bc2c01e320a3\/lib\/python3.6\/site-packages\/azureml\/core\/compute\/compute.py\", line 535, in list\n     env_obj = child.deserialize(workspace, env)\n   File \"\/azureml-envs\/azureml_912ebce86aa851a4f789bc2c01e320a3\/lib\/python3.6\/site-packages\/azureml\/core\/compute\/computeinstance.py\", line 638, in deserialize\n     target._initialize(workspace, object_dict)\n   File \"\/azureml-envs\/azureml_912ebce86aa851a4f789bc2c01e320a3\/lib\/python3.6\/site-packages\/azureml\/core\/compute\/computeinstance.py\", line 130, in _initialize\n     status.created_by_user_org)\n   File \"\/azureml-envs\/azureml_912ebce86aa851a4f789bc2c01e320a3\/lib\/python3.6\/site-packages\/azureml\/core\/compute\/computeinstance.py\", line 947, in _get_user_display_name\n     headers = {\"Authorization\": \"Bearer \" + workspace._auth._get_graph_token()}\n   File \"\/azureml-envs\/azureml_912ebce86aa851a4f789bc2c01e320a3\/lib\/python3.6\/site-packages\/azureml\/core\/authentication.py\", line 1455, in _get_graph_token\n     raise AuthenticationException(\"AzureMLTokenAuthentication._get_graph_token \"\n UserScriptException: UserScriptException:\n  Message: AzureMLTokenAuthentication._get_graph_token not yet supported.\n  InnerException AuthenticationException:\n  Message: AzureMLTokenAuthentication._get_graph_token not yet supported.\n  InnerException None\n  ErrorResponse \n {\n     \"error\": {\n         \"code\": \"UserError\",\n         \"inner_error\": {\n             \"code\": \"Authentication\"\n         },\n         \"message\": \"AzureMLTokenAuthentication._get_graph_token not yet supported.\"\n     }\n }\n  ErrorResponse \n {\n     \"error\": {\n         \"code\": \"UserError\",\n         \"message\": \"AzureMLTokenAuthentication._get_graph_token not yet supported.\"\n     }\n }\n\n\n\nHow can I launch a child run using a ScriptRunConfig with the same environment and compute target as the parent run?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-19T13:25:39.42Z",
                "Answer_score":1,
                "Answer_body":"@MARCOPINHEIRO-3774 Thanks, Find more details here for secret and for submit child..\n\n from azureml.core import Experiment, Run\n    \n run = Run.get_context()\n secret_value = run.get_secret(name=\"mysecret\")\n\n\n\n\nHere is the example using ScriptRunConfig(), you can access the key vault when you use ScriptRunConfig().\n\nAlso, Here are the details to create an environment and configure and run training runs.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Data Factory : How to pass DataPath as a parameter to Azure ML Pipeline activity?",
        "Question_creation_time":1599771191990,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/91785\/azure-data-factory-how-to-pass-datapath-as-a-param.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"Hello All,\n\nHow to pass a Datapath as a parameter in Azure ML Pipeline activity?\n\nMore details here : Have opened an issue here : https:\/\/github.com\/Azure\/Azure-DataFactory\/issues\/216\n\n\n\n\n\nThanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-25T08:43:19.257Z",
                "Answer_score":1,
                "Answer_body":"Thanks @SriramNarayanan-6939 for your patience!\n\nI discussed with the Product team and they confirmed that there is no datatype supported for \"DataPath\" parameter today in Azure Data Factory(ADF). However, there is a feature already raised for the same and work is in progress for it.\n\nI would recommend you also to submit an idea in feedback forum. The ideas in this forum are closely monitored by data factory product team and will prioritize implementing them in future releases.\n\nSorry for the inconvenience!",
                "Answer_comment_count":8,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Why does Azure AutoML TargetLag featurization use so much memory? Is this a bug?",
        "Question_creation_time":1607045489347,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/185758\/why-does-azure-automl-targetlag-featurization-use.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I am trying to train a time series forecast model using Azure AutoML. My data set has three series each with two years of hourly data. The whole csv file of training data is less than 2MB. My compute cluster is using D2V2 machines with 7GB of ram. If I configure the training with three target lags, the training run fails to get under way. It seems like there may be a bug. Can someone take a look at the stack trace below and confirm?\n\n\n\n\nThis is the error in the log:\n\n 2020-12-04 00:06:04,486|azureml.WorkerPool|ERROR|<class '__main__.UserScriptException'>: UserScriptException:\n     Message: There is not enough memory on the machine to do the requested operation. Please try running the experiment on a VM with higher memory.\n     InnerException ResourceException:\n     Message: There is not enough memory on the machine to do the requested operation. Please try running the experiment on a VM with higher memory.\n     InnerException: MemoryError: cannot allocate memory for array\n     ErrorResponse \n {\n     \"error\": {\n         \"code\": \"UserError\",\n         \"message\": \"There is not enough memory on the machine to do the requested operation. Please try running the experiment on a VM with higher memory.\",\n         \"details_uri\": \"https:\/\/aka.ms\/azurevmsizes\",\n         \"target\": \"Skipping setup\/featurization run split. Beginning full featurization logic.\",\n         \"inner_error\": {\n             \"code\": \"ResourceExhausted\",\n             \"inner_error\": {\n                 \"code\": \"Memory\"\n             }\n         },\n         \"reference_code\": \"791a2bd3-4812-407f-91f7-1f8a5a0b0f5a\"\n     }\n }\n\n\n\nI found the error stack trace in another log:\n\n raceback:\n   File \"telemetry_activity_logger.py\", line 57, in _log_activity\n     yield\n   File \"utilities.py\", line 177, in _transform_and_validate_input_data\n     feature_sweeping_config=feature_sweeping_config,\n   File \"contextlib.py\", line 99, in __exit__\n     self.gen.throw(type, value, traceback)\n   File \"telemetry_activity_logger.py\", line 81, in _log_activity\n     raise e.with_traceback(e.__traceback__)\n   File \"telemetry_activity_logger.py\", line 57, in _log_activity\n     yield\n   File \"utilities.py\", line 177, in _transform_and_validate_input_data\n     feature_sweeping_config=feature_sweeping_config,\n   File \"data_transformation.py\", line 529, in complete_featurization\n     fault_verifier=verifier\n   File \"data_transformation.py\", line 1048, in _get_ts_transformer_x\n     x_transform = tst.fit_transform(x, y)\n   File \"logging_utilities.py\", line 300, in debug_log_wrapped\n     r = f(self, *args, **kwargs)\n   File \"timeseries_transformer.py\", line 1475, in fit_transform\n     transformed = self.transform(X, y)\n   File \"logging_utilities.py\", line 300, in debug_log_wrapped\n     r = f(self, *args, **kwargs)\n   File \"timeseries_transformer.py\", line 1374, in transform\n     transformed_data = self._fit_columns_order()\n   File \"timeseries_transformer.py\", line 1260, in _fit_columns_order\n     self._known_train_part, self._known_train_part.ts_value.values)\n   File \"forecasting_pipeline.py\", line 390, in fit_transform\n     X, y, **fit_params)\n   File \"forecasting_pipeline.py\", line 284, in execute_pipeline_op\n     Xt, fit_params = self.__execute_pipeline__preprocess_fit(X, y, **fit_params)\n   File \"forecasting_pipeline.py\", line 320, in __execute_pipeline__preprocess_fit\n     return self._pipeline._fit(X, y, **fit_params)\n   File \"pipeline.py\", line 315, in _fit\n     **fit_params_steps[name])\n   File \"memory.py\", line 355, in __call__\n     return self.func(*args, **kwargs)\n   File \"pipeline.py\", line 728, in _fit_transform_one\n     res = transformer.fit_transform(X, y, **fit_params)\n   File \"logging_utilities.py\", line 300, in debug_log_wrapped\n     r = f(self, *args, **kwargs)\n   File \"lag_lead_operator.py\", line 904, in fit_transform\n     rv = super(LagLeadOperator, self).fit_transform(X, y, **fit_params)  # type: TimeSeriesDataFrame\n   File \"base.py\", line 574, in fit_transform\n     return self.fit(X, y, **fit_params).transform(X)\n   File \"logging_utilities.py\", line 300, in debug_log_wrapped\n     r = f(self, *args, **kwargs)\n   File \"lag_lead_operator.py\", line 882, in transform\n     left_index=True, right_index=True)\n   File \"time_series_data_frame.py\", line 2389, in merge\n     copy=copy, indicator=indicator)\n   File \"frame.py\", line 7349, in merge\n     validate=validate,\n   File \"merge.py\", line 83, in merge\n     return op.get_result()\n   File \"merge.py\", line 642, in get_result\n     join_index, left_indexer, right_indexer = self._get_join_info()\n   File \"merge.py\", line 859, in _get_join_info\n     (left_indexer, right_indexer) = self._get_join_indexers()\n   File \"merge.py\", line 838, in _get_join_indexers\n     self.left_join_keys, self.right_join_keys, sort=self.sort, how=self.how\n   File \"merge.py\", line 1312, in _get_join_indexers\n     lkey, rkey, count = fkeys(lkey, rkey)\n   File \"merge.py\", line 1902, in _factorize_keys\n     llab = rizer.factorize(lk)\n   File \"hashtable.pyx\", line 122, in pandas._libs.hashtable.Int64Factorizer.factorize\n   File \"hashtable_class_helper.pxi\", line 1222, in pandas._libs.hashtable.Int64HashTable.get_labels\n   File \"hashtable_class_helper.pxi\", line 1148, in pandas._libs.hashtable.Int64HashTable._unique\n   File \"hashtable_class_helper.pxi\", line 201, in pandas._libs.hashtable.Int64Vector.resize",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"how to fail an Azure ML run?",
        "Question_creation_time":1607609097120,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/193802\/how-to-fail-an-azure-ml-run.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":6,
        "Question_score":1,
        "Question_body":"We are using Azure ML for large tests to facilitate testing our code on CUDA in an automated manner. Things work mostly well, but one thing we cannot figure out is how to fail a job such that the job failure\n1. shows in the UI as Failed (see snapshot),\n2. gets propagated back to the submitting client (our testing code) such that we can fail the test when the Run has reached failed state.\n\n\n\n\nHere's what we tried:\n- Exit the run process with a non-zero status.\n- Use the Run instance to send the non-zero exit code and a reason from the VM.\n- Try to detect Failed state or reason\n\nWhen we call the following method:\ndef report_error(returncode: int):\nfrom azureml.core.run import Run\nrun = Run.get_context(allow_offline=False)\nprint(f\"Failing the run with return code={returncode}\")\nrun.fail(f\"A process returned a non-zero status code {returncode}\", error_code=returncode)\nexit(returncode)\n\nWe can see the exit code in the UI at the top of a failed run, but the run is still marked as Completed.\nAs a result, we are unable to determine that the job failed from the submitting client.\nAfter:\nrun.wait_for_completion(show_output=True,\nraise_on_error=True)\nWe tried:\nif result['status'] != 'Completed' or (result['details'] is not None and\n'A process returned a non-zero status code' in result['details']):\nrun.fail(error_details=result['details'], error_code=1)\nexit(1)\nYet, the return value of this process, communicated to the test client is zero.\n\nIs this a timing issue in obtaining the result details?\n\nWhat could we do to make sure such jobs actually show as Failed in the UI?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How to use AzureMLDataset",
        "Question_creation_time":1607676200880,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/194940\/how-to-use-azuremldataset.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"Hi,\n\nI have used the data labeling system within Azure Machine Learning studio to label a dataset of images.\nThen the output of the labeling system is a new dataset that can be found in the \"Dataset\" section of the designer in ML studio.\n\nThe problem is that this new dataset module, that can be dragged and dropped in the pipeline, has datatype \"AzureMLDataset\" (or datasoruce type \"amldataset\"), which then I cannot connect to any other module in the pipeline because there is no module which accepts as input something with datatype \"AzureMLDataset\" (or with datasource type \"amldataset\").\n\nI have seen that it is possible to consume the dataset using python, but I would like to use Azure ML studio because it is more convenient to the system I am working in.\n\nHow can I use the AzureMLDataset output module inside ML studio?\n\nThank you in advance!",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-11T10:35:45.227Z",
                "Answer_score":1,
                "Answer_body":"@MatteoPocchiari-8551 Yes, the azure ml dataset which is registered from your labels after exporting it cannot be used directly in the designer because all the modules are using dataframe ports as input to their respective modules. You can however follow these steps to convert the labeled datasets to pandas dataframe and re-upload the downloaded file as a dataset which can be used in the studio with the correct format.\n\n@LuZhang-4441 Is there any other workaround for this scenario?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Cannot disable Azure Machine Learning Schedule because of 'Provisioning' state",
        "Question_creation_time":1607510860937,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/191829\/cannot-disable-azure-machine-learning-schedule-bec.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"There is one Schedule that we are not able to disable on our Azure Machine Learning workspace:\n\naz ml pipeline disable-schedule --schedule-id SCHEDULE_ID \\\n                                --resource-group RG \\\n                                --workspace-name WN\n\n\n\n\nIt's been returning:\n\n(BadRequest) Cannot update an entity while it's in Provisioning state.\n\n\n\n\nThe status of the schedule is 'Active'.\nWe were able to disable other schedules on the workspace without any issues. Has anyone faced a similar issue?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-10T11:05:48.38Z",
                "Answer_score":0,
                "Answer_body":"@GilH-2940 Thanks for the question. Can you please share the Activity log and if possible please share the full error details. We have forwarded to the product team to check on this. If you want to be unblocked with the effected instances please raise a support request in the azure portal. This will help you to share the details securely and work with an engineer who can provide more insights about the issue that if it can be replicated.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning Workspaces REST API operations",
        "Question_creation_time":1602589232617,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/124740\/azure-machine-learning-workspaces-rest-api-operati.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Hi there,\n\nAs per Azure documentation, Azure Machine Learning Workspaces REST API operations can be listed through below call. Refer documentation: https:\/\/docs.microsoft.com\/en-us\/rest\/api\/azureml\/workspacesandcomputes\/operations\/list\n\nGET https:\/\/management.azure.com\/providers\/Microsoft.MachineLearningServices\/operations?api-version=2019-05-01\n\nWhen I try this call, it gives the REST API operations that one can do on a workspace like\n{\n\"name\": \"Microsoft.MachineLearningServices\/workspaces\/notebooks\/vm\/read\",\n\"display\": {\n\"provider\": \"Machine Learning Services Resource Provider\",\n\"resource\": \"Machine Learning Services Workspace\",\n\"operation\": \"Gets the Notebook VMs for a particular workspace\",\n\"description\": \"Gets the Notebook VMs for a particular workspace\"\n},\n\"origin\": \"user,system\",\n\"properties\": null,\n\"isDataAction\": false\n},\n\nAs per the highlighted text I understand that \"Microsoft.MachineLearningServices\/workspaces\/notebooks\/vm\/read\" can be used when we want to get the notebook VMs a workspace.\n\nI am unable to identify the complete REST API URL for this \"Microsoft.MachineLearningServices\/workspaces\/notebooks\/vm\/read\", so that I can use in my program.\n\nPlease suggest.\n\nThanks,",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-09T05:41:16.537Z",
                "Answer_score":0,
                "Answer_body":"Thanks for reaching out. I believe the List by Workspace operation is what you're looking for. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Model Deployment- POST Body Type",
        "Question_creation_time":1602526641177,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/123960\/azure-ml-model-deployment.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"I had registered a CNN model on Azure ML and would like to have and endpoint API that returns the predictions based on the image it receives and I also would like to send some metadata along the image itself. So, I prefer to POST the data in form-data format. However,The official tutorials mention application-json or binary data only.\nHow can I POST data in form-data format to an API in Azure ML ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-09T05:33:47.45Z",
                "Answer_score":0,
                "Answer_body":"Thanks for reaching out. Currently, the API only supports json or binary data.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Detect and treat local outliers",
        "Question_creation_time":1607084778140,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/186619\/detect-and-treat-local-outliers.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I have built a solution within Azure ML predicting the weight(\"Poids\" below) of our materials production. It happens that some rows have a cost value that is not normal considering the similarity of the values from the other features. This row should be then exluded (replaced with a mean) according to me. How can I do this ?\n\nAs this is not a real outlier in the all dataset but an outlier regarding values of the other fields.\n\nMy predictive model gives the result of 19.000 where visually I would have expected 50.000 which is the correct value....\n\nFT1Fini 20.00 20.00 20.00 20.00\n\nFT2Fini 28.30 28.30 28.30 28.30\n\nPagesTot 592 592 592 600\n\nQteFact 27.120 29.045 29.045 27.973\n\nPoidsKG 48.823 2.260 53.500 52.029\n\nThank you for your hep.\n\nRegards,\n\nMeddi.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-04T18:44:23.903Z",
                "Answer_score":0,
                "Answer_body":"Thanks for reaching out. Try to use Clip Values data transformation to identify and optionally replace data values that are above or below a specified threshold with a mean, a constant, or other substitute value. Hope this helps.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"D365 Demand Forecasting - Can we connect to new Azure ML Service instead of a classic studio service?",
        "Question_creation_time":1606959642257,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/183990\/d365-demand-forecasting-can-we-connect-to-new-azur.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"There is a D365 forecasting option that allows to connect to a azure ml classic studio service. Can we connect from D365 to the new Azure ML Service? I couldnt find any documentation about this, any pointers please.Thanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-04T08:31:11.253Z",
                "Answer_score":0,
                "Answer_body":"@SriramNarayanan-6939 you can deploy a real-time endpoint in Azure Machine Learning designer and get the REST endpoint\/token by following this doc: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Moving resources across the regions",
        "Question_creation_time":1606983526427,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/184565\/moving-resources-across-the-regions.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Hi,\nWe have resource group(RG1) created in Germany region. Resource created are\n1) Vnet\n2) VPN gateway\n3) Disks - HDD\n4) VM (database installed)\n\nWe wanted to use Azure machine learning service to read data from database(present in resource group RG1 in German region). We later found that azure machine learning service is not available in Germany region and in order to create end points for Azure ML service both the networks(vnets of the DB and Azure ML ) should be in the same region.\n\nSo we tried migrating the resource and resource group (RG1) from German region to west Europe by using wizard on the portal. But we got prompted that disk , vnet and vpn gateway cannot be moved to different region ) .\n\nIs there anyway we could move them ? or any alternate solutions ? .Else, we would end up recreating every thing in westeurope which i would like to avoid.\n\nRegards,\nSuman",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-03T08:30:58.243Z",
                "Answer_score":0,
                "Answer_body":"Maybe this is helpful:\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/site-recovery\/azure-to-azure-tutorial-migrate\n\n(If the reply was helpful please don't forget to upvote and\/or accept as answer, thank you)\n\nRegards\nAndreas Baumgarten",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2020-12-03T09:20:21.54Z",
                "Answer_score":1,
                "Answer_body":"@SumanKaranam-2803, There is a process in Azure to move VNET across region using ARM template. But, it is almost kind of recreating the resource with a automated template with desired configuration.\n\nFor VNET:\n\nMethod1: You can use an Azure Resource Manager template to complete the move of the virtual network to another region. You do this by exporting the virtual network to a template, modifying the parameters to match the destination region, and then deploying the template to the new region.\n\nRef Doc : Move an Azure virtual network to another region by using the Azure portal\n\nOR\n\nMethod2: You can use the latest Azure service called \"Azure Resource Mover\" to move VNET's across regions,\n\nRef Doc : Azure Resource Mover\n\nFor VPN gateway: AFAIK, today you can move VPN Gateway across Resource Groups and subscriptions only.\n\nSS:1\n\nNote : If you would like to request\/upvote for this feature use this feedback section for its future availability.\n\nPlease do not forget to \"Accept the answer\" wherever the information provided helps you to help others in the community.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-12-04T09:02:14.08Z",
                "Answer_score":0,
                "Answer_body":"@SumanKaranam-2803,\n\nIf you think your question has been answered, click \"Mark as Answer\" if just helped click \"Vote as helpful\". This can be beneficial to other community members reading this forum thread.\n\n\nBest regards\nSubhash",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to configute WebServiceOutput?",
        "Question_creation_time":1606819526077,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/181635\/how-to-configute-webserviceoutput.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Hi, I trained and deployed a ML model via Auto ML. The result looks like this:\n\"\\\"{\\\\\\\"result\\\\\\\": [\\\\\\\"Test\\\\\\\"]}\\\"\"\n\nOnce I did the same with an endpoint created with the Azure ML Designer my result looks like this:\n\"{\\\"Results\\\": {\\\"WebServiceOutput0\\\": [{\\\"Scored Labels\\\": \\\"Test\\\"}]}}\"\n\n\n\n\nIs there a way to configure the response that it looks similar to the AutoML response?\n\nThanks :)",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-02T12:31:00Z",
                "Answer_score":1,
                "Answer_body":"@27051995 Unfortunately, AutoML and AML Designer currently generates 2 different swagger format automatically, and there is no way to configure the output format. We are working on to address this inconsistency, and the Designer swagger format will be the converged format. Cheers!",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2020-12-02T10:15:50.67Z",
                "Answer_score":0,
                "Answer_body":"@27051995 Does your webservice output module connect to score model module? The default configuration for this module contains an option to append score columns to output. You can try to uncheck this option to check if the column name in the output is removed.\n\n\n\n\nOther option is to name your webservice output module to the required name but this field will be displayed for designer for the output module. The end result might not be exactly the same but you can extract the required result based on the result or Results field instead of following a fixed format parsing.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Training Personalizer",
        "Question_creation_time":1606863751290,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/182318\/training-personalizer.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I am considering using Personalizer for project and have found limited third party metrics for this service. This one article indicates needing TENS of thousands of hits to get good results.\n\nhttps:\/\/medium.com\/@EnefitIT\/we-tested-azure-personalizer-heres-what-you-can-expect-8c5ec074a28e\n\nCan any one provide any other data?\n\nObviously, over time it will get better, but does it have to get to 10K+ to get good?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-02T07:18:51.207Z",
                "Answer_score":0,
                "Answer_body":"@GregorioRojas-6472 The minimum requirements to have an effective recommendation is to have a minimum of ~1k\/day content-related events. Higher rate of events do help you to provide faster and better recommendations. All the requirements are documented in the official documentation page of the service. The samples repo provides some data along with the quickstart's from the documentation to get started. The service now provides an E0 tier or apprentice mode that helps you test the service and gain confidence to move to a higher tier with production level recommendations.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Machine Learning on Prem onebox configuration",
        "Question_creation_time":1606877642097,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/182686\/machine-learning-on-prem-onebox-configuration.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Hi,\n\nI am trying to setup Machine Learning 9.4.7 onebox configuration on windows 2016. When I am trying to configure onebox Admin cli utility got hang up. I tried to open up another window and run az mlserver admin node list. It says webnode is running but not compute node. So I set up compute node and tried to log in az mlserver login.\nIt fails with following error:\n\nAssert that [--mls-endpoint http:\/\/localhost:12800] is correct.\n('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n\nC:\\Program Files (x86)\\Microsoft SDKs\\Azure\\CLI2\\wbin>az mlserver login\nUsername: admin\nPassword:\nAssert that [--mls-endpoint http:\/\/localhost:12800] is correct.\n('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n\nC:\\Program Files (x86)\\Microsoft SDKs\\Azure\\CLI2\\wbin>az mlserver admin node list\n[\n{\n\"node\": \"web\",\n\"pid\": \"4608\",\n\"state\": \"running\"\n},\n{\n\"node\": \"compute\",\n\"pid\": \"6764\",\n\"state\": \"running\"\n}\n]\n\nC:\\Program Files (x86)\\Microsoft SDKs\\Azure\\CLI2\\wbin>\n\nI have also attached stderr log file for web node.44167-stderr.txt",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"I wish to store a variable in R in ML studio to use it for consecutive executions (Web service calls). But since the R script is run from the start, the variable's value resets to default value, that I set. Is there a way to achieve this?",
        "Question_creation_time":1606214692780,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/173691\/i-wish-to-store-a-variable-in-r-in-ml-studio-to-us.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"My Machine learning flow looks something like this:\n\n\n\n\n\n\n\nAnd my R script looks something like this:\n\n if(useAxe){\n    if (condition1) {\n       useAxe <- true\n    }else{\n       useAxe<- false\n }\n\n\n\n\nI want the value of useAxe from the previous execution and update it according to the criteria.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-24T12:23:39.357Z",
                "Answer_score":0,
                "Answer_body":"@SaurabhSadhwani-9510 Variables that are set in the R script or python script will get reset during subsequent calls to the web service as the complete predictive experiment is run when the endpoint is called. As an alternate you can set a web service parameter or export the data using the export data module and write the result to an external database.\n\nAn example of using the web service parameter to output the result to a csv file on blob storage is available in this blog. Some of the parameters and modules might not be in use now since the classic ML studio has a newer version in Machine Learning Designer on the new ML portal ml.azure.com",
                "Answer_comment_count":8,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Automated machine learning (AutoML)",
        "Question_creation_time":1606236131380,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/174091\/automated-machine-learning-automl.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Hi everyone,\n\nI want to find the right model for my code, that's why I would like to use Azure AutoML.\nI'm at the point where I split the data:\nX_train, X_test, y_train, y_test (...)\n\nA vector matrix is created from X_train with TF\/IDF:\ntfidf_vectorizer_matrix = tfidf_vectorizer.fit_transform (X_train).toarray ()\n\nNormally I would now run through my models one by one, which also works.\n\nMy problem is how must automl_config = AutoMLConfig (...) be filled so that I can use TF\/IDF ?\n\nA little sample code would be very helpful.\nPlease need help on this topic.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-25T13:25:23.43Z",
                "Answer_score":0,
                "Answer_body":"@WeinhandlVolkerNMMECM-6517 Thanks for the question. AutoMLConfig has a 'FeaturizationConfig' setting https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-train-automl-client\/azureml.train.automl.automlconfig.automlconfig?view=azure-ml-py . Using this, I believe you can specify TfIdf as a supported transformer for a particular column https:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-automl-core\/azureml.automl.core.constants.supportedtransformers?view=azure-ml-py\n\nThe following are the supported models for AutoMLconfig. The three different task parameter values determine the list of algorithms, or models, to apply. Use the allowed_models or blocked_models parameters to further modify iterations with the available models to include or exclude.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-12-01T08:40:40.047Z",
                "Answer_score":0,
                "Answer_body":"Hello ramr-msft,\n\nThanks for your quick reply.\nI am familiar with the 'FeaturizationConfig'.\nI created these as far as possible.\n\nfeaturization_config = FeaturizationConfig ()\nfeaturization_config.add_transformer_params ('TfIdf', ['cleaned'], ???)\n\nIt is just unclear to me what to add to 'params'\n1. CUSTOMIZABLE_TRANSFORMERS = {'Imputer', 'HashOneHotEncoder', 'TfIdf'}\n2. Enter columns for the specified transformer.\n3. ???\nadd_transformer_params (transformer: str, cols: typing.List [str], params: typing.Dict [str, typing.Any])\nThe examples shown are unclear for TfIdf.\n\n\n\n\n\n\nWhich entries I have to do in the AutoMLConfig?\n\nautoml_config = AutoMLConfig (name = 'Automated ML Experiment',\ntask = 'classification',\ncompute_target = training_cluster,\ntraining_data = X_train,\nlabel_column_name = y_train,\n#training_data = train_ds,\n#validation_data = test_ds,\n# label_column_name = 'destination_folder',\nprimary_metric = 'AUC_weighted',\nfeaturization = featurization_config,\nblocked_models = ['XGBoostClassifier'],\n)\n\nfeaturization = featurization_config\n\n\ntraining_data = Column or entire dataset?\n\n\nlabel_column_name = Result column?\n\nRegards, Volker",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML real time endpoints stuck in 'Transitioning' state",
        "Question_creation_time":1606672254767,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/179215\/azure-ml-real-time-endpoints-stuck-in-39transition.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I am trying to deploy Azure ML models as webservice endpoints using an AKS cluster. I have deployed the real time inference pipeline using the Azure ML Studio interface.\nThe endpoints deploy successfully and quickly reach a \"Healthy\" state, however occasionally the deployments are stuck in the \"Transitioning\" state for indefinite time. This disables the testing for the endpoints on the portal and we are unable to consume the webservice for that period of time.\nAny idea why this might be happening, or what I can do to fix this?\nIs there a limit to the number of endpoints available on an inference cluster ?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Register Azure ML Model from DatabricksStep",
        "Question_creation_time":1605264849177,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/162055\/register-azure-ml-model-from-databricksstep.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":6,
        "Question_score":1,
        "Question_body":"Hi,\n\nI'm calculating a model while executing a DatabricksStep in an Azure ML Pipeline, save it on my Blob Storage as .pkl file and upload it to the current Azure ML Run using Run.upload_file (). All this works without any problems.\n\nBut as soon as I try to register the model to the Azure ML Workspace using Run.register_model (), the script throws the following error:\n\nUserErrorException: UserErrorException:\nMessage:\nOperation returned an invalid status code 'Forbidden'. The possible reason could be:\n1. You are not authorized to access this resource, or directory listing denied.\n2. you may not login your azure service, or use other subscription, you can check your\ndefault account by running azure cli commend:\n'az account list -o table'.\n3. You have multiple objects\/login session opened, please close all session and try again.\n\n InnerException None\n ErrorResponse \n\n{\n\"error\": {\n\"code\": \"UserError\",\n\"message\": \"\\nOperation returned an invalid status code 'Forbidden'. The possible reason could be:\\n1. You are not authorized to access this resource, or directory listing denied.\\n2. you may not login your azure service, or use other subscription, you can check your\\ndefault account by running azure cli commend:\\n'az account list -o table'.\\n3. You have multiple objects\/login session opened, please close all session and try again.\\n \"\n}\n}\n\nwith the following call stack\n\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/models_client.py in register_model(self, name, tags, properties, description, url, mime_type, framework, framework_version, unpack, experiment_name, run_id, datasets, sample_input_data, sample_output_data, resource_requirements)\n70 return self.\\\n71 _execute_with_workspace_arguments(self._client.ml_models.register, model,\n---> 72 custom_headers=ModelsClient.get_modelmanagement_custom_headers())\n73\n74 @error_with_model_id_handling\n\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/workspace_client.py in _execute_with_workspace_arguments(self, func, args, *kwargs)\n65\n66 def _execute_with_workspace_arguments(self, func, args, *kwargs):\n---> 67 return self._execute_with_arguments(func, copy.deepcopy(self._workspace_arguments), args, *kwargs)\n68\n69 def get_or_create_experiment(self, experiment_name, is_async=False):\n\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_with_arguments(self, func, args_list, args, *kwargs)\n536 return self._call_paginated_api(func, args_list, *kwargs)\n537 else:\n--> 538 return self._call_api(func, args_list, *kwargs)\n539 except ErrorResponseException as e:\n540 raise ServiceException(e)\n\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _call_api(self, func, args, *kwargs)\n234 return AsyncTask(future, _ident=ident, _parent_logger=self._logger)\n235 else:\n--> 236 return self._execute_with_base_arguments(func, args, *kwargs)\n237\n238 def _call_paginated_api(self, func, args, *kwargs):\n\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_with_base_arguments(self, func, args, *kwargs)\n323 total_retry = 0 if self.retries < 0 else self.retries\n324 return ClientBase._execute_func_internal(\n--> 325 back_off, total_retry, self._logger, func, _noop_reset, args, *kwargs)\n326\n327 @classmethod\n\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _execute_func_internal(cls, back_off, total_retry, logger, func, reset_func, args, *kwargs)\n343 return func(args, *kwargs)\n344 except Exception as error:\n--> 345 left_retry = cls._handle_retry(back_off, left_retry, total_retry, error, logger, func)\n346\n347 reset_func(args, *kwargs) # reset_func is expected to undo any side effects from a failed func call.\n\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/_restclient\/clientbase.py in _handle_retry(cls, back_off, left_retry, total_retry, error, logger, func)\n384 3. You have multiple objects\/login session opened, please close all session and try again.\n385 \"\"\"\n--> 386 raise_from(UserErrorException(error_msg), error)\n387\n388 elif error.response.status_code == 429:\n\n\/databricks\/python\/lib\/python3.7\/site-packages\/six.py in raise_from(value, from_value)\n\nDid anybody experience the same error and knows what is its cause and how to solve it?\n\nBest,\nJonas",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-12-01T05:26:07.107Z",
                "Answer_score":0,
                "Answer_body":"@Jonas-4379 Thanks, We have created bug with the product team, we could see It is n't deterministic error. we would recommend to raise a Azure support desk ticket from Help+Support blade from Azure portal. This will help you to share the details securely and work with an engineer who can provide more insights about the issue that if it can be replicated.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML local Deployment: TypeError: 'NoneType' object is not subscriptable",
        "Question_creation_time":1606476453447,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/178262\/azure-ml-local-deployment-typeerror-39nonetype39-o.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":5,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"I made a script to automatically deploy Azure Models using the python SDK. I want the Data Scientists in my team to easily have their models tested locally and deploy in the cloud afterwards. I use Model.deploy with a custom configuration which looks like this:\n\ninference_config = InferenceConfig(source_directory=params[&#39;source_directory&#39;], entry_script=&#39;score.py&#39;, environment=environment)\n\nWhen I run the script in the cloud it is working perfectly, but when I run the script locally I get the following error:\n\nTraceback (most recent call last): File &#34;\/deploy_script.py&#34;, line 14, in &lt;module&gt; test_deploy.test_service(service, folder, params[&#39;service_name&#39;], delete_service_after_test=False) File &#34;\\testing_deployment.py&#34;, line 20, in test_service result = service.run(input_json) File &#34;\\azureml\\core\\webservice\\local.py&#34;, line 72, in decorated return func(self, *args, **kwargs) File &#34;\\azureml\\core\\webservice\\local.py&#34;, line 429, in run cleanup_on_failure=False, score_url=self.scoring_uri) File &#34;\\azureml\\core\\webservice\\local.py&#34;, line 442, in scoring_uri overrideScorePath = self._container_override_config[&#34;scorePath&#34;] TypeError: &#39;NoneType&#39; object is not subscriptable\n\nIt seems like there is a failure when _container_override_config is accessed because it is None.\n\nDoes anyone have an idea why it is not working for this local configuration, but it is working for the cloud-based solution?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"ML Studio endpoint problem after Aks\/VM Restart",
        "Question_creation_time":1605582083440,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/165092\/ml-studio-endpoint-problem-after-aksvm-restart.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":8,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"After restarting VM's associated to AKS created with to ML Studio deployed the ws endpoint gets unreachable.\n\nTry several time to restart but it doesn't work.\n\nAny idea? Any workaround besides re-create the cluster?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"AML Studio - cannot create dataset from datastore file",
        "Question_creation_time":1605192099620,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/160773\/aml-studio-cannot-create-dataset-from-datastore-fi.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I am using Jupyter notebooks to work in AML. I was able to upload a file to a datastore (the default workspaceblobstore), but am receiving an error when I try to create a dataset using this file. The relevant code is below:\n\n #This part works\n    \n datastore = ws.get_default_datastore()\n    \n datastore.upload_files(files = ['data\/german_credit_dataset.csv'], overwrite = True, show_progress = True)\n    \n # This part doesn't\n    \n dataset = Dataset.Tabular.from_delimited_files(path = [(datastore ,'german_credit_dataset.csv')])\n\nI know the file was uploaded correctly as I am able to locate it in the datastore, and manually create a dataset. The error I receive is:\n\ncode\": \"UserError\",\n\"message\": \"Cannot load any data from the specified path. Make sure the path is accessible and contains data.\\nScriptExecutionException was caused by DatastoreResolutionException.\\r\\n DatastoreResolutionException was caused by UnexpectedException.\\r\\n\nCould it be a permissions issue? I used the json file to connect to my compute instance and it seems to work since I was able to upload the file.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure ML Designer error: Dataset initialization failed",
        "Question_creation_time":1606556238047,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/178715\/azure-ml-designer-error-dataset-initialization-fai.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":7,
        "Question_score":1,
        "Question_body":"Getting following error when submiting Azure ML designer pipeline, following azure tutorial explore-data\n\n\n\n\nError msg:\nDataset initialization failed: Waiting for mount point to be ready has timed out. Check if fuse device is available on your system.\nIf mounting on remote targets, see https:\/\/docs.microsoft.com\/azure\/machine-learning\/how-to-train-with-datasets#mount-files-to-remote-compute-targets",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-30T08:48:28.543Z",
                "Answer_score":0,
                "Answer_body":"I had this problem only in us east region. I continue study in another region for now.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML workspace- compute prices",
        "Question_creation_time":1606098165613,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/171550\/azure-ml-workspace-compute-prices.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":1,
        "Question_body":"I was trying to create a compute instance on Azure ml workspace and found that few of the virtual machine sizes show blank in thee price column. Wondering if they are free to use or its a bug. I sorted by prices. So, you can see first few rows showing blanks under price column",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-30T08:49:53.507Z",
                "Answer_score":0,
                "Answer_body":"@rawwar Thanks for the feedback. It's bug over free AzureML compute, We will update once the team fix this issue.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is there any kinect version that helps in speech therapy?",
        "Question_creation_time":1606122417867,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/171998\/is-there-any-kinect-version-that-helps-in-speech-t.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":2,
        "Question_score":1,
        "Question_body":"Hi,\nI am an educator\/researcher who is working on a project or a thesis for my degree.\nI am thinking of using Kinect to recognize the lips\/ mouth movements to train speech delay kids. My idea is to show students audio-visual 3d mouth, tongue, and throat movements on the Kinect to train them to speak a letter or word by interacting with the camera and evaluating their sounds and movements by the Kinect. At the same time, the Kinect camera will configure if the student's sound and mouth movement are correct.\n\nI am perplexed about which tag I should use for my question to be best answered.\n\nI really appreciated it if there are studies or experiments on this issue to let me know.\n\nRegards",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-24T14:29:09.493Z",
                "Answer_score":0,
                "Answer_body":"@LaylaObeid-3644 Thanks, Please have a look at https:\/\/docs.microsoft.com\/en-us\/azure\/cognitive-services\/speech-service\/how-to-select-audio-input-devices for more info on selecting audio devices.\nWe also have a Robot Operating System(ROS) package for the Azure Kinect. The Kinect camera is a widely adopted sensor in the field of robotics.\nhttps:\/\/github.com\/microsoft\/azure_kinect_ros_driver\n\nAlso Have a look at https:\/\/github.com\/microsoft\/Azure-Kinect-Samples",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Split Data with randomized_split unchecked",
        "Question_creation_time":1605537495223,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/164274\/split-data-with-randomized-split-unchecked.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Please what happen when we split data on the mode SPLIT ROWS with randomized_split unchecked ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-17T11:19:48.147Z",
                "Answer_score":0,
                "Answer_body":"@hamzafq-5936 Thanks for the question. Can you please add more details about the document that you are following. Please follow the below document for data splits in AutoML.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-cross-validation-data-splits\n\nDid you split the dataset into training_data and validation_data. Please check the value count of the split data from the training_data and validation_data dataset.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML experiment run 70- driver log not printing after a few epoches",
        "Question_creation_time":1604880529150,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/155350\/azure-ml-experiment-run-70-driver-log-not-printing.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"I am training a deep learning artificial neural network model, usually the run submitted to the Experiment will show all the model running logs in 70-driver-log of 'outputs + logs' tab, but starting yesterday, the logs show only a few lines of logs and stop printing. I can still see the model is running since the 'metrics' tab is showing the loss and accuracy results.\n\nAnd another weird thing is that after model training finished, the model is not saved.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"What could I be doing wrong to get this result from Azure AutoML timeseries forecasting?",
        "Question_creation_time":1606359622230,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/176361\/what-could-i-be-doing-wrong-to-get-this-result-fro.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"I'm experimenting with Azure AutoML for timeseries forecasting. I have a simple two column training dataset with two years of data at hourly intervals. Column 1 is Date\/Time Column 2 is the variable I want to predict. I've done several runs of Azure AutoML and it seems to complete successfully. However, when I do a forecast and graph it something is obviously wrong. It looks like the forecast is being quantised somehow. The graph below is for the 7 days after the training set. Blue is actual and red is the forecast. This is obviously not right.\n\n\n\n\nHere is my configuration for the training (python):\n\n lags = [1,24,168]\n forecast_horizon = 7 * 24 # 7 days of hourly data\n forecasting_parameters = ForecastingParameters(\n     time_column_name=\"DateTime\",\n     forecast_horizon=forecast_horizon,\n     target_lags=lags,\n     country_or_region_for_holidays='NZ',\n     freq='H',\n     use_stl='season',\n     seasonality='auto'\n )\n automl_config = AutoMLConfig(task='forecasting',\n                              debug_log='automl_forecasting_function.log',\n                              primary_metric='normalized_root_mean_squared_error',\n                              experiment_timeout_hours=1,\n                              experiment_exit_score=0.05, \n                              enable_early_stopping=True,\n                              training_data=train_df,\n                              compute_target=compute,\n                              n_cross_validations=10,\n                              verbosity = logging.INFO,\n                              max_concurrent_iterations=19,\n                              max_cores_per_iteration=19,\n                              label_column_name=\"Output\",\n                              forecasting_parameters=forecasting_parameters,\n                              featurization=\"auto\",\n                              enable_dnn=False)\n\n\n\nThe best model from the run is a VotingEnsemble:\n\n ForecastingPipelineWrapper(pipeline=Pipeline(\n   memory=None,\n   steps=[('timeseriestransformer',\n   TimeSeriesTransformer(\n     featurization_config=None,\n     pipeline_type=<TimeSeriesPipelineType.FULL: 1>)),\n   ('prefittedsoftvotingregressor',\n   PreFittedSoftVotingRegressor(estimators=[('7',\n   Pipeline(memory=None,\n   steps=[('minmaxscaler',\n   MinMaxScaler(copy=True,\n   feature_range=(0,\n   1))...\n   DecisionTreeRegressor(ccp_alpha=0.0,\n   criterion='mse',\n   max_depth=None,\n   max_features=0.5,\n   max_leaf_nodes=None,\n   min_impurity_decrease=0.0,\n   min_impurity_split=None,\n   min_samples_leaf=0.00218714609400816,\n   min_samples_split=0.00630957344480193,\n   min_weight_fraction_leaf=0.0,\n   presort='deprecated',\n   random_state=None,\n   splitter='best'))],\n   verbose=False))],\n   weights=[0.5,\n   0.5]))],\n   verbose=False),\n   stddev=None)",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-26T20:37:59.827Z",
                "Answer_score":0,
                "Answer_body":"I tried again after turning off early stopping and letting it run for the two hours.... and got this",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"TabularDataset \"topandasdataframe()\" - does not support pandas errorbadlines?",
        "Question_creation_time":1605588169590,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/165143\/tabulardataset-34topandasdataframe34-does-not-supp.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Hello,\n\nI am trying to skip lines that produces more columns than intended while loading to a pandas dataframe.\n\nLike this Pandas Option: When error_bad_lines = False, pandas will skip these lines.\n\nHow can I achieve this with to-pandas-dataframe? Thanks.\n\nhttps:\/\/docs.microsoft.com\/en-us\/python\/api\/azureml-core\/azureml.data.tabulardataset?view=azure-ml-py#to-pandas-dataframe-on-error--null---out-of-range-datetime--null--",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-18T07:30:31.037Z",
                "Answer_score":0,
                "Answer_body":"@SriramNarayanan-6939 As mentioned in the referred documentation link this option is not available with to_pandas_dataframe(), you can only use on_error='null' to replace the failed values with null or fail with exception if 'fail' is used.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How does AzureML choose the node to launch a run?",
        "Question_creation_time":1605888033847,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/170198\/how-does-azureml-choose-the-node-to-launch-a-run.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"I have a question related with runs, compute clusters and vcpu\/memory boundaries for specific run.\n\nI have this mindset that a run executes over an environment (a docker image) in a specific compute target. My idea is, if there are resources (vcpu and memory) available on a node, so the run executes in that node. But I always see that a node only executes one run each time, independently the node sku of compute cluster. It seams, AzureML chooses always a idle node to launch a run.\n\nDoes a node always execute one, and not more than one, run in the same time?\nWhat are resources boundaries for run? Or the run might spread over all node resources?\nIf there is boundaries, the default boundaries is static or configurable through environment property `arguments` for docker run?\n\nWhat the following section in run raw json means?\n\n \"containerInstance\": {\n   \"region\": null,\n   \"cpuCores\": 2,\n   \"memoryGb\": 3.5\n },\n\n\n\nThanks",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure AutoML time series model returns strange forecast",
        "Question_creation_time":1604413410307,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/149896\/azure-automl-time-series-model-returns-strange-for.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I used Azure AutoML to train a time series forecasting model and selected the forecasting horizon to be 6. Each of our data row is one month, so we want to see the forecast for the following 6 months.\n\nHowever, when feeding 2 rows of data to the model, it returns 2 figures, and when feeding 8 rows of data, it returns 8 figures. We expect that as we select the forecasting horizon to be 6, regardless of how many rows of data being fed into the model, it should returns 6 figures.\n\nCould somebody explain why this happens and how to correct it? Thank you.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-04T05:17:37.92Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nI would suggest you double check how you are defining time_column_name. Thanks.\n\nAttached the definition of this class for your reference,\n\n fulldata: pandas.DataFrame           a time series dataset. Needs to contain X and y.\n time_column_name: string             which column (must be in fulldata) is the time axis\n target_column_name: string           which column (must be in fulldata) is to be forecast\n forecast_origin: datetime type       the last time we (pretend to) have target values \n horizon: timedelta                   how far forward, in time units (not periods)\n lookback: timedelta                  how far back does the model look?\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-11-26T03:31:04.907Z",
                "Answer_score":0,
                "Answer_body":"I think it will forecast the number of rows you feed into the forecast function (feed datetime with empty column for output). So the behaviour you see is expected.\n\nIdeally you feed in no more than your training forecast horizon. If you feed more it wil become increasingly inaccurate as it starts to use the previously forecast value as input for the \"over the horizon\" forecasts.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Blocked Algorithms still run for AutoML Experiment",
        "Question_creation_time":1605815289883,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/168932\/blocked-algorithms-still-run-for-automl-experiment.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"I have been trying to run an AutoML Forecasting Experiment with only allowing one algorithm (FBProphet) to run and no other supported algorithms. The issue I run into is that even though I specify the blocked algorithms, they still run in the experiment taking up unnecessary runtime. For eg, my experiment should run only for 1-2 hours but it ends up running for 24-30 hours because it still runs the undesired algorithms. Is there any way I can stop making the blocked algorithms from running in my experiment so I can save up on significant runtime? I have attached a screenshot and my AutoML config code to help understand this issue better.\n\nCode:\nn_test_periods = 60\nblocked_algos = ['ExtremeRandomTrees','DecisionTree','ElasticNet','LassoLars']\ntime_series_settings = {\n    'time_column_name': time_column_name,\n    'grain_column_names': grain_column_names ,\n    'forecast_horizon': n_test_periods\n}\nautoml_config = AutoMLConfig(task='forecasting',\n                             debug_log='Logs\/prophet_forecasting_errors.log',\n                             primary_metric='normalized_mean_absolute_error',\n                             training_data=train_data,\n                             label_column_name=target_column_name,\n                             compute_target=compute_target,\n                             featurization= 'off',\n                             blocked_model = blocked_algos,\n                             allowed_models = ['Prophet'],\n                             n_cross_validations= 3,\n                             verbosity=logging.INFO,\n                             max_cores_per_iteration=6,\n                             **time_series_settings)\nremote_run = experiment.submit(automl_config, show_output=True)\n\n\nScreenshot of the Experiment: (This took 32h when it should ideally take 56 mins)",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-25T13:20:31.887Z",
                "Answer_score":0,
                "Answer_body":"@MeghaLokanadham-7021 it's always good to have the latest version if possible, latest version is 1.18.0 as of today.\n\nCan you please try the following 1. Correct the name of the parameter( blocked_model) to \"blocked_models\" and keep both \"blocked_models\" and \"allowed_models\".",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"ML endpoint not accessible after stopping\/restarting ACI",
        "Question_creation_time":1604412389243,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/149864\/ml-endpoint-not-accessible-after-stoppingrestartin.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":5,
        "Question_follower_count":8,
        "Question_score":2,
        "Question_body":"I have been developing a ML model using Azure ML workspace and the azure-ml SDK. The development of the model and deployment of the model works using the SDK. I have confirmed multiple times that after the endpoint is created I can call it with the correct payload and the webservice will return the correct results.\n\nHowever, once I deploy a model to ACI and stop-start or restart the container instance resource in Azure. The endpoint stops working and I get a timeout error when calling the webservice.\n\nHave any of you run into the same issues when deploying an Azure ML model to ACI?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-04T05:00:25.88Z",
                "Answer_score":3,
                "Answer_body":"Hello,\n\nThe engineering team has confirmed this is a bug and we are in discussion about this bug. I will keep eyes on it and will let you know if there is any update. Thanks for reaching out to us.\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-11-18T17:55:30.803Z",
                "Answer_score":1,
                "Answer_body":"Hello everyone,\n\nThis issue has been confirmed fixed. It should work now with no issue. Please let me know if you are still suffering from bugs\/ errors\/...\n\nRegards,\nYutong",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML dataset: label column of dataset is None",
        "Question_creation_time":1605709509727,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/167244\/azure-ml-label-colzumn-of-dataset-is-none.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Hi,\n\nFor a project we need to load some data and its labels from an azure ML dataset. However when using the following sample code in python:\n\n     from azureml.core import Workspace, Dataset\n     subscription_id = 'sub-id...'\n     resource_group = 'res-grp...'\n     workspace_name = 'ws-name...'\n     ds_name = 'name-of-ds'\n    \n     workspace = Workspace(subscription_id, resource_group, workspace_name)\n     dataset = Dataset.get_by_name(workspace, name=ds_name).to_pandas_dataframe()\n\n\n\nthe labels are None. The dataset was exported from a \"Image Classification Multi-label\" project. For a dataset exported from a \"Image Classification Multi-class\" the code works fine. Currently I work on a local PC in Pycharm with Python 3.5 (due to easier debugging). Can you maybe help me with that?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-19T04:54:47.477Z",
                "Answer_score":0,
                "Answer_body":"@Daniel-8364 Here are the detailed steps to handle datasets with labels while loading to a pandas dataframe. For example:\n\n import azureml.core\n import azureml.contrib.dataset\n from azureml.core import Dataset, Workspace\n from azureml.contrib.dataset import FileHandlingOption\n    \n # get animal_labels dataset from the workspace\n animal_labels = Dataset.get_by_name(workspace, 'animal_labels')\n animal_pd = animal_labels.to_pandas_dataframe(file_handling_option=FileHandlingOption.DOWNLOAD, target_path='.\/download\/', overwrite_download=True)\n    \n import matplotlib.pyplot as plt\n import matplotlib.image as mpimg\n    \n #read images from downloaded path\n img = mpimg.imread(animal_pd.loc[0,'image_url'])\n imgplot = plt.imshow(img)\n\n\n\n\nA sample notebook to try these scenarios is also available here. We hope this helps!!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-11-25T12:28:45.993Z",
                "Answer_score":0,
                "Answer_body":"@romungi-MSFT thanks for the answer! Actually I'm not trying to download the images but only get the labels with it's corresponding image_url's. When I use the sample code provided I get the following error:\n\n TypeError: lstat: illegal type for path parameter\n During handling of the above exception, another exception occurred:\n azureml._common.exceptions.AzureMLException: AzureMLException:\n  Message: Execution failed in operation 'to_pandas_dataframe' for Dataset(id='subs_id...', name='ds_name...', version=1, exception_type=TypeError)\n  InnerException lstat: illegal type for path parameter\n  ErrorResponse \n {\n \"error\": {\n     \"message\": \"Execution failed in operation 'to_pandas_dataframe' for Dataset(id='subs_id...', name='ds_name...', version=1, exception_type=TypeError)\"\n }\n\n}\n\nHowever the data gets downloaded to '.\/download' but I still cant access the labels of the datapoints.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to retrain Automated ML generated Model with new Data",
        "Question_creation_time":1606117190360,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/171971\/how-to-retrain-automated-ml-generated-model-with-n.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Hi,\ni generated a machine learning model with Automated ML in Azure Machine Learning. Time to time i get new data, and i wanna feed the generated model with it.\nIs there a way to automatically retrain that model and updating the belonging endpoint.\n\nI have seen some intructions to this using Data Factory and Pipelines. Since I'm using Automated ML I'm not able to do it this way.\n\nThanks in advance.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-23T08:20:40.52Z",
                "Answer_score":0,
                "Answer_body":"@27051995 Thanks for the question. Model Deployment : AutoML models can be either downloaded locally or deployed to AML (AKS \/ ACI) for inference., Please use the Model Lifecycle management \/ MLOps: AzureML MLOps capabilities for continuous integration, retraining and automation pipelines.\n\nThe link below explains how to use Azure DevOps Project for build and release\/deployment pipelines along with Azure ML services for model retraining pipeline, model management and operationalization.\nhttps:\/\/github.com\/microsoft\/MLOpsPython\n\nPlease follow the below document for retrain your model on new data.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-model-management-and-deployment#retrain-your-model-on-new-data",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Deployment of ML model stuck in transitioning state",
        "Question_creation_time":1606113753810,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/171789\/deployment-of-ml-model-stuck-in-transitioning-stat.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"I am trying to deploy a simple LSTM model in ACI. The deployment is stuck in transitioning state for about a day now. Any help will be much appreciated.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-23T07:53:52.083Z",
                "Answer_score":0,
                "Answer_body":"@RamkumarSekar-7615 Thanks for the question, Can you please add error log details for further investigation. We would recommend to raise a Azure support desk ticket from Help+Support blade from Azure portal for your resource if you have a support plan for your subscription. This will help you to share the details securely and work with an engineer who can provide more insights about the issue that if it can be replicated.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Isn't Interactive login, default for Workspace.from_config()?",
        "Question_creation_time":1606097614390,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/171577\/isn39t-interactive-login-default-for-workspacefrom.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"According to this notebook\n\nInteractive Authentication\nInteractive authentication is the default mode when using Azure ML SDK.\n\n\nWhen you connect to your workspace using workspace.from_config, you will get an interactive login dialog.\n\nSo, i ran ws=Workspace.from_config()\nand got the following error\n\n --------------------------------------------------------------------------\n UserErrorException                        Traceback (most recent call last)\n <ipython-input-13-e469111f639c> in <module>\n ----> 1 ws = Workspace.from_config()\n    \n ~\\Documents\\Softwares\\Anaconda3\\lib\\site-packages\\azureml\\core\\workspace.py in from_config(path, auth, _logger, _file_name)\n     276\n     277             if not found_path:\n --> 278                 raise UserErrorException(\n     279                     'We could not find config.json in: {} or in its parent directories. '\n     280                     'Please provide the full path to the config file or ensure that '\n    \n UserErrorException: UserErrorException:\n         Message: We could not find config.json in: C:\\Users\\qwewqd or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.\n         InnerException None\n         ErrorResponse\n {\n     \"error\": {\n         \"code\": \"UserError\",\n         \"message\": \"We could not find config.json in: C:\\\\Users\\\\qwewqd or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.\"\n     }\n }",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-23T07:26:12.007Z",
                "Answer_score":0,
                "Answer_body":"@rawwar A configuration file(JSON) is created when you run the configuration.ipynb file or notebook which can then be used to get the configuration using\nws = Workspace.from_config()\n\nYou can run this notebook and create a new workspace if not available or use the existing workspace. For example, Set the workspace details as environment varibles.\n\n import os\n    \n subscription_id = os.getenv(\"SUBSCRIPTION_ID\", default=\"<my-subscription-id>\")\n resource_group = os.getenv(\"RESOURCE_GROUP\", default=\"<my-resource-group>\")\n workspace_name = os.getenv(\"WORKSPACE_NAME\", default=\"<my-workspace-name>\")\n workspace_region = os.getenv(\"WORKSPACE_REGION\", default=\"eastus2\")\n\n\n\n\nWrite then to config.json file\n\n from azureml.core import Workspace\n    \n try:\n     ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n     # write the details of the workspace to a configuration file to the notebook library\n     ws.write_config()\n     print(\"Workspace configuration succeeded. Skip the workspace creation steps below\")\n except:\n     print(\"Workspace not accessible. Change your parameters or create a new workspace below\")\n\n\n\n\nYou can now access this config from other notebooks and need not specify the subscription or workspace details in every notebook file.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Unable to start azure ml notebooks",
        "Question_creation_time":1600874019267,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/104765\/unable-to-start-azure-ml-notebooks.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":6,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"I have been trying to experiment with Azure ML. So, i created a workspace. When i create a notebook, i keep getting same error from past two days. Please help.\n\n\n\n\nAlso, you can see errors in console.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure ML: ID column for joining data returns \"No. Of unique values ... is greater than allowed\"",
        "Question_creation_time":1604936001023,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/156534\/auzre-ml-id-column-for-joining-data-returns-34no-o-1.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":6,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Hi.\n\nI am working on an ML model in Designer.\n\nI have a dataset of c. 55,000 rows.\n\nWhen I add an \"ID\" column (unique per row - so 55,000 IDs) to my dataset for training \/ scoring, I receive the error message:\n\nModuleExceptionMessage:ColumnUniqueValuesExceeded: Number of unique values in column: \"ID\" is greater than allowed.\n\nQuestion: is this error based on a physical cap on number of rows - or capacity based on e.g. Compute power associated with the instance?\n\nI can run 20k rows through the model without the ID column - so it seems the unique rows is the challenge.\n\nBut then - how do I keep an identifying column in the scored dataset, if there is a cap on unique values?\n\nBecause I need the ID column to join with other data that is not able to be used in modelling as features etc.\n\nAny guidance welcome!",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-17T23:07:36.913Z",
                "Answer_score":0,
                "Answer_body":"User can use Edit Metadata module to mark the ID column as \"ClearFeature\", and thus this will not be used in Train Model. This should prevent the error. Please have a try and let me know if there is any questions. https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/edit-metadata\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Is there a way to export experiment parameters and logged metrics in Azure ML to CSV?",
        "Question_creation_time":1605641332880,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/166057\/is-there-a-way-to-export-experiment-parameters-and.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"I am running a bunch of ML experiments using AzureML, sometimes changing training parameters and sometimes aspects of the data preprocessing. In general, for a given experiment I will be able to get a table (aka \"view\") like this:\n\nWhile the UI allows some minimum level of customization, sorting runs by e.g. desired columns (say the accuracy to identify the best runs) seems really problematic.\n\nThe only workaround I am aware of is to save the page to HTML (!) and extract the values from there.\nThe data in the cells can't by copied with a cursor either...\n\nIs there an easy way to export the data collected during several runs, via the UI or programmatically, without the need to scrape the blob storage of the Azure ML workspace (I am asking the community here as docs don't seem particularly helpful)?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-18T08:02:11.3Z",
                "Answer_score":2,
                "Answer_body":"@DavideFiocco-7346 You can use the SDK to export the run\/s using Run() or get_runs()\nThis sample provides an example to get all the files associated with a run. I think you can use the SDK to get all the runs with get_runs() and load the list to a dataframe and export the same to csv.\n\nThe portal does not have the functionality to export the table but we will provide the feedback to our team for upcoming updates to the portal. Thanks!!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Investigating AML workspace images crashes due to already deleted model",
        "Question_creation_time":1605805617850,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/168781\/investigating-aml-workspace-images-crashes-due-to.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"I am currently working with Azure Machine Learning. Doing this I encountered a problem when trying to access the images associated with the AML workspace I am working on. It seems, that the method is trying to get access to a model that was already deleted from the model registration by me some time ago. I deleted the model in the GUI of AML on the \"models\" tab.\n\nCalling:\n\n ws.images\n\n\n\nProduces:\n\n Received bad response from Model Management Service:\n Response Code: 404\n Headers: {'Date': 'Thu, 19 Nov 2020 16:56:10 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Vary': 'Accept-Encoding', 'x-ms-client-request-id': '5b1ae4fc52324429b241197be3f455a3', 'x-ms-client-session-id': '', 'api-deprecated-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'X-Content-Type-Options': 'nosniff', 'x-request-time': '2.912', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'Content-Encoding': 'gzip'}\n Content: b'{\"code\":\"NotFound\",\"statusCode\":404,\"message\":\"The specified resource was not found.\",\"details\":[{\"code\":\"NoSuchModelRegistered\",\"message\":\"One or more models are not registered in Account Subscription: da80dbc4-7dd6-4833-b66e-f6dbbbe42ece, ResourceGroup: dat-q-rg, Workspace: dat-q-aml-01. Unregistered modelIds sklearn_regression_model.pkl:13\"}],\"correlation\":{\"RequestId\":\"5b1ae4fc52324429b241197be3f455a3\"}}'\n    \n Traceback (most recent call last):\n   File \"C:\\Users\\d91755\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\azureml\\core\\image\\image.py\", line 577, in list\n     resp.raise_for_status()\n   File \"C:\\Users\\d91755\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\requests\\models.py\", line 943, in raise_for_status\n     raise HTTPError(http_error_msg, response=self)\n requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https:\/\/westeurope.modelmanagement.azureml.net\/modelmanagement\/v1.0\/subscriptions\/da80dbc4-7dd6-4833-b66e-f6dbbbe42ece\/resourceGroups\/dat-q-rg\/providers\/Microsoft.MachineLearningServices\/workspaces\/dat-q-aml-01\/images?expand=true\n\n\n\n\nThe model sklearn_regression_model.pkl:13 existed and was registered in AML but was deleted manually by me in AML. How come calling the images method has still knowledge of this model?\nHow can I fix this to be able to call the images method again?\n\nIn case this is a bug, where would I report it?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-20T13:11:00.177Z",
                "Answer_score":0,
                "Answer_body":"@ArielBrandes-8191 Thanks for the question. Your registered models are stored at a path pointed to by an environment variable called AZUREML_MODEL_DIR. For more information on the exact directory structure, see Locate model files in your entry script.You can use the Model.get_model_path() method to retrieve the path of the model file or files on the local file system.\n\nIf we use Model.deploy to deploy the model, SDK won\u2019t attach the azureml-app folder to the image. Therefore, if we pull the image from ACR and docker run your image locally, you have to place at least your score.py and model.pkl under azureml-app and use the below example command to start the container:\n\ndocker run -dit -p 5001:5001 -e AZUREML_MODEL_DIR=azureml-models\/<model_name>\/<version> -e AZUREML_ENTRY_SCRIPT=score.py --mount src=\"<local_filepath>\",target=\/var\/azureml-app,type=bind <image_id> runsvdir \/var\/runit\n\n\n\n\nPlease follow the below notebook sample to register and deploy to the cloud.\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/deployment\/deploy-to-cloud\/model-register-and-deploy.ipynb",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unable to find the example URL and other details after publishing the LUIS app",
        "Question_creation_time":1605612037043,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/165568\/unable-to-find-the-example-url-and-other-details-a.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":6,
        "Question_score":1,
        "Question_body":"Hii,\nI have created and a published a LUIS app, but in the manage section I am not able to see and example URL and other details such as keys and other Information after publishing it. Can some help me out with the mentioned issue?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-18T19:28:44.643Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nYou can go to Azure portal : https:\/\/ms.portal.azure.com\/\n\nGo to your LUIS resource and click \"Keys and Endpoint\"\n\nYou can get your keys and endpoint URL.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Deploying Machine Learning Modules to IoT Edge running on Windows",
        "Question_creation_time":1604258300613,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/147408\/deploying-machine-learning-modules-to-iot-edge-run.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I'm building an IoT device that needs to run on Windows. I'm aggregating data for analytics and would like to build a Machine Learning model. I've seen that IoT Edge with Windows Containers doesn't support Azure Machine Learning and won't be able to run modules written in Python. What options do you recommend for developing machine learning modules for Windows containers? Is there a timeline for IoT Edge supporting python in Windows containers? Or supporting Azure Machine Learning? I saw a forum post back in early 2019 from a Project Manager that said both were planned features and I don't want to spend time\/money developing a C# module if a Python update is around the corner and I just have to wait for deployment",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-02T23:17:10.847Z",
                "Answer_score":0,
                "Answer_body":"Hello @bbrsa welcome to Microsoft Q&A!\n\nCan you help us with your research so far - links to the info you encountered so that we can validate they stand true?\n\n\"Windows Containers doesn't support Azure Machine Learning\"\n\n\n\"Windows devices won't be able to run modules written in Python\"\n\n\n\"...saw a forum post back in early 2019 from a Project Manager that said both were planned features...\"\n\nFinally, can you consider running Linux Containers on a Windows Device? See: https:\/\/docs.microsoft.com\/en-us\/azure\/iot-edge\/support\nThanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"frame = ds.to_dataframe() doesn't work for me",
        "Question_creation_time":1605353730307,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/162914\/frame-dsto-dataframe-doesn39t-work-for-me.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-16T11:35:54.413Z",
                "Answer_score":0,
                "Answer_body":"@MohamedSalem-4734 Thanks for the question. A TabularDataset can be created from CSV, TSV, Parquet files, or SQL query using the from_* methods of the TabularDatasetFactory class. You can also convert a TabularDataset into other formats like a pandas DataFrame. Can you please add more details about the dataframe (pandas DataFrame or spark Dataframe) that you are trying.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Endpoint deployment stuck on \u201cTransitioning\u201d in Azure Machine Learning",
        "Question_creation_time":1605092257033,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/159147\/endpoint-deployment-stuck-on-transitioning-in-azur.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I am trying to deploy an endpoint from the machine learning studio, but all endpoints get stuck in the transitioning state.\n\n\n\n\nWhen looking at the container's activity log, I can see the following operations took place:\n\nAnd if I select the top level failed action, I can see this error message:\n\nHowever, I should have the usual permissions for the group I'm deploying in, as I've created other resources in this group before.\n\nAm I missing a different permission which would not be needed for other resources?\n\nResource group: intrglmpdev00002\n\nSubscription Id: 931c1c11-140f-4489-a457-6f4b22023b26\n\nWorkspace: LimburgsMooisteML1\n\nWhile searching for a solution earlier I found this thread; https:\/\/docs.microsoft.com\/en-us\/answers\/questions\/39341\/azure-ml-endpoint-stuck-in-transitioning-state.html I have also sent an email to microsoft as specified there.\n\nEDIT: I also just noticed that the description that I entered for testdeployment3 does not show up in the endpoint specifications.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-16T07:04:01.327Z",
                "Answer_score":0,
                "Answer_body":"Found below error in the logs:\n\nStatus Code: 400 BadRequest Reason Phrase: Python interpreter version must be specified in the Conda file.\n\nPlease try specifying python version in your Conda file, something like:\n\ndependencies:\n# The python interpreter version.\n# Currently Azure ML only supports 3.5.2 and later.\n- python=3.6.2",
                "Answer_comment_count":7,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Anaconda commercial use on Azure Machine Learning",
        "Question_creation_time":1605597154997,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/165312\/anaconda-commercial-use-on-azure-machine-learning.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Anaconda announced that commercial users should purchase the licenses on APR, 20, 2020.\nHowever, Azure Machine Learning heavily depends on this anaconda packages; developing models on computing instance and deploy container environment.\n\nDo commercial developers have to pay to anaconda to continue usage of Azure Machine Learning with anaconda?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-17T08:44:06.227Z",
                "Answer_score":0,
                "Answer_body":"@EisukeYonezawa-9200 If you are have the commercial version of Anaconda you can configure the same for your experiments to deploy packages that are available under license but in most cases you can simply use conda to install available python packages without paying for the commercial license. There is no restriction to have a commercial license to continue using Azure Machine Learning with anaconda. I hope this helps!!",
                "Answer_comment_count":4,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Endpoint stuck in 'transitioning' state",
        "Question_creation_time":1604939373570,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/156439\/endpoint-stuck-in-39transitioning39-state.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"I'm trying to use Azure ML to host an image classification model trained in lobe.ai (externally trained model).\n\nI've used the 'no code' model deployment approach described here\n\nI've been able to authenticate my workspace and register my TensorFlow model, but the endpoint is stuck on transitioning for over 2 hours.\n\nAny ideas?\n\n from azureml.core import Model\n    \n model = Model.register(workspace=ws,\n                        model_name='cxr',                            # Name of the registered model in your workspace.\n                        model_path='cxr_test',                       # Local Tensorflow SavedModel folder to upload and register as a model.\n                        model_framework=Model.Framework.TENSORFLOW,  # Framework used to create the model.\n                        model_framework_version='1.15.3',            # Version of Tensorflow used to create the model.\n                        description='Pneumonia-prediction model')\n    \n service_name = 'tensorflow-cxr-service'\n service = Model.deploy(ws, service_name, [model])",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-11T20:06:20.897Z",
                "Answer_score":0,
                "Answer_body":"We have created a support ticket for this issue and we will update the solution later. Thanks.\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Unable to use private docker registry with latest Azure ML release",
        "Question_creation_time":1604958506767,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/157021\/unable-to-use-private-docker-registry-with-latest.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":7,
        "Question_score":1,
        "Question_body":"Since the latest Azure ML release, we have been unable to submit any job using a private docker registry. Same jobs were working before the new release.\nWe configure the job as follows (all of this is automated and the code has not changed):\n\nbase_image_name = &#39;REDACTED.azurecr.io\/lb\/learning_box_azure_compute:0.1.15_1601582281&#39;\n\n # Set the container registry information\n myenv = Environment(name=&#34;lb&#34;)\n myenv.docker.enabled = True\n myenv.docker.base_image = base_image_name\n myenv.docker.base_image_registry.address = &#39;REDACTED.azurecr.io\/lb\/&#39;\n myenv.docker.base_image_registry.username, myenv.docker.base_image_registry.password = get_docker_secrets()\n myenv.python.user_managed_dependencies = True\n myenv.python.interpreter_path = &#34;\/opt\/miniconda\/bin\/python&#34;\n\n\n\nInstead of successful job submission, we are instead getting:\n{\n&#34;error&#34;: {\n&#34;message&#34;: &#34;Activity Failed:\\n{\\n \\&#34;error\\&#34;: {\\n \\&#34;code\\&#34;: \\&#34;UserError\\&#34;,\\n \\&#34;message\\&#34;: \\&#34;Unable to get image details : Specified base docker image REDACTED.azurecr.io\/lb\/learning_box_azure_compute:0.1.15_16\\&#34;,\\n \\&#34;details\\&#34;: []\\n },\\n \\&#34;correlation\\&#34;: {\\n \\&#34;operation\\&#34;: null,\\n \\&#34;request\\&#34;: \\&#34;c41448d429f9c80b\\&#34;\\n },\\n \\&#34;environment\\&#34;: \\&#34;eastus\\&#34;,\\n \\&#34;location\\&#34;: \\&#34;eastus\\&#34;,\\n \\&#34;time\\&#34;: \\&#34;2020-11-09T21:40:39.699533Z\\&#34;,\\n \\&#34;componentName\\&#34;: \\&#34;execution-worker\\&#34;\\n}&#34;\n}\n}\nThe image has not changed (we tried a few different ones from prior successful jobs) and the use of the SDK has not changed.\nHas anybody else encountered a similar problem since the Nov 5 upgrade (https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/azure-machine-learning-release-notes)?\nThis is a major block as we cannot proceed with any project that depend on Azure ML at this time.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-10T13:47:09.613Z",
                "Answer_score":0,
                "Answer_body":"@FabienCampagne-4175 Thanks for the details, with fully qualified base image name you do not need to specify container registry address. container registry address itself should be just a host name.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Deep learning training on Azure steps and tutorial",
        "Question_creation_time":1605040090287,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/158168\/deep-learning-training-on-azure-steps-and-tutorial.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":10,
        "Question_score":0,
        "Question_body":"Hi MSFT Community,\n\nI followed this guide to set up a GPU: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/data-science-virtual-machine\/dsvm-ubuntu-intro\n\nVM: Standard NC12_Promo, 12 vCPUs, 112 Gib RAM\nOperating System: Linux\nOffer: Ubuntu-1804\n\nI am ready to start deep learning training but I am confused about what to do next. I am doing a medical image classification project. I have 1 millions images store in Azure blob now. Do I need to download them to my VM in order to train? Or is it a better way to access image efficiently?\n\nWhat are some good tutorials to set up the experiments? I've read a lot of documentation but still confused.\n\nThank you very much!\nBest Regards,\nClaire",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-11T01:10:40.68Z",
                "Answer_score":2,
                "Answer_body":"@gecheng-2063\ncheck on the below AI training modules.\nhttps:\/\/aischool.microsoft.com\/en-us\/services\/learning-paths\n\nAI Lab\nhttps:\/\/www.microsoft.com\/en-us\/ai\/ai-lab-projects\n\nAI module gallery\nhttps:\/\/gallery.azure.ai\/browse\n\n\n\n\nPlease don\u2019t forget to \"Accept the answer\" and \u201cup-vote\u201d wherever the information provided helps you, this can be beneficial to other community members.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How can I attach a managed disk to a Machine Learning Compute instance?",
        "Question_creation_time":1601637154150,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/115201\/how-can-i-attach-a-managed-disk-to-a-machine-learn.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Hello experts,\n\nI would like to attach a managed disk to my machine learning compute instance. Is that possible?\n\nThere is a possible overlap to the question Attach Disk to Virtual Machine, but steps doesn't seem to apply to ML compute instances.\n\nThanks in advance,",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-04T08:05:55.917Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nYou can attach your managed disk by following steps in Azure portal:\n\n\nMore details and limitation please see:\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-compute-target#azure-machine-learning-compute-managed\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"i am not able to select jupyter notebook in azure ML",
        "Question_creation_time":1604559071717,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/152224\/i-am-not-able-to-select-jupyter-notebook-in-azure.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-06T01:03:43.72Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. Azure ML Studio (Classic) notebooks feature retired on 4\/13\/2020. Your notebook would no longer be available if it wasn't saved by the deadline. However, the new Azure ML Studio supports Jupyter Notebooks in your workspace. Hope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"R model deployment with custom Docker image: \"ModuleNotFoundError: No module named 'azureml.api'\"",
        "Question_creation_time":1602855221470,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/129038\/r-model-deployment-with-custom-docker-image-34modu.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":6,
        "Question_score":1,
        "Question_body":"I am trying to deploy an R inference script to Azure ML Service Endpoint as an Azure Container Instance. I have made the following steps:\n\ncreated a custom Docker image from scratch and pushed it to the Azure Container Registry (associated with AML Workspace)\n\n\nregistered a custom environment in AML Workspace, based on the image in ACR\n\n\ndeployed R entry script (just a simple hello world script with init() and run() functions defined)\n\n\nthe inference configuration uses the custom AML environment\n\n\ndeployment is made with Azure ML R SDK\n\nThe container instance is created, but the endpoint startup runs into error. Here is the output from the container instance:\n\n 2020-10-16T12:56:21,639812796+00:00 - gunicorn\/run \n 2020-10-16T12:56:21,639290594+00:00 - iot-server\/run \n 2020-10-16T12:56:21,640405198+00:00 - rsyslog\/run \n 2020-10-16T12:56:21,735291424+00:00 - nginx\/run \n EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n 2020-10-16T12:56:23,736657191+00:00 - iot-server\/finish 1 0\n 2020-10-16T12:56:23,834747728+00:00 - Exit code 1 is normal. Not restarting iot-server.\n Starting gunicorn 20.0.4\n Listening at: http:\/\/127.0.0.1:31311 (11)\n Using worker: sync\n worker timeout is set to 300\n Booting worker with pid: 38\n \/bin\/bash: \/root\/miniconda3\/lib\/libtinfo.so.6: no version information available (required by \/bin\/bash)\n SPARK_HOME not set. Skipping PySpark Initialization.\n Exception in worker process\n Traceback (most recent call last):\n   File \"\/var\/azureml-server\/app.py\", line 43, in <module>\n     from azureml.api.exceptions.ClientSideException import ClientSideException\n ModuleNotFoundError: No module named 'azureml.api'\n    \n During handling of the above exception, another exception occurred:\n    \n Traceback (most recent call last):\n   File \"\/usr\/lib\/python3\/dist-packages\/gunicorn\/arbiter.py\", line 583, in spawn_worker\n     worker.init_process()\n   File \"\/usr\/lib\/python3\/dist-packages\/gunicorn\/workers\/base.py\", line 119, in init_process\n     self.load_wsgi()\n   File \"\/usr\/lib\/python3\/dist-packages\/gunicorn\/workers\/base.py\", line 144, in load_wsgi\n     self.wsgi = self.app.wsgi()\n   File \"\/usr\/lib\/python3\/dist-packages\/gunicorn\/app\/base.py\", line 67, in wsgi\n     self.callable = self.load()\n   File \"\/usr\/lib\/python3\/dist-packages\/gunicorn\/app\/wsgiapp.py\", line 49, in load\n     return self.load_wsgiapp()\n   File \"\/usr\/lib\/python3\/dist-packages\/gunicorn\/app\/wsgiapp.py\", line 39, in load_wsgiapp\n     return util.import_app(self.app_uri)\n   File \"\/usr\/lib\/python3\/dist-packages\/gunicorn\/util.py\", line 383, in import_app\n     mod = importlib.import_module(module)\n   File \"\/usr\/lib\/python3.8\/importlib\/__init__.py\", line 127, in import_module\n     return _bootstrap._gcd_import(name[level:], package, level)\n   File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n   File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n   File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n   File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n   File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n   File \"\/var\/azureml-server\/wsgi.py\", line 1, in <module>\n     import create_app\n   File \"\/var\/azureml-server\/create_app.py\", line 3, in <module>\n     from app import main\n   File \"\/var\/azureml-server\/app.py\", line 45, in <module>\n     from azure.ml.api.exceptions.ClientSideException import ClientSideException\n ModuleNotFoundError: No module named 'azure.ml'\n Worker exiting (pid: 38)\n Shutting down: Master\n Reason: Worker failed to boot.\n 2020-10-16T12:56:39,434787859+00:00 - gunicorn\/finish 3 0\n 2020-10-16T12:56:39,435715063+00:00 - Exit code 3 is not normal. Killing image.\n\n\n\nHow do I install the azureml.api dependency, which can not be found? It doesn't seem to be part of the Azure ML SDK. I have installed the following dependencies in my Dockerfile:\n\n RUN apt-get -y install python3-flask python3-rpy2 python3-azure python3-applicationinsights\n RUN pip install azureml-core\n\n\n\nI also have Miniconda installed. Pip refers to Miniconda's pip.\n\nOr, is this dependency available to install at all? Should I use some pre-defined AML environment as the base Docker image? (Note: I am currently using bare FROM: ubuntu). Suggestions how to find and use the base images are also welcome, since this is not documented very well.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-19T10:44:00.927Z",
                "Answer_score":1,
                "Answer_body":"@LauriLehman-8626 Thanks for the question. Here is the document to Create Custom Docker Base Images for Azure Machine Learning Environments for R people.\nWe have used the AzureML RScriptStep pipeline feature which allows you to point to CRAN or Github or custom URLS, but this requires authoring the pipeline in python or YAML.. In R You can also these arguments in the Azuremlsdk R estimator function: https:\/\/azure.github.io\/azureml-sdk-for-r\/reference\/estimator.html\nAnother option that are not available through conda install as part of the R script with install.packages(\u201cpath\/*.tar.gz\u201d, repos=NULL))\n\nOne of the challenges is that the build at runtime can take a while to prepare the environment. R likes to compile packages on Linux environments and a large package could have lots of dependencies which would take a while. This is an R on Linux\/PaaS thing, rather than specific to AzureML\n\nTo make start up fast we created a custom docker image where you can tightly control the image ahead of runtime. If you want to go in this direction you can find an example Dockerfile to get you started here..\nhttps:\/\/github.com\/Azure\/azureml-sdk-for-r\/blob\/master\/.azure-pipelines\/docker\/Dockerfile",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How much will it cost me to learn Azure Machine Learning?",
        "Question_creation_time":1589500691030,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/27214\/how-much-will-it-cost-me-to-learn-azure-machine-le.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I&#39;m trying to do the Azure Data Scientist Associate certification. I&#39;m on the first portion of learning exercises and it has me create a Machine Learning Workspace and then its had me create a VM which according to the Azure pricing calculator will cost me $367 a month. If I forget to shut down this VM could I get a bill for this much? Is there a way to have these VM&#39;s automatically shut down? Since I&#39;m only interacting with this VM via a web interface I&#39;m really worried that I&#39;m going to get stuck with some hefty bills after this training. Should I be concerned? The Azure Portal has a cost estimate section but it does not include any of my Machine Learning resources or workspaces so I&#39;m not sure how I can get a realistic estimate for how much this will cost me to complete this training.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-05-17T13:45:44.483Z",
                "Answer_score":0,
                "Answer_body":"Hello @SteveZaske-8007,\n\nI believe that you are trying to create a compute instance from ML portal ml.azure.com which gives you an option to stop or delete the instance but does not have an option to auto shutoff the instance since this feature is not available for compute instance.\n\nYou have an option to use the compute cluster type of compute which allows you to set the minimum\/maximum number of nodes. In this case to avoid being billed when the training is not in progress the minimum number of 0 will ensure you do not have any nodes running when not required. You can also set this from the SDK if required.\n\nFor example, if you are using the Basic plan and you you train a model for 100 hours using 10 DS14 v2 VMs on an Basic workspace in US West 2. For a billing month of 30 days, your bill will be as follows:\n\nAzure VM Charge: (10 machines $1.196 per machine) 100 hours = $1,196\n\nAzure Machine Learning Charge: (10 machines 16 cores $0 per core) * 100 hours = $0\n\nTotal: $1,196 + $0 = $1,196\n\nBut if you are using an Enterprise edition when it becomes generally available, it will have a machine learning surcharge (for training and inferencing). When this is enabled the calculator will be updated to give you an estimate of surcharge based on the amount of time you run the training and inferencing.\n\nSo, in the current scenario the charge for your training depends on the amount of time you use the VM. If you use compute instance type you need to ensure to stop or delete it when not required, If compute cluster type is used you can set the minimum number of nodes to 0 to avoid billing when there is no training.\n\nWe hope this helps.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-05-18T22:59:00.463Z",
                "Answer_score":0,
                "Answer_body":"Hi @SteveZaske-8007 , The good news is that you can create an Azure Machine Learning studio workspace for free. All you have to do is open any modern browser, and go to studio dot Azure ML dot net, and sign in using a live I.D. and you're ready to go. Now of course it's free, so there are some restriction, especially around how much compute you can consume, so there are some restrictions, you can use the absolutely free version, that is no credit card required, that is no Azure subscription needed. Certainly, if you have an Azure subscription, you can use it and that'll allow you to create a slightly more complex model, that may consume more compute. Maybe you want to import some data from an existing source, or some other data store that already might be on Azure, you can use datasets up to 10GB for free. so I think for more serious projects, you'll probably end up using your Azure subscription,",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"(Beginner\/New to Azure ML)Unable to execute Jupyter Notebook code in Azure ML",
        "Question_creation_time":1603639845287,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/138151\/beginnernew-to-azure-mlunable-to-execute-jupyter-n.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Hello all,\nWhile trying to follow official guide for MOC as described here:\nhttps:\/\/docs.microsoft.com\/en-in\/learn\/modules\/classify-images-custom-vision\/3-create-image-classifier\n\nI am stuck at step 3 under 'Download the exercise files':\n\nWhen the new notebook has been created, ensure that the compute instance you created previously is selected in the Compute box, and that it has a status of Running. Then, in the rectangular cell that has been created in the notebook, paste the following code:\n\n!git clone https:\/\/github.com\/MicrosoftDocs\/ai-fundamentals\n\nAnd same issue running jupyter notebook here (step 11 running the code to test deployment):\n\nhttps:\/\/docs.microsoft.com\/en-in\/learn\/modules\/create-regression-model-azure-machine-learning-designer\/deploy-service\n\n\n\n\nWhat could be missing,why am I unable to see the output of the execution, it was working fine 2 days back with old Compute Instance(even tried creating new instance but unable to see any output or import of github folder).\n\n\n\n\nRegards.\nAditya Garg",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-26T22:31:36.267Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. Here's a screenshot of how the output should look like. Have you tried clicking on the refresh button?",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How can I utilize multiple cores on Azure ML Studio VM's?",
        "Question_creation_time":1603703811737,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/139002\/how-can-i-utilize-multiple-cores-on-azure-ml-studi.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Hi. I have a python script which can be run either sequentially or in parallel (using concurrent.futures). On my local machine using the parallel option results in a considerably faster execution (nearly linear speed up). Running the same script inside an Experiment on Azure ML Studio I was not able to observe any speedup from the parallel version. At first I thought adding the following line conda_env.docker.arguments = [&#34;--cpuset-cpus=4&#34;] would help, but still the same. Therfore my question is, how can I enable the docker container to leverage multiple cores of the vm-instance? Kind Regard Kai",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-04T08:09:05.837Z",
                "Answer_score":0,
                "Answer_body":"Hello Kai,\n\nYou can easily change your VM with different cores according to your need. Please see following pic and let me know if you have any question.\n\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-11-04T08:13:06.12Z",
                "Answer_score":0,
                "Answer_body":"Hello Yutonn,\n\nI know how to change the #cores of my VM. The problem is, that these cores are not utilized.\nI guess it's somehow related to this issue https:\/\/stackoverflow.com\/questions\/15639779\/why-does-multiprocessing-use-only-a-single-core-after-i-import-numpy\n\nRegards\nKai",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AzureML and PowerBI compatible endpoint error - \"list index out of range\"",
        "Question_creation_time":1602771468233,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/127842\/azureml-and-powerbi-compatible-endpoint.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"I have produced a model that is deployed as an ACI, which I can send data to via the REST API in python using the code described here (https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service?tabs=python#call-the-service-python).\n\nHowever I have ran into a problem producing a PowerBI compatible endpoint which requires an inference schema described here (https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-advanced-entry-script#power-bi-compatible-endpoint).\n\nI have adapted the input samples as required and the deployment goes ahead fine and is displayed as healthy. Checking the JSON, all seems fine with the schema. However when I try to send some data using the first script using the REST API, all that is returned is \"list index out of range\". All that has changed is the addition of the inference schema entry script.\n\nAny idea what might be causing this error? I have tried to change a variety of things to do with the data being sent and the entry script but it always ends with the same error.\n\nThanks\n\n\n\n\nEDIT:\n\nI should also clarify that the model returns a probability output of each class using a wrapper for .predict() which works fine before adding this PowerBI compatibility.\n\n class SklearnModelWrapper(mlflow.pyfunc.PythonModel):\n         def __init__(self, model):\n             self.model = model\n         def predict(self, model_input):\n             return self.model.predict_proba(model_input)\n\n\n\nThis is a binary problem so the output for two rows of data is the format [[0.3, 0.7], [0.64, 0.36]] representing the probability for each class. I have tried this for the sample output in the schema and still no change, the same error is produced regardless of deploying a wrapped model that returns the probability per each class or a normal model that returns the class. Both work fine without the inference schema.\n\nEntry script:\n\n import numpy as np\n import pandas as pd\n import joblib\n from azureml.core.model import Model\n    \n from inference_schema.schema_decorators import input_schema, output_schema\n from inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType\n from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n    \n def init():\n     global model\n     #Model name is the name of the model registered under the workspace\n     model_path = Model.get_model_path(model_name = 'databricksmodelpowerbi2')\n     model = joblib.load(model_path)\n    \n #Provide 3 sample inputs for schema generation for 2 rows of data\n numpy_sample_input = NumpyParameterType(np.array([[2400.0, 78.26086956521739, 11100.0, 3.612565445026178, 3.0, 0.0], [368.55, 96.88311688311687, 709681.1600000012, 73.88059701492537, 44.0, 0.0]], dtype = 'float64'))\n pandas_sample_input = PandasParameterType(pd.DataFrame({'value': [2400.0, 368.55], 'delayed_percent': [78.26086956521739, 96.88311688311687], 'total_value_delayed': [11100.0, 709681.1600000012], 'num_invoices_per30_dealing_days': [3.612565445026178, 73.88059701492537], 'delayed_streak': [3.0, 44.0], 'prompt_streak': [0.0, 0.0]}))\n standard_sample_input = StandardPythonParameterType(0.0)\n    \n # This is a nested input sample, any item wrapped by `ParameterType` will be described by schema\n sample_input = StandardPythonParameterType({'input1': numpy_sample_input, \n                                             'input2': pandas_sample_input, \n                                             'input3': standard_sample_input})\n    \n sample_global_parameters = StandardPythonParameterType(1.0) #this is optional\n sample_output = StandardPythonParameterType([1.0, 1.0])\n    \n @input_schema('inputs', sample_input)\n @input_schema('global_parameters', sample_global_parameters) #this is optional\n @output_schema(sample_output)\n    \n def run(inputs, global_parameters):\n     try:\n         data = inputs['input1']\n         # data will be convert to target format\n         assert isinstance(data, np.ndarray)\n         result = model.predict(data)\n         return result.tolist()\n     except Exception as e:\n         error = str(e)\n         return error\n\n\n\nPrediction script:\n\n import requests\n import json\n from ast import literal_eval\n    \n # URL for the web service\n scoring_uri = ''\n ## If the service is authenticated, set the key or token\n #key = '<your key or token>'\n    \n # Two sets of data to score, so we get two results back\n data = {\"data\": [[2400.0, 78.26086956521739, 11100.0, 3.612565445026178, 3.0, 0.0], [368.55, 96.88311688311687, 709681.1600000012, 73.88059701492537, 44.0, 0.0]]}\n # Convert to JSON string\n input_data = json.dumps(data)\n    \n # Set the content type\n headers = {'Content-Type': 'application\/json'}\n ## If authentication is enabled, set the authorization header\n #headers['Authorization'] = f'Bearer {key}'\n    \n # Make the request and display the response\n resp = requests.post(scoring_uri, input_data, headers=headers)\n print(resp.text)\n    \n result = literal_eval(resp.text)",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Parquet file registered in a Tabular format is loaded with worng values",
        "Question_creation_time":1602081582550,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/119459\/parquet-file-registered-in-a-tabluar-format-is-loa.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":3,
        "Question_score":1,
        "Question_body":"I'm facing an issue that pandas DataFrames loaded from the following two datasets are not identical although the same parquet file is used to register.\n\nDataFrame loaded with \"to_pandas_dataframe()\" from a dataset registered in a Tabular format\n\n\nDataFrame loaded with \"pandas.read_parquet()\" from a dataset registered in a File format\n\nSpecifically, DataFrame from the Tabular format has wrong values in some fields. Let's say, a DataFrame has 5 rows, and a field \"col1\" should has values [\"A\", \"A\", \"B\", \"C\", \"C\"] from the top, but it has [\"A\", \"B\", \"B\", \"C\", \"C\"]. The second element should have \"A\", but somehow it has \"B\". Wrong values are not completely unknown or broken values, but other values used in the same field seem to be set.\n\n\n\n\nI'd like to know there is a known issue to see how the situation (fix plan, etc.) is going. I cannot give reproducible environment here because this issue happened with internal dataset, and I tried but couldn't reproduce it with toy dataset that I can share in public.\n\n\n\n\nEnvironment that I created the parquet file\n- OS: Windows 10\n- Python: 3.7.4\n- pandas: 0.25.1\nThe parquet file was created with \"df.to_parquet(output_path, index=False)\" without any other args.\n\n\n\n\nEnvironment that I loaded dataset registered on AzureML\n- Notebook in AzureML workspace with default environment.\n\nPseudo script used to load dataset\nFor Tabular dataset\n\nfrom azureml.core import Dataset, Workspace\nws = Workspace.from_config()\ndf = Dataset.get_by_name(workspace=ws, name='dataset_name1').to_pandas_dataframe()\n\n\n\nFor File dataset\n\nfrom pathlib import Path\nfrom azureml.core import Dataset, Workspace\nimport pandas as pd\nws = Workspace.from_config()\nds = Dataset.get_by_name(workspace=ws, name='dataset_name2')\nwith ds.mount() as m:\n    path = str(Path(m.mount_point) \/ 'filename.parquet')\n    df = pd.read_parquet(path)",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-09T06:02:16.547Z",
                "Answer_score":0,
                "Answer_body":"@KengoWada-6837 we would recommend to raise a Azure support desk ticket from Help+Support blade from Azure portal. This will help you to share the internal dataset details securely and work with an engineer who can provide more insights about the issue that if it can be replicated.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Can machine learning rewrite\/recognize text to one truth",
        "Question_creation_time":1604082069767,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/146531\/can-machine-learning-rewriterecognize-text-to-one.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"Hi there,\n\nMy dataset has a lot of productnames, all the product of the shops are not written by the same.\nSo i want azure can recognize if it's the same:\n\nSo if the productgroup is X and productname looks like\/contains tomato. The product is tomato.\nExample: Tomatoes, tomato, bunch of tomatoes, a bag of tomatoes, small tomatoes = new colom tomato.\n\nHopefully someone can help me with this?\n\nThanks a lot.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-02T09:51:08.223Z",
                "Answer_score":0,
                "Answer_body":"@Borget-8487 Thanks for the details. With a variety of data inputs, Can you try fuzzy matching\/regex\u2019s or Azure Search would be a complete Information Retrieval engine. Azure Search works well for this.\nbut using full Lucene syntax you can do fuzzy and proximity search.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/search\/search-query-lucene-examples",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Parameters Tuning for Randomforest",
        "Question_creation_time":1603934642440,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/143528\/parameters-tuning-for-randomforest.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"I followed the samples from DP-100 lab 8A.\n\nhttps:\/\/github.com\/MicrosoftLearning\/DP100\/blob\/master\/08A%20-%20Tuning%20Hyperparameters.ipynb\n\nI tried to parameter tunning for randomforest regressor on Boston Data.\n\nHowever, the code is running. I am not able to get metric and the output of the result.\n\nWhat is the problem.\n\n\n\n\n\n %%writefile $experiment_folder\/diabetes_training.py\n # Import libraries\n import argparse\n import joblib\n import os\n from azureml.core import Run\n import pandas as pd\n import numpy as np\n from sklearn.model_selection import train_test_split\n from sklearn.linear_model import LogisticRegression\n from sklearn.metrics import roc_auc_score\n from sklearn.metrics import roc_curve\n    \n # Set regularization parameter\n parser = argparse.ArgumentParser()\n parser.add_argument(&#39;--regularization&#39;, type=float, dest=&#39;reg_rate&#39;, default=0.01, help=&#39;regularization rate&#39;)\n args = parser.parse_args()\n reg = args.reg_rate\n    \n # Get the experiment run context\n run = Run.get_context()\n    \n # load the diabetes dataset\n print(&#34;Loading Data...&#34;)\n diabetes = run.input_datasets[&#39;diabetes&#39;].to_pandas_dataframe() # Get the training data from the estimator input\n    \n # Separate features and labels\n X, y = diabetes[[&#39;Pregnancies&#39;,&#39;PlasmaGlucose&#39;,&#39;DiastolicBloodPressure&#39;,&#39;TricepsThickness&#39;,&#39;SerumInsulin&#39;,&#39;BMI&#39;,&#39;DiabetesPedigree&#39;,&#39;Age&#39;]].values, diabetes[&#39;Diabetic&#39;].values\n    \n # Split data into training set and test set\n X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n    \n # Train a logistic regression model\n print(&#39;Training a logistic regression model with regularization rate of&#39;, reg)\n run.log(&#39;Regularization Rate&#39;,  np.float(reg))\n model = LogisticRegression(C=1\/reg, solver=&#34;liblinear&#34;).fit(X_train, y_train)\n    \n # calculate accuracy\n y_hat = model.predict(X_test)\n acc = np.average(y_hat == y_test)\n print(&#39;Accuracy:&#39;, acc)\n run.log(&#39;Accuracy&#39;, np.float(acc))\n    \n # calculate AUC\n y_scores = model.predict_proba(X_test)\n auc = roc_auc_score(y_test,y_scores[:,1])\n print(&#39;AUC: &#39; + str(auc))\n run.log(&#39;AUC&#39;, np.float(auc))\n    \n os.makedirs(&#39;outputs&#39;, exist_ok=True)\n # note file saved in the outputs folder is automatically uploaded into experiment record\n joblib.dump(value=model, filename=&#39;outputs\/diabetes_model.pkl&#39;)\n    \n run.complete()\n from azureml.core import Experiment\n from azureml.train.sklearn import SKLearn\n from azureml.train.hyperdrive import GridParameterSampling, MedianStoppingPolicy, HyperDriveConfig, PrimaryMetricGoal, choice, normal\n from azureml.widgets import RunDetails\n    \n    \n # Sample a range of parameter values\n params = GridParameterSampling(\n     {\n         # Tuning the Parameters\n            \n         &#39;--max_depth&#39;:choice(70,100,130,160)\n     }\n )\n    \n    \n # Get the training dataset\n boston_ds = ws.datasets.get(&#34;boston dataset&#34;)\n    \n # Create an estimator that uses the remote compute\n hyper_estimator = SKLearn(source_directory=experiment_folder,\n                           inputs=[boston_ds.as_named_input(&#39;boston&#39;)], # Pass the dataset as an input...\n                           pip_packages=[&#39;azureml-sdk&#39;], # ...so we need azureml-dataprep (it&#39;s in the SDK!)\n                           entry_script=&#39;train_boston.py&#39;,\n                           compute_target = training_cluster,)\n    \n    \n #early_termination_policy = MedianStoppingPolicy(evaluation_interval=1, delay_evaluation=5)\n    \n    \n # Configure hyperdrive settings\n hyperdrive = HyperDriveConfig(estimator=hyper_estimator, \n                           hyperparameter_sampling=params, \n                           policy=None, \n                           primary_metric_name=&#39;MAE&#39;, \n                           primary_metric_goal= PrimaryMetricGoal.MINIMIZE, \n                           max_total_runs=6,\n                           max_concurrent_runs=4)\n    \n # Run the experiment\n experiment = Experiment(workspace = ws, name = &#39;boston_training_hyperdrive&#39;)\n run = experiment.submit(config=hyperdrive)\n    \n # Show the status in the notebook as the experiment runs\n RunDetails(run).show()\n run.wait_for_completion()",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-11-01T12:18:39.53Z",
                "Answer_score":0,
                "Answer_body":"@TomZhou-0695 Thanks for the details, Here are the azure ml samples..\n\nPlease follow the below doc for azure machine learning.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error: Scoring FE IP address not updated yet, when enabling the use of internal load balancer",
        "Question_creation_time":1602573604000,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/124588\/error-34scoring-fe-ip-address-not-updated-yet34-wh.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hello, currently, I'm having issues to enable private load balancer after attaching an existing AKS Cluster to AML Workspace. The error message \"Scoring FE IP address not updated yet\" is displayed when trying to enable private load balancer by following the instructions at https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-secure-inferencing-vnet?tabs=azure-cli#internal-aks-load-balancer. The AKS Cluster is in a separate VNet than the AML Workspace. The two VNet have peered. Also, I've tried using Azure CLI but receiving the same error message. Can you provide some help on resolving this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-14T13:38:20.347Z",
                "Answer_score":0,
                "Answer_body":"@AllenAzemia-2438 Thanks for the question. Details of creating a private IP link is here.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-network-security-overview#use-private-ips-with-azure-kubernetes-service\nfor secure AKS inference deployment, request an inbound NSG rule on port 80.\n\nThis rule is needed so that scoring endpoint can be called from outside the VNet. IP shown is not static but is the scoring endpoint IP.\n\nCurrently all the resources needs to be in the same VNet since AML workspace doesn\u2019t support multiple private endpoints but AKS cluster can be in its own subnet with the VNet. We have forwarded to the product team to check on this.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-10-21T05:12:01.293Z",
                "Answer_score":2,
                "Answer_body":"@ramr-msft We've resolved the issue. The AKS MSI did not have NetworkContributer Reader role assigned on the VNet which we thought that had already been applied. The AML workspace doesn't need to be private. It works for both AKS NetworkType (i.e. kubenet and Azure CNI).",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"\"LineTooLong('got more than 65536 bytes when reading the header line\" error while running a python code on MSML 9.3 using az ml admin diagnostic code option",
        "Question_creation_time":1604054581813,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/145900\/34linetoolong39got-more-than-65536-bytes-when-read.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"\"LineTooLong('got more than 65536 bytes when reading the header line\" error while running a python code on MSML 9.3 using az ml admin diagnostic code option.\n\ncould anyone help to figure out the issue here ?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Consume Azure ML Web Service with Postman: how to pass arguments?",
        "Question_creation_time":1603965300457,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/144230\/consume-azure-ml-web-service-with-postman-how-to-p.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"Is it possible to pass parameters to an Azure ML Web Service with Postman? I created an R web service endpoint that runs in an Azure Container Instance. My run function has one argument (\"data\"). I can call the web service using Azure ML R SDK (using invoke_webservice()) and the input parameter is read successfully from the request content. The input is constructed like:\n\n toJSON(data.frame(data=\"This is my test string\"))\n\n\n\nResult:\n\n [{\"data\": \"This is my test string\"}]\n\n\n\nIf I create a Postman request and copy the input to the request body, the input parameter is not passed to the web service. The web service can return a static output to Postman but the variable data is always empty. Is this a property of the ML Web Service? If not, how can I set up the request body so that the argument is read successfully? I have tried many variations, but none have worked.\n\nI have set content-type header to application\/json. I don't have authentication in the web service, since it is just a test instance.\n\nUltimately, we need to call the web service with C# from Azure Function. I know that we can use the C# template from documentation and it can probably pass the parameter to the web service, but it would be nice to be able to test the web service with Postman.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-29T12:55:26.077Z",
                "Answer_score":1,
                "Answer_body":"Try this in postman.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Variable importance in Linear regression",
        "Question_creation_time":1603453945917,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/136931\/variable-importance-in-linear-regression.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Hi,\n\nAm running a Linear regression model in Azure ML studio having multiple features(both numeric and categorical).\n\nIs there a way to get the important features among all the given input features?\n\nFrom the train model I see weights assigned to each of the variable. Does Azure ML regression normalize the variables before running the model. If so can we assume this weight for the important features ?\n\nCan we export this weights to csv file ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-23T22:04:46.733Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. AML has two modules for feature selection, please check out Filter Based Feature Selection and Permutation Feature Importance. Regarding the weights, are you referring to the output from regression model? If so, here's a description of the output parameters. To export model results, you can use the export data module to export results and data to any of the supported cloud services. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"If on Azure any reason not to use the Azure ML platform vs a dedicated VM and azure functions",
        "Question_creation_time":1603468321273,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/137047\/if-on-azure-any-reason-not-to-use-the-azure-ml-pla.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"I come from a full stack dev background and I don't know that much about ML, just evaluating a proposal. We have Azure web apps, Azure SQL and Azure BI for our SaaS. Seems it would make more sense to use the Azure ML platform and have it create the private endpoints and manage deployment, less setup...\nThis is more for text parsing, good and bad messages and suggestion like spam detection.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-23T20:42:31.993Z",
                "Answer_score":0,
                "Answer_body":"Hi, if you're going to be building and deploying ML solutions\/pipelines, Azure ML offers great flexibility. AML offers code, no-code, and auto-ml options for ml workflows. AML also enables you to manage all of your ML resources in your workspace and offers MLOPs. Also, the ability to deploy a machine learning model to Azure Functions is currently in preview. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Can't create dataset from csv file - error: 'Delimiter' is not specified or invalid.",
        "Question_creation_time":1603103147810,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/131015\/can39t-create-dataset-from-csv-file-error-39delimi.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"I have got a problem. I can't add my csv files to datasets. Every time I have got error:\n\n\"message\": \"'Delimiter' is not specified or invalid.\"\n\nIs there anyway to specified this while uploading csv file?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-23T03:59:01.367Z",
                "Answer_score":0,
                "Answer_body":"@Aki-4708 We have tried with the dataset downloaded from here,We are able to successfully create the dataset in ml.azure.com.\n\nPlease find the snapshot for the same. If possible please share the csv file to debug on this.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-10-23T14:21:39.537Z",
                "Answer_score":1,
                "Answer_body":"Thank for your replay. I have got some different CSV file, but I find a solution. You need first to upload file with checked \"Skip data validation\" option, next in Setting and preview set the delimiter and go back and again upload a file with working validation. Every thing now works fine.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Registered Dataset is not logged as reference in Azure Machine Service Experiment",
        "Question_creation_time":1601553618217,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/114019\/registered-dataset-is-not-logged-as-reference-in-a.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":7,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Hi there,\n\nI have tried executing the notebook \"tutorial-1st-experiment-sdk-train.ipynb\" given by Azure as part of the tutorial in Azure Machine Learning service itself.\n\nThe only change I made was, rather taking the input directly from package, I registered the dataset first and referred that in this notebook. My intention was to see how input dataset can be tracked in the experiment.\n\nBut, no luck. I was able to successfully execute the notebook, but in experiment, \"Input datasets\" was blank, not referenced, though I used a registered latest version of dataset from Azure as my input.\n\nHow do we tag the input dataset to an experiment when executing from Azure Machine Learning Notebook?\n\nThanks,",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How do I deploy R code & models as a web service on a ML Ubuntu server deployed on Azure cloud, accessible from the Internet?",
        "Question_creation_time":1602754539597,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/127379\/how-do-i-deploy-r-code-amp-models-as-a-web-service.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hi,\n\nI would like to build a simple model in R and deploy it on a Machine Learning Server instance (Linux Ubuntu 16.04) that I created in Azure.\nThis web service should be accessible from the Internet, through REST API calls.\n\nI tried to use the approach described here: https:\/\/docs.microsoft.com\/en-us\/machine-learning-server\/operationalize\/quickstart-publish-r-web-service\n\nThe problem is that I cannot login from R into the ML Server instance, namely, the following command fails:\n\n remoteLogin(&#34;http:\/\/myhost.switzerlandnorth.cloudapp.azure.com:12800&#34;, username = &#34;myusername&#34;, password = &#34;mypassword&#34;)\n\n\n\nOn the other hand, I can log into the ML Server instance from the command line, through ssh: the following command\n\n ssh  myusername:12800@myhost.switzerlandnorth.cloudapp.azure.com\n\n\n\nopens a terminal on the ML Server machine (the terminal greeting is &#34;Welcome to the Linux Data Science Virtual Machine on Azure!&#34;).\n\n\n\n\nWhat I am trying to achieve is explained in this figure:\n\nhttps:\/\/docs.microsoft.com\/en-us\/machine-learning-server\/operationalize\/configure-machine-learning-server-one-box\n\nIn that picture, I would want the &#34;one-box configuration&#34; to run entirely on the Microsoft Cloud (not on my laptop, or on other servers).\nAnd I would like to access the R models from a front-end app (deployed elsewhere) through authenticated REST API calls to the &#34;one-box&#34;.\nThis is how I provisioned my Linux Data Science VM on Azure:\n\nhttps:\/\/azuremarketplace.microsoft.com\/en-us\/marketplace\/apps\/deploy-r.operationalization?tab=overview\n\nThis is the kind of R script that I&#39;d like to use to deploy my R models on that DSVM:\nhttps:\/\/docs.microsoft.com\/en-us\/machine-learning-server\/operationalize\/quickstart-publish-r-web-service\n\nThis is what I&#39;m trying to do:\nhttps:\/\/docs.microsoft.com\/en-us\/machine-learning-server\/r-reference\/mrsdeploy\/mrsdeploy-package\n\nBut all examples I could find for the remoteLogin() function use a localhost server, not a remote server on the Microsoft Azure Cloud, see e.g.\n\n remoteLogin(&#34;https:\/\/localhost:1280&#34;, session=TRUE, diff=TRUE, commandline=TRUE)\n\n\n\nSee e.g. https:\/\/blog.revolutionanalytics.com\/2017\/03\/running-your-r-code-azure.html\n\nI searched the Q&amp;A forum, but could only find threads that are vaguely related to my issue, such as:\n\nhttps:\/\/social.msdn.microsoft.com\/Forums\/en-US\/b5cc5cff-ad46-4772-8d01-793dd067e4a6\/pass-web-service-input-to-r-script?forum=MachineLearning\nhttps:\/\/social.msdn.microsoft.com\/Forums\/en-US\/b47b0dcf-d92d-4bdf-9a19-f8ba0f5a29cc\/r-web-service-input?forum=MachineLearning\nhttps:\/\/social.msdn.microsoft.com\/Forums\/en-US\/598b0e20-5f12-47a2-8d8a-81dbff83ef6d\/how-to-consume-machine-learning-webservice-using-r?forum=MachineLearning\n\nAlso see here for related threads:\nhttps:\/\/medium.com\/@RonakTalreja\/deploying-apis-the-microsoft-way-ffde1fdd027a\nhttps:\/\/docs.microsoft.com\/en-us\/previous-versions\/machine-learning-server\/install\/operationalize-r-server-one-box-config",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-15T15:04:31.877Z",
                "Answer_score":0,
                "Answer_body":"@RenatoVitolo-8638 Azure Machine learning designer's execute R script allows you to run your R models on Azure ML with various compute sizes that are based on the latest generation of Azure VMs. Along with the other data processing modules of Azure ML designer you can create pipelines that can be deployed as CD\/CI model & web services can be deployed using a single click which also provides the ability to control access\n\nMachine Learning server can be still used but there are no active updates that could hamper future upgrades. You can try this ARM template deployment for ubuntu which deploys the following architecture & could cost more than designer's module architecture.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Unable to deploy a autoML as a webservice without using C#, Go, Java, or Python (just a browser)",
        "Question_creation_time":1603290567957,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/134024\/unable-to-deploy-a-automl-as-a-webservice-without.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"I am running this tutorial: https:\/\/docs.microsoft.com\/de-de\/azure\/machine-learning\/tutorial-first-experiment-automated-ml\n\nand struggle under \"next steps\" to deploy this model to a browser user interface of some kind (where I can manually type in the input values and press \"predict\" to get the output value).\n\nBackground: I would like to present this for a seminar \"AI without any code\" and hence I will not call this REST-API in any other place but try to stay in the (Azure) web ecosystem. Any chance to get such a webinterface (functionality)?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-21T22:38:57.64Z",
                "Answer_score":0,
                "Answer_body":"Thanks for reaching out. Currently, Azure AutoML does not support consuming deployed web services via UI. You can create a client for the service, or use python to consume the web service via Azure ML Notebooks. Sorry for the inconvenience.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"When I try to create a workshop for ml, why I get this error each time?",
        "Question_creation_time":1601774826563,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/116011\/when-i-try-to-create-a-workshop-for-ml-why-i-get-t.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"{\"code\":\"InvalidTemplate\",\"message\":\"Deployment template validation failed: 'The template resource 'storageAccountResourceGroupName' at line '101' and column '44' is not valid: The template function 'RESOURCEGROUP' is not expected at this location. Please see https:\/\/aka.ms\/arm-template-expressions for usage details.. Please see https:\/\/aka.ms\/arm-template-expressions for usage details.'.\",\"additionalInfo\":[{\"type\":\"TemplateViolation\",\"info\":{\"lineNumber\":101,\"linePosition\":44,\"path\":\"properties.template.parameters.storageAccountResourceGroupName\"}}]}",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-05T04:17:39.087Z",
                "Answer_score":2,
                "Answer_body":"Yeah, Vivek... sometimes it happens.\nSo create a resource group first separately, instead of creating it while creating the workspace and try to create a workspace.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Error when Visualizing Dataset in Microsoft Azure Machine Learning Studio",
        "Question_creation_time":1602791972497,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/127980\/error-when-visualizing-dataset-in-microsoft-azure.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"In Azure Machine learning Studio, I have imported a dataset from a locally stored spreadsheet. In the designer, I drag the dataset into the workspace, right click, and select 'Visualize. I get the following error:\n\n\"Unable to visualize this dataset. This might be because your data is stored behind a virtual network or your data does not support profile\". I've searched for hours for a remedy, but find nothing.\n\nWhat do I do to fix this error?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-19T17:33:57.01Z",
                "Answer_score":0,
                "Answer_body":"@DanaShields-7459 I have tried this scenario with my workspace and i was able to replicate the message you have seen. It looks like you are using the Dataset type as File while creating the dataset which is causing the issue. Please register the dataset as Tabular type and then use the dataset in designer. This should show you the preview of the data. Here is a screen shot from my workspace of the designer.",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Batch scoring pipeline NodeStartError \/ StorageErrorException",
        "Question_creation_time":1599466176397,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/88085\/batch-scoring-pipeline-nodestarterror-storageerror.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Hello,\n\nI'm trying to build a batch scoring pipeline in Azure ML using this Microsoft MLOpsPython repository. (https:\/\/github.com\/microsoft\/MLOpsPython)\n\nHowever, when I run the pipeline it fails at the batch scoring step and it says:\n\n User program failed with NodeStartError: Failed to start node after 10 tries. Please check logs for error. You can check logs\/readme.txt for the layout of logs.\n\n\n\nI went to the logs in the blob storage > azureml > [run id] > logs > sys > node > [ip] > _boot.txt and found these errors:\n\n azure.storage.blob._generated.models._models_py3.StorageErrorException: Operation returned an invalid status 'Specified feature is not yet supported for hierarchical namespace accounts.'\n    \n azure.core.exceptions.HttpResponseError: Specified feature is not yet supported for hierarchical namespace accounts.\n    \n TypeError: Object of type AioHttpTransportResponse is not JSON serializable\n\n\n\n\nI tried to Google these errors but I couldn't find any info.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-07T15:55:43.487Z",
                "Answer_score":0,
                "Answer_body":"@AxelVandevelde Are you using a storage account that supports hierarchical namespace? It looks like this account is not general purpose v2 storage account. Could you please try to run the same pipelines after confirguring a general purpose v2 storage account?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-09-22T09:59:13.407Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nI have exactly the same problem and the same error messages. I verified my storage account and I use a general purpose v2 storage...\nAny other idea?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-10-19T15:37:13.747Z",
                "Answer_score":0,
                "Answer_body":"Having the same problem. I also confirmed that my storage account is general purpose v2",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure machine learning data export module failure",
        "Question_creation_time":1602687603067,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/126502\/azure-machine-learning-data-export-module-failure.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"I want to export the data from my batch flow with the use of the data export module. Tried multiple file shares but get the following error.\n\n\n\n\nUser program failed with UserError: ScriptExecutionException was caused by WriteStreamsException.\nWriteStreamsException was caused by UnexpectedException.\nUnexpected exception while writing files with writer 'delimited'.\nStreamAccessException was caused by NotFoundException.\nFile Share '[REDACTED]' does not exist at '[REDACTED]'.\n| session_id=e1ee8699-3a94-4ea6-ab5d-f5bb945d56f3\n\n\n\n\nThe file share name is the Azure named file share name or is this something else. Cannot find an eample.\n\n\n\n\n\n\nThe export works to local ML workspace, but this doesn't accept folders creation.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-15T01:47:10.747Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nThanks for reaching out to us. The file share name is the name of FILE_SHARE_CONTAINER\n\nPlease refer to below document for more details:\n\nExport data module: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/export-data\n\nData storage - Azure File Share: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-access-data#azure-file-share\n\n\n\n\nPlease let me know if you have more questions.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"i cant access machine learning workspace",
        "Question_creation_time":1602927883520,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/129615\/i-cant-access-machine-learning-workspace.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"good day\n\nim trying to learn data science vi amicrosoft docs learn and i cant access the machine learning workspace,it keeps saying oops cannot create market place item.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-17T12:41:22.483Z",
                "Answer_score":1,
                "Answer_body":"Try to log out and login again else try after sometime by activating sandbox subscription again.\n\nAlso note - Microsoft learn related questions are not supported here\n\nPlease don't forget to Accept Answer and Up-vote if the response helped -- Vaibhav",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is it possible to migrate Machine learning from Classic Portal to ARM Portal?",
        "Question_creation_time":1601646927710,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/115313\/is-it-possible-to-migrate-machine-learning-from-cl.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Hi there, do we know if it's possible to migrate Machine learning from Classic Portal to ARM Portal without having to do it manully?\n\nThis would include trained models etc.\n\nThanks\nGregor",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-11T18:01:43.087Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nIf you mean you want to migrate your resource from Azure Machine Learning Studio (Classic) to Azure Machine Learning, there is not a tool for auto-migration from V1 to V2 for now and future since the architecture of studio(classic) and machine learning studio is totally different. So I don't think it's easy to migrate. But we will have plan for migration in next few month, there should be a way to migrate from studio(classic) to machine learning studio with effort.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Databrick workspace linking to Azure Machine Learning workspace error unable to get Workspace.from_config()",
        "Question_creation_time":1594145605387,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/43845\/azure-databrick-workspace-linking-to-azure-machine.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":35,
        "Question_score":2,
        "Question_body":"We are in a POC of Azure Databricks and Azure Machine Learning integration so that we can advance our MLOps practice.\n\nWe have been dealing the with workspace linking issue for the past few weeks and have hit a wall. We worked with Databricks and search the internet for solution but were not successful. As AML is still in Preview, documentation may not be all there.\n\nI think this example below is the most recent and calls out how the linking should work. Is the statement highlighted below correct and if so, is there detail configuration that we are missing besides clicking the \"Link Azure ML Workspace\" button?\n\n[https:\/\/tsmatz.github.io\/azure-databricks-exercise\/exercise10-mlflow.html][1]\n\nNote : Here (in this hands-on) we connect to an Azure Machine Learning workspace by running Python code, however, you can now use the following \"Link Azure ML Workspace\" button (simplified integrated experience) in Azure Databricks launcher page to connect a new or existing workspace. Once you have linked with this experience, you don't need to run the following ws.write_config(), Workspace.from_config(), and mlflow.set_tracking_uri().\n\nWe have done the following.\n1. Linked the workspace via \"Link Azure ML Workspace\" button\n2. Run the attached MLFLow + AML \u2013 Combined.dbc\n3. Failure in Cmd 15\nws = Workspace.from_config()\nUserErrorException: UserErrorException:\n\n\nUserErrorException Traceback (most recent call last)\n<command-4338604541924184> in <module>\n3\n4\n----> 5 ws = Workspace.from_config()\n6 exp = \"\/adb\/XXXXXXXXXXXXXXX\/XXXXXXXXXXXX\/Users\/######@#######.com\/MLFlow + AML - Combined\"\n7 runs = list(exp.get_runs())\n\n\/databricks\/python\/lib\/python3.7\/site-packages\/azureml\/core\/workspace.py in from_config(path, auth, _logger, _file_name)\n272 'We could not find config.json in: {} or in its parent directories. '\n273 'Please provide the full path to the config file or ensure that '\n--> 274 'config.json exists in the parent directories.'.format(normalized_path))\n275\n276 subscription_id, resource_group, workspace_name = project_info.get_workspace_info(\n\nUserErrorException: UserErrorException:\nMessage: We could not find config.json in: \/databricks\/driver or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.\nInnerException None\nErrorResponse\n{\n\"error\": {\n\"code\": \"UserError\",\n\"message\": \"We could not find config.json in: \/databricks\/driver or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.\"\n}\n}\n4. Config.json manually place into directory path specified in error message\n\n\n\n Perform workspace write_config(). But, forces interactive authentication which is blocked by our organization policy. \n\nBesides performing the \"Link Azure ML Workspace\" via the button from Databricks, we have not performed any other configuration. Based on the documentation, it should just work. Appreciate any assistance.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-09T06:20:07.913Z",
                "Answer_score":0,
                "Answer_body":"@tkdebug-4414 Thanks for the details. Can you please try to authenticate successfully using the following approach.\n\n\n\n\nfrom azureml.core.authentication import InteractiveLoginAuthentication\ninteractive_auth = InteractiveLoginAuthentication(tenant_id=\"<tenantID>\")\n\n\n\n\nws = Workspace(subscription_id=\"<>\",\nresource_group=\"rg-test-auseast-aidf-ml\",\nworkspace_name=\"mlworkspace-test-auseast-aidf\",\nauth=interactive_auth)",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Delimeter error while adding new dataset in ml service",
        "Question_creation_time":1602240911150,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/121529\/delimeter-error-while-adding-new-dataset-in-ml-ser.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":2,
        "Question_score":0,
        "Question_body":"Hello,\nI have problem with adding new dataset in ml service. After upload i'm getting below error (screen)\n\n\n\n\n\nI think is a new issue, because few days ago everything was good.\nIn my csv file is semicolon delimeter.\n\nThank you in advance!",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-09T12:06:42.077Z",
                "Answer_score":0,
                "Answer_body":"This file could contains sensitive data, i'm not sure about that, so i encrypted file content, but issue still appears.31130-test.txt\n\n\n\n\n\nJust change txt extension to csv.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-10-12T09:03:36.58Z",
                "Answer_score":0,
                "Answer_body":"@MateuszOrzymkowski-8017 Thanks for the details. We have checked with your 31130-test.txt and able to create the dataset successfully without any issue. Please find the snapshot for the same. Could you retry or If you still see an issue please raise a support issue against ML workspace from the Help + Support blade in Azure portal and this will help you to share the details securely and work with an engineer who can provide more insights about the issue that if it can be replicated.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Endpoint Wont deploy on AKS with Azure ML Studio",
        "Question_creation_time":1600005134313,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/93418\/azure-ml-endpoint-won39t-deploy-on-aks-with-azure.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":1,
        "Question_body":"Got problem while deploying Azure ML real-time Endpoint on AKS with Azure ML Studio. It remains in Transitioning state indefinitely. Looked in AKS event logs and found that error is\n\nFailed to pull image\n\"viennaglobal.azurecr.io\/azureml\/azureml_f7815e0137b51ac1464986018a7cb849\":\n[rpc error: code = Unknown desc = Error response from daemon: Get\nhttps:\/\/viennaglobal.azurecr.io\/v2\/azureml\/azureml_f7815e0137b51ac1464986018a7cb849\/manifests\/latest:\nunauthorized: Application not registered with AAD., rpc error: code = Unknown\ndesc = Error response from daemon: Get\nhttps:\/\/viennaglobal.azurecr.io\/v2\/azureml\/azureml_f7815e0137b51ac1464986018a7cb849\/manifests\/latest:\nunauthorized: authentication required, visit https:\/\/aka.ms\/acr\/authorization\nfor more information.]\n\nIt repeat this action with no success. This Inference cluster created with Azure ML Dashboard, and it worked week ago without any unauthorized problems. Tried to create new inference clusters, endpoints but with no success",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-14T16:49:36.553Z",
                "Answer_score":0,
                "Answer_body":"@Eugene-3520 Thanks for the question.This is likely because you don't permission to deploy to AKS. Can you share your role definition?We have forwarded to the product team to check on this.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-assign-roles#frequently-asked-questions",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"timestamp is in POSIXlt vector format in Azure Auto ML",
        "Question_creation_time":1601961656490,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/117596\/timestamp-is-in-posixlt-vector-format-in-azure-aut.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"What if timestamp is in POSIXlt vector format in Azure Auto ML? I am putting data in timestamp column in azure ML studio and it&#39;s not detecting",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-07T06:22:26.533Z",
                "Answer_score":0,
                "Answer_body":"@AmogiBasavarajRajkumar-8012 Thanks for spotting this. Yes, this is a limitation in the UI to recognize the posix timestamp format. Our team has taken this up as a feature request to support this in the future releases.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Best Practices for Routing Requests within Inference Clusters",
        "Question_creation_time":1601043259400,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/107990\/best-practices-for-routing-requests-within-inferen.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Hi,\n\nI have a Kubernetes Service attached as an inference cluster to an azure machine learning workspace. I have deployed multiple models to that the AKS service, each with their own endpoints. I plan to configure this such that I just need to send the request to one main endpoint, which after applying some conditions, will redirect the request to one of the endpoints (e.g. redirect the request to the appropriate model). Are there any best practices to approach this problem?\n\nThere seems to be an Azure ML router using azureml-fe that does something similar, but I cannot find any documentation about it.\n\nThanks,\nLawrence",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-05T21:49:22.66Z",
                "Answer_score":0,
                "Answer_body":"Hello @LawrenceWong-1664 ,\nWe do have a solution for this in private preview (called Many Models solution accelerator).\nPlease send your email id to AzCommunity[at]microsoft[dot]com). Include title and link to this thread in the email (and reply here once you do for faster response) and we can take the conversation from there.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure ML Deploy cannot connect to Kafka Server",
        "Question_creation_time":1599861372500,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/92960\/azure-ml-deploy-cannot-connect-to-kafka-server.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"In the run function of the entry script to deploy a model in azure ml, I included a producer function from kafka-python. However, using the deployed service, I can&#39;t seem to connect to the bootstrap_servers\/topics in Kafka.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-14T13:19:32.077Z",
                "Answer_score":1,
                "Answer_body":"@LawrenceWong-1664 Thanks for the question.\n\nWe have created an end to end HDInsight workshop for our customers. The git hub repo can be accessed here. The content has step by step guide for using HDInsight and Azure Machine Learning on the same use-case and dataset. It could be used to deliver a guided introductory workshop to customers.\n\nhttps:\/\/github.com\/akshata29\/msdataaihdi#step-9--real-time-and-batch-streaming-on-kafka\n\n\n\n\n\nIf possible can you please add more details about the model and the document that you are trying.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"ML Pickle file size Azure Machine Learning Service",
        "Question_creation_time":1599612419390,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/89630\/ml-pickle-file-size-azure-machine-learning-service.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"Is there any restriction on registering an ML pickle model into Azure Machine Learning Service in terms of the size of the pickle file?\n\nDoes it cause latency in realtime data processing and getting the prediction results from the pickle file if we have a model that let's say it 5MB and the other one is 500MB (The bigger file has better performance in terms of accuracy)?\nThanks,\n\nJohn",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-11T04:54:35.417Z",
                "Answer_score":0,
                "Answer_body":"@JA-4570 Thanks, For ACI we recommend not using a model over 1GB in size.\nFor AKS you are limited by the memory resources that you request for your service, minus about 500mb for the running python process in the pod.\n\nThere will be no difference in prediction speed once the model is successfully deployed.\nRegistering will take longer as we have to upload the model, and deploying will take longer as the service must download the model.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How can I mark an Azure Dataset as a time series dataset reading from a parquet folder with date partitions?",
        "Question_creation_time":1601474555217,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/112885\/how-can-i-mark-an-azure-dataset-as-a-time-series-d.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"I would like to create a Tabular\/Time series dataset from a folder that contains parquet files this way:\n- timestamp=2018-01-06\n- timestamp=2018-01-07\n\n\n\n\nHow can I make Azure Dataset, through the GUI, recognises the timestamp partition as a date and mark my dataset as a time series dataset?\n\nDoes anyone know?\n\nThank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-06T04:48:41.247Z",
                "Answer_score":0,
                "Answer_body":"@NastasiaSaby-8354 Thanks, In Azure Machine Learning Studio, you would need to setup partition format similar to python SDK, as follows, assuming your data path is \"timeseries\/timestamp=2020-01-01\/data.parquet\": Set up partition format when creating time series dataset.\n\nPlease follow the below document to connect the data through UI.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-connect-data-ui",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML authentication with Service Principal certificate",
        "Question_creation_time":1601045466093,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/108060\/azure-ml-authentication-with-service-principal-cer.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Hi,\n\nI am responsible for deploying Azure ML resources like workspace, compute target and datastore using Python from Azure CI\/CD Devops Pipeline. I have Service principal certificate for authentication. I am confused about which authentication method of Python I will follow.\n\nShall I used MSAL authentication? or\n\nplease suggest a secure authentication method of python that supports Service Principal certificate to authenticate Azure ML workspace. Please share a sample as reference if any.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-25T23:03:57.707Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. Check out this document regarding Azure Resource Manager service connection which provides information on different connection methods. Hope this helps, otherwise, let me know so we can get you the information you need. Thanks!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML - AKS Service deployment unable to handle concurrent requests despite auto scaling",
        "Question_creation_time":1601545725850,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/113919\/azure-ml-deployment-unable-to-handhle-concurrent-r.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":8,
        "Question_score":0,
        "Question_body":"I have deployed around 23 models (amounting to 1.57 GB) in a Azure ML workspace using Azure Kubernetes Service. For the AKS cluster, I have used 3 D8sv3 nodes, and enabled cluster auto scaling for the cluster up to 6 nodes.\nThe AksWebService is configured with 4.4 cores, 16 GB memory. I have enabled pod auto scaling for the Web service, having set autoscale_max_replicas at 40:\n\n aks_config = AksWebservice.deploy_configuration(cpu_cores = 4.4, memory_gb = 16, autoscale_enabled = True,\n                                                 description = 'TEST - Configuration for Kubernetes Compute Target',\n                                                 enable_app_insights = True, max_request_wait_time = 25000,\n                                                 autoscale_target_utilization = 0.6, autoscale_max_replicas = 40)\n\n\n\n\nI tried running load tests with 10 concurrent users (using JMeter). And I monitored the cluster application insights:\n\n\n\nI can see the nodes and pods scaling. However, there is no spike in CPU\/memory utilization. For 10 concurrent requests, only 5 to 6 requests pass, the rest fail. When I send an individual request to the deployed endpoint, the response is generated in 7 to 9 seconds. However, in the load test logs, there are plenty requests taking more than 15 seconds to generate a response. And the requests taking more than 25 seconds, fail with status code 503. I increased the max_request_wait_time due to this reason, however, I don't understand why it would take so much time despite such amount of compute, and the dashboard shows that memory isn't even 30% utilized. Should I be changing the replica_max_concurrent_requests param? Or should I be increasing the autoscale_max_replicas even more? Concurrent requests load may sometimes reach 100 in production, is there any solution to this?\n\nWill be grateful for any advice. Thanks.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Is there a tool for my scenario?",
        "Question_creation_time":1601450792517,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/112364\/is-there-a-tool-for-my-scenario.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"I have a scenario where we need to compare the content of two pages. Page2 will have the same text as page1 + some minor changes (extra image, extra space, etc). The changes are repetitive and very easy to catch with human eye. We need compare the 2 pages and confirm that indeed Page2 corresponds to Page1 and the changes have been applied correctly.\nWe have currently 10 000 of such page pairs, and expect half a million. We have people doing this manually.\n\nI would like them to stop.\n\nIs there an AI tool we could leverage for this scenario? I could feed it 1000 pairs and expect it to learn the pattern. I could provide either images of those pages or html. We have quite a big error margin (5% totally wrong, 15% partially wrong). I am totally green in the area, so any suggestions are welcome.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-30T17:50:03.637Z",
                "Answer_score":1,
                "Answer_body":"@Ana-7414 I think your use case is a perfect scenario for the Azure computer vision READ API. This API can read printed and handwritten text and provide the output of the document\/image as a JSON response which can be compared or processed by your application to determine if the content is similar with in the margin of error specified. This service can currently process PDF documents for upto the first two pages for free, this will help you to evaluate the API without any cost. If the results are satisfactory you can switch to paid tier to process multiple documents without the limits of the free tier. You can try this API with any of the language that is suitable with this quickstart.\n\nWe hope this helps you to get started. If this response is helpful, please accept the same as answer. Thanks!!",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How to create a machine learning workspace in Microsoft Azure?",
        "Question_creation_time":1600870263283,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/104585\/how-to-create-a-machine-learning-workspace-in-micr.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"I want to create a machine learning workspace in Microsoft Azure but I am not able to do it. Please provide me demo of it or provide me steps with detailed description.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-23T14:31:47.153Z",
                "Answer_score":0,
                "Answer_body":"HI @RahulGoswami-8243,\n\nYou can follow the official Microsoft guide over here:\n\nCreate and manage Azure Machine Learning workspaces in the Azure portal\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-manage-workspace\n\n(If the reply was helpful please don't forget to upvote or accept as answer, thank you)\n\n\n\n\nBest regards,\nLeon",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How can I create a dataset in Azure ML studio (through the GUI) from a parquet file created with Azure Spark",
        "Question_creation_time":1601468116080,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/112778\/how-can-i-create-a-dataset-in-azure-ml-studio-thro.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"I'm trying to load files as a dataset in the GUI of Azure ML Studio. These parquet files have been created through Spark.\n\nIn my folder, Spark creates files such as \"_SUCCESS\" or \"_committed_8998000\".\n\nAzure ML Studio is not able to read them or ignore them and tells me:\n\nThe provided file(s) have invalid byte(s) for the specified file encoding.\n{\n  \"message\": \" \"\n}\n\n\n\n\nI selected \"Ignore unmatched files path\" and yet, it still does not work.\n\nIf I remove the \"_SUCCESS\" and other Spark files, it works.\n\nDoes anyone have an idea about a workaround?\n\nThank you.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-10-01T06:51:09.84Z",
                "Answer_score":1,
                "Answer_body":"I used \"path\/\/.parquet\" in the \"Path\" field and now it works.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"In Automated ML how modules are linked together?",
        "Question_creation_time":1599749780997,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/91527\/in-automated-ml-how-modules-are-linked-together.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":2,
        "Question_score":0,
        "Question_body":"In Automated ML how modules are linked together?. Since we build many modules inside the Automated ML, how these modules are inter-linked and how they interact?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-11T00:10:46.623Z",
                "Answer_score":0,
                "Answer_body":"Hi Shashi,\n\nIf you are asking the architecture of Automated ML. I would say there are 3 layers. The first one is user end, which contains your modules. Then it should be the services you are using on Azure for those modules. The third one is the AML backend, which contains datasets\/ datastore\/ pipelines\/ Model management service\/....\n\nThanks,\nYutong.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure machine learning - Trying to use an analytical function from SQLite results in error",
        "Question_creation_time":1600977576630,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/106670\/azure-machine-learning-trying-to-use-an-analytical.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"When trying to use the LAG function from SQLite on an Apply SQL Transformation module from Azure Machine Learning designer results in a error, saying the sintax near \"(\" was wrong.\n\nThe SQL code:\n\nselect t1.id, t1.veiculo, lag(t1.id) over (partition by t1.veiculo order by t1.id) id_ant\nfrom t1\n\nLooking at the link below, there is no clue on why I can't use a analytical function from SQLite on the module.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/algorithm-module-reference\/apply-sql-transformation\n\nAny tips?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-28T00:27:09.423Z",
                "Answer_score":0,
                "Answer_body":"Hi Felipe,\n\nHave you tried to put default and offsite variable in to see if work or not?\n\nLike this,\nLAG (scalar_expression [,offset] [,default])\nOVER ( [ partition_by_clause ] order_by_clause )\n\nPlease let me know if that still not working.\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Why is the field \"compute target\" for data drift monitoring in ML studio still blank whereas I have a compute instance?",
        "Question_creation_time":1601275746390,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/109397\/why-is-the-field-34compute-target34-for-data-drift.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"I have created a compute instance:\n\nVirtual machine size\nSTANDARD_DS3_V2 (4 Cores, 14 GB RAM, 28 GB Disk)\n\nProcessing Unit\nCPU - General purpose\n\nBut, I'm not able to access it when trying to set it for data drift monitoring.\nThe dropdown list is empty. I can't understand why. Can you help me please?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-28T07:43:38.463Z",
                "Answer_score":1,
                "Answer_body":"I found the answer. You must give a cluster compute instance to do data drift in Azure Machine Learning Studio.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"From AMLS Deploying models in ACI in a vnet",
        "Question_creation_time":1601173833227,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/108659\/from-amls-deploying-models-in-aci-in-a-vnet.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"I am facing error when I deploy in ACI. Is there a way to deploy the models when AMLS and vnet are in different resource groups?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-28T04:03:15.363Z",
                "Answer_score":1,
                "Answer_body":"@AI866-6821 Thanks, If you are using AMLS SDK, Unfortunately this is a limitation today that we plan to address this in the near future.\nYou can create a pipeline, DevOps or manual process to deploy to any ACI in any VNET\/different subscription\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/container-instances\/container-instances-vnet\n\nPlease follow the below for common troubleshooting issues.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/container-instances\/container-instances-troubleshooting",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Upgrading Azure Machine Learning Compute Instance (virtual machine)",
        "Question_creation_time":1591430074777,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/32793\/upgrading-azure-machine-learning-compute-instance.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":1,
        "Question_follower_count":12,
        "Question_score":1,
        "Question_body":"Hi,\n\nHow can I safely upgrade the default OS and softwares of a compute instance (Azure Machine Learning)?\n\nThe default compute instance comes with pre-default versions for OS and packages.\n\nFor example, the following are a few which I\u2019ve inspected after spinning on a compute instance:\n1. OS is currently an Ubuntu LTS 16.04 (release date February 28, 2019)\n2. Python version 3.6.9 (release date July 2, 2019)\n3. R version 3.6.3 (release date February 29, 2020)\n\nThe latest stable versions of the above (as of today June 4,2020) are:\n1. Ubuntu 20.04 LTS (release date April 23,2020)\n2. Python version 3.7.7 (release date March 10,2020)\n3. R version 4.0 (release date April 24,2020)\n\nI actually tried upgrading the OS through the command line but it doesn't seem to be stable after the upgrade to Ubuntu LTS 18.04.\nUpgrading RStudio server also fails.\n\nSo I'm not entirely confident whether the usual commands to upgrade work.\nIs there anything I need to do with the repository list to ensure smooth upgrades and updates?\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-06T08:09:35.703Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nFrom Azure portal, go to the VM page. Under Operations, Select 'Update Management'. Select 'Enable for this VM'. It will take couple of minutes to finish apply settings. Once finished, you may be able to see the missing updates at the same page. Click 'Schedule Update Deployment' > Select the options needed and schedule it as per your convenience\n\nPlease mark as \"Accept the answer\" if the above steps helps you. Others with similar issues can also follow the solution as per your suggestion\n\nRegards,\n\nManu",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-06-09T15:04:40.577Z",
                "Answer_score":0,
                "Answer_body":"@AfiqCheJohari-9488 Are there any specific steps you followed to upgrade your VM version?\nFrom the documentation of RStudio 20.04 is not in the list of supported operating systems as mentioned here.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-09-27T15:06:06.693Z",
                "Answer_score":0,
                "Answer_body":"It would be great to have a reliable way to upgrade the Azure ML SDK and its dependencies on such a compute instance (or any existing conda environment for that matter) without having to abandon and recreate it from scratch, also redoing all the extra setup necessary by the user...\n\nIn my experience, just following the standard documentation pip upgrade instruction almost always messes up the conda environment and introduces multiple dependency errors...\nSo it would be great to have an upgrade option that just works.\nAt least to have a valid end-to-end script example in the documentation.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML web endpoint unreachable after successful deployment",
        "Question_creation_time":1600890127103,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/105346\/azure-ml-web-endpoint-unreachable-after-successful.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"The deployment state of the service is marked as being unhealthy.\n\nCompute target is AKS.\n\nThe pod is running and the logs says that the init() completed successfully.\n\nAlso, when deploying it as a local web service it works.\n\nModel size is small, execution time is < 2 min and we are requesting 0.7 cpu and 0.5 Gb mem. Increasing these requests does not solve it, so guess that it's not related to request limit.\n\nHowever, when trying to consume the scoring service, an 504 error is returned saying that:\n\nRROR - Received bad response from Model Management Service:\nResponse Code: 504\nHeaders: {'Date': 'Wed, 23 Sep 2020 18:44:31 GMT', 'Content-Type': 'text\/html', 'Content-Length': '160', 'Connection': 'keep-alive', 'x-request-time': '180.032', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\nContent: b'<html>\\r\\n<head><title>504 Gateway Time-out<\/title><\/head>\\r\\n<body>\\r\\n<center><h1>504 Gateway Time-out<\/h1><\/center>\\r\\n<hr><center>nginx<\/center>\\r\\n<\/body>\\r\\n<\/html>\\r\\n'\n\n\n\n\nGuess this should be fixed on AKS. But what should be done? Any help much appreciated.\n\nContainer logs:",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Quality of a Classifier Model",
        "Question_creation_time":1600172751413,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/95756\/quality-of-a-classifier-model.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":2,
        "Question_score":1,
        "Question_body":"I have been trying out a classifier model in ML studio, and I have got some results in the Visualize option. I can see the values for Precision, Recall, Accuracy, threshold and also the Confusion Matrix. Now my question is, which of the above mentioned parameters describes the quality of the model?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-16T13:36:07.547Z",
                "Answer_score":0,
                "Answer_body":"@MUJEEBURRAHMAN-1177 Thanks, If your ML model has good performance metrics (you should decide which works best based on confusion matrix and which error can be handled and which should be reduced) then it is a great solution. All the metrics computed and displayed are on validation set and not on the original training set.\n\nSplit the provided dataset in train \/ validation \/ test subsets (if chooses the additional test option)\n\n\nUse train and validation sets to find the best model\n\n\nRetrain best model with best algo and parameters using combined train + validation sets\n\n\nEvaluate on test set and check the results.\n\nIf possible please share the classifier model that you are trying.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Prediction of Cancer",
        "Question_creation_time":1600172964937,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/95802\/prediction-of-cancer.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":2,
        "Question_score":1,
        "Question_body":"I have made a prediction algorithm in which I have predicted whether a patient has cancer or not based on the past data. I have also run the model successfully and have received the parameters. Now my question is, which parameter should I give the most importance for this case of prediction? Is it the precision, recall, accuracy or the threshold?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-16T13:18:10.467Z",
                "Answer_score":0,
                "Answer_body":"@MUJEEBURRAHMAN-1177 Thanks, If your ML model has good performance metrics (you should decide which works best based on confusion matrix and which error can be handled and which should be reduced) then it is a great solution. Can you please share link to the model and the features that you are trying, also please share what feature engineering have you tried.\n\nCould you please add more details about how you\u2019re measuring your model error. If it\u2019s doing worse than validation against your test set, then something weird is going on. If it\u2019s doing better but not reaching 100% accuracy, that\u2019s probably fine, and maybe preferable since it suggests that you\u2019re not overfitting.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Can I add OpenAPI specification to a webservice deployed with AzureML in AKS?",
        "Question_creation_time":1600897231890,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/105437\/can-i-add-openapi-specification-to-a-webservice-de.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"I'd like to deploy a machine learning service using AzureML on AKS. I also need to add some OpenAPI specification for it.\n\nFeatures in https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-azure-kubernetes-service?tabs=python are neat, but that of having API docs\/swagger for the webservice seems missing.\n\nHaving some documentation is useful especially if the model takes in input several features of different type.\n\nTo overcome this, I currently get models trained in AzureML and include them in Docker containers that use the python FastAPI library to build the API and OpenAPI\/Swagger specs, and those are deployed on some host.\n\nCan I do something equivalent to this with AKS in AzureML instead? If so, how?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-24T06:54:05.547Z",
                "Answer_score":2,
                "Answer_body":"@DavideFiocco-7346 The deployments of Azure ML provide a swagger specification URI that can be used directly. The documentation of this is available here. You can print your swagger_uri of the web service and check if it confirms with the specifications you are creating currently.\n\nIf the above response helps, please accept the response as answer. Thanks!!",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"What does \"local\" mean in compute target?",
        "Question_creation_time":1600495202147,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/99901\/what-does-34local34-mean-in-compute-target.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":1,
        "Question_body":"Hi guys, I'm new to Azure ML. Following the URL below, I tried to run my python script on local machine. By local, I meant exactly Windows on my local physical machine in my house. But it seems python script 'transform_titanic.py' was executed on Azure.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-set-up-training-targets#local-compute-target\n\nI executed the script below on my local computer, and expected it runs 'transform_titanic.py' on my local computer.\n\nfrom azureml.core import Environment, Experiment, ScriptRunConfig, Workspace\nfrom dotenv import load_dotenv\nload_dotenv()\nws = Workspace(\n    os.environ['SUBSCRIPTION_ID']\n    os.environ['RESOURCE_GROUP']\n    os.environ['WORKSPACE_NAME']\n)\nexp = Experiment(workspace=ws, name='experiment')\nenv = Environment('user-managed-env')\nenv.python.user_managed_dependencies = True\nscript_run_config = ScriptRunConfig(\n    source_directory='src\/transform',\n    script='transform_titanic.py',\n    arguments=['--input_dataset_name1', 'titanic'],\n)\nscript_run_config.run_config.target = 'local'\nscript_run_config.run_config.environment = env\nrun = exp.submit(config=script_run_config)\nprint(run.get_portal_url())\nrun.wait_for_completion()",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-19T06:10:30.72Z",
                "Answer_score":1,
                "Answer_body":"Sorry, I found it was run on my local computer. Some artifact created in the script was in C:\\Users{username}\\AppData\\Local\\Temp\\azureml_runs\\local_experiment_XXXXXXXXXX",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"No option to select Local machine for compute in Azure ML",
        "Question_creation_time":1600253902967,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/96915\/no-option-to-select-local-machine-for-compute-in-a.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"Hi,\n\nI have created ML space for experimenting ML on azure. However to execute my ML work I need to select compute target and as per Azure docs I can select local machine or remote compute but I don't see option to select local machine. I only have options to create compute instance, compute clusters.\n\nCan someone please help me why I don't have the option.\n\nreference on doc: concept-azure-machine-learning-architecture",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-16T14:57:05.957Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. Yes, you can use your local computer as a local target, but it is currently not an available option in Azure ML Studio. You'd need to configure it in a script as shown in this tutorial. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Clean Missing Data",
        "Question_creation_time":1600173335010,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/95746\/clean-missing-data.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"While doing a machine learning algorithm in Azure ML Studio, I used a dataset which contained some missing data. So I used the Clean Missing Data module for this purpose. Inn the fields section, there are fields named as Minimum Missing Value Ratio and Maximum Missing Value Ratio. I referred to the documentation mentioned here. But I couldn't understand whether giving these fields are necessary or not. Is it necessary to provide these two fields?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-16T14:00:54.36Z",
                "Answer_score":1,
                "Answer_body":"Hi, thanks for reaching out. The minimum and maximum missing value ratio is useful for defining the conditions under which a cleaning operation is performed on the dataset. Minimum missing value ratio is used to specify the minimum number of missing values required for the operation to be performed. By default, the minimum missing value ratio property is set to 0 which means that missing values are cleaned even if there is only one missing value. If you set minimum missing value ratio to 20%, it means missing values are cleaned when there are over 20% rows containing missing values. Maximum missing value ratio is used to specify the maximum number of missing values that can be present for the operation to be performed. If you set maximum missing value ratio to 20%, it means missing values are cleaned when there 20% or fewer rows containing missing values. I would consider it necessary especially if you want to specify conditions for the cleaning operation. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to use \"Web serivie iput\"module on MicroSoft Azure Machien lerning designer reak-time inferance",
        "Question_creation_time":1599810536260,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/92414\/how-to-use-34web-serivie-iput34module-on-microsoft.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"I deplyed image classificatin reak-time inferanceon on Azure Machine Lerning designer.\nSo Id like to test this model by using REST API.\nbut REST API Need prameter og Image by Data Ftame directory Type parametar.\nCan I use REST API by using direct image(Direct PUT iamge or via Storage URI) like Azure Custom Vision'sREST API not ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-11T10:16:35.367Z",
                "Answer_score":0,
                "Answer_body":"@AzureSolutionExpert-2776 You can publish a REST API and use the trained model as the real time endpoint to get the response from the model\/endpoint but the implementation to use the image from storage depends on how you choose to import data i.e if you choose to import data via HTTP using a URL you can replicate the functionality of Azure custom vision. You can also try our new sample for image classification using densenet. This is available in our portal ml.azure.com as a sample which can be customized or used as is to publish an endpoint.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"LGPL license restriction in azureml-core phyton library",
        "Question_creation_time":1599557373747,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/89083\/lgpl-license-restriction-in-azureml-core-phyton-li.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":2,
        "Question_score":0,
        "Question_body":"Hello all,\n\n\n\n\nWe are using azureml-core phyton library to interact with Azure Machine Learning Workspace. The library is hosted on https:\/\/pypi.org\/project\/azureml-core-->; https:\/\/pypi.org\/project\/azureml-core\/ It is authored by Microsoft and maintained by pypi community members.\n\n\n\n\nOne of the dependencies of azureml-core is \"chardet\" phyton library and it has LGPL license restriction. https:\/\/pypi.org\/project\/chardet\/ --> chardet\n\nOur compliance team would like us to avoid the use of LGPL licensed open source libraries to avoid future license implications. I am wondering if there is an alternative to azureml-core phyton library? I noticed that there are two GitHub initiatives to replace chardet . Please refer to below links:\n\nhttps:\/\/github.com\/psf\/requests\/issues\/4848\n\nhttps:\/\/github.com\/encode\/httpx\/issues\/1018\n\nI am wondering whether Microsoft is planning to taken an action on the replacement of chardet library and avoid LGPL licensing issues.\n\nThanks in advance\n\nMehmet Baserdem",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-09T21:49:52.623Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. At the moment, there isn't any public information available regarding the replacement of chardet library. I suggest raising a feature request so you and others can upvote to help the product team prioritize this request. Hope this helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Model for Predicting Earthquakes",
        "Question_creation_time":1600174009770,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/95792\/model-for-predicting-earthquakes.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":2,
        "Question_score":0,
        "Question_body":"I am planning to create an Azure Machine Learning model to Predict the number of Earthquakes based on past historical data. I am asked to use one of the Regression techniques. Which regression model should I be using? Can I use Logistic Regression, or Poisson Regression, or Fast Forest Quantile Regression?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-15T13:46:48.727Z",
                "Answer_score":1,
                "Answer_body":"Hello, thanks for reaching out. Since you want to predict event counts, Poisson Regression would be appropriate. As a future reference, refer to this document for choosing the right algorithm for your predictive analytics model. Hope this helps.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Model for Amount spent in a Supermarket",
        "Question_creation_time":1600176252270,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/95768\/model-for-amount-spent-in-a-supermarket.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":2,
        "Question_score":0,
        "Question_body":"I was asked to create a model to predict the average amount of money spent by a user at a Supermarket. But I am unable to identify which algorithm would be most appropriate. Which algorithm can I use? Can I use Regression, or Clustering, or Classification?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-15T13:44:05.523Z",
                "Answer_score":1,
                "Answer_body":"Hello, thanks for reaching out. Since you want to predict numeric values, regression would be appropriate. As a future reference, refer to this document for choosing the right algorithm for your predictive analytics model. Hope this helps.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"creating conda environment on azure hdinsight spark cluster taking hours",
        "Question_creation_time":1599747249100,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/91524\/creating-conda-environment-on-azure-hdinsight-spar.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"trying to follow the code in this tutorial , https:\/\/github.com\/Azure\/MachineLearningNotebooks\/blob\/master\/how-to-use-azureml\/training\/train-in-spark\/train-in-spark.ipynb\n\nwhen i send the run to run to azure ml, the run essentially stalls on the step creating the conda environment in the hdinsight cluster I am looking to run the pyspark code on.\n\nI am wondering if anyone has run into the same problem where creating a conda environment on a hdinsight cluster for the first time is taking hours, already been 2 hours for me.\n\nThanks",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Machine Learning Server - Where are the web services published stored?",
        "Question_creation_time":1599623268007,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/89720\/machine-learning-server-where-are-the-web-services.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":2,
        "Question_score":1,
        "Question_body":"For machine learning server, we are able to publish model as a web service to Machine Learning Server using the publishService() function from the mrsdeploy package.\n\nFor the published web services, where can they be found?\n\nFirst, are the published web services in the web node or compute node?\n\nSecond, which directory are they stored in?\n\nThird, are they stored in each of the web nodes or compute nodes if multiple nodes were setup?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-10T05:22:38.54Z",
                "Answer_score":0,
                "Answer_body":"@Jiahao-5010 Thanks for the question. Please follow the below document to find and list the published service and the sample notebook to explore the web service.\n\nhttps:\/\/docs.microsoft.com\/en-us\/machine-learning-server\/operationalize\/python\/how-to-consume-web-services#find-and-list-web-services\nhttps:\/\/github.com\/Microsoft\/ML-Server-Python-Samples\/blob\/master\/operationalize\/Explore_Consume_Python_Web_Services.ipynb\n\nknown issues in machine learning server:\nhttps:\/\/docs.microsoft.com\/en-us\/machine-learning-server\/resources-known-issues",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"\" Object of type 'int64' is not JSON serializable\" when running automl time series",
        "Question_creation_time":1599571606537,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/89272\/34-object-of-type-39int6439-is-not-json-serializab.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"I am trying to use the Online ML studio and running an \"Automated ML\". I upload my dataset (see simple example below) which passes fine and then I start a automl experiment selecting \"time series forecasting\". I select all the revelant fields and everything starts without any issues.\n\nShortly after the process fails and the error given is:\n\n\"User error: User program failed with TypeError: Object of type 'int64' is not JSON serializable\"\n\nDigging into the logs the only log with any useful information appears to be the driver_log which has these lines with no more detail about the error unless the INFO about streaming is actually an error not information:\n\n2020-09-08 11:17:01.734 - INFO - Successfully retrieved data using dataprep.\n2020-09-08 11:17:01.734 - INFO - Streaming is not conducive due to incompatible settings. Reason[s]: [Forecasting is not supported, 'n_cross_validations' was non-empty]\n2020-09-08 11:17:01.734 - INFO - Service responded with streaming disabled\n2020-09-08 11:17:01.734 - INFO - Inferring type for feature columns.\n2020-09-08 11:17:12.669 - INFO - Error in setup_wrapper.\n2020-09-08 11:17:12.670 - ERROR - Marking Run AutoML_f5a7c759-653c-4314-98a9-c2afbcecff55_setup as Failed.\n\n\n\n\nCan anyone suggest an answer or recommend some ways to debug this?\n\n][1]",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-09-08T13:41:33.393Z",
                "Answer_score":0,
                "Answer_body":"found the more detailed stacktrace\n\n\"debugInfo\": {\n\"type\": \"TypeError\",\n\"message\": \"Object of type 'int64' is not JSON serializable\",\n\"stackTrace\": \" File \\\"\/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/brian-ml-learning\/azureml\/automl_f5a7c759-653c-4314-98a9-c2afbcecff55_setup\/mounts\/workspaceblobstore\/azureml\/AutoML_f5a7c759-653c-4314-98a9-c2afbcecff55_setup\/azureml-setup\/context_manager_injector.py\\\", line 166, in execute_with_context\\n runpy.run_path(sys.argv[0], globals(), run_name=\\\"main\\\")\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/runpy.py\\\", line 263, in run_path\\n pkg_name=pkg_name, script_name=fname)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/runpy.py\\\", line 96, in _run_module_code\\n mod_name, mod_spec, pkg_name, script_name)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/runpy.py\\\", line 85, in _run_code\\n exec(code, run_globals)\\n File \\\"setup_AutoML_f5a7c759-653c-4314-98a9-c2afbcecff55.py\\\", line 731, in <module>\\n result = setup_run()\\n File \\\"setup_AutoML_f5a7c759-653c-4314-98a9-c2afbcecff55.py\\\", line 725, in setup_run\\n prep_type=preparation_type\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/runtime\/_remote_script.py\\\", line 578, in setup_wrapper\\n setup_run._fail_with_error(e)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/site-packages\/azureml\/train\/automl\/run.py\\\", line 1258, in _fail_with_error\\n logging_utilities.log_traceback(exception, logger)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/site-packages\/azureml\/automl\/core\/shared\/logging_utilities.py\\\", line 212, in log_traceback\\n error_msg_without_pii = _get_pii_free_message(exception)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/site-packages\/azureml\/automl\/core\/shared\/logging_utilities.py\\\", line 140, in _get_pii_free_message\\n return exception.get_pii_free_exception_msg_format()\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/site-packages\/azureml\/automl\/core\/shared\/exceptions.py\\\", line 151, in get_pii_free_exception_msg_format\\n error_dict = json.loads(self.serialize_json())\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/site-packages\/azureml\/common\/exceptions.py\\\", line 181, in serialize_json\\n return json.dumps(error_ret, indent=indent)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/json\/init.py\\\", line 231, in dumps\\n return default_encoder.encode(obj)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/json\/encoder.py\\\", line 199, in encode\\n chunks = self.iterencode(o, one_shot=True)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/json\/encoder.py\\\", line 257, in iterencode\\n return iterencode(o, 0)\\n File \\\"\/azureml-envs\/azureml_63ddfcee3da4413e556b059b99c2fb63\/lib\/python3.6\/json\/encoder.py\\\", line 180, in default\\n o.class.name)\\n\",\n\"innerException\": null,\n\"data\": null,\n\"errorResponse\": null\n}",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Deploy ML model to Kubernetes + overwrite previous endpoint",
        "Question_creation_time":1598425965377,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/77362\/deploy-ml-model-to-kubernetes-overwrite-previous-e.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I'm building a CI\/CD pipeline in Azure DevOps for the deployment of my Machine Learning model to Azure Kubernetes Service. I have the following task in my YAML pipeline file (replaced some of the values with '...'):\n\n - task: AzureCLI@1\n   displayName: \"Deploy to AKS\"\n   inputs:\n     azureSubscription: '...'\n     scriptLocation: inlineScript\n     workingDirectory: $(Build.SourcesDirectory)\/score\n     inlineScript: |\n       set -e # fail on error\n             \n       az ml model deploy --name 'aks-deploy-test' --model '$(MODEL_NAME):$(get_model.MODEL_VERSION)' \\\n       --compute-target $(AKS_COMPUTE_NAME) \\\n       --ic inference_config.yml \\\n       --dc deployment_config_aks.yml \\\n       -g ... --workspace-name ... \\\n       --overwrite -v\n\n\n\nWhen I run the pipeline the first time, it successfully deployed the ML model and I can see the Endpoint in the Azure ML workspace. However, when I try to run the pipeline a second time (to deploy a newer version of the model), I get the error:\n\n Error:\n {\n   \"code\": \"KubernetesError\",\n   \"statusCode\": 400,\n   \"message\": \"Kubernetes Deployment Error\",\n   \"details\": [\n     {\n       \"code\": \"Unschedulable\",\n       \"message\": \"0\/6 nodes are available: 4 Insufficient cpu, 6 Insufficient memory.\"\n     },\n     {\n       \"code\": \"DeploymentFailed\",\n       \"message\": \"Couldn't schedule because the kubernetes cluster didn't have available resources after trying for 00:05:00.\\nYou can address this error by either adding more nodes, changing the SKU of your nodes or changing the resource requirements of your service.\\nPlease refer to https:\/\/aka.ms\/debugimage#container-cannot-be-scheduled for more information.\"\n     }\n   ]\n }\n\n\n\nIsn't the --overwrite option in the az ml model deploy command supposed to completely overwrite the current deployment of the model? If so, why am I still getting this error, or is there a better way to deploy a newer version of the ML model to the same AKS cluster?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-28T04:02:16.747Z",
                "Answer_score":0,
                "Answer_body":"@AxelVandevelde Thanks for the question. The error message literally indicates the issue, none of the nodes have CPUs available.\nCan you please add more details about the sku's. If Possible please share the link to the tutorial\/documentation you were following.\n\nEnable AppInsights flag will start flowing the logs (for Application monitoring).\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/service\/how-to-enable-app-insights\n\n\n\n\nFor cluster monitoring you can use log analytics via AKS.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/aks\/view-master-logs",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Consume private packages from DevOps Artifacts in AzureML",
        "Question_creation_time":1598473641800,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/78083\/consume-private-packages-from-devops-artifacts-in.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"I have published a private Python package to Azure DevOps Artifact.\nWhen trying to follow this tutorial I encounter following problem, to which there is no help online whatsoever.\n\n{\n\"code\": \"AciDeploymentFailed\",\n\"statusCode\": 400,\n\"message\": \"Failed to submit build for Environment with Name: deploymentenv Version: Autosave_2020-08-26T19:42:40Z_b11e8d13 Reason: {\\n \\\"error\\\": {\\n \\\"code\\\": \\\"UserError\\\",\\n \\\"severity\\\": null,\\n \\\"message\\\": \\\"Unable to set authorization on python feed. Multiple connections available for the specified host company.pkgs.visualstudio.com\\\",\\n \\\"messageFormat\\\": null,\\n \\\"messageParameters\\\": null,\\n \\\"referenceCode\\\": null,\\n \\\"detailsUri\\\": null,\\n \\\"target\\\": null,\\n \\\"details\\\": [],\\n \\\"innerError\\\": null,\\n \\\"debugInfo\\\": null\\n },\\n \\\"correlation\\\": {\\n \\\"operation\\\": \\\"fcd33b3aaf97a04982c36841fd2176d5\\\",\\n \\\"request\\\": \\\"4ddc0bff3cd6ec47\\\"\\n },\\n \\\"environment\\\": \\\"westeurope\\\",\\n \\\"location\\\": \\\"westeurope\\\",\\n \\\"time\\\": \\\"2020-08-26T20:15:48.9795242+00:00\\\",\\n \\\"componentName\\\": \\\"environment-management\\\"\\n}.\",\n\"details\": []\n}\nI replaced the actual company name with \"company\".\n\nWhat does the error Unable to set authorization on python feed. Multiple connections available for the specified host mean?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-27T11:53:25.37Z",
                "Answer_score":0,
                "Answer_body":"@FabianGeiger-5116 adding a reference to the same issue posted on VS community channel. Is the PAT token scope set to Packaging > Read?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"No module named 'xgboost'",
        "Question_creation_time":1597377002880,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/66628\/no-module-named-39xgboost39.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":1,
        "Question_score":0,
        "Question_body":"Hello there,\n\nI'm seeing an error - No module named 'xgboost' when attempting to deploy a model using python SDK. Here is my conda yaml file. What am I missing?\nUnable to get the end point to generate an output.\n\nname: project_environment\ndependencies:\n# The python interpreter version.\n# Currently Azure ML only supports 3.5.2 and later.\n- python=3.6.2\n\npip:\n\n\ninference-schema\n\n\nazureml-defaults\n\n\nazureml-explain-model\n\n\nnumpy>=1.16.0,<1.17.0\n\n\npandas>=0.21.0,<=0.23.4\n\n\nscikit-learn>=0.19.0,<=0.20.3\n\n\npy-xgboost\n\n\nfbprophet==0.5\n\n\nholidays==0.9.11\n\n\npsutil>=5.2.2,<6.0.0\n\n\nxgboost\n\n\nazureml-sdk[notebooks,automl]\nchannels:\n\n\nanaconda\n\n\nconda-forge",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-14T10:05:53.963Z",
                "Answer_score":0,
                "Answer_body":"@VikManne-0966 Thanks for the question. Can you please check on the pip and coda packages properly separated. If possible please share the link to the yaml file.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning and jupyterlab git extension not working",
        "Question_creation_time":1594716551237,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/46614\/azure-machine-learning-and-jupyterlab-git-extensio.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":4,
        "Question_comment_count":5,
        "Question_follower_count":37,
        "Question_score":1,
        "Question_body":"Hi,\n\n\n\n\nI need some help trying to understand why I can't see any GIT options (left panel and top selection drop down menu) in my Azure machine learning JupyterLab.\n\n\n\n\nI did the following steps:\n\n\n\n jupyter labextension install @jupyterlab\/git\n pip install --upgrade jupyterlab-git\n jupyter serverextension enable --py jupyterlab_git\n jupyter lab build\n\n\n\n\nI've restarted my jupyterLab a couple of times, if I check the command:\n\n\n\n jupyter labextension list\n\n\n\n\nI get that @jupyterlab\/git v0,20,0 is enabled and ok.\nWhat am I doing wrong?\n\n\n\n\nThank you in advance,\nCarla",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-14T21:32:40.103Z",
                "Answer_score":1,
                "Answer_body":"Hi @ramr-msft ,\n\n\n\n\nI did the steps mention in the link you gave me (https:\/\/github.com\/jupyterlab\/jupyterlab-git) but still I can't open the Git extension from the Git tab on the left panel because it still doesn't exists.\n\n\n\n\nYou mentioned we can still manage git repositories using the command line. Do you have any useful documentation on this approach?\n\n\n\n\nOnce again, thank you in advance.\nCarla",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2020-07-16T12:03:40.593Z",
                "Answer_score":1,
                "Answer_body":"@CarlaFiadeiro-3395 We have checked with the product team and As per the confirmation this extension is removed as of March-2020 releases since it has been causing perf issues with fileshare storage. We will add it back in future once we fix perf issues. Current alternative is to use git CLI.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-16T13:23:42.487Z",
                "Answer_score":1,
                "Answer_body":"Hi @ramr-msft ,\n\n\n\n\nThank you a lot for the reply.\nFor the moment I'll use git CLI.\n\n\n\n\nOnce again thank you for the help.\n\n\n\n\nRegards,\nCarla",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-09-03T18:17:49.423Z",
                "Answer_score":0,
                "Answer_body":"Carla, after you complete the steps you mentioned at the beginning of this thread, try restarting your Azure ML Compute and then open Jupyter Lab:",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How is AML's average GpuUtilization metric computed?",
        "Question_creation_time":1598450649953,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/77678\/how-is-aml39s-gpuutilization-metric-computed.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"How is the \"GpuUtilization\" metric computed for an AML workspace? What are the inputs and what is the equation used to compute GpuUtilization?\n\nThe \"metrics\" tab in the AML web portal shows a chart of the GpuUtilization over a specified time period, along with the average GpuUtilization for that time period. However, I have found that average GpuUtilization does not appear to accurately reflect the data shown in the chart for some of my organization's AML workspaces.\n\nFor example, the following screenshot shows the GpuUtilization for July 1-31, with the average GpuUtilization reported as 54.06. This is clearly much higher than what is shown in the chart. When I download the data from the chart (Share -> Download to Excel), I compute the average GpuUtilization to be ~11% in Excel. Why is there such a discrepancy?\n\nI have found similar discrepancies for other AML workspaces as well. However, the average GpuUtilization appears to be more accurate for the August 1-25 time period than it is for July 1-31. I wish to better understand how AML computes the average GpuUtilization over a time period so we can accurately account for my organization's AML GPU usage on a per-workspace basis.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-27T14:49:02.87Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. GpuUtilization shows how much percentage of GPU was utilized for a given node during a run\/job. One node can have one or more GPUs. This metric is published per GPU per node. You can apply filters based on node to understand the computation better. Let me know if that helps or if you need further assistance. Thanks.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Access Azure Machine Learning logs from another Azure Project",
        "Question_creation_time":1598601355923,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/79984\/access-azure-machine-learning-logs-from-another-az.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"I am running two Azure instances. The main instance can be considered the parent instance and will house all insights across all the children instances. The children instances are aligned to specific lines of business performing machine learning. The children instances will use the Azure Machine Learning service. Models will be trained here and the model metrics are stored here as logs. Following [this].\n\nI need to monitor the children instances from my main instance. By this, I need to get all the logs from Azure Machine Learning in the child instance to the parent instance. Assume storage is a blob container. Does Azure Machine Learning have an API to get logs from an external Azure instance?\n\nI know you can use the Azure ML SDK to access logging, but how would the permissions need to be set up to access from an external Azure instance?\n\n\n\n\n\n[this]: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-monitor-view-training-logs",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-29T00:19:56.137Z",
                "Answer_score":0,
                "Answer_body":"Hello, thanks for reaching out. We don't have an API for accessing logs from another compute instance. However, you can export logs or use Azure Monitor to monitor logs across Azure resources. Hope this helps. Let me know if you have any further questions or concerns. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Studio Notebooks folder structure",
        "Question_creation_time":1598909886827,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/82485\/azure-ml-studio-notebooks-folder-structure.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"Is it possible to create non-user folders for Notebooks in Azure ML Studio? I would look to organize my notebooks into folders, but outside of my persona user folder structure (similar to how Azure Databricks allows you to create folders within the workspace) \u2013 doesn\u2019t look like that is possible, but wanted to double check.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-31T22:37:02.513Z",
                "Answer_score":1,
                "Answer_body":"Hi, thanks for reaching out. Currently, there's no way to create non-user folders in AML Studio. All files and folders and stored in the user's location. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Update out of date packages on Azure Machine Learning Compute instance",
        "Question_creation_time":1598608952077,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/80212\/update-out-of-date-packages-on-azure-machine-learn.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"Started up a STANDARD_D11_V2 cluster to run some notebooks on.\n\nWanted to use json_normalize from pandas: https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.json_normalize.html and I get the below error:\n\nAttributeError: module 'pandas' has no attribute 'json_normalize'\n\n\n\nPandas seems to be out of date. Checked the installed version of pandas:\n\n$ python\nPython 3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31) [GCC 7.3.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import pandas\n>>> pandas.__version__\n'0.23.4\n\n\n\nPandas is indeed out of date, the latest version is v1.1.1. Fired up a terminal to run:\n\nconda update --all\n\n\n\nOn the azureml_py36 environment which I had selected to run the notebook on. It hangs on:\n\nSolving environment: \/\n\n\n\nWent to update conda to see if that would help:\n\nconda update conda\n\n\n\nBut I get this error:\n\nPackageNotInstalledError: Package is not installed in prefix.\n  prefix: \/anaconda\/envs\/azureml_py36\n  package name: conda\n\n\n\nWhich leads me to think this is not a typical installation of conda.\n\nWould like to run the most up to date packages on Azure Machine Learning to replicate the local environment I have setup. Does anyone know how to do this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-28T13:43:08.187Z",
                "Answer_score":0,
                "Answer_body":"@philmariusnew-9791 I have tried the above steps and the installation completed successfully for conda. But when we upgrade pandas azureml package has a dependency so it cannot use version v1.1.1\n\nI have went ahead and upgrade the pandas version but there is a warning as seen below:\n\nWe would recommend to use the package that is compatible with azureml so your environment setup works as expected.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Jupyterlab page is blank",
        "Question_creation_time":1598559753367,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/79393\/jupyterlab-page-is-blank.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":2,
        "Question_score":0,
        "Question_body":"In my Workspace, after creating a compute, when I click on Jupyterlab , I get a blank page. When I click on Jupyter, the notebook work fine.\n\nWhats the issue",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-28T20:00:16.237Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nThanks for reaching out to us. I can confirm that it works well in my laptop as following:\n\n\n\n\n\n\nCould you please share your region so I can reproduce more accurately? Thanks.\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Accessing the my ML Model from azure ml",
        "Question_creation_time":1598739182170,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/80879\/accessing-the-my-ml-model-from-azure-ml.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":2,
        "Question_score":0,
        "Question_body":"I am accessing my ML modal that i have deployed on azure ml and using that model to predict but is there any way i can pass the data other than json format ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-31T10:50:21.85Z",
                "Answer_score":0,
                "Answer_body":"@YashPathak-1466 Thanks for the question. Can you please add more details about the model that you are trying. Basically, the test data content needs to be parsed and transformed just like how your training data is transformed before it gets into model.fit(). Without knowing what your model does, it\u2019s hard to see what\u2019s going on.For Deep learning models If test data are text, then it needs to be tokenized. If numbers, they need to be transformed and normalized. Either way, test data has to become numpy array or a generator that streams numpy.\n\nPlease follow the below document for ways to consume the deployed AML as web service.\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-consume-web-service",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Git integration with ML Azure Jupyterhub is very slow",
        "Question_creation_time":1598513619823,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/78634\/git-integration-with-ml-azure-jupyterhub-is-very-s.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"JupyterLab (in ML Azure) default mounts a shared file system for all users in my workspace. The documentation recommends to \"clone git repositories into our own user directory\". It works, but it is extremely slow. A simple 'git status' can take up to 3 seconds to run. Committing, pushing, pulling, stashing, each can take long time to execute (matter of seconds). In a my local machine it takes the order of milliseconds. This can be very annoying, specially if one does so very frequently.\n\nSo here is my question: is there a way to fix it or is it inherently bounded to the slow mounted file system? If it can't be solved, how can I change Jupyter's mounting point (so I can point it out to a local file system)?\n\nThanks,",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-31T10:03:21.92Z",
                "Answer_score":2,
                "Answer_body":"@GiovanniGATTIPINHEIRO-3694 Our team has confirmed this as a known issue while using Azure File Share and are working on a design change to ensure the performance is improved. We currently do not have an ETA on this implementation, we shall update this thread as soon as we have an update.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"ModuleExceptionMessage:ColumnUniqueValuesExceeded: Number of unique values in column: ds is greater than allowed.",
        "Question_creation_time":1597254135800,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/65476\/moduleexceptionmessagecolumnuniquevaluesexceeded-n.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":1,
        "Question_score":0,
        "Question_body":"We are trying to train a model using the Boosted Tree Regression model and running into the \"ModuleExceptionMessage:ColumnUniqueValuesExceeded: Number of unique values in column: \"ds\" is greater than allowed.\" error.\n\nThis is a time series data and it is going to have unique values in the timestamp - how are we supposed to get around the issue.\n\nPS: When using the exact same dataset in the classic studio it runs fine and does not throw this error.\n\nThe big picture: We are happy with studio based results on the prediction however, there isn't a way to fully end to end automate, meaning retrain the model with latest data and use the API to download the results in classic version. We are looking to use the new Azure ML pipelines and endpoints etc but quite frankly all of this is turning out be quite complex than needed for some reason. And the documentation to retrain the models shows a mixture of classic and new azure ml steps which is quite frustrating.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How to deploy Azure automated machine learning model to production to generate forecast",
        "Question_creation_time":1597314320727,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/66173\/how-to-deploy-azure-automated-machine-learning-mod-1.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":2,
        "Question_score":0,
        "Question_body":"I managed to use Azure automated machine learning to train a time series forecasting model in Azure machine learning studio.\n\nWe get new data only once a month, therefore we do not think that web service is necessary for our needs.\n\nWe want to deploy the model on the cloud or locally to start generating forecasting data. But We are not quite sure how to do so. We do not have knowledge about Python and machine learning deployment.\n\nCould you recommend some instructions on how to deploy Azure automated machine learning model on the cloud and locally? Thank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-13T18:59:22.42Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nThanks a lot for reaching out to us, please check following guidance for how to configure and train a time-series forecasting regression model using automated machine learning in the Azure Machine Learning Python SDK.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-forecast#configure-and-run-experiment\n\nPlease let me know for more question. Thanks!\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to deploy Azure automated machine learning model to generate forecast",
        "Question_creation_time":1597314111690,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/66092\/how-to-deploy-azure-automated-machine-learning-mod.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":2,
        "Question_score":0,
        "Question_body":"I managed to use Azure automated machine learning to train a time series forecasting model in Azure machine learning studio.\n\nWe get new data only once a month, therefore we do not think that web service is necessary for our needs.\n\nWe want to deploy the model on the cloud or locally to start generating forecasting data. But We are not quite sure how to do so. We do not have knowledge about Python and machine learning deployment.\n\nCould you recommend some instructions on how to deploy Azure automated machine learning model on the cloud and locally? Thank you!",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-13T18:59:54.333Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nI think you have posted the same question in this forum. Please check following guidance for how to configure and train a time-series forecasting regression model using automated machine learning in the Azure Machine Learning Python SDK.\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-auto-train-forecast#configure-and-run-experiment\n\nPlease let me know for more question. Thanks!\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"azureml-sdk and azure-identity==1.4.0",
        "Question_creation_time":1598460449627,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/77924\/azureml-sdk-and-azure-identity140.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"In our project we already use azure-identity==1.4.0 (to use az cli authentication in development - DefaultAzureCredential). Now we would like to use azureml-sdk however it seems that it only works with azure-identity<1.3.0.\nIs there any workaround to make it work? Any idea when azureml-sdk will catch up and how to make a pressure on them?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-27T01:58:22.053Z",
                "Answer_score":0,
                "Answer_body":"Hello,\n\nOne workaround I have not is, you can use AzureML SDK without dataprep that brings the dependency. I would recommend you to not use metapackages like azureml-sdk and install the dependencies you need only.\n\nPlease let me know if you need more information.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-08-27T13:09:53.183Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nI do encounter the same problem. As I need to make use of the AzureML dataprep, the suggested work around is not applicable for me. How can I make an offical feature request for the upgrade of the dependency?\n\nThanks,\nAlice",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"how to Create calculated column",
        "Question_creation_time":1598247159813,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/74771\/how-to-create-calculated-column.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":0,
        "Question_score":0,
        "Question_body":"Hi,\n\nI want to create calculated column. i have text probability field and estimated revenue field. i want to multiple estimated value with probability field. probability field has value like 10, 20, 5 etc.\n\npls guide how to create calculated column to perform these calculation.\n\nthx",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-24T16:38:39.657Z",
                "Answer_score":0,
                "Answer_body":"Hello, thanks for reaching out. For simple calculations like the one you described, the Apply Math Operation module should suffice and enables you to apply Arithmetic Operations such as multiply, divide, etc. For more complex calculations, you can write a script to perform data transformation using Execute R Script, Execute Python Script, and Apply SQL Transformation modules. Feel free to review these tutorials on how to use Apply SQL Transformation and create custom scripts. Hope this helps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"MLS version (9.4.7) is supported up to Cloudera 6.1",
        "Question_creation_time":1597330930617,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/66337\/mls-version-947-is-supported-up-to-cloudera-61.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":2,
        "Question_score":0,
        "Question_body":"The current latest MLS version (9.4.7) is supported up to Cloudera 6.1 only, so wanted to check if there are any plans and a timeline to certify\/support Cloudera 6.3.2 versions.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-25T13:25:28.9Z",
                "Answer_score":0,
                "Answer_body":"Hello, we don't have an exact timeline to share with customers at this time, however, we have plans to support Cloudera 6.3.2 soon. Hope this helps. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is there a way to access compute quotas with the Azure CLI or Python SDK?",
        "Question_creation_time":1597248641713,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/65511\/is-there-a-way-to-access-compute-quotas-with-the-a.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":1,
        "Question_score":0,
        "Question_body":"I want to tabulate the compute quotas for each Azure ML workspace, in each Azure location, for my organization's Azure subscription. Although it is possible to look at the quotas manually through the Azure Portal (link), I have not found a way to do this with the Azure CLI or Python SDK for Azure. Since there are many resource groups and AML workspaces for different teams under my Azure subscription, it would be much more efficient to do this programmatically rather than manually through the portal. Is this even possible, and if so how can it be done?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-13T15:31:33.373Z",
                "Answer_score":0,
                "Answer_body":"Yes, we have a REST API that returns quota usage by subscription, workspace, and cluster. Please check out this example call. Let me know if this answers your question. Thanks.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Deleted Azure ML Key Vault",
        "Question_creation_time":1597243360113,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/65422\/deleted-azure-ml-key-vault.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Does anyone have an idea if there's a way to associate an existing ML resource with a different key vault, storage account, etc? The names generated for these resources when you create a ML resource do not match our naming convention, plus, our key vault associated with the ML resource was accidentally deleted.\n\nEDIT: hoping someone has a good solution, but for now, the only thing i can think of is Terraform. I'll pursue that and update the thread",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-13T09:57:04.29Z",
                "Answer_score":0,
                "Answer_body":"@EnsembleMark2-1646 Once a Azure ML workspace is created there is no option to change the key vault id on the workspace properties. This is documented here in Azure documentation.\n\nOnce a workspace has been created, you cannot change the settings for confidential data, encryption, key vault ID, or key identifiers. To change these values, you must create a new workspace using the new values.\n\nHowever, if you have enabled soft delete for your key vault it can be restored and your workspace should not be effected after a restore. If you have not enabled this feature then you can enable this after creating a new workspace.\n\nAlso, you can use an existing storage account and keyvault while creating a new workspace by using this ARM template by following the steps mentioned here.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AI Build Flow Getting Failed Due to Error &#34;Action &#39;Predict&#39; failed&#34;",
        "Question_creation_time":1597387903250,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/66913\/ai-build-flow-getting-failed-due-to-error-amp34act.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":2,
        "Question_score":0,
        "Question_body":"Dear Team,\n\nTrying to build a AI Build solution flow to capture the PDF information, but getting below error details\nStart time: Aug 14, 09:23 AM (2 h ago)\nDuration: 00:00:41\nStatus: Failed\nError: Action 'Predict' failed\nError Details:\n{\"operationStatus\":\"Error\",\"error\":{\"type\":\"Error\",\"code\":\"DependencyTimeout\",\"message\":\"The request timed out or was cancelled by the client for method POST\",\"properties\":{\"BackendErrorCode\":\"DependencyTimeout\",\"DependencyHttpStatusCode\":\"504\"}}}\n\n\n\n\nCan anyone help me, why this error being returned.\n\nThanks\nManoj",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Zoom or increase size of a cell in azure notebooks",
        "Question_creation_time":1597097734127,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/63846\/zoom-or-increase-size-of-a-cell-in-azure-notebooks.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":2,
        "Question_score":1,
        "Question_body":"Hi,\n\nI have a plot but the cell is quite small to correctly display the plot, I didn\u00b4t find how to zoom or increase cell size for better display, any alternative?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-12T12:13:48.643Z",
                "Answer_score":0,
                "Answer_body":"@RaulAndresDuque Thanks for the question. If you don't want to change your default settings, and you only want to change the width of the current Jupyter notebook you're working on, you can enter the following into a cell:\n\nfrom IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container { width:100% !important; }<\/style>\"))\n\nYou can use Jupyterlab from the Notebooks that have full pledge native IDE support.\n\nWe have forwarded to product team to check for azure notebooks or you can also raise an issue in the following link.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"how to retrain model and deploy (if new model is better) by schedule or trigger with Azure MLops ?",
        "Question_creation_time":1592185292417,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/35810\/how-to-retrain-model-and-deploy-if-new-model-is-be.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Hi\n\ni am beginner of azure.\n\ni am trying to use mlops.\n\nit is not easy to not programmer...\n\nbut i want to practice mlops.\n\ni want to retrain model by scheduling.\n\nplease let me know how to retrain model and deploy (if new model is better) by schedule or trigger with Azure MLops",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-15T15:16:31.297Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nOnce you have decided to retrain, you should:\n\nPreprocess your data using a repeatable, automated process\nTrain your new model\nCompare the outputs of your new model to those of your old model\nUse predefined criteria to choose whether to replace your old model\nA theme of the above steps is that your retraining should be automated, not ad hoc. Azure Machine Learning pipelines are a good answer for creating workflows relating to data preparation, training, validation, and deployment. Read Retrain models with Azure Machine Learning designer (preview) to see how pipelines and the Azure Machine Learning designer fit into a retraining scenario.\n\nPlease let me know if you have more questions.\n\nThanks,\nYutong",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-06-22T16:24:16.883Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nAML pipeline is good way to help the model retraining with MLOps and Pyhton\n\nThis reference architecture shows how to implement a continuous integration (CI), continuous delivery (CD), and retraining pipeline for an AI application using Azure DevOps and Azure Machine Learning. The solution is built on the scikit-learn diabetes dataset but can be easily adapted for any AI scenario and other popular build systems such as Jenkins and Travis.\n\n\nThis is a sample of self-supervised learning with hyperparameter tuning and automated retraining: https:\/\/github.com\/Microsoft\/MLOps_VideoAnomalyDetection\n\n\n\n\n\n\nMLOps doc: https:\/\/github.com\/microsoft\/MLOps\nMLOps Python doc:https:\/\/docs.microsoft.com\/en-us\/azure\/architecture\/reference-architectures\/ai\/mlops-python\nMLOps repo: https:\/\/github.com\/microsoft\/MLOps\nMLOps pipeline: https:\/\/docs.microsoft.com\/en-us\/azure\/architecture\/reference-architectures\/ai\/mlops-python#mlops-pipeline",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-06-23T14:43:35.153Z",
                "Answer_score":2,
                "Answer_body":"Just a question, is there a way to automate the creation of a new web-service which contains the new model once retrain has be done. For example, I have created a retraining pipeline and I see that the model is performing better. Can I automate the process of deploying the new model behind an existing web-service or does this always have to be a manual job?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-08-12T17:50:18.45Z",
                "Answer_score":1,
                "Answer_body":"I'm interested in the above question as well, is there a way to accomplish this automatically without manually doing it?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Migration from azure notebooks",
        "Question_creation_time":1596029416727,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/54459\/migration-from-azure-notebooks.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":0,
        "Question_score":0,
        "Question_body":"I have receive many warnings saying that Azure notebooks will be shutdown end of September.\nI wanted to migrate to azure machine learning studio but the notebooks&#39; icon that it is supossed to appear is not there.\nCan you tell me where to find updated instructions in order to create a new space to work with my notebooks?\nSincerely\nHermes",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-29T13:31:39.817Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nYou can follow along here:\nhttps:\/\/notebooks.azure.com\/Content\/alternatives.html\n\n\n\n\nBest regards,\nLeon",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-08-05T18:02:33.617Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nThanks for reaching out. Azure Machine Learning provides an end-to-end machine learning platform to enable users to build and deploy models faster on Azure. Azure ML allows you to run Jupyter Notebooks on a VM or a shared cluster computing environment. If you are in need of a cloud-based solution for your ML workload with experiment tracking, dataset management, and more, we recommend Azure Machine Learning. To get started with Azure ML please try following:\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/notebooks\/quickstart-export-jupyter-notebook-project#use-notebooks-with-azure-machine-learning\n\nLet me know if you have more questions.\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Pipe %&gt;% for R is not working in azure notebooks",
        "Question_creation_time":1597095266457,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/63863\/pipe-ampgt-for-r-is-not-working-in-azure-notebooks.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":2,
        "Question_score":0,
        "Question_body":"Hi,\n\nI tried to use the pipe operation %>% of R in an azure notebook without success ...\n\n\n\n\n\nis possible to use it or it is a limitation in azure notebooks ?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-10T22:11:14.163Z",
                "Answer_score":1,
                "Answer_body":"Hi,\n\nFixed.\n\nAzure Notebook release the session after some time of inactivity, therefore the dplyr package wasn\u00b4t loaded in the session",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Simple filter is not working in Azure notebook for R",
        "Question_creation_time":1597096204317,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/63901\/simple-filter-is-not-working-in-azure-notebook-for.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":2,
        "Question_score":1,
        "Question_body":"I have imported packages:\n\nlibrary(dplyr)\n\nUploaded my dataset:\n\nbike <- readRDS(\"bike.rds\")\n\nBut when I try simple \"filter\" it is not working:",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-10T22:06:10.387Z",
                "Answer_score":1,
                "Answer_body":"Fixed.\n\nIt looks azure notebook clean the session after some period of inactivity, there the package dplyr was not loaded after some time",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Added Experiment to Collection becomes Deleted item",
        "Question_creation_time":1596654530823,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/60092\/added-experiment-to-collection-becomes-deleted-ite.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":1,
        "Question_score":0,
        "Question_body":"Hi, I\u2019ve been having trouble adding an experiment into my collection to show employers. Everytime I add an experiment into my collection it becomes a deleted file. Does anyone else encounter this?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Reinforcement Learning - Windows server administration",
        "Question_creation_time":1596612095990,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/59522\/reinforcement-learning-windows-server-administrati.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":1,
        "Question_score":0,
        "Question_body":"Hi Team,\nGreetings!!!\n\nI have been looking for use cases that can be addressed using Reinforcement Learning(RL) agent by Machine learning. Would you please share some business use cases?\nOne of the example is clearing\/archiving log files, when it expands. Agent will reward(1) or punish(0) based on the action taken by the system. Over a period of time, system will learn by itself and apply the solution based on reward points.\n\nThanks\nDinesh",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-08-06T02:53:36.163Z",
                "Answer_score":0,
                "Answer_body":"@DineshSundaram-9074 Thanks for the question. We are seeing 3rd party enterprise customers train reinforcement learning agents on up to 512 cores or running their training over multiple days. In practice, it can take millions of trial runs to train an agent. These trial runs happen automatically, rapidly in parallel and the system continuously learns and improves. Azure Machine Learning uses the Ray framework to distribute reinforcement learning training to support large scale training.\n\nPlease follow the below GitHub samples for RL.\nYou can train your own reinforcement learning agents using Azure Machine Learning using the following resources.\n\u2022 How to: reinforcement learning with Azure Machine Learning\n\u2022 Github samples\n\u2022 AI Show: introductory video\nVideo interview Microsoft Research",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Cannot create compute instance with 2 nodes",
        "Question_creation_time":1595860934587,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/52800\/cannot-create-compute-instance-with-2-nodes.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":1,
        "Question_score":0,
        "Question_body":"I am not able to create computer cluster with 2 nodes, every time I try to do it, it gives the error - You only have enough quota to scale upto to 1 node. I am studying for azure exam DP-100. I am following the given learning paths, it was working fine for first 2-3 modules but after that I am not able to create cluster with 2 nodes and not able to proceed with my learning.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-28T07:15:52.07Z",
                "Answer_score":0,
                "Answer_body":"@KUSHGARG-1386 Are you using a free azure subscription? It looks like you have reached a quota limit for the instances you want to spin up in this cluster. You can go ahead and delete any unused clusters and retry this step again or navigate to the Usages + quotas page from the left pane of Azure portal and configure the quotas if permitted. More details about Azure ML workspace related quotas are documented here.\n\n\n\n\nIf the above mentioned limits cannot be changed then you might need to upgrade your subscription to pay as you go and try to increase the quotas from the Usages + quotas page",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Non-interactive login to registered dataset",
        "Question_creation_time":1595346764937,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/50386\/non-interactive-login-to-registered-dataset.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":36,
        "Question_score":0,
        "Question_body":"I'm trying to tune hyperparameters similar to the following guide: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-tune-hyperparameters\n\nMy PyTorch Dataset in train.py contains:\n\n ws = Workspace.from_config()\n ds = Dataset.get_by_name(ws, 'train')\n df = ds.to_pandas_dataframe()\n\nThis code works fine when run from the command-line, but when I submit a hyperparam tuning job to each node of a training cluster, I get the following error:\n\nWe could not find config.json in: \/mnt\/batch\/tasks\/shared\/LS_root\/jobs\/adamml\/azureml\/hd_ba15bb39-f0fe-47a7-afbc-d2f9968e9687_3\/mounts\/workspaceblobstore\/azureml\/HD_ba15bb39-f0fe-47a7-afbc-d2f9968e9687_3 or in its parent directories. Please provide the full path to the config file or ensure that config.json exists in the parent directories.\n\nIf I manually pass my subscription id, resource group, and workspace id, I don't get this error, but now every single hyperparam tuning experiment requires me to log in through the web portal. Is there a way to do a non-interactive login?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-23T20:05:42.24Z",
                "Answer_score":2,
                "Answer_body":"If I read the post correctly, you were trying to get an registered dataset within a submitted run. There, Workspace.from_config() won't work since there is no config.json file as the error suggested.\n\nAnd when you created an auth object which is InteractiveLoginAuth, it is expected to perform interactive login.\n\nWithin a run the recommended way to connect to current workspace it via:\n\nfrom azureml.core import Run\nrun = Run.get_context().experiment.workspace\n\n\n\nMeanwhile, there is way to pass in an dataset object to a run without involving register and workspace signin. If that fit your scenario better, please refer to the example in this document https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-train-with-datasets#access-and-explore-input-datasets\n\nfrom azureml.core import Dataset, Run\nrun = Run.get_context()\n# get the input dataset by name\ndataset = run.input_datasets['titanic']\n# load the TabularDataset to pandas DataFrame\ndf = dataset.to_pandas_dataframe()",
                "Answer_comment_count":3,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Not able to deploy a classification Model using autoML",
        "Question_creation_time":1596056740773,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/54834\/not-able-to-deploy-a-classification-model-using-au.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":3,
        "Question_score":1,
        "Question_body":"While deploying a classification model to use it as a web service from azure Ml studio, the deployment Pane stays put and no deployment status is shown and not completed even after 20-30 minutes.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-30T10:33:20.407Z",
                "Answer_score":0,
                "Answer_body":"@SaumyaBahukhandi-9175 Thanks for the question. We are able to deploy the AutoML classification sample successfully as shown below.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Endpoint stuck in \"Transitioning\" state",
        "Question_creation_time":1592942479500,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/39341\/azure-ml-endpoint-stuck-in-transitioning-state.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":2,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Hello,\n\nI am trying to deploy several Azure ML models as webservice endpoints using an AKS cluster. I have scripted the deployment process and created a new inference cluster using the Azure ML Studio interface. The first 2-3 endpoints deploy successfully and quickly reach a \"Healthy\" state (in under a minute), but any subsequent deployments are stuck in the \"Transitioning\" state endlessly (several hours before just deleting the endpoint).\n\nAny idea why this might be happening, or what I can do to fix this?\nIs there a limit to the number of endpoints available on an inference cluster?\n\nI noticed another question with a similar problem about 12 days ago, but that seems to have been resolved by deploying a fix to infrastructure.\n\nThank you in advance.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-01T15:30:20.057Z",
                "Answer_score":0,
                "Answer_body":"@PranavLakshminarayanan-4988 Our team has deployed a fix in all the regions yesterday. Could you please check if you are able to deploy the endpoint now?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-29T21:27:06.36Z",
                "Answer_score":0,
                "Answer_body":"Hi @romungi-MSFT , I am also facing similar issue while deploying a classification model. Is this latest release with the fix globally available? This was my first deployment of an autoML trained model in AML studio.\n\nAlso I opened another thread for this issue, before coming across this discussion\nhttps:\/\/docs.microsoft.com\/en-us\/answers\/questions\/54834\/not-able-to-deploy-a-classification-model-using-au.html\n\nThanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"In Azure ML Pipeline, unable to train the model with large dataset",
        "Question_creation_time":1595970998073,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/53724\/in-azure-ml-pipeline-unable-to-train-the-model-wit.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":0,
        "Question_score":0,
        "Question_body":"I want to train the model with binary logistic regression model,with a dataset of 3000 data points. while creating the pipeline , it fails at the training model step.\n\nPlease help me to train the model with large datasets or retrain the model continously.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-28T23:25:04.833Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nI haven't seen there is a limitation for training dataset size. May I know how you do the pipeline? If you are using Azure Machine Learning Designer, could you please try the enterprise version? https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-ml-pipelines#building-pipelines-with-the-designer\n\nAlso, I have attached a tutorial here for large data pipeline: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-pipeline-batch-scoring-classification\n\nPlease let me know more details (like the error message )about your issue if above not solved your problem.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AzureML Sending and parsing datarequests to update AZURE Blob Storage.",
        "Question_creation_time":1595285072103,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/49944\/azureml-sending-and-parsing-datarequests-to-update.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":36,
        "Question_score":0,
        "Question_body":"Hello dear,\n\nI need to be able to send data (HTTP request)s from different systems (SAP, for example) to update data in Azure Blob Storage.\n\nAnd correspondingly, I need to be able to accept coming requests with data from Azure Blob Storage, so that I can train ML models based on that.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Invalid graph - invalid dataset",
        "Question_creation_time":1595587512910,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/51962\/invalid-graph-invalid-dataset.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":1,
        "Question_score":0,
        "Question_body":"Invalid graph - Invalid dataset",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-25T07:57:18.377Z",
                "Answer_score":0,
                "Answer_body":"Thanks @ShowndaryaMadhavan for your quick response.\n\nI found that I had to press Generate Profile as in the picture below and then it worked",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2020-07-24T11:30:32.627Z",
                "Answer_score":0,
                "Answer_body":"Hi @ThalanayarMuthukumar-6317\n\nThere might be multiple reasons for this error:\n\nYour input dataset has invalid characters, bad values, or out of range values\n\n\nSome column is empty or contains too many missing values. ( You can use Clean Missing Data module to handle missing data in your dataset before you split )\n\n\nIf the data format is not supported.\n\n\nIf there are atleast 2 rows for Split Data to work\n\n\nIf you have specified desired rows to be split, make sure the number is less than the total rows,\n\nAnd, what mode of splitting have you chosen in Split Data? If you are splitting by rows, check if Stratified split is set to false. If it is true, check the target column you have chosen.\n\nHope this helps!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Machine Learning",
        "Question_creation_time":1595618344213,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/52106\/machine-learning-1.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":0,
        "Question_score":0,
        "Question_body":"My company provides analytics and machine learning services to enterprises. Now that we are moving over to Azure (from AWS and on-prem), I would like to understand how our workflow might change. The main aspects I am uncertain about is how we ingest data from our customers and how we deploy models for real-time and batch inference with minimal technical overheads.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-28T02:53:58.29Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nThanks for reaching out to us. For real-time machine learning deployment, we now have Azure Machine Learning Designer which is very easy to use and friendly for new user.\n\nFirst I want to share the workflow of Azure Machine Learning Service:\n\n\nWorkflow\nThe machine learning model workflow generally follows this sequence:\n\nTrain\n\nDevelop machine learning training scripts in Python, R, or with the visual designer.\nCreate and configure a compute target.\nSubmit the scripts to a configured compute target to run in that environment. During training, the scripts can read from or write to datastores. The logs and output produced during training are saved as runs in the workspace and grouped under experiments.\nPackage - After a satisfactory run is found, register the persisted model in the model registry.\n\nValidate - Query the experiment for logged metrics from the current and past runs. If the metrics don't indicate a desired outcome, loop back to step 1 and iterate on your scripts.\n\nDeploy - Develop a scoring script that uses the model and Deploy the model as a web service in Azure, or to an IoT Edge device.\n\nMonitor - Monitor for data drift between the training dataset and inference data of a deployed model. When necessary, loop back to step 1 to retrain the model with new training data.\n\nAnd Azure Machine Learning pipelines can help you make everything automatically: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-azure-machine-learning-architecture#ml-pipelines\n\nI have shared a basic workflow and quick start here for your reference: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-designer-automobile-price-deploy\n\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"ML Service started return InternalError 500 for batch requests. Code:14.",
        "Question_creation_time":1595609615540,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/52082\/ml-service-started-return-internalerror-500-for-ba.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":1,
        "Question_score":0,
        "Question_body":"ML Service started return InternalError for batch requests with Code:14.\nI enabled logs, logs are good, even results in storage are good.\n\nSingle request works without any issues.\n\n\n\n\n{\"error\":{\"code\":\"InternalError\",\"message\":\"Execution encountered an internal error.\",\"details\":[{\"code\":\"14\"}]}}\n\n\n\n\nBatch Request Log shows request as \"Finished\" and provides link to blob.\n\nAnybody knows what is a Code:14?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-28T02:45:54.197Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nSorry for your experience. Do you have a support plan under your subscription account? If yes, I will highly suggest you to open one support ticket for this problem. If not, please send me an email at Azcommunity@microsoft.com with this URL and also your subscription ID, I can help you to connect to a support engineer for deeper help.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"azure ML no kernel connected jupyter notebook",
        "Question_creation_time":1593201636980,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/40474\/azure-ml-no-kernel-connected-jupyter-notebook.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"I Setup a new ML Resource, cloned a tutorial notebook from azure ml and when i try to get &#34;Jupyter Kernel Failure&#34;. I do see at the top right no kernel is connected. i have set a compute. How am i able to start or restart the jupyter kernel?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-29T11:50:51.187Z",
                "Answer_score":0,
                "Answer_body":"@Orange-7012 If you are using ml.azure.com for Azure ML notebooks you should see an option to interrupt the kernel and restart it or use the menu option of your notebook for Kernel operations to perform the same.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-24T16:00:18.113Z",
                "Answer_score":0,
                "Answer_body":"hello romungi,\ni do not see the option to interrupt and restart the kernel, the kernel options is greyed out and does not let me view the menu.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML How to retrain published ML WebSerice (end point) using Jupyter Notebooks",
        "Question_creation_time":1595284669333,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/49994\/azure-ml-how-to-retrain-published-ml-webserice-end.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":37,
        "Question_score":0,
        "Question_body":"Hi Azure ML\n\nWe are using Azure Notebooks to train ML models. We are able to publish Web services then.(https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/tutorial-deploy-models-with-aml)\n\nOut data is stored in Azure Blob Storage. My qustions are:\n\n1- How can i remotely (as from a web point) update the data at Blob Storage?\n\n2- How Can I retrain model on that new data that is already publiched? Here I need some kind separate rest end point to be able to lunch retraining remotely.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-21T01:55:42.433Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nThe machine learning model workflow generally follows this sequence:\n\nTrain\n\nDevelop machine learning training scripts in Python, R, or with the visual designer.\nCreate and configure a compute target.\nSubmit the scripts to a configured compute target to run in that environment. During training, the scripts can read from or write to datastores. The logs and output produced during training are saved as runs in the workspace and grouped under experiments.\nPackage - After a satisfactory run is found, register the persisted model in the model registry.\n\nValidate - Query the experiment for logged metrics from the current and past runs. If the metrics don't indicate a desired outcome, loop back to step 1 and iterate on your scripts.\n\nDeploy - Develop a scoring script that uses the model and Deploy the model as a web service in Azure, or to an IoT Edge device.\n\nMonitor - Monitor for data drift between the training dataset and inference data of a deployed model. When necessary, loop back to step 1 to retrain the model with new training data.\n\n\n\n\nFor your scenario, I would highly recommend you try Azure Machine Learning Designer, which works with Azure Notebook well and easy to use.\n\nIF you still want to stick with Notebook, I think creating pipelines will be good to you. https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-create-your-first-pipeline?view=azure-devops\n\nThanks,\nYutong",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Relational Database for Automated Machine Learning",
        "Question_creation_time":1594992643703,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/48810\/relational-database-for-automated-machine-learning.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":34,
        "Question_score":1,
        "Question_body":"I'm trying to build a time-series Machine Learning experiment in Azure Machine Learning. However, I'm using outputs from previous functions which analyzes multiple factors using the same timestamp. For example, extracting all key phrases from customer surveys, and using it to forecast future sales. This creates a new row for each key phrase found, with all of the other survey data points and the same timestamp. This causes an error due to duplicate timestamps across multiple rows forecasting the same target value. I need to either make each timestamp\/survey on row, convert the columns to a list\/array, and have it iterate through each key phrase in that column, or use a relational database where the key phrases column is the foreign key to my table of keyphrases. Any recommendations on how to solve this? Thanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-23T13:27:08.11Z",
                "Answer_score":0,
                "Answer_body":"@WillSpagnoli-5705 Is the idea that these key phrases will be used to help predict the sale, or are they being added with goal of helping explain the prediction? We believe these phrases, if used for prediction, will not be very useful as the survey may not be known into the future - so we'd be predicting both the survey phrases and the sale. If the timedelta is small or the survey keywords are generally the same across time, the feature may provide more value.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How to run CuDNNLSTM on JupyterLab within Azure Machine Learning?",
        "Question_creation_time":1595404543680,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/50813\/how-to-run-cudnnlstm-on-jupyterlab-within-azure-ma.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":35,
        "Question_score":0,
        "Question_body":"Good day Everyone\n\nI am trying to train an LSTM based recurrent neural network using Azure Machine Learning JupyterLab. I have setup the VM instance to use a 6 core GPU. However, when i try to train my recurrent network using the efficient GPU based CuDNNLSTM network i get a \"ModuleNotFoundError: no module named tensorflow.contrib\". How can i rectify this so that i can be able to run CuDNNLSTM based code on my GPU?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-23T07:03:36.42Z",
                "Answer_score":0,
                "Answer_body":"Thank you. I am using the Microsoft Azure Machine Learning JupyterLab notebook so it comes pre-installed with all the packages and dependencies. So i have no idea what they are using unless if you know where i can check the versions used by Microsoft Azure?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Specify your own equation in ML.NET",
        "Question_creation_time":1594911016883,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/48563\/specify-your-own-equation-in-mlnet.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":35,
        "Question_score":0,
        "Question_body":"Is there a way to specify your own equation when using ML.NET in Visual Studio?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-20T17:51:59.093Z",
                "Answer_score":0,
                "Answer_body":"Hi @deskcheck1-0579\n\n\n\n\nUsing the tooling (Model Builder) in Visual Studio, not by default. However, you can take the generated code and add custom transforms after the fact. Using the API, you can use custom transforms. In both cases, what you'll want to use is the CustomMapping transform.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-21T14:44:12.81Z",
                "Answer_score":0,
                "Answer_body":"@deskcheck1-0579\n\n\n\n\nHi,\n\n\n\n\nWe have another forum for ML.NET only, I would highly recommend you to post your question there. https:\/\/github.com\/dotnet\/machinelearning\/issues\n\n\n\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Random forests on Azure GPU VM using the SDK",
        "Question_creation_time":1595050125193,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/49008\/random-forests-on-azure-gpu-vm-using-the-sdk.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":34,
        "Question_score":1,
        "Question_body":"Can you please share any code examples for training random forests with GPU on Azure using libraries.\nI want to run on the multiple nodes.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-20T07:47:48.033Z",
                "Answer_score":0,
                "Answer_body":"@vautoml-0887 Thanks for the question. You can run LightGBM with boosting=random_forest, Please follow the below documentation:\nhttps:\/\/github.com\/microsoft\/LightGBM\/blob\/master\/docs\/Parameters.rst#boosting\n\n\n\n\nHere is a general tutorial on how to run LightGBM on GPU, You can run it on any Azure GPU VM:\nhttps:\/\/github.com\/microsoft\/LightGBM\/blob\/master\/docs\/GPU-Tutorial.rst\n\n\n\n\nIf you need to run it on multiple nodes, there is also a distributed spark implementation available at https:\/\/github.com\/Azure\/mmlspark.\n\n\n\n\nRandom Forests for the GPU using PyCUDA: https:\/\/pypi.org\/project\/cudatree\/",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure Stream Analytics: ML Service function call in cloud job results in no output events",
        "Question_creation_time":1594918621430,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/48592\/azure-stream-analytics-ml-service-function-call-in.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":4,
        "Question_comment_count":0,
        "Question_follower_count":37,
        "Question_score":1,
        "Question_body":"Hey,\nI've got a problem with an Azure Stream Analytics (ASA) job that should call an Azure ML Service function to score the provided input data.\nThe query was developed und tested in Visual Studio (VS) 2019 with the \"Azure Data Lake and Stream Analytics Tools\" Extension.\nAs input the job uses an Azure IoT-Hub and as output the VS local output for testing purposes (and later even with Blobstorage).\nWithin this environment everything works fine, the call to the ML Service function is successfull and it returns the desired response.\nUsing the same query, user-defined functions and aggregates like in VS in the cloud job, no output events are generated (with neither Blobstorage nor Power BI as output).\nIn the ML Webservice it can be seen, that ASA successfully calls the function, but somehow does not return any response data.\nDeleting the ML function call from the query results in a successfull run of the job with output events.\n\nFor the deployment of the ML Webservice I tried the following (working for VS, no output in cloud):\n\nACI (1 CPU, 1 GB RAM)\n\n\nAKS dev\/test (Standard_B2s VM)\n\n\nAKS production (Standard_D3_v2 VM)\n\nThe inference script function schema:\n\ninput: array\n\n\noutput: record\n\n\n\n\n\n\n\nThe ASA job subquery with ML function call:\n\n\"Sequence\" is a subquery that aggregates the data into sequences (arrays) with an user-defined aggragate.\n\nI hope the provided information is sufficient and you can help me.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-16T21:46:51.443Z",
                "Answer_score":0,
                "Answer_body":"Hi, can you share a link to your swagger? This is a public link that can be accessed without any keys.\n\nFew questions:\n1. In VS 2019, did you test using live data flowing in from your IoT Hub? Or did you use a sample input file\/local input?\n2. You mention that the input is an array, however the sample input says [[1.]*18]. I am trying to understand what this represents. And what does numpyfySeq UDF do?\n3. Can you open the ml UDF on the portal and see if the \"function signature\" is listed correctly?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-17T07:58:51.603Z",
                "Answer_score":0,
                "Answer_body":"Thank you for your reply.\n\nYes sure, here it is:\nswagger.json\n\nTo your questions:\n\nIn VS i was using live data from the IoT-Hub.\n\n\nThe numpyfySeq UDF looks like this:\n\n\nList item\n\nIt uses the aggregates created in the \"Sequence\" subquery and puts them all together in a N x 18 size array.\nThe \"Sequence\" subquery uses also an UDA (\"stackSequence\") to aggregate data into arrays of arbitrary length (all occured events in a hopping window with width N seconds and hop size 1 second should be appended to an array).\nPart of the \"Sequence\" subquery:\n\nThe used schema [[1.]*18] creates a reduced form (1 x 18 shape) of the desired input array shape and with the optional parameter \"enforce_shape=False\" in the decorator i could manage to call the function with an abitrary N x 18 shape array.\n\nOn the portal the function signature is listed correctly:",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-17T22:25:58.167Z",
                "Answer_score":0,
                "Answer_body":"Thanks for the details. Everything seems like it is configured correctly. And from what you say, it sounds like this scoring works well when using VS but not when job is running? One last thing to check is maybe the event ordering settings of your job on the portal. When job is running, you can also see the metric \"late events\" to see if these inputs are getting filtered out.\n\nIn this case it will require additional debugging from our team. Can you please file a support ticket and reference this thread?",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-18T10:09:45.22Z",
                "Answer_score":0,
                "Answer_body":"Yes, this is correct, in VS the scoring works well and works both with local and blobstorage output and when the job is running, the function is called successfully, but no output is generated.\nI checked the metric \"late input events\" within a period of the last 30 days and the rate is very low (0.0003 %).\n\nI will file a support ticket then.\nThanks for your help so far.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Enpoint deployment failed EAST US region",
        "Question_creation_time":1594945530060,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/48609\/azure-ml-enpoint-deployment-failed-east-us-region.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":44,
        "Question_score":0,
        "Question_body":"I have an Azure ML Real-time inference endpoint deployed ran for a month till yesterday. Today it is in the state of \"Failed\".\n\nI did create a new compute and did a new deployment in the same region EAST US and it failed again.\n\nWhat's going? Is this just a problem for me or a general issue?\n\nThanks\n-Dali",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-17T02:30:29.753Z",
                "Answer_score":0,
                "Answer_body":"Hi, thanks for reaching out. I successfully deployed in the east us region. Please review the following troubleshooting guidelines. Also check for any service\/resource health issues that could be impacting your service. Let me know if you're still experiencing issues afterwards and please share the logs so we can investigate further. Thanks.",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Feature request: module for selecting rows in a dataset",
        "Question_creation_time":1594758444380,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/47022\/feature-request-module-for-selecting-rows-in-a-dat.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":39,
        "Question_score":0,
        "Question_body":"I'm looking for a module similar to Select Columns in Dataset but for rows. For example, one of the columns in my dataset is a string containing the quality control level. If the QC level equals some value, I would like to keep that row and discard the rest of the rows. Similarly, my dataset contains -999 values to represent NaNs, but I have no way of removing these values without writing a custom Python script to do so.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-14T20:31:07.72Z",
                "Answer_score":0,
                "Answer_body":"Thanks for the feedback! We appreciate your input, I will forward your content to product group for reviewing. ^^\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-16T05:36:20.9Z",
                "Answer_score":1,
                "Answer_body":"You could use Execute Python Script module.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Question: how to define custom Model in Designer",
        "Question_creation_time":1594757599337,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/46909\/question-how-to-define-custom-model-in-designer.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":38,
        "Question_score":0,
        "Question_body":"In Azure ML Designer, I can't figure out how to define a custom Model. The builtin NN Regression module has many bugs (will open a separate issue for those), so I need to make my own custom model. The closest thing I've found so far is Create Python Model, but this has the following limitation:\n\nCan't parametrize model, so doesn't work with Tune Model Hyperparameters module\n\nIs there any way to design my own model, and is it possible to contribute this upstream for others to use?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-16T08:26:49.827Z",
                "Answer_score":0,
                "Answer_body":"@AdamStewart-2203 Yes, I think the current custom python model has a limitation while using it with Tune Model Hyperparameters. Our PG would like to discuss more about the contributions or inputs for this module, Could you please email us at AzCommunity[at]microsoft[dot]com so we can guide you accordingly.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Question: what framework\/language does Designer use behind the scenes?",
        "Question_creation_time":1594757836773,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/46976\/question-what-frameworklanguage-does-designer-use.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":38,
        "Question_score":0,
        "Question_body":"I'm using Azure ML Designer, but it isn't clear what framework\/language is being used behind the scenes. For example, deep learning is incredibly computation-heavy, so I would like to run any matrix multiplications on a GPU instead of on a CPU. For the builtin modules, does the framework support GPU operations, or only CPU? If I have a complex pipeline, are all steps in the pipeline (that don't depend on each other) run in parallel? Or does that require the use of a Compute Cluster instead of a Compute Instance? How are NaNs handled in the dataset? So far I've only encountered seg faults with the builtin models, so I'm assuming they aren't handled. Also, why does the pipeline take so long to run? If I code things in pure pandas, the pipeline should finish in under a second on my laptop, but takes several minutes to run in Azure ML Designer, regardless of which hardware I choose.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-16T07:48:59.63Z",
                "Answer_score":0,
                "Answer_body":"@AdamStewart-2203 Thanks for the questions. For any errors that are internal or faults our PG team looks at the issues that are submitted from Azure ML portal. The smiley option on the top right corner of the portal helps you to send these errors and queries related to the pipelines or experiments to our service engineers who can lookup the issue for more details and advise.\n\nIt would be great if you could also email us at AzCommunity[at]microsoft[dot]com to discuss more about the feature requests and questions as some of them might be in development or some may need more information to create a backlog.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Real-time endpoint response is empty",
        "Question_creation_time":1592313268633,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/36610\/real-time-endpoint-response-is-empty.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":5,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Hi, I've created and deployed NLP pipeline as a real-time endpoint, but the response that I get is an empty result ( {\"Results\":{}} ) with Status 200 OK.\n\n\n\n\nI have the Owner role, so i think that the permission is not a problem. I've also tried to deploy the preset experiment \"Sample 1: Regression - Automobile Price Prediction (Basic)\" using the same resources and it returned the results without a problem.\n\nIn the training pipeline, I've used the train and validation datasets. After creating the real-time inference pipeline, it automatically created two Web Service inputs the one linked to the train dataset input is irrelevant in the real-time inference pipeline as it's used only to create the Vocabulary for the Extract N-Gram Features from Text module linked to the validation dataset.\nAfter that, I've deleted the Web Service input connected to the training dataset and tried to deploy the real-time endpoint.\n\n\n\n\n\n\nAfter submitting the training pipeline, I've saved the Result Vocabulary from the Extract N-Gram Features from Text module that is connected to the training dataset and used it as an input vocabulary for the N-Gram module (ReadOnly vocabulary mode) in the real-time inference pipeline and deployed that as a real-time endpoint.\n\n\n\n\nIn both cases above, I didn't get any errors, scoring and evaluation of a model are correct but the response from the endpoint is empty.\nIt's worth mentioning, that if I leave the real-time pipeline as is (with two inputs) it doesn't work because of the parameter settings in the Extract N-Gram Features from Text module where training dataset is connected.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-01T07:58:21.297Z",
                "Answer_score":0,
                "Answer_body":"@AntonioAli-4907 Is it possible to share details of your experiment and issue from the ml.azure.com portal for a service engineer to lookup the issue? This option is available from the top right hand corner of the portal by clicking the smiley face, Please select the option Microsoft can email you about the feedback along with a screen shot so our service team can lookup and advise through email.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning with on premise SQL Server",
        "Question_creation_time":1592874857830,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/38894\/azure-machine-learning-with-on-premise-sql-server-1.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"Hi is there a way for Azure Machine Learning to be able to perform analytics using data from an on premise SQL Server?\n\nOnly found the below article which is for Azure Machine Learning Studio (classic):\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/use-data-from-an-on-premises-sql-server\n\nThanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-23T08:17:48.573Z",
                "Answer_score":1,
                "Answer_body":"@conrad Here is the link to connect with the Azure SQL server.\nhttps:\/\/stackoverflow.com\/questions\/61806350\/database-communication-link-error-occurded-on-azure-ml-service-used-azure-sql-s\/61950481#61950481",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2020-06-25T18:27:33.377Z",
                "Answer_score":0,
                "Answer_body":"Light Servi\u00e7os de Eletricidade",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"User program failed with ValueError: ZIP does not support timestamps before 1980",
        "Question_creation_time":1594652762620,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/46217\/user-program-failed-with-valueerror-zip-does-not-s.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":38,
        "Question_score":0,
        "Question_body":"Hi i'm running into an issue in Azure ML-\n\nI'm getting the error \"User program failed with ValueError: ZIP does not support timestamps before 1980\"\nwhen it calls the\n\nwhen i run the following part of the code as a part of a pipeline\n\nfrom azureml.train.estimator import Estimator\n\nscript_folder = os.getcwd()\nprint(\"script folder : \",script_folder)\nest = Estimator(source_directory=script_folder,\ncompute_target=compute_target,\nenvironment_definition=env,\nentry_script='train.py')\n\nrun = exp.submit(config=est)\nprint(run)\n\nNot sure what is causing this but when i run the file independently of the pipeline it runs fine",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-15T16:14:03.76Z",
                "Answer_score":0,
                "Answer_body":"There may be an issue with the timestamp of your file or parent folder. Try moving your file to another directory or creating a new workspace, if that doesn't help, please let me know so we can investigate further. The product team are aware of this issue and currently working on a resolution. Thanks.\n\nNote: try adding the following to the parent script to create a new directory (outside of the current working directory) and copy the child script there:\n\n # create child_run_directory\n     os.makedirs('\/tmp\/child_dir', exist_ok=True)\n    \n     os.system('cp .\/child.py \/tmp\/child_dir\/child.py')\n    \n     \n    \n     # kick off child run\n    \n     child_config = ScriptRunConfig(\n    \n         source_directory=\"\/tmp\/child_dir\",\n    \n         script='child.py',\n    \n         run_config=rc,\n    \n         ...\n    \n         )",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Time out after Succeded",
        "Question_creation_time":1594192651827,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/44044\/time-out-after-succeded.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":32,
        "Question_score":0,
        "Question_body":"Hi, I was trying to deploy my model as a web service after I run this command (Webservice.deploy_from_model), it said it was succeded. After that, I run this command (service.wait_for_deployment). this process told me the \"Time out\" condition. My region is southeast Asia. can you help me what's wrong with my development?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure Automated ML(interface) Does k-fold cross validation in autoML use just random sampling?",
        "Question_creation_time":1593759166663,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/42551\/azure-automated-mlinterface-does-k-fold-cross-vali.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":20,
        "Question_score":0,
        "Question_body":"Is k-fold cross validation in automated ML(interface) stratified sampling or random sampling by default?\nI have ran several automated ML experiments using a training set with five data points for the least common class(say class A), and started to wonder if each CV set is guaranteed to have at least one element from the class A when I set k as 4 or 5.\nI read the 'Train and validation data' part in the link below\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-configure-auto-train\nand want to make sure if it's okay to use 4-fold cv or 5-fold cv.\nThanks.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-06T10:45:14.49Z",
                "Answer_score":0,
                "Answer_body":"Thanks for the question. We don't expose the sampling methods.If possible can we discuss offline on this, please send an email to AzCommunity@microsoft.com to discuss further on this. Creating an AutoML tool is always a balance of automating as much as possible for the user while allowing advanced users to have deeper control of the process. You can consider some pre-processing on the data before handing off to AutoML. A few techniques that worked with that you may want to consider or combine with SMOTE:\n\u2022 Downsample the majority class\n\u2022 Stratified sampling\n\u2022 ADASYN for creating synthetic observations\nIn fact, the SMOTE paper actually references a few cases where when SMOTE is combined with downsampling, it outperforms SMOTE on its own.\nHere is the helpful link for cross-validation folds.\nhttps:\/\/github.com\/Azure\/MachineLearningNotebooks\/issues\/596",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Question: distinction between Modules and Models in Designer",
        "Question_creation_time":1594756919963,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/46991\/question-distinction-between-modules-and-models-in.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":38,
        "Question_score":0,
        "Question_body":"In Azure ML, under designer, there are 3 categories:\n\nDatasets\n\n\nModules\n\n\nModels\n\nDatasets are pretty straightforward, but I don't understand the distinction between Modules and Models. As an ML researcher, when I think of a \"model\", I think of something like linear regression or SVM. However, those are listed under Modules -> Machine Learning Algorithms. So what exactly qualifies as a Model?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-14T20:39:44.477Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nThanks for reaching out.\n\nModel is a concept of Machine Learning itself. A machine learning model is a file that has been trained to recognize certain types of patterns. You train a model over a set of data, providing it an algorithm that it can use to reason over and learn from those data. Once you have trained the model, you can use it to reason over data that it hasn't seen before, and make predictions about those data. For example, let's say you want to build an application that can recognize a user's emotions based on their facial expressions. You can train a model by providing it with images of faces that are each tagged with a certain emotion, and then you can use that model in an application that can recognize any user's emotion.\n\nModules is one of the concept of Azure Machine Learning Designer. Each module represents a set of code that can run independently and perform a machine learning task, given the required inputs. A module might contain a particular algorithm, or perform a task that is important in machine learning, such as missing value replacement, or statistical analysis.\n\nLet me know if you have any question.\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Bug report: can't parametrize # hidden node or momentum in NN regression model",
        "Question_creation_time":1594758142250,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/47011\/bug-report-cant-parametrize-hidden-node-or-momentu.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":38,
        "Question_score":0,
        "Question_body":"I'm using the NN regression model in Azure ML Designer, but it appears to have a bug. If I switch trainer mode to ParameterRange, it allows me to use a semicolon-separated list of hyperparameters for learning rate and epochs. However, I'm unable to use a semicolon-separated list of hyperparameters for number of hidden nodes or momentum. Since the number of hidden nodes is the most commonly tuned hyperparameter for a MLP, this module doesn't seem particularly useful if I want to use it to tune hyperparameters.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-14T20:29:26.033Z",
                "Answer_score":0,
                "Answer_body":"Thanks for reaching out to us. We will investigate this deeper and let you know any update.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-14T20:33:46.64Z",
                "Answer_score":0,
                "Answer_body":"You can provide this feedback over here on uservoice\nhttps:\/\/feedback.azure.com\/forums\/257792-machine-learning",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Feature request: more customizability in builtin models",
        "Question_creation_time":1594758735000,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/46982\/feature-request-more-customizability-in-builtin-mo.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":38,
        "Question_score":0,
        "Question_body":"In Azure ML Designer, I would like to customize and parametrize other aspects of the models. For example, in the NN Regression model, I would like to try various optimizers (Adam, Adagrad, SGD) and activation functions (ReLU, Sigmoid, Tanh).",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-14T20:33:16.577Z",
                "Answer_score":0,
                "Answer_body":"You can provide this feedback over here on uservoice\nhttps:\/\/feedback.azure.com\/forums\/257792-machine-learning",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-14T20:33:28.937Z",
                "Answer_score":0,
                "Answer_body":"Thanks for the feedback! We appreciate your input, I will forward your content to product group for reviewing. We will contact you if more information needed. ^^\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Feature request: module for handling timestamps",
        "Question_creation_time":1594758338030,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/47021\/feature-request-module-for-handling-timestamps.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":38,
        "Question_score":1,
        "Question_body":"In Azure ML Designer, there are dozens of builtin Modules for data transformation, but none of them can handle timestamps. What I'm looking for is a module in which the user:\n\nSelects which column of the input dataset contains a timestamp\n\n\nSelects which output columns they would like to compute, such as: year, month, day, hour, min, sec, DOY, DOW, etc.\n\n\nSelects how they want to perform the operation: inplace, append, etc.\n\nIf you can show me how to write a custom Module and contribute it upstream, I would be more than happy to do this myself.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-14T20:30:34.37Z",
                "Answer_score":0,
                "Answer_body":"Thanks for the feedback! We appreciate your input, I will forward your content to product group for reviewing. ^^\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-14T20:32:47.193Z",
                "Answer_score":1,
                "Answer_body":"You can provide this feedback over here on uservoice\nhttps:\/\/feedback.azure.com\/forums\/257792-machine-learning",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Feature request: models only support single prediction column",
        "Question_creation_time":1594758597390,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/46949\/feature-request-models-only-support-single-predict.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":38,
        "Question_score":0,
        "Question_body":"Many machine learning tasks involve input data in the form of scalars, vectors, matrices, and higher-order tensors. Similarly, the output predictions are often in the same format. The builtin NN regression model in Azure ML Designer only supports scalar predictions (single column of ground truth labels), but many tasks involve multiple columns. For example, you might be trying to predict mean and std dev, or a bounding box.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-14T20:32:43.09Z",
                "Answer_score":0,
                "Answer_body":"Thanks for the feedback! We appreciate your input, I will forward your content to product group for reviewing. ^^\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Bug report: Apply Math Operation doesn't cache and reuse results from previous run",
        "Question_creation_time":1594757991143,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/47002\/bug-report-apply-math-operation-doesnt-cache-and-r.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":38,
        "Question_score":0,
        "Question_body":"In Azure ML Designer, I have a complex data preprocessing pipeline. One of the main features of Designer pipelines is that they are supposed to cache the results of each run, so that they don't need to be re-executed every time if nothing that they depend on has changed. This feature works correctly for all of the nodes in my graph except for the Apply Math Operation nodes. This results in the second half of my pipeline needing to be re-run every time I add a new node.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-14T20:28:46.2Z",
                "Answer_score":0,
                "Answer_body":"Thanks for reaching out to us. We will investigate this deeper and let you know any update.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Machine Learning",
        "Question_creation_time":1594208627597,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/44135\/machine-learning.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":32,
        "Question_score":1,
        "Question_body":"i have problem with detecting the objects using the ML.NET and draw a boundary boxes\nand i cannot find an example or module that i can learn.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-14T19:13:54.527Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nObject detection is one of the classic problems in computer vision: Recognize what objects are inside a given image and also where they are in the image. For these cases, you can either use pre-trained models or train your own model to classify images specific to your custom domain. This sample uses a pre-trained model by default, but you can also add your own model exported from Custom Vision.\n\nI have a sample here for you:\n\nhttps:\/\/github.com\/dotnet\/machinelearning-samples\/tree\/master\/samples\/csharp\/end-to-end-apps\/ObjectDetection-Onnx\n\nThis sample consists of two separate apps:\n\nA WPF Core desktop app that renders a live-stream of the device's web cam, runs the video frames through an object detection model using ML.NET, and paints bounding boxes with labels indicating the objects detected in real-time.\nAn ASP.NET Core Web app that allows the user to upload or select an image. The Web app then runs the image through an object detection model using ML.NET, and paints bounding boxes with labels indicating the objects detected.\nThe Web app shows the images listed on the right, and each image may be selected to process. Once the image is processed, it is drawn in the middle of the screen with labeled bounding boxes around each detected object as shown below.\n\nLet me know if you have any question.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"While running an Azure ML Experiement, I get \"File Not found\" error when attempting to find ODBC driver for python pyodbc.connect command",
        "Question_creation_time":1594589100353,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/45912\/while-running-an-azure-ml-experiement-i-get-file-n.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":3,
        "Question_comment_count":0,
        "Question_follower_count":45,
        "Question_score":0,
        "Question_body":"Hello:\n\nThis is the python command. It works fine in my local Windows environment and I can connect to the remote Azure SQL DB that I want to connect to.\n\nsql_conn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server}; ...\n\nHowever, when I run my az ml submit-run CLI command in order to run an experiment in Azure Machine Learning, I get this error.:\n\n[01000] [unixODBC][Driver Manager]Can't open lib 'ODBC Driver 17 for SQL Server' : file not found\n\nSo, it seems that AML is running its containers in Linux. Ok....I have no problem with that, but how do I configure either my <filename>.runconfig or my .yaml file to tell the Linux machine where to find the driver?\n\nI can't really connect to a virtual machine and install this driver if I use AML, right? It's needs to be done in one of the aforementioned files, right?\n\nDan",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-13T12:10:47.957Z",
                "Answer_score":0,
                "Answer_body":"@DanWellisch-1648 Are you using a Jupyter notebook from Azure ML portal to run the commands to connect to a SQL DB? If Yes, you can install the required library on your notebook VM and try to connect again.\n\n\n\n\nIn this case you should have enabled SSH access to your compute instance to login and install the required library.\n\n\n\n\n\n=>Enable SSH access\n\n\n\n\n\n\n\n\n=>Login to the terminal of the instance using the link after the compute is created. Install the library if not available already\n\n\nsudo dpkg -l|grep msodbcsql # If this command return blank the you know that the driver indeed is missing on your server and that you need to install it\n\n #And to install this driver you can run the following:\n         \n sudo ACCEPT_EULA=Y apt-get install msodbcsql17\n\n\n\n\n\n\n\n=>The following files should be available which should help to configure and use the drivers.\n\n\n\n\nFirst a new directory located in \/opt\/microsoft\/msodbcsql17\/ this is the directory where the libraries are installed\n\n\n\n\nSecond a file in \/etc\/ called odbcinst.ini that will host the paths for the libraries and that python will need\n\n\n\n\nThird the main library that is hosted in\/opt\/microsoft\/msodbcsql17\/lib64\/libmsodbcsql-17.4.so.1.1 and this library should have all the dynamic libraries attached by default.\n\n\n\n\n\n\n\nYou can then run the experiment again to check if the connection works.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-13T15:28:23.887Z",
                "Answer_score":0,
                "Answer_body":"Hello:\n\nI am NOT running from a Jupiter Notebook. I am running on my laptop with the az ml submit-run CLI command which specifies my python code, run config, .yml file.\n\nBut, if I create an Azure notebook while logged in to the portal, and run through the steps you mentioned, that would configure my compute for me and my AZ ML Submit-Run CLI command should then find it's ODBC library, correct?\n\nDan",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-13T15:56:13.76Z",
                "Answer_score":0,
                "Answer_body":"@DanWellisch-1648 You can always from within your train script use pyodbc to access on prem SQL server as long as there\u2019s network connectivity.\nYou will need to define a custom docker image to configure the driver if you use on demand AML compute. It\u2019s easier to use VM:\n\n\n\n\nSee this: https:\/\/github.com\/mkleehammer\/pyodbc\/wiki\/Connecting-to-SQL-Server-from-Linux\n\n\n\n\n\nor",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Does Azure Ml support training deep learning models like yolov3, faster R-CNN, Deeplabv3+, Mask R-CNN",
        "Question_creation_time":1594372489527,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/45193\/does-azure-ml-support-training-deep-learning-model.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":32,
        "Question_score":0,
        "Question_body":"Does the azure ml supports training and inference task for deep learning models for object detection, semantic segmentation models.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-10T09:26:16.96Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nAzure Machine Learning appears to support Yolov3 and Faster R-CNN:\nhttps:\/\/azure.microsoft.com\/en-us\/blog\/new-azure-machine-learning-updates-simplify-and-accelerate-the-ml-lifecycle\n\nhttps:\/\/devblogs.microsoft.com\/cse\/2017\/10\/24\/bird-detection-with-azure-ml-workbench\n\n\n\n\nBest regards,\nLeon",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-07-10T20:57:55.633Z",
                "Answer_score":0,
                "Answer_body":"Thanks for reaching out. Yes, Azure ML supports deep learning models for object detection using ONNX. Please review this document for more details. Models from many frameworks including TensorFlow, PyTorch, SciKit-Learn, Keras, Chainer, MXNet, MATLAB, and SparkML can be exported or converted to the standard ONNX format. Once the models are in the ONNX format, they can be run on a variety of platforms\/devices including Azure Machine Learning services.\n\n\n\n\nMany models including object detection can be represented as ONNX models and can be obtained through the following ways:\n\nTrain a new ONNX model in Azure Machine Learning or by using automated Machine Learning capabilities\n\n\nConvert existing model from another format to ONNX\n\n\nGet a pre-trained ONNX model from the ONNX Model Zoo\n\n\nGenerate a customized ONNX model from Azure Custom Vision service\n\nFurthermore, you can deploy, manage, and monitor your ONNX models in Azure ML. Please check out the following examples on how-to-use-azureml\/deployment\/onnx in Python as well as samples in other programming languages. Let us know if you have any further questions or concerns. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Machine Learning Model Deployment",
        "Question_creation_time":1593620777527,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/41755\/machine-learning-model-deployment.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":1,
        "Question_score":0,
        "Question_body":"I am new to ML model and am researching using Azure Databricks and MLFlow to train a model. My question is once the model is created, is there a way to host the model that can be downloaded and inferenced remotely ? I am looking for options other than deploying it as a REST endpoint.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-07T08:37:52.993Z",
                "Answer_score":0,
                "Answer_body":"@MaheshSivan-3675 I think this video from MS build 2019 will help you understand on the integration of databricks with mlflow and Azure ML. Some of the UI or ML portal seen in demo might have changed but the functionality remains the same.\n\n\n\n\nWhile using Azure ML you can register and download your model which can be deployed to different targets other than a REST API.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning Jupyter Lab Git options",
        "Question_creation_time":1594373340610,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/45187\/azure-machine-learning-jupyter-lab-git-options.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":30,
        "Question_score":1,
        "Question_body":"Hi,\nI&#39;m trying to setup an integration between a GITHub repository and my Jupyter Lab but I&#39;m struggling to find the GIT options in my Jupyter Lab application.\n\nI was expecting to see a Git clone button, a Git option on the toolbar and also the same option on the left pane but there is nothing GIT related.\n\nI&#39;ve already installed successfully the following:\n\npip install jupyterlab-git\npip install --upgrade python-gitlab\n\nBut nothing happens.\nWhen I try to clone a GIT repository, I get the folders\/files but then I can&#39;t interact with it. It&#39;s just copying it into my space but then I can&#39;t push\/pull anything.\n\nCan you help me on this?\n\nThank you,\nCarla",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-10T10:56:41.087Z",
                "Answer_score":1,
                "Answer_body":"I found the answer to my question by following the steps here:\n\nhttps:\/\/www.oreilly.com\/library\/view\/jupyterlab-quick-start\/9781789805543\/94288841-0158-4a98-8151-4a90ea9bf2da.xhtml",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"More convenient service to read avro files from Azure Data Lake Gen2",
        "Question_creation_time":1591655876897,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/33682\/more-convenient-service-to-read-avro-files-from-az.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Hi,\n\nI have to read lots of avro files created by an Event Hub Capture in a Data Lake Gen2. Data must be filtered, processed and then applied to train a machine learning model. I'm considering Azure Databricks and the Azure Machine Learning service itself for this ETL.\n\nWhat is the best option in order to take advantage of the hierarchical namespace of files in the lake? Is it definitely Databricks, due to the Hadoop compatible access to data? What about working with datastores and the python SDK in AML service? Would be the data access efficiency comparable?\n\nOne critical requirement I have is the data filtering step, i.e. reading from the lake just the captured avro files containing specific data (unable to be inferred from the file path though). Does Spark-avro in Databricks give some advantage in this regard? For example with respect to the azure.storage.filedatalake python package, which doesn't offer avro-specific functions.\n\nThanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-10T23:48:13.263Z",
                "Answer_score":0,
                "Answer_body":"Hello @acedola\n\n\n\n\nWelcome to the Q&A .\n\n\n\n\nYou never mentioned as to how the data is structured on the HNS as thats the key . You can read about that here https:\/\/docs.microsoft.com\/en-us\/azure\/storage\/blobs\/data-lake-storage-namespace#the-benefits-of-a-hierarchical-namespace\n\n\n\n\nOn the data filtering part , i think ADB will just do fine , moreover the data is well structure on the HNS , it will be more performant .\n\n\n\n\nThanks Himanshu\n\n\n\n\nPlease do consider to click on \"Accept Answer\" and \"Up-vote\" on the post that helps you, as it can be beneficial to other community members",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"model status unhealthy unable to debug",
        "Question_creation_time":1592232758653,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/36115\/model-status-unhealthy-nable-to-debug.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":13,
        "Question_score":1,
        "Question_body":"Hi team,\n\nI am new to azure and trying to deploy model with multiple files on azure. after deployment process it was showing unhealthy status.how can i debug?\n\nThank you",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-15T20:46:49.827Z",
                "Answer_score":0,
                "Answer_body":"Hello @DeepeshMahule-7481,\n\n\n\n\nThanks for using Azure! it looks like you are seeing the service state. During model deployment, you may see the service state change while your ML model fully deploys this is not the final state. Give your deployment some more time. To learn more about the differnt service state please read this documentation. If you are still seeing the unhealthy status after a few hours please let us know so we can investigate further.\n\n\n\n\n\n\n\nBest,\n\n\n\n\nGrace",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Is there a way not to record the source directory files snapshot or delete it after an AML pipeline run?",
        "Question_creation_time":1592380547767,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/37071\/is-there-a-way-not-to-record-the-source-directory.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"I am running experiments with AML pipeline and I do not want to store the source directory files of my script steps in the experiment panel after the run is completed (when I enter a run from the experiments panel, there is a snapshot containing those files). I know experiment runs can't be deleted, only archived, but this is not what I'm looking for.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-17T13:20:35.593Z",
                "Answer_score":0,
                "Answer_body":"@CarlosAlcantara-3452 If you are submitting the pipeline using the SDK you can prevent unnecessary files from being included in the snapshot using an ignore file (.gitignore or .amlignore) file. The syntax used allows you to exclude files using syntax and patterns. Here is the link to the documentation that talks about it in a bit of detail.",
                "Answer_comment_count":3,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Automated ML(interface) how do models created from an Automated ML experiment handle Imbalanced Data?",
        "Question_creation_time":1593407718737,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/40727\/azure-automated-mlinterface-how-do-models-created.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"I have run automated ML experiments with imbalanced data (10:1, 20:1, sometimes 30:1) and deployed the best models which all showed fantastic results.\n\nWhen I looked up the link\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-manage-ml-pitfalls#identify-models-with-imbalanced-data\n, it says Azure automated ML can properly handle imbalance of up to 20:1.\nI started to wonder where the ratio 20:1 came from.\n\nAs far as I understand, Azure automated ML doesn't use upsampling, downsampling or resampling, and is more focused on a column of weights to make a class more or less important, and a performance metric dealing better with imbalanced data.\n\nDoes this 20:1 come from some theory? or from tons of experiments already conducted?\n\n\n\n\n\nAzure automated ML shows the result with warning when I use 30:1(or more) imbalanced data, but I still wonder why it is 20:1.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-06T10:22:39.317Z",
                "Answer_score":0,
                "Answer_body":"In AutoML we use 5% minority class as threshold to classify imbalance\/non-imbalance. This is a heuristic, and is one guideline produced in the Guardrails to the question \u201cAt x% threshold level is the dataset balanced?\u201d. Since it is not possible to absolutely classify imbalance in all cases (depending on the dataset and its size and distribution, 5% or 10% or even higher may mean imbalance, whereas for very large datasets the minority class may have sufficient training samples for model to learn and get a reasonable imbalance-appropriate metric such as weighted AUC or balanced accuracy), current Guardrails serve the goal of surfacing \u201csubstantial\u201d imbalance to user so the user can take any of the following measures:\n\n\u2022 When the user knows (either from their knowledge of their own data or from guardrails) that there is imbalance, Automated ML provides an option in the Automated ML config to provide sample weights \u2013 a user-specified weight array where user can specify to weight each sample with a weight. That way they can weigh the minority class more when submitting the data into Automated ML config. We will soon provide weighting option for imbalance classes from within AutoML that will be activated automatically when imbalance is detected.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2020-07-01T06:12:08.183Z",
                "Answer_score":0,
                "Answer_body":"@JiinJeong-9636 The following is the road-map for this. The ratio for detecting imbalance has been updated to 1:5 rather than 1:20, meaning that AutoML would identify a dataset to have imbalance when the number of samples in the least common class is equal to or fewer than the number of samples in the most common class. This should be available within a week. The reason for doing this is as follows:\nThe ratio of 1:20 only detects very severe imbalance, whereas we've noticed both in our experiments as well as literature & industry practices, that even the treatment of mild imbalance (something like 1:5) could offer better results.\nThe ratio is based on comparing least common to most common as opposed to least common class to all the samples, because the former gives more consistent results empirically.\nThe solution to tackle imbalanced data is to apply weights internally to the dataset in the inverse proportion of the number of samples belonging to a particular class. Here's how we do it:\nIf the 1:5 ratio isn't satisfied, we trigger a message via Guardrails saying that \"PASSED: No Class Imbalance\" If the ratio isn't satisfied, i.e. imbalance is detected, then we run an experiment with sub-sampled data and check if the above solution of \"applying weights for class balancing\" proves to be better.\nIf the experiment is not leading to better results, we don't apply weights, and trigger a message in Guardrails saying that \"ALERT: Class Imbalance is present\" If the experiment does lead to better results, we apply the weights and fix the imbalance, and trigger a message in Guardrails saying that \"DONE: Class Imbalance was fixed\".\nThe documentation update is in-progress for Handling imbalance data of the following document.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Machine Learning Code",
        "Question_creation_time":1593978457140,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/43081\/machine-learning-code.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":1,
        "Question_follower_count":37,
        "Question_score":0,
        "Question_body":"Hey,\n\nI followed your Tutorial: Categorize iris flowers using k-means clustering with ML.NET to develop a porgram on drivers: whether a driver is good or bad.\nI would like that on the console it shows me the 2 groups that it has to form with their properties (for example prenon and last name). all the bad drivers then all the good. How can I do that?\n\nI look forward to your response\nThank you very much",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Machine Learning Code",
        "Question_creation_time":1593980194230,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/43091\/machine-learning-code-1.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":37,
        "Question_score":0,
        "Question_body":"Hey,\n\nI am developing an ASP.Net application and I would like to integrate machine learning into my app. But let the result appear in a window of my app and not on the console. Can you tell me how to do it please?\n\nThank you in advance\nI look forward to your response",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-05T20:48:56.967Z",
                "Answer_score":1,
                "Answer_body":"Might try them over here.\nhttps:\/\/forums.asp.net\/1247.aspx\/1?Azure+and+ASP+NET",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Resource Groups are EMPTY for all the AI lessons in MSLearn",
        "Question_creation_time":1593355107607,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/40537\/resource-groups-are-empty-for-all-the-ai-lessons-i.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"I have been attempting to complete the AI learning challenge. Starting with the Create Bot lesson and then Cognitive Vision services lesson, I can&#39;t create resources as the Resource groups lists are empty. I type in the names in the lessons and that doesn&#39;t work.\n\nI click the link to the Azure portal and I go to the one I created ... and it exists. But it can&#39;t find anything (like mslearn-faceapi) to complete the lessons.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure Machine Learning Studio Designer (preview) - Selective module execution",
        "Question_creation_time":1593464903017,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/41135\/azure-machine-learning-studio-designer-preview-sel.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":2,
        "Question_score":1,
        "Question_body":"I find that I am often inserting or modifying one module in a flow, and needing to edit several later items in the DAG,\n\nBut since the prior module is now invalidated, It asks me to SUBMIT and run the full experiment, so that I can do things like select columns.\n\nIs there not a way to disable modules? or selectively execute just a subset of modules?\n\nI am using the preview versions of the ML studio.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-07-01T11:32:32.75Z",
                "Answer_score":0,
                "Answer_body":"@StevenGutfreund-9039 Thanks for the feedback.Currently We don't support selected node run yet in Designer. BTW pipeline has the capability to use previous run result if the input data hasn't changed. You can confirm whether a step is reused or not from the recycle icon as shown below:\n\n\n\n\nPlease share your feedback from the ml.azure.com portal to prioritize this feature.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AzureML cosmosDB integration",
        "Question_creation_time":1592481284737,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/37574\/azureml-cosmosdb-integration.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"I would like to know why azureML has no inbuilt integration with cosmosDB.For ML studio cosmosDB is one of the input data sources,why is it not considered in azureML?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-18T22:36:18.813Z",
                "Answer_score":0,
                "Answer_body":"Thanks for reaching out to us and your feedback, I will forward this suggestion to product team to see if this is in the roadmap with reason.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Something Wrong?",
        "Question_creation_time":1593090172523,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/40031\/something-wrong.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Isn&#39;t me only or...?[welcome-to-azure][1]![10701-%E6%89%B9%E6%B3%A8-2020-06-25-205624.png][2]\n\n\n\n\n\n\n[1]: https:\/\/docs.microsoft.com\/zh-cn\/learn\/modules\/welcome-to-azure\/\n\n[2]: \/answers\/storage\/attachments\/10701-\u6279\u6ce8-2020-06-25-205624.png",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-30T17:36:13.787Z",
                "Answer_score":0,
                "Answer_body":"@egov Hi, could you please provide more information to us about what issue you are facing? So basically you can use this introduction module to learn Azure.\n\nJust easy click \"\u5f00\u59cb\" so you can start at the beginning. You can also jump to any module you want. Let us know more if you have any issue.\n\nRegards,\nYutong",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"AzureMLCompute Job Failed",
        "Question_creation_time":1592828367680,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/38604\/azuremlcompute-job-failed.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"I am having this error when I was following the notebook here:\n\nhttps:\/\/docs.microsoft.com\/en-us\/learn\/modules\/use-automated-machine-learning\/\n\nAzureMLCompute job failed. BFSMountError: unable to mount blob fuse file system Info: Could not mount Azure Blob Container azureml-blobstore-29.......xx12 at workspaceblobstore: Unauthorized. Cannot access the storage account with the given account key. Please verify that the account key is valid. Info: Job environment preparation failed on 10.0.0.4.\n\n{\n\"message\": \"AzureMLCompute job failed.\\nBFSMountError: unable to mount blob fuse file system\\n\\tInfo: Could not mount Azure Blob Container azureml-blobstore-29.......xx12 at workspaceblobstore: Unauthorized. Cannot access the storage account with the given account key. Please verify that the account key is valid.\\n\\tInfo: Job environment preparation failed on 10.0.0.4.\"\n}\n\nIt says 'cannot access the storage account' however I am able to run a Jupiter notebook within this compute and access the storage account without any problem. I guess 'account key' is referring to the storage account key. If so, how can I provide it during deployment?\n\nNote:\n1. I am having a similar error when I try to deploy a model to ACI.\n2. The AML workspace and so the storages are created in a VNET",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-22T22:25:37.37Z",
                "Answer_score":0,
                "Answer_body":"Hi.\n\nThanks for reaching out to us and sorry for your experience. For this error, the root cause might be the Updated Storage keys were not synced correctly, because of which the ML service was still using the old storage keys.\n\nI will suggest you to do:\n\nRun \"az ml workspace sync-keys -w myworkspace -g myresourcegroup\" to sync up the key again\n\nPlease have a try to see if this can be solved.\n\nRegards,\nYutong",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-06-30T13:17:20.447Z",
                "Answer_score":0,
                "Answer_body":"It's not supported using the Azure Machine Learning designer or automated machine learning (from the studio) with resources inside a virtual network.\u201d \/ https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-enable-virtual-network\n\nIn near future we will support private link for ML in general in near future.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Ranking calculation of probability programming with draw",
        "Question_creation_time":1593445781820,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/40959\/ranking-calculation-of-probability-programming-wit.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"On the web page\u201c https:\/\/docs.microsoft.com\/zh-cn\/dotnet\/machine-learning\/how-to-guides\/matchup-app-infer-net \u201dAccording to the winning and losing relationship of each player and the result of the game, the players are ranked by using probabilistic programming. The source code is as follows\n\n\n\nstatic void Main(string[] args)\n{\n\u202f\u202f\u202f \/\/ The winner and loser in each of 6 samples games\n\u202f\u202f\u202f var winnerData = new[] { 0, 0, 0, 1, 3, 4 };\n\u202f\u202f\u202f var loserData = new[] { 1, 3, 4, 2, 1, 2 };\n\nHere only win or lose, such as the game is a draw, how to add a draw data, how to calculate the ranking\n\n\n     \u202f\u202f\u202f \/\/ Define the statistical model as a probabilistic program\n     \u202f\u202f\u202f var game = new Range(winnerData.Length);\n     \u202f\u202f\u202f var player = new Range(winnerData.Concat(loserData).Max() + 1);\n     \u202f\u202f\u202f var playerSkills = Variable.Array<double>(player);\n     \u202f\u202f\u202f playerSkills[player] = Variable.GaussianFromMeanAndVariance(6, 9).ForEach(player);\n     \u202f\u202f\u202f var winners = Variable.Array<int>(game);\n     \u202f\u202f\u202f var losers = Variable.Array<int>(game);\n     \u202f\u202f\u202f using (Variable.ForEach(game))\n     \u202f\u202f\u202f {\n     \u202f\u202f\u202f\u202f\u202f\u202f\u202f \/\/ The player performance is a noisy version of their skill\n     \u202f\u202f\u202f\u202f\u202f\u202f\u202f var winnerPerformance = Variable.GaussianFromMeanAndVariance(playerSkills[winners[game]], 1.0);\n     \u202f\u202f\u202f\u202f\u202f\u202f\u202f var loserPerformance = Variable.GaussianFromMeanAndVariance(playerSkills[losers[game]], 1.0);\n\n\n\n\u202f\u202f\u202f\u202f\u202f\u202f\u202f \/\/ The winner performed better in this game\n\u202f\u202f\u202f\u202f\u202f\u202f\u202f Variable.ConstrainTrue(winnerPerformance > loserPerformance);\n\u202f\u202f\u202f }\n\n     \u202f\u202f\u202f \/\/ Attach the data to the model\n     \u202f\u202f\u202f winners.ObservedValue = winnerData;\n     \u202f\u202f\u202f losers.ObservedValue = loserData;\n     \u202f\u202f\u202f \/\/ Run inference\n     \u202f\u202f\u202f var inferenceEngine = new InferenceEngine();\n     \u202f\u202f\u202f var inferredSkills = inferenceEngine.Infer<Gaussian[]>(playerSkills);\n     \u202f\u202f\u202f \/\/ The inferred skills are uncertain, which is captured in their variance\n     \u202f\u202f\u202f var orderedPlayerSkills = inferredSkills\n     \u202f\u202f\u202f\u202f\u202f\u202f\u202f.Select((s, i) => new { Player = i, Skill = s })\n     \u202f\u202f\u202f\u202f\u202f\u202f\u202f.OrderByDescending(ps => ps.Skill.GetMean());\n     \u202f\u202f\u202f foreach (var playerSkill in orderedPlayerSkills)\n     \u202f\u202f\u202f {\n     \u202f\u202f\u202f\u202f\u202f\u202f\u202f Console.WriteLine($\"Player {playerSkill.Player} skill: {playerSkill.Skill}\");\n     \u202f\u202f\u202f }\n     }\n    The result of these games is only win or lose, there is no draw, official example\u201c https:\/\/github.com\/dotnet\/infer\/blob\/master\/src\/Tutorials\/ChessAnalysis.cs \u201dI can't understand. How to use a draw game Infet.net Ranking players",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-30T10:00:57.257Z",
                "Answer_score":1,
                "Answer_body":"Answered on github",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"ML Training course - Cost",
        "Question_creation_time":1592141346953,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/35883\/ml-training-course-cost.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Hi Team,\n\nI am working in E&amp;Y. Wanted to know info about training course.\n\nif we want to do training course i.e &#34; Azure Machine Learning&#34; for the team(10 people), What would be the cost involved for instructor based training.\n\nIf you can provide us quote , it would be great.\n\n\n\n\nThanks &amp; Regards,",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-14T14:02:19.707Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nI suggest you find a Microsoft partner\/solution provider near you, they may be able to deliver Azure Machine Learning courses\/workshops.\n\nMicrosoft Solution Providers\nhttps:\/\/www.microsoft.com\/en-us\/solution-providers\/home\n\nYou may also contact Azure sales:\n\nAzure Sales\nhttps:\/\/azure.microsoft.com\/en-us\/overview\/sales-number\n\n\n\n\nBest regards,\nLeon",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-06-15T12:05:27.633Z",
                "Answer_score":0,
                "Answer_body":"@DishaGupta-0133 If you are looking to get started with Machine Learning on Azure, you can also take this course on our learn site.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Can you give me an example of a draw with Infer.net",
        "Question_creation_time":1593357487593,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/40647\/can-you-give-me-an-example-of-a-draw-with-infernet.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"On the web\u201c https:\/\/docs.microsoft.com\/en-au\/dotnet\/machine-learning\/how-to-guides\/matchup-app-infer-net \u201dFor Infer.net Probability programming example of. In this example, there are only wins or losses, no draws. Can you give me an example of a draw, which can be used in the machine learning of E-sports Bo 2 or football, thank you",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-29T12:48:42.093Z",
                "Answer_score":1,
                "Answer_body":"The Chess Analysis example in the Infer.NET documentation includes draws.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Practice Exam for DP-100",
        "Question_creation_time":1593082618390,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/39948\/practice-exam-for-dp-100.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"Hello,\n\nno practice exam for the Azure certification DP-100 seems to be available in the official channels. It would, however, be very helpful for preparing.\nBy any chance, do you plan to introduce such a resource any time soon?\n\nThanks and best regards\nTim",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-25T11:08:59.537Z",
                "Answer_score":2,
                "Answer_body":"Hi,\n\nMicrosoft Certification \/ Exams are currently not supported in the Q&A forums, the supported products are listed over here https:\/\/docs.microsoft.com\/en-us\/answers\/products (more to be added later on).\n\nYou can ask the experts in the dedicated Microsoft Certification - Preparation Resources forum over here:\nhttps:\/\/trainingsupport.microsoft.com\/en-us\/mcp\/forum\/mcp_exams-mcp_prep\n\n(Please don't forget to accept helpful replies as answer)\n\nBest regards,\nLeon",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Endpoint not being created Azure Designer",
        "Question_creation_time":1592922691007,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/39203\/endpoint-not-being-created-azure-designer.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":4,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"I created a simple recommendation model in Azure Designer. The model is able to train and from that, I created an inference pipeline. I ran it and deployed it, under a new AKS inference cluster and even experiment. However, the endpoint is just not being created. I can see the model is registered with a new version but no endpoint is created. Below, I have attached a screenshot of the inference pipeline in designer.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How to Cancel Upload? - Azure Machine Learning Studio",
        "Question_creation_time":1592921687557,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/39201\/how-to-cancel-upload-azure-machine-learning-studio.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Hi,\n\nPlease will you tell me how to cancel a dataset upload?\n\n\n\n\nI tried to upload a small (321kb) CSV to Azure Machine Learning Studio. The upload has been running for more than 1 hour, but it still says uploading.\n\nI tried to upload other files (different names), and they are hanging too....same symptoms.\n\nIt seems the first problem is blocking all subsequent upload attempts.\n\nUntil today uploads worked perfectly.....multiple file types, multiple sizes, multiple dates, were all OK.\n\nI have plenty of space left in my environment.\n\nI tried closing and restarting my browser....same problem. I accessed my AMLS via a different computer...same problem.\n\n\n\n\nThanks in advance for any advice you can give.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-23T17:33:31.233Z",
                "Answer_score":0,
                "Answer_body":"Well, I don't know if you (@GiftA-MSFT) did something to help, but it's solved! Thanks if you did take that initiative, I appreciate it. :-)\n\n...or it could be that after 4-5 hours the upload just completed. My internet connection was fine (it's a 40Mb line), so I'm not sure what the solution was. Perhaps patience alone is the answer.\n\nAnyway, thanks for taking an interest in my problem either way.\n\nBest wishes. :-)",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Pathway for code free predictive modeling",
        "Question_creation_time":1592869306553,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/38841\/pathway-for-code-free-predictive-modeling.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":2,
        "Question_score":1,
        "Question_body":"I am looking at Azure&amp;#39;s training modules and it states I can learn no-code models with Azure, but it also tells me I should know python. I&amp;#39;m a little confused at where I should spend time training in most efficient pathway. My goal is to just do predictive modeling within Azure. I have technical\/IT literacy however coding is at a basic level.\n\nIdeally id like some sort of Certification, if possible from just &amp;#34;Create no-code predictive models with Azure Machine Learning&amp;#34;\n\nIs &amp;#34;Microsoft Certified: Azure Data Scientist Associate&amp;#34; going to require a lot of pre work on python\/torch\/tensor? I&amp;#39;d ideally like Azure to be my entry.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-23T15:06:48.467Z",
                "Answer_score":2,
                "Answer_body":"Thanks for reaching out. Azure machine learning has a drag and drop interface (Designer) that supports code free predictive modeling. Create no-code predictive models with Azure Machine Learning training modules is a great starting point and provides a pathway for Azure Data Scientist Associate certification. However, you also need programming experience and familiarity with various data science processes\/principles to be successful on the certification exam.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Out-of-memory error webservice deployed with Azure ML Studio",
        "Question_creation_time":1592827334117,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/38509\/out-of-memory-error-webservice-deployed-with-azure.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"I have a webservice which exposes a predictive model. It has been deployed with Auzure ML Studio. Since the last model re-training and webservice deployment, in circa 1% of the cases in production, I get the following out-of-memory (possibly correlated) errors:\n\n1) \"The model consumed more memory than was appropriated for it. Maximum allowed memory for the model is 2560 MB. Please check your model for issues.\"\n2) \"The following error occurred during evaluation of R script: R_tryEval: return error: Error: cannot allocate vector of size 57.6 Mb\"\n\nPlease note that these errors occur exclusively while trying to consume the webservice, and not while model training, evaluation and deployment.\n\nAlso, consuming the webservice in batch mode, as suggested here, is not a viable option for our business use case.\n\nIs there a way to increase the memory limit for Azure webservices?\n\nThank you",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-23T12:55:13.067Z",
                "Answer_score":0,
                "Answer_body":"Thanks for reaching out. Currently, there's no way to increase memory limit in Classic Studio. We encourage customers to try Azure Machine Learning designer (preview), which provides similar drag and drop ML modules plus scalability, version control, and enterprise security. Furthermore, with Designer, the endpoints are deployed to AKS where no limit other than cluster resource is imposed.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How to consume easily for test Azure ML Studio webservice",
        "Question_creation_time":1592224847787,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/36106\/how-to-consume-easily-for-test-azure-ml-studio-web.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Dear,\n\nDoes someone manage to consume an experiments deployed in a webservice via an external source just for testing. (multiple users want to test)\nThe solutions I have is :\nfrom excel but requires addons on users laptops\nfrom a webpage bu requires coding\n\nI would like to have a shared webpage for example and from there :\nusers enter features values\nusers get in reply via the webservice the predicted value.\n==> SharePoint might be useful ?? Microsoft Apps ??\nI need to select a solution that avoids any coding work as it is only for users testing....\n\n\n\n\nRegards,\n\nMohamed.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-16T15:46:14.997Z",
                "Answer_score":0,
                "Answer_body":"@Mohamedelham-2250 You can enable automatic schema generation with your deployment and get the OpenAPI specification of your service by using the swagger properties. With this specification you can use swagger inspector to test the endpoint with no custom code to test your endpoint.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"in Azure Machine Learning service, how to update python pickle file 's ML model parameter?",
        "Question_creation_time":1592180368837,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/35933\/in-azure-machine-learning-service-how-to-update-py.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"after using Azure Auto ML or Designer, model creates Pickle file.\n\ni tried to develop model in python pickle file by tunning some parameter by set_params method\n\nas you know this pickle file has 'Pipeline', 'y_transformer', 'y_transformer_name' key.\n\nand Pipeline has parameter setting\n\nbut as i wrote,\n\na.pipeline.set_params (memory = 'n')\n\nthis code is work.\n\nmemory parameter is changed.\n\nbut\n\na.pipeline.set_params (XGBoostClassifier__base_score = 0.6)\n\nthis code is not work.\n\nplease let me know how to change model's hyperparameter",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Azure Machine Learning best model's update paramete with python pickle",
        "Question_creation_time":1591866370453,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/34853\/azure-machine-learning-best-models-update-paramete.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":3,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Hi\n\ni am trying to Azure Machine Learning best model&#39;s update parameter with python pickle type\n\nbest model trained by xgboost.\n\ni load model through pickle and tried to change parameter.\n\nimport joblib\n\na=joblib.load(\"model.pkl\")\n\na.pipeline.set_params(XGBoostClassifier__base_score=0.6)\n\nbut it doesn't work.\n\nhowever\n\na.pipeline.set_params(memory='n')\n\nthis code is works.\n\nlet me know how to change model's parameter.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Linear Regression Large Values",
        "Question_creation_time":1591119581903,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/31250\/linear-regression-large-values.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"I am trying to make a model that does simple counting (ex when I input 14, it outputs 15 or when I input 273 it outputs 274). OLS linear regression comes out to be the most accurate model, and it works really well for numbers with up to 7 digits. However, when I input a number that is more than 7 digits, (ex. 743829543), instead of returning the input +1, it will return a number that has the same first seven digits, but the other digits will be completely off. Is this just a function of the model? What can I do to fix this\/what dataset can I use to train the model to get more accurate outputs?",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Connect 2 separate experiments via webservice - Azure MLS Classic",
        "Question_creation_time":1592407262483,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/37128\/connect-2-separate-experiments-via-webservice-azur.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"I have 2 experiments A and B in Azure MLS classic. I need the web service output of experiment A as one of the web service inputs for experiment B. Please let me know if it is possible and if yes, how I can do it.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-17T22:36:57.623Z",
                "Answer_score":0,
                "Answer_body":"I used export module in experiment A and import module in experiment B to transfer the output of A as input of B.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Convert web service output to a dataset Azure MLS classic",
        "Question_creation_time":1592408319737,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/37214\/convert-web-service-output-to-a-dataset-azure-mls.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"Is it possible to convert a web service output as a dataset or a csv file ? I want to consume this in another experiment.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-17T17:56:25.02Z",
                "Answer_score":0,
                "Answer_body":"You can delete or export in-product data stored by Azure Machine Learning Studio (classic) by using the Azure portal, the Studio (classic) interface, PowerShell, and authenticated REST APIs. This article tells you how.\n\nTelemetry data can be accessed through the Azure Privacy portal.\n\nMore details please refer to: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio\/export-delete-personal-data-dsr\n\nAnd also you can use one of the Azure Machine Learning Studio Module - \"Export Data\" to do it : https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/studio-module-reference\/export-data?redirectedfrom=MSDN\n\nLet me know if you have more questions.\n\nRegards,\nYutong",
                "Answer_comment_count":2,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning resync keys not working - no longer able to access files\/submit experiments to ML service",
        "Question_creation_time":1591893115170,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/35043\/azure-machine-learning-resync-keys-not-working-no.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":4,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"I followed this tutorial: https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-change-storage-access-key - to update the access keys of my default blob datastore linked to my Machine Learning service. This worked a month ago. After doing it today, every time when submitting an experiment I get the error:\n\"Job preparation failed: HTTP Error 403: Server failed to authenticate the request. Make sure the value of Authorization header is formed correctly including the signature\"\n\nWhen opening log files for an experiment I get:\n\"403: You are not authorized to access this resource.\"\n\nThe resync keys operation from the command line works, as I can see in the Machine Learning service Activity log. The Python SDK code also works, as I tried updating the resource group name or default datastore and this gets through.\n\nAny ideas on how to fix this? I am at a loss.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-16T10:35:20.733Z",
                "Answer_score":0,
                "Answer_body":"Updating this thread with the resolution steps performed by our team in this scenario.\n\n\n\n\nIssue:\n\n\n\n\nAfter updating the storage access keys, the job submission was failing with 403\n\n\n\n\nCause:\n\n\n\n\nThe values for the storage keys was cached in the storage connection strings at the backend\n\n\n\n\nResolution:\n\n\n\n\nThe engineering team manually deleted the cached storage keys from the backend\n\n\n\n\n@Jim-9799 Please feel free to accept this as answer so any other user can follow the steps.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"View Logistic Regression Model Weights in Machine Learning Studio Enterprise",
        "Question_creation_time":1591270358033,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/32045\/view-logistic-regression-model-weights-in-machine.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":0,
        "Question_comment_count":2,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"In ML Studio Classic you can see the logistic regression model weights (intercept and coefficients) when you click on the output from &amp;amp;#34;Train model&amp;amp;#34; module. This feature however is not available in the new ML Studio Enterprise. I only get the Trained_model blob in blob storage. Seeing the weights is a must have when building credit scoring models and this current deficiency is what&amp;amp;#39;s keeping us from switching to ML Studio Enterprise.\n\nIs there a plan to re-introduce this feature from the ML Studio Classic? Alternatively is there a way I can serialize the data.ilearner file and get the model weights from there?\n\nI know I could use the &amp;amp;#34;Train Python model&amp;amp;#34; module instead, but the &amp;amp;#34;Evaluate Model&amp;amp;#34; module fails with an unspecified error when I use that.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Jupyter link is not working in Azure ML studio",
        "Question_creation_time":1591784712670,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/34363\/jupyter-link-is-not-working-in-azure-ml-studio.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"I am trying to create an experiment, For that When I am trying to create Jupypter notebook on running compute Instance, It redirects me to the Login page again and again. So I am not able to proceed further. I think there's a small glitch",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-12T13:45:59.233Z",
                "Answer_score":0,
                "Answer_body":"Yes, Compute instance was created by me only, Jupyter link is working fine now. Couldn't determine what was the problem before though.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Deployment of Multiple Models to Container Instance Fails in Azure DevOps",
        "Question_creation_time":1592223294357,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/36104\/deployment-of-multiple-models-to-container-instanc.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":6,
        "Question_score":0,
        "Question_body":"Hi Team,\n\nI am trying to deploy 2 ML models ( which is registered in Model Registry ) to Azure Container Instance using DevOps Release pipeline using AZ CLI ML extension\n\nMy ACI Configuration is :\n\ncontainerResourceRequirements: cpu: 1 memoryInGB: 4 computeType: ACI\n\nInference Config :\n\nentryScript: score.py runtime: python condaFile: conda_dependencies.yml extraDockerfileSteps: schemaFile: sourceDirectory: enableGpu: False baseImage: baseImageRegistry:\n\nAll score.py, conda_dependencies.yml, aciDeploymentConfig.yml is placed in a flattened directory which is publised in to DevOps pipeline artifcat and looks like\n\n\n\n\n\nDevOps Deploy command looks like\n\naz ml model deploy -g $(ml.resourceGroup) -w $(ml.workspace) --name $(service.name.staging) -f .\/model.json -m \"GloVe:4\" --dc aciDeploymentConfig.yml --ic inferenceConfig.yml --overwrite --debug\n\nAlso i have set the working directory as the folder where all above files are placed. something like\n\n$(System.DefaultWorkingDirectory)\/_Symptom-Code-Indexing\/symptom_model\/a\n\nIts getting in to an exception as\n\n2020-06-08T12:50:27.9202657Z \"error\": {\n2020-06-08T12:50:27.9208361Z \"message\": \"Received bad response from Model Management Service:\\nResponse Code: 400\\nHeaders: {'Date': 'Mon, 08 Jun 2020 12:50:27 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': '823e8483923846b1958c08ffaba074ff', 'x-ms-client-session-id': '62e84a29-b77c-456f-9d91-5ca6be26f79c', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\\nContent: b'{\\\"code\\\":\\\"BadRequest\\\",\\\"statusCode\\\":400,\\\"message\\\":\\\"The request is invalid.\\\",\\\"details\\\":[{\\\"code\\\":\\\"InvalidOverwriteRequest\\\",\\\"message\\\":\\\"Invalid overwrite request - cannot update container resource requirements, dns name label, or deployment type. Please delete and redeploy this service.\\\"}],\\\"correlation\\\":{\\\"RequestId\\\":\\\"823e8483923846b1958c08ffaba074ff\\\"}}'\"\n2020-06-08T12:50:27.9212109Z }\n2020-06-08T12:50:27.9212376Z }}\n2020-06-08T12:50:27.9213437Z {'Azure-cli-ml Version': '1.6.0', 'Error': WebserviceException:\n2020-06-08T12:50:27.9214158Z Message: Received bad response from Model Management Service:\n2020-06-08T12:50:27.9214688Z Response Code: 400\n2020-06-08T12:50:27.9217800Z Headers: {'Date': 'Mon, 08 Jun 2020 12:50:27 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': '823e8483923846b1958c08ffaba074ff', 'x-ms-client-session-id': '62e84a29-b77c-456f-9d91-5ca6be26f79c', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\n2020-06-08T12:50:27.9222115Z Content: b'{\"code\":\"BadRequest\",\"statusCode\":400,\"message\":\"The request is invalid.\",\"details\":[{\"code\":\"InvalidOverwriteRequest\",\"message\":\"Invalid overwrite request - cannot update container resource requirements, dns name label, or deployment type. Please delete and redeploy this service.\"}],\"correlation\":{\"RequestId\":\"823e8483923846b1958c08ffaba074ff\"}}'\n2020-06-08T12:50:27.9223705Z InnerException None\n2020-06-08T12:50:27.9224049Z ErrorResponse\n2020-06-08T12:50:27.9224320Z {\n2020-06-08T12:50:27.9224617Z \"error\": {\n2020-06-08T12:50:27.9229025Z \"message\": \"Received bad response from Model Management Service:\\nResponse Code: 400\\nHeaders: {'Date': 'Mon, 08 Jun 2020 12:50:27 GMT', 'Content-Type': 'application\/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Request-Context': 'appId=cid-v1:2d2e8e63-272e-4b3c-8598-4ee570a0e70d', 'x-ms-client-request-id': '823e8483923846b1958c08ffaba074ff', 'x-ms-client-session-id': '62e84a29-b77c-456f-9d91-5ca6be26f79c', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\\nContent: b'{\\\"code\\\":\\\"BadRequest\\\",\\\"statusCode\\\":400,\\\"message\\\":\\\"The request is invalid.\\\",\\\"details\\\":[{\\\"code\\\":\\\"InvalidOverwriteRequest\\\",\\\"message\\\":\\\"Invalid overwrite request - cannot update container resource requirements, dns name label, or deployment type. Please delete and redeploy this service.\\\"}],\\\"correlation\\\":{\\\"RequestId\\\":\\\"823e8483923846b1958c08ffaba074ff\\\"}}'\"\n2020-06-08T12:50:27.9230782Z }\n2020-06-08T12:50:27.9230908Z }}\n2020-06-08T12:50:27.9231134Z Event: Cli.PostExecute [<function AzCliLogging.deinit_cmd_metadata_logging at 0x7fea2ca1f730>]\n2020-06-08T12:50:27.9231431Z az_command_data_logger : exit code: 1\n2020-06-08T12:50:27.9275693Z telemetry.save : Save telemetry record of length 7390 in cache\n2020-06-08T12:50:27.9280735Z telemetry.check : Negative: The \/home\/vsts\/work\/_temp\/.azclitask\/telemetry.txt was modified at 2020-06-08 12:47:41.161160, which in less than 600.000000 s\n2020-06-08T12:50:27.9290480Z command ran in 55.735 seconds.\n2020-06-08T12:50:28.1525434Z ##[error]Script failed with exit code: 1\n2020-06-08T12:50:28.1536650Z [command]\/opt\/hostedtoolcache\/Python\/3.6.10\/x64\/bin\/az account clear\n2020-06-08T12:50:29.9078943Z ##[section]Finishing: Deploy Model to ACI\n\nBut when i tried to Deploy it using Python SDK it works as well. Is there any permission issues or login to be set before using DevOps Release. I have not done any sort of login in my DevOps Build pipeline.\n\nAny pointers on what is going wrong here ? It would be really helpful.\n\nThanks,\nSrijith",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-15T12:17:00.34Z",
                "Answer_score":1,
                "Answer_body":"They're actively answering Devops question in dedicated forums here.\n\n\n\n\nhttps:\/\/developercommunity.visualstudio.com\/spaces\/21\/index.html\n\n\n\n\n--please don't forget to Accept as answer if the reply is helpful--\n\nRegards, Dave Patrick ....\nMicrosoft Certified Professional\nMicrosoft MVP [Windows Server] Datacenter Management\n\n\n\n\nDisclaimer: This posting is provided \"AS IS\" with no warranties or guarantees, and confers no rights.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Access to neural network model",
        "Question_creation_time":1591889003457,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/34890\/access-to-neural-network-model.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"We have built numerous diagnostic models which can be reduced to equations and code that will allow us to repeat the work. We have the code physically available to us, so it can be installed in our own software.\n\nNow I would like to use artificial neural networks to build a prediction model. After I build that model, will I be able to take that model and transfer it to our own software environment? My concern is that the prediction model will just be a black box. Thanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-12T08:31:58.437Z",
                "Answer_score":0,
                "Answer_body":"@OliverBathe-8330 Please follow the below Deployment scenarios. If possible can you please add more details about the use case.\n\n\n\n\nOption A: Use the DevOps pipeline integration to rollout to production Using same approach as in the MLOps repo, set up a release trigger for your DevOps release pipeline listening from your dev workspace model registry but then deploy to your production workspace (requires registering again in Prod model registry, call model.deploy() in the Prod workspace\n\n\n\n\nOption B: Use the AML pipeline to rollout to production Following same example as above, add additional PythonScriptStep in your AML pipeline to register and deploy model in the Production workspace\n\n\n\n\nhttps:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/how-to-deploy-and-where",
                "Answer_comment_count":1,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Azure ml notebooks sharing and compute selection.",
        "Question_creation_time":1591956129183,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/35432\/azure-ml-notebooks-sharing-and-compute-selection.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"What kind of collaboration do we need among the data scientists or developers who need to share these notebooks? What kind of compute does these notebooks require? Is it all single node?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-12T11:43:28.857Z",
                "Answer_score":0,
                "Answer_body":"@azureml056-5112 Please follow the below for managing compute instances. https:\/\/docs.microsoft.com\/en-us\/azure\/machine-learning\/concept-compute-instance#managing-a-compute-instance All data scientists or developers need is access to the AzureML Workspace and they will have access to a shared file share where everyone\u2019s notebooks can be accessed.\n\n\n\n\nAll notebook require a Compute Instance(CI). CI is a managed VM that exists in AzureML.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Creating datasets in Azure Machine Learning service from more than 100 paths",
        "Question_creation_time":1591718920387,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/34010\/creating-datasets-in-azure-machine-learning-servic.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":7,
        "Question_score":0,
        "Question_body":"Hi,\n\nI need to create a dataset in Azure Machine Learning service from an Azure Data Lake Gen2 registered as a Datastore. Data in the lake are 1000's of avro files stored by an Event Hub Capture following the pattern [EventHub]\/[Partition]\/[YYYY]\/[MM]\/[DD]\/[HH]\/[mm]\/[ss], so there is one path for each file.\n\nAccording to the datasets documentation it is recommended \"... creating dataset referencing less than 100 paths in datastores for optimal performance.\"\n\nWhat would be the alternative\/recommended approach in my application? Streaming data are continuously captured by the Event Hub.\n\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-11T04:48:23.87Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nYou can create dataset with globing pattern.\nds = Dataset.File.from_files((datastore, '[EventHub]\/[Partition]\/**))\n\nThe mount time should be less than 1 min.",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"TensorFlow 2.2.0 update for the tensorflow estimator for Azure ML, or disable horovod?",
        "Question_creation_time":1591339346177,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/32334\/tensorflow-220-update-for-the-tensorflow-estimator.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"I would like to use the tensorflow hub to retrain existing models, however tensorflow supports the hub library only on their 2.2 version. And The Estimator azure presents supports tf 2.0.\n\nWhen I list tensorflow 2.2 as a required dependency as a pip package, during docker image creation the system fails - it seems like horovod is responsible, - that it cannot find the correct libraries.\n\n\n\n\nIs this possible to be fixed? as in either an Estimator with tf 2.2 support, or an esitmator without the horovod - as I do not need a distributed system for my solution.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-06T14:46:51.35Z",
                "Answer_score":0,
                "Answer_body":"Following the pointers from @romungi-MSFT, defining estimator with gpubase image; \"mcr.microsoft.com\/azureml\/base-gpu:openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04\" solves the problem, and Tensorflow 2.2 can be included. Tensorflow uses GPU by default when available.\n\n\n\n estimator = Estimator(source_directory=experiment_folder,\n                       compute_target=compute_target,\n                       script_params=script_params,\n                       entry_script='rps_efn_b0.py',\n                       node_count=1,        \n                       conda_packages=['ipykernel'],\n                       pip_packages = ['azureml-sdk',\n                                       'pyarrow',\n                                       'pyspark',\n                                       'azureml-mlflow',\n                                       'joblib',\n                                       'matplotlib',\n                                       'Pillow',\n                                       'tensorflow==2.2',\n                                       'tensorflow-datasets',\n                                       'tensorflow-hub',\n                                       'azureml-defaults',\n                                       'azureml-dataprep[fuse,pandas]'],\n                       custom_docker_image='mcr.microsoft.com\/azureml\/base-gpu:openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04')",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"(UserError) Error when parsing request; unable to deserialize request body",
        "Question_creation_time":1591616365497,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/33313\/usererror-error-when-parsing-request-unable-to-des.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":2,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"Hi, getting this error when i run an azureml experiment with custom_docker_image (basegpu image of mcr) - can anybody help me understand this? Have tested this in local compute and it works, not sure why this does not work on a training cluster vm?\n\n\n\n\n    azureml._restclient.exceptions.ServiceException: ServiceException:\n         Code: 400\n         Message: (UserError) Error when parsing request; unable to deserialize request body\n         Details:\n        \n         Headers: {\n             \"Date\": \"Mon, 08 Jun 2020 11:03:52 GMT\",\n             \"Content-Type\": \"application\/json; charset=utf-8\",\n             \"Transfer-Encoding\": \"chunked\",\n             \"Connection\": \"keep-alive\",\n             \"Request-Context\": \"appId=cid-v1:6a27ce65-5555-41a3-85f7-b7a1ce31fd6b\",\n             \"x-ms-response-type\": \"error\",\n             \"Strict-Transport-Security\": \"max-age=15724800; includeSubDomains; preload\"\n         }\n         InnerException: {\n         \"additional_properties\": {},\n         \"error\": {\n             \"additional_properties\": {},\n             \"code\": \"UserError\",\n             \"message\": \"Error when parsing request; unable to deserialize request body\",\n             \"details_uri\": null,\n             \"target\": null,\n             \"details\": [],\n             \"inner_error\": null,\n             \"debug_info\": null,\n             \"message_format\": null,\n             \"message_parameters\": null,\n             \"reference_code\": null\n         },\n         \"correlation\": {\n             \"operation\": \"e96d6285280f5849a4a5e3f172d65d36\",\n             \"request\": \"1beee8ecb7180147\"\n         },\n         \"environment\": \"westeurope\",\n         \"location\": \"westeurope\",\n         \"time\": {}\n     }",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-11T14:05:05.637Z",
                "Answer_score":1,
                "Answer_body":"My bad, after giving it some days and looking at the code, I noticed i had forgotten to add the parameters for the estimator configuration. Here is the estimator configuration that works for me:\n\n\n\n estimator = Estimator(source_directory=experiment_folder,\n                       compute_target=compute_target,\n                       script_params=script_params,\n                       entry_script='rps_efn_b0.py',\n                       node_count=1,        \n                       conda_packages=['ipykernel'],\n                       pip_packages = ['azureml-sdk',\n                                       'pyarrow',\n                                       'pyspark',\n                                       'azureml-mlflow',\n                                       'joblib',\n                                       'matplotlib',\n                                       'Pillow',\n                                       'tensorflow==2.2',\n                                       'tensorflow-datasets',\n                                       'tensorflow-hub',\n                                       'azureml-defaults',\n                                       'azureml-dataprep[fuse,pandas]'],\n                       custom_docker_image='mcr.microsoft.com\/azureml\/base-gpu:openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04')",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            },
            {
                "Answer_creation_time":"2020-06-09T14:44:45.27Z",
                "Answer_score":0,
                "Answer_body":"@sadeghHosseinpoor-9324 Apologies for not responding on the previous thread as we are having platform issues on providing response to some threads.\n\nIn this case having access to the backend details of your experiment run could help to suggest what changes are required in your current experiment setup. This can be addressed by our support team if you can raise a support ticket against this resource from the azure portal.\n\nMeanwhile, I have tried to lookup similar error messages faced by other users and based on your scenario are you installing any package in your environment with package name and version which is failing to read the request json? I found one user who corrected this error during environment setup by correcting the request for spark package installation in their environment.\n\nBefore:\n\n environment.spark.packages=[SparkPackage(group='com.microsoft.azure', artifact='azure:azure-sqldb-spark', version='1.0.2')]\n\n\n\nAfter:\n\n environment.spark.packages=[{'group':'com.microsoft.azure', 'artifact': 'azure-sqldb-spark', 'version':'1.0.2'}]\n\n\n\n\nIs there any similar requests in your case?",
                "Answer_comment_count":1,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Don't show button for teams bot",
        "Question_creation_time":1589929289250,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/28063\/dont-show-button-for-teams-bot.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":2,
        "Question_comment_count":1,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Hi,\n\nI am deploy Azure web app bot.\nIf I test bot in Azure web-chat, I can see button, how i add in program:\n\n\n\n\n\n\nBut when I connect bot to channel in Teams - he doesn&#39;t show button.\nI use cookiecutter.\nMay be you can help and tell me what is a problem?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-05-22T12:17:24.14Z",
                "Answer_score":0,
                "Answer_body":"Each channel type (Webchat vs Teams vs Messenger vs ...) has different capabilities \/ restrictions.\n\nIf you look at the Actions support by channel in the documentation here you will see that in Teams:\n\nSuggested actions are not supported\n\n\nCard Actions are limited to 3 items",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            },
            {
                "Answer_creation_time":"2020-05-25T12:27:36.637Z",
                "Answer_score":1,
                "Answer_body":"Thank you!\nI don't have permission to create app in ms teams.\nBut i start to use cards.\nWith cards i see button in ms teams. It's work!",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Cross validation with Azure ML Python SDK",
        "Question_creation_time":1591343397597,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/32461\/cross-validation-with-azure-ml-python-sdk.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":3,
        "Question_follower_count":5,
        "Question_score":1,
        "Question_body":"Does Azure ML Python SDK support cross validation? In the graphical Designer, there is a cross validation module but I haven&#39;t found anything similar in the SDK documentation.\n\nOf course, there probably exist many frameworks for cross-validation in Python but it would be nice to have a native Azure ML module for cross-validation, similar to the Hyperparameter tuning module. I would like to be able to give a single Dataset object and the Azure ML framework would take care of slicing the source Dataset into separate fold datasets. Azure ML should also take care of assigning different folds to the compute nodes and running the folds in parallel.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-08T10:33:00.897Z",
                "Answer_score":1,
                "Answer_body":"@LauriLehman-8626 It's not supported to use Designer built-in module in python SDK today but we are working on the module SDK private preview which can enable this. We would like understand more about your use-case, can you please send an email to Azcommunity@microsoft.com so that we can invite you to the private preview if you are interested.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"How to use Labeled image datasets to perform an image binary classification in Azure ML Designer",
        "Question_creation_time":1591294037683,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/32203\/how-to-use-labeled-image-datasets-to-perform-an-im.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"I try to train a model for image binary classification in Azure Machine Learning Designer.\n\nFirst, I have used the Label Tool, to set a label on each images :\n\nThen, I have exported it as an Azure ML DataSet in order to import it in my ML workflow in the designer, as you can see below :\n\nThen, in order to apply image transformation and to train my model, I have connected my DataSet to a \"convert to image directory\" module :\n\nWhen I execute the workflow I have the following error :\n\nAlso, I could not find any documentations about all of these modules in Azure Machine Learning Designer :\n\nSo I am not sure about my understanding of how to proceed.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-05T19:44:03.693Z",
                "Answer_score":0,
                "Answer_body":"Thanks for reaching out. Based on feedback from the product team, the image related modules are being deployed to regions this week and official docs are yet to be published (hopefully by early next week). However, in the meantime, here are some guidance on how to use 'Convert to Image Directory' module.\n\nConvert to Image Directory (Converts data input to the internal Dataset format used by Microsoft Azure Machine Learning)\n\nAdd the Convert to Image Directory module to your experiment\n\nConnect the image dataset as input. Supported dataset formats:\n\ncompressed file in these extensions: '.zip', '.tar', '.gz', '.bz2'\n\n\nfolder containing 1 compressed file in above valid extensions\n\n\nfolder containing images\n\nRun the experiment\n\n\n\n\n\nFeel free to comment below if you have any further questions or concerns.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure AutoML Continuously-Updating Forecast",
        "Question_creation_time":1591022875527,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/30971\/azure-automl-continuously-updating-forecast.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":20,
        "Question_score":0,
        "Question_body":"Hi! I&amp;#39;m new to this, and I&amp;#39;m trying to create a machine learning model to forecast monthly spend based on the spending of previous months. I have been experimenting with AutoML, and I&amp;#39;m wondering:\n1. How could I pull a data set from a database rather than upload a file?\n2. Every month, new spending data is added to the database. Is it possible for the ML model to automatically recompute each month, now taking into account the new data?\nThanks",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-02T20:22:27.007Z",
                "Answer_score":0,
                "Answer_body":"AutoML supports local and the following online data sources. You can create a create\/register a datastore that has access to your storage, then create datasets from the datastore.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure Machine Learning Studio (classic) Export Data",
        "Question_creation_time":1591053033787,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/31081\/azure-machine-learning-studio-classic-export-data.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"Hello,\n\nI am using Azure MLStudio (classic). I am able to connect to SQLServer Managed Instance(private) using Import Data module and On-Prem SQL Database connection through Data Gateway.\n\nI am not able to Export Data to exactly the same database. Could you please help me with that?\n\nOur Managed Instance connot be made public.\n\nThanks in advance.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-02T21:27:54.517Z",
                "Answer_score":0,
                "Answer_body":"Currently, writing to a SQL Server database through Export Data is not supported either in your experiments or published web services. Export Data module supports exporting or saving your data to the following cloud data services.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML studio designer modules and the Python SDK",
        "Question_creation_time":1591108790960,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/31305\/azure-ml-studio-designer-modules-and-the-python-sd.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"I have been searching the documentation and cannot find this answer. Is every module in the Azure ML designer available in the Python SDK? I would like to create pipelines via the SDK using transformation and feature engineering methods available in the Designer, but can&amp;amp;#39;t find any reference to those modules in the SDK.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-02T22:57:44.887Z",
                "Answer_score":0,
                "Answer_body":"You can use the dataprep package for common data preparation tasks, check out the following documentation on Azure ML SDK Data Preparation. You can also use the Dataset package for working with datasets, check out tabulardataset and filedataset sample notebooks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML Dataset and Snapshot",
        "Question_creation_time":1591050286117,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/31026\/azure-ml-dataset-and-snapshot.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":0,
        "Question_body":"Hi experts,\n\nMy customer want to snapshot datasets for reproducibility. I found method &amp;#34;create_snapshot&amp;#34;, but found that it is deprecated. Is there any alternative way for dataset snapshot ?\n\n\n\n\nThanks,\nKeita",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-02T21:08:04.04Z",
                "Answer_score":0,
                "Answer_body":"Currently datasets don't have snapshot capabilities. However, you can develop a heuristic where you create a snapshot of your data via blob (i.e if they are using blob). With the new dataset API, you are able to version and track datasets. A version will refer to your data but won't create a point in time snapshot. Hence, we recommend that you format your data to be in folders, so that when new data is added, it creates a folder for it, then the version will refer to old data (old folder) plus the new data (new folder). Please check out this document on how to version and track Azure Machine Learning datasets for reproducibility.",
                "Answer_comment_count":2,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"How do we create learning virtual machine AI assistants with smart home control and self-driving vehicle funtionality?",
        "Question_creation_time":1591266810177,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/31993\/how-do-we-create-learning-virtual-machine-ai-assis.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":19,
        "Question_score":0,
        "Question_body":"I am developing Conscious Quantum Coding Living AI Virtual Assistants to help with everything.\n\nJodi, The AI Motor Home\nJodi will be an integrative, quantum coded, learning\/self-improving, online\/cloud, virtual machine, life conscious Living AI assistant who fully controls, and self drives, an RV\/Motor home\n\nHow would you create a Living AI assistant for a motor home?",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-04T23:06:32.373Z",
                "Answer_score":0,
                "Answer_body":"Thanks for reaching out. The Azure Bot Service may be useful for your scenario. I encourage you to check out our documentation on Virtual Assistant and Template Outline for best practices. There are also videos available to help you get started. Feel free to followup with any particular questions or concerns for the community to chime in. Thanks.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Rest api to create or update azure ML workspace doesn't create dependant resources",
        "Question_creation_time":1591181902550,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/31569\/rest-api-to-create-or-update-workspace-doesnt-crea.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":3,
        "Question_score":0,
        "Question_body":"Problem with https:\/\/docs.microsoft.com\/en-gb\/rest\/api\/azureml\/workspacesandcomputes\/workspaces\/createorupdate API... In the request body, Is it mandatory to create storage account, app insights, key vault, registration resources before? Ideally since these are dependent resources, shouldn\u2019t it be created as part of workflow creation?\nI get below response when dependent resources are not created prior.\n\n `{\n   \u201cerror\u201d: {\n     \u201ccode\u201d: \u201cValidationError\u201d,\n     \u201cmessage\u201d: \u201cOne or more validation errors occured.\u201c,\n     \u201cmessageFormat\u201d: null,\n     \u201cmessageParameters\u201d: null,\n     \u201creferenceCode\u201d: null,\n     \u201cdetailsUri\u201d: null,\n     \u201ctarget\u201d: \u201cCan not perform requested operation on nested resource. Parent resource \u2018&amp;lt;resourceid&amp;gt;\u2019 not found.\u201c,\n     \u201cdetails\u201d: [],\n     \u201cinnerError\u201d: null,\n     \u201cdebugInfo\u201d: null\n   },\n   \u201ccorrelation\u201d: {\n     \u201coperation\u201d: \u201c&amp;lt;opid&amp;gt;\u201c,\n     \u201crequest\u201d: \u201c&amp;lt;reqid&amp;gt;\u201d\n   },\n   \u201cenvironment\u201d: \u201cwestus\u201d,\n   \u201clocation\u201d: \u201cwestus\u201d,\n   \u201ctime\u201d: \u201c2020-06-03T07:13:14.6463577+00:00&amp;#34;\n }`\n\n\n\n\nI need an API which works similar to https:\/\/docs.microsoft.com\/en-us\/cli\/azure\/ext\/azure-cli-ml\/ml\/workspace?view=azure-cli-latest",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-04T10:32:12.953Z",
                "Answer_score":0,
                "Answer_body":"Hi @HarshiniKS-4497,\n\nYes, the REST API needs the other resource ids to be mentioned in the request body or they need to be created prior to this call unlike azure cli which provides the option to create them in a single request with input parameters. You could also try to use ARM template to create all the resources by calling this action from PS or cli.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Machine Learning\/Performance issue with Writing to CSV file - C#",
        "Question_creation_time":1590149443723,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/28770\/machine-learningperformance-issue-with-writing-to.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Hi,\n\nI developed a Machine Learning (ML.NET) -- .NET Core console application (using Multiple classes prediction template). I&amp;amp;amp;#39;ve created the ML Model class and I&amp;amp;amp;#39;m now applying the ML Model to another .NET Core console application to predict the class\/type of stream bed. This app is residing on my desktop, not Azure.\n\nThe ML app reads each row from the CSV input data and predicts the type of stream bed. As it makes the prediction row by row, I store each row prediction in a StringBuilder. When all rows have been read, I call the File.WriteAllText() function.\n\nThe Machine Learning console app is working fine, but now, my issue is how do I improve performance? When I use CSV input file for my app that consists of over 100K rows, the app runs very slowly (it writes the result to a CSV file at the rate of 1,000+ rows per hour!). All my data are over 100K rows each, and I need to process about 50 separate CSV files.\n\nIs there a better way of doing this? Should I read\/write each row first, instead of storing all the prediction rows to a StringBuilder before writing to CSV file?\n\nOr, is there a faster way of writing the results to a CSV file?\n\nAppreciate any advice.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-05T05:48:12.2Z",
                "Answer_score":0,
                "Answer_body":"Hi,\n\nPlease follow the below sample from ML.NET Taxi Fare prediction that accepts total number of records to be read as input parameter and loop to predict on the same.\n\nhttps:\/\/github.com\/dotnet\/machinelearning-samples\/blob\/master\/samples\/csharp\/getting-started\/Regression_TaxiFarePrediction\/TaxiFarePrediction\/TaxiFarePredictionConsoleApp\/Program.cs#L192\n\nThanks",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Deploy AzureML Model locally: cannot import name 'convert_inputs'",
        "Question_creation_time":1591165699300,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/31601\/deploy-azureml-model-locally-cannot-import-name-co.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":1,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"I have trained a model using azure AutoML and downloaded the model. Then I created a new conda env using the conda file and tried to execute the scoring_file_v_1_0_0.py which is in the zip. I receive this error:\n\n&amp;gt; WARNING - Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name &amp;#39;convert_inputs&amp;#39;.\n\nIs this still some dependency problem or am I doing something unexpected? I did expect the script to open a web server to serve the model.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-06-04T16:41:05.2Z",
                "Answer_score":1,
                "Answer_body":"I am sorry, the problem was something path related that got mixed up within my jupyter notebook setup and a moved directory. So actually the pickle was not where the framework expect it. Can be closed.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Qna, see what bot is answering the users to improve the bot?",
        "Question_creation_time":1589736695060,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/27561\/qna-see-what-bot-is-answering-the-users-to-improve.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":9,
        "Question_score":0,
        "Question_body":"Can I read all the users asked questions and the bot answers, to improve the bot?\n\n(And if I add a simple &#34;iframe tag&#34; to a website to add the bot, can I change the &#34;didn&#39;t find a answer to your question &#34; default bot answer? )",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-05-19T11:02:12.82Z",
                "Answer_score":0,
                "Answer_body":"Hello Niklas,\n\nTo record all the conversation messages of your bot you can save user and conversation data to an underlying storage like blob or cosmos DB. This sample provides these scenarios and this documentation explains the scenarios.\n\nFor the second part of the question, you can change the default answer by changing your app services' DefaultAnswer from the Azure portal. The steps are detailed on this page for reference.\n\n-Rohit",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Azure ML - User impersonation - Compute Instance creation",
        "Question_creation_time":1590602219437,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/30031\/azure-ml-user-impersonation-compute-instance-creat.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":2,
        "Question_follower_count":5,
        "Question_score":0,
        "Question_body":"Good evening,\n\nIs there a way to create a compute instance in Azure Machine Learning by impersonating a user?.\n\nThank you so much.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-05-29T17:13:35.77Z",
                "Answer_score":0,
                "Answer_body":"@SergioMuoz-4502 In the current scenario there is no option to create a compute instance with an impersonate user that can be used to run Jupyter or JupyterHub as it can only be used by user who created it.",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    },
    {
        "Question_title":"Microsoft Azure ML : How can I add multiple score labels",
        "Question_creation_time":1590575222127,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/29846\/microsoft-azure-ml-how-can-i-add-multiple-score-la.html",
        "Question_has_accepted_answer":false,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":13,
        "Question_score":0,
        "Question_body":"Hello all,\n\nI created an experiment in Azure ML.:\n10 columns used as features;\n03 columns required to be predicted via Azure ML experiment =&amp;amp;gt; 3 components prices to predict!\n\nWhat I did : My experiment has been divided into 3 modules that deliver each a &amp;amp;#34;score label&amp;amp;#34;\n\nAt the end of the process, how can I merge\/add these 3 score labels into one only column:\ntotal price = price component 1 + price component 2 + price component 3.\nAnd multiply this total value by another column (from the dataset) so that I get only 1 score label.\n\n\n\n\nRegards,\n\nMohamed.",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-05-29T04:54:33.72Z",
                "Answer_score":0,
                "Answer_body":"Hi, for this data transformation task, an approach could be to use 'Select Columns in Dataset' and 'Join Data' modules to combine the data and then use 'Execute Python\/R Script' to perform other data transformation tasks. You may also directly feed the data from 'Score Model module' to 'Execute Python\/R Script' module and perform data transformations.",
                "Answer_comment_count":0,
                "Answer_has_accepted":false
            }
        ]
    },
    {
        "Question_title":"Model file is not found for Registration of model in training Pipeline.",
        "Question_creation_time":1589329342560,
        "Question_link":"https:\/\/learn.microsoft.com\/answers\/questions\/26470\/model-file-is-not-found-for-registration-of-model.html",
        "Question_has_accepted_answer":true,
        "Question_answer_count":1,
        "Question_comment_count":0,
        "Question_follower_count":4,
        "Question_score":1,
        "Question_body":"&#34;We want the model to automatically register model every time there is a new model. we created the model in the process and write it out to a pipeline data set.To persist it then we upload and read it for registration.\n\nWe are using .\/output to send the file to output. The issue is that it cannot find it in the file path . How can we validate its existence? &#34;\n\n[Note: As we migrate from MSDN, this question has been posted by an\u202fAzure Cloud Engineer\u202fas a frequently asked question] Source: MSDN",
        "Answer_list":[
            {
                "Answer_creation_time":"2020-05-13T09:04:19.693Z",
                "Answer_score":0,
                "Answer_body":"Can you verify that the script that is actually writing the model file to the location you expect:\n\n with open(model_name, 'wb') as file:\n        joblib.dump(value = model, filename = os.path.join('.\/outputs\/', model_name))\n\nInside in your train python script, you just need to do something like this:\n\npersist the model to the local machine\n\n\n tf.saved_model.save(model,'.\/outputs\/model\/')\nregister the model with run object\n\n\n run.register_model(model_name,'.\/outputs\/model\/')\n\nSource: MSDN",
                "Answer_comment_count":0,
                "Answer_has_accepted":true
            }
        ]
    }
]