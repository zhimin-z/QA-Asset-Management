[
    {
        "Question_title":"Issue installing polyaxon python client urllib3.exceptions.ProtocolError: OSError",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1519",
        "Question_creation_time":1667914384000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"Archived from slack discussion!\n\nI\u2019m receiving the following error recently, but it only occurs when I use a VPN, if I\u2019m in the office I don\u2019t get this issue.\nHas anyone received similar or have any clues on what might be the problem?\n\n File \"\/usr\/local\/opt\/python@3.8\/Frameworks\/Python.framework\/Versions\/3.8\/lib\/python3.8\/ssl.py\", line 1019, in _create\n    self.getpeername()\nurllib3.exceptions.ProtocolError: ('Connection aborted.', OSError(22, 'Invalid argument'))",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-11-08T13:34:15Z",
                "Answer_score":1,
                "Answer_body":"Sometimes the CA bundle is not up-to date and needs to be installed manually, especially if it's a new Python version. Please run the following commands:\n\ncd \/Applications\/Python\\ 3.8\/\n\nthen\n\n.\/Install\\ Certificates.command"
            }
        ]
    },
    {
        "Question_title":"Can I add Component Tags via Input Params?",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1518",
        "Question_creation_time":1667585195000,
        "Question_answer_count":0,
        "Question_score":1,
        "Question_body":"I have no idea if this is possible, but I found myself wanting to do the following.\n\nIn words, I want to add component tags based on matrix parameters. The following yaml doesn't work, but I think it illustrates what I want.\n\nversion: 1.1\nkind: operation\nmatrix:\n  kind: grid\n  params:\n    sota:\n      kind: choice\n      value:\n        - model: ModelA\n          max_epochs: 200\n          dataset_hash: ae43ff\n        - model: ModelB\n          max_epochs: 150\n          dataset_hash: 33fba2\ncomponent:\n  name: model-trainer\n  tags:\n    - dataset_update_retrain\n    - \"{{ sota.model }}\"  #<- I want to set this dynamically based on the job input\n  inputs:\n    - name: sota\n      type: dict\n      isOptional: false\n  run:\n    kind: job\n    container:\n      args: >\n        set -x;\n       train \\\n          hydra.run.dir={{ globals.run_outputs_path }} \\\n          model={{ sota.model }} \\\n            model.datamodule.dataset_hash={{ sota.dataset_hash }}\/ \\\n            model.datamodule.data_directory=\/data\/{{ sota.model }}\/ \\\n          trainer=gpu \\\n            trainer.max_epochs={{ sota.max_epochs }} \\\n      ...\n\nAs the above pattern doesn't work, I am either doing it wrong or it isn't possible in the config. Could I potentially set ENV vars that could get picked up by the tracking client?\n\nThanks a ton for the help!",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How to using client to upload data\/artifacts to s3 bucket?",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1516",
        "Question_creation_time":1665738037000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"How to use the client to upload data\/artifacts to the s3 bucket?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-10-14T10:05:16Z",
                "Answer_score":1,
                "Answer_body":"To upload artifacts to a newly created run, you can use a snippet like this one:\n\n...\n# upload_to should be a value like `path\/code`\nupload_to = upload_to or DEFAULT_UPLOADS_PATH\nmeta_info = {META_UPLOAD_ARTIFACTS: upload_to}\nclient = RunClient(owner=owner, project=project_name)\nrun_instance = client.create(\n    name=name,\n    description=description,\n    tags=tags,\n    content=op_spec,\n    is_managed=True,\n    meta_info=meta_info,\n   pending=V1RunPending.UPLOAD,  # Very important to tell the server to wait for the upload to finish\n)\n...\n# If path from then check if file otherwise it's local directory\nis_file = os.path.isfile(path_from) if path_from else False \nclient = RunClient(owner=owner, project=project_name, run_uuid=run_instance.uuid)\nif is_file:\n    response = client.upload_artifact(filepath=path_from, path=path_to, overwrite=True)\nelse:\n    response = client.upload_artifacts_dir(dirpath=path_from, path=path_to, overwrite=True, relative_to=path_from)"
            }
        ]
    },
    {
        "Question_title":"How to start a tensorboard for all runs that are part of a hyperparameter tuning operation",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1503",
        "Question_creation_time":1651747709000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"From slack\n\nCurrently, I am selecting all runs from the table and then creating a multi-run downstream operation. with the id of those runs.\nIdeally, there should be a simple way to start such multi-run tensorboard without manually selecting the runs, especially when the number of run of the hyperparameter operation is very large, at least larger than the maximum number of runs allowed by the pagination: 50.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-05T10:51:36Z",
                "Answer_score":1,
                "Answer_body":"You do not have to manually select the runs for a hyperparameter operation, you can use the pipeline operation's uuid to query all, or a subset, runs belonging to that matrix operation:\n\nversion: 1.1\nkind: operation\nhubRef: tensorboard:multi-runs\njoins:\n- query: \"pipeline: MATRIX_UUID\"\n  params:\n    uuids: {value: \"globals.uuid\"}\n\nTo filter further by a specific condition, for example loss metric:\n\nversion: 1.1\nkind: operation\nhubRef: tensorboard:multi-runs\njoins:\n- query: \"pipeline: MATRIX_UUID, metrics.loss: < 0.02\"\n  sort: metrics.loss\n  limit: 60\n  params:\n    uuids: {value: \"globals.uuid\"}"
            }
        ]
    },
    {
        "Question_title":"How to patch a multi-run downstream operation, for example tensorboard:multi-run",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1502",
        "Question_creation_time":1651747273000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"From slack\n\nHi, simple Q. I want to launch a tensorboard with the tensorboard profiler pip installed from the GUI. At the moment I am using this:\n\nversion: 1.1\nkind: operation\nhubRef: tensorboard:multi-run\njoins:\n- query: \"uuid: XX\"\n  params:\n    uuids: {value: \"globals.uuid\"}\n\nHowever I want to runPatch it so that it installs:\n\npip install -U tensorboard-plugin-profile\n\nIs there a way to easily do this?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-05-05T10:43:55Z",
                "Answer_score":1,
                "Answer_body":"You can add the following runPatch:\n\n...\npatchStrategy: replace\nrunPatch:\n  container:\n    command: [\"bash\", \"-c\"]\n    args:\n      - \"pip install -U tensorboard-plugin-profile && tensorboard --logdir={{globals.artifacts_path}} --port={{globals.ports[0]}} --path_prefix={{globals.base_url}} --host=0.0.0.0\"\n\nFor the specific case of tensorboard, we will add a new input plugins of type List[str] to the tensorboard component versions , so instead of patching the component, users can pass a parameter:\n\nparams:\n  plugins: { value: [tensorboard-plugin-profile, tensorboard-plugin-custom, ...] }"
            }
        ]
    },
    {
        "Question_title":"How to stop all runs attached to a specific queue",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1500",
        "Question_creation_time":1650719473000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"From slack\n\nHi team, I am trying to reconfigure queues for one of our agents, and one queue (used by several projects) is full and has several runs queued. Is there a feature to drain a queue, like a button or an API to stop all runs for a specific queue in all projects? (edited)",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-23T13:12:57Z",
                "Answer_score":1,
                "Answer_body":"Under all runs, you can just filter the table by that queue and then stop the runs using the selection and multi-run action:\n\nIf you use the same name for your queues in all agents you can additionally select the specific agent using the filter:"
            }
        ]
    },
    {
        "Question_title":"How to persist custom job runs table",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1499",
        "Question_creation_time":1650636682000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"From slack\n\nHi everyone. Is there a way to save display preferences in the job runs search UI? My main interest is in saving (1) which columns are displayed, and (2) the order in which they are displayed. Thank you.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-22T14:12:42Z",
                "Answer_score":1,
                "Answer_body":"There\u2019s a save button next to the query search, it persist everything configured in the dashboard: https:\/\/polyaxon.com\/docs\/management\/organizations\/searches\/"
            }
        ]
    },
    {
        "Question_title":"Artifacts lineage is tracked but the Dashboard and Artifacts tabs are empty",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1498",
        "Question_creation_time":1650441558000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"From slack\n\nI'm currently facing a problem regarding the polyaxon tracking module. When running a job, I can see the logged metrics, parameters, artifacts in the lineage tab, although on the Dashboard tab, I can see only the chart's name and no values being tracked.\n\nHave anyone encountered this issue before? Any help will be much appreciated.\n\nI have tried a basic example of MNIST, when training it on CPU it tracks the metrics, but on GPU it doesn't.\n\nAlso, when I'm running a training job (MNIST) on the CPU it tracks the metrics and I can see the charts in the Dashboard, but when I configure the polyaxonfile to use GPU, the logs are indeed saying that the GPU is being used, but the metrics charts are empty.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-20T08:04:02Z",
                "Answer_score":1,
                "Answer_body":"You are probably deploying Polyaxon with the default artifacts store and you are using multiple nodes.\n\nIf that's the case you will need to upgrade your deployment with one if the artifacts stores that supports multi-node deployment: https:\/\/polyaxon.com\/integrations\/#Artifacts\n\nMore info about the artifacts store default behavior: https:\/\/polyaxon.com\/docs\/setup\/connections\/#artifactsstore\n\nAlso, when I'm running a training job (MNIST) on the CPU it tracks the metrics and I can see the charts in the Dashboard, but when I configure the polyaxonfile to use GPU, the logs are indeed saying that the GPU is being used, but the metrics charts are empty.\n\nYour GPU is on different node that's why it shows the metrics and artifacts when running with CPU, note that even with CPU if it's on a different node nothing will show up, so you will need a PVC \/ blob storage accessible to all nodes."
            }
        ]
    },
    {
        "Question_title":"Pickle support?",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1493",
        "Question_creation_time":1548256656000,
        "Question_answer_count":2,
        "Question_score":1,
        "Question_body":"Would it be reasonable to have a custom pickling magic method? Something like this:\n\nclass DataFrameSummary:\n    ...\n\n    def __getstate__(self):\n         return {'length': self.length, \n                 'column_stats': self.column_stats,\n                 'corr': self.corr}\n   \n    def __setstate__(self, state):\n        self.length = state['length']\n        self.column_stats = state['column_stats']\n        self.corr = state['corr']\n\nI guess that usually, you don't need to store df property because it is probably already stored somewhere. Or it could be an optional behavior depending on __init__ parameters.\n\nWhat do you think?",
        "Answer_list":[
            {
                "Answer_creation_time":"2019-01-24T20:00:24Z",
                "Answer_score":1,
                "Answer_body":"I am not sure what would be the use case? Faster access or caching?"
            },
            {
                "Answer_creation_time":"2019-01-25T09:53:45Z",
                "Answer_score":1,
                "Answer_body":"In my case, it was for the purpose of restoring the state from the previous run. I am using Jupyter notebooks to carry out some data analysis, and the dataset is huge enough to take a few minutes to compute summary statistics. So I am doing something like this:\n\ntemp_summary = temp_dir\/'summary.pickle'\nif temp_summary.exists():\n    print(f'Loading previously saved summary: {temp_summary}')\n    summary = pickle.load(temp_summary.open('rb'))\nelse:\n    print('Generating summary statistics')\n    summary = DataFrameSummary(data)\n    print('Saving summary into pickle file...')\n    summary.df = None  # don't need to save the dataset itself\n    with temp_summary.open('wb') as file:\n        pickle.dump(summary, file)\n\nNot a bit deal but requires additional step to save summary onto disk :) Or even better, it could be something like summary.to_pickle() and summary.read_pickle(). Does it make sense?"
            }
        ]
    },
    {
        "Question_title":"How to filter all jobs that accessed a connection, a dataset, or an artifact",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1487",
        "Question_creation_time":1649676773000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"From slack\n\nHi, I have a quick question, is it possible to filter all jobs that requested\/accessed a specific connection?\n\nTo explain my use-case, we detected an issue with some data, and we would like to assess how many jobs and how far in the past that data was used in our training jobs.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-11T11:35:09Z",
                "Answer_score":1,
                "Answer_body":"V1.18 the following filters, or any combination, will be possible:\n\nBy connection name connections.name: CONNECTION1 | CONNECTION2\nBy connection tag connections.tags: TAG1 | TAG2\nBy connection kind connections.kind: git or connections.kind: KIND1 | KIND2\nBy artifact name artifacts.name: LINEAGE1 | LINEAGE2\nBy artifact kind artifacts.kind: model or artifacts.kind: KIND1 | KIND2\nBy artifact path artifacts.path: foo\/bar\nBy artifact state artifacts.state: STATE"
            }
        ]
    },
    {
        "Question_title":"How to retrieve all the artifacts lineage for a set of runs, based on both the name of the run, and the name of the artifact?",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1486",
        "Question_creation_time":1649410426000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"From slack\n\nI have several runs with the named RUN_NAME each run is logging an artifact named ARTIFACT_NAME. I would like to query all these artifacts from all this subset of runs.\n\nWhat I\u2019m using to try to achieve this is calling RunClient.client.runs_v1.get_runs_artifacts_lineage, but in this function I get all artifacts from all runs ever independently from the run name.\nAlso, when listing the artifacts from these runs, for some reason the path is always None, even though if I use the function you suggested last time, get_artifacts_lineage , for a specific run, I do get values on the path field.\nSo my two main issues are:\n\nHow do I get all artifacts from a set of runs with the same run_name?\nWhy the path is empty in case this is the correct function to use?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-08T09:35:06Z",
                "Answer_score":1,
                "Answer_body":"To filter all artifacts lineage directly by run name and artifact name:\n\nfrom polyaxon.client import RunClient\n\nRunClient.client.runs_v1.get_runs_artifacts_lineage(project=\"PROJECT_NAME\", query=\"run.name: RUN_NAME, kind: ARTIFACT_KIND, name: ARTIFACT_NAME\")"
            }
        ]
    },
    {
        "Question_title":"How to get model references logged by a specific run?",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1485",
        "Question_creation_time":1649410139000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"We are trying to save a model using log_model_ref and add a name to it, i.e. best_auc. Then we want to be able to retrieve this model from the latest run.\nHowever, if we use RunClient.client.runs_v1.get_runs_artifacts_lineage this returns all the artifacts ever generated for that project. And if we use RunClient.get_artifacts_tree, we do have more control about which run we are looking at, but we lose the name information we set when using log_model_ref?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-08T09:30:38Z",
                "Answer_score":1,
                "Answer_body":"To get the logged model refs:\n\nfrom polyaxon.client import RunClient\n\nrun_client = RunClient(project=\"PROJECT_NAME\", run_uuid=\"RUN_UUID\")\n\n# Query the lineage information\nlineages = run_client.get_artifacts_lineage(query=\"kind: model\").results\n\n# Download the lineage assets\nfor lineage in lineages:\n    run_client.download_artifact_for_lineage(lineage=lineage)\n\nYou can restrict the ref to specific lineage by filtering further by name:\n\nlineages = run_client.get_artifacts_lineage(query=\"kind: model, name: best_auc\").results"
            }
        ]
    },
    {
        "Question_title":"I would like to configure Polyaxon in a way to avoid asking data-scientists to configure pre-emptible node-pools or request TPUs on their own",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1484",
        "Question_creation_time":1649336966000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"From slack\n\nI am currently defining some machines configuration using machine-env1.yaml, machine-env2.yaml which basically contains node selectors and CPU, GPU, and TPU requests configuration, and then running:\n\npolyaxon run -f polyaxonfile.yaml -f machine-env1.yaml\n\nI have two problems with this approach:\n\nI need to copy the env files to all our git repos, which means if I make a change I need to perform several pull requests\nI need to tell the data-scientits to pull the last commit, sometimes that's not possible because they can not merge\/rebase the changes.\n\nBased on those two issues, in the end we tell data-scientists to just use:\n\nenvironment:\n  nodeSelector:\n    nodes: large-pool\n...\nrun:\n  ...\n  container:\n      resources:\n        limits:\n          cpu: 3000m\n          memory: 6000Mi\n        requests:\n          cpu: 2000m\n          memory: 4000Mi\n\nWhich is error prone and confusing for them, and make the files bigger and difficult to change.\n\nAny elegant way to abstract this type of configuration from the data-scientists?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-07T13:14:34Z",
                "Answer_score":1,
                "Answer_body":"We have already shared a resource on how to configure the environments in this guide\n\nif you are using multiple git repos and you do not want to replicate the yaml files in all repos you can register those files as presets:\n\nUsers will be able to use --presets machine1 or --presets=env1\n\nNote that in the example in that link, it shows that it defines a queue but you do not have to define a queue, a preset is just any YAML file that can be used with the override operator -f main.yaml -f override1.yaml -f override2.yaml in this case override1.yaml and override2.yaml it can be saved as organization presets using the UI.\n\nMore info from the intro section about presets and the UI section\n\nAlso, when you define presets you can use them directly on the operation or component\n\npresets: [preset1, preset2]\n\nThis is similar to the CLI command\n\npolyaxon run -f polyaxon.yaml --presets preset1,preset2"
            }
        ]
    },
    {
        "Question_title":"How can I start a Tensorboard for the top 5 experiments",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1483",
        "Question_creation_time":1649335986000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"From slack\n\nI would like to compare the top 4 experiments based on a specific metrics.\n\nCurrently I query the top experiment using the cli:\n\npolyaxon ops ls -q \"name: GROUP_NAME, metrics.loss:<0.002\"  -s \"metrics.loss\" -l 5\n\nAnd then I copy\/paste the run UUIDs to:\n\npolyaxon run --hub tensorboard:mulit-run -P uuids=UUID1,UUID2,UUID3,UUID4,UUID5",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-07T12:59:37Z",
                "Answer_score":1,
                "Answer_body":"From the UI or using a YAML file, you can run:\n\nversion: 1.1\nkind: operation\nhubRef: tensorboard:multi-run\njoins:\n- query: \"name: GROUP_NAME, metrics.loss:<0.002,  kind:job\"  \n  sort: \"metrics.loss\"\n  limit: 5\n  params:\n    uuids: {value: \"globals.uuid\"}\n\nNote that in the UI if create a filter \/ sort configuration, you can automatically create a multi-run Tensorboard based on that query, for example:"
            }
        ]
    },
    {
        "Question_title":"Are Tensorboad services preventing CPU nodes to scale down?",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1482",
        "Question_creation_time":1649335208000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"From slack\n\nWhen I schedule a tensorboard from the UI does it always schedule on the polyaxon \"core nodes\", or does it schedule on any cpu machine that is available?\n\nWe have an issue sometimes with cpu nodes not scaling down, and I am wondering if it is because tensorboards are running on them?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-07T12:47:05Z",
                "Answer_score":1,
                "Answer_body":"By default, Tensorboard service does not use any node scheduling, so it probably uses the default nodes.\nIf you need to use a different node selectors or attach presets. When you click start tensorboard or run downstreamOp, the modal shows an editor which is basically prefilled a polyaxonfile:\n\nyou can just assign a preset if you have one:\n\npresets: [tensorboard-cpu-preset]\n\nOr patch the run with a node selector:\n\nrunPatch:\n  environment:\n    nodeSelector:\n      polyaxon_pool_type: polyaxon-tensorboard\n\nNote that for Tensorboad, by default it loads the component from here: Tensorboard Component\nYou can create your own Tensorboad component by following this tutorial\nIn that case you will use:\n\nhubRef: ORG\/tensorboard:VERSION\n\nFinally you can add this preset if you think that you might forget about a services running forever: https:\/\/polyaxon.com\/docs\/core\/scheduling-presets\/services-timeout\/\n\nOr adding it before clicking start:\n\ntermination:\n  timeout: 86400 # 24 hours"
            }
        ]
    },
    {
        "Question_title":"How can I send Slack alert on failure ?",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1481",
        "Question_creation_time":1649334677000,
        "Question_answer_count":0,
        "Question_score":1,
        "Question_body":"From slack",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"How to configured S3 connection to upload\/download artifacts programmatically",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1480",
        "Question_creation_time":1649333190000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"We\u2019re implementing a few things and I\u2019ve got a quick question.\nI see the example here https:\/\/github.com\/polyaxon\/polyaxon\/blob\/faec6649ed6a09ad29365f17795a404cc714c22e\/site\/integrations\/data-on-s3.md but I don\u2019t quite understand how to setup that S3Service(...) object. what would I pass in? a connection? how do I create the s3 connection object to pass in? I\u2019ve got the connection defined in polyaxon\u2019s config\/polyaxonfile but I\u2019m not sure what to create in python there.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-07T12:11:52Z",
                "Answer_score":1,
                "Answer_body":"We have to update that section, those services are deprecated, I would use the new implementation:\n\nfrom polyaxon.fs.fs import get_fs_from_name\n\nfs = get_fs_from_name(\"model-registry-s3\")\n\nThis will return a fully resolved s3fs object. More information about how to use the fs object: https:\/\/s3fs.readthedocs.io\/en\/latest\/#examples.\n\nNote 1: The s3 rquirement is not installed by default, you wiil need pip install \"polyaxon[s3]\"\n\nNote2: You will have to request the connection:\n\nrun:\n  connections: [\"model-registry-s3\"]\n\nAlso by requesting the connection, the secret\/config will be available in the container, so you can also use boto3 automatically if you do not like the to the s3fs implementation.\n\nThe docs for:\n\nGCS\nS3\nAzure"
            }
        ]
    },
    {
        "Question_title":"How to show all active runs without selecting the status manually",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1479",
        "Question_creation_time":1649332873000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"From slack\n\nThere used to be a switch to show\/hide all active runs (multiple states at once) under the flags dropdown, I can't find it anymore. Was it removed from the UI?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-07T12:01:37Z",
                "Answer_score":1,
                "Answer_body":"It's directly under statuses, we consolidated some flags\/config options:"
            }
        ]
    },
    {
        "Question_title":"Update jobs status from CLI or Client",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1478",
        "Question_creation_time":1649332613000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"From slack\n\nI was wondering if there is CLI option to \"Update the Job status\" similar to:\n\nI have found polyaxon ops update --help\n\nUsage: polyaxon ops update [OPTIONS]\n\n  Update run.\n\n  Uses \/docs\/core\/cli\/#caching\n\n  Examples:\n\n  $ polyaxon ops update --uid 8aac02e3a62a4f0aaa257c59da5eab80\n  --description=\"new description for my runs\"\n\n  $ polyaxon ops update --project=cats-vs-dogs -uid 8aac02e3a62a4f0aaa257c59da5eab80 --tags=\"foo, bar\" --name=\"unique-name\"\n\nOptions:\n  -p, --project TEXT  The project name, e.g. 'mnist' or 'acme\/mnist'.\n  -uid, --uid TEXT    The run uuid.\n  -n, --name TEXT     Name of the run (optional).\n  --description TEXT  Description of the run (optional).\n  --tags TEXT         Tags of the run (comma separated values).\n  --help              Show this message and exit.\n\nLong story short is that lot of my jobs finished working with status \"Running\". Don't know why, but in logs I see they finished.\nSo I decided to stop them manually, and I see \"Stopping\".\nSome jobs are being stopped but did not change status\nSo I want to clean that and \"update the status\" manually --> let's mark them as stopped.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-07T11:58:53Z",
                "Answer_score":1,
                "Answer_body":"The first thing is the check the release notes with this kind of problems, as the issue could have been solved in subsequent releases.\n\nNow going back to the solution, It's better to use client to iterate over the runs and mark them as finished:\n\nfrom polyaxon.client import ProjectClient\n\npclient = ProjectClient(project=\"PROJECT_NAME\")\nfor r in pclient.list_runs(query=\"status: stopping\").results:\n    print(\"cleaning {}\".format(r.uuid)\n    RunClient(\"PROJECT_NAME\", run_uuid=r.uuid).log_stopped(message=\"manual cleaning\")"
            }
        ]
    },
    {
        "Question_title":"How to use boolean params as string values without converting to a boolean values",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1477",
        "Question_creation_time":1649330562000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"From slack\n\nI have a problem with plx CLI, a param of type str with value False that gets converted automatically, but I want to have a string parameter:\n\n- {name: add_noise,       type: str,   isOptional: true, value: \"False\"}\n\nPolyaxon compiles the YAML to\n\ninputs:\n  - ...\n  - name: add_noise\n    type: str\n    value: false  <-----\n    isOptional: true\n\nrun:\n  ...\n  container:\n    args:\n      - ...\n      - '--add_noise=false' <----",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-07T11:24:08Z",
                "Answer_score":1,
                "Answer_body":"To force the string value, you should use double quotation to avoid Yaml\/Json interpreting the value as bool \"...\":\n\n- {name: add_noise, type: str, isOptional: true, value: '\"False\"'}"
            }
        ]
    },
    {
        "Question_title":"Programmatic upload and start an operation without CLI",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1476",
        "Question_creation_time":1649330161000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"From slack\n\nI am using the python run client and am trying to use 'pending' correctly. Here is an example of my code:\n\nclient = RunClient(owner=\"owner\", project=\"project\")\nclient.create(content=operation, pending='upload')\nclient.upload_artifacts_dir('.\/')\n\nI can see in the UI a new job is created, the artifacts have been uploaded correctly but in the info panel pending is still in the 'upload' state and the status remains as 'created'.How do I progress the job \/ remove the pending status after the upload has occurred?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-07T11:19:11Z",
                "Answer_score":1,
                "Answer_body":"To start the operation and remove the pending state, you need to call client.approve().\n\nTo correct creation process with an upload should be:\n\nfrom polyaxon.schemas import V1RunPending\nfrom polyaxon.constants.globals import DEFAULT_UPLOADS_PATH\nfrom polyaxon.constants.metadata import META_UPLOAD_ARTIFACTS\n\nmeta_info = {}\nmeta_info[META_UPLOAD_ARTIFACTS] =  DEFAULT_UPLOADS_PATH  # or a custom path if you pass a custom upload to path \n# 1. Create\nclient.create(content=operation, meta_info=meta_info, pending=V1RunPending.UPLOAD)\n# 2. Upload\nclient.upload_artifacts_dir('.\/')\n# 3. Approve\nclient.approve()"
            }
        ]
    },
    {
        "Question_title":"Make references dynamic in DAGs",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1475",
        "Question_creation_time":1649330065000,
        "Question_answer_count":0,
        "Question_score":1,
        "Question_body":"From slack\n\nI would like to use a parameter with a ref to a run whose uuid is read from a parameter. For example, inside a DAG I can do the following:\n\nparams:\n  my_arg:\n    value: artifacts.my_artifact\n    ref: ops.my_op_in_the_same_dag\n\nI would also like to do\n\nparams:\n  my_arg:\n    value: artifacts.my_artifact\n    ref: runs.{{ params.upstream_run_uuid_not_in_this_dag }}\n\nThis is not possible at the moment because params object isn't ready in this context. But I guess with some dependency resolution, it could be made to work? I have a workaround for this myself (I'm generating polyaxonfiles on the fly based on some input arguments, so I can inject the UUID at compile time to the polyaxonfile), but IMO such a feature would be useful.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Auto-resume for deep learning training is not working",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1474",
        "Question_creation_time":1649329501000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"From slack\n\nI'm trying to run a training job and make it resume automatically whenever it is preempted or it encounters an issue.\nI'm using for this the \"termination\" and \"maxRetries\" field to restart the job.\nAfter a problem happens, the job is restarted automatically starting from where the problem has happened if I look at the logs. However, nothing is being saved to the artifacts and any call to tracking.log_metric doesn't seem to have an effect. If I look at the logs, the job then continues until it reaches the end. However instead of just ending, it just keeps restarting (from the point where the problem occurred) until all the \"maxRetries\" are used and fails with the warning \"Underlying job has an issue\" at the status page.\nAny idea what could cause such a problem and if there is anything I could do to avoid it?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-07T11:11:51Z",
                "Answer_score":1,
                "Answer_body":"Polyaxon provides several strategies to restart, restrat with copy mode, and resumes jobs. The auto-resume behavior is enabled by default\n\nNote that resuming a job can only work if your code supports loading the last checkpoint.\n\nHere's a quick debugging logic to check that the resuming process works as expected:\n\nmain.py\ndef main():\n    tracking.init()\n    checkpoint_path = tracking.get_outputs_path(\"checkpoint.json\")\n    checkpoint_path_exists = os.path.exists(checkpoint_path)\n    print(\"[CHECKPOINT] path found: {}\".format(checkpoint_path_exists))\n    if checkpoint_path_exists:\n        with open(checkpoint_path, \"r\") as checkpoint_file:\n            checkpoint = json.loads(checkpoint_file.read())\n            print(\"[CHECKPOINT] last content: {}\".format(checkpoint))\n    else:\n      print(\"[CHECKPOINT] init ...\")\n      checkpoint = {\n        \"last_time\": time.time(),\n        \"last_index\": 0,\n        \"array\": [],\n      }\n    for i in range(checkpoint[\"last_index\"] + 1, 300):\n      print(\"[CHECKPOINT] step {}\".format(i))\n      tracking.log_progress((i + 1)\/300)\n      tracking.log_metric(name=\"index\", value=i, step=i)\n      checkpoint[\"array\"].append(i)\n      checkpoint[\"last_index\"] = i\n      checkpoint[\"last_time\"] = time.time()\n      if i in [10, 50]:\n        print(\"[CHECKPOINT] Saving last content ...\")\n        with open(checkpoint_path, \"w\") as checkpoint_file:\n          checkpoint_file.write(json.dumps(checkpoint))\n        raise ValueError(\"Error was raised at {}\".format(i))\n      time.sleep(1)\npolyaxonfile.yaml\nversion: 1.1\nkind: component\ntermination:\n  maxRetries: 3\nrun:\n  kind: job\n  container:\n    image: polyaxon\/polyaxon-examples:artifacts\n    workingDir: \"{{ globals.run_artifacts_path }}\/uploads\"\n    command: [\"\/bin\/bash\", -c]\n    args: [\"pip install -U polyaxon --no-cache && python3 main.py\"]\nLogged a dummy metric that resumes from last checkpoint and (apart from the warning regression that I mentioned) the job succeeds after after two failures (you can see the first chart where the x-axis is the time that there's gap time)"
            }
        ]
    },
    {
        "Question_title":"Polyaxon CE fresh deployment never finishes",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1473",
        "Question_creation_time":1649328918000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"From slack\n\nHi, I\u2019m trying to deploy Polyaxon CE with helm\/argocd and the polyaxon-api keeps logging in loop:\n\nSystem check identified some issues:\n\nPreparing...\n\n\nand the pod never becomes ready.\nAny idea what could cause that?\n\nMore\n\nIt seems the polyaxon helm chart installation always fails with the message:\n\nError: timed out waiting for the condition\nThis is what I see:\n\npolyaxon-polyaxon-api-d8d7c8b5f-spsb2           1\/1     Running   0          3d5h\npolyaxon-polyaxon-api-dbb84b79c-6jqm9           0\/1     Running   2          13m\n\n\nThe polyaxon api pods take a long time to become ready. It fails liveness probe:\n\nEvents:\n  Type     Reason     Age                   From               Message\n  ----     ------     ----                  ----               -------\n  Normal   Scheduled  15m                   default-scheduler  Successfully assigned polyaxon\/polyaxon-polyaxon-api-dbb84b79c-6jqm9 to ip-192-168-165-30.us-east-2.compute.internal\n  Normal   Pulling    14m                   kubelet            Pulling image \"polyaxon\/polyaxon-api:xx\"\n  Normal   Pulled     14m                   kubelet            Successfully pulled image \"polyaxon\/polyaxon-api:xx\" in 33.387487209s\n  Normal   Created    14m                   kubelet            Created container polyaxon-api\n  Normal   Started    14m                   kubelet            Started container polyaxon-api\n  Normal   Killing    8m49s                 kubelet            Container polyaxon-api failed liveness probe, will be restarted\n  Warning  Unhealthy  8m37s (x10 over 13m)  kubelet            Readiness probe failed: Get \"[http:\/\/192.168.184.124:80\/healthz\/](http:\/\/192.168.184.124\/healthz\/)\": dial tcp 192.168.184.124:80: connect: connection refused\n  Normal   Pulled     8m19s                 kubelet            Container image \"polyaxon\/polyaxon-api:1.9.5\" already present on machine\n  Warning  Unhealthy  4m49s (x16 over 13m)  kubelet            Liveness probe failed: Get \"[http:\/\/192.168.184.124:80\/healthz\/](http:\/\/192.168.184.124\/healthz\/)\": dial tcp 192.168.184.124:80: connect: connection refused",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-07T11:02:58Z",
                "Answer_score":1,
                "Answer_body":"The firts step is to cehck if you are using the --wait flag with Helm, if yes the deployment will not pass because there's helm hook.\n\nThe reason of the deadlock: helm waits forever for API to be healthy and the API is waiting for the hook to initialize the database.\n\nMore info about the helm deadlock issue: helm\/helm#5118\n\nFor ArgoCD, the flag is set to true automatically: argoproj\/argo-cd#6880\n\nFor the Terraform provider for helm release, the flag is set to true by default: https:\/\/registry.terraform.io\/providers\/hashicorp\/helm\/latest\/docs\/resources\/release#wait and should be set it to false."
            }
        ]
    },
    {
        "Question_title":"How to debug my init git container",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1472",
        "Question_creation_time":1649328334000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"From slack\n\nMy job is stack with a warning status, I configured a private bitbucket connection and the cloning fails.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-07T10:51:48Z",
                "Answer_score":1,
                "Answer_body":"Before updating the connections or changing anything about your current deployment, please perform the following debugging steps:\n\nEnable logs from all containers:\n\n\n\nYou can also inspect the operations from the statuses page to get more information (for distributed runs you can select the correct pod)\n\n\nYou can suspend the init container using :\n\n  - connection: my-connection\n    git: {...}\n    container:\n      command: [\"\/bin\/bash\", \"-c\"]\n      args: [\"sleep 3600\"]\nUse shell to get inside the container (for distributed runs you can select the correct pod and container):"
            }
        ]
    },
    {
        "Question_title":"Batch deletion of archived runs",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1471",
        "Question_creation_time":1649327972000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"From slack\n\nI\u2019m new to Polyaxon and still learning how to use the UI. I would like to delete all archived jobs from All Runs but I can\u2019t see the option to filter them. We are running v1.17.0. Can you advise how to do it please? Thanks!",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-07T10:41:48Z",
                "Answer_score":1,
                "Answer_body":"You should first filter for archived runs, and then select all and use the actions above to delete the selection, you can eventually select a large table size, for example 50.\n\n  \n\nif you are an org admin and you need to delete archived runs cross-projects, you can use the button All Runs under the organization and follow the steps above:"
            }
        ]
    },
    {
        "Question_title":"Is there a way to have the logs from a polyaxon run viewable via the cloud UI?",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1470",
        "Question_creation_time":1649327817000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"From slack\n\nIs there some way we could save the output logs to have them be accessible?",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-07T10:37:50Z",
                "Answer_score":1,
                "Answer_body":"That's not possible I am afraid. Logs, as well as other artifacts, are only viewable via the gateway deployed with the agent.\n\nIn order to provide such option, Polyaxon will have to have access to the artifacts store, but I do not think that we want to provide such functionality at the moment since logs also can include sensitive information."
            }
        ]
    },
    {
        "Question_title":"Serverless Airflow Operators on Polyaxon",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1469",
        "Question_creation_time":1649327667000,
        "Question_answer_count":0,
        "Question_score":1,
        "Question_body":"Release the components library based on Airflow operators:\n\nRun in serverless way\nRun in containers\nLeverage the connection catalog based on the Kubernetes\/Vault secrets (no storing secrets in a database)",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Welcome to Discussions!",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1290",
        "Question_creation_time":1619177543000,
        "Question_answer_count":0,
        "Question_score":1,
        "Question_body":"Hey everyone,\n\nWe're opening up Discussions as a place for our community users to interact with each other and Polyaxon' contributors.\n\nWe've historically used Slack as the place to ask questions, and we would like to try a new experiment with discussion as the new default place to ask repeatable questions about how to use a specific feature.\n\nQ&A, Ideation, and feature requests\n\nThis is a great place to:\n\nAsk questions about Polyaxon\nRequest features from our team\nShare ideas and projects you are working on\nBug Reports\n\nIf you've found a bug, it is best to file an issue.\n\nJoin us on Slack\n\nYou are welcome to join our Slack community by signing up here\n\nWe will still be using Slack as a place to provide private help and make announcements about events and releases. We encourage all of our users to still join our community. If you have a question that contains sensitive information that needs to be asked in private, it is best to do it on Slack.\n\nCode of Conduct\n\nIn addition to the Code of Conduct guide line, we have a couple of rules we would like you to follow:\n\nBe nice, always!\nBe respectful; we assume positive intent from you and we ask the same in return\nAvoid posting sensitive information\nDon\u2019t abuse tagging other users\nDon\u2019t advertise material unrelated to Polyaxon\nExplicit is better than implicit: be as precise as you can.\nIt\u2019s OK to disagree but disagree politely and constructively.\nAvoid absolutes: absolute statements do not provide room for a conversation to grow\nNever attack: being defensive about your own ideas, or running offense on another person\u2019s ideas will always result in shutting down collaboration\nStay humble: disagreements are learning opportunities\nBefore creating a new topic, search if someone posted a similar issue before to avoid duplication.\nEach topic should be well-scoped (focused on one thing), non-duplicated and specific to problematic we are solving in one of our repos or with our solution.\nOrganizing FAQs and discussions\nTitle: try to specify the problem rather than the feature or solution you tried.\nIf you have multiple issues, please break them down to multiple discussions.\nUse labels to categorize the new discussion.\nProvide as much information as you can to help us identify the root cause of the issue:\nWhat environment are you using, e.g. Python version when for CLI\/Library issues?\nWhat infrastructure are you using, e.g. an on-premise deployment, a specific cloud provider (AWS, GCP, Azure).\nWhat version are you using?\nDid you check the docs and search bar?\nDid you check the discussions and github search?\nDid you try upgrading before asking?\nIf the issue is related to operations on k8s, can you please use the inpsection button and copy\/paste the YAML results as an attachement (you can replace sensitive info with xxx).\nCan you share logs or code snippets that can make it easier to reproduce your issue?\nAs a discussion creator, you will have a button that allows you to accept an answer. If some user responds to your question with a great answer, mark it as the accepted solution. Doing that helps others quickly navigate to the answer that helped you solve the problem.\nCategories\nAnnouncements: a category for general-purpose category for announcing new releases and blog posts.\nFAQ: a category for frequently asked questions not strictly falling into any other mentioned category.\nQ&A: a category to ask for help.\nGeneral: a category for discussing anything related to Polyaxon.\nShow and tell: a category for links to various resources that can help you get started and learn about Polyaxon as we as a place for sharing blog posts, walkthroughs, or simply sharing how to solve a specific problem.\nIdeas: a category to share ideas for new features.",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Create video tutorials for the new users",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1459",
        "Question_creation_time":1649007252000,
        "Question_answer_count":2,
        "Question_score":3,
        "Question_body":"We have been using Polyaxon for years as the ML Platform team. One feedback we got from ML engineers is the onboarding cost. One idea to help the onboarding is to create video tutorials for new users.",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-04-03T18:51:28Z",
                "Answer_score":2,
                "Answer_body":"Hi @shotarok ,\n\nI already started some work around some recurrent use-cases that I see in demos: https:\/\/www.youtube.com\/channel\/UCbzCxshQWTxCZPWZwgM0ePw\nMore short content around specific use-cases is under work.\nIf you have specific use-cases that you would like to see and share with the rest of your team as an educational or on-boarding material, please let me know."
            },
            {
                "Answer_creation_time":"2022-04-03T18:55:19Z",
                "Answer_score":1,
                "Answer_body":"Another idea that I was thinking about is starting a bi-weekly or a monthly community call, where anyone can join and we can either demo specific aspects of the platform or answer questions."
            }
        ]
    },
    {
        "Question_title":"Does Community UI has Admin dashboard?",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1460",
        "Question_creation_time":1648187728000,
        "Question_answer_count":4,
        "Question_score":1,
        "Question_body":"I have setup a community self-hosted polyaxon, and the config abourt ui is\n\nui:\n  enabled: true\n  offline: false\n  adminEnabled: true\n\n\naccording to the documentation, if I set adminEnabled to true, there should be an admin dashboard. But I did not find it, there is no difference to turn it on\/off",
        "Answer_list":[
            {
                "Answer_creation_time":"2022-03-25T08:25:27Z",
                "Answer_score":1,
                "Answer_body":"The admin page is under http:\/\/localhost:8000\/_admin\/"
            },
            {
                "Answer_creation_time":"2022-03-26T13:32:39Z",
                "Answer_score":1,
                "Answer_body":"The admin page is under http:\/\/localhost:8000\/_admin\/\n\nthanks, can I expose it with ingress to a LAN IP instead of localhost?"
            },
            {
                "Answer_creation_time":"2022-03-26T13:35:31Z",
                "Answer_score":1,
                "Answer_body":"by the way, what's the default user name and pwd? I used the value in default config.yml, can not login in"
            },
            {
                "Answer_creation_time":"2022-03-26T13:41:33Z",
                "Answer_score":1,
                "Answer_body":"thanks, can I expose it with ingress to a LAN IP instead of localhost?\n\nIt should be visible from the ingress as well."
            }
        ]
    },
    {
        "Question_title":"Support for spark DF?",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1497",
        "Question_creation_time":1644430572000,
        "Question_answer_count":0,
        "Question_score":1,
        "Question_body":"",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Re-introduce a per-operation automatic build process",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1286",
        "Question_creation_time":1619176829000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"This discussion was started on slack and was moved to github for future reference.\n\nOriginal content:\n\nAfter some thinking about the impact and the size of this feature request https:\/\/polyaxon.slack.com\/archives\/C6QBND2SV\/p1618316341162200\nI think we will probably deploy an experimental version next release (v1.9) or the one after (v1.10) to Polyaxon Cloud. Once we think the feature is stable and does not require any major migrations (both on the spec and db level) we will move it to CE & EE.\n\nThis feature will not replace the ad-hoc build operations, users can still create independent polyaxonfiles with a kaniko\/dockerize hub ref.\nThe no-build requirement that the platform provides at the moment will stay the same, so users who have stable pipelines that do not require frequent changes to their images can safely ignore this feature.\nA new section build will be introduced, where users can signal to the platform that a build is required prior to starting the main operation, the build section will provide the necessary fields to provide stuff like, queue, preset, resources, node selectors, ... specific to the build.\nCache (and invalidation) requires some improvements on the commercial offering, but they are planned anyway. I am not sure yet how it would work for CE, but we will work on it when we get to that point and will add docs around edge cases.\nBy providing a build section, Polyaxon will take care of generating the image based on the project and the uuid, project:build-uuid, and will set that image automatically on the container of the main operation. The registry to use will be still configured via a connection.\nA new status building will be added to show that a build is progressing before compiling the main manifest (without the build). And a build icon in the UI to redirect to the build run for viewing info, logs, \u2026 about the build operation.\nWhen the build and matrix sections are used together, a single build operation will be scheduled and will be used for all runs.\nTo make the process predictable and easy, when the build section is used with -u\/--upload flag of the run command, the uploaded artifacts will automatically be injected in the build operation and not the main operation, which means users have to copy any necessary artifacts to their generated image.",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-27T18:21:27Z",
                "Answer_score":1,
                "Answer_body":"https:\/\/polyaxon.com\/docs\/automation\/builds\/"
            }
        ]
    },
    {
        "Question_title":"(How) Can I pass path to Dockerfile using Kaniko?",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1315",
        "Question_creation_time":1620659662000,
        "Question_answer_count":1,
        "Question_score":1,
        "Question_body":"Context\n\nLet's say I have following structure\n\nroot\n\u251c\u2500\u2500model_files\n\u251c\u2500\u2500polyaxonfiles\n\u2502      \u251c\u2500\u2500build.yml\n\u2502      \u2514\u2500\u2500run.yml\n\u251c\u2500\u2500utils\n\u2514\u2500\u2500dockerfiles\n         \u251c\u2500\u2500Dockerfile.0\n         \u2514\u2500\u2500Dockerfile.1\n\n\nmy build looks as simple as:\n\nversion: 1.1\nkind: operation\nname: build\nparams:\n  context:\n    value: \"{{ globals.run_artifacts_path }}\/uploads\"\n  destination:\n    connection: docker-registry\n    value: machine-learning\/polyaxon-tutorial:1\n\nhubRef: kaniko\n\nRunning this with command\n\npolyaxon run -f polyaxonfiles\/build.yml -u\n\nGives me very much expected error:\n\nError: error resolving dockerfile path: please provide a valid path to a Dockerfile within the build context with --dockerfile\n\nSo the Kaniko expects Dockerfile to exist in root of the context by default. Does the polyaxonfile specification exposes a way to overwrite the default as suggested with error message?",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-05-10T16:58:05Z",
                "Answer_score":2,
                "Answer_body":"Hi @captainCapitalism, next release we will be pushing a new set of guides, including guides for building containers and how to pass a custom dockerfile context.\n\nWe will update this thread as soon as we start updating the documentation's guides section."
            }
        ]
    },
    {
        "Question_title":"Best practices of project management for multiple users on Polyaxon v1",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1306",
        "Question_creation_time":1619642544000,
        "Question_answer_count":1,
        "Question_score":6,
        "Question_body":"Hello all, I\u2019m curious about the best practices of project management for multiple users on Polyaxon v1. Polyaxon v0 allows multiple users to have the same name project, but a project seems to be global under an organization on Polyaxon v1. The ideas I came up with are the following. Do we have other approaches?\n\nAdd username as a prefix or suffix to a project name\nUse username as a tag in a project",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-29T18:21:00Z",
                "Answer_score":1,
                "Answer_body":"Let's make this Discussion a home for sharing and discussing patterns users are following to:\n\nOrganize and manage their projects\nSettings for CI\/CD\/CT\nEnable the rest of the community to share their thoughts on this important part of developing and scaling their workflows with Polyaxon\nEnable auditing and access to protected data\nGo from experimentation to deployment\nEnable reproducibility\nEnable collaboration\n\nTo set a template of how to share a pattern and to keep the Discussion organized:\n\nLet's make each comment describe a pattern\nLet's use threads to comment and ask questions about a specific pattern\nLet's follow, loosely, the template below\n\nNote: Some of the patterns might be converted to tutorials or added as guides in the scheduling strategies or deployment strategies in the documentation.\n\nTemplate\n\n## Overview\n\n> A description of the process or the pattern\n\n## Local project structure\n\n> Folders and files structure\n\n## Writing\/Authoring polayxonfiles\n\n> YAML vs Python\n> Using presets?\n> Using `pathRef`, `UrlRef`, `HubRef`, or a built-in component\n> Component vs Operation\n> Forking public hub components?\n\n## Development\n\n> How do you submit files to the API\/Scheduler during devlopement?\n> Do you use git or upload?\n> Do you require rebuilding images?\n> Do you generally delete test files and test runs?\n> How do you manage tags?\n> Does Polyaxon need some extra tags management on the project\/org level?\n> Does Polyaxon need some special tags: like `prod`\/`stage`\/`testing` similar to the model and the component versions?\n> Does Polyaxon need some special dropdown to allow users to easily switch the view to prod\/test, and the space should be preserved throughout the browsing experience?\n\n## Testing\n\n> How do you test your files and the logic you are running?\n> Do you declare a test data as a second connection and do you manually need to deploy a polyaxonfile with that subset\/test data?\n> Do you run the logic with NO_OP or OFFLINE?\n\n## Deployment\n\n> How do you handle polyaxonfiles discovery?\n> Do you write descriptions and do you deploy with new descriptions for each run? \n> How do you handle building images?\n> Do you submit polyaxonfiles with external systems?\n\n## Presets\n\n> Do you write override files?\n> Do you save them globally or on each repo?\n> Do you use presets to switch between test and prod?\n\n## Agents or Multi-deployment clusters\n\n> How do you manage multi-environments?\n> How do you manage data access?\n> How do you manage access to production connections?\n> Do you mount specific configmaps\/variables for production?\n\n## Limitations\n\n> Are their any limitations with this pattern?\n> Do you feel like Polyaxon can expose some abstractions to simplify this pattern?"
            }
        ]
    },
    {
        "Question_title":"Private github repo fail for using log_model and log_metric",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1302",
        "Question_creation_time":1619492179000,
        "Question_answer_count":2,
        "Question_score":1,
        "Question_body":"Describe the bug\n\nI have two version for using component. One is directly uploading local code to each pod, this work fine that we could see the models artifact and metric curve. The other one use the same code as the first one, except for using private github to load the code. In this case, the \"dashboards\", \"artifacts\" and \"resources\" pages show only \"NO DATA\", and \"logs\" page shows training output message normally.\n\nTo reproduce\nAdd private code connection\nconnections:\n  - name: my-repo\n    kind: git\n    schema:\n      url: https:\/\/github.com\/xxx\/my-repo\n    secret:\n      name: \"github-secret-my-repo\"\n\nruning job config:\nrun:\n  kind: job\n  init:\n    - connection: my-repo\n\nHow we use log_metric and log_model\n# log metric\ntracking.log_metric(\"val_loss\", val_loss, step=epoch)\ntracking.log_metric(\"val_precision\", precision, step=epoch)\ntracking.log_metric(\"val_recall\", recall, step=epoch)\n\n# log model\nmodel_output_dir = tracking.get_outputs_path(\"models\", is_dir=True)\nckpt_file = os.path.join(model_output_dir, 'checkpoint.pth.tar')\ntorch.save({xxx}, ckpt_file)\ntracking.log_model(name=\"checkpoint\", path=ckpt_file, framework=\"pytorch\")\n\nExpected behavior\n\nShowing metric curve and saving models normally.\n\nEnvironment\n\nminikube: v1.15.1\npolyaxon ce: 1.7.5",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-27T07:35:55Z",
                "Answer_score":1,
                "Answer_body":"This is very hard to debug, you need to check if the git repo has some more information like a hard-coded NO_OP.\n\nAlso I would check if you added the local cache folder .polyaxon to your .gitignore and .dockerignore. If this folder was added to you git repo, then indeed the metrics and artifacts will be saved to a different run.\n\nYou can also validate that the run is running with the correct run-uuid:\n\n...\nprint(tracking.TRACKING_RUN.run_uuid)\n...\n\nIf the run_uuid does not correspond to the currently running run, then the cache is bundled somewhere (git repo or docker image)."
            },
            {
                "Answer_creation_time":"2021-04-27T08:07:08Z",
                "Answer_score":1,
                "Answer_body":"I didn't add .polyaxon to my .gitignore, after fixed it, everything is ok now. Thanks!"
            }
        ]
    },
    {
        "Question_title":"Improve integrations with data sources",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1297",
        "Question_creation_time":1619251910000,
        "Question_answer_count":0,
        "Question_score":2,
        "Question_body":"This discussion was started on slack and was moved to github for future reference.\n\nOriginal content:\n\nThese are actually good questions (both the \u201cis there an integration for DVC\u201d and \u201chow do you want to use DVC\u201d), it was also asked a couple of times in the past, and I also had such discussions in demos or feedback sessions and shared some info with some users about upcoming work.\n\nI can share some ideas and some features we are planning, I think some of them will materialize in the next few months.\n\nFirst, I think it depends on the kind of data, how it\u2019s stored, how it changes, and how frequently it changes, and who changes that data. But we can look at the integration from the point of view of Polyaxon as it provides the orchestration and scheduling mechanisms that should work with different external systems and libraries.\n\nUsing DVC, DBT, Feast, \u2026 are all good candidates for integration in addition to the direct access with boto, GCS, Azure client, mounted paths, git, \u2026 that we currently provide.\n\nWe provide an abstraction called connection , that\u2019s how we integrate Polyaxon with an external system, some systems support a versioning mechanism like git, docker registries, data\/volumes\/buckets (by calculating a hash and storing the path)\nFor the current systems that we integrate with, we provide 3 mechanisms, an optional way to fetch the data automatically (an initializer), an optional way to collect some outputs automatically, and a custom container (main) that runs the user\u2019s logic with some accompanying tracking methods to log the version summary, and some predefined logic (i.e. tracking the commit, calculating the hash\/path, storing the image hash, \u2026) that the users can use or provide their own summary (json blob) about such versions.\n\nAdding an integration as initializer for DVC, DBT, Feast, \u2026 is a matter of extending the connection schema to allow the user to define the default access method, when multiple options are possible, like for datasets a user can use the native client or DVC, for a database the user can use the native library or DBT ...\nLinking and exploring artifacts and lineage for each connection. In Polyaxon EE\/Cloud we have a connections catalog metadata layer, this layer will be promoted to the same level as projects\/component hub\/model registry in the next coming releases. Users can explore all artifacts related to a connection, e.g. all container images related to a registry, all commits used in Polyaxon related to a git connection, all metrics references in an artifacts store. They can also see the runs that requested those git commits or artifact versions under a specific connection as well as the profile of the runs that interacted with those connections (e.g. duration, resources GPU\/CPU, ...).\nAdding an integration to the logging system, this is actually coming rather soon we are still thinking how best to handle CE. The tracking code will allow to specify the the connection for log_artifact_ref , log_code_ref , log_data_ref , log_file_ref , log_dir_ref and the generic log_artifact_lineage to provide the user with the tools to create such rich metadata.\nIf anyone want to discuss such features or would like share more ideas, feel free to comment. (edited)",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Push image error: Get \"https:\/\/https\/v2\/\": dial tcp: lookup https on SOME-IP: no such host",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1292",
        "Question_creation_time":1619178414000,
        "Question_answer_count":1,
        "Question_score":2,
        "Question_body":"This is question\/issue from Polyaxon Slack that was resolved. I am posting it for visibility if someone stumbles on the same issue with answer down below.\n\nGiven setup:\nDocker-registry provider: Amazon Elastic Container Registry (ECR)\nPolyaxon version: 1.7.3 CE\nDeployed with Kubernetes on AWS\nAnd Kaniko configuration:\nconnections:\n  - name: docker-registry\n    kind: registry\n    description: \"aws docker repository\"\n    schema:\n      url: https:\/\/ID.dkr.ecr.SOME-REGION.amazonaws.com\n secret:\n      name: aws-secret\n      mountPath: \/root\/.aws\/\n    configMap:\n      name: docker-config\n      mountPath: \/kaniko\/.docker\nAnd polyaxonfile for the build:\nversion: 1.1\nkind: operation\nname: build\nparams:\n  destination:\n    connection: docker-registry\n    value: polyaxon\nrunPatch:\n  init:\n  - dockerfile:\n      image: \"tensorflow\/tensorflow:2.0.1-py3\"\n      run:\n      - 'pip3 install --no-cache-dir -U polyaxon[\"polyboard\",\"polytune\"]'\n      langEnv: 'en_US.UTF-8'\nhubRef: kaniko\nThen raised error:\nConditions:\nTYPE    STATUS    REASON                MESSAGE                                      LAST_UPDATE_TIME    LAST_TRANSITION_TIME\n------  --------  --------------------  -------------------------------------------  ------------------  ----------------------\nfailed  True      BackoffLimitExceeded  Job has reached the specified backoff limit  a few seconds ago   a few seconds ago\n2021-04-19 08:18:08.805683+02:00 | error checking push permissions -- make sure you entered the correct tag name, and that you are authenticated correctly,\n and try again: checking push permission for \"https:\/\/ID.dkr.ecr.REGION.amazonaws.com\/SOME-NAME:SOME-TAG\": creating push check transport for https: failed: Get \"https:\/\/https\/v2\/\": dial tcp: lookup https on SOME-IP: no such host",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-23T12:58:58Z",
                "Answer_score":1,
                "Answer_body":"Resolution:\n\nThis was error on the ECR side. The repo SOME-NAME:SOME-TAG was not existing inside docker registry. Creating SOME-NAME in ECR allowed successful build and push."
            }
        ]
    },
    {
        "Question_title":"Able to push image to ECR with Kaniko but pull stuck on ContainersNotReady containers with unready status: [polyaxon-main polyaxon-sidecar]",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1294",
        "Question_creation_time":1619180115000,
        "Question_answer_count":1,
        "Question_score":2,
        "Question_body":"This question was resolved and discussed on Polyaxon Slack. Posting for visibility if someone stumbles upon the same issue.\n\nGiven setup:\nDocker-registry provider: Amazon Elastic Container Registry (ECR)\nPolyaxon version: 1.7.3 CE\nDeployed with Kubernetes on AWS\nAnd built image at:\n\nID.dkr.ecr.REGION.amazonaws.com\/VALID-DIRECTORY\/VALID-REPO:polyaxon-1\n\nAnd polyaxonfile based on xgboost\/boston example :\n\nyou can see that run.environment was added to expose aws-secret and run.container.image was substituted with above\n\nversion: 1.1\nkind: component\ntags: [examples, xgboost]\ninputs:\n  - {name: max_depth, type: int, isOptional: true, value: 5}\n  - {name: eta, type: float, isOptional: true, value: 0.5}\n  - {name: gamma, type: float, isOptional: true, value: 0.1}\n  - {name: subsample, type: int, isOptional: true, value: 1}\n  - {name: lambda, type: int, isOptional: true, value: 1}\n  - {name: alpha, type: float, isOptional: true, value: 0.35}\n  - {name: objective, type: str, isOptional: true, value: 'reg:squarederror'}\n  - {name: cross_validate, type: bool, isOptional: true, value: false}\nrun:\n  kind: job\n  connections: [docker-registry]\n  environment:\n    imagePullSecrets:\n     - aws-secret\n  init:\n  - git: {\"url\": \"https:\/\/github.com\/polyaxon\/polyaxon-examples\"}\n  container:\n    image: ID.dkr.ecr.REGION.amazonaws.com\/VALID-DIRECTORY\/VALID-REPO:polyaxon-1\n    workingDir: \"{{ globals.artifacts_path }}\/polyaxon-examples\/in_cluster\/xgboost\/boston\"\n    command: [\"python\", \"-u\", \"model.py\"]\n    args: [\n      \"--max_depth={{ max_depth }}\",\n      \"--eta={{ eta }}\",\n      \"--gamma={{ gamma }}\",\n      \"--subsample={{ subsample }}\",\n      \"--lambda={{ lambda }}\",\n      \"--alpha={{ alpha }}\",\n      \"--objective={{ objective }}\",\n      \"--cross_validate={{ cross_validate }}\",\n    ]\nThen experiment would start but would be stuck on status indifinetely:\nConditions:\nTYPE      STATUS    REASON                MESSAGE                                                           LAST_UPDATE_TIME    LAST_TRANSITION_TIME\n--------  --------  --------------------  ----------------------------------------------------------------  ------------------  ----------------------\ncreated   True      OperationServiceInit  Run is created                                                    a few seconds ago   a few seconds ago\ncompiled  True      SchedulerPrepare      Run is compiled                                                   a few seconds ago   a few seconds ago\nqueued    True      SchedulerStart        Run is queued                                                     a few seconds ago   a few seconds ago\nstarting  True      OperatorController    Operation is starting                                             a few seconds ago   a few seconds ago\nwarning   True      ContainersNotReady    containers with unready status: [polyaxon-main polyaxon-sidecar]  a few seconds ago   a few seconds ago\n\nAnd manually creating dummy pod with helm:\n\nwas also not able to be built due to error with pulling the image.\n\napiVersion: v1\nkind: Pod\nmetadata:\n  namespace: POLYAXON_NAMESPACE\nspec:\n  containers:\n  - name: test\n    image: ECR_IMAGE_TO_TEST\n    command:\n    - '\/bin\/bash'\n    - '-c'\n    args:\n    - echo\n    - \"works\"",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-23T12:58:35Z",
                "Answer_score":1,
                "Answer_body":"Resolution:\n\nThe issue was aws credentials.\n\nDisclaimer: I am more of a consumer of Polyaxon and I have limited AWS knowledge so if terminology is not precise that is the reason.\n\nWe were trying two kinds of authorizations:\na. The 12-hour auth that needs refreshing.\nb. The auth with no time constraints.\nWe were not able to work with token A for builds so B was used there .\nThis is when we encountered above error.\nThe dummy pod did not work with token B for build(Kaniko) setting.\nSetting up token A allowed to pull the image from ECR and complete experiment.\n\nWe ended up with having two different types of aws-secrets:\n\nthe indefinite for the build;\n12-hour for pulling images during experiment."
            }
        ]
    },
    {
        "Question_title":"Image push with Kaniko stuck on ContainersNotReady containers with unready status: [polyaxon-main polyaxon-sidecar]",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1296",
        "Question_creation_time":1619182392000,
        "Question_answer_count":1,
        "Question_score":2,
        "Question_body":"This question was resolved and discussed on Polyaxon Slack. Posting for visibility if someone stumbles upon the same issue.\n\nGiven setup:\nDocker-registry provider: Amazon Elastic Container Registry (ECR)\nPolyaxon version: 1.7.3 CE\nDeployed with Kubernetes on AWS\nAnd credentials setup from Kaniko github: Pushing to Amazon ECR\nAnd Kaniko integration in polyaxon-config.yml:\nconnections:\n  - name: docker-registry\n    kind: registry\n    description: \"aws docker repository\"\n    schema:\n      url: https:\/\/ID.dkr.ecr.SOME-REGION.amazonaws.com\n    secret:\n      name: docker-conf\n      mountPath: \/kaniko\/.docker\nAnd polyaxonfile.yml from polyaxon example:\nversion: 1.1\nkind: operation\nname: build\nparams:\n  destination:\n    connection: docker-registry\n    value: polyaxon-examples:ml\nrunPatch:\n  init:\n  - dockerfile:\n      image: \"tensorflow\/tensorflow:2.0.1-py3\"\n      run:\n      - 'pip3 install --no-cache-dir -U polyaxon[\"polyboard\",\"polytune\"]'\n      langEnv: 'en_US.UTF-8'\nhubRef: kaniko\nThen warning was raised:\n\nand job would be stuck like this until manually stopped.\n\nTYPE     STATUS    REASON              MESSAGE                                                           LAST_UPDATE_TIME    LAST_TRANSITION_TIME\n-------  --------  ------------------  ----------------------------------------------------------------  ------------------  ----------------------\nwarning  True      ContainersNotReady  containers with unready status: [polyaxon-main polyaxon-sidecar]  a few seconds ago   a few seconds ago",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-23T12:57:53Z",
                "Answer_score":1,
                "Answer_body":"Resolution:\n\nThe issue was with aws-secret type.\n\nAt first we had the type of secret that expires every 12 hours.\nChanging it to one that does not expire allowed successful connection and push of built image."
            }
        ]
    },
    {
        "Question_title":"Advanced filters for the comparison table",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1287",
        "Question_creation_time":1619177274000,
        "Question_answer_count":0,
        "Question_score":1,
        "Question_body":"We are in the process of thinking about some new ways to simplify filtering runs in the comparison table.\nSome of these filters are:\n\nA filter based on parallel coordinate chart\nA filter based on some other graphs like line chart or a scatter plot\nA filter based on a calendar\nA filter based on a histogram of runs",
        "Answer_list":[

        ]
    },
    {
        "Question_title":"Issue building docker image using example build config",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1303",
        "Question_creation_time":1618113122000,
        "Question_answer_count":14,
        "Question_score":1,
        "Question_body":"Describe the bug\n\nAttempting to deploy the docker image build yaml file available under https:\/\/github.com\/polyaxon\/polyaxon-examples\/blob\/master\/in_cluster\/build_image\/build-ml.yaml using the polyaxon cli returns the following error:\n\n>polyaxon run -f build_docker_image.yaml -l\nPolyaxonfile is not valid.\nError message: The Polyaxonfile's version specified is not supported by your current CLI.Your CLI support Polyaxonfile versions between: 1.1 <= v <= 1.1.You can run `polyaxon upgrade` and check documentation for the specification..\n\nTo reproduce\n\nThe contents of build_docker_image.yaml\n\nversion: 1.1\nkind: operation\nname: build\nparams:\n  destination:\n    connection: localreg\n    value: polyaxon-examples:ml\nrunPatch:\n  init:\n  - dockerfile:\n      image: python:3.8.8-buster\n      run:\n      - 'pip3 install --no-cache-dir -U polyaxon[\"polyboard\"]'\n      - pip3 install scikit-learn xgboost matplotlib vega-datasets joblib lightgbm xgboost\n      langEnv: 'en_US.UTF-8'\nhubRef: kaniko\n\nExpected behavior\n\nA build operation should begin that results in an image being saved to the docker registry connected under destination: connection:\n\nEnvironment\n\nPolyaxon 1.8.0\nPolyaxon CLI 1.8.0",
        "Answer_list":[
            {
                "Answer_creation_time":"2021-04-11T10:26:39Z",
                "Answer_score":1,
                "Answer_body":"Can you check if your environment has by any chance the legacy CLI also installed:\n\npip freeze | grep polyaxon\n\n\nIf it's the case, you need to uninstall the legacy libraries and only keep the new python library."
            },
            {
                "Answer_creation_time":"2021-04-11T12:21:18Z",
                "Answer_score":1,
                "Answer_body":"These are the only two polyaxon libraries installed:\npolyaxon==1.8.0\npolyaxon-sdk==1.8.0"
            },
            {
                "Answer_creation_time":"2021-04-11T12:43:00Z",
                "Answer_score":1,
                "Answer_body":"Libraries installed are correct, I quickly tried and was not able to reproduce the file was submitted correctly.\nWe will check it on Monday."
            },
            {
                "Answer_creation_time":"2021-04-11T18:18:15Z",
                "Answer_score":1,
                "Answer_body":"I can confirm that the same error appears using a freshly installed polyaxon 1.8.0 on the windows subsystem for linux (ubuntu) with the same file."
            },
            {
                "Answer_creation_time":"2021-04-15T12:35:50Z",
                "Answer_score":1,
                "Answer_body":"@mouradmourafiq any updates? :)"
            },
            {
                "Answer_creation_time":"2021-04-15T13:04:02Z",
                "Answer_score":1,
                "Answer_body":"@minaadel sorry, completely forgot about this :)\n\nI think it might be some formatting issues due to windows? Can you run polyaxon check -f FILENAME.yaml\n\nAlso you might copy the content to an editor to check if you are using spaces or tabs, I think yaml has issues with tabs."
            },
            {
                "Answer_creation_time":"2021-04-16T12:32:07Z",
                "Answer_score":1,
                "Answer_body":"No issue, it happens :)\n\nHere's the output of the check command.\n\n>polyaxon check -f build_docker_image.yaml\nPolyaxonfile is not valid.\nError message: The Polyaxonfile's version specified is not supported by your current CLI.Your CLI support Polyaxonfile versions between: 1.1 <= v <= 1.1.You can run `polyaxon upgrade` and check documentation for the specification..\n\n\nThe actual file itself uses 2 spaces per indentation, no tabs"
            },
            {
                "Answer_creation_time":"2021-04-16T13:37:38Z",
                "Answer_score":1,
                "Answer_body":"Very strange, and I could not reproduce. Did you try other files in the same examples folder https:\/\/github.com\/polyaxon\/polyaxon-examples\/tree\/master\/in_cluster\/build_image ?\nNot sure if quoting all values would work on your system:\n\nversion: 1.1\nkind: operation\nname: build\nparams:\n  destination:\n    connection: localreg\n    value: \"polyaxon-examples:ml\"\nrunPatch:\n  init:\n  - dockerfile:\n      image: \"python:3.8.8-buster\"\n      run:\n      - 'pip3 install --no-cache-dir -U polyaxon[\"polyboard\"]'\n      - 'pip3 install scikit-learn xgboost matplotlib vega-datasets joblib lightgbm xgboost'\n      langEnv: 'en_US.UTF-8'\nhubRef: kaniko\n\nFinally you may try with polyaxon -v ... to trigger some additional debug information."
            },
            {
                "Answer_creation_time":"2021-04-16T14:49:19Z",
                "Answer_score":1,
                "Answer_body":"You're absolutely correct!\nSimply quoting all the values did indeed force a new build that was eventually pushed to my connection :)\nThank you very much!\n\nOne last question though (I can open a new issue with the question if you'd like), how am I supposed to pull that same image from the localreg connection from within a polyaxonfile with kind: component (the one I use to run the usual experiments) ?"
            },
            {
                "Answer_creation_time":"2021-04-16T16:07:46Z",
                "Answer_score":1,
                "Answer_body":"I am not sure how you declared the registry and what type of registry you are using, but you will need something like image: url\/image:tag, for instance if you are trying the in-cluster registry (https:\/\/polyaxon.com\/integrations\/in-cluster-registry\/) the image should be:\n\nrun:\n  container:\n    image: \"172.0.0.1:31320\/name:latest\"\n\nIf you are using GCR, the url will be the full GCR url with the image name and tag."
            },
            {
                "Answer_creation_time":"2021-04-16T16:24:04Z",
                "Answer_score":1,
                "Answer_body":"I use the microk8s built in docker registry enabled via\nmicrok8s enable registry\nthis I then connected with polyaxon by using the following snippet in my polyaxon_config file that I pass to helm.\n\nconnections:\n  - name: localreg\n    kind: registry\n    schema: \n      url: 10.152.183.135:5000\n\n\nThe entire reason I'm trying to use a named connection is to abstract from having to use the particular ip of the registry when submitting a job to the polyaxon instance.\nIt's why I came to use the following snippet for the build operation\n\nparams:\n  destination:\n    connection: localreg\n    value: \"docker_img\"\n\n\nand wanted to do something similar with the component operation (experiment run)."
            },
            {
                "Answer_creation_time":"2021-04-16T16:28:50Z",
                "Answer_score":1,
                "Answer_body":"This is planned but not implemented yet, see #1049, where the user can declare a registry-connection:read and registry-connection:write and the system would know if it needs to inject the required info for read or write.\n\nThere's also a discussion going on in slack for providing an automated build process(https:\/\/polyaxon.slack.com\/archives\/C6QBND2SV\/p1618316341162200) but we are still gathering interest and thinking about the best approach to provide such feature."
            },
            {
                "Answer_creation_time":"2021-04-16T17:50:53Z",
                "Answer_score":1,
                "Answer_body":"So if I understand you correctly, there is currently no way to use a polyaxon registry connection to pull an image from that registry. It is currently only possible just to build an image and push it to said registry via the connection. Any image pulling needs to be done using the IP of the registry. Have I understood that properly?"
            },
            {
                "Answer_creation_time":"2021-04-18T14:08:57Z",
                "Answer_score":1,
                "Answer_body":"I guess a kinda hacky way to achieve my particular use case is to define a fixed url in \/var\/snap\/microk8s\/current\/args\/containerd-template.toml\nas\n\n[plugins.cri.registry.mirrors.\"registry:5000\"]\n          endpoint = [\"http:\/\/10.152.183.135:5000\"]\n\n\n\nwhich can be reached in a unified manner from within a polyaxon run as:\n\ncontainer:\n    image: \"registry:5000\/image\"\n\n\nThank you very much for your assistance :)"
            }
        ]
    },
    {
        "Question_title":"Allow annotations in connections",
        "Question_link":"https:\/\/github.com\/orgs\/polyaxon\/discussions\/1304",
        "Question_creation_time":1593440974000,
        "Question_answer_count":0,
        "Question_score":1,
        "Question_body":"Use case\n\nWe would like to use Vault for managing some connection's secrets.\n\nEDIT: Different use case where node scheduling can be also linked directly to a connection:\n\nWhen I need to iterate multiple times over the input data I would like to copy the data from the network storage to the SSD of the experiment machine as first step in my polyaxon file and then use that local copy to iterate on.\n\nIn this case we might want to always schedule a connection with a specific node or nodes(s).\n\nFeature description\nAllow annotations in connections.\nAllow node scheduling in connections.\nAlternatives\n\nI think these use-cases can be manged right now using RunProfile.\n\nN.B. the second issue was raised by a CE user, where the RunProfile is not accessible.\n\nConsiderations\n\nIf we provide annotations\/node-scheduling and other meta-data in connections we need to think about:\n\nThe overlap between the RunProfile and Connection concepts. RunProfile concept still handles more logic, but we should not duplicate efforts\nIf both concepts provide overlapping logic it can result in unexpected behaviour.",
        "Answer_list":[

        ]
    }
]